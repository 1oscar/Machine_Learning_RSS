<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>智能单元 - 知乎专栏</title><link>https://zhuanlan.zhihu.com/intelligentunit</link><description>斯坦福CS231n官方教程笔记翻译连载。

深度增强学习领域论文和项目的原创思考和Demo复现。

领域内其他感兴趣论文和项目的原创思考解读。</description><lastBuildDate>Thu, 18 Aug 2016 08:21:40 GMT</lastBuildDate><generator>Ricky</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>智能单元专栏投稿说明</title><link>https://zhuanlan.zhihu.com/p/21917736</link><description>&lt;p&gt;&lt;img src="https://pic3.zhimg.com/7d2d39eb9ae721a13607713c73193172_r.jpg"&gt;&lt;/p&gt;首先感谢各位知友对于本专栏的支持！发布本说明是因为收到知友的投稿和建议，促使我和&lt;a href="https://www.zhihu.com/people/23deec836a24f295500a6d740011359c" data-hash="23deec836a24f295500a6d740011359c" class="member_mention" data-title="@Flood Sung" data-tip="p$b$23deec836a24f295500a6d740011359c"&gt;@Flood Sung&lt;/a&gt; 重新思考专栏的定位和意义。&lt;h2&gt;来龙去脉&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;原本定位&lt;/b&gt;：这个专栏&lt;b&gt;原本只是我们整理记录深度学习笔记和思考的地方&lt;/b&gt;，立足相互促进学习，自产自销，没考虑过有人投稿。由于各位知友抬爱，也收到了一些投稿及意见。&lt;br&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;主要疑虑&lt;/b&gt;：接受投稿，就要负起审稿甚至查询是否原创等相关责任，而我们时间有限，刚开始存在多一事不如少一事的心理。自己写的文章，自己把关。面对知友的投稿，我们可能方向不同，或水平有限，也难以做出权威的判断。&lt;br&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;主要动力&lt;/b&gt;：知友的支持，增进交流的初心和把专栏做好的小小成就感。最终，我们还是决定开放投稿，并讨论出一些向本专栏投稿的原则性思路。&lt;br&gt;&lt;/li&gt;&lt;/ul&gt;&lt;br&gt;&lt;p&gt;&lt;b&gt;重要说明&lt;/b&gt;：我们只是凭借自己的知识背景进行讨论，缺乏更多法律背景上的相关知识，&lt;u&gt;&lt;b&gt;如果知友发现我们的投稿要求有不妥的地方，敬请评论或私信指正&lt;/b&gt;！&lt;/u&gt;我们也&lt;b&gt;会根据大家的反馈持续对下面的投稿要求进行修改&lt;/b&gt;。&lt;/p&gt;&lt;h2&gt;向专栏投稿&lt;/h2&gt;&lt;p&gt;&lt;b&gt;投稿原则&lt;/b&gt;：本专栏接受的投稿应满足：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;原创&lt;/b&gt;：我们更推崇原创的实践与思考，以及由此而激起的理性探讨交流。不强求首发，如果您想投稿自己以前的文章，也是可以的。&lt;/li&gt;&lt;li&gt;&lt;b&gt;题材&lt;/b&gt;：深度学习相关的技术内容。比如前沿的新技术原创实践与思考，重要的资料翻译，和自己的实践与思考总结等。&lt;/li&gt;&lt;li&gt;&lt;b&gt;排版&lt;/b&gt;：请合理使用知乎的文章的编辑功能，让排版简约大方。&lt;/li&gt;&lt;li&gt;&lt;b&gt;版权&lt;/b&gt;：&lt;b&gt;版权归原作者所有&lt;/b&gt;。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;赞赏所得&lt;/b&gt;：本专栏已经开通赞赏功能，&lt;b&gt;赞赏所得归投稿者所有&lt;/b&gt;。具体操作请参考知乎产品专栏中的说明：&lt;a href="https://zhuanlan.zhihu.com/p/21268480?refer=zhihu-product" data-title="知乎专栏文章开始内测" class=""&gt;知乎专栏文章开始内测&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;&lt;b&gt;审稿原则&lt;/b&gt;：我们会在认真阅读投稿后和你进行讨论。如果在投稿题材上不是很有把握，也可以直接私信&lt;a href="https://www.zhihu.com/people/928affb05b0b70a2c12e109d63b6bae5" data-hash="928affb05b0b70a2c12e109d63b6bae5" class="member_mention" data-title="@杜客" data-tip="p$b$928affb05b0b70a2c12e109d63b6bae5"&gt;@杜客&lt;/a&gt; 或&lt;a href="https://www.zhihu.com/people/23deec836a24f295500a6d740011359c" data-hash="23deec836a24f295500a6d740011359c" class="member_mention" data-tip="p$b$23deec836a24f295500a6d740011359c"&gt;@Flood Sung&lt;/a&gt; 提前交流。 &lt;/p&gt;&lt;h2&gt;最后的话&lt;/h2&gt;&lt;p&gt;期待更多小伙伴的投稿、交流和拍砖的同时，我和&lt;a href="https://www.zhihu.com/people/23deec836a24f295500a6d740011359c" data-hash="23deec836a24f295500a6d740011359c" class="member_mention" data-tip="p$b$23deec836a24f295500a6d740011359c"&gt;@Flood Sung&lt;/a&gt; 依旧会坚持原创与翻译，保证高质量的输出。&lt;/p&gt;</description><author>杜客</author><pubDate>Sun, 14 Aug 2016 21:30:21 GMT</pubDate></item><item><title>斯坦福CS231n课程作业# 3简介</title><link>https://zhuanlan.zhihu.com/p/21946525</link><description>&lt;p&gt;&lt;img src="https://pic4.zhimg.com/89758df295a0927d26da59356338a2ff_r.jpg"&gt;&lt;/p&gt;译者注：本文&lt;a href="https://zhuanlan.zhihu.com/intelligentunit" class="" data-editable="true" data-title="智能单元"&gt;智能单元&lt;/a&gt;首发，由@&lt;a href="https://www.zhihu.com/people/du-ke" class="" data-editable="true" data-title="杜客"&gt;杜客&lt;/a&gt;翻译自斯坦福CS231n课程作业1介绍页面&lt;a href="http://cs231n.github.io/assignments2016/assignment2/" class="" data-editable="true" data-title="[Assignment #2]"&gt;[Assignment #2]&lt;/a&gt;。&lt;h2&gt;原文如下&lt;/h2&gt;&lt;p&gt;在本作业中，你将实现循环网络，并将其应用于在微软的COCO数据库上进行图像标注。我们还会介绍TinyImageNet数据集，然后在这个数据集使用一个预训练的模型来查看图像梯度的不同应用。本作业的目标如下：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;理解&lt;i&gt;循环神经网络（RNN）&lt;/i&gt;的结构，知道它们是如何随时间共享权重来对序列进行操作的。&lt;/li&gt;&lt;li&gt;理解普通循环神经网络和长短基记忆（Long-Short Term Memory）循环神经网络之间的差异。&lt;/li&gt;&lt;li&gt;理解在测试时如何从RNN生成序列。&lt;/li&gt;&lt;li&gt;理解如何将卷积神经网络和循环神经网络结合在一起来实现图像标注。&lt;/li&gt;&lt;li&gt;理解一个训练过的卷积神经网络是如何用来从输入图像中计算梯度的。&lt;/li&gt;&lt;li&gt;进行高效的交叉验证并为神经网络结构找到最好的超参数。&lt;/li&gt;&lt;li&gt;实现图像梯度的不同应用，比如显著图，搞笑图像，类别可视化，特征反演和DeepDream。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;安装&lt;/h2&gt;&lt;p&gt;有两种方法来完成作业：在本地使用自己的机器，或者使用&lt;a href="https://link.zhihu.com/?target=http%3A//Terminal.com" class="" data-editable="true" data-title="http://Terminal.com"&gt;http://Terminal.com&lt;/a&gt;的虚拟机。&lt;br&gt;&lt;/p&gt;&lt;h3&gt;云端作业&lt;/h3&gt;&lt;p&gt;Terminal公司为我们的课程创建了一个单独的子域名：&lt;a href="https://link.zhihu.com/?target=https%3A//www.stanfordterminalcloud.com/" class="" data-editable="true" data-title="www.stanfordterminalcloud.com"&gt;www.stanfordterminalcloud.com&lt;/a&gt;。在该域名下注册。作业2的快照可以在&lt;a href="https://link.zhihu.com/?target=https%3A//www.stanfordterminalcloud.com/snapshot/49f5a1ea15dc424aec19155b3398784d57c55045435315ce4f8b96b62819ef65" class="" data-editable="true" data-title="这里"&gt;这里&lt;/a&gt;找到。如果你注册到了本课程，就可以联系上助教（更多信息请上Piazza）来得到用来做作业的点数。一旦你启动了快照，所有的环境都是为你配置好的，马上就可以开始作业。我们在Terminal上写了一个简明&lt;a href="https://link.zhihu.com/?target=http%3A//cs231n.github.io/terminal-tutorial/" class="" data-editable="true" data-title="教程"&gt;教程&lt;/a&gt;。&lt;br&gt;&lt;/p&gt;&lt;h3&gt;本地作业&lt;/h3&gt;&lt;p&gt;点击&lt;a href="http://cs231n.stanford.edu/winter1516_assignment3.zip" class="" data-editable="true" data-title="此处"&gt;此处&lt;/a&gt;下载代码压缩文件。初次之外还有些库间依赖的配置：&lt;/p&gt;&lt;p&gt;&lt;b&gt;[选项1]使用Anaconda&lt;/b&gt;：推荐方法是安装&lt;a href="https://link.zhihu.com/?target=https%3A//www.continuum.io/downloads" class="" data-editable="true" data-title="Anaconda"&gt;Anaconda&lt;/a&gt;，它是Python的一个发布版，包含了最流行的科研、数学、工程和数据分析Python包。一旦安装了它，下面的提示就都可略过，准备直接开始写作业吧。&lt;i&gt;译者注：推荐。&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;[选项2]手动安装，虚拟环境&lt;/b&gt;：如果你不想用Anaconda，想要走一个充满风险的手动安装路径，那么可能就要为项目创建一个&lt;a href="https://link.zhihu.com/?target=http%3A//docs.python-guide.org/en/latest/dev/virtualenvs/" class="" data-editable="true" data-title="虚拟环境"&gt;虚拟环境&lt;/a&gt;了。如果你不想用虚拟环境，那么你的确保所有代码需要的依赖关系都是景在你的机器上被安装了。要建立虚拟环境，运行下面代码：&lt;/p&gt;&lt;code lang="text"&gt;cd assignment3
sudo pip install virtualenv      # This may already be installed
virtualenv .env                  # Create a virtual environment
source .env/bin/activate         # Activate the virtual environment
pip install -r requirements.txt  # Install dependencies
# Work on the assignment for a while ...
deactivate                       # Exit the virtual environment
&lt;/code&gt;&lt;p&gt;&lt;b&gt;下载数据&lt;/b&gt;：一旦得到作业初始代码，你就需要下载CIFAR-10数据集，然后在assignment1目录下运行下面代码：&lt;i&gt;译者注：也可手动下载解压后放到&lt;/i&gt;&lt;i&gt;cs231n/datasets目录&lt;/i&gt;&lt;i&gt;。&lt;/i&gt;&lt;/p&gt;&lt;code lang="text"&gt;cd cs231n/datasets 
./get_coco_captioning.sh
./get_tiny_imagenet_a.sh
./get_pretrained_model.sh
&lt;/code&gt;&lt;p&gt;&lt;b&gt;编译Cython扩展包&lt;/b&gt;：卷积神经网络需要一个高效的实现。我们使用&lt;a href="http://cython.org/" data-editable="true" data-title="Cython" class=""&gt;Cython&lt;/a&gt;实现了一些函数。在运行代码前，你需要编译Cython扩展包。在cs231n目录下，运行下面命令：&lt;/p&gt;&lt;code lang="text"&gt;python setup.py build_ext --inplace
&lt;/code&gt;&lt;p&gt;&lt;b&gt;启用IPython&lt;/b&gt;：得到了CIFAR-10数据集之后，你应该在作业assignment1目录中启用IPython notebook的服务器，如果对IPython notebook不熟悉，可以阅读&lt;a href="https://link.zhihu.com/?target=http%3A//cs231n.github.io/ipython-tutorial" class="" data-editable="true" data-title="教程"&gt;教程&lt;/a&gt;。&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;注意&lt;/b&gt;：如果你是在OSX上的虚拟环境中工作，可能会遇到一个由matplotlib导致的错误，原因在&lt;a href="https://link.zhihu.com/?target=http%3A//matplotlib.org/faq/virtualenv_faq.html" class="" data-editable="true" data-title="这里"&gt;这里&lt;/a&gt;。你可以通过在assignment2目录中运行start_ipython_osx.sh脚本来解决问题。&lt;/p&gt;&lt;h2&gt;提交作业&lt;/h2&gt;&lt;p&gt;无论你是在云终端还是在本地完成作业，一旦完成作业，就运行collectSubmission.sh脚本；这样将会产生一个assignment3.zip的文件，然后将这个文件上传到你的dropbox中这门课的&lt;a href="https://coursework.stanford.edu/portal/site/W15-CS-231N-01/" class="" data-editable="true" data-title="作业页面"&gt;作业页面&lt;/a&gt;。&lt;/p&gt;&lt;h3&gt;Q1：使用普通RNN进行图像标注（40分）&lt;/h3&gt;&lt;p&gt;IPython Notebook文件&lt;b&gt;RNN_Captioning.ipynb&lt;/b&gt;将会带你使用普通RNN实现一个在微软COCO数据集上的图像标注系统。&lt;/p&gt;&lt;h3&gt;Q2：使用LSTM进行图像标注（35分）&lt;/h3&gt;&lt;p&gt;IPython Notebook文件&lt;b&gt;LSTM_Captioning.ipynb&lt;/b&gt;将会带你实现LSTM，并应用于在微软COCO数据集上进行图像标注。&lt;br&gt;&lt;/p&gt;&lt;h3&gt;Q3：图像梯度：显著图和高效图像（10分）&lt;/h3&gt;&lt;p&gt;IPython Notebook文件&lt;b&gt;ImageGradients.ipynb&lt;/b&gt;将会介绍TinyImageNet数据集。你将使用一个训练好的模型在这个数据集上计算梯度，然后将其用于生成显著图和高效图像。&lt;/p&gt;&lt;h3&gt;Q4：图像生成：类别，反演和DeepDream（30分）&lt;/h3&gt;&lt;p&gt;在IPython Notebook文件&lt;b&gt;ImageGeneration.ipynb&lt;/b&gt;中，你将使用一个训练好的TinyImageNet模型来生成图像。具体说来，你将生成类别可视化，实现特征反演和DeepDream。&lt;/p&gt;&lt;br&gt;&lt;h3&gt;Q5：做点儿其他的！（+10分）&lt;br&gt;&lt;/h3&gt;&lt;p&gt;根据作业内容，做点够酷的事儿。比如作业中没有讲过的其他生成图像的方式？&lt;/p&gt;&lt;p&gt;&lt;b&gt;全文完。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;译者反馈：&lt;/h2&gt;&lt;ol&gt;&lt;li&gt;转载须全文转载并注明原文链接，否则保留维权权利；&lt;br&gt;&lt;/li&gt;&lt;li&gt;如对翻译有意见建议，请通过评论批评指正，贡献者均会补充提及；&lt;/li&gt;&lt;li&gt;后续将根据作业内容和自己的学习笔记原创教程。&lt;/li&gt;&lt;/ol&gt;</description><author>杜客</author><pubDate>Thu, 11 Aug 2016 06:30:36 GMT</pubDate></item><item><title>斯坦福CS231n课程作业# 2简介</title><link>https://zhuanlan.zhihu.com/p/21941485</link><description>&lt;p&gt;&lt;img src="https://pic1.zhimg.com/4b4c825806caf0c939f97a95be32944c_r.jpg"&gt;&lt;/p&gt;译者注：本文&lt;a href="https://zhuanlan.zhihu.com/intelligentunit" class="" data-editable="true" data-title="智能单元"&gt;智能单元&lt;/a&gt;首发，由@&lt;a href="https://www.zhihu.com/people/du-ke" class="" data-editable="true" data-title="杜客"&gt;杜客&lt;/a&gt;翻译自斯坦福CS231n课程作业1介绍页面&lt;a href="http://cs231n.github.io/assignments2016/assignment2/" class="" data-editable="true" data-title="[Assignment #2]"&gt;[Assignment #2]&lt;/a&gt;。&lt;h2&gt;原文如下&lt;/h2&gt;&lt;p&gt;在本作业中，你将练习编写反向传播代码，训练神经网络和卷积神经网络。本作业的目标如下：&lt;/p&gt;&lt;br&gt;&lt;ul&gt;&lt;li&gt;理解&lt;b&gt;神经网络&lt;/b&gt;及其分层结构。&lt;/li&gt;&lt;li&gt;理解并实现（向量化）&lt;b&gt;反向传播&lt;/b&gt;。&lt;/li&gt;&lt;li&gt;实现多个用于神经网络最优化的&lt;b&gt;更新方法&lt;/b&gt;。&lt;/li&gt;&lt;li&gt;实现用于训练深度网络的&lt;b&gt;批量归一化&lt;/b&gt;（ &lt;strong&gt;batch normalization&lt;/strong&gt; ）。&lt;/li&gt;&lt;li&gt;实现&lt;b&gt;随机失活&lt;/b&gt;（&lt;b&gt;dropout&lt;/b&gt;）。&lt;/li&gt;&lt;li&gt;进行高效的&lt;b&gt;交叉验证&lt;/b&gt;并为神经网络结构找到最好的超参数。&lt;/li&gt;&lt;li&gt;理解&lt;b&gt;卷积神经网络&lt;/b&gt;的结构，并积累在数据集上训练此类模型的经验。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;安装&lt;/h2&gt;&lt;p&gt;有两种方法来完成作业：在本地使用自己的机器，或者使用&lt;a href="https://link.zhihu.com/?target=http%3A//Terminal.com" class="" data-editable="true" data-title="http://Terminal.com"&gt;http://Terminal.com&lt;/a&gt;的虚拟机。&lt;br&gt;&lt;/p&gt;&lt;h3&gt;云端作业&lt;/h3&gt;&lt;p&gt;Terminal公司为我们的课程创建了一个单独的子域名：&lt;a href="https://link.zhihu.com/?target=https%3A//www.stanfordterminalcloud.com/" class="" data-editable="true" data-title="www.stanfordterminalcloud.com"&gt;www.stanfordterminalcloud.com&lt;/a&gt;。在该域名下注册。作业2的快照可以在&lt;a href="https://link.zhihu.com/?target=https%3A//www.stanfordterminalcloud.com/snapshot/49f5a1ea15dc424aec19155b3398784d57c55045435315ce4f8b96b62819ef65" class="" data-editable="true" data-title="这里"&gt;这里&lt;/a&gt;找到。如果你注册到了本课程，就可以联系上助教（更多信息请上Piazza）来得到用来做作业的点数。一旦你启动了快照，所有的环境都是为你配置好的，马上就可以开始作业。我们在Terminal上写了一个简明&lt;a href="https://link.zhihu.com/?target=http%3A//cs231n.github.io/terminal-tutorial/" class="" data-editable="true" data-title="教程"&gt;教程&lt;/a&gt;。&lt;br&gt;&lt;/p&gt;&lt;br&gt;&lt;h3&gt;本地作业&lt;/h3&gt;&lt;p&gt;点击&lt;a href="http://vision.stanford.edu/teaching/cs231n/winter1516_assignment2.zip" class="" data-editable="true" data-title="此处"&gt;此处&lt;/a&gt;下载代码压缩文件。初次之外还有些库间依赖的配置：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;[选项1]使用Anaconda&lt;/strong&gt;：推荐方法是安装&lt;a href="https://link.zhihu.com/?target=https%3A//www.continuum.io/downloads" class="" data-editable="true" data-title="Anaconda"&gt;Anaconda&lt;/a&gt;，它是Python的一个发布版，包含了最流行的科研、数学、工程和数据分析Python包。一旦安装了它，下面的提示就都可略过，准备直接开始写作业吧。&lt;i&gt;&lt;b&gt;译者注：推荐。&lt;/b&gt;&lt;/i&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;strong&gt;[选项2]手动安装，虚拟环境&lt;/strong&gt;：如果你不想用Anaconda，想要走一个充满风险的手动安装路径，那么可能就要为项目创建一个&lt;a href="https://link.zhihu.com/?target=http%3A//docs.python-guide.org/en/latest/dev/virtualenvs/" class="" data-editable="true" data-title="虚拟环境"&gt;虚拟环境&lt;/a&gt;了。如果你不想用虚拟环境，那么你的确保所有代码需要的依赖关系都是景在你的机器上被安装了。要建立虚拟环境，运行下面代码：&lt;/p&gt;&lt;br&gt;&lt;code lang="text"&gt;cd assignment2
sudo pip install virtualenv      # This may already be installed
virtualenv .env                  # Create a virtual environment
source .env/bin/activate         # Activate the virtual environment
pip install -r requirements.txt  # Install dependencies
# Work on the assignment for a while ...
deactivate                       # Exit the virtual environment
&lt;/code&gt;&lt;p&gt;&lt;strong&gt;下载数据&lt;/strong&gt;：一旦得到作业初始代码，你就需要下载CIFAR-10数据集，然后在&lt;b&gt;assignment1&lt;/b&gt;目录下运行下面代码：&lt;i&gt;&lt;b&gt;译者注：也可手动下载解压后放到&lt;/b&gt;&lt;/i&gt;&lt;i&gt;&lt;b&gt;cs231n/datasets目录&lt;/b&gt;&lt;/i&gt;&lt;i&gt;&lt;b&gt;。&lt;/b&gt;&lt;/i&gt;&lt;/p&gt;&lt;br&gt;&lt;code lang="text"&gt;cd cs231n/datasets 
./get_datasets.sh
&lt;/code&gt;&lt;p&gt;&lt;strong&gt;编译Cython扩展包：&lt;/strong&gt;卷积神经网络需要一个高效的实现。我们使用&lt;a href="http://cython.org/" data-editable="true" data-title="Cython" class=""&gt;Cython&lt;/a&gt;实现了一些函数。在运行代码前，你需要编译Cython扩展包。在&lt;b&gt;cs231n&lt;/b&gt;目录下，运行下面命令：&lt;/p&gt;&lt;code lang="text"&gt;python setup.py build_ext --inplace
&lt;/code&gt;&lt;p&gt;&lt;strong&gt;启用IPython&lt;/strong&gt;：得到了CIFAR-10数据集之后，你应该在作业&lt;b&gt;assignment1&lt;/b&gt;目录中启用IPython notebook的服务器，如果对IPython notebook不熟悉，可以阅读&lt;a href="https://link.zhihu.com/?target=http%3A//cs231n.github.io/ipython-tutorial" class="" data-editable="true" data-title="教程"&gt;教程&lt;/a&gt;。&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;注意&lt;/strong&gt;：如果你是在OSX上的虚拟环境中工作，可能会遇到一个由&lt;strong&gt;matplotlib&lt;/strong&gt;导致的错误，原因在&lt;a href="https://link.zhihu.com/?target=http%3A//matplotlib.org/faq/virtualenv_faq.html" class="" data-editable="true" data-title="这里"&gt;这里&lt;/a&gt;。你可以通过在&lt;b&gt;assignment2&lt;/b&gt;目录中运行&lt;b&gt;start_ipython_osx.sh&lt;/b&gt;脚本来解决问题。&lt;/p&gt;&lt;br&gt;&lt;h2&gt;提交作业&lt;/h2&gt;&lt;p&gt;无论你是在云终端还是在本地完成作业，一旦完成作业，就运行&lt;b&gt;collectSubmission.sh&lt;/b&gt;脚本；这样将会产生一个&lt;b&gt;assignment2.zip&lt;/b&gt;的文件，然后将这个文件上传到你的dropbox中这门课的&lt;a href="https://coursework.stanford.edu/portal/site/W15-CS-231N-01/" class="" data-editable="true" data-title="作业页面"&gt;作业页面&lt;/a&gt;。&lt;/p&gt;&lt;h3&gt;Q1：全连接神经网络（30分）&lt;/h3&gt;&lt;p&gt;IPython Notebook文件&lt;b&gt;FullyConnectedNets&lt;/b&gt;&lt;strong&gt;.ipynb&lt;/strong&gt;将会向你介绍我们的模块化设计，然后使用不同的层来构建任意深度的全连接网络。为了对模型进行最优化，还需要实现几个常用的更新方法。&lt;/p&gt;&lt;h3&gt;Q2：批量归一化（30分）&lt;/h3&gt;&lt;p&gt;在IPython Notebook文件&lt;b&gt;BatchNormalization.ipynb&lt;/b&gt;中，你需要实现批量归一化，然后将其应用于深度全连接网络的训练中。&lt;br&gt;&lt;/p&gt;&lt;h3&gt;Q3：随机失活（Dropout）（10分）&lt;/h3&gt;&lt;p&gt;IPython Notebook文件&lt;b&gt;Dropout.ipynb&lt;/b&gt;将会帮助你需要实现随机失活，然后在模型泛化中检查它的效果。&lt;/p&gt;&lt;h3&gt;Q4：在CIFAR-10上运行卷积神经网络（30分）&lt;/h3&gt;&lt;p&gt;在IPython Notebook文件&lt;b&gt;ConvolutionalNetworks.ipynb&lt;/b&gt;中，你将实现几个卷积神经网络中常用的新的层。你将在CIFAR-10上训练一个深度较浅的卷积神经网络，然后由你决定竭尽所能地训练处一个最好网络。&lt;/p&gt;&lt;h3&gt;Q5：做点儿其他的！（+10分）&lt;br&gt;&lt;/h3&gt;&lt;p&gt;在训练网络的过程中，为了得到更好的结果，你可以自由实现任何想法。你可以修改训练器（solver），实现额外的层，使用不同的正则化方法，使用模型集成，或者任何其它你想到的东西。如果你实现了作业要求以外的内容，那么将得到加分。&lt;/p&gt;&lt;p&gt;&lt;b&gt;全文完。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;译者反馈：&lt;/h2&gt;&lt;ol&gt;&lt;li&gt;转载须全文转载并注明原文链接，否则保留维权权利；&lt;br&gt;&lt;/li&gt;&lt;li&gt;如对翻译有意见建议，请通过评论批评指正，贡献者均会补充提及；&lt;/li&gt;&lt;li&gt;后续将根据作业内容和自己的学习笔记原创教程。&lt;/li&gt;&lt;/ol&gt;</description><author>杜客</author><pubDate>Wed, 10 Aug 2016 11:19:25 GMT</pubDate></item><item><title>CS231n课程笔记翻译：神经网络笔记3（下）</title><link>https://zhuanlan.zhihu.com/p/21798784</link><description>&lt;p&gt;&lt;img src="https://pic4.zhimg.com/940c2e8d2edc3018771c752d977a6f27_r.png"&gt;&lt;/p&gt;译者注：本文&lt;a href="https://zhuanlan.zhihu.com/intelligentunit" data-editable="true" data-title="智能单元" class=""&gt;智能单元&lt;/a&gt;首发，译自斯坦福CS231n课程笔记&lt;a href="http://cs231n.github.io/neural-networks-3/" class="" data-editable="true" data-title="Neural Nets notes 3"&gt;Neural Nets notes 3&lt;/a&gt;，课程教师&lt;a href="https://link.zhihu.com/?target=http%3A//cs.stanford.edu/people/karpathy/" class="" data-editable="true" data-title="Andrej Karpathy"&gt;Andrej Karpathy&lt;/a&gt;授权翻译。本篇教程由&lt;a href="https://www.zhihu.com/people/du-ke" class="" data-editable="true" data-title="杜客"&gt;杜客&lt;/a&gt;翻译完成，&lt;a href="https://www.zhihu.com/people/kun-kun-97-81" class="" data-editable="true" data-title="堃堃"&gt;堃堃&lt;/a&gt;和&lt;a href="https://www.zhihu.com/people/hmonkey" class="" data-editable="true" data-title="巩子嘉"&gt;巩子嘉&lt;/a&gt;进行校对修改。译文含公式和代码，建议PC端阅读。&lt;h2&gt;原文如下&lt;/h2&gt;&lt;p&gt;内容列表：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;梯度检查&lt;/li&gt;&lt;li&gt;合理性（Sanity）检查&lt;/li&gt;&lt;li&gt;检查学习过程&lt;ul&gt;&lt;li&gt;损失函数&lt;/li&gt;&lt;li&gt;训练与验证准确率&lt;/li&gt;&lt;li&gt;权重：更新比例&lt;/li&gt;&lt;li&gt;每层的激活数据与梯度分布&lt;/li&gt;&lt;li&gt;可视化 &lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;参数更新 &lt;i&gt;&lt;b&gt;译者注：下篇翻译起始处&lt;/b&gt;&lt;/i&gt;&lt;ul&gt;&lt;li&gt;一阶（随机梯度下降）方法，动量方法，Nesterov动量方法&lt;/li&gt;&lt;li&gt;学习率退火&lt;/li&gt;&lt;li&gt;二阶方法&lt;/li&gt;&lt;li&gt;逐参数适应学习率方法（Adagrad，RMSProp）&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;超参数调优&lt;/li&gt;&lt;li&gt;评价&lt;ul&gt;&lt;li&gt;模型集成&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;总结&lt;/li&gt;&lt;li&gt;拓展引用&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;参数更新&lt;/h2&gt;&lt;p&gt;一旦能使用反向传播计算解析梯度，梯度就能被用来进行参数更新了。进行参数更新有好几种方法，接下来都会进行讨论。&lt;/p&gt;&lt;p&gt;深度网络的最优化是现在非常活跃的研究领域。本节将重点介绍一些公认有效的常用的技巧，这些技巧都是在实践中会遇到的。我们将简要介绍这些技巧的直观概念，但不进行细节分析。对于细节感兴趣的读者，我们提供了一些拓展阅读。&lt;/p&gt;&lt;h3&gt;随机梯度下降及各种更新方法&lt;/h3&gt;&lt;p&gt;&lt;b&gt;普通更新&lt;/b&gt;。最简单的更新形式是沿着负梯度方向改变参数（因为梯度指向的是上升方向，但是我们通常希望最小化损失函数）。假设有一个参数向量&lt;b&gt;x&lt;/b&gt;及其梯度&lt;b&gt;dx&lt;/b&gt;，那么最简单的更新的形式是：&lt;/p&gt;&lt;code lang="python"&gt;# 普通更新
x += - learning_rate * dx
&lt;/code&gt;&lt;p&gt;其中learning_rate是一个超参数，它是一个固定的常量。当在整个数据集上进行计算时，只要学习率足够低，总是能在损失函数上得到非负的进展。&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;动量（&lt;/b&gt;&lt;strong&gt;Momentum&lt;/strong&gt;&lt;b&gt;）更新&lt;/b&gt;是另一个方法，这个方法在深度网络上几乎总能得到更好的收敛速度。该方法可以看成是从物理角度上对于最优化问题得到的启发。损失值可以理解为是山的高度（因此高度势能是&lt;equation&gt;U=mgh&lt;/equation&gt;，所以有&lt;equation&gt;U\propto h&lt;/equation&gt;）。用随机数字初始化参数等同于在某个位置给质点设定初始速度为0。这样最优化过程可以看做是模拟参数向量（即质点）在地形上滚动的过程。&lt;/p&gt;&lt;p&gt;因为作用于质点的力与梯度的潜在能量（&lt;equation&gt;F=-\nabla U&lt;/equation&gt;）有关，质点&lt;b&gt;所受的力&lt;/b&gt;就是损失函数的&lt;b&gt;（负）梯度&lt;/b&gt;。还有，因为&lt;equation&gt;F=ma&lt;/equation&gt;，所以在这个观点下（负）梯度与质点的加速度是成比例的。注意这个理解和上面的随机梯度下降（SDG）是不同的，在普通版本中，梯度直接影响位置。而在这个版本的更新中，物理观点建议梯度只是影响速度，然后速度再影响位置：&lt;/p&gt;&lt;br&gt;&lt;code lang="python"&gt;# 动量更新
v = mu * v - learning_rate * dx # 与速度融合
x += v # 与位置融合
&lt;/code&gt;&lt;p&gt;在这里引入了一个初始化为0的变量&lt;b&gt;v&lt;/b&gt;和一个超参数&lt;b&gt;mu&lt;/b&gt;。说得不恰当一点，这个变量（mu）在最优化的过程中被看做&lt;i&gt;动量&lt;/i&gt;（一般值设为0.9），但其物理意义与摩擦系数更一致。这个变量有效地抑制了速度，降低了系统的动能，不然质点在山底永远不会停下来。通过交叉验证，这个参数通常设为[0.5,0.9,0.95,0.99]中的一个。和学习率随着时间退火（下文有讨论）类似，动量随时间变化的设置有时能略微改善最优化的效果，其中动量在学习过程的后阶段会上升。一个典型的设置是刚开始将动量设为0.5而在后面的多个周期（epoch）中慢慢提升到0.99。&lt;/p&gt;&lt;br&gt;&lt;blockquote&gt;&lt;p&gt;通过动量更新，参数向量会在任何有持续梯度的方向上增加速度。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;b&gt;Nesterov动量&lt;/b&gt;与普通动量有些许不同，最近变得比较流行。在理论上对于凸函数它能得到更好的收敛，在实践中也确实比标准动量表现更好一些。&lt;/p&gt;&lt;br&gt;&lt;p&gt;Nesterov动量的核心思路是，当参数向量位于某个位置&lt;b&gt;x&lt;/b&gt;时，观察上面的动量更新公式可以发现，动量部分（忽视带梯度的第二个部分）会通过&lt;b&gt;mu * v&lt;/b&gt;稍微改变参数向量。因此，如果要计算梯度，那么可以将未来的近似位置&lt;b&gt;x + mu * v&lt;/b&gt;看做是“向前看”，这个点在我们一会儿要停止的位置附近。因此，计算&lt;b&gt;x + mu * v&lt;/b&gt;的梯度而不是“旧”位置&lt;b&gt;x&lt;/b&gt;的梯度就有意义了。&lt;/p&gt;&lt;p&gt;————————————————————————————————————————&lt;/p&gt;&lt;img src="412afb713ddcff0ba9165ab026563304.png" data-rawwidth="1580" data-rawheight="514"&gt;&lt;p&gt;Nesterov动量。既然我们知道动量将会把我们带到绿色箭头指向的点，我们就不要在原点（红色点）那里计算梯度了。使用Nesterov动量，我们就在这个“向前看”的地方计算梯度。&lt;/p&gt;&lt;br&gt;&lt;p&gt;————————————————————————————————————————&lt;/p&gt;&lt;p&gt;也就是说，添加一些注释后，实现代码如下：&lt;br&gt;&lt;/p&gt;&lt;code lang="python"&gt;x_ahead = x + mu * v
# 计算dx_ahead(在x_ahead处的梯度，而不是在x处的梯度)
v = mu * v - learning_rate * dx_ahead
x += v
&lt;/code&gt;&lt;p&gt;然而在实践中，人们更喜欢和普通SGD或上面的动量方法一样简单的表达式。通过对&lt;b&gt;x_ahead = x + mu * v&lt;/b&gt;使用变量变换进行改写是可以做到的，然后用&lt;b&gt;x_ahead&lt;/b&gt;而不是&lt;b&gt;x&lt;/b&gt;来表示上面的更新。也就是说，实际存储的参数向量总是向前一步的那个版本。&lt;b&gt;x_ahead&lt;/b&gt;的公式（将其重新命名为&lt;b&gt;x&lt;/b&gt;）就变成了：&lt;/p&gt;&lt;code lang="python"&gt;v_prev = v # 存储备份
v = mu * v - learning_rate * dx # 速度更新保持不变
x += -mu * v_prev + (1 + mu) * v # 位置更新变了形式
&lt;/code&gt;&lt;p&gt;对于NAG（Nesterov's Accelerated Momentum）的来源和数学公式推导，我们推荐以下的拓展阅读：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Yoshua Bengio的&lt;a href="http://arxiv.org/pdf/1212.0901v2.pdf" data-editable="true" data-title="Advances in optimizing Recurrent Networks" class=""&gt;Advances in optimizing Recurrent Networks&lt;/a&gt;，Section 3.5。&lt;/li&gt;&lt;li&gt;&lt;a href="http://www.cs.utoronto.ca/%7Eilya/pubs/ilya_sutskever_phd_thesis.pdf" data-editable="true" data-title="Ilya Sutskever's thesis"&gt;Ilya Sutskever's thesis&lt;/a&gt; (pdf)在section 7.2对于这个主题有更详尽的阐述。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;学习率退火&lt;/h3&gt;&lt;p&gt;在训练深度网络的时候，让学习率随着时间退火通常是有帮助的。可以这样理解：如果学习率很高，系统的动能就过大，参数向量就会无规律地跳动，不能够稳定到损失函数更深更窄的部分去。知道什么时候开始衰减学习率是有技巧的：慢慢减小它，可能在很长时间内只能是浪费计算资源地看着它混沌地跳动，实际进展很少。但如果快速地减少它，系统可能过快地失去能量，不能到达原本可以到达的最好位置。通常，实现学习率退火有3种方式：&lt;/p&gt;&lt;br&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;随步数衰减&lt;/b&gt;：每进行几个周期就根据一些因素降低学习率。典型的值是每过5个周期就将学习率减少一半，或者每20个周期减少到之前的0.1。这些数值的设定是严重依赖具体问题和模型的选择的。在实践中可能看见这么一种经验做法：使用一个固定的学习率来进行训练的同时观察验证集错误率，每当验证集错误率停止下降，就乘以一个常数（比如0.5）来降低学习率。&lt;br&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;指数衰减&lt;/b&gt;。数学公式是&lt;equation&gt;\alpha=\alpha_0e^{-kt}&lt;/equation&gt;，其中&lt;equation&gt;\alpha_0,k&lt;/equation&gt;是超参数，&lt;equation&gt;t&lt;/equation&gt;是迭代次数（也可以使用周期作为单位）。&lt;/li&gt;&lt;li&gt;&lt;b&gt;1/t衰减&lt;/b&gt;的数学公式是&lt;equation&gt;\alpha=\alpha_0/(1+kt)&lt;/equation&gt;，其中&lt;equation&gt;\alpha_0,k&lt;/equation&gt;是超参数，t是迭代次数。&lt;/li&gt;&lt;/ul&gt;&lt;br&gt;&lt;p&gt;在实践中，我们发现随步数衰减的随机失活（dropout）更受欢迎，因为它使用的超参数（衰减系数和以周期为时间单位的步数）比&lt;equation&gt;k&lt;/equation&gt;更有解释性。最后，如果你有足够的计算资源，可以让衰减更加缓慢一些，让训练时间更长些。&lt;/p&gt;&lt;h3&gt;二阶方法&lt;/h3&gt;&lt;p&gt;在深度网络背景下，第二类常用的最优化方法是基于&lt;a href="https://en.wikipedia.org/wiki/Newton%27s_method_in_optimization" data-editable="true" data-title="牛顿法" class=""&gt;牛顿法&lt;/a&gt;的，其迭代如下：&lt;br&gt;&lt;/p&gt;&lt;equation&gt;\displaystyle x\leftarrow x-[Hf(x)]^{-1}\nabla f(x)&lt;/equation&gt;&lt;br&gt;&lt;p&gt;这里&lt;equation&gt;Hf(x)&lt;/equation&gt;是&lt;a href="https://en.wikipedia.org/wiki/Hessian_matrix" data-editable="true" data-title="Hessian矩阵" class=""&gt;Hessian矩阵&lt;/a&gt;，它是函数的二阶偏导数的平方矩阵。&lt;equation&gt;\nabla f(x)&lt;/equation&gt;是梯度向量，这和梯度下降中一样。直观理解上，Hessian矩阵描述了损失函数的局部曲率，从而使得可以进行更高效的参数更新。具体来说，就是乘以Hessian转置矩阵可以让最优化过程在曲率小的时候大步前进，在曲率大的时候小步前进。需要重点注意的是，在这个公式中是没有学习率这个超参数的，这相较于一阶方法是一个巨大的优势。&lt;/p&gt;&lt;p&gt;然而上述更新方法很难运用到实际的深度学习应用中去，这是因为计算（以及求逆）Hessian矩阵操作非常耗费时间和空间。举例来说，假设一个有一百万个参数的神经网络，其Hessian矩阵大小就是[1,000,000 x 1,000,000]，将占用将近3,725GB的内存。这样，各种各样的&lt;i&gt;拟&lt;/i&gt;-牛顿法就被发明出来用于近似转置Hessian矩阵。在这些方法中最流行的是&lt;a href="https://en.wikipedia.org/wiki/Limited-memory_BFGS" data-editable="true" data-title="L-BFGS"&gt;L-BFGS&lt;/a&gt;，该方法使用随时间的梯度中的信息来隐式地近似（也就是说整个矩阵是从来没有被计算的）。&lt;/p&gt;&lt;p&gt;然而，即使解决了存储空间的问题，L-BFGS应用的一个巨大劣势是需要对整个训练集进行计算，而整个训练集一般包含几百万的样本。和小批量随机梯度下降（mini-batch SGD）不同，让L-BFGS在小批量上运行起来是很需要技巧，同时也是研究热点。&lt;/p&gt;&lt;p&gt;&lt;b&gt;实践&lt;/b&gt;。在深度学习和卷积神经网络中，使用L-BFGS之类的二阶方法并不常见。相反，基于（Nesterov的）动量更新的各种随机梯度下降方法更加常用，因为它们更加简单且容易扩展。&lt;/p&gt;&lt;p&gt;参考资料：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;a href="http://research.google.com/archive/large_deep_networks_nips2012.html" data-editable="true" data-title="Large Scale Distributed Deep Networks"&gt;Large Scale Distributed Deep Networks&lt;/a&gt; 一文来自谷歌大脑团队，比较了在大规模数据情况下L-BFGS和SGD算法的表现。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="http://arxiv.org/abs/1311.2115" data-editable="true" data-title="SFO"&gt;SFO&lt;/a&gt;算法想要把SGD和L-BFGS的优势结合起来。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;逐参数适应学习率方法&lt;/h2&gt;&lt;p&gt;前面讨论的所有方法都是对学习率进行全局地操作，并且对所有的参数都是一样的。学习率调参是很耗费计算资源的过程，所以很多工作投入到发明能够适应性地对学习率调参的方法，甚至是逐个参数适应学习率调参。很多这些方法依然需要其他的超参数设置，但是其观点是这些方法对于更广范围的超参数比原始的学习率方法有更良好的表现。在本小节我们会介绍一些在实践中可能会遇到的常用适应算法：&lt;/p&gt;&lt;p&gt;&lt;b&gt;Adagrad&lt;/b&gt;是一个由&lt;a href="http://jmlr.org/papers/v12/duchi11a.html" data-editable="true" data-title="Duchi等"&gt;Duchi等&lt;/a&gt;提出的适应性学习率算法&lt;/p&gt;&lt;code lang="python"&gt;# 假设有梯度和参数向量x
cache += dx**2
x += - learning_rate * dx / (np.sqrt(cache) + eps)
&lt;/code&gt;&lt;p&gt;注意，变量&lt;b&gt;cache&lt;/b&gt;的尺寸和梯度矩阵的尺寸是一样的，还跟踪了每个参数的梯度的平方和。这个一会儿将用来归一化参数更新步长，归一化是逐元素进行的。注意，接收到高梯度值的权重更新的效果被减弱，而接收到低梯度值的权重的更新效果将会增强。有趣的是平方根的操作非常重要，如果去掉，算法的表现将会糟糕很多。用于平滑的式子&lt;b&gt;eps&lt;/b&gt;（一般设为1e-4到1e-8之间）是防止出现除以0的情况。Adagrad的一个缺点是，在深度学习中单调的学习率被证明通常过于激进且过早停止学习。&lt;/p&gt;&lt;p&gt;&lt;b&gt;RMSprop&lt;/b&gt;。是一个非常高效，但没有公开发表的适应性学习率方法。有趣的是，每个使用这个方法的人在他们的论文中都引用自Geoff Hinton的Coursera课程的&lt;a href="http://www.cs.toronto.edu/%7Etijmen/csc321/slides/lecture_slides_lec6.pdf" data-editable="true" data-title="第六课的第29页PPT"&gt;第六课的第29页PPT&lt;/a&gt;。这个方法用一种很简单的方式修改了Adagrad方法，让它不那么激进，单调地降低了学习率。具体说来，就是它使用了一个梯度平方的滑动平均：&lt;/p&gt;&lt;code lang="python"&gt;cache =  decay_rate * cache + (1 - decay_rate) * dx**2
x += - learning_rate * dx / (np.sqrt(cache) + eps)
&lt;/code&gt;&lt;p&gt;在上面的代码中，decay_rate是一个超参数，常用的值是[0.9,0.99,0.999]。其中&lt;b&gt;x+=&lt;/b&gt;和Adagrad中是一样的，但是&lt;b&gt;cache&lt;/b&gt;变量是不同的。因此，RMSProp仍然是基于梯度的大小来对每个权重的学习率进行修改，这同样效果不错。但是和Adagrad不同，其更新不会让学习率单调变小。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Adam&lt;/b&gt;。&lt;a href="http://arxiv.org/abs/1412.6980" data-editable="true" data-title="Adam"&gt;Adam&lt;/a&gt;是最近才提出的一种更新方法，它看起来像是RMSProp的动量版。简化的代码是下面这样：&lt;/p&gt;&lt;code lang="python"&gt;m = beta1*m + (1-beta1)*dx
v = beta2*v + (1-beta2)*(dx**2)
x += - learning_rate * m / (np.sqrt(v) + eps)
&lt;/code&gt;&lt;p&gt;注意这个更新方法看起来真的和RMSProp很像，除了使用的是平滑版的梯度&lt;b&gt;m&lt;/b&gt;，而不是用的原始梯度向量&lt;b&gt;dx&lt;/b&gt;。论文中推荐的参数值&lt;b&gt;eps=1e-8, beta1=0.9, beta2=0.999&lt;/b&gt;。在实际操作中，我们推荐Adam作为默认的算法，一般而言跑起来比RMSProp要好一点。但是也可以试试SGD+Nesterov动量。完整的Adam更新算法也包含了一个偏置&lt;em&gt;（bias）矫正&lt;/em&gt;机制，因为&lt;b&gt;m,v&lt;/b&gt;两个矩阵初始为0，在没有完全热身之前存在偏差，需要采取一些补偿措施。建议读者可以阅读论文查看细节，或者课程的PPT。&lt;/p&gt;&lt;p&gt;拓展阅读：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="http://arxiv.org/abs/1312.6055" data-editable="true" data-title="Unit Tests for Stochastic Optimization" class=""&gt;Unit Tests for Stochastic Optimization&lt;/a&gt;一文展示了对于随机最优化的测试。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;——————————————————————————————————————————&lt;/p&gt;&lt;p&gt;&lt;img src="7fd7404711c99456237cdff7b3a3bad7.png" data-rawwidth="1598" data-rawheight="640"&gt;&lt;b&gt;&lt;i&gt;译者注：上图原文中为动图，知乎专栏不支持动图，知友可点击&lt;a href="http://cs231n.github.io/neural-networks-3/" data-editable="true" data-title="原文链接" class=""&gt;原文链接&lt;/a&gt;查看。&lt;/i&gt;&lt;/b&gt;&lt;/p&gt;&lt;p&gt;上面的动画可以帮助你理解学习的动态过程。&lt;b&gt;左边&lt;/b&gt;是一个损失函数的等高线图，上面跑的是不同的最优化算法。注意基于动量的方法出现了射偏了的情况，使得最优化过程看起来像是一个球滚下山的样子。&lt;b&gt;右边&lt;/b&gt;展示了一个马鞍状的最优化地形，其中对于不同维度它的曲率不同（一个维度下降另一个维度上升）。注意SGD很难突破对称性，一直卡在顶部。而RMSProp之类的方法能够看到马鞍方向有很低的梯度。因为在RMSProp更新方法中的分母项，算法提高了在该方向的有效学习率，使得RMSProp能够继续前进。图片版权：&lt;a href="https://twitter.com/alecrad" data-editable="true" data-title="Alec Radford" class=""&gt;Alec Radford&lt;/a&gt;。&lt;/p&gt;&lt;br&gt;&lt;p&gt;——————————————————————————————————————————&lt;/p&gt;&lt;h2&gt;超参数调优&lt;/h2&gt;&lt;p&gt;我们已经看到，训练一个神经网络会遇到很多超参数设置。神经网络最常用的设置有：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;初始学习率。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;学习率衰减方式（例如一个衰减常量）。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;正则化强度（L2惩罚，随机失活强度）。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;但是也可以看到，还有很多相对不那么敏感的超参数。比如在逐参数适应学习方法中，对于动量及其时间表的设置等。在本节中将介绍一些额外的调参要点和技巧：&lt;/p&gt;&lt;p&gt;&lt;b&gt;实现&lt;/b&gt;。更大的神经网络需要更长的时间去训练，所以调参可能需要几天甚至几周。记住这一点很重要，因为这会影响你设计代码的思路。一个具体的设计是用&lt;b&gt;仆程序&lt;/b&gt;持续地随机设置参数然后进行最优化。在训练过程中，&lt;b&gt;仆程序&lt;/b&gt;会对每个周期后验证集的准确率进行监控，然后向文件系统写下一个模型的记录点（记录点中有各种各样的训练统计数据，比如随着时间的损失值变化等），这个文件系统最好是可共享的。在文件名中最好包含验证集的算法表现，这样就能方便地查找和排序了。然后还有一个&lt;b&gt;主程序&lt;/b&gt;，它可以启动或者结束计算集群中的&lt;b&gt;仆程序&lt;/b&gt;，有时候也可能根据条件查看&lt;b&gt;仆程序&lt;/b&gt;写下的记录点，输出它们的训练统计数据等。&lt;/p&gt;&lt;p&gt;&lt;b&gt;比起交叉验证最好使用一个验证集&lt;/b&gt;。在大多数情况下，一个尺寸合理的验证集可以让代码更简单，不需要用几个数据集来交叉验证。你可能会听到人们说他们“交叉验证”一个参数，但是大多数情况下，他们实际是使用的一个验证集。&lt;/p&gt;&lt;p&gt;&lt;b&gt;超参数范围&lt;/b&gt;。在对数尺度上进行超参数搜索。例如，一个典型的学习率应该看起来是这样：&lt;b&gt;learning_rate = 10 ** uniform(-6, 1)&lt;/b&gt;。也就是说，我们从标准分布中随机生成了一个数字，然后让它成为10的阶数。对于正则化强度，可以采用同样的策略。直观地说，这是因为学习率和正则化强度都对于训练的动态进程有乘的效果。例如：当学习率是0.001的时候，如果对其固定地增加0.01，那么对于学习进程会有很大影响。然而当学习率是10的时候，影响就微乎其微了。这就是因为学习率乘以了计算出的梯度。因此，比起加上或者减少某些值，思考学习率的范围是乘以或者除以某些值更加自然。但是有一些参数（比如随机失活）还是在原始尺度上进行搜索（例如：&lt;b&gt;dropout=uniform(0,1)&lt;/b&gt;）。&lt;/p&gt;&lt;p&gt;&lt;b&gt;随机搜索优于网格搜索&lt;/b&gt;。Bergstra和Bengio在文章&lt;a href="http://www.jmlr.org/papers/volume13/bergstra12a/bergstra12a.pdf" data-editable="true" data-title="Random Search for Hyper-Parameter Optimization"&gt;Random Search for Hyper-Parameter Optimization&lt;/a&gt;中说“随机选择比网格化的选择更加有效”，而且在实践中也更容易实现。&lt;/p&gt;&lt;p&gt;——————————————————————————————————————————&lt;/p&gt;&lt;p&gt;&lt;img src="d25cf561835c7b96ae6d1c91868bcbff.png" data-rawwidth="1596" data-rawheight="432"&gt;在&lt;a href="http://www.jmlr.org/papers/volume13/bergstra12a/bergstra12a.pdf" data-editable="true" data-title="Random Search for Hyper-Parameter Optimization"&gt;Random Search for Hyper-Parameter Optimization&lt;/a&gt;中的核心说明图。通常，有些超参数比其余的更重要，通过随机搜索，而不是网格化的搜索，可以让你更精确地发现那些比较重要的超参数的好数值。&lt;br&gt;&lt;/p&gt;&lt;p&gt;——————————————————————————————————————————&lt;/p&gt;&lt;p&gt;&lt;b&gt;对于边界上的最优值要小心&lt;/b&gt;。这种情况一般发生在你在一个不好的范围内搜索超参数（比如学习率）的时候。比如，假设我们使用&lt;b&gt;learning_rate = 10 ** uniform(-6,1)&lt;/b&gt;来进行搜索。一旦我们得到一个比较好的值，一定要确认你的值不是出于这个范围的边界上，不然你可能错过更好的其他搜索范围。&lt;/p&gt;&lt;p&gt;&lt;b&gt;从粗到细地分阶段搜索&lt;/b&gt;。在实践中，先进行初略范围（比如10 ** [-6, 1]）搜索，然后根据好的结果出现的地方，缩小范围进行搜索。进行粗搜索的时候，让模型训练一个周期就可以了，因为很多超参数的设定会让模型没法学习，或者突然就爆出很大的损失值。第二个阶段就是对一个更小的范围进行搜索，这时可以让模型运行5个周期，而最后一个阶段就在最终的范围内进行仔细搜索，运行很多次周期。&lt;/p&gt;&lt;p&gt;&lt;b&gt;贝叶斯超参数最优化&lt;/b&gt;是一整个研究领域，主要是研究在超参数空间中更高效的导航算法。其核心的思路是在不同超参数设置下查看算法性能时，要在探索和使用中进行合理的权衡。基于这些模型，发展出很多的库，比较有名的有： &lt;a href="https://github.com/JasperSnoek/spearmint" data-editable="true" data-title="Spearmint"&gt;Spearmint&lt;/a&gt;, &lt;a href="http://www.cs.ubc.ca/labs/beta/Projects/SMAC/" data-editable="true" data-title="SMAC"&gt;SMAC&lt;/a&gt;, 和&lt;a href="http://jaberg.github.io/hyperopt/" data-editable="true" data-title="Hyperopt" class=""&gt;Hyperopt&lt;/a&gt;。然而，在卷积神经网络的实际使用中，比起上面介绍的先认真挑选的一个范围，然后在该范围内随机搜索的方法，这个方法还是差一些。&lt;a href="http://nlpers.blogspot.com/2014/10/hyperparameter-search-bayesian.html" data-editable="true" data-title="这里"&gt;这里&lt;/a&gt;有更详细的讨论。&lt;/p&gt;&lt;h2&gt;评价&lt;/h2&gt;&lt;h3&gt;模型集成&lt;/h3&gt;&lt;p&gt;在实践的时候，有一个总是能提升神经网络几个百分点准确率的办法，就是在训练的时候训练几个独立的模型，然后在测试的时候平均它们预测结果。集成的模型数量增加，算法的结果也单调提升（但提升效果越来越少）。还有模型之间的差异度越大，提升效果可能越好。进行集成有以下几种方法：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;同一个模型，不同的初始化&lt;/b&gt;。使用交叉验证来得到最好的超参数，然后用最好的参数来训练不同初始化条件的模型。这种方法的风险在于多样性只来自于不同的初始化条件。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;在交叉验证中发现最好的模型&lt;/b&gt;。使用交叉验证来得到最好的超参数，然后取其中最好的几个（比如10个）模型来进行集成。这样就提高了集成的多样性，但风险在于可能会包含不够理想的模型。在实际操作中，这样操作起来比较简单，在交叉验证后就不需要额外的训练了。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;一个模型设置多个记录点&lt;/b&gt;。如果训练非常耗时，那就在不同的训练时间对网络留下记录点（比如每个周期结束），然后用它们来进行模型集成。很显然，这样做多样性不足，但是在实践中效果还是不错的，这种方法的优势是代价比较小。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;在训练的时候跑参数的平均值&lt;/b&gt;。和上面一点相关的，还有一个也能得到1-2个百分点的提升的小代价方法，这个方法就是在训练过程中，如果损失值相较于前一次权重出现指数下降时，就在内存中对网络的权重进行一个备份。这样你就对前几次循环中的网络状态进行了平均。你会发现这个“平滑”过的版本的权重总是能得到更少的误差。直观的理解就是目标函数是一个碗状的，你的网络在这个周围跳跃，所以对它们平均一下，就更可能跳到中心去。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;模型集成的一个劣势就是在测试数据的时候会花费更多时间。最近Geoff Hinton在“&lt;a href="https://www.youtube.com/watch?v=EK61htlw8hY" data-editable="true" data-title="Dark Knowledge"&gt;Dark Knowledge&lt;/a&gt;”上的工作很有启发：其思路是通过将集成似然估计纳入到修改的目标函数中，从一个好的集成中抽出一个单独模型。&lt;/p&gt;&lt;h2&gt;总结&lt;/h2&gt;&lt;p&gt;训练一个神经网络需要：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;利用小批量数据对实现进行梯度检查，还要注意各种错误。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;进行合理性检查，确认初始损失值是合理的，在小数据集上能得到100%的准确率。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;在训练时，跟踪损失函数值，训练集和验证集准确率，如果愿意，还可以跟踪更新的参数量相对于总参数量的比例（一般在1e-3左右），然后如果是对于卷积神经网络，可以将第一层的权重可视化。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;推荐的两个更新方法是SGD+Nesterov动量方法，或者Adam方法。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;随着训练进行学习率衰减。比如，在固定多少个周期后让学习率减半，或者当验证集准确率下降的时候。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;使用随机搜索（不要用网格搜索）来搜索最优的超参数。分阶段从粗（比较宽的超参数范围训练1-5个周期）到细（窄范围训练很多个周期）地来搜索。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;进行模型集成来获得额外的性能提高。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;拓展阅读&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Leon Bottou的《&lt;a href="http://research.microsoft.com/pubs/192769/tricks-2012.pdf" data-title="SGD要点和技巧" class="" data-editable="true"&gt;SGD要点和技巧&lt;/a&gt;》。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Yann LeCun的《&lt;a href="http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf" data-editable="true" data-title="Efficient BackProp" class=""&gt;Efficient BackProp&lt;/a&gt;》。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;Yoshua Bengio的《&lt;a href="http://arxiv.org/pdf/1206.5533v2.pdf" data-editable="true" data-title="Practical Recommendations for Gradient-Based Training of Deep Architectures" class=""&gt;Practical Recommendations for Gradient-Based Training of Deep Architectures&lt;/a&gt;》。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;译者反馈&lt;/h2&gt;&lt;ol&gt;&lt;li&gt;&lt;b&gt;转载须全文转载且注明原文链接&lt;/b&gt;，否则保留维权权利；&lt;/li&gt;&lt;li&gt;请知友们通过评论和私信等方式批评指正，贡献者均会补充提及。&lt;/li&gt;&lt;/ol&gt;</description><author>杜客</author><pubDate>Tue, 09 Aug 2016 15:12:17 GMT</pubDate></item><item><title>深度增强学习之Policy Gradient方法1</title><link>https://zhuanlan.zhihu.com/p/21725498</link><description>&lt;p&gt;&lt;img src="https://pic2.zhimg.com/6f589df38509d14f839737645322a011_r.jpg"&gt;&lt;/p&gt;&lt;h2&gt;1 前言&lt;/h2&gt;&lt;p&gt;在之前的深度增强学习系列文章中，我们已经详细分析了DQN算法，一种基于价值Value的算法，那么在今天，我们和大家一起分析深度增强学习中的另一种算法，也就是基于策略梯度Policy Gradient的算法。这种算法和基于价值Value的算法结合而成的Actor-Critic算法是目前效果最好的深度增强学习算法。&lt;/p&gt;&lt;p&gt;那么关于Policy Gradient方法的学习，有以下一些网上的资源值得看：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;Andrej Karpathy blog: &lt;a href="https://link.zhihu.com/?target=http%3A//karpathy.github.io/2016/05/31/rl/" class="" data-editable="true" data-title="Deep Reinforcement Learning: Pong from Pixels"&gt;Deep Reinforcement Learning: Pong from Pixels&lt;/a&gt;&lt;br&gt;&lt;/li&gt;&lt;li&gt;David Silver ICML 2016：&lt;a href="https://link.zhihu.com/?target=http%3A//icml.cc/2016/tutorials/deep_rl_tutorial.pdf" class="" data-editable="true" data-title="深度增强学习Tutorial"&gt;深度增强学习Tutorial&lt;/a&gt;&lt;br&gt;&lt;/li&gt;&lt;li&gt;John Schulman：&lt;a href="https://link.zhihu.com/?target=http%3A//learning.mpi-sws.org/mlss2016/speakers/" class="" data-editable="true" data-title="Machine Learning Summer School"&gt;Machine Learning Summer School&lt;/a&gt;&lt;br&gt;&lt;/li&gt;&lt;li&gt;David Silver的增强学习课程（有视频和ppt）: &lt;a href="https://link.zhihu.com/?target=http%3A//www0.cs.ucl.ac.uk/staff/D.Silver/web/Teaching.html" class="" data-editable="true" data-title="http://www0.cs.ucl.ac.uk/staff/D.Silver/web/Teaching.html"&gt;http://www0.cs.ucl.ac.uk/staff/D.Silver/web/Teaching.html&lt;/a&gt;&lt;br&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;那么实际上Andrej Karpathy的blog已经很详细的分析了Policy Gradient的方法，这里我将综合以上的内容根据我自己的理解来说以下Policy Gradient。&lt;/p&gt;&lt;h2&gt;2 Why Policy Network?&lt;/h2&gt;&lt;p&gt;我们已经知道DQN是一个基于价值value的方法。换句话说就是通过计算每一个状态动作的价值，然后选择价值最大的动作执行。这是一种间接的做法。那么，更直接的做法是什么？&lt;/p&gt;&lt;p&gt;&lt;b&gt;能不能直接更新策略网络Policy Network呢？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;什么是策略网络Policy Network？就是一个神经网络，输入是状态，输出直接就是动作（不是Q值）。&lt;/p&gt;&lt;equation&gt;a = \pi(s,\theta)&lt;/equation&gt;&lt;equation&gt;a = \pi(s,\theta)  &lt;/equation&gt;&lt;br&gt;&lt;p&gt;或者输出概率：&lt;equation&gt;a = \pi(a|s,\theta)&lt;/equation&gt;&lt;/p&gt;&lt;p&gt;这里要提一下概率输出的问题。对于DQN来说，本质上是一个接近于确定性输出的算法。至多就是采用&lt;equation&gt;\epsilon-greedy&lt;/equation&gt;进行探索。但是有很多时候，在某一个特定状态下，很多动作的选择可能都是可以的。比如说我有20块钱去买饭。那么不管我买的是蛋炒饭还是土豆肉片盖码饭，结果都是一样的填饱肚子。因此，采用输出概率会更通用一些。而DQN并不能输出动作的概率，所以采用Policy Network是一个更好的办法。&lt;/p&gt;&lt;h2&gt;3 Policy Gradient&lt;/h2&gt;&lt;p&gt;要更新策略网络，或者说要使用梯度下降的方法来更新网络，我们需要有一个目标函数。对于策略网络，目标函数其实是比较容易给定的，就是很直接的，最后的结果！也就是&lt;/p&gt;&lt;p&gt;&lt;equation&gt;L(\theta) = \mathbb E(r_1+\gamma r_2 + \gamma^2 r_3 + ...|\pi(,\theta))&lt;/equation&gt; 所有带衰减reward的累加期望&lt;br&gt;&lt;/p&gt;&lt;p&gt;那么问题就在于如何利用这个目标来更新参数&lt;equation&gt;\theta&lt;/equation&gt;呢？咋一看这个损失函数和策略网络简直没有什么直接联系，reward是环境给出的，如何才能更新参数？换个说法就是如何能够计算出损失函数关于参数的梯度（也就是策略梯度）：&lt;/p&gt;&lt;equation&gt;\nabla_{\theta} L(\theta)&lt;/equation&gt;&lt;p&gt;咋一看根本就没有什么思路是不是，所以先换一个思路来考虑问题。&lt;/p&gt;&lt;h2&gt;4 就给我一个Policy Network，也没有loss，怎么更新？&lt;/h2&gt;&lt;blockquote&gt;改变动作的出现概率！&lt;br&gt;&lt;/blockquote&gt;&lt;p&gt;现在我们不考虑别的，就仅仅从概率的角度来思考问题。我们有一个策略网络，输入状态，输出动作的概率。然后执行完动作之后，我们可以得到reward，或者result。那么这个时候，我们有个非常简单的想法：&lt;/p&gt;&lt;blockquote&gt;&lt;b&gt;如果某一个动作得到reward多，那么我们就使其出现的概率增大，如果某一个动作得到的reward少，那么我们就使其出现的概率减小。&lt;br&gt;&lt;/b&gt;&lt;/blockquote&gt;&lt;p&gt;当然，也显然的，用reward来评判动作的好坏是不准确的，甚至用result来评判也是不准确的。毕竟任何一个reward，result都依赖于大量的动作才导致的。但是这并不妨碍我们做这样的思考：&lt;/p&gt;&lt;blockquote&gt;&lt;b&gt;如果能够构造一个好的动作评判指标，来判断一个动作的好与坏，那么我们就可以通过改变动作的出现概率来优化策略！&lt;br&gt;&lt;/b&gt;&lt;/blockquote&gt;&lt;p&gt;假设这个评价指标是&lt;equation&gt;f(s,a)&lt;/equation&gt;,那么我们的Policy Network输出的是概率。一般情况下，更常使用log likelihood &lt;equation&gt;log \pi(a|s,\theta)&lt;/equation&gt;。原因的话看这里&lt;a href="http://math.stackexchange.com/questions/892832/why-we-consider-log-likelihood-instead-of-likelihood-in-gaussian-distribution" class="" data-title="Why we consider log likelihood instead of Likelihood in Gaussian Distribution"&gt;Why we consider log likelihood instead of Likelihood in Gaussian Distribution&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;因此，我们就可以构造一个损失函数如下：&lt;/p&gt;&lt;equation&gt;L(\theta) = \sum log\pi(a|s,\theta)f(s,a)&lt;/equation&gt;&lt;br&gt;&lt;p&gt;怎么理解呢？举个简单的AlphaGo的例子吧。对于AlphaGo而言，f(s,a)就是最后的结果。也就是一盘棋中，如果这盘棋赢了，那么这盘棋下的每一步都是认为是好的，如果输了，那么都认为是不好的。好的f(s,a)就是1，不好的就-1。所以在这里，如果a被认为是好的，那么目标就是最大化这个好的动作的概率，反之亦然。&lt;/p&gt;&lt;p&gt;这就是Policy Gradient最基本的思想。&lt;/p&gt;&lt;h2&gt;5 另一个角度：直接算&lt;/h2&gt;&lt;p&gt;f(s,a)不仅仅可以作为动作的评价指标，还可以作为目标函数。就如同AlphaGo，评价指标就是赢或者输，而目标就是结果赢。这和之前分析的目标完全没有冲突。因此，我们可以利用评价指标f(s,a)来优化Policy，同时也是在优化的同时优化了f(s,a).那么问题就变成对f(s,a)求关于参数的梯度。下面的公式直接摘自Andrej Karpathy的blog，f(x)即是f(s,a)&lt;/p&gt;&lt;equation&gt;\begin{align}
\nabla_{\theta} E_x[f(x)] &amp;amp;= \nabla_{\theta} \sum_x p(x) f(x) &amp;amp; \text{definition of expectation} \\
&amp;amp; = \sum_x \nabla_{\theta} p(x) f(x) &amp;amp; \text{swap sum and gradient} \\
&amp;amp; = \sum_x p(x) \frac{\nabla_{\theta} p(x)}{p(x)} f(x) &amp;amp; \text{both multiply and divide by } p(x) \\
&amp;amp; = \sum_x p(x) \nabla_{\theta} \log p(x) f(x) &amp;amp; \text{use the fact that } \nabla_{\theta} \log(z) = \frac{1}{z} \nabla_{\theta} z \\
&amp;amp; = E_x[f(x) \nabla_{\theta} \log p(x) ] &amp;amp; \text{definition of expectation}
\end{align}&lt;/equation&gt;&lt;br&gt;&lt;p&gt;从公式得到的结论可以看到正好和上一小结分析得到的目标函数一致。&lt;/p&gt;&lt;p&gt;因此，Policy Gradient方法就这么确定了。&lt;/p&gt;&lt;h2&gt;6 小结&lt;/h2&gt;&lt;p&gt;本篇blog作为一个引子，介绍下Policy Gradient的基本思想。那么大家会发现，如何确定这个评价指标才是实现Policy Gradient方法的关键所在。所以，在下一篇文章中。我们将来分析一下这个评价指标的问题。&lt;/p&gt;</description><author>Flood Sung</author><pubDate>Wed, 03 Aug 2016 11:04:25 GMT</pubDate></item><item><title>CS231n课程笔记翻译：神经网络笔记3（上）</title><link>https://zhuanlan.zhihu.com/p/21741716</link><description>&lt;p&gt;&lt;img src="https://pic3.zhimg.com/b629f243297cf32d2507bdaa1bc38e12_r.jpg"&gt;&lt;/p&gt;译者注：本文&lt;a href="https://zhuanlan.zhihu.com/intelligentunit" data-editable="true" data-title="智能单元" class=""&gt;智能单元&lt;/a&gt;首发，译自斯坦福CS231n课程笔记&lt;a href="http://cs231n.github.io/neural-networks-3/" class="" data-editable="true" data-title="Neural Nets notes 3"&gt;Neural Nets notes 3&lt;/a&gt;，课程教师&lt;a href="https://link.zhihu.com/?target=http%3A//cs.stanford.edu/people/karpathy/" class="" data-editable="true" data-title="Andrej Karpathy"&gt;Andrej Karpathy&lt;/a&gt;授权翻译。本篇教程由&lt;a href="https://www.zhihu.com/people/du-ke" class="" data-editable="true" data-title="杜客"&gt;杜客&lt;/a&gt;翻译完成，&lt;a href="https://www.zhihu.com/people/kun-kun-97-81" class="" data-editable="true" data-title="堃堃"&gt;堃堃&lt;/a&gt;和&lt;a href="https://www.zhihu.com/people/hmonkey" class="" data-editable="true" data-title="巩子嘉"&gt;巩子嘉&lt;/a&gt;进行校对修改。译文含公式和代码，建议PC端阅读。&lt;h2&gt;原文如下&lt;/h2&gt;&lt;p&gt;内容列表：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;梯度检查&lt;/li&gt;&lt;li&gt;合理性（Sanity）检查&lt;/li&gt;&lt;li&gt;检查学习过程&lt;ul&gt;&lt;li&gt;损失函数&lt;/li&gt;&lt;li&gt;训练集与验证集准确率&lt;/li&gt;&lt;li&gt;权重：更新比例&lt;/li&gt;&lt;li&gt;每层的激活数据与梯度分布&lt;/li&gt;&lt;li&gt;可视化 &lt;b&gt;&lt;i&gt;译者注：上篇翻译截止处&lt;/i&gt;&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;参数更新&lt;ul&gt;&lt;li&gt;一阶（随机梯度下降）方法，动量方法，Nesterov动量方法&lt;/li&gt;&lt;li&gt;学习率退火&lt;/li&gt;&lt;li&gt;二阶方法&lt;/li&gt;&lt;li&gt;逐参数适应学习率方法（Adagrad，RMSProp）&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;超参数调优&lt;/li&gt;&lt;li&gt;评价&lt;ul&gt;&lt;li&gt;模型集成&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;总结&lt;/li&gt;&lt;li&gt;拓展引用&lt;/li&gt;&lt;/ul&gt;&lt;h1&gt;学习过程&lt;/h1&gt;&lt;p&gt;在前面章节中，我们讨论了神经网络的静态部分：如何创建网络的连接、数据和损失函数。本节将致力于讲解神经网络的动态部分，即神经网络学习参数和搜索最优超参数的过程。&lt;br&gt;&lt;/p&gt;&lt;h2&gt;梯度检查&lt;/h2&gt;&lt;p&gt;理论上将进行梯度检查很简单，就是简单地把解析梯度和数值计算梯度进行比较。然而从实际操作层面上来说，这个过程更加复杂且容易出错。下面是一些提示、技巧和需要仔细注意的事情：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;使用中心化公式。&lt;/strong&gt;在使用有限差值近似来计算数值梯度的时候，常见的公式是：&lt;/p&gt;&lt;equation&gt;\displaystyle \frac{df(x)}{dx}=\frac{f(x+h)-f(x)}{h}(bad,\ do\ not\ use)&lt;/equation&gt;&lt;br&gt;&lt;p&gt;其中&lt;equation&gt;h&lt;/equation&gt;是一个很小的数字，在实践中近似为1e-5。在实践中证明，使用&lt;i&gt;中心化&lt;/i&gt;公式效果更好：&lt;br&gt;&lt;/p&gt;&lt;equation&gt;\displaystyle \frac{df(x)}{dx}=\frac{f(x+h)-f(x-h)}{2h}(use\ instead)&lt;/equation&gt;&lt;br&gt;&lt;p&gt;该公式在检查梯度的每个维度的时候，会要求计算两次损失函数（所以计算资源的耗费也是两倍），但是梯度的近似值会准确很多。要理解这一点，对&lt;equation&gt;f(x+h)&lt;/equation&gt;和&lt;equation&gt;f(x-h)&lt;/equation&gt;使用泰勒展开，可以看到第一个公式的误差近似&lt;equation&gt;O(h)&lt;/equation&gt;，第二个公式的误差近似&lt;equation&gt;O(h^2)&lt;/equation&gt;（是个二阶近似）。&lt;i&gt;&lt;b&gt;（译者注：泰勒展开相关内容可阅读《高等数学》第十二章第四节：函数展开成幂级数。）&lt;/b&gt;&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;使用相对误差来比较&lt;/b&gt;。比较数值梯度&lt;equation&gt;f'_n&lt;/equation&gt;和解析梯度&lt;equation&gt;f'_a&lt;/equation&gt;的细节有哪些？如何得知此两者不匹配？你可能会倾向于监测它们的差的绝对值&lt;equation&gt;|f'_a-f'_n|&lt;/equation&gt;或者差的平方值，然后定义该值如果超过某个规定阈值，就判断梯度实现失败。然而该思路是有问题的。想想，假设这个差值是1e-4，如果两个梯度值在1.0左右，这个差值看起来就很合适，可以认为两个梯度是匹配的。然而如果梯度值是1e-5或者更低，那么1e-4就是非常大的差距，梯度实现肯定就是失败的了。因此，使用&lt;i&gt;相对误差&lt;/i&gt;总是更合适一些：&lt;br&gt;&lt;/p&gt;&lt;equation&gt;\displaystyle \frac{|f'_a-f'_n|}{max(|f'_a|,|f'_n|)}&lt;/equation&gt;&lt;br&gt;&lt;p&gt;上式考虑了差值占两个梯度绝对值的比例。注意通常相对误差公式只包含两个式子中的一个（任意一个均可），但是我更倾向取两个式子的最大值或者取两个式子的和。这样做是为了防止在其中一个式子为0时，公式分母为0（这种情况，在ReLU中是经常发生的）。然而，还必须注意两个式子都为零且通过梯度检查的情况。在实践中：&lt;br&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;相对误差&amp;gt;1e-2：通常就意味着梯度可能出错。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;1e-2&amp;gt;相对误差&amp;gt;1e-4：要对这个值感到不舒服才行。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;1e-4&amp;gt;相对误差：这个值的相对误差对于有不可导点的目标函数是OK的。但如果目标函数中没有kink（使用tanh和softmax），那么相对误差值还是太高。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;1e-7或者更小：好结果，可以高兴一把了。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;要知道的是网络的深度越深，相对误差就越高。所以如果你是在对一个10层网络的输入数据做梯度检查，那么1e-2的相对误差值可能就OK了，因为误差一直在累积。相反，如果一个可微函数的相对误差值是1e-2，那么通常说明梯度实现不正确。&lt;br&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;strong&gt;使用双精度。&lt;/strong&gt;一个常见的错误是使用单精度浮点数来进行梯度检查。这样会导致即使梯度实现正确，相对误差值也会很高（比如1e-2）。在我的经验而言，出现过使用单精度浮点数时相对误差为1e-2，换成双精度浮点数时就降低为1e-8的情况。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;保持在浮点数的有效范围。&lt;/strong&gt;建议通读《&lt;a href="http://docs.oracle.com/cd/E19957-01/806-3568/ncg_goldberg.html" data-editable="true" data-title="What Every Computer Scientist Should Konw About Floating-Point Artthmetic" class=""&gt;What Every Computer Scientist Should Konw About Floating-Point Artthmetic&lt;/a&gt;》一文，该文将阐明你可能犯的错误，促使你写下更加细心的代码。例如，在神经网络中，在一个批量的数据上对损失函数进行归一化是很常见的。但是，如果每个数据点的梯度很小，然后又用数据点的数量去除，就使得数值更小，这反过来会导致更多的数值问题。这就是我为什么总是会把原始的解析梯度和数值梯度数据打印出来，确保用来比较的数字的值不是过小（通常绝对值小于1e-10就绝对让人担心）。如果确实过小，可以使用一个常数暂时将损失函数的数值范围扩展到一个更“好”的范围，在这个范围中浮点数变得更加致密。比较理想的是1.0的数量级上，即当浮点数指数为0时。&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;b&gt;目标函数的不可导点（kinks）&lt;/b&gt;。在进行梯度检查时，一个导致不准确的原因是不可导点问题。不可导点是指目标函数不可导的部分，由ReLU（&lt;equation&gt;max(0,x)&lt;/equation&gt;）等函数，或SVM损失，Maxout神经元等引入。考虑当&lt;equation&gt;x=-1e6&lt;/equation&gt;的时，对ReLU函数进行梯度检查。因为&lt;equation&gt;x&amp;lt;0&lt;/equation&gt;，所以解析梯度在该点的梯度为0。然而，在这里数值梯度会突然计算出一个非零的梯度值，因为&lt;equation&gt;f(x+h)&lt;/equation&gt;可能越过了不可导点(例如：如果&lt;equation&gt;h&amp;gt;1e-6&lt;/equation&gt;)，导致了一个非零的结果。你可能会认为这是一个极端的案例，但实际上这种情况很常见。例如，一个用CIFAR-10训练的SVM中，因为有50,000个样本，且根据目标函数每个样本产生9个式子，所以包含有450,000个&lt;equation&gt;max(0,x)&lt;/equation&gt;式子。而一个用SVM进行分类的神经网络因为采用了ReLU，还会有更多的不可导点。&lt;/p&gt;&lt;br&gt;&lt;p&gt;注意，在计算损失的过程中是可以知道不可导点有没有被越过的。在具有&lt;equation&gt;max(x,y)&lt;/equation&gt;形式的函数中持续跟踪所有“赢家”的身份，就可以实现这一点。其实就是看在前向传播时，到底x和y谁更大。如果在计算&lt;equation&gt;f(x+h)&lt;/equation&gt;和&lt;equation&gt;f(x-h)&lt;/equation&gt;的时候，至少有一个“赢家”的身份变了，那就说明不可导点被越过了，数值梯度会不准确。&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;strong&gt;使用少量数据点。&lt;/strong&gt;解决上面的不可导点问题的一个办法是使用更少的数据点。因为含有不可导点的损失函数(例如：因为使用了ReLU或者边缘损失等函数)的数据点越少，不可导点就越少，所以在计算有限差值近似时越过不可导点的几率就越小。还有，如果你的梯度检查对2-3个数据点都有效，那么基本上对整个批量数据进行梯度检查也是没问题的。所以使用很少量的数据点，能让梯度检查更迅速高效。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;谨慎设置步长h。&lt;/strong&gt;在实践中h并不是越小越好，因为当&lt;equation&gt;h&lt;/equation&gt;特别小的时候，就可能就会遇到数值精度问题。有时候如果梯度检查无法进行，可以试试将&lt;equation&gt;h&lt;/equation&gt;调到1e-4或者1e-6，然后突然梯度检查可能就恢复正常。这篇&lt;a href="https://en.wikipedia.org/wiki/Numerical_differentiation" data-editable="true" data-title="维基百科文章" class=""&gt;维基百科文章&lt;/a&gt;中有一个图表，其x轴为&lt;equation&gt;h&lt;/equation&gt;值，y轴为数值梯度误差。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;在操作的特性模式中梯度检查。&lt;/strong&gt;有一点必须要认识到：梯度检查是在参数空间中的一个特定（往往还是随机的）的单独点进行的。即使是在该点上梯度检查成功了，也不能马上确保全局上梯度的实现都是正确的。还有，一个随机的初始化可能不是参数空间最优代表性的点，这可能导致进入某种病态的情况，即梯度看起来是正确实现了，实际上并没有。例如，SVM使用小数值权重初始化，就会把一些接近于0的得分分配给所有的数据点，而梯度将会在所有的数据点上展现出某种模式。一个不正确实现的梯度也许依然能够产生出这种模式，但是不能泛化到更具代表性的操作模式，比如在一些的得分比另一些得分更大的情况下就不行。因此为了安全起见，最好让网络学习（“预热”）一小段时间，等到损失函数开始下降的之后再进行梯度检查。在第一次迭代就进行梯度检查的危险就在于，此时可能正处在不正常的边界情况，从而掩盖了梯度没有正确实现的事实。&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;strong&gt;不要让正则化吞没数据。&lt;/strong&gt;通常损失函数是数据损失和正则化损失的和（例如L2对权重的惩罚）。需要注意的危险是正则化损失可能吞没掉数据损失，在这种情况下梯度主要来源于正则化部分（正则化部分的梯度表达式通常简单很多）。这样就会掩盖掉数据损失梯度的不正确实现。因此，推荐先关掉正则化对数据损失做单独检查，然后对正则化做单独检查。对于正则化的单独检查可以是修改代码，去掉其中数据损失的部分，也可以提高正则化强度，确认其效果在梯度检查中是无法忽略的，这样不正确的实现就会被观察到了。&lt;/p&gt;&lt;p&gt;&lt;b&gt;记得关闭随机失活（dropout）和数据扩张（augmentation）&lt;/b&gt;。在进行梯度检查时，记得关闭网络中任何不确定的效果的操作，比如随机失活，随机数据扩展等。不然它们会在计算数值梯度的时候导致巨大误差。关闭这些操作不好的一点是无法对它们进行梯度检查（例如随机失活的反向传播实现可能有错误）。因此，一个更好的解决方案就是在计算&lt;equation&gt;f(x+h)&lt;/equation&gt;和&lt;equation&gt;f(x-h)&lt;/equation&gt;前强制增加一个特定的随机种子，在计算解析梯度时也同样如此。&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;检查少量的维度。&lt;/strong&gt;在实际中，梯度可以有上百万的参数，在这种情况下只能检查其中一些维度然后假设其他维度是正确的。&lt;strong&gt;注意&lt;/strong&gt;&lt;b&gt;：&lt;/b&gt;确认在所有不同的参数中都抽取一部分来梯度检查。在某些应用中，为了方便，人们将所有的参数放到一个巨大的参数向量中。在这种情况下，例如偏置就可能只占用整个向量中的很小一部分，所以不要随机地从向量中取维度，一定要把这种情况考虑到，确保所有参数都收到了正确的梯度。&lt;br&gt;&lt;/p&gt;&lt;br&gt;&lt;h2&gt;学习之前：合理性检查的提示与技巧&lt;/h2&gt;&lt;p&gt;在进行费时费力的最优化之前，最好进行一些合理性检查：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;寻找特定情况的正确损失值。&lt;/strong&gt;在使用小参数进行初始化时，确保得到的损失值与期望一致。最好先单独检查数据损失（让正则化强度为0）。例如，对于一个跑CIFAR-10的Softmax分类器，一般期望它的初始损失值是2.302，这是因为初始时预计每个类别的概率是0.1（因为有10个类别），然后Softmax损失值正确分类的负对数概率：-ln(0.1)=2.302。对于Weston Watkins SVM，假设所有的边界都被越过（因为所有的分值都近似为零），所以损失值是9（因为对于每个错误分类，边界值是1）。如果没看到这些损失值，那么初始化中就可能有问题。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;第二个合理性检查：提高正则化强度时导致损失值变大。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;对小数据子集过拟合。&lt;/strong&gt;最后也是最重要的一步，在整个数据集进行训练之前，尝试在一个很小的数据集上进行训练（比如20个数据），然后确保能到达0的损失值。进行这个实验的时候，最好让正则化强度为0，不然它会阻止得到0的损失。除非能通过这一个正常性检查，不然进行整个数据集训练是没有意义的。但是注意，能对小数据集进行过拟合并不代表万事大吉，依然有可能存在不正确的实现。比如，因为某些错误，数据点的特征是随机的，这样算法也可能对小数据进行过拟合，但是在整个数据集上跑算法的时候，就没有任何泛化能力。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;br&gt;&lt;h2&gt;检查整个学习过程&lt;/h2&gt;&lt;p&gt;在训练神经网络的时候，应该跟踪多个重要数值。这些数值输出的图表是观察训练进程的一扇窗口，是直观理解不同的超参数设置效果的工具，从而知道如何修改超参数以获得更高效的学习过程。&lt;/p&gt;&lt;br&gt;&lt;p&gt;在下面的图表中，x轴通常都是表示&lt;b&gt;&lt;u&gt;周期（epochs）&lt;/u&gt;&lt;/b&gt;单位，该单位衡量了在训练中每个样本数据都被观察过次数的期望（一个周期意味着每个样本数据都被观察过了一次）。相较于迭代次数（iterations），一般更倾向跟踪周期，这是因为迭代次数与数据的批尺寸（batchsize）有关，而批尺寸的设置又可以是任意的。&lt;/p&gt;&lt;h2&gt;损失函数&lt;/h2&gt;&lt;p&gt;训练期间第一个要跟踪的数值就是损失值，它在前向传播时对每个独立的批数据进行计算。下图展示的是随着损失值随时间的变化，尤其是曲线形状会给出关于学习率设置的情况：&lt;/p&gt;&lt;p&gt;————————————————————————————————————————&lt;/p&gt;&lt;p&gt;&lt;img src="753f398b46cc28c1916d6703cf2080f5.png" data-rawwidth="1578" data-rawheight="706"&gt;&lt;b&gt;左图&lt;/b&gt;展示了不同的学习率的效果。过低的学习率导致算法的改善是线性的。高一些的学习率会看起来呈几何指数下降，更高的学习率会让损失值很快下降，但是接着就停在一个不好的损失值上（绿线）。这是因为最优化的“能量”太大，参数在混沌中随机震荡，不能最优化到一个很好的点上。&lt;b&gt;右图&lt;/b&gt;显示了一个典型的随时间变化的损失函数值，在CIFAR-10数据集上面训练了一个小的网络，这个损失函数值曲线看起来比较合理（虽然可能学习率有点小，但是很难说），而且指出了批数据的数量可能有点太小（因为损失值的噪音很大）。&lt;/p&gt;&lt;p&gt;————————————————————————————————————————&lt;/p&gt;&lt;p&gt;损失值的震荡程度和批尺寸（batch size）有关，当批尺寸为1，震荡会相对较大。当批尺寸就是整个数据集时震荡就会最小，因为每个梯度更新都是单调地优化损失函数（除非学习率设置得过高）。&lt;/p&gt;&lt;p&gt;有的研究者喜欢用对数域对损失函数值作图。因为学习过程一般都是采用指数型的形状，图表就会看起来更像是能够直观理解的直线，而不是呈曲棍球一样的曲线状。还有，如果多个交叉验证模型在一个图上同时输出图像，它们之间的差异就会比较明显。&lt;/p&gt;&lt;p&gt;有时候损失函数看起来很有意思：&lt;a href="http://lossfunctions.tumblr.com" data-editable="true" data-title="lossfunctions.tumblr.com" class=""&gt;lossfunctions.tumblr.com&lt;/a&gt;。&lt;/p&gt;&lt;h3&gt;训练集和验证集准确率&lt;/h3&gt;&lt;p&gt;在训练分类器的时候，需要跟踪的第二重要的数值是验证集和训练集的准确率。这个图表能够展现知道模型过拟合的程度：&lt;br&gt;&lt;/p&gt;&lt;p&gt;————————————————————————————————————————&lt;/p&gt;&lt;p&gt;&lt;img src="05a6960a01c0204ced8d875ac3d91fba.jpg" data-rawwidth="660" data-rawheight="200"&gt;在训练集准确率和验证集准确率中间的空隙指明了模型过拟合的程度。在图中，蓝色的验证集曲线显示相较于训练集，验证集的准确率低了很多，这就说明模型有很强的过拟合。遇到这种情况，就应该增大正则化强度（更强的L2权重惩罚，更多的随机失活等）或收集更多的数据。另一种可能就是验证集曲线和训练集曲线如影随形，这种情况说明你的模型容量还不够大：应该通过增加参数数量让模型容量更大些。&lt;/p&gt;&lt;p&gt;————————————————————————————————————————&lt;/p&gt;&lt;h3&gt;权重更新比例&lt;/h3&gt;&lt;p&gt;最后一个应该跟踪的量是权重中更新值的数量和全部值的数量之间的比例。注意：是&lt;em&gt;更新的&lt;/em&gt;，而不是原始梯度（比如，在普通sgd中就是梯度乘以学习率）。需要对每个参数集的更新比例进行单独的计算和跟踪。一个经验性的结论是这个比例应该在1e-3左右。如果更低，说明学习率可能太小，如果更高，说明学习率可能太高。下面是具体例子：&lt;/p&gt;&lt;code lang="python"&gt;# 假设参数向量为W，其梯度向量为dW
param_scale = np.linalg.norm(W.ravel())
update = -learning_rate*dW # 简单SGD更新
update_scale = np.linalg.norm(update.ravel())
W += update # 实际更新
print update_scale / param_scale # 要得到1e-3左右
&lt;/code&gt;&lt;p&gt;相较于跟踪最大和最小值，有研究者更喜欢计算和跟踪梯度的范式及其更新。这些矩阵通常是相关的，也能得到近似的结果。&lt;/p&gt;&lt;br&gt;&lt;h3&gt;每层的激活数据及梯度分布&lt;/h3&gt;&lt;p&gt;一个不正确的初始化可能让学习过程变慢，甚至彻底停止。还好，这个问题可以比较简单地诊断出来。其中一个方法是输出网络中所有层的激活数据和梯度分布的柱状图。直观地说，就是如果看到任何奇怪的分布情况，那都不是好兆头。比如，对于使用tanh的神经元，我们应该看到激活数据的值在整个[-1,1]区间中都有分布。如果看到神经元的输出全部是0，或者全都饱和了往-1和1上跑，那肯定就是有问题了。&lt;/p&gt;&lt;h2&gt;第一层可视化&lt;/h2&gt;&lt;p&gt;最后，如果数据是图像像素数据，那么把第一层特征可视化会有帮助：&lt;/p&gt;&lt;p&gt;————————————————————————————————————————&lt;/p&gt;&lt;p&gt;&lt;img src="96573094f9d7f4b3b188069726840a2e.png" data-rawwidth="1602" data-rawheight="552"&gt;将神经网络第一层的权重可视化的例子。&lt;b&gt;左图&lt;/b&gt;中的特征充满了噪音，这暗示了网络可能出现了问题：网络没有收敛，学习率设置不恰当，正则化惩罚的权重过低。&lt;b&gt;右图&lt;/b&gt;的特征不错，平滑，干净而且种类繁多，说明训练过程进行良好。&lt;/p&gt;&lt;br&gt;&lt;p&gt;————————————————————————————————————————&lt;/p&gt;&lt;p&gt;&lt;b&gt;神经网络笔记3 （上）结束。&lt;/b&gt;&lt;br&gt;&lt;/p&gt;&lt;h2&gt;译者反馈&lt;/h2&gt;&lt;ol&gt;&lt;li&gt;&lt;b&gt;转载须全文转载且注明原文链接&lt;/b&gt;，否则保留维权权利；&lt;/li&gt;&lt;li&gt;请知友们通过评论和私信等方式批评指正，贡献者均会补充提及；&lt;/li&gt;&lt;li&gt;CS231n的翻译即将进入尾声，&lt;b&gt;欢迎知友们建议后续的翻译方向；&lt;/b&gt;&lt;/li&gt;&lt;li&gt;知友@&lt;a href="https://www.zhihu.com/people/ksma" class="" data-editable="true" data-title="猪皮"&gt;猪皮&lt;/a&gt;建议下一步的翻译方向是领域内的一些经典论文；&lt;/li&gt;&lt;li&gt;知友@&lt;a href="https://www.zhihu.com/people/nan-tian-qi-6" class="" data-editable="true" data-title="一蓑烟灰"&gt;一蓑烟灰&lt;/a&gt;在评论中详细解释了自己学习CS231n及本科毕设相关情况，建议下一步的翻译方向是课程作业解析。&lt;/li&gt;&lt;/ol&gt;</description><author>杜客</author><pubDate>Tue, 02 Aug 2016 14:26:25 GMT</pubDate></item><item><title>CS231n课程笔记翻译：神经网络笔记 2</title><link>https://zhuanlan.zhihu.com/p/21560667</link><description>&lt;p&gt;&lt;img src="https://pic1.zhimg.com/9843b69865ebb95506dfe9b4df48e31c_r.jpg"&gt;&lt;/p&gt;译者注：本文&lt;a href="https://zhuanlan.zhihu.com/intelligentunit" data-editable="true" data-title="智能单元" class=""&gt;智能单元&lt;/a&gt;首发，译自斯坦福CS231n课程笔记&lt;a href="http://cs231n.github.io/neural-networks-2/" class="" data-editable="true" data-title="Neural Nets notes 2"&gt;Neural Nets notes 2&lt;/a&gt;，课程教师&lt;a href="https://link.zhihu.com/?target=http%3A//cs.stanford.edu/people/karpathy/" class="" data-editable="true" data-title="Andrej Karpathy"&gt;Andrej Karpathy&lt;/a&gt;授权翻译。本篇教程由&lt;a href="https://www.zhihu.com/people/du-ke" class="" data-editable="true" data-title="杜客"&gt;杜客&lt;/a&gt;翻译完成，&lt;a href="https://www.zhihu.com/people/kun-kun-97-81" class="" data-editable="true" data-title="堃堃"&gt;堃堃&lt;/a&gt;进行校对修改。译文含公式和代码，建议PC端阅读。&lt;h2&gt;原文如下&lt;/h2&gt;&lt;p&gt;内容列表：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;设置数据和模型&lt;ul&gt;&lt;li&gt;数据预处理&lt;/li&gt;&lt;li&gt;权重初始化&lt;/li&gt;&lt;li&gt;批量归一化（Batch Normalization）&lt;/li&gt;&lt;li&gt;正则化（L2/L1/Maxnorm/Dropout）&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;损失函数&lt;/li&gt;&lt;li&gt;小结&lt;/li&gt;&lt;/ul&gt;&lt;h1&gt;设置数据和模型&lt;/h1&gt;&lt;p&gt;在上一节中介绍了神经元的模型，它在计算内积后进行非线性激活函数计算，神经网络将这些神经元组织成各个层。这些做法共同定义了&lt;b&gt;评分&lt;/b&gt;&lt;strong&gt;函数（score function）&lt;/strong&gt;的新形式，该形式是从前面线性分类章节中的简单线性映射发展而来的。具体来说，神经网络就是进行了一系列的线性映射与非线性激活函数交织的运算。本节将讨论更多的算法设计选项，比如数据预处理，权重初始化和损失函数。&lt;/p&gt;&lt;br&gt;&lt;h2&gt;数据预处理&lt;/h2&gt;&lt;p&gt;关于数据预处理我们有3个常用的符号，数据矩阵&lt;b&gt;X&lt;/b&gt;，假设其尺寸是&lt;b&gt;[N x D]&lt;/b&gt;（&lt;b&gt;N&lt;/b&gt;是数据样本的数量，&lt;b&gt;D&lt;/b&gt;是数据的维度）。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;均值减法（&lt;/strong&gt;&lt;strong&gt;Mean subtraction&lt;/strong&gt;&lt;strong&gt;）&lt;/strong&gt;是预处理最常用的形式。它对数据中每个独立&lt;em&gt;特征&lt;/em&gt;减去平均值，从几何上可以理解为在每个维度上都将数据云的中心都迁移到原点。在numpy中，该操作可以通过代码&lt;b&gt;X -= np.mean(X, axis=0)&lt;/b&gt;实现。而对于图像，更常用的是对所有像素都减去一个值，可以用&lt;b&gt;X -= np.mean(X)&lt;/b&gt;实现，也可以在3个颜色通道上分别操作。&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;strong&gt;归一化（&lt;/strong&gt;&lt;strong&gt;Normalization&lt;/strong&gt;&lt;strong&gt;）&lt;/strong&gt;是指将数据的所有维度都归一化，使其数值范围都近似相等。有两种常用方法可以实现归一化。第一种是先对数据做零中心化（zero-centered）处理，然后每个维度都除以其标准差，实现代码为&lt;b&gt;X /= np.std(X, axis=0)&lt;/b&gt;。第二种方法是对每个维度都做归一化，使得每个维度的最大和最小值是1和-1。这个预处理操作只有在确信不同的输入特征有不同的数值范围（或计量单位）时才有意义，但要注意预处理操作的重要性几乎等同于学习算法本身。在图像处理中，由于像素的数值范围几乎是一致的（都在0-255之间），所以进行这个额外的预处理步骤并不是很必要。&lt;/p&gt;&lt;br&gt;&lt;p&gt;——————————————————————————————————————————&lt;/p&gt;&lt;p&gt;&lt;img src="e743b6777775b1671c3b5503d7afbbc4.png" data-rawwidth="1592" data-rawheight="560"&gt;一般数据预处理流程：&lt;b&gt;左边：&lt;/b&gt;原始的2维输入数据。&lt;b&gt;中间：&lt;/b&gt;在每个维度上都减去平均值后得到零中心化数据，现在数据云是以原点为中心的。&lt;b&gt;右边：&lt;/b&gt;每个维度都除以其标准差来调整其数值范围。红色的线指出了数据各维度的数值范围，在中间的零中心化数据的数值范围不同，但在右边归一化数据中数值范围相同。&lt;br&gt;&lt;/p&gt;&lt;p&gt;——————————————————————————————————————————&lt;/p&gt;&lt;p&gt;&lt;strong&gt;PCA和白化（&lt;/strong&gt;&lt;strong&gt;Whitening&lt;/strong&gt;&lt;strong&gt;）&lt;/strong&gt;是另一种预处理形式。在这种处理中，先对数据进行零中心化处理，然后计算协方差矩阵，它展示了数据中的相关性结构。&lt;/p&gt;&lt;code lang="python"&gt;# 假设输入数据矩阵X的尺寸为[N x D]
X -= np.mean(X, axis = 0) # 对数据进行零中心化(重要)
cov = np.dot(X.T, X) / X.shape[0] # 得到数据的协方差矩阵
&lt;/code&gt;&lt;p&gt;数据协方差矩阵的第(i, j)个元素是数据第i个和第j个维度的&lt;i&gt;协方差&lt;/i&gt;。具体来说，该矩阵的对角线上的元素是方差。还有，协方差矩阵是对称和&lt;a href="https://en.wikipedia.org/wiki/Positive-definite_matrix#Negative-definite.2C_semidefinite_and_indefinite_matrices" data-editable="true" data-title="半正定" class=""&gt;半正定&lt;/a&gt;的。我们可以对数据协方差矩阵进行SVD（奇异值分解）运算。&lt;br&gt;&lt;/p&gt;&lt;code lang="python"&gt;U,S,V = np.linalg.svd(cov)
&lt;/code&gt;&lt;p&gt;U的列是特征向量，S是装有奇异值的1维数组（因为cov是对称且半正定的，所以S中元素是特征值的平方）。为了去除数据相关性，将已经零中心化处理过的原始数据投影到特征基准上：&lt;/p&gt;&lt;br&gt;&lt;code lang="python"&gt;Xrot = np.dot(X,U) # 对数据去相关性
&lt;/code&gt;&lt;p&gt;注意U的列是标准正交向量的集合（范式为1，列之间标准正交），所以可以把它们看做标准正交基向量。因此，投影对应x中的数据的一个旋转，旋转产生的结果就是新的特征向量。如果计算&lt;b&gt;Xrot&lt;/b&gt;的协方差矩阵，将会看到它是对角对称的。&lt;b&gt;np.linalg.svd&lt;/b&gt;的一个良好性质是在它的返回值&lt;b&gt;U&lt;/b&gt;中，特征向量是按照特征值的大小排列的。我们可以利用这个性质来对数据降维，只要使用前面的小部分特征向量，丢弃掉那些包含的数据没有&lt;u&gt;&lt;b&gt;方差&lt;/b&gt;&lt;/u&gt;的维度。 这个操作也被称为主成分分析（ &lt;a href="http://en.wikipedia.org/wiki/Principal_component_analysis" data-editable="true" data-title="Principal Component Analysis" class=""&gt;Principal Component Analysis&lt;/a&gt; 简称PCA）降维：&lt;/p&gt;&lt;code lang="python"&gt;Xrot_reduced = np.dot(X, U[:,:100]) # Xrot_reduced 变成 [N x 100]
&lt;/code&gt;&lt;p&gt;经过上面的操作，将原始的数据集的大小由[N x D]降到了[N x 100]，留下了数据中包含最大&lt;u&gt;&lt;b&gt;方差&lt;/b&gt;&lt;/u&gt;的100个维度。通常使用PCA降维过的数据训练线性分类器和神经网络会达到非常好的性能效果，同时还能节省时间和存储器空间。&lt;/p&gt;&lt;br&gt;&lt;p&gt;最后一个在实践中会看见的变换是&lt;strong&gt;白化（&lt;/strong&gt;&lt;strong&gt;whitening&lt;/strong&gt;&lt;strong&gt;）&lt;/strong&gt;。白化操作的输入是特征基准上的数据，然后对每个维度除以其特征值来对数值范围进行归一化。该变换的几何解释是：如果数据服从多变量的高斯分布，那么经过白化后，数据的分布将会是一个均值为零，且协方差相等的矩阵。该操作的代码如下：&lt;/p&gt;&lt;br&gt;&lt;code lang="python"&gt;# 对数据进行白化操作:
# 除以特征值 
Xwhite = Xrot / np.sqrt(S + 1e-5)
&lt;/code&gt;&lt;p&gt;&lt;em&gt;警告：夸大的噪声&lt;/em&gt;。注意分母中添加了1e-5（或一个更小的常量）来防止分母为0。该变换的一个缺陷是在变换的过程中可能会夸大数据中的噪声，这是因为它将所有维度都拉伸到相同的数值范围，这些维度中也包含了那些只有极少差异性(方差小)而大多是噪声的维度。在实际操作中，这个问题可以用更强的平滑来解决（例如：采用比1e-5更大的值）。&lt;br&gt;&lt;/p&gt;&lt;p&gt;——————————————————————————————————————————&lt;/p&gt;&lt;p&gt;&lt;img src="aae11de6e6a29f50d46b9ea106fbb02a.png" data-rawwidth="1602" data-rawheight="542"&gt;PCA/白化。&lt;b&gt;左边&lt;/b&gt;是二维的原始数据。&lt;b&gt;中间&lt;/b&gt;：经过PCA操作的数据。可以看出数据首先是零中心的，然后变换到了数据协方差矩阵的基准轴上。这样就对数据进行了解相关（协方差矩阵变成对角阵）。&lt;b&gt;右边&lt;/b&gt;：每个维度都被特征值调整数值范围，将数据协方差矩阵变为单位矩阵。从几何上看，就是对数据在各个方向上拉伸压缩，使之变成服从高斯分布的一个数据点分布。&lt;br&gt;&lt;/p&gt;&lt;p&gt;——————————————————————————————————————————&lt;/p&gt;&lt;p&gt;我们可以使用CIFAR-10数据将这些变化可视化出来。CIFAR-10训练集的大小是50000x3072，其中每张图片都可以拉伸为3072维的行向量。我们可以计算[3072 x 3072]的协方差矩阵然后进行奇异值分解（比较耗费计算性能），那么经过计算的特征向量看起来是什么样子呢？&lt;br&gt;&lt;/p&gt;&lt;p&gt;—————————————————————————————————————————&lt;/p&gt;&lt;p&gt;&lt;img src="8608c06086fc196228f4dda78499a2d9.png" data-rawwidth="1604" data-rawheight="450"&gt;&lt;b&gt;最左&lt;/b&gt;：一个用于演示的集合，含49张图片。&lt;b&gt;左二&lt;/b&gt;：3072个特征值向量中的前144个。靠前面的特征向量解释了数据中大部分的方差，可以看见它们与图像中较低的频率相关。&lt;b&gt;第三张&lt;/b&gt;是49张经过了PCA降维处理的图片，展示了144个特征向量。这就是说，展示原始图像是每个图像用3072维的向量，向量中的元素是图片上某个位置的像素在某个颜色通道中的亮度值。而现在每张图片只使用了一个144维的向量，其中每个元素表示了特征向量对于组成这张图片的贡献度。为了让图片能够正常显示，需要将144维度重新变成基于像素基准的3072个数值。因为U是一个旋转，可以通过乘以U.transpose()[:144,:]来实现，然后将得到的3072个数值可视化。可以看见图像变得有点模糊了，这正好说明前面的特征向量获取了较低的频率。然而，大多数信息还是保留了下来。&lt;b&gt;最右&lt;/b&gt;：将“白化”后的数据进行显示。其中144个维度中的方差都被压缩到了相同的数值范围。然后144个白化后的数值通过乘以U.transpose()[:144,:]转换到图像像素基准上。现在较低的频率（代表了大多数方差）可以忽略不计了，较高的频率（代表相对少的方差）就被夸大了。&lt;/p&gt;&lt;br&gt;&lt;p&gt;——————————————————————————————————————————&lt;/p&gt;&lt;p&gt;&lt;strong&gt;实践操作。&lt;/strong&gt;在这个笔记中提到PCA和白化主要是为了介绍的完整性，实际上在卷积神经网络中并不会采用这些变换。然而对数据进行零中心化操作还是非常重要的，对每个像素进行归一化也很常见。&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;strong&gt;常见错误。&lt;/strong&gt;进行预处理很重要的一点是：任何预处理策略（比如数据均值）都只能在训练集数据上进行计算，算法训练完毕后再应用到验证集或者测试集上。例如，如果先计算整个数据集图像的平均值然后每张图片都减去平均值，最后将整个数据集分成训练/验证/测试集，那么这个做法是错误的。&lt;strong&gt;应该怎么做呢？应该先分成训练/验证/测试集，只是从训练集中求图片平均值，然后各个集（训练/验证/测试集）中的图像再减去这个平均值。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;&lt;i&gt;译者注：此处确为初学者常见错误，请务必注意！&lt;/i&gt;&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;权重初始化&lt;/h2&gt;&lt;p&gt;我们已经看到如何构建一个神经网络的结构并对数据进行预处理，但是在开始训练网络之前，还需要初始化网络的参数。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;错误：全零初始化。&lt;/strong&gt;让我们从应该避免的错误开始。在训练完毕后，虽然不知道网络中每个权重的最终值应该是多少，但如果数据经过了恰当的归一化的话，就可以假设所有权重数值中大约一半为正数，一半为负数。这样，一个听起来蛮合理的想法就是把这些权重的初始值都设为0吧，因为在期望上来说0是最合理的猜测。这个做法错误的！因为如果网络中的每个神经元都计算出同样的输出，然后它们就会在反向传播中计算出同样的梯度，从而进行同样的参数更新。换句话说，如果权重被初始化为同样的值，神经元之间就失去了不对称性的源头。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;小随机数初始化。&lt;/strong&gt;因此，权重初始值要非常接近0又不能等于0。解决方法就是将权重初始化为很小的数值，以此来&lt;i&gt;打破对称性&lt;/i&gt;。其思路是：如果神经元刚开始的时候是随机且不相等的，那么它们将计算出不同的更新，并将自身变成整个网络的不同部分。小随机数权重初始化的实现方法是：&lt;b&gt;W = 0.01 * np.random.randn(D,H)。&lt;/b&gt;其中&lt;b&gt;randn&lt;/b&gt;函数是基于零均值和标准差的一个高斯分布（&lt;b&gt;&lt;i&gt;译者注：国内教程一般习惯称均值参数为期望&lt;equation&gt;\mu&lt;/equation&gt;&lt;/i&gt;&lt;/b&gt;）来生成随机数的。根据这个式子，每个神经元的权重向量都被初始化为一个随机向量，而这些随机向量又服从一个多变量高斯分布，这样在输入空间中，所有的神经元的指向是随机的。也可以使用均匀分布生成的随机数，但是从实践结果来看，对于算法的结果影响极小。&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;em&gt;&lt;b&gt;警告&lt;/b&gt;。&lt;/em&gt;并不是小数值一定会得到好的结果。例如，一个神经网络的层中的权重值很小，那么在反向传播的时候就会计算出非常小的梯度（因为梯度与权重值是成比例的）。这就会很大程度上减小反向传播中的“梯度信号”，在深度网络中，就会出现问题。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;使用1/sqrt(n)校准方差&lt;/strong&gt;&lt;strong&gt;。&lt;/strong&gt;上面做法存在一个问题，随着输入数据量的增长，随机初始化的神经元的输出数据的分布中的方差也在增大。我们可以除以输入数据量的平方根来调整其数值范围，这样神经元输出的方差就归一化到1了。也就是说，建议将神经元的权重向量初始化为：&lt;b&gt;w = np.random.randn(n) / sqrt(n)。&lt;/b&gt;其中&lt;b&gt;n&lt;/b&gt;是输入数据的数量。这样就保证了网络中所有神经元起始时有近似同样的输出分布。实践经验证明，这样做可以提高收敛的速度。&lt;/p&gt;&lt;p&gt;上述结论的推导过程如下：假设权重&lt;equation&gt;w&lt;/equation&gt;和输入&lt;equation&gt;x&lt;/equation&gt;之间的内积为&lt;equation&gt;s=\sum^n_iw_ix_i&lt;/equation&gt;，这是还没有进行非线性激活函数运算之前的原始数值。我们可以检查&lt;equation&gt;s&lt;/equation&gt;的方差：&lt;br&gt;&lt;/p&gt;&lt;equation&gt;\displaystyle Var(s)=Var(\sum^n_iw_ix_i)&lt;/equation&gt;&lt;br&gt;&lt;equation&gt;\displaystyle =\sum^n_iVar(w_ix_i)&lt;/equation&gt;&lt;br&gt;&lt;equation&gt;\displaystyle =\sum^n_i[E(w_i)]^2Var(x_i)+E[(x_i)]^2Var(w_i)+Var(xIi)Var(w_i)&lt;/equation&gt;&lt;br&gt;&lt;equation&gt;\displaystyle =\sum^n_iVar(x_i)Var(w_i)&lt;/equation&gt;&lt;br&gt;&lt;equation&gt;\displaystyle =(nVar(w))Var(x)&lt;/equation&gt;&lt;br&gt;&lt;p&gt;在前两步，使用了&lt;a href="http://en.wikipedia.org/wiki/Variance" data-editable="true" data-title="方差的性质"&gt;方差的性质&lt;/a&gt;。在第三步，因为假设输入和权重的平均值都是0，所以&lt;equation&gt;E[x_i]=E[w_i]=0&lt;/equation&gt;。注意这并不是一般化情况，比如在ReLU单元中均值就为正。在最后一步，我们假设所有的&lt;equation&gt;w_i,x_i&lt;/equation&gt;都服从同样的分布。从这个推导过程我们可以看见，如果想要&lt;equation&gt;s&lt;/equation&gt;有和输入&lt;equation&gt;x&lt;/equation&gt;一样的方差，那么在初始化的时候必须保证每个权重&lt;equation&gt;w&lt;/equation&gt;的方差是&lt;equation&gt;1/n&lt;/equation&gt;。又因为对于一个随机变量&lt;equation&gt;X&lt;/equation&gt;和标量&lt;equation&gt;a&lt;/equation&gt;，有&lt;equation&gt;Var(aX)=a^2Var(X)&lt;/equation&gt;，这就说明可以基于一个标准高斯分布，然后除以&lt;equation&gt;a=\sqrt{1/n}&lt;/equation&gt;，使其方差为&lt;equation&gt;1/n&lt;/equation&gt;，于是得出：&lt;b&gt;w = np.random.randn(n) / sqrt(n)&lt;/b&gt;。&lt;/p&gt;&lt;br&gt;&lt;p&gt;Glorot等在论文&lt;a href="http://jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf" data-editable="true" data-title="Understanding the difficulty of training deep feedforward neural networks" class=""&gt;Understanding the difficulty of training deep feedforward neural networks&lt;/a&gt;中作出了类似的分析。在论文中，作者推荐初始化公式为&lt;equation&gt; \( \text{Var}(w) = 2/(n_{in} + n_{out}) \) &lt;/equation&gt;，其中&lt;equation&gt;\(n_{in}, n_{out}\)&lt;/equation&gt;是在前一层和后一层中单元的个数。这是基于妥协和对反向传播中梯度的分析得出的结论。该主题下最新的一篇论文是：&lt;a href="http://arxiv-web3.library.cornell.edu/abs/1502.01852" data-editable="true" data-title="Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification" class=""&gt;Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification&lt;/a&gt;，作者是He等人。文中给出了一种针对ReLU神经元的特殊初始化，并给出结论：网络中神经元的方差应该是&lt;equation&gt;2.0/n&lt;/equation&gt;。代码为&lt;strong&gt;w = np.random.randn(n) * sqrt(2.0/n)&lt;/strong&gt;。这个形式是神经网络算法使用ReLU神经元时的当前最佳推荐。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;稀疏初始化（&lt;/strong&gt;&lt;strong&gt;Sparse initialization&lt;/strong&gt;&lt;strong&gt;）。&lt;/strong&gt;另一个处理非标定方差的方法是将所有权重矩阵设为0，但是为了打破对称性，每个神经元都同下一层固定数目的神经元随机连接（其权重数值由一个小的高斯分布生成）。一个比较典型的连接数目是10个。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;偏置（biases）的初始化。&lt;/strong&gt;通常将偏置初始化为0，这是因为随机小数值权重矩阵已经打破了对称性。对于ReLU非线性激活函数，有研究人员喜欢使用如0.01这样的小数值常量作为所有偏置的初始值，这是因为他们认为这样做能让所有的ReLU单元一开始就激活，这样就能保存并传播一些梯度。然而，这样做是不是总是能提高算法性能并不清楚（有时候实验结果反而显示性能更差），所以通常还是使用0来初始化偏置参数。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;实践。&lt;/strong&gt;当前的推荐是使用ReLU激活函数，并且使用&lt;strong&gt;w = np.random.randn(n) * sqrt(2.0/n)&lt;/strong&gt;来进行权重初始化，关于这一点，&lt;a href="http://arxiv-web3.library.cornell.edu/abs/1502.01852" data-editable="true" data-title="这里" class=""&gt;这篇文章&lt;/a&gt;有讨论。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;批量归一化（&lt;/strong&gt;&lt;strong&gt;Batch Normalization&lt;/strong&gt;&lt;strong&gt;）。&lt;/strong&gt;&lt;a href="http://arxiv.org/abs/1502.03167" data-editable="true" data-title="批量归一化"&gt;批量归一化&lt;/a&gt;是loffe和Szegedy最近才提出的方法，该方法减轻了如何合理初始化神经网络这个棘手问题带来的头痛：），其做法是让激活数据在训练开始前通过一个网络，网络处理数据使其服从标准高斯分布。因为归一化是一个简单可求导的操作，所以上述思路是可行的。在实现层面，应用这个技巧通常意味着全连接层（或者是卷积层，后续会讲）与激活函数之间添加一个BatchNorm层。对于这个技巧本节不会展开讲，因为上面的参考文献中已经讲得很清楚了，需要知道的是在神经网络中使用批量归一化已经变得非常常见。在实践中，使用了批量归一化的网络对于不好的初始值有更强的鲁棒性。最后一句话总结：批量归一化可以理解为在网络的每一层之前都做预处理，只是这种操作以另一种方式与网络集成在了一起。搞定！&lt;/p&gt;&lt;h2&gt;正则化 Regularization&lt;/h2&gt;&lt;p&gt;有不少方法是通过控制神经网络的容量来防止其过拟合的：&lt;/p&gt;&lt;p&gt;&lt;b&gt;L2正则化&lt;/b&gt;可能是最常用的正则化方法了。可以通过惩罚目标函数中所有参数的平方将其实现。即对于网络中的每个权重&lt;equation&gt;w&lt;/equation&gt;，向目标函数中增加一个&lt;equation&gt;\frac{1}{2}\lambda w^2&lt;/equation&gt;，其中&lt;equation&gt;\lambda&lt;/equation&gt;是正则化强度。前面这个&lt;equation&gt;\frac{1}{2}&lt;/equation&gt;很常见，是因为加上&lt;equation&gt;\frac{1}{2}&lt;/equation&gt;后，该式子关于&lt;equation&gt;w&lt;/equation&gt;梯度就是&lt;equation&gt;\lambda w&lt;/equation&gt;而不是&lt;equation&gt;2\lambda w&lt;/equation&gt;了。L2正则化可以直观理解为它对于大数值的权重向量进行严厉惩罚，倾向于更加分散的权重向量。在线性分类章节中讨论过，由于输入和权重之间的乘法操作，这样就有了一个优良的特性：使网络更倾向于使用所有输入特征，而不是严重依赖输入特征中某些小部分特征。最后需要注意在梯度下降和参数更新的时候，使用L2正则化意味着所有的权重都以&lt;b&gt;w += -lambda * W&lt;/b&gt;向着0线性下降。&lt;/p&gt;&lt;p&gt;&lt;b&gt;L1正则化&lt;/b&gt;是另一个相对常用的正则化方法。对于每个&lt;equation&gt;w&lt;/equation&gt;我们都向目标函数增加一个&lt;equation&gt;\lambda|w|&lt;/equation&gt;。L1和L2正则化也可以进行组合：&lt;equation&gt;\lambda_1|w|+\lambda_2w^2&lt;/equation&gt;，这也被称作&lt;a href="http://web.stanford.edu/%7Ehastie/Papers/B67.2%20%282005%29%20301-320%20Zou%20&amp;amp;%20Hastie.pdf" data-editable="true" data-title="Elastic net regularizaton" class=""&gt;Elastic net regularizaton&lt;/a&gt;。L1正则化有一个有趣的性质，它会让权重向量在最优化的过程中变得稀疏（即非常接近0）。也就是说，使用L1正则化的神经元最后使用的是它们最重要的输入数据的稀疏子集，同时对于噪音输入则几乎是不变的了。相较L1正则化，L2正则化中的权重向量大多是分散的小数字。在实践中，如果不是特别关注某些明确的特征选择，一般说来L2正则化都会比L1正则化效果好。&lt;/p&gt;&lt;p&gt;&lt;b&gt;最大范式约束（Max norm constraints）。&lt;/b&gt;另一种形式的正则化是给每个神经元中权重向量的量级设定上限，并使用投影梯度下降来确保这一约束。在实践中，与之对应的是参数更新方式不变，然后要求神经元中的权重向量&lt;equation&gt;\overrightarrow{w}&lt;/equation&gt;必须满足&lt;equation&gt;||\overrightarrow{w}||_2&amp;lt;c&lt;/equation&gt;这一条件，一般&lt;equation&gt;c&lt;/equation&gt;值为3或者4。有研究者发文称在使用这种正则化方法时效果更好。这种正则化还有一个良好的性质，即使在学习率设置过高的时候，网络中也不会出现数值“爆炸”，这是因为它的参数更新始终是被限制着的。&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;strong&gt;随机失活（Dropout）&lt;/strong&gt;是一个简单又极其有效的正则化方法。该方法由Srivastava在论文&lt;a href="http://www.cs.toronto.edu/%7Ersalakhu/papers/srivastava14a.pdf" data-editable="true" data-title="Dropout: A Simple Way to Prevent Neural Networks from Overfitting" class=""&gt;Dropout: A Simple Way to Prevent Neural Networks from Overfitting&lt;/a&gt;中提出的，与L1正则化，L2正则化和最大范式约束等方法互为补充。在训练的时候，随机失活的实现方法是让神经元以超参数&lt;equation&gt;p&lt;/equation&gt;的概率被激活或者被设置为0。&lt;br&gt;&lt;/p&gt;&lt;p&gt;—————————————————————————————————————————&lt;/p&gt;&lt;p&gt;&lt;img src="63fcf4cc655cb04f21a37e86aca333cf.png" data-rawwidth="1590" data-rawheight="608"&gt;图片来源自&lt;a href="http://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf" data-editable="true" data-title="论文"&gt;论文&lt;/a&gt;，展示其核心思路。在训练过程中，随机失活可以被认为是对完整的神经网络抽样出一些子集，每次基于输入数据只更新子网络的参数（然而，数量巨大的子网络们并不是相互独立的，因为它们都共享参数）。在测试过程中不使用随机失活，可以理解为是对数量巨大的子网络们做了模型集成（model ensemble），以此来计算出一个平均的预测。&lt;br&gt;&lt;/p&gt;&lt;p&gt;—————————————————————————————————————————&lt;/p&gt;&lt;p&gt;一个3层神经网络的普通版随机失活可以用下面代码实现：&lt;br&gt;&lt;/p&gt;&lt;code lang="python"&gt;""" 普通版随机失活: 不推荐实现 (看下面笔记) """

p = 0.5 # 激活神经元的概率. p值更高 = 随机失活更弱

def train_step(X):
  """ X中是输入数据 """
  
  # 3层neural network的前向传播
  H1 = np.maximum(0, np.dot(W1, X) + b1)
  U1 = np.random.rand(*H1.shape) &amp;lt; p # 第一个随机失活遮罩
  H1 *= U1 # drop!
  H2 = np.maximum(0, np.dot(W2, H1) + b2)
  U2 = np.random.rand(*H2.shape) &amp;lt; p # 第二个随机失活遮罩
  H2 *= U2 # drop!
  out = np.dot(W3, H2) + b3
  
  # 反向传播:计算梯度... (略)
  # 进行参数更新... (略)
  
def predict(X):
  # 前向传播时模型集成
  H1 = np.maximum(0, np.dot(W1, X) + b1) * p # 注意：激活数据要乘以p
  H2 = np.maximum(0, np.dot(W2, H1) + b2) * p # 注意：激活数据要乘以p
  out = np.dot(W3, H2) + b3
&lt;/code&gt;&lt;p&gt;在上面的代码中，&lt;b&gt;train_step&lt;/b&gt;函数在第一个隐层和第二个隐层上进行了两次随机失活。在输入层上面进行随机失活也是可以的，为此需要为输入数据&lt;b&gt;X创建&lt;/b&gt;一个二值的遮罩。反向传播保持不变，但是肯定需要将遮罩&lt;b&gt;U1&lt;/b&gt;和&lt;b&gt;U2&lt;/b&gt;加入进去。&lt;/p&gt;&lt;br&gt;&lt;p&gt;注意：在&lt;b&gt;predict&lt;/b&gt;函数中不进行随机失活，但是对于两个隐层的输出都要乘以&lt;equation&gt;p&lt;/equation&gt;，调整其数值范围。这一点非常重要，因为在测试时所有的神经元都能看见它们的输入，因此我们想要神经元的输出与训练时的预期输出是一致的。以&lt;equation&gt;p=0.5&lt;/equation&gt;为例，在测试时神经元必须把它们的输出减半，这是因为在训练的时候它们的输出只有一半。为了理解这点，先假设有一个神经元&lt;equation&gt;x&lt;/equation&gt;的输出，那么进行随机失活的时候，该神经元的输出就是&lt;equation&gt;px+(1-p)0&lt;/equation&gt;，这是有&lt;equation&gt;1-p&lt;/equation&gt;的概率神经元的输出为0。在测试时神经元总是激活的，就必须调整&lt;equation&gt;x\to px&lt;/equation&gt;来保持同样的预期输出。在测试时会在所有可能的二值遮罩（也就是数量庞大的所有子网络）中迭代并计算它们的协作预测，进行这种减弱的操作也可以认为是与之相关的。&lt;/p&gt;&lt;br&gt;&lt;p&gt;上述操作不好的性质是必须在测试时对激活数据要按照&lt;equation&gt;p&lt;/equation&gt;进行数值范围调整。既然测试性能如此关键，实际更倾向使用&lt;b&gt;反向随机失活（inverted dropout）&lt;/b&gt;，它是在训练时就进行数值范围调整，从而让前向传播在测试时保持不变。这样做还有一个好处，无论你决定是否使用随机失活，预测方法的代码可以保持不变。反向随机失活的代码如下：&lt;/p&gt;&lt;br&gt;&lt;code lang="python"&gt;""" 
反向随机失活: 推荐实现方式.
在训练的时候drop和调整数值范围，测试时不做任何事.
"""

p = 0.5 # 激活神经元的概率. p值更高 = 随机失活更弱

def train_step(X):
  # 3层neural network的前向传播
  H1 = np.maximum(0, np.dot(W1, X) + b1)
  U1 = (np.random.rand(*H1.shape) &amp;lt; p) / p # 第一个随机失活遮罩. 注意/p!
  H1 *= U1 # drop!
  H2 = np.maximum(0, np.dot(W2, H1) + b2)
  U2 = (np.random.rand(*H2.shape) &amp;lt; p) / p # 第二个随机失活遮罩. 注意/p!
  H2 *= U2 # drop!
  out = np.dot(W3, H2) + b3

  # 反向传播:计算梯度... (略)
  # 进行参数更新... (略)

def predict(X):
  # 前向传播时模型集成
  H1 = np.maximum(0, np.dot(W1, X) + b1) # 不用数值范围调整了
  H2 = np.maximum(0, np.dot(W2, H1) + b2)
  out = np.dot(W3, H2) + b3
&lt;/code&gt;&lt;p&gt;在随机失活发布后，很快有大量研究为什么它的实践效果如此之好，以及它和其他正则化方法之间的关系。如果你感兴趣，可以看看这些文献：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;a href="http://www.cs.toronto.edu/%7Ersalakhu/papers/srivastava14a.pdf" data-editable="true" data-title="Dropout paper"&gt;Dropout paper&lt;/a&gt; by Srivastava et al. 2014.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href="http://papers.nips.cc/paper/4882-dropout-training-as-adaptive-regularization.pdf" data-editable="true" data-title="Dropout Training as Adaptive Regularization" class=""&gt;Dropout Training as Adaptive Regularization&lt;/a&gt;：“我们认为：在使用费希尔信息矩阵（&lt;a href="https://en.wikipedia.org/wiki/Fisher_information_metric" data-editable="true" data-title="fisher information matrix"&gt;fisher information matrix&lt;/a&gt;）的对角逆矩阵的期望对特征进行数值范围调整后，再进行L2正则化这一操作，与随机失活正则化是一阶相等的。”&lt;/p&gt;&lt;br&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;前向传播中的噪音。&lt;/strong&gt;在更一般化的分类上，随机失活属于网络在前向传播中有随机行为的方法。测试时，通过&lt;i&gt;分析法&lt;/i&gt;（在使用随机失活的本例中就是乘以&lt;equation&gt;p&lt;/equation&gt;）或&lt;i&gt;数值法&lt;/i&gt;（例如通过抽样出很多子网络，随机选择不同子网络进行前向传播，最后对它们取平均）将噪音边缘化。在这个方向上的另一个研究是&lt;a href="http://cs.nyu.edu/%7Ewanli/dropc/" data-editable="true" data-title="DropConnect"&gt;DropConnect&lt;/a&gt;，它在前向传播的时候，一系列权重被随机设置为0。提前说一下，卷积神经网络同样会吸取这类方法的优点，比如随机汇合（stochastic pooling），分级汇合（fractional pooling），数据增长（data augmentation）。我们在后面会详细介绍。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;偏置正则化。&lt;/strong&gt;在线性分类器的章节中介绍过，对于偏置参数的正则化并不常见，因为它们在矩阵乘法中和输入数据并不产生互动，所以并不需要控制其在数据维度上的效果。然而在实际应用中（使用了合理数据预处理的情况下），对偏置进行正则化也很少会导致算法性能变差。这可能是因为相较于权重参数，偏置参数实在太少，所以分类器需要它们来获得一个很好的数据损失，那么还是能够承受的。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;每层正则化。&lt;/strong&gt;对于不同的层进行不同强度的正则化很少见（可能除了输出层以外），关于这个思路的相关文献也很少。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;实践&lt;/strong&gt;：通过交叉验证获得一个全局使用的L2正则化强度是比较常见的。在使用L2正则化的同时在所有层后面使用随机失活也很常见。&lt;equation&gt;p&lt;/equation&gt;值一般默认设为0.5，也可能在验证集上调参。&lt;/p&gt;&lt;br&gt;&lt;h2&gt;损失函数&lt;/h2&gt;&lt;p&gt;我们已经讨论过损失函数的正则化损失部分，它可以看做是对模型复杂程度的某种惩罚。损失函数的第二个部分是&lt;em&gt;数据损失&lt;/em&gt;，它是一个有监督学习问题，用于衡量分类算法的预测结果（即分类评分）和真实标签结果之间的一致性。数据损失是对所有样本的数据损失求平均。也就是说，&lt;equation&gt;L=\frac{1}{N}\sum_iL_i&lt;/equation&gt;中，&lt;equation&gt;N&lt;/equation&gt;是训练集数据的样本数。让我们把神经网络中输出层的激活函数简写为&lt;equation&gt;f=f(x_i;W)&lt;/equation&gt;，在实际中你可能需要解决以下几类问题：&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;分类问题&lt;/b&gt;是我们一直讨论的。在该问题中，假设有一个装满样本的数据集，每个样本都有一个唯一的正确标签（是固定分类标签之一）。在这类问题中，一个最常见的损失函数就是SVM（是Weston Watkins 公式）：&lt;/p&gt;&lt;equation&gt;\displaystyle L_i=\sum_{j\not=y_i}max(0,f_j-f_{y_i}+1)&lt;/equation&gt;&lt;br&gt;&lt;p&gt;之前简要提起过，有些学者的论文中指出平方折叶损失（即使用&lt;equation&gt;max(0,f_j-f_{y_i}+1)^2&lt;/equation&gt;）算法的结果会更好。第二个常用的损失函数是Softmax分类器，它使用交叉熵损失：&lt;/p&gt;&lt;equation&gt;\displaystyle L_i=-log(\frac{e^{f_{y_i}}}{\sum_je^{f_j}})&lt;/equation&gt;&lt;br&gt;&lt;p&gt;&lt;strong&gt;问题：类别数目巨大。&lt;/strong&gt;当标签集非常庞大（例如字典中的所有英语单词，或者ImageNet中的22000种分类），就需要使用&lt;em&gt;分层Softmax（&lt;/em&gt;&lt;i&gt;Hierarchical Softmax&lt;/i&gt;&lt;em&gt;）&lt;/em&gt;了（&lt;a href="http://arxiv.org/pdf/1310.4546.pdf" data-editable="true" data-title="参考文献" class=""&gt;参考文献&lt;/a&gt;）。分层softmax将标签分解成一个树。每个标签都表示成这个树上的一个路径，这个树的每个节点处都训练一个Softmax分类器来在左和右分枝之间做决策。树的结构对于算法的最终结果影响很大，而且一般需要具体问题具体分析。&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;b&gt;属性（Attribute）分类。&lt;/b&gt;上面两个损失公式的前提，都是假设每个样本只有一个正确的标签&lt;equation&gt;y_i&lt;/equation&gt;。但是如果&lt;equation&gt;y_i&lt;/equation&gt;是一个二值向量，每个样本可能有，也可能没有某个属性，而且属性之间并不相互排斥呢？比如在Instagram上的图片，就可以看成是被一个巨大的标签集合中的某个子集打上标签，一张图片上可能有多个标签。在这种情况下，一个明智的方法是为每个属性创建一个独立的二分类的分类器。例如，针对每个分类的二分类器会采用下面的公式：&lt;/p&gt;&lt;equation&gt;\displaystyle L_i=\sum_jmax(0,1-y_{ij}f_j)&lt;/equation&gt;&lt;br&gt;&lt;p&gt;上式中，求和是对所有分类&lt;equation&gt;j&lt;/equation&gt;，&lt;equation&gt;y_{ij}&lt;/equation&gt;的值为1或者-1，具体根据第i个样本是否被第j个属性打标签而定，当该类别被正确预测并展示的时候，分值向量&lt;equation&gt;f_j&lt;/equation&gt;为正，其余情况为负。可以发现，当一个正样本的得分小于+1，或者一个负样本得分大于-1的时候，算法就会累计损失值。&lt;/p&gt;&lt;p&gt;另一种方法是对每种属性训练一个独立的逻辑回归分类器。二分类的逻辑回归分类器只有两个分类（0，1），其中对于分类1的概率计算为：&lt;/p&gt;&lt;equation&gt;\displaystyle P(y=1|x;w,b)=\frac{1}{1+e^{-(w^Tx+b)}}=\sigma(w^Tx+b)&lt;/equation&gt;&lt;br&gt;&lt;p&gt;因为类别0和类别1的概率和为1，所以类别0的概率为：&lt;equation&gt;\displaystyle P(y=0|x;w,b)=1-P(y=1|x;w,b)&lt;/equation&gt;。这样，如果&lt;equation&gt;\sigma(w^Tx+b)&amp;gt;0.5&lt;/equation&gt;或者&lt;equation&gt;w^Tx+b&amp;gt;0&lt;/equation&gt;，那么样本就要被分类成为正样本（y=1）。然后损失函数最大化这个对数似然函数，问题可以简化为：&lt;/p&gt;&lt;equation&gt;\displaystyle L_i=\sum_jy_{ij}log(\sigma(f_j))+(1-y_{ij})log(1-\sigma(f_j))&lt;/equation&gt;&lt;br&gt;&lt;p&gt;上式中，假设标签&lt;equation&gt;y_{ij}&lt;/equation&gt;非0即1，&lt;equation&gt;\sigma(.)&lt;/equation&gt;就是sigmoid函数。上面的公式看起来吓人，但是&lt;equation&gt;f&lt;/equation&gt;的梯度实际上非常简单：&lt;equation&gt;\displaystyle \frac{\partial L_i}{\partial f_j}=y_{ij}-\sigma(f_j)&lt;/equation&gt;（你可以自己求导来验证）。&lt;/p&gt;&lt;p&gt;&lt;b&gt;回归问题&lt;/b&gt;是预测实数的值的问题，比如预测房价，预测图片中某个东西的长度等。对于这种问题，通常是计算预测值和真实值之间的损失。然后用L2平方范式或L1范式度量差异。对于某个样本，L2范式计算如下：&lt;/p&gt;&lt;equation&gt;L_i=||f-y_i||^2_2&lt;/equation&gt;&lt;br&gt;&lt;p&gt;之所以在目标函数中要进行平方，是因为梯度算起来更加简单。因为平方是一个单调运算，所以不用改变最优参数。L1范式则是要将每个维度上的绝对值加起来：&lt;br&gt;&lt;/p&gt;&lt;equation&gt;L_i=||f-y_i||_1=\sum_j|f_j-(y_i)_j|&lt;/equation&gt;&lt;br&gt;&lt;p&gt;在上式中，如果有多个数量被预测了，就要对预测的所有维度的预测求和，即&lt;equation&gt;\sum_j&lt;/equation&gt;。观察第i个样本的第j维，用&lt;equation&gt;\delta_{ij}&lt;/equation&gt;表示预测值与真实值之间的差异。关于该维度的梯度（也就是&lt;equation&gt;\partial L_i/\partial f_j&lt;/equation&gt;）能够轻松地通过被求导为L2范式的&lt;equation&gt;\delta_{ij}&lt;/equation&gt;或&lt;equation&gt;sign(\delta_{ij})&lt;/equation&gt;。这就是说，评分值的梯度要么与误差中的差值直接成比例，要么是固定的并从差值中继承sign。&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;em&gt;注意&lt;/em&gt;：L2损失比起较为稳定的Softmax损失来，其最优化过程要困难很多。直观而言，它需要网络具备一个特别的性质，即对于每个输入（和增量）都要输出一个确切的正确值。而在Softmax中就不是这样，每个评分的准确值并不是那么重要：只有当它们量级适当的时候，才有意义。还有，L2损失鲁棒性不好，因为异常值可以导致很大的梯度。所以在面对一个回归问题时，先考虑将输出变成二值化是否真的不够用。例如，如果对一个产品的星级进行预测，使用5个独立的分类器来对1-5星进行打分的效果一般比使用一个回归损失要好很多。分类还有一个额外优点，就是能给出关于回归的输出的分布，而不是一个简单的毫无把握的输出值。如果确信分类不适用，那么使用L2损失吧，但是一定要谨慎：L2非常脆弱，在网络中使用随机失活（尤其是在L2损失层的上一层）不是好主意。&lt;/p&gt;&lt;br&gt;&lt;blockquote&gt;&lt;p&gt;当面对一个回归任务，首先考虑是不是必须这样。一般而言，尽量把你的输出变成二分类，然后对它们进行分类，从而变成一个分类问题。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;strong&gt;结构化预测（s&lt;/strong&gt;&lt;strong&gt;tructured prediction&lt;/strong&gt;&lt;strong&gt;）。&lt;/strong&gt;结构化损失是指标签可以是任意的结构，例如图表、树或者其他复杂物体的情况。通常这种情况还会假设结构空间非常巨大，不容易进行遍历。结构化SVM背后的基本思想就是在正确的结构&lt;equation&gt;y_i&lt;/equation&gt;和得分最高的非正确结构之间画出一个边界。解决这类问题，并不是像解决一个简单无限制的最优化问题那样使用梯度下降就可以了，而是需要设计一些特殊的解决方案，这样可以有效利用对于结构空间的特殊简化假设。我们简要地提一下这个问题，但是详细内容就超出本课程范围。&lt;/p&gt;&lt;h2&gt;小结&lt;/h2&gt;&lt;p&gt;小结如下：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;推荐的预处理操作是对数据的每个特征都进行零中心化，然后将其数值范围都归一化到[-1,1]范围之内。&lt;/li&gt;&lt;li&gt;使用标准差为&lt;equation&gt;\sqrt{2/n}&lt;/equation&gt;的高斯分布来初始化权重，其中&lt;equation&gt;n&lt;/equation&gt;是输入的神经元数。例如用numpy可以写作：&lt;b&gt;w = np.random.randn(n) * sqrt(2.0/n)&lt;/b&gt;。&lt;/li&gt;&lt;li&gt;使用L2正则化和随机失活的倒置版本。&lt;/li&gt;&lt;li&gt;使用批量归一化。&lt;/li&gt;&lt;li&gt;讨论了在实践中可能要面对的不同任务，以及每个任务对应的常用损失函数。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;现在，我们预处理了数据，初始化了模型。在下一节中，我们将讨论算法的学习过程及其运作特性。&lt;/p&gt;&lt;h2&gt;译者反馈&lt;/h2&gt;&lt;ol&gt;&lt;li&gt;&lt;b&gt;转载须全文转载且注明原文链接&lt;/b&gt;，否则保留维权权利；&lt;/li&gt;&lt;li&gt;感谢知友@&lt;a href="https://www.zhihu.com/people/chen-di-cd" class="" data-editable="true" data-title="陈狄"&gt;陈狄&lt;/a&gt;和@&lt;a href="https://www.zhihu.com/people/han-jie-qun" class="" data-editable="true" data-title="韩劼群"&gt;韩劼群&lt;/a&gt;的建议，本系列对于&lt;b&gt;model ensemble&lt;/b&gt;将固定翻译为&lt;b&gt;模型集成&lt;/b&gt;；&lt;/li&gt;&lt;li&gt;感谢知友@&lt;a href="https://www.zhihu.com/people/clarkzdyhit" class="" data-editable="true" data-title="天堂之拳"&gt;天堂之拳&lt;/a&gt;的细致指正和讨论，本系列对于&lt;b&gt;pooling&lt;/b&gt;将固定翻译为&lt;b&gt;汇合；&lt;/b&gt;&lt;/li&gt;&lt;li&gt;感谢知友@&lt;a href="https://www.zhihu.com/people/chen-di-cd" class="" data-editable="true" data-title="陈狄"&gt;陈狄&lt;/a&gt;和@&lt;a href="https://www.zhihu.com/people/han-jie-qun" class="" data-editable="true" data-title="韩劼群"&gt;韩劼群&lt;/a&gt;的建议，本系列对于&lt;b&gt;dropout&lt;/b&gt;将固定翻译为&lt;b&gt;随机失活&lt;/b&gt;；&lt;/li&gt;&lt;li&gt;针对部分知友建议保留英文不做翻译的建议，请参考下方我的回复中关于Emil Cioran名句的引用，以及我的个人态度；&lt;/li&gt;&lt;li&gt;请知友们通过评论和私信等方式批评指正，贡献者均会补充提及。&lt;/li&gt;&lt;/ol&gt;</description><author>杜客</author><pubDate>Tue, 26 Jul 2016 17:19:34 GMT</pubDate></item><item><title>DQN从入门到放弃7  连续控制DQN算法-NAF</title><link>https://zhuanlan.zhihu.com/p/21609472</link><description>&lt;p&gt;&lt;img src="https://pic2.zhimg.com/178c11fcc99098e7fc039c8f7a96576d_r.png"&gt;&lt;/p&gt;&lt;h2&gt;1 前言&lt;/h2&gt;&lt;p&gt;在上一篇文章&lt;a href="https://zhuanlan.zhihu.com/p/21547911?refer=intelligentunit" class="" data-title="DQN从入门到放弃6 DQN的各种改进" data-editable="true"&gt;DQN从入门到放弃6 DQN的各种改进&lt;/a&gt;中，我们介绍了DQN的各个方面的改进。从各种改进的角度和思路很有利于我们思考如何去创新这个事情。那么，本着从入门到放弃的精神[呲牙]，在今天这篇文章中，我们还是来分析一下将DQN拓展到连续控制的算法------NAF。&lt;/p&gt;&lt;h2&gt;2 DQN算法用在连续控制上存在的问题&lt;/h2&gt;&lt;p&gt;从之前对DQN的分析，大家已经知道，DQN是一个面向离散控制的算法，也就是说输出的动作是离散的，不是连续的。这里也单独说一下离散控制和连续控制。这可以认为是增强学习任务的一种分类方法。那么一开始在没有引入深度学习的情况下，增强学习的任务基本是面向低维输入，低维输出的问题，因为高维的问题难度实在是太大，很难收敛。那么，DQN，引入了深度学习，使得输入可以拓展到高维空间，比如玩Atari，完全图像输入，维度是80x80=6400维，但是玩Atari的输出只是离散的键盘按键输出，比如Breakout这个游戏，也就是4个输出。而如果问题换成一个机械臂的控制呢？假设有6个关节，然后每个关节的扭矩输出是连续值，也就是在一个范围内任意取值，比如（-1，1）。那么，即使把每一个输出离散化，比如精度到0.01，那么一个动作有200个取值，那么6个关节也就是200的6次方个取值，这实在太多了。更何况如果进一步提升这个精度，那么取值的数量就成倍增加了。这就是连续控制比离散控制难得多的地方。将连续控制离散化也是完全不可取的做法&lt;/p&gt;&lt;p&gt;那么DQN为什么没办法直接用在连续控制上呢？原因很简单，DQN依靠计算每一个动作的Q值，然后选择最大的Q值对应的动作。那么这种方法在连续控制上完全不起作用。因为，根本就没办法穷举每一个动作，也就无法计算最大的Q值对应的动作。&lt;/p&gt;&lt;p&gt;所以，问题也就来了：&lt;/p&gt;&lt;blockquote&gt;&lt;b&gt;如何将DQN拓展成能够用在连续控制上的深度增强学习算法？&lt;br&gt;&lt;/b&gt;&lt;/blockquote&gt;&lt;h2&gt;3 Continuous Deep Q-Learning with NAF&lt;/h2&gt;&lt;blockquote&gt;&lt;a href="http://arxiv.org/abs/1603.00748" data-title="http://arxiv.org/abs/1603.00748
" class="" data-editable="true"&gt;http://arxiv.org/abs/1603.00748&lt;br&gt;&lt;/a&gt;&lt;/blockquote&gt;&lt;p&gt;在上面这篇Paper中，作者提出了一种idea来实现连续控制。基本思路是这样的：&lt;/p&gt;&lt;p&gt;&lt;b&gt;Step 1：在DQN的框架下，连续控制的输出需要满足什么条件？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;因为DQN是通过计算Q值的最大值来选择动作。那么对于连续控制，我们已经无法选择动作，我们只能设计一种方法，使得&lt;b&gt;我们输入状态，然后能够输出动作，并且保证输出动作对应的Q值是最大值。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;Step 2：又要输出动作，又要输出Q值？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;第一步的分析我们会发现一个两难的境地，就是我们输入状态，输出的时候，既要能输出动作，还要能输出Q值。那么这个时候，我们有两种选择，一种就是弄两个神经网络，一个是Policy网络，输入状态，输出动作，另一个是Q网络，输入状态，输出Q值。另外一种就是&lt;b&gt;弄一个神经网络，既输出动作，有能输出Q值&lt;/b&gt;。先说第一种做法。这种做法其实就是Actor-Critic算法的做法。这种做法需要能够构建一个能够更新Policy网络的方法。而DQN并没有提供更新Policy网络的方法。这使得我们要基于DQN做文章，只有一个办法，就是只弄一个神经网络，既能输出动作也能输出Q值。But，how？&lt;/p&gt;&lt;p&gt;&lt;b&gt;Step 3：如何构建神经网络，又能输出动作，也能输出Q值，而且动作对应的Q值最大？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这个问题确实是很困难的一个问题，很难直接就想出一个好的做法。虽然在Paper中作者其实只用了一段话来说明他们的方法，但是确实是很酷的idea。先提一下这些作者&lt;a href="http://arxiv.org/find/cs/1/au:+Gu_S/0/1/0/all/0/1" data-editable="true" data-title="Shixiang Gu"&gt;Shixiang Gu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Lillicrap_T/0/1/0/all/0/1" data-editable="true" data-title="Timothy Lillicrap"&gt;Timothy Lillicrap&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Sutskever_I/0/1/0/all/0/1" data-editable="true" data-title="Ilya Sutskever"&gt;Ilya Sutskever&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1" data-editable="true" data-title="Sergey Levine"&gt;Sergey Levine&lt;/a&gt; 后面两个都很牛。然后我们还是直接分析他们提出的方法吧！&lt;/p&gt;&lt;p&gt;&lt;img src="a09b42361028b98ff0a23789a6171567.png" data-rawwidth="2012" data-rawheight="1164"&gt;上图就是这个方法的示意图了。输入输出关系非常复杂。正常简单的Q网络就是200relu之后直接输出Q，但是这里经过很多复杂的步骤之后才输出Q。&lt;/p&gt;&lt;p&gt;基本的idea就是引入了Advantage，也就是每一个动作在特定状态下的优劣。我们不是要选最优的动作吗？其实就是要选Advantage最大的动作。Q,A(Advantage)和V(Value)的关系如下：&lt;/p&gt;&lt;equation&gt;Q(s,a) = A(s,a) + V(s)&lt;/equation&gt;&lt;br&gt;&lt;p&gt;所以，&lt;b&gt;核心idea来了&lt;/b&gt;：&lt;b&gt;如果我们能够限制A小于等于0，并且选择的动作对应的A为0&lt;/b&gt;，那么问题就解决了。要做到这点，一种简单的想法就是让&lt;/p&gt;&lt;p&gt;&lt;equation&gt;A(a) = -P(a-x)^2&lt;/equation&gt; P为正&lt;br&gt;&lt;/p&gt;&lt;p&gt;也就是二次方程取负。这个时候当a=x即选择的动作时为0.&lt;/p&gt;&lt;p&gt;那么具体构建当然是用矩阵的方式来构建。只是显然复杂的多。&lt;/p&gt;&lt;blockquote&gt;&lt;b&gt;state经过两个200层的神经网络（包含非线性）后分别构建三个分力的全连接层，输出Value，mu（动作）还有构建矩阵P所需的L0。也就是同时输出了价值还有动作&lt;/b&gt;&lt;/blockquote&gt;&lt;p&gt;那么最大的问题就是如何构造A的矩阵表示了。&lt;/p&gt;&lt;p&gt;&lt;img src="45e5b81e7f78dd9c3ddbf1be740606c1.png" data-rawwidth="1036" data-rawheight="126"&gt;上式是A的矩阵表示，也就是一个二次型。其中x是状态，u是动作，mu是神经网络的输出动作。&lt;/p&gt;&lt;p&gt;那么令&lt;equation&gt;z = u - \mu &lt;/equation&gt;,也就是&lt;/p&gt;&lt;equation&gt;A = -0.5z^TPz\leq 0&lt;/equation&gt;&lt;br&gt;&lt;p&gt;即&lt;/p&gt;&lt;equation&gt;z^TPz&amp;gt;0&lt;/equation&gt;&lt;br&gt;&lt;p&gt;要满足这个要求，P必须为正定矩阵。这本身也就是正定矩阵的定义。&lt;/p&gt;&lt;p&gt;接下来就是如何构造P的问题了。&lt;/p&gt;&lt;p&gt;这里作者竟然采用了乔列斯基（Cholesky）分解：&lt;/p&gt;&lt;blockquote&gt;若A为n阶对称正定矩阵，则存在唯一的主对角线元素都是正数的下三角阵L，使得&lt;equation&gt;A=LL^T&lt;/equation&gt;，此分解式称为 正定矩阵的乔列斯基（Cholesky）分解。&lt;/blockquote&gt;&lt;p&gt;也就是构造了一个对角线元素都是正数的下三角阵L，然后利用L构造P。&lt;/p&gt;&lt;p&gt;---------------------------------------------------------------------------------------&lt;/p&gt;&lt;p&gt;上面的分析确实是有点复杂。&lt;/p&gt;&lt;p&gt;那么我们再回到上面那个神经网络流程图来具体看看神经网络具体是怎么处理的？&lt;/p&gt;&lt;p&gt;1）State，维度是输入维度state_dim&lt;/p&gt;&lt;p&gt;2) 经过两个200的RELU全连接层&lt;/p&gt;&lt;p&gt;3）输出V，维度为1&lt;/p&gt;&lt;p&gt;4）输出mu（动作），维度为动作的维度action_dim&lt;/p&gt;&lt;p&gt;5）输出L0,维度为（action_dim)x(action_dim+1)/2，也就是构造下三角矩阵L所需要的维度&lt;/p&gt;&lt;p&gt;6）构造L。将L0转化为L.也就是将一个列向量转换为下三角矩阵，就是从新排列，然后把对角线的数exp对数化。&lt;/p&gt;&lt;p&gt;7）根据L构造P。&lt;/p&gt;&lt;p&gt;8）根据mu，P，action构造A&lt;/p&gt;&lt;p&gt;9）根据A和V构造Q，也就是Q=A+V&lt;/p&gt;&lt;p&gt;综上，最终输出Q，并且可以根据DQN的方法进行梯度下降。&lt;/p&gt;&lt;p&gt;&lt;img src="a9a5bf66e222fda74e9e0e700ff3881c.png" data-rawwidth="1068" data-rawheight="952"&gt;以上就是这个算法的整个过程。&lt;/p&gt;&lt;h2&gt;3 小结&lt;/h2&gt;&lt;p&gt;这个算法确实设计精美，但实现起来其实蛮复杂。未来需要有更多的改进！&lt;/p&gt;</description><author>Flood Sung</author><pubDate>Fri, 15 Jul 2016 23:38:37 GMT</pubDate></item><item><title>CS231n课程笔记翻译：神经网络笔记1（下）</title><link>https://zhuanlan.zhihu.com/p/21513367</link><description>&lt;p&gt;&lt;img src="https://pic2.zhimg.com/421c2492bfe445a3b7e92e18ced0e8dd_r.jpg"&gt;&lt;/p&gt;译者注：本文&lt;a href="https://zhuanlan.zhihu.com/intelligentunit" data-editable="true" data-title="智能单元" class=""&gt;智能单元&lt;/a&gt;首发，译自斯坦福CS231n课程笔记&lt;a href="http://cs231n.github.io/neural-networks-1/" class="" data-editable="true" data-title="Neural Nets notes 1"&gt;Neural Nets notes 1&lt;/a&gt;，课程教师&lt;a href="https://link.zhihu.com/?target=http%3A//cs.stanford.edu/people/karpathy/" class="" data-editable="true" data-title="Andrej Karpathy"&gt;Andrej Karpathy&lt;/a&gt;授权翻译。本篇教程由&lt;a href="https://www.zhihu.com/people/du-ke" class="" data-editable="true" data-title="杜客"&gt;杜客&lt;/a&gt;翻译完成，&lt;a href="https://www.zhihu.com/people/li-yi-ying-73" class="" data-editable="true" data-title="李艺颖"&gt;李艺颖&lt;/a&gt;和&lt;a href="https://www.zhihu.com/people/kun-kun-97-81" class="" data-editable="true" data-title="堃堃"&gt;堃堃&lt;/a&gt;进行校对修改。译文含公式和代码，建议PC端阅读。&lt;h2&gt;原文如下&lt;/h2&gt;&lt;p&gt;内容列表：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;不用大脑做类比的快速简介&lt;/li&gt;&lt;li&gt;单个神经元建模&lt;ul&gt;&lt;li&gt;生物动机和连接&lt;/li&gt;&lt;li&gt;作为线性分类器的单个神经元&lt;/li&gt;&lt;li&gt;常用的激活函数 &lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;神经网络结构 &lt;i&gt;&lt;b&gt;译者注：下篇翻译起始处&lt;/b&gt;&lt;/i&gt;&lt;ul&gt;&lt;li&gt;层组织&lt;/li&gt;&lt;li&gt;前向传播计算例子&lt;/li&gt;&lt;li&gt;表达能力&lt;/li&gt;&lt;li&gt;设置层的数量和尺寸&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;小节&lt;/li&gt;&lt;li&gt;参考文献&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;神经网络结构&lt;/h2&gt;&lt;h2&gt;灵活地组织层&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;将神经网络算法以神经元的形式图形化。&lt;/strong&gt;神经网络被建模成神经元的集合，神经元之间以无环图的形式进行连接。也就是说，一些神经元的输出是另一些神经元的输入。在网络中是不允许循环的，因为这样会导致前向传播的无限循环。通常神经网络模型中神经元是分层的，而不是像生物神经元一样聚合成大小不一的团状。对于普通神经网络，最普通的层的类型是&lt;strong&gt;全连接层（&lt;/strong&gt;&lt;b&gt;fully-connected
layer&lt;/b&gt;&lt;strong&gt;）&lt;/strong&gt;。全连接层中的神经元与其前后两层的神经元是完全成对连接的，但是在同一个全连接层内的神经元之间没有连接。下面是两个神经网络的图例，都使用的全连接层：&lt;/p&gt;&lt;p&gt;————————————————————————————————————————&lt;/p&gt;&lt;p&gt;&lt;img src="ccb56c1fb267bc632d6d88459eb14ace.png" data-rawwidth="1542" data-rawheight="456"&gt;左边是一个2层神经网络，隐层由4个神经元（也可称为单元（unit））组成，输出层由2个神经元组成，输入层是3个神经元。右边是一个3层神经网络，两个含4个神经元的隐层。注意：层与层之间的神经元是全连接的，但是层内的神经元不连接。&lt;br&gt;&lt;/p&gt;&lt;p&gt;————————————————————————————————————————&lt;/p&gt;&lt;p&gt;&lt;strong&gt;命名规则。&lt;/strong&gt;当我们说N层神经网络的时候，我们没有把输入层算入。因此，单层的神经网络就是没有隐层的（输入直接映射到输出）。因此，有的研究者会说逻辑回归或者SVM只是单层神经网络的一个特例。研究者们也会使用&lt;i&gt;人工神经网络（&lt;/i&gt;Artificial Neural
Networks &lt;i&gt;缩写ANN）&lt;/i&gt;或者&lt;i&gt;多层感知器（&lt;/i&gt;Multi-Layer Perceptrons &lt;i&gt;缩写&lt;/i&gt;&lt;i&gt;MLP）&lt;/i&gt;来指代神经网络。很多研究者并不喜欢神经网络算法和人类大脑之间的类比，他们更倾向于用&lt;i&gt;单元（unit）&lt;/i&gt;而不是神经元作为术语。&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;strong&gt;输出层。&lt;/strong&gt;和神经网络中其他层不同，输出层的神经元一般是不会有激活函数的（或者也可以认为它们有一个线性相等的激活函数）。这是因为最后的输出层大多用于表示分类评分值，因此是任意值的实数，或者某种实数值的目标数（比如在回归中）。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;确定网络尺寸。&lt;/strong&gt;用来度量神经网络的尺寸的标准主要有两个：一个是神经元的个数，另一个是参数的个数，用上面图示的两个网络举例：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;第一个网络有4+2=6个神经元（输入层不算），[3x4]+[4x2]=20个权重，还有4+2=6个偏置，共26个可学习的参数。&lt;/li&gt;&lt;li&gt;第二个网络有4+4+1=9个神经元，[3x4]+[4x4]+[4x1]=32个权重，4+4+1=9个偏置，共41个可学习的参数。 &lt;/li&gt;&lt;/ul&gt;&lt;br&gt;&lt;p&gt;为了方便对比，现代卷积神经网络能包含约1亿个参数，可由10-20层构成（这就是深度学习）。然而，&lt;i&gt;有效（effective）&lt;/i&gt;连接的个数因为参数共享的缘故大大增多。在后面的卷积神经网络内容中我们将学习更多。&lt;/p&gt;&lt;h2&gt;前向传播计算举例&lt;/h2&gt;&lt;p&gt;&lt;em&gt;不断重复的矩阵乘法与激活函数交织&lt;/em&gt;。将神经网络组织成层状的一个主要原因，就是这个结构让神经网络算法使用矩阵向量操作变得简单和高效。用上面那个3层神经网络举例，输入是[3x1]的向量。一个层所有连接的强度可以存在一个单独的矩阵中。比如第一个隐层的权重&lt;b&gt;W1&lt;/b&gt;是[4x3]，所有单元的偏置储存在&lt;b&gt;b1&lt;/b&gt;中，尺寸[4x1]。这样，每个神经元的权重都在&lt;b&gt;W1&lt;/b&gt;的一个行中，于是矩阵乘法&lt;b&gt;np.dot(W1, x)&lt;/b&gt;就能计算该层中所有神经元的激活数据。类似的，&lt;b&gt;W2&lt;/b&gt;将会是[4x4]矩阵，存储着第二个隐层的连接，&lt;b&gt;W3&lt;/b&gt;是[1x4]的矩阵，用于输出层。完整的3层神经网络的前向传播就是简单的3次矩阵乘法，其中交织着激活函数的应用。&lt;br&gt;&lt;/p&gt;&lt;code lang="python"&gt;# 一个3层神经网络的前向传播:
f = lambda x: 1.0/(1.0 + np.exp(-x)) # 激活函数(用的sigmoid)
x = np.random.randn(3, 1) # 含3个数字的随机输入向量(3x1)
h1 = f(np.dot(W1, x) + b1) # 计算第一个隐层的激活数据(4x1)
h2 = f(np.dot(W2, h1) + b2) # 计算第二个隐层的激活数据(4x1)
out = np.dot(W3, h2) + b3 # 神经元输出(1x1)
&lt;/code&gt;&lt;p&gt;在上面的代码中，&lt;b&gt;W1，W2，W3，b1，b2，b3&lt;/b&gt;都是网络中可以学习的参数。注意&lt;b&gt;x&lt;/b&gt;并不是一个单独的列向量，而可以是一个批量的训练数据（其中每个输入样本将会是&lt;b&gt;x&lt;/b&gt;中的一列），所有的样本将会被并行化的高效计算出来。注意神经网络最后一层通常是没有激活函数的（例如，在分类任务中它给出一个实数值的分类评分）。&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;全连接层的前向传播一般就是先进行一个矩阵乘法，然后加上偏置并运用激活函数。&lt;br&gt;&lt;/blockquote&gt;&lt;h2&gt;表达能力&lt;/h2&gt;&lt;p&gt;理解具有全连接层的神经网络的一个方式是：可以认为它们定义了一个由一系列函数组成的函数族，网络的权重就是每个函数的参数。如此产生的问题是：该函数族的表达能力如何？存在不能被神经网络表达的函数吗？&lt;/p&gt;&lt;p&gt;现在看来，拥有至少一个隐层的神经网络是一个&lt;em&gt;通用的近似器&lt;/em&gt;。在研究（例如1989年的论文&lt;a href="http://www.dartmouth.edu/%7Egvc/Cybenko_MCSS.pdf" data-title="Approximation by Superpositions of Sigmoidal Function" class="" data-editable="true"&gt;Approximation by Superpositions of Sigmoidal Function&lt;/a&gt;，或者&lt;a href="http://neuralnetworksanddeeplearning.com/chap4.html" data-editable="true" data-title="Michael Nielsen"&gt;Michael Nielsen&lt;/a&gt;的这个直观解释。）中已经证明，给出任意连续函数&lt;equation&gt;f(x)&lt;/equation&gt;和任意&lt;equation&gt;\epsilon &amp;gt;0&lt;/equation&gt;，均存在一个至少含1个隐层的神经网络&lt;equation&gt;g(x)&lt;/equation&gt;（并且网络中有合理选择的非线性激活函数，比如sigmoid），对于&lt;equation&gt;\forall x&lt;/equation&gt;，使得&lt;equation&gt;|f(x)-g(x)|&amp;lt;\epsilon&lt;/equation&gt;。换句话说，神经网络可以近似任何连续函数。&lt;/p&gt;&lt;br&gt;&lt;p&gt;既然一个隐层就能近似任何函数，那为什么还要构建更多层来将网络做得更深？答案是：虽然一个2层网络在数学理论上能完美地近似所有连续函数，但在实际操作中效果相对较差。在一个维度上，虽然以&lt;equation&gt;a,b,c&lt;/equation&gt;为参数向量“指示块之和”函数&lt;equation&gt;g(x)=\sum_ic_i1(a_i&amp;lt;x&amp;lt;b_i) &lt;/equation&gt;也是通用的近似器，但是谁也不会建议在机器学习中使用这个函数公式。神经网络在实践中非常好用，是因为它们表达出的函数不仅平滑，而且对于数据的统计特性有很好的拟合。同时，网络通过最优化算法（例如梯度下降）能比较容易地学习到这个函数。类似的，虽然在理论上深层网络（使用了多个隐层）和单层网络的表达能力是一样的，但是就实践经验而言，深度网络效果比单层网络好。&lt;/p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;另外，在实践中3层的神经网络会比2层的表现好，然而继续加深（做到4，5，6层）很少有太大帮助。卷积神经网络的情况却不同，在卷积神经网络中，对于一个良好的识别系统来说，深度是一个极端重要的因素（比如数十(以10为量级)个可学习的层）。对于该现象的一种解释观点是：因为图像拥有层次化结构（比如脸是由眼睛等组成，眼睛又是由边缘组成），所以多层处理对于这种数据就有直观意义。&lt;/p&gt;&lt;br&gt;&lt;p&gt;全面的研究内容还很多，近期研究的进展也很多。如果你对此感兴趣，我么推荐你阅读下面文献：&lt;/p&gt;&lt;br&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="http://www.deeplearningbook.org/" data-editable="true" data-title="Deep Learning" class=""&gt;Deep Learning&lt;/a&gt;的&lt;a href="http://www.deeplearningbook.org/contents/mlp.html" data-editable="true" data-title="Chapter6.4" class=""&gt;Chapter6.4&lt;/a&gt;，作者是Bengio等。&lt;/li&gt;&lt;li&gt;&lt;a href="http://arxiv.org/abs/1312.6184" data-editable="true" data-title="Do Deep Nets Really Need to be Deep?" class=""&gt;Do Deep Nets Really Need to be Deep?&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="http://arxiv.org/abs/1412.6550" data-editable="true" data-title="FitNets: Hints for Thin Deep Nets" class=""&gt;FitNets: Hints for Thin Deep Nets&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;设置层的数量和尺寸&lt;/h2&gt;&lt;p&gt;在面对一个具体问题的时候该确定网络结构呢？到底是不用隐层呢？还是一个隐层？两个隐层或更多？每个层的尺寸该多大？&lt;/p&gt;&lt;p&gt;首先，要知道当我们增加层的数量和尺寸时，网络的容量上升了。即神经元们可以合作表达许多复杂函数，所以表达函数的空间增加。例如，如果有一个在二维平面上的二分类问题。我们可以训练3个不同的神经网络，每个网络都只有一个隐层，但是每层的神经元数目不同：&lt;/p&gt;&lt;br&gt;&lt;p&gt;————————————————————————————————————————&lt;/p&gt;&lt;p&gt;&lt;img src="cf3fc543bf1dc81e2083530a4492b0ec.png" data-rawwidth="1568" data-rawheight="560"&gt;更大的神经网络可以表达更复杂的函数。数据是用不同颜色的圆点表示他们的不同类别，决策边界是由训练过的神经网络做出的。你可以在&lt;a href="http://cs.stanford.edu/people/karpathy/convnetjs/demo/classify2d.html" data-editable="true" data-title="ConvNetsJS demo" class=""&gt;ConvNetsJS demo&lt;/a&gt;上练练手。&lt;/p&gt;&lt;p&gt;————————————————————————————————————————&lt;/p&gt;&lt;p&gt;在上图中，可以看见有更多神经元的神经网络可以表达更复杂的函数。然而这既是优势也是不足，优势是可以分类更复杂的数据，不足是可能造成对训练数据的过拟合。&lt;strong&gt;过拟合&lt;/strong&gt;&lt;b&gt;（Overfitting）&lt;/b&gt;是网络对数据中的噪声有很强的拟合能力，而没有重视数据间（假设）的潜在基本关系。举例来说，有20个神经元隐层的网络拟合了所有的训练数据，但是其代价是把决策边界变成了许多不相连的红绿区域。而有3个神经元的模型的表达能力只能用比较宽泛的方式去分类数据。它将数据看做是两个大块，并把个别在绿色区域内的红色点看做噪声。在实际中，这样可以在测试数据中获得更好的&lt;b&gt;泛&lt;/b&gt;&lt;strong&gt;化（generalization）&lt;/strong&gt;能力。&lt;/p&gt;&lt;br&gt;&lt;p&gt;基于上面的讨论，看起来如果数据不是足够复杂，则似乎小一点的网络更好，因为可以防止过拟合。然而并非如此，防止神经网络的过拟合有很多方法（L2正则化，dropout和输入噪音等），后面会详细讨论。在实践中，使用这些方法来控制过拟合比减少网络神经元数目要好得多。&lt;/p&gt;&lt;p&gt;不要减少网络神经元数目的主要原因在于小网络更难使用梯度下降等局部方法来进行训练：虽然小型网络的损失函数的局部极小值更少，也比较容易收敛到这些局部极小值，但是这些最小值一般都很差，损失值很高。相反，大网络拥有更多的局部极小值，但就实际损失值来看，这些局部极小值表现更好，损失更小。因为神经网络是非凸的，就很难从数学上研究这些特性。即便如此，还是有一些文章尝试对这些目标函数进行理解，例如&lt;a href="http://arxiv.org/abs/1412.0233" data-editable="true" data-title="The Loss Surfaces of Multilayer Networks" class=""&gt;The Loss Surfaces of Multilayer Networks&lt;/a&gt;这篇论文。在实际中，你将发现如果训练的是一个小网络，那么最终的损失值将展现出多变性：某些情况下运气好会收敛到一个好的地方，某些情况下就收敛到一个不好的极值。从另一方面来说，如果你训练一个大的网络，你将发现许多不同的解决方法，但是最终损失值的差异将会小很多。这就是说，所有的解决办法都差不多，而且对于随机初始化参数好坏的依赖也会小很多。&lt;/p&gt;&lt;p&gt;重申一下，正则化强度是控制神经网络过拟合的好方法。看下图结果：&lt;/p&gt;&lt;p&gt;————————————————————————————————————————&lt;/p&gt;&lt;p&gt;&lt;img src="4f8af027d6059549d160199a1717df14.png" data-rawwidth="1562" data-rawheight="580"&gt;不同正则化强度的效果：每个神经网络都有20个隐层神经元，但是随着正则化强度增加，它的决策边界变得更加平滑。你可以在&lt;a href="http://cs.stanford.edu/people/karpathy/convnetjs/demo/classify2d.html" data-editable="true" data-title="ConvNetsJS demo" class=""&gt;ConvNetsJS demo&lt;/a&gt;上练练手。&lt;br&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;————————————————————————————————————————&lt;/p&gt;&lt;p&gt;需要记住的是：不应该因为害怕出现过拟合而使用小网络。相反，应该进尽可能使用大网络，然后使用正则化技巧来控制过拟合。&lt;br&gt;&lt;/p&gt;&lt;h1&gt;小结&lt;/h1&gt;&lt;p&gt;小结如下：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;介绍了生物神经元的粗略模型；&lt;/li&gt;&lt;li&gt;讨论了几种不同类型的激活函数，其中ReLU是最佳推荐；&lt;/li&gt;&lt;li&gt;介绍了&lt;strong&gt;神经网络&lt;/strong&gt;，神经元通过&lt;strong&gt;全连接层&lt;/strong&gt;连接，层间神经元两两相连，但是层内神经元不连接；&lt;/li&gt;&lt;li&gt;理解了分层的结构能够让神经网络高效地进行矩阵乘法和激活函数运算；&lt;/li&gt;&lt;li&gt;理解了神经网络是一个&lt;strong&gt;通用函数近似器&lt;/strong&gt;，但是该性质与其广泛使用无太大关系。之所以使用神经网络，是因为它们对于实际问题中的函数的公式能够某种程度上做出“正确”假设。&lt;/li&gt;&lt;li&gt;&lt;p&gt;讨论了更大网络总是更好的这一事实。然而更大容量的模型一定要和更强的正则化（比如更高的权重衰减）配合，否则它们就会过拟合。在后续章节中我们讲学习更多正则化的方法，尤其是dropout。&lt;/p&gt;&lt;h1&gt;参考资料&lt;/h1&gt;&lt;/li&gt;&lt;li&gt;使用Theano的&lt;a href="http://www.deeplearning.net/tutorial/mlp.html" data-editable="true" data-title="deeplearning.net tutorial" class=""&gt;deeplearning.net tutorial&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="http://www.deeplearning.net/tutorial/mlp.html" data-editable="true" data-title="ConvNetJS"&gt;ConvNetJS&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="http://neuralnetworksanddeeplearning.com/chap1.html" data-editable="true" data-title="Michael Nielsen's tutorials"&gt;Michael Nielsen's tutorials&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;译者反馈&lt;/h2&gt;&lt;ol&gt;&lt;li&gt;&lt;b&gt;转载须全文转载且注明原文链接&lt;/b&gt;，否则保留维权权利；&lt;/li&gt;&lt;li&gt;请知友们通过评论和私信等方式批评指正，贡献者均会补充提及。&lt;/li&gt;&lt;/ol&gt;</description><author>杜客</author><pubDate>Sun, 10 Jul 2016 17:33:42 GMT</pubDate></item><item><title>DQN从入门到放弃6 DQN的各种改进</title><link>https://zhuanlan.zhihu.com/p/21547911</link><description>&lt;p&gt;&lt;img src="https://pic2.zhimg.com/178c11fcc99098e7fc039c8f7a96576d_r.png"&gt;&lt;/p&gt;&lt;h2&gt;1 前言&lt;/h2&gt;&lt;p&gt;在上一篇文章&lt;a href="https://zhuanlan.zhihu.com/p/21421729?refer=intelligentunit" class="" data-editable="true" data-title="DQN从入门到放弃5 深度解读DQN算法"&gt;DQN从入门到放弃5 深度解读DQN算法&lt;/a&gt;中，我们深入地介绍了基本的DQN算法，也就是NIPS 2013版本的算法。那么在这之后，DeepMind不断对DQN进行改进，首先在2015年初发布了Nature文章，提出了Nature版本的DQN，然后接下来在2015年一年内提出了Double DQN，Prioritied Replay，还有Dueling Network三种主要方法，又极大的提升了DQN的性能，目前的改进型DQN算法在Atari游戏的平均得分是Nature版DQN的三倍之多。因此，在本文中，我们将介绍一下各个改进的方法。&lt;/p&gt;&lt;h2&gt;2 Nature DQN&lt;/h2&gt;&lt;p&gt;NIPS DQN在基本的Deep Q-Learning算法的基础上使用了Experience Replay经验池。通过将训练得到的数据储存起来然后随机采样的方法降低了数据样本的相关性。提升了性能。接下来，Nature DQN做了一个改进，就是增加Target Q网络。也就是我们在计算目标Q值时使用专门的一个目标Q网络来计算，而不是直接使用预更新的Q网络。这样做的目的是为了减少目标计算与当前值的相关性。&lt;/p&gt;&lt;p&gt;&lt;img src="741e46913effd4d0821ff57b54ff5580.png" data-rawwidth="1502" data-rawheight="224"&gt;如上面的损失函数公式所示，计算目标Q值的网络使用的参数是w-，而不是w。就是说，原来NIPS版本的DQN目标Q网络是动态变化的，跟着Q网络的更新而变化，这样不利于计算目标Q值，导致目标Q值和当前的Q值相关性较大。因此提出单独使用一个目标Q网络。那么目标Q网络的参数如何来呢？还是从Q网络中来，只不过是延迟更新。也就是每次等训练了一段时间再将当前Q网络的参数值复制给目标Q网络。&lt;/p&gt;&lt;p&gt;这个做的效果还是很明显的，效果见下表（引用自Nature 论文）：&lt;/p&gt;&lt;p&gt;&lt;img src="bc99f61adeb19a7343d70ce6015e303f.png" data-rawwidth="1300" data-rawheight="360"&gt;这就是Nature DQN的改进。&lt;/p&gt;&lt;h2&gt;3 DQN有什么问题？还可以如何改进？&lt;/h2&gt;&lt;p&gt;在Nature DQN出来之后，肯定很多人在思考如何改进它。那么DQN有什么问题呢？&lt;/p&gt;&lt;ul&gt;&lt;li&gt;目标Q值的计算准确吗？全部通过max Q来计算有没有问题？&lt;/li&gt;&lt;li&gt;随机采样的方法好吗？按道理不同样本的重要性是不一样的&lt;/li&gt;&lt;li&gt;Q值代表状态，动作的价值，那么单独动作价值的评估会不会更准确？&lt;/li&gt;&lt;li&gt;DQN中使用&lt;equation&gt;\epsilon-greedy&lt;/equation&gt;的方法来探索状态空间，有没有更好的做法？&lt;/li&gt;&lt;li&gt;使用卷积神经网络的结构是否有局限？加入RNN呢？&lt;/li&gt;&lt;li&gt;DQN无法解决一些高难度的Atari游戏比如Montezuma's Revenge，如何处理这些游戏？&lt;/li&gt;&lt;li&gt;DQN训练时间太慢了，跑一个游戏要好几天，有没有办法更快？&lt;/li&gt;&lt;li&gt;DQN训练是单独的，也就是一个游戏弄一个网络进行训练，有没有办法弄一个网络同时掌握多个游戏，或者训练某一个游戏后将知识迁移到新的游戏？&lt;/li&gt;&lt;li&gt;DQN能否用在连续动作输出问题？&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;那么现在的事实发现DeepMind确实在思考解决上面的几个问题，并且基本上每一个问题都有一定的解决方法。下面罗列一下各个问题的解决文章：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;改进目标Q值计算：&lt;a href="http://arxiv.org/abs/1509.06461" class="" data-title="Deep Reinforcement Learning with Double Q-learning" data-editable="true"&gt;Deep Reinforcement Learning with Double Q-learning&lt;/a&gt;&lt;/li&gt;&lt;li&gt;改进随机采样：&lt;a href="http://arxiv.org/abs/1511.05952" class="" data-title="Prioritized Experience Replay" data-editable="true"&gt;Prioritized Experience Replay&lt;/a&gt;&lt;/li&gt;&lt;li&gt;改进网络结构，评估单独动作价值：&lt;a href="http://arxiv.org/abs/1511.06581" class="" data-editable="true" data-title="Dueling Network Architectures for Deep Reinforcement Learning"&gt;Dueling Network Architectures for Deep Reinforcement Learning&lt;/a&gt; ( 本文为ICML最佳论文之一）&lt;/li&gt;&lt;li&gt;改进探索状态空间方式：（1）&lt;a href="http://arxiv.org/abs/1602.04621" class="" data-editable="true" data-title="Deep Exploration via Bootstrapped DQN"&gt;Deep Exploration via Bootstrapped DQN&lt;/a&gt;  （2）&lt;a href="http://arxiv.org/abs/1507.00814" class="" data-title="Incentivizing Exploration In Reinforcement Learning With Deep Predictive Models" data-editable="true"&gt;Incentivizing Exploration In Reinforcement Learning With Deep Predictive Models&lt;/a&gt;&lt;/li&gt;&lt;li&gt;改变网络结构，增加RNN：&lt;a href="http://arxiv.org/abs/1507.06527" class="" data-title="Deep Recurrent Q-Learning for Partially Observable MDPs" data-editable="true"&gt;Deep Recurrent Q-Learning for Partially Observable MDPs&lt;/a&gt;（非DeepMind出品，效果很一般，谈不上改进，本文也不考虑讲解）&lt;/li&gt;&lt;li&gt;实现DQN训练的迁移学习：（1）&lt;a href="http://arxiv.org/abs/1511.06295" class="" data-editable="true" data-title="Policy Distillation"&gt;Policy Distillation&lt;/a&gt;  （2） &lt;a href="https://arxiv.org/abs/1511.06342" class="" data-title="Actor-Mimic: Deep Multitask and Transfer Reinforcement Learning" data-editable="true"&gt;Actor-Mimic: Deep Multitask and Transfer Reinforcement Learning&lt;/a&gt;&lt;/li&gt;&lt;li&gt;解决高难度游戏Montezuma‘s Revenge：&lt;a href="https://arxiv.org/abs/1606.01868" class="" data-editable="true" data-title="Unifying Count-Based Exploration and Intrinsic Motivation"&gt;Unifying Count-Based Exploration and Intrinsic Motivation&lt;/a&gt;&lt;/li&gt;&lt;li&gt;加快DQN训练速度：&lt;a href="https://arxiv.org/abs/1602.01783" class="" data-editable="true" data-title="Asynchronous Methods for Deep Reinforcement Learning"&gt;Asynchronous Methods for Deep Reinforcement Learning&lt;/a&gt; （这篇文章还引出了可以替代DQN的A3C算法，效果4倍Nature DQN）&lt;/li&gt;&lt;li&gt;改变DQN使之能够应用在连续控制上面：&lt;a href="http://arxiv.org/abs/1603.00748" class="" data-editable="true" data-title="Continuous Deep Q-Learning with Model-based Acceleration"&gt;Continuous Deep Q-Learning with Model-based Acceleration&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;除了上面的问题，其他的就是将DQN应用到其他领域比如文字理解，目标定位等等，也就是DQN的拓展研究，这里就不罗列相关文章了。上面的这些成果基本出自DeepMind之手，只有一两篇出自其他大牛，比如&lt;a href="http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1" data-editable="true" data-title="Pieter Abbeel" class=""&gt;Pieter Abbeel&lt;/a&gt;，&lt;a href="https://arxiv.org/find/cs/1/au:+Salakhutdinov_R/0/1/0/all/0/1" data-editable="true" data-title="Ruslan Salakhutdinov" class=""&gt;Ruslan Salakhutdinov&lt;/a&gt;。&lt;/p&gt;&lt;h2&gt;4 Double DQN，Prioritised Replay，Dueling Network三大改进&lt;/h2&gt;&lt;p&gt;大幅度提升DQN玩Atari性能的主要就是Double DQN，Prioritised Replay还有Dueling Network三大方法。&lt;/p&gt;&lt;p&gt;David Silver在ICML 2016中的Tutorial上做了介绍：&lt;a href="https://link.zhihu.com/?target=http%3A//icml.cc/2016/tutorials/deep_rl_tutorial.pdf" class="" data-editable="true" data-title="深度增强学习Tutorial"&gt;深度增强学习Tutorial&lt;/a&gt; 下图引用其PPT：&lt;br&gt;&lt;img src="37e899a561b4e7fcfee04fc75744f319.png" data-rawwidth="1512" data-rawheight="1042"&gt;简单说明一下：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Double DQN：目的是减少因为max Q值计算带来的计算偏差，或者称为过度估计（over estimation）问题，用当前的Q网络来选择动作，用目标Q网络来计算目标Q。&lt;/li&gt;&lt;li&gt;Prioritised  replay：也就是优先经验的意思。优先级采用目标Q值与当前Q值的差值来表示。优先级高，那么采样的概率就高。&lt;/li&gt;&lt;li&gt;Dueling Network：将Q网络分成两个通道，一个输出V，一个输出A，最后再合起来得到Q。如下图所示（引用自Dueling Network论文）。这个方法主要是idea很简单但是很难想到，然后效果一级棒，因此也成为了ICML的best paper。&lt;img src="287cb3ac0fc93e4c6573617bc46cbda4.png" data-rawwidth="200" data-rawheight="226"&gt;&lt;br&gt;&lt;/li&gt;&lt;/ul&gt;&lt;br&gt;&lt;h2&gt;5 小结&lt;/h2&gt;&lt;p&gt;本文为大家分享了DQN之后的各种改进，简单介绍了Double DQN，Prioritised replay，Dueling Network的方法。由于到这个程度需要阅读的论文的量就比较大了，所以也想&lt;b&gt;听听知友们的意见&lt;/b&gt;。如果有很多知友到了这里，那么接下来我会继续分析一些DQN相关的改进，要不然DQN 从入门到放弃系列也将到此为止了，虽然我们的实战篇部分还会继续跟大家分享如何实打实的实现算法。接下来，我们将进入深度增强学习的另外一种解决方法：Policy Gradient策略梯度方法的分析，感谢大家的关注！&lt;/p&gt;&lt;h2&gt;本文为原创文章，未经作者允许不得转载！&lt;/h2&gt;</description><author>Flood Sung</author><pubDate>Sun, 10 Jul 2016 17:00:10 GMT</pubDate></item></channel></rss>