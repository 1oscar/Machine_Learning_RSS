<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>

机器学习
 - 知乎收藏夹</title><link>https://www.zhihu.com/collection/113183484</link><description>每天整理和机器学习有关的优质回答</description><lastBuildDate>Tue, 20 Sep 2016 04:01:54 GMT</lastBuildDate><generator>Ricky</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>如何看待国人的论文SARM作者将论文从nips撤稿？</title><link>https://www.zhihu.com/question/50508148/answer/121407287</link><description>&lt;div class="zm-editable-content"&gt;&lt;a href="//link.zhihu.com/?target=https%3A//www.reddit.com/r/MachineLearning/comments/51ut79/sarm_stacked_approximated_regression_machine/" class=" wrap external" target="_blank" rel="nofollow noreferrer"&gt;SARM (Stacked Approximated Regression Machine) withdrawn : MachineLearning&lt;i class="icon-external"&gt;&lt;/i&gt;&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;已经传疯了，大家都说这是scandal.&lt;/div&gt;&lt;div class="zm-editable-content clearfix"&gt;
谢邀，这件事情，我觉得本人的动机如何，估计谁也无法知道，但是我们可以探讨一下从中可以学习到什么教训。Reddit上的讨论很好，有兴趣的同学可以看看。&lt;br&gt;&lt;br&gt;首先，如果这篇文章的确是真实的话，那的确是深度学习领域的一大突破。从LeNet以来，supervised sgd training一直是保证实验效果的必要途径，而这篇文章说明，unsupervisee layer-by-layer pretraining，直接类似k-svd或者OMP这样的算法就可以达到非常好的效果，这几乎颠覆了我们以前对于深度学习“需要大量训练数据”的认知。&lt;br&gt;&lt;br&gt;同时，这篇文章的一个疑点也是很显然的：自从Olshausen提出sparse coding以来，有无数的工作试图将类sparse coding（包括OMP，ISTA这样的相关算法）应用到多于一层的情况中去。但是，这些工作都失败了 - 这篇文章似乎没有提出什么新的算法，但是为什么能达到那么好的效果呢？&lt;br&gt;&lt;br&gt;大家都倾向于相信Tom组的这个工作，因为Tom组以前有很不错的sparse coding论文，比如说Jianchao Yang的ScSPM。但是，根据Reddit上复现的结果来看，作者似乎使用了测试集数据来做参数训练和选择（具体的方法还未知，作者目前的声明中也语焉不详）。在机器学习中，这应该是一个初学研究生就应该学习到的标准：测试集不能被用来做任何训练相关的调参，如果需要调参的话，应该在验证集（validation set）上做，或者在训练集上做k-fold cross validation。&lt;br&gt;&lt;br&gt;所以，作者很显然犯了一个非常低级的错误，或者有意隐瞒了这个细节 - 我倾向于相信后者，因为很多证据表明，原文中的很多claim，比如说训练时间等等，在现有的实验方法中是完全不可能存在的，作者本人不可能实现了文章中提到的速度。为什么文章会有意这样写，这是一个很大的问题。&lt;br&gt;&lt;br&gt;我无意批评作者本人，但是从最近几年审的稿子来看，咱们有一些中国的留学生（国外也有，比如说其他答案提到的sentence2vec，目前大家倾向于相信文章的实验不准确）的确倾向于有意无意忽略一些实验的细节，或者故意不仔细调baseline的效果，使得文章提出的算法比其他方法好一截。这个问题在深度学习上尤其明显，因为网络结构的小变化有可能会导致实验结果很大的区别。我有时候会看到文章，提出一个比较fancy的算法，但是在选基本网络结构的时候，baseline用AlexNet，自己的算法用Inception。&lt;br&gt;&lt;br&gt;这不对。&lt;br&gt;&lt;br&gt;最近几年我在审稿的时候，发现用的最多的一个评论是“more ablation study is needed”。作为一篇文章，最重要的是要告诉我们“为什么这个方法work”，而不是“实验效果提高了0.2”。越有影响的文章，对于方法本质的探讨越多，而对于实验结果数字的追求越不重要。&lt;br&gt;&lt;br&gt;这一次SARM这篇文章的影响，不仅在于实验设计中的小瑕疵，而且在于实际实验和文章的内容严重不符。这样的影响很不好，学术圈讲究的是诚信，其实大家都知道，私底下聊天的时候我们都会提到“谁谁写的文章水分很大”，“谁谁写的文章一般都很可信”，因为大家的时间都很有限，不可能每篇文章都重现一下。比如说这次，Reddit上很多人都试图重现这一算法，我也在小规模cifar上试图实现（因为太忙，还没出有意义的结果，reddit上就已经有结论了）。从我个人的角度说，我会对作者将来的文章都抱有一定的怀疑，不是因为歧视，而是因为大家资源都有限，我会更愿意让我的组员关注其他工作，比如deepmind。&lt;br&gt;&lt;br&gt;学术圈就是这样，大家都是好人，但是也不会随便姑息，一旦你被打上“有水分”甚至“造假”的标签，你的学术生涯就会受到非常大的影响。希望我们大家都能从这篇文章当中学到一些教训，有则改之，无则加勉。
&lt;/div&gt;</description><author>知乎用户</author><pubDate>2016-09-20</pubDate></item><item><title>如何评价百度开源的深度学习框架 Paddle?</title><link>https://www.zhihu.com/question/50185775/answer/119784535</link><description>&lt;div class="zm-editable-content"&gt;百度开源了自家的深度学习框架，与其他家的对比有什么优势？&lt;/div&gt;&lt;div class="zm-editable-content clearfix"&gt;
今天刚看到的，简单说一些第一印象（以目前的github repo为准）。整体的设计感觉和Caffe心有灵犀，同时解决了Caffe早期设计当中的一些问题（比如说default stream）。&lt;br&gt;&lt;br&gt;1. 很高质量的GPU代码&lt;br&gt;&lt;br&gt;2. 非常好的RNN设计&lt;br&gt;&lt;br&gt;3. 设计很干净，没有太多的abstraction，这一点比TensorFlow好很多。&lt;br&gt;&lt;br&gt;4. 高速RDMA的部分貌似没有开源（可能是因为RDMA对于cluster design有一定要求）：&lt;a href="//link.zhihu.com/?target=https%3A//github.com/baidu/Paddle/blob/master/paddle/pserver/RDMANetwork.h%23L17-L19" class=" wrap external" target="_blank" rel="nofollow noreferrer"&gt;Paddle/RDMANetwork.h at master · baidu/Paddle · GitHub&lt;i class="icon-external"&gt;&lt;/i&gt;&lt;/a&gt;&lt;br&gt;&lt;br&gt;5. 设计思路比较像第一代的DL框架，不过考虑到paddle已经有年头了，这样设计还是有历史原因的。&lt;br&gt;&lt;br&gt;  5.1 config是hard-code的protobuf message，这对扩展性可能会有影响。&lt;br&gt;&lt;br&gt;  5.2 可以看到很多有意思的类似历史遗留的设计：采用了STREAM_DEFAULT macro，然后通过TLS的方式定向到非default stream：&lt;a href="//link.zhihu.com/?target=https%3A//github.com/baidu/Paddle/blob/4fe7d833cf0dd952bfa8af8d5d7772bbcd552c58/paddle/cuda/include/hl_base.h%23L228-L229" class=" wrap external" target="_blank" rel="nofollow noreferrer"&gt;Paddle/hl_base.h at 4fe7d833cf0dd952bfa8af8d5d7772bbcd552c58 · baidu/Paddle · GitHub&lt;i class="icon-external"&gt;&lt;/i&gt;&lt;/a&gt; （所以Paddle off-the-shelf不支持mac？）&lt;br&gt;&lt;br&gt;  5.3 在梯度计算上采用了传统的粗粒度forward/backward设计（类似Caffe）。可能有人会说“所以paddle没有auto gradient generation”，这是不对的，autograd的存在与否和op的粒度粗细无关。事实上，TensorFlow在意识到细粒度operator超级慢的速度以后，也在逐渐转回粗粒度的operator上。&lt;br&gt;&lt;br&gt;目前只看到这里。总之是一个非常solid的框架，百度的开发功底还是不错的。
&lt;/div&gt;</description><author>知乎用户</author><pubDate>2016-09-20</pubDate></item><item><title>如何评价余凯创立的horizon robotics？</title><link>https://www.zhihu.com/question/31943421/answer/120759325</link><description>&lt;div class="zm-editable-content"&gt;定位，业务，技术，市场以及需要的人才均可讨论。&lt;/div&gt;&lt;div class="zm-editable-content clearfix"&gt;
原以为是个冷门话题，没想到也过百赞了，感谢大家认可！看到点赞和感谢的基本都是业内人士，有些是之前就在关注的大牛，顿时觉得鸭梨很大。&lt;b&gt;挑毛病是容易的，创业是极为艰难的&lt;/b&gt;，答主也在相关领域创业，所以请务必带着就事论事的心态看这篇回答，以探讨和进步为主，不带任何情绪和利益：&lt;br&gt;&lt;br&gt;---------以下原回答------------------&lt;br&gt;不看好。&lt;br&gt;&lt;br&gt;简单说就是：懂AI的人很多都不是合格的business man，business man里大部分人又不懂AI。即使是懂AI的business man，也需要几次试错机会。所以现在的AI创业，不管大V、小V还是草根团队，不管是技术切入、数据切入，离大的商业成熟还有很长的路要走。&lt;br&gt;&lt;br&gt;简单分析一下人工智能领域的创业机会：&lt;br&gt;&lt;br&gt;AI领域的创业机会可以分三个维度来分析：&lt;b&gt;人工部分、智能部分、场景部分&lt;/b&gt;。&lt;br&gt;&lt;br&gt;&lt;b&gt;人工的部分就是数据&lt;/b&gt;：数据是有壁垒的，在大家鼓吹大数据时代的时候，数据就是金钥匙；但是人工智能时代的数据，很多都是online的场景数据，也就是说，数据是伴随产品的使用而产生的。比如无人车，不是说到哪去买一堆训练数据，然后跑一下算法优化一下参数，就可以上路测试的。无人车的数据，都是在路上跑出来的。数据从input变为output（当然output要再次转化为input去提升性能），身份的变化，使得数据不再是人工智能时代的主要创业门槛。&lt;br&gt;&lt;br&gt;&lt;b&gt;智能的部分就是算法&lt;/b&gt;：目前AI的算法有很高的技术门槛，但是都没有很强的技术壁垒，微软研究院人工智能首席科学家邓力就曾提到，他们用AI做了个现场实时翻译的demo，然后告诉记者，这里面的技术，都是没有知识产权保护的。虽然技术的进入门槛挺高，但对于已经进入的团队来说，基本上是在同一起跑线上的竞争。&lt;br&gt;&lt;br&gt;&lt;b&gt;场景部分就是产品/市场痛点&lt;/b&gt;：这一块乍一看也没什么壁垒，场景可以复制，甚至复制难度还非常低。但实际上在AI领域创业，场景就是壁垒。因为场景带来第一批数据，数据带来性能提升，进而形成壁垒。复制的场景至少在数据层面是重复发明轮子，效率要比领跑的产品低，赶超难度也逐渐增大。所以，吃场景更容易吃到AI那块蛋糕。&lt;br&gt;&lt;br&gt;总结：&lt;b&gt;在AI领域创业，应该拼命往前端跑，往离钱近，离市场痛点近的地方跑，占领场景阵地。&lt;/b&gt;走一步就有充沛的现金流，有源源不断的数据积累，就已经是default alive的企业。然后再下面几步，逐渐形成自己的数据壁垒、行业地位。最后，再回到那个技术的菜市场去看看谁家的技术好，买回来用就是。&lt;br&gt;&lt;br&gt;所以，回头看余总的地平线机器人，在拼命的往后端跑，往离钱远，离市场痛点远的地方跑。但问题是大家GPU用的好好的啊，行业还远远没成熟到需要一个集成度更高的解决方案啊，那这个时候做芯片，要研发多久？卖给谁？能卖多少？这些都是变数很大的变量，一个企业面临那么多大变量，就算是明星企业，也不看好。&lt;br&gt;&lt;br&gt;后记：大多数时候，先进的技术，都是被整合的资源，是客体，而不能成为整合别的资源的主体。当一个站在技术前沿的人去讲商业故事的时候，通常都值得警惕，商业故事应该由合格的生意人去讲。&lt;br&gt;&lt;br&gt;ps：创业不易，虽然本人经常骂各种创业项目不靠谱，但本意是想共同进步，绝无恶意哈！
&lt;/div&gt;</description><author>邱彼特</author><pubDate>2016-09-20</pubDate></item><item><title>你必读的 RSS 订阅源有哪些？</title><link>https://www.zhihu.com/question/19580096/answer/119486747</link><description>&lt;div class="zm-editable-content"&gt;&lt;/div&gt;&lt;div class="zm-editable-content clearfix"&gt;
机器学习越来越火了，感觉不学一把机器学习简直赶不上时代了，下面公开一下本人的机器学习RSS订阅&lt;br&gt;&lt;br&gt;在机器学习的路上摸索前行，为了更快速的跟进行业最新的动态，我开始整理和收集机器学习相关的&lt;b&gt;优秀博客&lt;/b&gt;、&lt;b&gt;专栏&lt;/b&gt;和&lt;b&gt;活跃大V&lt;/b&gt;。&lt;br&gt;&lt;br&gt;我将最终整理到的学习资源整理为全文RSS订阅:&lt;br&gt;&lt;noscript&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/d9e1c849e8ac017ebe22dae14428b7b9_b.jpg" data-rawwidth="1262" data-rawheight="815" class="origin_image zh-lightbox-thumb" width="1262" data-original="https://pic2.zhimg.com/d9e1c849e8ac017ebe22dae14428b7b9_r.jpg"&gt;&lt;/noscript&gt;&lt;img rel="noreferrer"  data-rawwidth="1262" data-rawheight="815" class="origin_image zh-lightbox-thumb lazy" width="1262" data-original="https://pic2.zhimg.com/d9e1c849e8ac017ebe22dae14428b7b9_r.jpg" data-actualsrc="https://pic2.zhimg.com/d9e1c849e8ac017ebe22dae14428b7b9_b.jpg"&gt;&lt;br&gt;&lt;br&gt;&lt;b&gt;知乎专栏&lt;/b&gt;&lt;br&gt;&lt;noscript&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/9ef96b9eee6611b73aecb72131718d6e_b.jpg" data-rawwidth="893" data-rawheight="466" class="origin_image zh-lightbox-thumb" width="893" data-original="https://pic3.zhimg.com/9ef96b9eee6611b73aecb72131718d6e_r.jpg"&gt;&lt;/noscript&gt;&lt;img rel="noreferrer"  data-rawwidth="893" data-rawheight="466" class="origin_image zh-lightbox-thumb lazy" width="893" data-original="https://pic3.zhimg.com/9ef96b9eee6611b73aecb72131718d6e_r.jpg" data-actualsrc="https://pic3.zhimg.com/9ef96b9eee6611b73aecb72131718d6e_b.jpg"&gt;&lt;br&gt;&lt;b&gt;微信订阅号&lt;/b&gt;&lt;br&gt;&lt;noscript&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/346e14c8fbd1aaaefe707625117afb6d_b.jpg" data-rawwidth="855" data-rawheight="269" class="origin_image zh-lightbox-thumb" width="855" data-original="https://pic2.zhimg.com/346e14c8fbd1aaaefe707625117afb6d_r.jpg"&gt;&lt;/noscript&gt;&lt;img rel="noreferrer"  data-rawwidth="855" data-rawheight="269" class="origin_image zh-lightbox-thumb lazy" width="855" data-original="https://pic2.zhimg.com/346e14c8fbd1aaaefe707625117afb6d_r.jpg" data-actualsrc="https://pic2.zhimg.com/346e14c8fbd1aaaefe707625117afb6d_b.jpg"&gt;&lt;br&gt;&lt;b&gt;博客&lt;/b&gt;&lt;br&gt;&lt;noscript&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/ad2ea2251d2f6971f3e26e4da8eb961b_b.jpg" data-rawwidth="896" data-rawheight="340" class="origin_image zh-lightbox-thumb" width="896" data-original="https://pic4.zhimg.com/ad2ea2251d2f6971f3e26e4da8eb961b_r.jpg"&gt;&lt;/noscript&gt;&lt;img rel="noreferrer"  data-rawwidth="896" data-rawheight="340" class="origin_image zh-lightbox-thumb lazy" width="896" data-original="https://pic4.zhimg.com/ad2ea2251d2f6971f3e26e4da8eb961b_r.jpg" data-actualsrc="https://pic4.zhimg.com/ad2ea2251d2f6971f3e26e4da8eb961b_b.jpg"&gt;&lt;br&gt;&lt;b&gt;微博&lt;/b&gt;&lt;br&gt;&lt;noscript&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/56fd483613dd8058d986edf932b5abbb_b.jpg" data-rawwidth="877" data-rawheight="86" class="origin_image zh-lightbox-thumb" width="877" data-original="https://pic4.zhimg.com/56fd483613dd8058d986edf932b5abbb_r.jpg"&gt;&lt;/noscript&gt;&lt;img rel="noreferrer"  data-rawwidth="877" data-rawheight="86" class="origin_image zh-lightbox-thumb lazy" width="877" data-original="https://pic4.zhimg.com/56fd483613dd8058d986edf932b5abbb_r.jpg" data-actualsrc="https://pic4.zhimg.com/56fd483613dd8058d986edf932b5abbb_b.jpg"&gt;&lt;br&gt;&lt;b&gt;OPML&lt;/b&gt;&lt;br&gt;最终整理的 OPML 链接为:&lt;br&gt;&lt;a href="//link.zhihu.com/?target=https%3A//raw.githubusercontent.com/RickyWong33/Machine_Learning_RSS/master/OPML.xml" class=" external" target="_blank" rel="nofollow noreferrer"&gt;&lt;span class="invisible"&gt;https://&lt;/span&gt;&lt;span class="visible"&gt;raw.githubusercontent.com&lt;/span&gt;&lt;span class="invisible"&gt;/RickyWong33/Machine_Learning_RSS/master/OPML.xml&lt;/span&gt;&lt;span class="ellipsis"&gt;&lt;/span&gt;&lt;i class="icon-external"&gt;&lt;/i&gt;&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;b&gt;使用方法 1(推荐) - inoreader&lt;/b&gt;&lt;br&gt;在设置的 OPML 订阅源中填入本 repo 的 OPML RAW 文件地址:&lt;br&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;pre&gt;&lt;code class="language-text"&gt;https://raw.githubusercontent.com/RickyWong33/Machine_Learning_RSS/master/OPML.xml
&lt;/code&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;/div&gt;&lt;noscript&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/efd1db237f284203514302363e524d1b_b.jpg" data-rawwidth="1206" data-rawheight="757" class="origin_image zh-lightbox-thumb" width="1206" data-original="https://pic4.zhimg.com/efd1db237f284203514302363e524d1b_r.jpg"&gt;&lt;/noscript&gt;&lt;img rel="noreferrer"  data-rawwidth="1206" data-rawheight="757" class="origin_image zh-lightbox-thumb lazy" width="1206" data-original="https://pic4.zhimg.com/efd1db237f284203514302363e524d1b_r.jpg" data-actualsrc="https://pic4.zhimg.com/efd1db237f284203514302363e524d1b_b.jpg"&gt;&lt;blockquote&gt;inoreader 能同步本 OPML 的更新，以后扩展的订阅源都会被 inoreader 自动同步，推荐使用&lt;/blockquote&gt;&lt;b&gt;&lt;br&gt;使用方法 2 - Feedly&lt;/b&gt;&lt;br&gt;下载 &lt;a href="//link.zhihu.com/?target=https%3A//raw.githubusercontent.com/RickyWong33/Machine_Learning_RSS/master/OPML.xml" class=" wrap external" target="_blank" rel="nofollow noreferrer"&gt;OPML LINK&lt;i class="icon-external"&gt;&lt;/i&gt;&lt;/a&gt; 后保存为 OPML.xml，在  Feedly  源管理页面导入。&lt;br&gt;&lt;blockquote&gt;由于本 RSS可能会频繁更新订阅源（或者修订 RSS 输出的样式），如果需要更新的话，请重新下载后再导入 Feedly 。&lt;br&gt;&lt;/blockquote&gt;&lt;b&gt;&lt;br&gt;致谢&lt;/b&gt;&lt;br&gt;感谢以上提到的博主积极的知识输出&lt;br&gt;欢迎推荐更多的优质机器学习阅读资源 &lt;br&gt;Github 项目地址，欢迎加 star 加 watch 保持关注:  &lt;a href="//link.zhihu.com/?target=https%3A//github.com/RickyWong33/Machine_Learning_RSS" class=" wrap external" target="_blank" rel="nofollow noreferrer"&gt;Machine_Learning_RSS&lt;i class="icon-external"&gt;&lt;/i&gt;&lt;/a&gt;
&lt;/div&gt;</description><author>Ricky</author><pubDate>2016-09-20</pubDate></item><item><title>当前人工智能特别是深度学习最前沿的研究方向是什么？</title><link>https://www.zhihu.com/question/46485555/answer/119428123</link><description>&lt;div class="zm-editable-content"&gt;深度学习显然是人工智能中最热门的研究方向，不过这里我想问的是更具体一点的研究方向。比如OpenAI的研究方向：&lt;br&gt;1）Deep Generative Models 深度生成模型&lt;br&gt;2）Neural Turing Machine 神经图灵机&lt;br&gt;3）Deep Reinforcement Learning 深度增强学习&lt;br&gt;但这也让我产生疑问：这三个方向是不是人工智能领域最前沿最重要的研究方向，还有什么研究方向的重要性和这三个方向相当？为什么DeepMind和OpenAI重点研究这三个方向呢？&lt;br&gt;恳请知乎大牛们分享一下你们的看法。这个问题顺便可以回答 到底研究什么人工智能问题才是最有价值的，最值得去做的？&lt;br&gt;另外，无论是计算机视觉，语音识别，机器人控制，都只能算是人工智能算法的应用出口。上面提及的方向都能够应用到不同垂直领域。&lt;/div&gt;&lt;div class="zm-editable-content clearfix"&gt;
&lt;p&gt;当前深度学习技术主要是data driven的，即对一个特定任务来说，只要增加训练数据的规模，深度学习模型的表现就可以得到提高。但是发展到今天，这种思路面临很多挑战。主要面临下面几个问题：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;很多领域（如医疗，教育），很难获取大量的监督数据或者数据的标注成本过高。&lt;/li&gt;&lt;li&gt;训练数据规模再大，也有难以覆盖的情况。例如聊天机器人，你不可能穷尽所有可能的答案。而且很多答案，也是随时间变化的（例如明星年龄，配偶）。因此仅仅依靠大规模的训练语料，并不能解决这些问题。&lt;/li&gt;&lt;li&gt;通用深度学习模型，直接应用到具体问题，表现（效果，性能，占用资源等）可能不尽如人意。这就要求根据特定的问题和数据，来定制和优化深度学习网络结构。这个是当前研究最多最热的地方。&lt;/li&gt;&lt;li&gt;训练的问题。包括网络层数增加带来的梯度衰减，如何更有效的进行大规模并行训练等等。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;为了解决上面的问题，当前的研究前沿主要包括以下几个方向：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;引入外部知识(如知识图谱,WordNet) &lt;br&gt;Knowledge-Based Semantic Embedding for Machine Translation &lt;br&gt;A Neural Knowledge Language Model&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;深度学习与传统方法的结合。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;人工规则与神经网络的结合 &lt;br&gt;Harnessing Deep Neural Networks with Logic Rules&lt;/li&gt;&lt;li&gt;贝叶斯与神经网络的结合 &lt;br&gt;Human-level concept learning through probabilistic program induction(论文讲的是用贝叶斯让机器模仿人写字的，但是对深度学习有非常大的启发价值）&lt;/li&gt;&lt;li&gt;迁移学习与神经网络的结合&lt;/li&gt;&lt;li&gt;强化学习与神经网络的结合 &lt;br&gt;Mastering the game of Go with deep neural networks and tree search&lt;/li&gt;&lt;li&gt;图模型与神经网络的结合 &lt;br&gt;Bidirectional LSTM-CRF Models for Sequence Tagging &lt;br&gt;A Hierarchical Latent Variable Encoder-Decoder Model for Generating Dialogues&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;无监督的深度生成模型。 &lt;br&gt;Generative Adversarial Networks&lt;/p&gt;&lt;/li&gt;&lt;li&gt;新的网络结构 &lt;br&gt;Highway Networks &lt;br&gt;Neural Turing Machines &lt;br&gt;End-To-End Memory Networks &lt;br&gt;Deep Residual Learning for Image Recognition &lt;br&gt;Mollifying Networks&lt;/li&gt;&lt;li&gt;新的训练方法 &lt;br&gt;Batch Normalization Accelerating Deep Network Training by Reducing Internal Covariate Shift&lt;/li&gt;&lt;/ul&gt;从具体研究方向上来说，我觉得深度学习在图像和语音上已经非常成熟，因为图像信号和语音信号，都是比较原始的信号，从原始信号中抽取特征对人比较困难，但对深度学习模型比较容易，因此深度学习技术率先在这两个领域取得巨大成功。而NLP领域，因为文字是一种high level的信息，而且从文字到语义，存在一个比较大的语义鸿沟，因此深度学习技术在NLP上存在很大的挑战，但是挑战也意味着机会，因此除了传统NLP领域的研究人大量开始发力深度学习，许多其他领域的人（如机器学习，统计），也开始向NLP进军（Bengio组的人开始搞机器翻译，语言模型，对话系统等等）。&lt;br&gt;&lt;br&gt;上面是我一些不太成熟的看法，欢迎大家指正交流。
&lt;/div&gt;</description><author>知乎用户</author><pubDate>2016-09-20</pubDate></item><item><title>推荐系统有哪些比较好的论文？</title><link>https://www.zhihu.com/question/25566638/answer/37455091</link><description>&lt;div class="zm-editable-content"&gt;最好是像kdd的论文和presentation那样，从特定问题出发，特征工程、模型选择等整个过程都提及的&lt;/div&gt;&lt;div class="zm-editable-content clearfix"&gt;
（昨天正好回答过一个相关问题，拿过来给题主参考以下）&lt;br&gt;推荐几篇对工业界比较有影响的论文吧：&lt;br&gt;1. The Wisdom of The Few 豆瓣阿稳在介绍豆瓣猜的时候极力推荐过这篇论文，豆瓣猜也充分应用了这篇论文中提出的算法；&lt;br&gt;2. Restricted Boltzmann Machines for Collaborative Filtering 目前Netflix使用的主要推荐算法之一；&lt;br&gt;3. Factorization Meets the Neighborhood: a Multifaceted Collaborative Filtering Model 这个无需强调重要性，LFM几乎应用到了每一个商业推荐系统中；&lt;br&gt;4. Collaborative Filtering with Temporal Dynamics 加入时间因素的SVD++模型，曾在Netflix Prize中大放溢彩的算法模型；&lt;br&gt;5. Context-Aware Recommender Systems 基于上下文的推荐模型，现在不论是工业界还是学术界都非常火的一个topic；&lt;br&gt;6. Toward the next generation of recommender systems 对下一代推荐系统的一个综述；&lt;br&gt;7. Item-Based Collaborative Filtering Recommendation Algorithms 基于物品的协同过滤，Amazon等电商网站的主力模型算法之一；&lt;br&gt;8. Information Seeking-Convergence of Search, Recommendations and Advertising 搜索、推荐和广告的大融合也是未来推荐系统的发展趋势之一；&lt;br&gt;9. Ad Click Prediction: a View from the Trenches 可以对推荐结果做CTR预测排序；&lt;br&gt;10. Performance of Recommender Algorithm on top-n Recommendation Task TopN预测的一个综合评测，TopN现在是推荐系统的主流话题，可以全部实现这篇文章中提到的算法大概对TopN有个体会；&lt;br&gt;11. &lt;a href="//link.zhihu.com/?target=http%3A//dsec.pku.edu.cn/%7Ejinlong/publication/wjlthesis.pdf" class=" external" target="_blank" rel="nofollow noreferrer"&gt;&lt;span class="invisible"&gt;http://&lt;/span&gt;&lt;span class="visible"&gt;dsec.pku.edu.cn/~jinlon&lt;/span&gt;&lt;span class="invisible"&gt;g/publication/wjlthesis.pdf&lt;/span&gt;&lt;span class="ellipsis"&gt;&lt;/span&gt;&lt;i class="icon-external"&gt;&lt;/i&gt;&lt;/a&gt; 北大一博士对Netflix Prize算法的研究做的毕业论文，这篇论文本身对业界影响不大，但是Netflix Prize中运用到的算法极大地推动了推荐系统的发展；&lt;br&gt;通过这些论文可以对推荐系统有个总体上的全面认识，并且能够了解一些推荐系统的发展趋势。剩下的就是多实践了。Good luck！&lt;br&gt;&lt;br&gt;------------------------------------------------------------羊年大年初一补充-----------------------------------------------------&lt;br&gt;Quora上有一个相关的回答，质量非常不错：&lt;a href="//link.zhihu.com/?target=http%3A//www.quora.com/What-are-the-seminal-papers-on-recommender-systems" class=" external" target="_blank" rel="nofollow noreferrer"&gt;&lt;span class="invisible"&gt;http://www.&lt;/span&gt;&lt;span class="visible"&gt;quora.com/What-are-the-&lt;/span&gt;&lt;span class="invisible"&gt;seminal-papers-on-recommender-systems&lt;/span&gt;&lt;span class="ellipsis"&gt;&lt;/span&gt;&lt;i class="icon-external"&gt;&lt;/i&gt;&lt;/a&gt; 回答了关于推荐系统起源问题的相关论文，同样值得阅读。
&lt;/div&gt;</description><author>知乎用户</author><pubDate>2016-09-20</pubDate></item><item><title>如何评价rcnn、fast-rcnn和faster-rcnn这一系列方法？</title><link>https://www.zhihu.com/question/35887527/answer/72876282</link><description>&lt;div class="zm-editable-content"&gt;或者相关的检测方法如OverFeat、SPPNet和最新的YOLO。&lt;/div&gt;&lt;div class="zm-editable-content clearfix"&gt;
泻药，终于看到符合自己胃口的问题啦！怒答一枚。RCNN和Fast-RCNN简直是引领了最近两年目标检测的潮流！&lt;br&gt;-------------------------------&lt;br&gt;提到这两个工作，不得不提到RBG大神&lt;a href="//link.zhihu.com/?target=http%3A//www.cs.berkeley.edu/%7Erbg/index.html" class=" wrap external" target="_blank" rel="nofollow noreferrer"&gt;rbg's home page&lt;i class="icon-external"&gt;&lt;/i&gt;&lt;/a&gt;，该大神在读博士的时候就因为dpm获得过pascal voc 的终身成就奖。博士后期间更是不断发力，RCNN和Fast-RCNN就是他的典型作品。&lt;br&gt;&lt;br&gt;RCNN：RCNN可以看作是RegionProposal+CNN这一框架的开山之作，在imgenet/voc/mscoco上基本上所有top的方法都是这个框架，可见其影响之大。RCNN的主要缺点是重复计算，后来MSRA的kaiming组的SPPNET做了相应的加速。&lt;br&gt;&lt;br&gt;Fast-RCNN：RCNN的加速版本，在我看来，这不仅仅是一个加速版本，其优点还包括：&lt;br&gt;(a) 首先，它提供了在caffe的框架下，如何定义自己的层/参数/结构的范例，这个范例的一个重要的应用是python layer的应用，我在这里&lt;a href="http://www.zhihu.com/question/36847520/answer/72824645" class="internal"&gt;支持多label的caffe，有比较好的实现吗？ - 孔涛的回答&lt;/a&gt;也提到了。&lt;br&gt;(2) training and testing end-to-end 这一点很重要，为了达到这一点其定义了ROIPooling层，因为有了这个，使得训练效果提升不少。&lt;br&gt;(3) 速度上的提升，因为有了Fast-RCNN，这种基于CNN的 real-time 的目标检测方法看到了希望，在工程上的实践也有了可能，后续也出现了诸如Faster-RCNN/YOLO等相关工作。&lt;br&gt;&lt;br&gt;这个领域的脉络是：RCNN -&amp;gt; SPPNET -&amp;gt; Fast-RCNN -&amp;gt; Faster-RCNN。关于具体的细节，建议题主还是阅读相关文献吧。&lt;br&gt;&lt;br&gt;这使我看到了目标检测领域的希望。起码有这么一部分人，他们不仅仅是为了几个百分点的提升，而是切实踏实在做贡献，相信不久这个领域会有新的工作出来。&lt;br&gt;&lt;br&gt;以上纯属个人观点，欢迎批评指正。&lt;br&gt;&lt;br&gt;参考：&lt;br&gt;[1] R-CNN: Girshick R, Donahue J, Darrell T, et al. Rich feature hierarchies for accurate object detection and semantic segmentation[C], CVPR, 2014.&lt;br&gt;[2] SPPNET: He K, Zhang X, Ren S, et al. Spatial pyramid pooling in deep convolutional networks for visual recognition[C], ECCV, 2014.&lt;br&gt;[3] Fast-RCNN: Girshick R. Fast R-CNN[C]. ICCV, 2015.&lt;br&gt;[4] Fater-RCNN: Ren S, He K, Girshick R, et al. Faster r-cnn: Towards real-time object detection with region proposal networks[C]. NIPS, 2015.&lt;br&gt;[5] YOLO: Redmon J, Divvala S, Girshick R, et al. You Only Look Once: Unified, Real-Time Object Detection[J]. arXiv preprint arXiv:1506.02640, 2015.
&lt;/div&gt;</description><author>孔巴巴</author><pubDate>2016-09-20</pubDate></item><item><title>ICML 2016上哪些论文值得关注？</title><link>https://www.zhihu.com/question/45716405/answer/105619854</link><description>&lt;div class="zm-editable-content"&gt;ICML 2016的录用论文列表已经发布，&lt;a href="//link.zhihu.com/?target=http%3A//icml.cc/2016/%3Fpage_id%3D1649" class=" wrap external" target="_blank" rel="nofollow noreferrer"&gt;Accepted Papers&lt;i class="icon-external"&gt;&lt;/i&gt;&lt;/a&gt;，我们可以一起交流下这个会议上哪些论文特别值得关注，代表未来的研究热点和重点？&lt;/div&gt;&lt;div class="zm-editable-content clearfix"&gt;
&lt;a data-hash="cc0767a011397b2adac4e1ae6ac00b83" href="//www.zhihu.com/people/cc0767a011397b2adac4e1ae6ac00b83" class="member_mention" data-editable="true" data-title="@刘知远" data-tip="p$b$cc0767a011397b2adac4e1ae6ac00b83" data-hovercard="p$b$cc0767a011397b2adac4e1ae6ac00b83"&gt;@刘知远&lt;/a&gt; 老师此题好比crowdsourcing：ICML涉及领域众多，欲精通所有不太现实，但博采众长即可去伪存真、沙里淘金。在此仅抛砖引玉，提几篇个人比较感兴趣的paper。&lt;br&gt;&lt;br&gt;近期一直关注深度学习的研究和发展，因此下面八篇文章均涉及DL：&lt;br&gt;&lt;ol&gt;&lt;li&gt;Understanding and Improving Convolutional Neural Networks via Concatenated Rectified Linear Units (&lt;a href="//link.zhihu.com/?target=http%3A//jmlr.org/proceedings/papers/v48/shang16.pdf" class=" external" target="_blank" rel="nofollow noreferrer"&gt;&lt;span class="invisible"&gt;http://&lt;/span&gt;&lt;span class="visible"&gt;jmlr.org/proceedings/pa&lt;/span&gt;&lt;span class="invisible"&gt;pers/v48/shang16.pdf&lt;/span&gt;&lt;span class="ellipsis"&gt;&lt;/span&gt;&lt;i class="icon-external"&gt;&lt;/i&gt;&lt;/a&gt;)：这篇文章出自U. Michigan，以及著名的NEC和Oculus VR。作者受到自己对CNN可视化发现的启发，设计了一种新的激活函数，即concatenated ReLU (CReLU)，在ImageNet等数据上不仅能取得更好结果，同时所需参数也可大幅缩减。&lt;br&gt;&lt;/li&gt;&lt;li&gt;Noisy Activation Functions (&lt;a href="//link.zhihu.com/?target=http%3A//jmlr.org/proceedings/papers/v48/gulcehre16.pdf" class=" external" target="_blank" rel="nofollow noreferrer"&gt;&lt;span class="invisible"&gt;http://&lt;/span&gt;&lt;span class="visible"&gt;jmlr.org/proceedings/pa&lt;/span&gt;&lt;span class="invisible"&gt;pers/v48/gulcehre16.pdf&lt;/span&gt;&lt;span class="ellipsis"&gt;&lt;/span&gt;&lt;i class="icon-external"&gt;&lt;/i&gt;&lt;/a&gt;)：Bengio作品。为解决传统激活函数的「饱和效应」（也称「梯度弥散」现象），作者提出在梯度饱和部分加入合适的噪声以解决先前的优化难题。如此“反人类”的做法却取得了较好的泛化效果。&lt;/li&gt;&lt;li&gt;Learning End-to-end Video Classification with Rank-Pooling (&lt;a href="//link.zhihu.com/?target=http%3A//jmlr.org/proceedings/papers/v48/fernando16.pdf" class=" external" target="_blank" rel="nofollow noreferrer"&gt;&lt;span class="invisible"&gt;http://&lt;/span&gt;&lt;span class="visible"&gt;jmlr.org/proceedings/pa&lt;/span&gt;&lt;span class="invisible"&gt;pers/v48/fernando16.pdf&lt;/span&gt;&lt;span class="ellipsis"&gt;&lt;/span&gt;&lt;i class="icon-external"&gt;&lt;/i&gt;&lt;/a&gt;)：先前在CNN中对video特征进行pooling的方法无异于max和average，该文提出了一种新的rank-pooling方法作为内嵌优化来学习如何更有效的将时序信息encode到最终特征中去。&lt;/li&gt;&lt;li&gt;Large-Margin Softmax Loss for Convolutional Neural Networks (&lt;a href="//link.zhihu.com/?target=http%3A//jmlr.org/proceedings/papers/v48/liud16.pdf" class=" external" target="_blank" rel="nofollow noreferrer"&gt;&lt;span class="invisible"&gt;http://&lt;/span&gt;&lt;span class="visible"&gt;jmlr.org/proceedings/pa&lt;/span&gt;&lt;span class="invisible"&gt;pers/v48/liud16.pdf&lt;/span&gt;&lt;span class="ellipsis"&gt;&lt;/span&gt;&lt;i class="icon-external"&gt;&lt;/i&gt;&lt;/a&gt;)提出了一种新型基于「大间隔」的softmax loss。&lt;br&gt;&lt;/li&gt;&lt;li&gt;Augmenting Supervised Neural Networks with Unsupervised Objectives for Large-scale Image Classification (&lt;a href="//link.zhihu.com/?target=http%3A//jmlr.org/proceedings/papers/v48/zhangc16.pdf" class=" external" target="_blank" rel="nofollow noreferrer"&gt;&lt;span class="invisible"&gt;http://&lt;/span&gt;&lt;span class="visible"&gt;jmlr.org/proceedings/pa&lt;/span&gt;&lt;span class="invisible"&gt;pers/v48/zhangc16.pdf&lt;/span&gt;&lt;span class="ellipsis"&gt;&lt;/span&gt;&lt;i class="icon-external"&gt;&lt;/i&gt;&lt;/a&gt;)：通过构建CNN网络的“镜像网络”来「无监督」的重建图像，进而增强「监督」网络的判别能力。&lt;br&gt;&lt;/li&gt;&lt;li&gt;Unsupervised Deep Embedding for Clustering Analysis (&lt;a href="//link.zhihu.com/?target=http%3A//jmlr.org/proceedings/papers/v48/xieb16.pdf" class=" external" target="_blank" rel="nofollow noreferrer"&gt;&lt;span class="invisible"&gt;http://&lt;/span&gt;&lt;span class="visible"&gt;jmlr.org/proceedings/pa&lt;/span&gt;&lt;span class="invisible"&gt;pers/v48/xieb16.pdf&lt;/span&gt;&lt;span class="ellipsis"&gt;&lt;/span&gt;&lt;i class="icon-external"&gt;&lt;/i&gt;&lt;/a&gt;)：RBG作品。DL版本的聚类。&lt;br&gt;&lt;/li&gt;&lt;li&gt;Learning Convolutional Neural Networks for Graphs (&lt;a href="//link.zhihu.com/?target=http%3A//jmlr.org/proceedings/papers/v48/niepert16.pdf" class=" external" target="_blank" rel="nofollow noreferrer"&gt;&lt;span class="invisible"&gt;http://&lt;/span&gt;&lt;span class="visible"&gt;jmlr.org/proceedings/pa&lt;/span&gt;&lt;span class="invisible"&gt;pers/v48/niepert16.pdf&lt;/span&gt;&lt;span class="ellipsis"&gt;&lt;/span&gt;&lt;i class="icon-external"&gt;&lt;/i&gt;&lt;/a&gt;)：图结构在机器学习中举足轻重，本文提出可以利用CNN来学习任意图结构。（不知会不会在graph based learning或mining领域引起轩然大波。）&lt;br&gt;&lt;/li&gt;&lt;li&gt;Deep Speech 2 : End-to-End Speech Recognition in English and Mandarin (&lt;a href="//link.zhihu.com/?target=http%3A//jmlr.org/proceedings/papers/v48/amodei16.pdf" class=" external" target="_blank" rel="nofollow noreferrer"&gt;&lt;span class="invisible"&gt;http://&lt;/span&gt;&lt;span class="visible"&gt;jmlr.org/proceedings/pa&lt;/span&gt;&lt;span class="invisible"&gt;pers/v48/amodei16.pdf&lt;/span&gt;&lt;span class="ellipsis"&gt;&lt;/span&gt;&lt;i class="icon-external"&gt;&lt;/i&gt;&lt;/a&gt;)：来自Baidu的一篇系统论文。工业界朋友可以重点参考，其中介绍了很多语音系统实现方法和技巧。&lt;br&gt;&lt;/li&gt;&lt;/ol&gt;&lt;u&gt;可以很容易发现，ICML'16中涉及DL/NN的文章，要么解决了DL中非常fundamental的问题，如提出新的activation function或pooling layer；要么就是用DL解决了很fundamental的任务，如clustering，graph learning和unsupervised learning；要么就是很具实践指导性的Deep Speech 2。鲜有非常CV口味的应用文章，也许这就是不同background对DL不同的喜好吧。&lt;/u&gt;
&lt;/div&gt;</description><author>魏秀参</author><pubDate>2016-09-20</pubDate></item><item><title>深度机器学习中的batch的大小对学习效果有何影响？</title><link>https://www.zhihu.com/question/32673260/answer/71137399</link><description>&lt;div class="zm-editable-content"&gt;如题，在深度学习中，刚入门的小弟一直听闻一个batch中同时训练多个数据可以得到较好的效果，于是小弟在caffe上跑deepID的网络时对如何选取batchsize颇具困惑。恳求万能的知友给予指点~~&lt;/div&gt;&lt;div class="zm-editable-content clearfix"&gt;
&lt;b&gt;谈谈深度学习中的 Batch_Size&lt;/b&gt;&lt;br&gt;Batch_Size（批尺寸）是机器学习中一个重要参数，涉及诸多矛盾，下面逐一展开。&lt;br&gt;&lt;br&gt;&lt;b&gt;首先，为什么需要有 Batch_Size 这个参数？&lt;/b&gt;&lt;br&gt;Batch 的选择，&lt;b&gt;首先决定的是下降的方向。&lt;/b&gt;如果数据集比较小，完全可以采用&lt;b&gt;全数据集&lt;/b&gt; （ &lt;b&gt;Full Batch Learning&lt;/b&gt; ）的形式，这样做&lt;u&gt;至少&lt;/u&gt;有 2 个好处：其一，由全数据集确定的方向能够更好地代表样本总体，从而&lt;a href="http://www.zhihu.com/question/37129350/answer/70964527#" class="internal"&gt;更准确地朝向极值所在的方向&lt;/a&gt;。其二，由于不同权重的梯度值差别巨大，因此选取一个全局的学习率很困难。 Full Batch Learning 可以使用&lt;b&gt;Rprop&lt;/b&gt; 只基于梯度符号并且针对性单独更新各权值。&lt;br&gt;&lt;br&gt;对于更大的数据集，以上 2 个好处又变成了 2 个坏处：其一，随着数据集的海量增长和内存限制，一次性载入所有的数据进来变得越来越不可行。其二，以 Rprop 的方式迭代，会由于各个 Batch 之间的采样差异性，各次梯度修正值相互抵消，无法修正。这才有了后来 &lt;b&gt;RMSProp&lt;/b&gt; 的妥协方案。&lt;br&gt;&lt;br&gt;&lt;b&gt;既然 Full Batch Learning 并不适用大数据集，那么走向另一个极端怎么样？&lt;/b&gt;&lt;br&gt;所谓另一个极端，就是每次只训练一个样本，即 Batch_Size = 1。这就是&lt;b&gt;在线学习&lt;/b&gt;&lt;b&gt;（Online Learning）&lt;/b&gt;。线性神经元在均方误差代价函数的错误面是一个抛物面，横截面是椭圆。对于多层神经元、非线性网络，在局部依然近似是抛物面。使用在线学习，每次修正方向以各自样本的梯度方向修正，横冲直撞各自为政，&lt;b&gt;难以达到收敛&lt;/b&gt;。&lt;br&gt;&lt;br&gt;&lt;noscript&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/f5a6d3b5c4b5a91851f0f8b8735f162d_b.png" data-rawwidth="952" data-rawheight="662" class="origin_image zh-lightbox-thumb" width="952" data-original="https://pic2.zhimg.com/f5a6d3b5c4b5a91851f0f8b8735f162d_r.png"&gt;&lt;/noscript&gt;&lt;img rel="noreferrer"  data-rawwidth="952" data-rawheight="662" class="origin_image zh-lightbox-thumb lazy" width="952" data-original="https://pic2.zhimg.com/f5a6d3b5c4b5a91851f0f8b8735f162d_r.png" data-actualsrc="https://pic2.zhimg.com/f5a6d3b5c4b5a91851f0f8b8735f162d_b.png"&gt;&lt;br&gt;&lt;br&gt;&lt;b&gt;可不可以选择一个适中的 Batch_Size 值呢？&lt;/b&gt;&lt;br&gt;当然可以，这就是&lt;b&gt;批梯度下降法（Mini-batches Learning）&lt;/b&gt;。因为如果数据集足够充分，那么用一半（&lt;u&gt;甚至少得多&lt;/u&gt;）的数据训练算出来的梯度与用全部数据训练出来的梯度是&lt;u&gt;几乎一样&lt;/u&gt;的。&lt;br&gt;&lt;br&gt;&lt;b&gt;在合理范围内，增大 Batch_Size 有何&lt;u&gt;好处&lt;/u&gt;？&lt;/b&gt;&lt;br&gt;&lt;ul&gt;&lt;li&gt;内存利用率提高了，大矩阵乘法的并行化效率提高。&lt;/li&gt;&lt;li&gt;跑完一次 epoch（全数据集）所需的迭代次数减少，对于相同数据量的处理速度进一步加快。&lt;/li&gt;&lt;li&gt;在一定范围内，一般来说 Batch_Size 越大，其确定的下降方向越准，引起训练震荡越小。&lt;/li&gt;&lt;/ul&gt;&lt;br&gt;&lt;b&gt;盲目增大 Batch_Size 有何&lt;u&gt;坏处&lt;/u&gt;？&lt;/b&gt;&lt;br&gt;&lt;ul&gt;&lt;li&gt;内存利用率提高了，但是内存容量可能撑不住了。&lt;/li&gt;&lt;li&gt;跑完一次 epoch（全数据集）所需的迭代次数减少，要想达到相同的精度，其所花费的时间大大增加了，从而对参数的修正也就显得更加缓慢。&lt;/li&gt;&lt;li&gt;Batch_Size 增大到一定程度，其确定的下降方向已经基本不再变化。&lt;br&gt;&lt;/li&gt;&lt;/ul&gt;&lt;br&gt;&lt;b&gt;调节 Batch_Size 对训练效果影响到底如何？&lt;/b&gt;&lt;br&gt;这里跑一个 LeNet 在 MNIST 数据集上的效果。MNIST 是一个手写体标准库，我使用的是 &lt;b&gt;Theano &lt;/b&gt;框架。这是一个 Python 的深度学习库。&lt;a href="//link.zhihu.com/?target=http%3A//deeplearning.net/software/theano/install.html%23install" class=" wrap external" target="_blank" rel="nofollow noreferrer"&gt;安装方便&lt;i class="icon-external"&gt;&lt;/i&gt;&lt;/a&gt;（几行命令而已），调试简单（自带 Profile），GPU / CPU 通吃，&lt;a href="//link.zhihu.com/?target=http%3A//deeplearning.net/tutorial/contents.html" class=" wrap external" target="_blank" rel="nofollow noreferrer"&gt;官方教程相当完备&lt;i class="icon-external"&gt;&lt;/i&gt;&lt;/a&gt;，支持模块十分丰富（除了 CNNs，更是支持 RBM / DBN / LSTM / RBM-RNN / SdA / MLPs）。在其上层有 &lt;a href="//link.zhihu.com/?target=http%3A//keras.io/" class=" wrap external" target="_blank" rel="nofollow noreferrer"&gt;Keras&lt;i class="icon-external"&gt;&lt;/i&gt;&lt;/a&gt; 封装，支持 GRU / JZS1, JZS2, JZS3 等较新结构，支持 Adagrad / Adadelta / RMSprop / Adam 等优化算法。&lt;br&gt;&lt;br&gt;&lt;noscript&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/8182178facd79a8828e31966e0c4587c_b.png" data-rawwidth="753" data-rawheight="176" class="origin_image zh-lightbox-thumb" width="753" data-original="https://pic1.zhimg.com/8182178facd79a8828e31966e0c4587c_r.png"&gt;&lt;/noscript&gt;&lt;img rel="noreferrer"  data-rawwidth="753" data-rawheight="176" class="origin_image zh-lightbox-thumb lazy" width="753" data-original="https://pic1.zhimg.com/8182178facd79a8828e31966e0c4587c_r.png" data-actualsrc="https://pic1.zhimg.com/8182178facd79a8828e31966e0c4587c_b.png"&gt;&lt;br&gt;&lt;noscript&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/d6fb7abbaeef80e739d824582a0fa384_b.png" data-rawwidth="1558" data-rawheight="344" class="origin_image zh-lightbox-thumb" width="1558" data-original="https://pic1.zhimg.com/d6fb7abbaeef80e739d824582a0fa384_r.png"&gt;&lt;/noscript&gt;&lt;img rel="noreferrer"  data-rawwidth="1558" data-rawheight="344" class="origin_image zh-lightbox-thumb lazy" width="1558" data-original="https://pic1.zhimg.com/d6fb7abbaeef80e739d824582a0fa384_r.png" data-actualsrc="https://pic1.zhimg.com/d6fb7abbaeef80e739d824582a0fa384_b.png"&gt;&lt;br&gt;运行结果如上图所示，其中绝对时间做了标幺化处理。运行结果与上文分析相印证：&lt;br&gt;&lt;ul&gt;&lt;li&gt;Batch_Size 太小，算法在 200 epoches 内不收敛。&lt;br&gt;&lt;/li&gt;&lt;li&gt;随着 Batch_Size 增大，处理相同数据量的速度越快。&lt;/li&gt;&lt;li&gt;随着 Batch_Size 增大，达到相同精度所需要的 epoch 数量越来越多。&lt;br&gt;&lt;/li&gt;&lt;li&gt;由于上述两种因素的矛盾， Batch_Size 增大到&lt;u&gt;某个&lt;/u&gt;时候，达到&lt;b&gt;时间上&lt;/b&gt;的最优。&lt;/li&gt;&lt;li&gt;由于最终收敛精度会陷入不同的局部极值，因此 Batch_Size 增大到&lt;u&gt;某些&lt;/u&gt;时候，达到最终收敛&lt;b&gt;精度上&lt;/b&gt;的最优。&lt;/li&gt;&lt;/ul&gt;&lt;br&gt;欢迎一起讨论。
&lt;/div&gt;</description><author>程引</author><pubDate>2016-09-20</pubDate></item><item><title>机器学习、深度学习等人工智能技术在工业界的应用状况是怎样的？人力供需状况如何？</title><link>https://www.zhihu.com/question/41012507/answer/106702987</link><description>&lt;div class="zm-editable-content"&gt;&lt;a href="//link.zhihu.com/?target=http%3A//tech.sina.cn/detail.d.html%3FdocID%3Dfxqaffy3552046%26wm%3D3049_0016%26vt%3D4" class=" wrap external" target="_blank" rel="nofollow noreferrer"&gt;李开复:我在硅谷看到了什么？&lt;i class="icon-external"&gt;&lt;/i&gt;&lt;/a&gt;&lt;br&gt;在李开复的关于硅谷前沿科技的这篇文章里提到，深度学习的博士毕业生可以拿到200万美金以上的年薪，很是厉害啊。&lt;br&gt;----&lt;br&gt;本题已收录至&lt;b&gt;知乎圆桌 » &lt;/b&gt;&lt;b&gt;&lt;a href="https://www.zhihu.com/roundtable/alphago-vs-lee" class="internal"&gt;对弈人工智能&lt;/a&gt;&lt;/b&gt;，更多关于&lt;b&gt;李世石对战人工智能&lt;/b&gt;的解读欢迎关注讨论。&lt;/div&gt;&lt;div class="zm-editable-content clearfix"&gt;
国内的情况不了解，本人在东京从事人工智能的工作，日本这边人工智能技术应用于工业界的比较多，随便举几个例子吧：&lt;br&gt;&lt;br&gt;（1）代替肉眼检查作业，实现製造检查智能化和无人化&lt;br&gt;例如工程岩体的分类，目前主要是通过有经验的工程师通过仔细鑑别来判断，效率比较低，并且因人有不同的判断偏差。通过採用人工智能，把工程师的经验转化为深度学习算法，判断的淮确率和人工判断相当。得到对应的权值后开发出APP，这样现场工程人员在使用tablet拍照后，就可以通过APP自动得到工程岩体分类的结果，高效且淮确率高。&lt;br&gt;&lt;br&gt;还有汽车零部件厂商，目前检查生产出的零件磨损种类与等级情况时，多是有经验的人工。同样，通过採用深度学习算法，可以把人工的检测经验转化为算法，从而实现无人化检测。&lt;br&gt;&lt;br&gt;（2）大幅改善工业机器人的作业性能，提升製造流程的自动化和无人化&lt;br&gt;&lt;noscript&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/2ee505389f7a3fdc89be4812c2b64b16_b.jpg" data-rawwidth="800" data-rawheight="533" class="origin_image zh-lightbox-thumb" width="800" data-original="https://pic3.zhimg.com/2ee505389f7a3fdc89be4812c2b64b16_r.jpg"&gt;&lt;/noscript&gt;&lt;img rel="noreferrer"  data-rawwidth="800" data-rawheight="533" class="origin_image zh-lightbox-thumb lazy" width="800" data-original="https://pic3.zhimg.com/2ee505389f7a3fdc89be4812c2b64b16_r.jpg" data-actualsrc="https://pic3.zhimg.com/2ee505389f7a3fdc89be4812c2b64b16_b.jpg"&gt;&lt;br&gt;例如bin picking机器人，工业上有许多需要分捡的作业，如上圖所示的零件分捡，採用人工的话，速度缓慢且成本高，而且还需要提供适宜的工作温度环境（夏天的空调，冬天的暖气等），如果採用工业机器人的话，可以大幅减低成本，提高速度。但是，一般需要分捡的零件是没有整齐摆放的，机器人虽然有camera看到零件，但却不知道如何把零件成功的捡起来。这种情况下，使用机器学习，先让工业随机的进行一次分捡动作，然后告诉它这次动作是成功分捡到零件还是抓空了，经过多次训练之后，机器人会知道按照怎样的顺序来分捡，会有更高的成功率，如下图。&lt;br&gt;&lt;noscript&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/346241d6c0f6b510bc77d42992d19a45_b.jpg" data-rawwidth="800" data-rawheight="533" class="origin_image zh-lightbox-thumb" width="800" data-original="https://pic2.zhimg.com/346241d6c0f6b510bc77d42992d19a45_r.jpg"&gt;&lt;/noscript&gt;&lt;img rel="noreferrer"  data-rawwidth="800" data-rawheight="533" class="origin_image zh-lightbox-thumb lazy" width="800" data-original="https://pic2.zhimg.com/346241d6c0f6b510bc77d42992d19a45_r.jpg" data-actualsrc="https://pic2.zhimg.com/346241d6c0f6b510bc77d42992d19a45_b.jpg"&gt;&lt;br&gt;&lt;noscript&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/34e86b54797982d228372621652808bf_b.jpg" data-rawwidth="800" data-rawheight="533" class="origin_image zh-lightbox-thumb" width="800" data-original="https://pic4.zhimg.com/34e86b54797982d228372621652808bf_r.jpg"&gt;（上面的图片显示，经过机器学习后，机器人知道了分捡时夹圆柱的哪个位置会有更高的捡起成功率）&lt;/noscript&gt;&lt;img rel="noreferrer"  data-rawwidth="800" data-rawheight="533" class="origin_image zh-lightbox-thumb lazy" width="800" data-original="https://pic4.zhimg.com/34e86b54797982d228372621652808bf_r.jpg" data-actualsrc="https://pic4.zhimg.com/34e86b54797982d228372621652808bf_b.jpg"&gt;（上面的图片显示，经过机器学习后，机器人知道了分捡时夹圆柱的哪个位置会有更高的捡起成功率）&lt;br&gt;&lt;noscript&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/e51198d518aae1ffc2b1ba7271a7d3e8_b.png" data-rawwidth="919" data-rawheight="268" class="origin_image zh-lightbox-thumb" width="919" data-original="https://pic1.zhimg.com/e51198d518aae1ffc2b1ba7271a7d3e8_r.png"&gt;（上面的图片表明通过机器学习后，机器人知道按照按照怎样的顺序分捡，成功率会更高，图中数字是分捡的先后次序）&lt;/noscript&gt;&lt;img rel="noreferrer"  data-rawwidth="919" data-rawheight="268" class="origin_image zh-lightbox-thumb lazy" width="919" data-original="https://pic1.zhimg.com/e51198d518aae1ffc2b1ba7271a7d3e8_r.png" data-actualsrc="https://pic1.zhimg.com/e51198d518aae1ffc2b1ba7271a7d3e8_b.png"&gt;（上面的图片表明通过机器学习后，机器人知道按照按照怎样的顺序分捡，成功率会更高，图中数字是分捡的先后次序）&lt;br&gt;&lt;noscript&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/af709798568df18678cb7b78c53cf026_b.jpg" data-rawwidth="596" data-rawheight="658" class="origin_image zh-lightbox-thumb" width="596" data-original="https://pic3.zhimg.com/af709798568df18678cb7b78c53cf026_r.jpg"&gt;&lt;/noscript&gt;&lt;img rel="noreferrer"  data-rawwidth="596" data-rawheight="658" class="origin_image zh-lightbox-thumb lazy" width="596" data-original="https://pic3.zhimg.com/af709798568df18678cb7b78c53cf026_r.jpg" data-actualsrc="https://pic3.zhimg.com/af709798568df18678cb7b78c53cf026_b.jpg"&gt;&lt;br&gt;（上面的图片显示，经过8个小时的学习后，机器人的分捡成功率可以达到90%，和熟练工人的水平相當）&lt;br&gt;&lt;br&gt;（3）工业机器人异常的提前检知，从而有效避免机器故障带来的损失和影响&lt;br&gt;这方面和IoT(Internet of Things)结合比较多。例如在製造流水线上，有大量的工业机器人。如果其中一个机器人出现了故障，当人感知到这个故障时，可能已经造成大量的不合格品，从而带来不小的损失。如果能在故障发生以前就检知的话，可以有效做出预防，减少损失。例如下图的工業机器人减速机和主轴，如果给它们配上sensor，并提前採取它们正常／不正常工作时的波形，电流等信息，用于训练机器学习系统，那么训练出来的模型就可以用来提前预警，实际的数据也表明人工智能会比人更早地预知到故障，从而降低损失。&lt;br&gt;&lt;noscript&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/2c77682f512774c1652fb22e2a685503_b.png" data-rawwidth="928" data-rawheight="628" class="origin_image zh-lightbox-thumb" width="928" data-original="https://pic4.zhimg.com/2c77682f512774c1652fb22e2a685503_r.png"&gt;（上图表明，经过机器学习后，模型通过观测到的波形，可以检知到人很难感知到的细微的变化，并在工业机器人彻底故障的之前的数星期，就提出有效预警）&lt;/noscript&gt;&lt;img rel="noreferrer"  data-rawwidth="928" data-rawheight="628" class="origin_image zh-lightbox-thumb lazy" width="928" data-original="https://pic4.zhimg.com/2c77682f512774c1652fb22e2a685503_r.png" data-actualsrc="https://pic4.zhimg.com/2c77682f512774c1652fb22e2a685503_b.png"&gt;（上图表明，经过机器学习后，模型通过观测到的波形，可以检知到人很难感知到的细微的变化，并在工业机器人彻底故障的之前的数星期，就提出有效预警）&lt;br&gt;&lt;noscript&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/8b633371a1dc4ef8d8f6bb7301b740bb_b.png" data-rawwidth="940" data-rawheight="625" class="origin_image zh-lightbox-thumb" width="940" data-original="https://pic4.zhimg.com/8b633371a1dc4ef8d8f6bb7301b740bb_r.png"&gt;&lt;/noscript&gt;&lt;img rel="noreferrer"  data-rawwidth="940" data-rawheight="625" class="origin_image zh-lightbox-thumb lazy" width="940" data-original="https://pic4.zhimg.com/8b633371a1dc4ef8d8f6bb7301b740bb_r.png" data-actualsrc="https://pic4.zhimg.com/8b633371a1dc4ef8d8f6bb7301b740bb_b.png"&gt;&lt;br&gt;（上图是利用机器学习来提前预警主轴的故障，一般人都是主轴出现问题后才知道）&lt;br&gt;&lt;br&gt;（4）例如工业上的3D模型设计完成后，需要根据3D模型中参数，寻找可对应的现实中的零件，用于製造实际的产品。使用机器学习来完成这个任务的话，可以快速，高匹配率的找出符合3D模型参数的那些现实零件。&lt;br&gt;&lt;noscript&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/5f0c58aaac13b70a376df84d26c5c917_b.jpg" data-rawwidth="980" data-rawheight="229" class="origin_image zh-lightbox-thumb" width="980" data-original="https://pic4.zhimg.com/5f0c58aaac13b70a376df84d26c5c917_r.jpg"&gt;&lt;/noscript&gt;&lt;img rel="noreferrer"  data-rawwidth="980" data-rawheight="229" class="origin_image zh-lightbox-thumb lazy" width="980" data-original="https://pic4.zhimg.com/5f0c58aaac13b70a376df84d26c5c917_r.jpg" data-actualsrc="https://pic4.zhimg.com/5f0c58aaac13b70a376df84d26c5c917_b.jpg"&gt;&lt;br&gt;（上图是根据3D模型设计的参数，机器学习模型计算各个现实零件与这些参数的类似度，从而筛选出匹配的现实零件。没有使用机器学习时，筛选的匹配率大概是68%，也就是说，找出的现实零件中有1/3不能满足3D模型设计的参数，而使用机器学习后，匹配率达到了96%）&lt;br&gt;&lt;br&gt;（5）PCB电路板的辅助设计&lt;br&gt;任何一块印製板，都存在著与其他结构件配合装配的问题，所以，印製板的外形和尺寸，必须以产品整机结构为依据，另外还需要考虑到生产工艺。层数方面，也需要根据电路性能要求，板尺寸和线路的密集程度而定。如果不是经验丰富的技术人员，很难设计出合适的多层板。通过机器学习，可以将技术人员的经验转化为模型，从而提升PCB设计的效率与成功率。&lt;br&gt;&lt;noscript&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/6e1ebd7ee08c659c42addf929f348122_b.jpg" data-rawwidth="980" data-rawheight="316" class="origin_image zh-lightbox-thumb" width="980" data-original="https://pic3.zhimg.com/6e1ebd7ee08c659c42addf929f348122_r.jpg"&gt;&lt;/noscript&gt;&lt;img rel="noreferrer"  data-rawwidth="980" data-rawheight="316" class="origin_image zh-lightbox-thumb lazy" width="980" data-original="https://pic3.zhimg.com/6e1ebd7ee08c659c42addf929f348122_r.jpg" data-actualsrc="https://pic3.zhimg.com/6e1ebd7ee08c659c42addf929f348122_b.jpg"&gt;&lt;br&gt;&lt;br&gt;除了以上的例子，机器学习在日本还有各种各样的应用，如下图中利用机器学习来进行糖尿病的诊断等，准确率很高。&lt;br&gt;&lt;noscript&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/44c50282157231e94dc85b5368f63ffd_b.png" data-rawwidth="800" data-rawheight="471" class="origin_image zh-lightbox-thumb" width="800" data-original="https://pic2.zhimg.com/44c50282157231e94dc85b5368f63ffd_r.png"&gt;&lt;/noscript&gt;&lt;img rel="noreferrer"  data-rawwidth="800" data-rawheight="471" class="origin_image zh-lightbox-thumb lazy" width="800" data-original="https://pic2.zhimg.com/44c50282157231e94dc85b5368f63ffd_r.png" data-actualsrc="https://pic2.zhimg.com/44c50282157231e94dc85b5368f63ffd_b.png"&gt;&lt;br&gt;总结一下，国内的话，人工智能应用于互联网的情况比较多，日本这边的人工智能技术更多是用来服务于製造业的。许多日本製造业公司正在通过人工智能实现製造智能化、最大程度减少人力、提升製造品质。
&lt;/div&gt;</description><author>Tomi</author><pubDate>2016-09-20</pubDate></item></channel></rss>