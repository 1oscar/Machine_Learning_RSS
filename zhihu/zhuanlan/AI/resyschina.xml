<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>ResysChina - 知乎专栏</title><link>https://zhuanlan.zhihu.com/resyschina</link><description>微信公众号 ResysChina，中国最专业的个性化推荐技术与产品社区。更多内容会首发在微信公众号，推荐关注。</description><lastBuildDate>Wed, 28 Sep 2016 00:15:35 GMT</lastBuildDate><generator>Ricky</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>搜索、推荐和广告架构能统一吗？</title><link>https://zhuanlan.zhihu.com/p/22560037</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-167a16ee605ea41a9b27d1ad454cc149_r.jpeg"&gt;&lt;/p&gt;&lt;p&gt;搜索，推荐，广告是互联网时代最主要的三种获取信息方式。如果你了解三个系统的具体实现，甚至自己还分别亲手做过，那么你应该有一种模模糊糊的印象：似乎有些底层的技术和数据是可以共享的啊，但是为什么我们公司是分属三个不同的团队在搞呢？有时候似乎还要打个架什么的。&lt;/p&gt;&lt;p&gt;如果你有这个模模糊糊的印象，那么我告诉你：你不是一个人！Hector Molina在Recsys'14上就提出了将搜索、推荐、广告三合一的观点[1]。同时，在国内的微博上，也因此掀起了一些讨论[2]。微博上的讨论先按下不表，我们先来看看为什么三合一是一种可能的趋势？如果要合，又有哪些困难呢？&lt;/p&gt;&lt;h2&gt;不同与相似&lt;/h2&gt;&lt;p&gt;搜索，推荐和广告本质上都在解决信息过载的问题，各自解决的手段、目标不相同，各自诞生在产品生命周期不同阶段，以至于系统实现不尽相同。&lt;/p&gt;&lt;p&gt;从几个维度对比一下，看看他们不同和相同在哪。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-e4c989986a1e2ed449fc053f70e3da89.png" data-rawwidth="886" data-rawheight="470"&gt;&lt;p&gt;搜索要解决的是精确快速找到想要的结果。最重要的目标是降低延迟和提高相关性。搜索更关注内容消费者，用双手让他们爽。搜索引擎不会像社交网站或资讯网站那样变成time killer，人们依赖搜索而不沉迷搜索就与搜索引擎的目标有关。在搜索解决用户的信息获取需求时，很少给予用户一些惊喜，这也不是搜索的目的，也不会随随便便地利用集体智慧去扩充一些不那么直接相关的结果。&lt;/p&gt;&lt;p&gt;推荐系统则不同，首先很少有靠推荐系统撑起一款产品，大都是起一个“锦上添花”的作用，好的推荐系统都会变成一个time  killer，让用户走进去就不想出来那是坠吼的。推荐系统通常不必须要明确表达需求的“query”，因此在给出的结果中就有很多发挥的余地，可以给用户制造一些惊喜，这一点和搜索很不一样。&lt;/p&gt;&lt;p&gt;根据策略不同，推荐系统有不同的实现方式。比如基于内容的推荐，很接近一个搜索引擎，实际上很多推荐引擎底层的技术实现，尤其是数据存储上大量借鉴了搜索相关技术，比如按照兴趣标签对推荐候选池做倒排索引。另外，搜索是针对个人用户的，一个用户发起一个请求，而推荐系统既可能真对单个用户进行推荐，也可能针对用户群进行推荐。&lt;/p&gt;&lt;p&gt;广告则是一个很特殊的存在，它在产品形式上很像推荐，总是“不请自来”，而在技术实现上又兼有推荐和搜索两者特点，而且它又是一个商业驱动的系统，所以更多关注商业利益最大化。&lt;/p&gt;&lt;p&gt;有一个很有意思的现象，搜索和推荐的信息对象理论上可以共用的，也就是说可以允许用户设置条件检索一堆候选对象，也可以把这些候选对象主动推荐给可能感兴趣的用户面前。但是广告的信息对象却是另一个隔离的存在，为什么不能让用户直接设置条件检索我们的广告库存呢，就像是一个通常的搜索引擎一样？也许是可能的。&lt;/p&gt;&lt;h2&gt;抽象看三者&lt;/h2&gt;&lt;p&gt;这三个系统有这些特点，对于大多数成熟公司，他们已经被把持在三个不同的团队部门手中，各自团队每天在同时填着大同小异的技术坑。&lt;/p&gt;&lt;p&gt;我们抽象一下三者的需求共性：本质上都是在匹配，匹配用户的兴趣和需求（看成context），但匹配的目标，条件和策略不尽相同。&lt;/p&gt;&lt;p&gt;进一步抽象下去，又可以分为三步：过滤候选（filter）+排序候选（ranking）+个性化输出（personalization）。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-cdf03b6e948aa9779ca9df4704e9001f.png" data-rawwidth="953" data-rawheight="625"&gt;&lt;p&gt;过滤候选这一步在搜索里面天经地义，query解析得到查询意图，或者更多结构化的搜索条件，用结构化的查询条件去倒排索引中获取搜索候选。&lt;/p&gt;&lt;p&gt;与之相似的是广告系统，搜索广告也是拿着query去获取候选广告，而联盟广告则是拿着用户标签去需求方获取广告候选。&lt;/p&gt;&lt;p&gt;filter在基于内容的推荐策略中也有类似的过程，而其它推荐策略，比如协同过滤或者隐因子模型，一般是提前计算好的，并没有明显的类似搜索一样的filter，不过我们仍然可以抽象地把各种不同召回策略视为filter这一步，只不过filter并不是同步进行的，而是异步进行的。&lt;/p&gt;&lt;p&gt;ranking这一步主要区别在于排序的目标和约束。搜索的排序目标是高相关性，无论BM25为代表的传统排序模型还是以Learn to rank为代表的机器学习排序，皆如此，用户每次在搜索上花费的时间是不是更少（而不是更多）来衡量搜索的效果。&lt;/p&gt;&lt;p&gt;推荐系统的ranking比较复杂，相关性只是很小的部分，根据推荐系统的产品形式不同，ranking时排序不同。通常推荐系统用CTR预估来融合各种召回策略得到的候选集，如果做得深入，还需要考虑Exploit－Explore问题。附加的约束则千变万化：电商中，当天买过的当天就不能再推了，新闻推荐里，重复的新闻不能再推了，某些场景需要推荐搭配，某些场景需要推荐相似，topN 推荐还需要考虑多样性，序列推荐要考虑前序和后续，etc。&lt;/p&gt;&lt;p&gt;广告系统的排序更多是从经济学角度去看，通常CPC广告的排序方式是结合预估CTR、出价、广告质量三者一起考虑。同时还要考虑很多别的因素，尤其是商业因素，平台方的要求，广告主的要求等等，是一个纯动态博弈，正如微软亚洲研究院的刘铁岩所介绍那样[4]。&lt;/p&gt;&lt;p&gt;personalization最被推荐系统看重，而且在某些场合，个性化一度成为推荐系统的代名词，然而个性化只是推荐系统的衡量指标之一而已，个性化的前提也一定是信息够丰富够垂直才行；搜索的personalization相对来说就粗浅一些，常见的是利用地域等人口统计学来做personalization，而且对于歧义较少的query，搜索如果太个性化既没意义又有风险。&lt;/p&gt;&lt;h2&gt;三者的协同&lt;/h2&gt;&lt;p&gt;虽然事实上三个系统目前是军阀割据，但其业务和技术上已经有很多重叠，也能够产生很多协同作用。&lt;/p&gt;&lt;p&gt;有一部分搜索需求是无法用搜索相关性满足的，比如“一个人的夜晚听什么歌”这样的query，需要推荐系统去满足，交互形式可能是眼下大热的bot，也可能是传统的流推荐等等。如果能够识别出这样的搜索请求，其实更应该交给推荐系统来响应。&lt;/p&gt;&lt;p&gt;推荐系统总体上滞后于用户的即时需求，所以强大如Amazon这样的推荐系统，也是有搜索引擎来与之配合的。一方面，搜索因为能够满足用户的主动寻找需求，所以能够化解一些推荐不力不及时的尴尬；另一方面，搜索可以积累用户兴趣数据；当二者结合起来考虑时，可以避免“搜什么推什么”的窘境，整个系统能够综合考虑哪些是即时快速需求，哪些是长期兴趣。&lt;/p&gt;&lt;p&gt;广告系统，在技术上和搜索跟推荐并无本质差异，差异在意图不同，功能不同。对用户的信息需求满足，搜索和推荐离真正得到满足之间总是有一定的鸿沟，要么是信息不足，要么是信息过载，这些鸿沟可以利用经济手段进行调配，也就是广告系统。&lt;/p&gt;&lt;h2&gt;业界观点&lt;/h2&gt;&lt;p&gt;以上分析只是基于纯粹技术和业务角度的简单分析，结束军阀割据，一统天下似乎是人民的殷殷期盼，然而，这个“人民”似乎只有你我这种站在“上帝视角”的人们。前面提到，之前在微博上，一众从业者集体讨论过这个问题[2][3]，讨论总结为：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;几乎所有人都觉得这个提法是意料之中，也承认三者有统一的概念基础，对此亦有共识；&lt;/li&gt;&lt;li&gt;仅有少数公司（豆瓣）有成功的统一案例，并没有人提出业界还有类似案例；&lt;/li&gt;&lt;li&gt;少数前辈（@清风运文，@张栋_机器学习） 三个系统都经历过，认为实际上困难重重，困难不在框架上，在细节上，各自优化需求差别很大；&lt;/li&gt;&lt;li&gt;还有一些人调侃说来自人的困难大于技术上的困难，这个自己体会不一样，没法写论文。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;总之，从这篇微博看到的讨论来说，几乎都持悲观态度。&lt;/p&gt;&lt;h2&gt;我的看法&lt;/h2&gt;&lt;p&gt;基于以上的讨论观点及事实，虽然业界很悲观，但并不是毫无希望，总结几点：&lt;/p&gt;&lt;p&gt;1. 三者有统一的可能性，而且不低；&lt;/p&gt;&lt;p&gt;2. 在已经被割据的公司里，再重新一统天下非常困难，投入产出比会很低；&lt;/p&gt;&lt;p&gt;如果要统一，从0就开始，所以更适合创业公司或中小公司，可能这也是为什么豆瓣有成功案例的原因；&lt;/p&gt;&lt;p&gt;3. 由于人的因素很重，所以从一开始就应该把三者划归一个团队来统一规划，人员配置上：技术上统一，业务上分开。&lt;/p&gt;&lt;p&gt;4. 必须用数据证明统一之后比统一之前好，而不是工程师自己“感觉不错”，这个“好”可以体现在实际上的业务指标提升，也可以体现在开发效率提升。&lt;/p&gt;&lt;h2&gt;参考文献&lt;/h2&gt;&lt;p&gt;[1] Information Seeking: Convergence of Search, Recommendations and Advertising &lt;/p&gt;&lt;p&gt;[2] &lt;a href="http://ml.memect.com/remix/3783095167238447.html" data-editable="true" data-title="memect.com 的页面"&gt;http://ml.memect.com/remix/3783095167238447.html&lt;/a&gt;&lt;/p&gt;&lt;p&gt;[3] &lt;a href="http://weibo.com/1818327890/ByRGsun39?type=repost" data-editable="true" data-title="看了Hector Molina在Recsys'14上提的Search... 来自Arber"&gt;看了Hector Molina在Recsys'14上提的Search... 来自Arber&lt;/a&gt;&lt;/p&gt;&lt;p&gt;[4] &lt;a href="http://www.msra.cn/zh-cn/jobs/storiesatmsra/tie-yan-liu-20160120.aspx" data-editable="true" data-title="刘铁岩：在微软大学的三次华丽转型" class=""&gt;刘铁岩：在微软大学的三次华丽转型&lt;/a&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;本文作者：&lt;/p&gt;&lt;p&gt;陈开江@刑无刀，资深推荐系统从业者，更多交流可加他个人微信【kaijiang_chen】。添加时请注明：来自ResysChina。&lt;/p&gt;关注 ResysChina 微信公众号，查看更多推荐系统相关内容。&lt;/blockquote&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/22560037&amp;pixel&amp;useReferer"/&gt;</description><author>刑无刀</author><pubDate>Thu, 22 Sep 2016 00:29:46 GMT</pubDate></item><item><title>当我们谈论 Bot 的时候，我们在谈论什么</title><link>https://zhuanlan.zhihu.com/p/21973054</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/6d9b94ba18d9c08df54fcf6a14127ed9_r.jpg"&gt;&lt;/p&gt;进入2016年，Chatbot 无疑已经成为互联网业界和投资领域的热点之一。在短短几个月的时间之内，行业巨头微软、Facebook、亚马逊、Google 和苹果纷纷发布了各自在 Chatbot 领域的战略和相关产品。3月，微软在 BUILD 大会上发布聊天机器人框架 Bot Farmework；4月，Facebook 在 F8大会上展示了 Messenger 平台，Telegram 宣布为机器人开发者设立奖金；5月，Google 在 I/O 大会上正式推出 Google Assistant，同时发布了 Allo Messenger 以及语音家用音箱；Amazon 把智能音箱 Echo 背后的大脑 Alexa 开放出来，让用户可以通过浏览器使用；6月，苹果在 WWDC 大会上开放 iMessage 给第三方集成，并且发布了 Siri SDK；IBM的第一个法律机器人已经被华尔街雇佣；最近，Yahoo 也不甘寂寞在聊天工具中发布了第一款 Chatbot —Kik Messenger。至于 Chatbot 领域的创业公司，更是如雨后春笋般层出不穷。VentureRadar总结了截止到6月份Chatbot 领域最受瞩目的25家创业公司，所处的行业也是五花八门：包括个人助理，客户服务，招聘助手，品牌沟通，虚拟买手，保险代理，以及机器人平台等等，大都拿到了天使或 A/B 轮融资，一派欣欣向荣的景象。 &lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/ff29605194236527f6bfd3572e9fed10.png" data-rawwidth="2560" data-rawheight="1440"&gt;25 Chatbot Startups You Should Know, Andrew Thomson, June 14, 2016, Venture Radar&lt;b&gt;Chatbot 历史&lt;/b&gt;追根溯源，Chatbot 并不是个新鲜的概念。上点儿年纪的 IT 从业者很多都知道 ELIZA，这是上世纪60年代一位 MIT 的教授Joseph Weizenbaum开发的人工智能机器人，可以和人进行简单对话，但更多的时候可能你看到最多的回复是”What are you saying about…” （可以在 GNU Emacs 中运行 M-x doctor 唤出 ELIZA 的一个版本分支DOCTOR）。上个世纪90年代微软为 Office软件配备的虚拟助手 Clippy（回形针），可能是最早大规模推向市场并接触到主流人群的Chatbot原型，它可以在用户使用 office 软件的过程中提供对话形式的帮助，不过很多用户对它的评价是” intrusive and annoying”（冒冒失失令人讨厌），也正是因为反对的声音太多，2003年它就正式下线了。进入二十一世纪，一款名为 A.L.I.C.E (Artificial Linguistic Internet Computer Entity) 的聊天机器人吸引了行业目光，它嵌入了AIML（Artificial Intelligence Markup Language）并结合一系列启发式规则重写了后台的处理引擎，大大改善了对话质量。由于和同类应用相比显著的优势，AliceBot 三次获得了Leobner Prize——机器人领域最重要的奖项之一。遗憾的是，无论是 ELIZA 还是 ALICE，离通过图灵测试都还差得远。任何人跟他们聊上几句就会发现其中的破绽，或者答非所问，或者掉进明显的模式循环之中，感觉都是套路… …由于对话质量不尽如人意，以及应用场景的缺失，Chatbot 在过去的十年间并未吸引太多的注意，仅仅是作为一项有趣的、半科幻的不太成熟的玩具存在着。从2016年3月份开始，如本文开始所提到的，巨头们的介入使得 Chatbot 以一种意想不到的方式迅速成为各个科技媒体和开发者社区讨论的焦点。进入6月份，不光是科技和风投界的媒体，Forbes, Fortune, Financial Times 这些老牌的商业媒体也把目光投了过来，纷纷讨论 Chatbot 的广泛应用到底能够给目前的商业环境带来什么样的影响。难道真的是一夜之间 Chatbot 相关的技术发生了天翻地覆的变化，你手机里的 siri 从一个呆萌的应声虫摇身一变，成为了无所不知无所不能的百事通？先不忙下结论，我们看看过去几年，互联网的商业和技术环境中都发生了什么。 &lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/de7f568a25a7f18d7e3c814d69df38e9.png" data-rawwidth="826" data-rawheight="293"&gt;“chatbot” 在 Google Trends 上的热度随时间变化趋势&lt;b&gt;网络生态与技术变革&lt;/b&gt;过去5年间，消息服务无疑是增长最快的网络应用。内有微信，外有 What’sApp, Facebook Messenger, 月活超过6亿，在过去几年中成功占领了绝大部分用户的碎片时间，成为新的、事实上的移动互联网时代的“浏览器“入口。并且，和 web 时代相比，由于移动应用的封闭性，缺少网页之间彼此互通有无的超链接作为联系纽带，移动互联网环境下的信息孤岛效应更加明显。据统计，当前平均每个用户手机上应用的数量大约是55个，平均每月使用的应用数量大约是23个，每天使用的数量大约是12个。不过，其中大约有一半左右的使用时间给了排第一位的应用，80%的时间给了排前三位的应用。这种比”二八原则“还要夸张的注意力分配还造成了一个尴尬的事实，下载移动应用所带来的流量红利正在慢慢消失，在北美市场，2015年5月到2016年5月全年的移动应用下载量比前一年下降了20%（全球的数字为增加2%，主要由新兴市场贡献），并且，大约有65%的用户在过去一个月中没有下载任何应用。在这样的大趋势下，大家意外的发现，Chatbot 似乎可以解决 App 生态环境面临的一系列困境。Chatbot 开发成本低，而且是真正的跨平台，不必考虑 Android/iOS资源的投入。其次，在移动时代成长起来的用户天然接受即时消息通讯的方式，进入门槛低、粘性高，依附于大的平台，似乎是可以绕开 APP 越来越低的下载率和活跃度的问题。消息服务作为 Chatbot天然的载体，俨然已经成为移动生态环境的基础设施；那么，Chatbot 作为消息服务之上最自然的应用，会不会取代 App，构建出自己的生态环境？ &lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/88449ca08d5f27dfa51c880c8168f2e8.png" data-rawwidth="592" data-rawheight="302"&gt;Source: Business Insider, Fortune, Mashable, AppAnnie, AdWeek, Quartz, Yahoo Finance, Experian, TechCrunch, Forbes, Tehc in Asia, eMarketer, Compete, Activate analysis在技术层面，人工智能以一种出人意料的方式重回大众视野。2016年3月，Google Deep Mind AlphaGo 在五番棋中以压倒性的优势击败世界冠军李世石，人工智能在围棋领域战胜人类顶尖棋手，这在5年前还是遥不可及的梦想，如今却成为现实。事实上，自上世纪五十年代现代意义的人工智能诞生以来，已经至少经历过两次大起大落，也分化出大大小小各种流派，在最近一次低潮期，从业者们甚至更愿意用“数据挖掘”、“知识推理”、“机器学习”或“统计学习”这样的字眼来指代自己的工作，小心的避免使用“人工智能”这样过于耀眼承载了太多希望的词语。2006年至今深度学习技术的飞速进展，无疑是当前这次人工智能崛起的最重要基石。多层神经网络在计算机视觉和语音识别领域已经取得突破性进展，在效果上比之前的方法有了质的飞跃。比如在图像识别领域的 ImageNet 竞赛中，2012年Hinton 研究小组利用 GPU 跑的深度卷积神经网络算法远远超过了原有的各种机器学习方法，识别率甚至超过了人类。包括原本认为很难突破的围棋，机器在原本人类擅长的领域表现得更加优异，所带来的心理冲击无疑是全方位的。验证了深度学习的威力之后，人们自然而然的希望扩展到各个领域，特别是一直自成体系，也公认难度很高的自然语言处理。自从现代计算机概念诞生的第一天开始就对人类的语言处理问题有着强烈的兴趣，著名的图灵测试，也是围绕着测试者能够在多大程度上区分机器还是人类产生的语言来设计的。而 Chatbot 所做的事情，恰好综合了自然语言处理技术的各个方面。借人工智能崛起的这一波东风，一举突破当前在 Chatbot 领域面临的各种瓶颈，甚至通过图灵测试，也似乎不再是遥不可及的事情。此外，自然语言作为人机交互界面，这无疑是比从鼠标键盘到触摸屏还要令人激动的巨大变革，彻底把各种智能设备的使用门槛降低为零。并且，如果能够在理解文本语义的基础上自动进行下一步动作，很多繁琐、重复的文字类的人工劳动将被自动化的机器取代，释放出的市场潜力无疑是非常巨大的 — —这会不会是”The next big thing”？看起来市场环境和技术各自沿着自己的轨道向前发展，在这个时间点双方交汇到了一个点上。也正是因为这样的原因，在 Chatbot 领域巨头们争相投入，从前沿的算法研究到底层的基础设施平台搭建，从面向普通用户的最终应用到面向开发者的一线列工具，迅速成型并投入使用，唯恐在未来的竞争中落了后手。无论前景如何，从客观上来看，至少目前我们能够便捷的使用一系列平台和工具，使用这些工具，搭建一个 Chatbot 要比开发一个移动应用、或者是建个网站快得多。&lt;b&gt;Chatbot 相关技术&lt;/b&gt;从应用的场景来看，Chatbot 可以分为开放域（Open-Domain）问题和封闭域（Closed-Domain）问题两大类。开放域问题和图灵测试更接近，也更困难。没有任何限定的主题或明确的目标，用户和Chatbot 之间可以进行任何话题的自由对话。可想而知，由于话题内容和形式的不确定性，开放域 Chatbot要准备的知识库和模型要复杂很多。并且，从实际的应用场景来看，开放域 Chatbot 更多应用在聊天、虚拟形象等泛娱乐领域，虽然用户基数比较大，也容易传播，但由于目的性不强、内容深度不够、对话质量不高等等一系列问题，用户粘性有限、商业价值较低，至少在目前的市场环境和技术水平之下，看不到明确的应用前景和清晰的商业模式。和开放域问题不同，封闭域问题通常有若干明确的目标和限定的知识范围，也就是说，Chatbot 所面临的输入和输出通常是有限的。虽然这个限定范围会随着问题领域以及对推理深度要求的不同变化很大，但无论如何，与开放域问题相比，问题空间大大缩小，目标也更加清晰明确。特别是从应用场景上来看，用户不会期待和一个客服机器人谈论历史知识，也不会向一个电商导购机器人提各种与购物无关的刁钻古怪的问题。并且，更加垂直和场景化的应用使得封闭域的 Chatbot从诞生的第一天开始就肩负了商业使命，无论是节省人力成本还是提升人工效率，问题的定义和评判标准都是比较清晰和明确的。不过，也正是因为如此，封闭域问题 Chatbot 对对话错误的容忍度更低、对质量要求更高，这就要求Chatbot 能够整合更多的领域知识、用户的基本信息，以及对上下文语境的分析和判断。并且，针对一个领域建立的模型和知识图谱，往往是很难方便的迁移到另外的领域。在这些因素的共同作用下，建立一个封闭域的 Chatbot 就不再单单是一个技术问题，而是融合了商业、产品、运营、数据知识积累和模型调优等等方方面面的权衡和综合考量。从表现形式看，Chatbot可以分为单轮对话和多轮对话两种类型。单轮对话其实可以看做是问答系统（Question Answering System）的变形， 一般是一问一答的形式，用户提问，机器生成相应答案的文本或者是综合与答案相关的各种信息返回给用户。多轮对话则更接近我们通常理解的人与人之间的对话模式，通常是有问有答，除了用户提问，机器也会主动向用户询问，并且会根据上下文来判断该给出什么样的答案或提出什么样的问题。从应用的角度来看，单轮对话更适合使用在信息查询、客户服务、产品介绍等等目标明确、会话行程短的浅服务类项目，用户对通过使用这类产品获得的服务有明确的预期，更多的是把它看做快速获取信息、提升效率的入口。而多轮对话服务，往往会应用在信息搜集、商品和服务导购推荐、专业方案咨询等等一系列结构复杂、会话行程长的深度服务项目里，用户通过使用这类产品会在某一领域获得相对完整的服务，解决一个复杂问题，或者获得某种方向性的引导。一般来说，企业使用多轮对话服务的目标不仅仅是提升效率降低成本，还往往可以改进产品质量带来更多的收入。从技术的角度看，实现一个 Chatbot 也可以大致分为基于检索的模型和生成模型两种方案。基于检索的模型在算法流程和结构上相对更容易理解，在很大程度上和搜索引擎的技术实现类似。一方面事先定义好了问题库和答案知识库或回答的模板，另一方面通过 NLP 技术对用户提出的问题进行分析，通过关键词提取、倒排索引、文档排序等等方法与定义好的知识库进行匹配，并返回给用户。事实上，的确有一些 Chatbot 项目就是用开源搜索引擎来实现的。 在规则匹配和文档排序上可以加入各种复杂的启发式规则或者机器学习算法，从而提高匹配精度。并且，在知识库上还可以嵌入知识发现和推理机制，提升对话质量。于此相反，生成模型通常不依赖于特定的答案库，而是依据从大量语料中习得的“语言能力”来进行对话，看起来这个过程更加接近人类思考和产生语言的过程。而这个“语言能力”，往往涉及到基本语言元素的知识表示、以某种结构（比如深度神经网络）来模拟的语言模型，以及对生成的语言对象的评价和选择标准。两种模型有各自的优劣，对于领域范围清晰、指向明确的问题，基于检索的模型的对话质量更高。并且，基于检索的模型不会犯各种语法错误，但它的回答很难跳出预定的答案库，需要花费很大的精力来维护更新知识库和匹配规则。生成模型直接从语料来训练知识表示和语言模型，可以有效降低维护问答库和规则的精力；同时，生成模型可以应对各种不在预设的问题库的问题，表现形式更加灵活。但是，好的生成模型往往需要巨大规模的训练语料，并且，对话中的上下文关系、信息和人格的一致性、以及关键意图识别等等一系列问题都是生成模型需要克服的难关。早期 Chatbot 领域的架构几乎都是基于检索模型的，但深度学习技术取得突破性进展之后，越来越多的研究者和业界的工程师把目光转向了生成模型，因为深度学习的 Sequence-to-Sequence方式可以非常好的实现生成模型的框架。深度学习有一个非常诱人的优势，就是拥有可以避免人为特征工程的端到端（End-to-End）框架。通俗地讲，就是有机会利用深度学习强大的计算和抽象能力，自动从海量的数据源中归纳、抽取对解决问题有价值的知识和特征，使这一过程对于问题的解决者来说透明化，从而规避人为特征工程所带来的不确定性和繁重的工作量。例如 AlphaGo 在提升围棋水平的过程中，并没有像传统围棋程序那样硬编码大量的布局定式、死活类型和官子技巧，而是直接通过学习高质量棋谱（以及通过增强学习自身产生的棋谱）提升水平。具体到 Chatbot 领域，这让我们能够设想只要有足够多的对话语料，就可以利用端到端框架直接进行训练，而不必考虑复杂的语法规则、微妙的对话情景等等一系列人为特征工程需要关注的焦点。这无疑代表了大家都希望追寻的美好前景。 &lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/e3718cf9fd4a78603204cbfe01df7b51.png" data-rawwidth="1323" data-rawheight="780"&gt;来源： 爱因互动，EinBot Conversation Generating Framework&lt;b&gt;问题与展望&lt;/b&gt;不过，在巨头重金压注、风投界推波助澜和科技媒体摇旗呐喊的背景之下，也有一些冷静的观察者指出了一个基本事实，那就是目前 Chatbot 能够做的事情还相当有限，整体的用户体验依旧和合格的 APP 相去甚远。TechCrunch在最近的一篇文章中指出：“关于 Chatbot，看见的 demo 都很好，但这些 demo 都忽视（或者是故意不提）关键的一点——很多 APP 尤其是好用的 APP，通常并不需要涉及那么多输入，往往滑一滑、点一点就可以了... … 现阶段，很多 Chatbot 还不支持语音，因此你得手动输入文字，这样做还不如直接用 APP 省事。此外，很多时候 chatbot 搞不懂你的意思，意味着你得多次重新输入，改换表述让 chatbot 理解你的意思”这段描述点明了 Chatbot 目前在具体的应用环境中面临的两大困境：一方面在许多场景下APP的操作更加简单，Chatbot并未体现出以自然语言作为交互界面的优势。另一方面，对于机器理解人们日常使用的自然语言这件事情，事实上我们与几年前相比并未取得明显的进步，也就是说，目前的聊天机器人，还没那么“智能”，远远达不到人们对流畅对话的期待。比如下面这个 Facebook Messenger 上面颇为流行的查询天气的机器人 Poncho 和用户之间的对话： &lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/1b2b4ec80c8a5f06dccbdf316f340fa9.png" data-rawwidth="1200" data-rawheight="1068"&gt;从中可以看出，对于语法结构完整、指向明确的问题，Poncho 能够给出相应的回答；但稍微发挥一点，省略语法结构，它就难以领略用户的真正意图，迷失在语境之中了。明显可以看出，Poncho对上下文的理解是割裂的，仅仅是理解简单的天气查询也这样困难，更不用说很多需要复杂的语义和逻辑执行的问题了，这也是Chatbot 普遍面临的难题。在Chatbot 所面临的两个困境之中，第二个问题，也就是对话的质量，是最关键的，因为本质上来讲，第一个问题的解决在很大程度上依赖于我们对第二个问题的解决有多成功。试想，对于指令性的和获取信息类的操作，有什么是比自然语言作为交互界面更合适的呢？一个能够完整、准确的理解自然语言的 Chatbot 无疑能让我们放弃在界面和交互设计上所花费的额外的心思，更加贴近问题和产品的本质，贴近需求本身和用户价值。因此，无论业界和媒体在这件事情上怎样的风生水起，无论巨头和创业公司面对用户许下怎样的美好未来，能否兑现承诺，取决于我们在机器理解人类自然语言这件事情上能否取得真正的突破，哪怕是在特定的领域、特定的场景下，能否诞生不低于人和人之间平均对话质量的应用。客观来看，强 AI、顺利通过图灵测试的机器，这些科幻小说中的场景看起来依旧不会是短期内能够发生的事情，Chatbot 领域工业界的先行者们更愿意从解决具体的问题入手，一点一滴的积累经验。比如在行程规划、个人助理、售前咨询、客户服务等领域，都有不少朝气蓬勃的创业公司在深入的研究用户需求，搭建技术基础设施、开发相关的 Chatbot 产品。虽然这些 Chatbot 所提供的对话质量和服务还不能完全令人满意，但至少这些探索和尝试对提升产品体验、吸引用户关注和教育市场起到了相当有益的作用。无论如何，知识自动化和更加自然的人机交互这一趋势无可避免，由此带来了机器智能的两大应用场景：要么协助或替代人力的知识产生和传播过程，要么更好的服务于这些被替代下来的人们。相信这些都将是无比广阔的市场和商业机会，Chatbot 能不能引领我们，敲开这扇大门？&lt;b&gt;参考资料&lt;/b&gt;How Chatbots And Deep Learning Will Change The Future Of Organizations，Daniel Newman，Forbes，June 28，2016The Rise of the Chatbots: Is It Time to Embrace Them?, knowledge@Wharton, June 9, 2016Deep Learning for Chatbots, Part 1 – Introduction, April 6, 2016,  Denny Britz, WildMLDeep Learning for Chatbots, Part 2 – Implementing a Retrieval-Based Model in TensorFlow, July 4, 2016,  Denny Britz, WildML&lt;p&gt;关注 ResysChina 微信公众号，回复“bot”可以查看更多聊天机器人相关内容。&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/21973054&amp;pixel&amp;useReferer"/&gt;</description><author>王守崑</author><pubDate>Thu, 11 Aug 2016 18:33:11 GMT</pubDate></item><item><title>少数人的智慧</title><link>https://zhuanlan.zhihu.com/p/21875823</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/f9eb1b6af438ad745d3fc9145bb4580c_r.jpg"&gt;&lt;/p&gt;&lt;p&gt;在写完《&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA4OTk5OTQzMg==&amp;amp;mid=2449231283&amp;amp;idx=1&amp;amp;sn=3d5f5989896a2b7be52558c9cc56e855&amp;amp;scene=21#wechat_redirect" data-editable="true" data-title="Quora是如何做推荐的"&gt;Quora是如何做推荐的&lt;/a&gt;》一文之后，我在思考一个问题：伴随着Quora、知乎这样的知识分享型社区的兴起，涌现了一大批各个领域的专家用户，这会对推荐系统带来哪些可能的变化呢？恰好今天在读马尔科姆·格拉德威尔的&lt;a href="https://www.amazon.cn/gp/product/B00JA4TFD0/ref=as_li_tf_tl?ie=UTF8&amp;amp;camp=536&amp;amp;creative=3200&amp;amp;creativeASIN=B00JA4TFD0&amp;amp;linkCode=as2&amp;amp;tag=resyschina-23" data-editable="true" data-title="《眨眼之间》" class=""&gt;《眨眼之间》&lt;/a&gt;这本书的时候，看到了这么一段，&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;当我们在某一方面修炼到登堂入室的程度时，我们的品味会变得愈发专业精深、愈发让外行难以理解。也就是说，&lt;strong&gt;只有专家才能对自己的反馈信息和看法负起责任。&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;我忽然想起来我在09年写过一篇blog《The Wisdom of the Few》，正好和这个事情特别相关。《The Wisdom of the Few》是来自Telefonica Research的一篇论文，《The Wisdom of the Few: A Collaborative Filtering Approach Based on Expert Opinions from the Web》[1]。我当年是在SIGIR'09里面发现的，觉得很有意思。这篇论文的核心内容非常简单，主要方式是对比分析，结论也挺中肯的。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;首先定义「专家/Expert」，他们必须是这样的一群人：在一个特定的领域内，能对该领域内的条目给出深思熟虑的、一致的、可靠的评价（打分）。&lt;/strong&gt;[2]&lt;/p&gt;&lt;p&gt;1）通过对 Netflix Users vs. Experts（作者自己收集的）的数据进行对比分析&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Number of Ratings and Data Sparsity&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Average Rating Distribution&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Rating Standard Deviation (std) &lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;得出结论认为，&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;专家打分数据的稀疏性要好得多。&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;专家的打分对象更全面&lt;/strong&gt;，好的坏的，流行的冷门的，都会涉及到；而不像大众打分会倾向于流行的和自己喜欢的。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;对好电影的评价专家们更趋一致。&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;对于每单个电影的评价，&lt;strong&gt;专家们的分歧也相对更小&lt;/strong&gt;。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;对于每单个用户和专家的对比，&lt;strong&gt;专家给出的打分更为稳定&lt;/strong&gt;。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;2）进行 Nearest-Neighbor CF vs. Expert CF 的推荐效果对比，主要评价「准确性/MAD」和「覆盖率/Coverage」两个指标，&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/42cbeec6e7c26423ddd508a24bc39156.png" data-rawwidth="836" data-rawheight="384"&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;推荐准确性，NN-CF 差不多比 Expert-CF 要好 10%。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;推荐覆盖率，Expert-CF 差不多比 NN-CF 要高 10%。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;有意思的是上面的右图，用户分布与推荐准确性的关系，&lt;/p&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;在 MAE &amp;lt; 0.5 时，两种方法覆盖的用户数差不多&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;差不多在 MAE = 0.5 时，NN-CF 比 Expert-CF 多 10%&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;之后 MAE 在 [0.5, 1.0] 区间内时，NN-CF 与 Expert-CF 几乎平行&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;这个意思是说，与 Expert-CF 相比，NN-CF 仅对少部分用户（MAE&amp;lt;0.5的用户，占总数的10%）有明显优势。而这部分用户又可以认为是可预测性很高的用户，Expert-CF 比较容易利用其他方法提高效果。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;p&gt;结论是，&lt;strong&gt;Expert-CF 大多数情况下与 NN-CF 效果相当。&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;3）进行 Nearest-Neighbor CF vs Expert CF 的推荐效果的用户调研，推荐系统最终是为用户服务的，用户说好才是真的好！&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/6f52f0fbc30339f1adde0d3252e78b7b.png" data-rawwidth="613" data-rawheight="296"&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Random，随机生成的推荐列表。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Critics' Choice，Experts 平均打分比较高的影片组成的推荐列表。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;kNN-CF/Experts-CF，文中两种算法生成的推荐列表。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;左图是用户满意度，调查推荐列表里是否包含用户喜欢的影片。两个评价指标，包含喜欢影片的多少，及是否有惊喜。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;右图是用户反感度，调查推荐列表里是否包含用户讨厌的影评。两个评价指标，包含讨厌影片的多少，及讨厌程度。推荐系统里面有句名言，「错误的推荐还不如不推荐」。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;结论是，&lt;strong&gt;Experts-CF 的用户满意度更高。&lt;/strong&gt;当然了，这个结论的现实性是有一些争议的，比如，参与用户的数量很少，且大多数是男性用户。不过论文作者在这方面都有提到，比较中肯。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;证明了 Expert-CF 的可用性之后，吸引人的是这个方法相对传统CF方法，能够带来的好处。&lt;/p&gt;&lt;p&gt;1、Data  Sparsity，&lt;strong&gt;数据稀疏性&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;专家的打分数据数据通常涵盖面更广，使用这个数据作推荐，解决了传统 CF 的数据稀疏问题。&lt;/p&gt;&lt;p&gt;2、Noise and Malicious Ratings，&lt;strong&gt;噪音及恶意打分&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;专家的打分通常更加认真或是专业，解决了用户不小心打错分及恶意捣乱的问题。&lt;/p&gt;&lt;p&gt;3、Cold Start Problem，&lt;strong&gt;冷启动问题&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;专家通常更加关注自己领域内的新事物，并能够更快地给出评价。&lt;/p&gt;&lt;p&gt;4、Scalability，&lt;strong&gt;可扩展性&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;对于 (N-User, M-Item) 的推荐问题，传统 NN-CF 的算法复杂度是 O(N2M)，计算量很大。而Expert-CF方法可以大幅度降低计算成本。比如论文里的数据，169 experts vs. 500, 000 potential neighbors (Netflix database)。&lt;/p&gt;&lt;p&gt;5、Privacy，&lt;strong&gt;用户隐私&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;如何更好地保护用户隐私，一直是推荐系统领域的一个热点问题。比如，基于Expert-CF方法，可以把一小撮专家打分数据下载到手机上，进行本地计算，然后得到推荐结果，而避免把过多的数据都存储在应用服务商的服务器上。&lt;/p&gt;&lt;p&gt;当年我这篇blog发出之后，在推荐圈引发了一些小讨论，当年还是豆瓣算法组小鲜肉现在已经成为机器学习大牛的阿稳同学也给出了自己的解读。[2]&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;之所以要提出专家CF的算法取代传统的CF，是基于传统CF的一些弊病，比如数据的稀疏性，数据噪声以及计算量的庞大等等，而正是这些数据上的原因导致传统CF算法推荐多样性不足、推荐不准确以及推荐可扩展性不良好等种种问题。这里提出的专家CF算法目的并不在于在某些数学精度指标上压倒传统的CF算法，而希冀能探究如下几个问题：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;一个庞大的用户集合的偏好是否可以通过一个比较小的用户集合的偏好预测出来；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;对于一个源数据集来说，另一个与之不同源的、无直接相关的数据集是否具有对它进行推荐的能力；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;分析专家的收藏是否可以用作普通用户的推荐；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;探讨专家CF是否能解决传统CF的一些难题。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;看这篇文章，更多的是看文中阐述的思想，虽然这可能并不是他们首创的，但毕竟他们作了一个很好的总结与分析。我一直在思索我们到底需要什么样的推荐，最近我觉得：&lt;strong&gt;至少在大部分的场合，我们需要的并不是与自己相似的用户的推荐，而是与自己相似的专家的推荐。无论是看书、看电影、买手机、买笔记本，那批「行内人物」的观点往往是左右我们决定的主要因素。这个结论在个性化要求相对比较低的中国显得更为真实。&lt;/strong&gt;&lt;/blockquote&gt;&lt;p&gt;在这篇论文里，作者并没有详细地探讨如何从数据中发现一批领域专家，他们挑选的是一批来自从烂番茄网站爬取的现成的电影评论专家。这也是当年使用这个方法的一个难题，去哪里找到这些各个领域的专家。而如今7年过去了，Quora、知乎、微博、包括各个垂直专业领域的自媒体的崛起，几乎已经让这个问题迎刃而解。&lt;/p&gt;&lt;p&gt;类似于SaaS，目前又有个提法叫做「数据即服务」。留个讨论，你认同DaaS吗，和本文的方法结合这里面可能有什么机会呢？一起开开脑洞吧。&lt;/p&gt;&lt;p&gt;参考资料：&lt;/p&gt;&lt;p&gt;[1] &lt;a href="http://www.nuriaoliver.com/recsys/wisdomFew_sigir09.pdf"&gt;http://www.nuriaoliver.com/recsys/wisdomFew_sigir09.pdf&lt;/a&gt;&lt;/p&gt;&lt;p&gt;[2] &lt;a href="http://blog.sciencenet.cn/blog-64458-372804.html"&gt;http://blog.sciencenet.cn/blog-64458-372804.html&lt;/a&gt;，阿稳的blog已经访问不了了，只能放这个转载了。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;推荐关注微信公众号【ResysChina】，中国最专业的个性化推荐技术与产品社区。更多内容会首发在微信公众号。&lt;/p&gt;&lt;p&gt;★ 猜你喜欢：「&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA4OTk5OTQzMg==&amp;amp;mid=2449231335&amp;amp;idx=1&amp;amp;sn=d3ba98841e85b7cea0049cc43b3c16ca#rd"&gt;基于Deep Learning的中文分词尝试&lt;/a&gt;」&lt;/p&gt;&lt;/blockquote&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/21875823&amp;pixel&amp;useReferer"/&gt;</description><author>谷文栋</author><pubDate>Fri, 05 Aug 2016 01:02:44 GMT</pubDate></item><item><title>推荐系统的苟且和远方</title><link>https://zhuanlan.zhihu.com/p/21840306</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/be39bbe37297171cbb73d1fb1c41e63e_r.jpg"&gt;&lt;/p&gt;&lt;h2&gt;苟且和远方&lt;/h2&gt;&lt;p&gt;提到推荐系统，你们会首先想到什么？&lt;/p&gt;&lt;p&gt;产品和运营们首先想到的就是打标签，而做过的人还会想到协同过滤（collaborative  filter，下面简称CF）。&lt;/p&gt;&lt;p&gt;是的，CF几乎是推荐系统发展史上浓墨重彩的一笔，其背后的思想简单深刻，在万物互联的今天，协同过滤的威力更加强大。CF看上去是一种技术，不如说是一种方法论，不是机器在给你推荐，而是“集体智慧”在给你推荐。&lt;/p&gt;&lt;p&gt;CF的基本假设就是“物以类聚，人以群分”，你的圈子决定了你能见到的物品。这很靠谱，但是却隐藏了一些重要的问题：作为用户的我们还可能看到新的东西吗？还可能有惊喜吗？还可能有圈子的流动吗？&lt;/p&gt;&lt;p&gt;是咯，我就知道你会提出这么精妙的问题，要不然也不会有这篇文章了。毕竟你我都曾经站在高高的谷堆上唱过：“推荐系统不是只有眼前的苟且，还有诗和远方的田野”。这也是在推荐和广告界被大量研究的EE问题（Exploit &amp;amp; Explore），Exploit就是眼前的苟且，Explore就是诗和远方的田野。&lt;/p&gt;&lt;p&gt;做Explore的方法有很多，bandit算法是其中的一种流派。前面也介绍过几种bandit算法，基本上就是估计置信区间的做法，然后按照置信区间的上界来进行推荐，以UCB,LinUCB为代表。&lt;/p&gt;&lt;p&gt;作为要寻找诗和远方的bandit浪漫派算法，能不能和CF这种名门望族结合起来呢？事实上已经有人这么尝试过了，前阵子在arxiv看到一篇论文，题目是Collaborative Filtering Bandits[1]，arxiv上还有另一篇是同一作者先前的尝试（Online Clustering of Bandits）[2]，两者的区别是后者只对用户聚类（即只考虑了User-based的协同过滤），而前者采用了协同聚类（co-clustering，可以理解为item-based和user-based两种协同方式在同时进行），后者算是前者的一个特殊情况。今天我们就一起来开拓一下思路，看看Collaborative Filtering Bandits这篇文章是如何把CF和Bandit结合起来的。&lt;/p&gt;&lt;h2&gt;bandit怎么结合CF&lt;/h2&gt;&lt;p&gt;很多推荐场景中都有这两个规律：&lt;/p&gt;&lt;p&gt;1. 相似的用户对同一个物品的反馈可能是一样的。也就是对一个聚类用户群体推荐同一个item，他们可能都喜欢，也可能都不喜欢，同样地，同一个用户会对相似的物品反馈相同。这是属于CF可以解决的问题；&lt;/p&gt;&lt;p&gt;2. 在使用推荐系统过程中，用户的决策是动态进行的，尤其是新用户。这就导致无法提前为用户准备好推荐候选，只能“走一步看一步”，是一个动态的推荐过程。&lt;/p&gt;&lt;p&gt;这篇文章就提出，每一个推荐候选item，都可以根据用户对其偏好不同（payoff不同）将用户聚类成不同的群体，一个群体来集体预测这个item的可能的收益，这就有了协同的效果，然后再实时观察真实反馈回来更新用户的个人参数，这就有了bandit的思想在里面。&lt;/p&gt;&lt;p&gt;举个例子，如果你父母给你安排了很多相亲对象，要不要见面去相一下？那需要提前看看每一个相亲对象的资料，每次大家都分成好几派，有说好的，有说再看看的，也有说不行的；你自己也会是其中一派的一员，每次都是你所属的那一派给你集体打分，因为他们是和你“三观一致的人”，“诚不欺我”；这样从一堆资料中挑出分数最高的那个人，你出去见TA，回来后把实际感觉说给大家听，同时自己心里的标准也有些调整，重新给剩下的其它对象打分，打完分再去见，周而复始......&lt;/p&gt;&lt;p&gt;以上就是CF和bandit结合的思想。&lt;/p&gt;&lt;p&gt;另外，如果要推荐的候选item较多，还需要对item进行聚类，这样就不用按照每一个item对user聚类，而是按照每一个item的类簇对user聚类，如此以来，item的类簇数相对于item数要大大减少。&lt;/p&gt;&lt;h2&gt;COFIBA算法&lt;/h2&gt;&lt;p&gt;基于这些思想，文中设计的算法COFIBA（读作coffee bar），简要描述如下：&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;在时刻t，有一个用户来访问推荐系统，推荐系统需要从已有的候选池子中挑一个最佳的物品推荐给他，然后观察他的反馈，用观察到的反馈来更新挑选策略。&lt;/p&gt;&lt;p&gt;这里的每个物品都有一个特征向量，所以这里的bandit算法是context相关的。&lt;/p&gt;&lt;p&gt;这里依然是用岭回归去拟合用户的权重向量，用于预测用户对每个物品的可能反馈（payoff），这一点和我们上一次介绍的linUCB算法是一样的。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;对比上一次介绍的LinUCB算法，COFIBA的不同有两个：&lt;/p&gt;&lt;p&gt;1. 基于用户聚类挑选最佳的item（相似用户集体决策的bandit）&lt;/p&gt;&lt;p&gt;2. 基于用户的反馈情况调整user和item的聚类（CF部分）&lt;/p&gt;&lt;p&gt;整体算法过程如下：&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/6f70398fb425c94d4891af9e28032dc4.png" data-rawwidth="712" data-rawheight="1206"&gt;&lt;p&gt;对关键部分用人话来说就是：&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;在针对某个用户i，在每一轮试验时做以下事情：&lt;/p&gt;&lt;p&gt;1. 首先计算该用户的bandit参数W（和LinUCB相同），但是这个参数并不直接参与到bandit的选择决策中（和LinUCB不同），而是用来更新用户聚类的；&lt;/p&gt;&lt;p&gt;2. 遍历候选item，每一个item表示成一个context向量了。&lt;/p&gt;&lt;p&gt;3. 每一个item都对应一套用户聚类结果，所以遍历到每一个item时判断当前用户在当前item下属于哪个类簇，然后把对应类簇中每个用户的M矩阵(对应LinUCB里面的A矩阵)，b向量（payoff向量，对应linUCB里面的b向量）聚合起来，从而针对这个类簇求解一个岭回归参数（类似LinUCB里面单独针对每个用户所做），同时计算其payoff预测值和置信上边界&lt;/p&gt;&lt;p&gt;4. 每个item都得到一个payoff预测值及置信区间上界，挑出那个上边界最大的item推出去（和LinUCB相同）&lt;/p&gt;&lt;p&gt;5. 观察用户的真实反馈，然后更新用户自己的M矩阵和b向量（更新个人的，对应类簇里其他的不更新）&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;以上是COFIBA算法的一次决策过程。在收到用户真实反馈之后，还有两个计算过程：&lt;/p&gt;&lt;p&gt;1. 更新user聚类&lt;/p&gt;&lt;p&gt;2. 更新item聚类&lt;/p&gt;&lt;p&gt;如何更新user和item的聚类呢？文章中给出了一个示意图：&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/1d4d1fc1bcae659dc8ac408a6dceb346.png" data-rawwidth="1252" data-rawheight="1032"&gt;&lt;p&gt;解释一下这个图。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;(a) 这里有6个user，8个item，初始化时，user和item的类簇个数都是1&lt;/p&gt;&lt;p&gt;(b1) 在某一轮试验时，推荐系统面对的用户是4。推荐过程就是遍历1～8每个item，然后看看对应每个item时，user4在哪个类簇中，把对应类簇中的用户聚合起来为这个item预测payoff和CB。这里假设最终item5胜出，被推荐出去了。&lt;/p&gt;&lt;p&gt;(b2) 在时刻t，item有3个类簇，需要更新的用户聚类是item5对应的user4所在类簇。更新方式：看看该类簇里面除了user4之外的用户，对item5的payoff是不是和user4相近，如果是，则保持原来的连接边，否则删除原来的连接边。删除边之后重新构建聚类结果。这里假设重新构建后原来user4所在的类簇分裂成了两个类簇：{4,5}和{6}&lt;/p&gt;&lt;p&gt;(c) 更新完用户类簇后，item5对应的类簇也要更新。更新方式是：对于每一个和item5(被推荐出的那个item)还存在连接边的item j，都去构造一个user的近邻集合N，这个集合的用户对item j有相近的payoff，然后看看N是不是和刚刚更新后的user4所在的类簇相同，是的话，保留item5和item j之间的连接边，否则删除。这里假设item 3和item 5之间的连接边被删除。item3独立后给他初始化了一个聚类结果：所有用户还是一个类簇。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;简单来说就是这样：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;User-based协同过滤来选择要推荐的item，选择时用了LinUCB的思想&lt;/li&gt;&lt;li&gt;根据用户的反馈，调整User-based和Item-based的聚类结果&lt;/li&gt;&lt;li&gt;Item-based的聚类变化又改变了User的聚类&lt;/li&gt;&lt;li&gt;不断根据用户实时动态的反馈来划分User-Item矩阵&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;cofiba算法也很容易实现，github上就有[3]。论文也从理论和实验两方面证明了它的有效性，但是能否在实际项目中用上，仍然存疑，毕竟复杂度不低。&lt;/p&gt;&lt;h2&gt;关于EE问题的思考&lt;/h2&gt;&lt;p&gt;之所以想写bandit算法系列，是因为Exploit-Explore这一对矛盾一直客观存在，而bandit算法是公认的一种比较好的解决EE问题的方案。除了bandit算法之外，还有一些其他的explore的办法，比如跟xlvector大牛讨论时，他就提到一种：在推荐时，随机地去掉一些用户历史行为（特征）。&lt;/p&gt;&lt;p&gt;解决Explore，势必就是要冒险，势必要走向未知，而这显然就是会伤害用户体验的：明知道用户肯定喜欢A，你还偏偏以某个小概率给推荐非A。&lt;/p&gt;&lt;p&gt;实际上，很少有公司会采用这些理性的办法做Explore，反而更愿意用一些盲目主观的方式。究其原因，可能是因为：&lt;/p&gt;&lt;p&gt;1. 互联网产品生命周期短，而Explore又是为了提升长期利益的，所以没有动力做；&lt;/p&gt;&lt;p&gt;2. 用户使用互联网产品时间越来越碎片化，Explore的时间长，难以体现出Explore 的价值；&lt;/p&gt;&lt;p&gt;3. 同质化互联网产品多，用户选择多，稍有不慎，用户用脚投票，分分钟弃你于不顾。&lt;/p&gt;&lt;p&gt;4. 已经成规模的平台，红利杠杠的，其实是没有动力做Explore的；&lt;/p&gt;&lt;p&gt;基于这些，我们如果想在自己的推荐系统中引入Explore机制，需要注意以下几点：&lt;/p&gt;&lt;p&gt;1. 用于Explore的item要保证其本身质量，纵使用户不感兴趣，也不至于引起其反感；&lt;/p&gt;&lt;p&gt;2. Explore本身的产品需要精心设计，让用户有耐心陪你玩儿；&lt;/p&gt;&lt;p&gt;3. 深度思考，这样才不会做出脑残的产品，产品不会早早夭折，才有可能让Explore机制有用武之地。&lt;/p&gt;&lt;p&gt;好了，让我们再唱一遍，结束本系列：&lt;/p&gt;&lt;blockquote&gt;推荐不止眼前的苟且，还有诗和远方的田野&lt;/blockquote&gt;&lt;p&gt;[1] &lt;a href="http://arxiv.org/abs/1401.8257"&gt;http://arxiv.org/abs/1401.8257&lt;/a&gt;&lt;/p&gt;&lt;p&gt;[2] &lt;a href="http://arxiv.org/abs/1502.03473"&gt;http://arxiv.org/abs/1502.03473&lt;/a&gt;&lt;/p&gt;&lt;p&gt;[3] &lt;a href="https://github.com/qw2ky/CoLinUCB_Revised/blob/master/COFIBA.py" class=""&gt;https://github.com/qw2ky/CoLinUCB_Revised/blob/master/COFIBA.py&lt;/a&gt;&lt;/p&gt;&lt;blockquote&gt;推荐关注微信公众号【ResysChina】，中国最专业的个性化推荐技术与产品社区。更多内容会首发在微信公众号。猜你喜欢：&lt;a href="https://zhuanlan.zhihu.com/p/21404922?refer=resyschina"&gt;LinUCB算法&lt;/a&gt;&lt;/blockquote&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/21840306&amp;pixel&amp;useReferer"/&gt;</description><author>刑无刀</author><pubDate>Tue, 02 Aug 2016 23:30:31 GMT</pubDate></item><item><title>[译文]如何破解YouTube视频推荐算法</title><link>https://zhuanlan.zhihu.com/p/21797132</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/7a268dd234e346acde771c5a09628675_r.png"&gt;&lt;/p&gt;&lt;p&gt;如果你是某个发行渠道（比如电影、戏剧、电视节目、网络视频）的内容工作者，那么内容的成败就取决于发行机制的运转逻辑。比如说，你制作了一档电视节目，你很想它能火起来，那么你就得知道该在哪里切入广告，怎么宣传节目，上哪个频道播放，所选的频道能被多少家庭收看，等等，诸如此类。&lt;/p&gt;&lt;p&gt;如果你的发行渠道是YouTube，那么你最应该搞清楚的是YouTube的算法是怎么工作的。然而，全天下所有由算法来运营的平台，要搞清楚这一点那不是一般的困难。&lt;/p&gt;&lt;p&gt;YouTube没有把他们算法用到的变量公之于众。要搞清楚其算法的运转原理，即使数据很有限，我们也得对这个大大的黑盒子一探究竟。有些算法倚重的变量，我们是一点数据也拿不到的（比如缩略图，标题印象，用户访问历史，用户行为，会话信息，等），如果能拿到这些数据，那等于就是把YouTube的算法脱光了让我们看，然而呢，呵呵哒，并没有。&lt;/p&gt;&lt;p&gt;看起来我们啥都没有，但还是想尽可能用手上这点数据大致搞清楚其算法逻辑。所以，我的前同事（为什么是“前”同事呢？因为我最近从Frederator离职啦，哇咔咔）Jeremy Rosen花了半年时间分析Frederator自己掌握和运营的频道数据，想搞清楚YouTube的算法。&lt;/p&gt;&lt;p&gt;开始之前，先明确一下：这篇文章内所指的算法包含多个YouTube增长类算法（为你推荐（Recommended），建议观看（Suggest），相关视频（Related），搜索（Search），原始评分（MetaScore），等等）。这些不同的算法产品，各有侧重，但有一个共同点，那就是它们的优化目标相同，都是观看时长（Watch Time）。&lt;/p&gt;&lt;h2&gt;观看时长&lt;/h2&gt;&lt;p&gt;先要说清楚的，“观看时长”并不是说观看过的分钟数。这个概念我们之前也讨论过[1]，观看时长由以下指标构成：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;访问次数&lt;/li&gt;&lt;li&gt;访问停留&lt;/li&gt;&lt;li&gt;会话开始&lt;/li&gt;&lt;li&gt;上传频率&lt;/li&gt;&lt;li&gt;会话时长&lt;/li&gt;&lt;li&gt;会话结束&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;本质上以上每一项都关系着频道以及频道的视频表现好坏，人们是不是经常来访问（开始一次页面访问的会话）以及是不是停留很长时间。&lt;/p&gt;&lt;p&gt;要在算法那里积累下任何变量的取值，你的频道和视频首先得有人来访问你才行。一个视频要成功（成功定义为订阅者中超过一半的人在前30天访问过）需要视频发布的前几分钟、前几小时、前几天内得到大量的访问，我们把这称之为访问速率（ View Velocity）&lt;/p&gt;&lt;h2&gt;访问以及访问速率&lt;/h2&gt;&lt;p&gt;我们分析Frederator的访问速率，发现整个生命周期内累计访问次数与前48小时内订阅用户访问百分比呈指数关系。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/cd2c8f55771c1d04e19025f660679a9f.png" data-rawwidth="480" data-rawheight="358"&gt;&lt;pre&gt;&lt;code lang="text"&gt;                48小时内访问的订阅用户百分比与得到的平均访问次数&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;基于这个观察，我们稍微深挖了一下，发现用这个速率规律去预测一个视频是否会成功，可以做到92%的准确率。其实，还存在一个更直接的相关性：72小时内访问的订阅用户百分比，与视频整个生命周期的累计被访问次数之间。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/7db767217941a5591b6718d0b9915b02.png" data-rawwidth="800" data-rawheight="466"&gt;&lt;pre&gt;&lt;code lang="text"&gt;        72小时内访问的订阅用户百分比与整个生命周期内累计的访问次数&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这两个图以及相关系数充分说明访问次数和访问速率对视频和频道有着直接而重要的影响。除此之外，我们还有证据证明这个规律反过来也成立。差劲的访问速率不但影响这个视频本身，还影响其上一个和下一个视频。&lt;/p&gt;&lt;p&gt;下图说明如果Frederator上一个视频48小时内访问速率比较糟糕（少于5%的订阅用户访问），那么接下来上传的视频也会受其影响。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/54cb55cb2063ee500797e8a8a2b69900.png" data-rawwidth="466" data-rawheight="331"&gt;&lt;pre&gt;&lt;code lang="text"&gt;访问了下一个视频的订阅用户百分比与访问了前两个视频的订阅用户平均百分比之间的关系
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这个数据证实了Matthew Patrick的理论：如果某一个视频点击效果不好，那么你的下一次上传的视频，YouTube就不会给予太多权重让它被你的订阅用户看到。［2］&lt;/p&gt;&lt;p&gt;也可能是因为上一个视频表现糟糕，所以访问你的频道次数就会减少，自然地就导致更少的订阅用户以原生的方式访问到。不管到底“为什么”，结果反正就是酱紫。&lt;/p&gt;&lt;p&gt;另一个负速率对新上传视频的影响就是：有证据表明这还会伤害到你的整个视频库。下面的第一张图是视频上传48小时内就访问的订阅用户7天平均百分比（译者注：这7天上传了若干个视频，纪录每个视频上传后48小时就访问的订阅用户百分比，然后取这些百分比的平均值）与频道总访问次数（译者注：反应了整个视频库的效果）的关系。第二张图是某一天访问视频的总体订阅用户百分比与当日的总体访问次数之间的关系。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/258b3d20b9ba4141cb90b51c1ee41893.png" data-rawwidth="800" data-rawheight="463"&gt;&lt;pre&gt;&lt;code lang="text"&gt;七天内的平均“48小时内访问视频的订阅用户百分比” 与 每日整个频道视频访问总数之间的关系&lt;/code&gt;&lt;/pre&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/4ef151f7f0a0e558440e2df6d3fcf095.png" data-rawwidth="1287" data-rawheight="791"&gt;&lt;pre&gt;&lt;code lang="text"&gt;                七天平均订阅用户访问人数  与 总体访问访问次数之间的关系&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这些图标都说明一件事：一旦新上传视频和整个视频库的访问用户百分比走低，那么频道的总体访问次数也会走低。对于我们来说的启示是：YouTube算法更看重那些能够吸引到核心观众的频道，而惩罚那些不能吸引其核心观众的。&lt;/p&gt;&lt;p&gt;访问停留&lt;/p&gt;&lt;p&gt;另一个算法非常看重的指标就是访问停留（View Duration）。&lt;/p&gt;&lt;p&gt;访问停留就是用户会花多长时间停留在单个视频页面。这个变量的权重很高，我们的数据中能看到一个明显的引爆点。Frederator其中一个频道，前30天内，平均访问时长8分钟的视频，比平均5分钟的要多350%的访问量。下图表明，Frederator的一个频道的视频访问量，与平均访问停留时长的关系。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/b96fc8ff33f9ddee022db8a639883833.png" data-rawwidth="800" data-rawheight="537"&gt;&lt;pre&gt;&lt;code lang="text"&gt;                  整个生命周期内，平均访问时长和平均访问量的关系
                  注意，这里没考虑访问时长在八分钟之上的数据。&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;我们还发现，访问停留时长越长，视频表现越好。下面这张图是七天内访问停留时长少于5分钟的视频（1），介于五分钟到十分钟的（5）， 十分钟以上的（10）分别与访问量的关系。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/63d75e99edda3fad38c42712abb9fd9b.png" data-rawwidth="467" data-rawheight="320"&gt;&lt;pre&gt;&lt;code lang="text"&gt;                       七天内平均访问量与平均访问停留时长的关系&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;下面这张图也是一个意思，不过从7天拉长到整个生命周期内了。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/e6adbe48f326f6a3fa3c85c3fc666b0f.png" data-rawwidth="472" data-rawheight="326"&gt;&lt;pre&gt;&lt;code lang="text"&gt;                 整个生命周期内平均访问量与平均访问停留时长的关系&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;基于这些发现，我们可以得出一个简单的结论：发布长视频可以提高访问效果。Frederator有一个关于儿童乐园的频道，每周会上传三到四个不同长度（3分钟，10分钟，30分钟。70分钟）的视频，我们发现每个视频发布后的48小时内，70分钟视频的访问次数远远超过其他长度的视频，哪怕是重发一些炒剩饭的旧视频。除此之外，70分钟的视频和其他版本的视频有相同的平均访问停留时长。&lt;/p&gt;&lt;p&gt;于是，我们建议公司每周就只上传70分钟长度的视频就好了。就用了这个策略，频道日均访问量增长了50万，而过去6周里我们上传的视频个数却减少了75%。好了好了，我知道你受刺激了，不要崇拜哥。&lt;/p&gt;&lt;h2&gt;会话开始，会话时长，会话结束&lt;/h2&gt;&lt;p&gt;能做这篇研究，全都得益于我之前的一篇文章：《观看时长是个什么鬼》（WTF is  WatchTime?）[1]&lt;/p&gt;&lt;p&gt;快速回顾一下，会话开始（Session  Starts）就是指用户有多少次是从你的视频开始访问YouTube的。这其实说明了订阅用户能在前72小时访问你是多么重要。订阅用户是在视频发布后最早能看到的你人，他们也是最可能点击你频道图标的人，因为他们已经熟悉你的品牌了。&lt;/p&gt;&lt;p&gt;会话时长（Session Duration）就是你的内容让用户在YouTube平台上逗留了多久，他们访问你的视频，以及访问之后都算是在平台上逗留。除了用户平均访问时长（Average View Duration ）和独立访问数（ Unique Views），也没有更好的数据了。&lt;/p&gt;&lt;p&gt;会话结束（Session Ends）衡量用户是不是经常在看完你的视频后就离开了YouTube平台。这是算法利用的一个负面指标，但是我们根本拿不到数据。&lt;/p&gt;&lt;h2&gt;一则算法理论&lt;/h2&gt;&lt;p&gt;YouTube的算法设计时关注的是频道效果而不是单个视频效果。但是它要利用单个视频来提高频道效果。&lt;/p&gt;&lt;p&gt;算法结合了单个视频的特定数据和频道的聚合数据来决定推荐哪个视频。最终目标仍然是为频道聚拢其目标观众。&lt;/p&gt;&lt;p&gt;YouTube这么做是因为：&lt;/p&gt;&lt;p&gt;1. 让用户常常回访YouTube平台&lt;/p&gt;&lt;p&gt;2. 让用户在平台停留越久越好&lt;/p&gt;&lt;p&gt;下面有三张图表来证明这则理论是成立的。&lt;/p&gt;&lt;p&gt;第一张图是48小时内访问的订阅者比例与7天内总访问量之间的关系。这张图说明，如果开始有大量用户从你的视频开始的平台会话，那么你的视频就会获得很大的访问量。到达一个阈值之后，就会呈指数级增长。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/ffd12db6c9695b8ed6a9734b00edb994.png" data-rawwidth="572" data-rawheight="414"&gt;&lt;pre&gt;&lt;code lang="text"&gt;                  7日内总访问量与48小时内访问的订阅用户百分比&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;第二个图是频道内日均访问量与5日内访问的订阅用户百分比的关系。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/b0b147422b11a302f8c6d03c588f7562.png" data-rawwidth="481" data-rawheight="335"&gt;&lt;pre&gt;&lt;code lang="text"&gt;                     日均访问量与5日内访问的订阅用户百分比的关系&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这意味着如果能一直让大量用户从你开始访问YouTube（近5天内平均来看），那么算法就会将用户每日访问向你整个频道视频库倾斜。&lt;/p&gt;&lt;p&gt;最后一幅图是日均访问的订阅用户百分比与5天内访问的订阅用户百分比之间的关系。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/b05c9e9639b993ec474f058485a6b85a.png" data-rawwidth="469" data-rawheight="333"&gt;&lt;pre&gt;&lt;code lang="text"&gt;           日均访问的订阅用户百分比与5日内访问的订阅用户百分比之间的关系&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;我们相信这一切都表明，频道效果的连贯性与访问量之间存在相关性，访问量又表现在订阅用户访问百分比，YouTube就会因此把流量倾斜给你。&lt;/p&gt;&lt;p&gt;假如说你有一个游戏频道，10万个订阅用户，你每天上传6个视频，每个视频有5%的订阅用户访问。你的每个视频的平均访问订阅用户会稳定在区区5%。这意味你会每天产生30%的订阅用户访问次数（3万/天，60万/月）。现在假设你有1百万订阅用户，那么每日访问次数在30万，每月在600万。&lt;/p&gt;&lt;p&gt;我们认为这一段数学运算是不会骗人的。这意味YouTube在根据一些指标选择一些频道进行推荐，然后只要算法帮这个频道提高访问量。&lt;/p&gt;&lt;p&gt;但，壮士请留步，以上还仅仅是理论上的分析！&lt;/p&gt;&lt;h2&gt;一种打分算法&lt;/h2&gt;&lt;p&gt;这里我们打算破解YouTube的算法，然后重建一个。用了15个信号量，以及我们估计的权重，来重新构建打分算法。信号量列举如下：&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/28a5ecccba116619eccbf1ab3e0ff7e2.png" data-rawwidth="179" data-rawheight="174"&gt;&lt;pre&gt;&lt;code lang="text"&gt;                       用来开发打分算法的信号量／因素&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;下面这些图是这些信号量实际产生的效果。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/2da3d73ff506d6cfc6a18fdff93e7ef9.png" data-rawwidth="545" data-rawheight="300"&gt;&lt;pre&gt;&lt;code lang="text"&gt;                  三天的算法平均分与访问量的相关趋势&lt;/code&gt;&lt;/pre&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/84c7eb3a45dccb69ae7f0b3493578e72.png" data-rawwidth="526" data-rawheight="302"&gt;&lt;pre&gt;&lt;code lang="text"&gt;                    算法打分与访问量的相关性趋势&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;下面这张图更详细一些。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/2200742e37640a827c0f37affb3ce7cc.png" data-rawwidth="601" data-rawheight="412"&gt;&lt;pre&gt;&lt;code lang="text"&gt;                       三天的算法打分均值与每日访问量&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;知道你还是很好奇，那下面就揭晓我们模拟出来的各种权重:&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/9ad3ae4d277525cd46edbcef0bfb0ccb.png" data-rawwidth="488" data-rawheight="509"&gt;&lt;pre&gt;&lt;code lang="text"&gt;                         各种算法的权重分布模拟&lt;/code&gt;&lt;/pre&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/b9ede94c0bd2ce7484edc9ad557b9d16.png" data-rawwidth="423" data-rawheight="504"&gt;&lt;pre&gt;&lt;code lang="text"&gt;                   观看时长优化算法的各信号量权重分布模拟&lt;/code&gt;&lt;/pre&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/307ff40a4a1717ff925f7cd502808a86.png" data-rawwidth="439" data-rawheight="513"&gt;&lt;pre&gt;&lt;code lang="text"&gt;                   相关推荐及其他算法的各信号量权重分布&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;然而但是but，我们也没有其他数据了，所以我们也不敢肯定在计算相关性时该用哪种回归方式，也只敢说大多数信号和算法之间很相关，而已。也正因为如此，我们对YouTube算法一直热情不减。&lt;/p&gt;&lt;h2&gt;对YouTube算法的看法&lt;/h2&gt;&lt;p&gt;根据我们的数据，至少可以得到6个粗浅结论：&lt;/p&gt;&lt;p&gt;1. YouTube用算法决定了我们的视频和频道能得到多少访问量。&lt;/p&gt;&lt;p&gt;2. 成功的频道都是专注在特定类型的内容或创意上。&lt;/p&gt;&lt;p&gt;3. 频道自己一旦明确了哪种类型的内容成功之后，就不要再摇摆了。&lt;/p&gt;&lt;p&gt;4. 内容制作者光靠钱在YouTube平台上绝无可能成功，因此土豪型的制作者不太会全身心拥抱YouTube。&lt;/p&gt;&lt;p&gt;5. 个性化的节目/频道会一直是YouTube上面占统治地位的内容类型，因为这就是人们要找的“特定类型的内容”。&lt;/p&gt;&lt;p&gt;6. 新建的频道，如果不能在YouTube站外导流进去的话，相当长时间内增长都会比较困难。&lt;/p&gt;&lt;p&gt;前面说到，YouTube更注重于提高频道的访问效果，这个观点只是我们推测得到的。频道能够上传很多视频，从而获得和留住大量的目标观众。如果你想在YouTube上成功，我们能给的建议就是：瞄准一个非常垂直的兴趣类型，然后持续去制作10分钟以上的视频，一定得是你选定的这个兴趣类型的视频。&lt;/p&gt;&lt;p&gt;我这里是私人博客，需要提醒一下，YouTube可是储备了大量的算法弹药啊，也希望他们不把本文视为对算法的负面消息。通过这篇研究，我更加感谢YouTube及其算法工程师们，有预见性地设计了这些算法。毕竟，他们还是想努力让这个世界上的十亿用户能在一个月内不重样地观看视频。如果你能停下来回头再整体上审视一下这一切，你会惊叹于YouTube算法设计如此优雅，在实现商业目标上和保护平台健康发展上做得难以置信的好。为他们点32个赞！&lt;/p&gt;&lt;h2&gt;作者简介：&lt;/h2&gt;&lt;blockquote&gt;&lt;p&gt;	Matt Gielen是Frederator Networks的前副总裁， 主管编程和观众开发。&lt;/p&gt;&lt;p&gt;	Matt所管的团队是世界上最大的动画制作网络公司，Frederator网络频道。&lt;/p&gt;&lt;p&gt;	他还带领团队制作和编程了Frederator Networks自己的YouTube运营频道：Channel Frederator，The Leaderboard，Cinematica。&lt;/p&gt;&lt;p&gt;	你还可以在twitter上关注他@mattgielen。&lt;/p&gt;&lt;/blockquote&gt;&lt;h2&gt;译后记：&lt;/h2&gt;&lt;blockquote&gt;&lt;p&gt;最初看到这篇文章是@fengyoung 在Facebook上分享的，觉得题目很有意思就看了一遍，看完后感觉很有启发，遂决定翻译一下让更多人看到。&lt;/p&gt;&lt;p&gt;这篇文章给我的启发有三方面：&lt;/p&gt;&lt;p&gt;1. 从YouTube平台的算法设计人员角度，设计繁多的推荐算法，是为了提高频道的观看时长，而提高频道的观看时长又是为了让用户能够经常访问平台。这是一种双赢的思维，说白了：谁能帮平台留住用户，平台就重点扶持他。&lt;/p&gt;&lt;p&gt;2. 文章得出结论，要做垂直内容才能在YouTube上活下去。平台上内容越多样，平台越健康，这是毋庸置疑的，尽管我赞同这个结论，但是我没有在本文中看到作者是如何得到这个结论的。这一点就是YouTube和国内视频平台最大的差别，国内的视频平台严重趋同，花高价购买独家版权似乎是国内视频平台的唯一出路，也是一个妖魔化的出路，反观YouTube，他们利用算法驱使了各个频道专耕某一个垂直内容，然后把最适合的用户给你匹配上，这才是更宏大的一盘内容棋。&lt;/p&gt;&lt;p&gt;3. 本文作者给我们了一个启示，算法并不是黑盒子，是可以hack的，尽管这个也只能hack到冰山一角，但是也比我们盲目地运营要明亮很多了。作者的研究方式，首先是明确了一个平台的算法目标是什么，YouTube是watch time，那么就去观察这个目标和哪些指标有关，进一步看到每个指标又能怎么提高。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;[0] 原文：&lt;a href="http://www.tubefilter.com/2016/06/23/reverse-engineering-youtube-algorithm/" class=""&gt;http://www.tubefilter.com/2016/06/23/reverse-engineering-youtube-algorithm/&lt;/a&gt;&lt;/p&gt;&lt;p&gt;[1] &lt;a href="http://www.tubefilter.com/2016/05/12/youtube-watch-time-metric-algorithm-statistics/" class=""&gt;http://www.tubefilter.com/2016/05/12/youtube-watch-time-metric-algorithm-statistics/&lt;/a&gt;&lt;/p&gt;&lt;p&gt;[2] &lt;a href="https://www.youtube.com/watch?v=HLJQ0gFHM8s" class=""&gt;https://www.youtube.com/watch?v=HLJQ0gFHM8s&lt;/a&gt;&lt;/p&gt;&lt;blockquote&gt;推荐关注微信公众号【ResysChina】，中国最专业的个性化推荐技术与产品社区。更多内容会首发在微信公众号。猜你喜欢：&lt;a href="https://zhuanlan.zhihu.com/p/20901694?refer=resyschina"&gt;关于 Facebook NewsFeed，看这一篇就够了！&lt;/a&gt;&lt;/blockquote&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/21797132&amp;pixel&amp;useReferer"/&gt;</description><author>刑无刀</author><pubDate>Sat, 30 Jul 2016 18:26:33 GMT</pubDate></item><item><title>Quora是如何做推荐的？</title><link>https://zhuanlan.zhihu.com/p/21740678</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/faec30ea1002ced23937167dc62cb941_r.png"&gt;&lt;/p&gt;&lt;p&gt;知乎联合创始人张亮在值乎上问了俞军老师一个问题，「以您的使用体验看，您觉得知乎现在最急需做的三到五项产品改进是哪些？」俞军老师的回答中给的第一个意见就是，「个性化内容的挖掘和推送，我知道知乎里有大量内容是我感兴趣的，但知乎推送的内容只有很少是我愿意点击的，总让我有种入宝山而空回的感觉，这方面网易云音乐、淘宝、今日头条都是不错的学习对象。」&lt;/p&gt;&lt;p&gt;其实知乎在2013年11月就推出了「开启新版首页动态体验」这个实验室功能，其中的一个feature就是「动态中的内容会根据用户间的关系、用户对话题的兴趣和内容的质量进行调整，不再严格依据时间排序」。但不知道为什么到现在好像也没有正式启用，而且这个实验室功能还是默认关闭的，需要用户自己手动打开。如果不知道这个功能的朋友们，可以去打开尝试一下，在「设置-实验室」里面勾选即可。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/e67d6710d0dd34aebc862650e7a82197.png" data-rawwidth="1958" data-rawheight="354"&gt;&lt;p&gt;前段时间，Quora的VP Engineering机器学习大牛Xavier Amatriain，在WWW2016大会的Question Answering Workshop做了一个报告，《Machine Learning for Q&amp;amp;A Sites: The Quora Example》[1]，我周末学习了一下，分享给大家。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Quora的Mission：To share and grow the world's knowledge。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Quora主要考虑的三个因素：Relevance、Quality和Demand。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/92cab50896d2b246079074a448cf9c36.png" data-rawwidth="628" data-rawheight="274"&gt;&lt;p&gt;Quora核心的数据模型及其之间的关系。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/45a7702bc0b9864b833e8e6c3a8a21ad.png" data-rawwidth="623" data-rawheight="305"&gt;&lt;p&gt;&lt;strong&gt;Feed Ranking&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Quora做推荐的一个最核心问题就是Personalized Feed Ranking。Quora是以问题、答案与主题为核心把「知识」串联起来，然后基于用户的顶和踩等动作来划分内容质量，最后再通过人和问题的Follow关系让知识在社区内流动起来。而个人Feed正是这种「流动」的最主要的载体。Xavier说Quora做Feed Ranking的难度要比Netflix大，这也正常，没有更大的挑战想来Xavier也不会跳槽是吧。Quora Feed Ranking的首要目标是确保推送进用户Feed的内容应该是和用户兴趣高度相关的，其次还需要考虑的包括用户之间的Follow关系以及互动，Xavier管这个叫做social relevance，另外还有时间因素，比如一些和热点事件相关的问答，也应该及时地推送进用户Feed。&lt;/p&gt;&lt;p&gt;1、目标：Present most interesting stories for a user at a given time&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Interesting = topical relevance + social relevance + timeliness&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Stories = questions + answers&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;2、主要使用的是个性化的learning-to-rank方法&lt;/p&gt;&lt;p&gt;3、Xavier确认了一点，相比于时间排序(time-ordered)，相关度排序大大提升了用户参与度。&lt;/p&gt;&lt;p&gt;4、面临的挑战，&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;potentially many candidate stories&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;real-time ranking&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;optimize for relevance&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;下图是Quora做Feed Ranking最最基础的数据构成，Quora管这个叫做「impression logs」。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/27194ebd8443ea9bd3ddc8b7058115a5.png" data-rawwidth="1252" data-rawheight="688"&gt;&lt;p&gt;围绕这些基础行为，Quora定义的Relevance函数如下。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/dfb9a67c50b91a49db62393d266e75a9.png" data-rawwidth="1252" data-rawheight="636"&gt;&lt;p&gt;简单讲就是使用一个「行为加权函数」来预测用户对一个story的感兴趣程度。有两种可选的计算方法，一种是把所有行为弄到一个回归模型里面直接预测最终值，另外一种就是先分别预测每个动作的可能性（比如顶、阅读、分享等）然后再综合起来加权求和。第一种简单，但可解释性稍差，第二种可以更好的利用每个动作信号，但需要给每个动作配一个分类器，计算消耗大。&lt;/p&gt;&lt;p&gt;Quora主要使用的三类模型如下。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/c718750cb82125092bf4661250cb7a9a.png" data-rawwidth="1248" data-rawheight="606"&gt;&lt;p&gt;另外Xavier也强调了特征工程的重要性，在这块下功夫搞一下对最终能得到一个好的ranking结果非常有帮助，如果能够实时在线的更新特征就更好了，这样可以更及时地对用户的行为作出响应。Quora最主要的特征包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;user (e.g. age, country, recent activity)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;story (e.g. popularity, trendiness, quality)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;interactions between the two (e.g. topic or author affinity)&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;从整体框架来看，Quora的Feed Ranking也没有什么太特别的地方，基本上也是业界的标准打法。Quora比较特别的是它的数据模型相对其他网站更复杂，之间的关系也更多样化。比如从用户角度看，既可以follow其他用户User，又可以follow问题Question，还可以follow主题Topic。&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;Follow用户接收到的信息范围更广也更多样化，惊喜内容很可能就是来自于自己关注的有趣的用户，但也可能最容易制造不相关的内容噪音，这块的最重要工作是用户专业度的评估。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Question/Answer是Quora最核心的内容元素，也是驱动Quora体系里知识流动的原力，这块的主要工作是引导更多的高专业度用户来贡献优质答案，另外就是如何激发生产出更多的好问题（甚至是自动生成问题），要计算answer ranking，还有要做反sapm的工作。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Topic是对一个主题内容的聚合，Topic在Quora的信息架构里面承载着极其重要的角色，是知识结构的骨架，Quora管这个叫做Topic Network，如何构建Topic Network本身就是一个非常大的挑战，另外还需要解决的问题包括，如何把Topic下（潜在）优质的问题发掘出来，以及如何把水问题降权和过滤/合并重复问题等。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;围绕着这些核心问题，Quora分别都进行了更深入的工作。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Answer Ranking&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Goal：Given a question and n answers, come up with the ideal ranking of those n answers.&lt;/p&gt;&lt;p&gt;Quora主要考虑了下面三大维度来进行Ranking计算，每个大维度下面又包含了很多的features。&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;答案内容本身的质量度。Quora对什么是「好的答案」有明确的指导[2]，比如应该是有事实根据的，有可复用价值的，提供了解释说明的，进行了好的格式排版的等等。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;互动，包括顶/踩、评论、分享、收藏、点击等等。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;回答者本身的一些特征，比如回答者在问题领域的专业度。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;另外这块的工作也包含非个性化的与个性化的两部分，某些类问题的排序是非个性化的，最好的答案对所有用户而言都是一致的，而另外一些问题则是个性化的，对于每个人而言最好的答案会有自己个性化的判断。总之，Answer Ranking对Quora非常重要，这块Quora做得很细致，Quora的blog上有一篇专门的文章讲这个，有兴趣的朋友可以去看看原文[3]。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/f7647f51bca047478eb79bde9f53e23a.png" data-rawwidth="572" data-rawheight="367"&gt;&lt;p&gt;&lt;strong&gt;Ask2Answers&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;A2A是Quora产品里面非常重要的一个功能，本来Quora是可以直接把相关问题推荐给系统认为的合适的回答者的，Quora最开始也是这么做的，但系统自动做这事儿显然不如发动群众人肉邀请回答来得感觉好，A2A操作增强了仪式感，让被邀请者有种被人需要的感觉，心理上很满足，另外这也是一种社交动作，社交的精髓之一就是为用户制造「装逼」的便利，回答问题前很随意的「谢邀/泻药」，一切尽在不言中了。这个功能看似很简单，Quora也是下了功夫的，Quora把A2A这事model成了一个机器学习问题：Given a question and a viewer rank all other users based on how 「well-suited」 they are。其中「well-suited」= likelihood of viewer sending a request + likelihood of the candidate adding a good answer，既要考虑浏览用户发送邀请的可能性，又要考虑被邀请者受邀回答的可能性。Quora的blog上也有一篇文章详细讲解了他们的做法[4]。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/5927313e96ff8e2cca1ea9d3f06ab705.jpg" data-rawwidth="572" data-rawheight="429"&gt;&lt;p&gt;&lt;strong&gt;Topic Network&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Quora花了很大力气来正确引导用户给内容打标签，持续不断坚持这项工作的好处开始逐渐显露出来了，他们发现[5]，&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;随着用户群体的扩大，Topic正在呈现出迅速多样化的势头。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;很多领域都自组织出了相当不错的层级知识结构。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;Quora相信这种依靠社群来组织领域知识的方式是可行的。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/805a3756f437db871ea52e1eed21936f.png" data-rawwidth="1252" data-rawheight="684"&gt;&lt;p&gt;&lt;strong&gt;User Trust/Expertise Inference&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这是Quora另一件非常重要的事情，Quora需要找出某个领域的专家，然后通过产品引导这些专家在这个领域里贡献更多的优质答案。Quora会考虑用户在某个领域里回答问题的多少，接收到的顶、踩、感谢、分享、收藏及浏览等数据。另外还有一个很重要的是专业度的传播效应，比如Xavier在推荐系统领域对某个答案顶了一下，那么这个答案作者在推荐系统领域很可能具备较高的专业度。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;其他&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;其他相关的，包括推荐主题、推荐用户、相关问题、重复问题、反Spam等等，Quora大量地在使用机器学习的方法来解决这些问题。&lt;/p&gt;&lt;p&gt;Quora最大的宝藏，就是这几年在各个领域不断积累下来的大量有价值的内容，Quora自然也少不了对这些的挖掘，有篇《Mapping the Discussion on Quora Over Time through Question Text》[6]，就是一个很好的挖掘数据价值的案例。作者陶雯雯，看个人简介是北大元培计划的，妥妥地又一个美女学霸，感觉知乎可以出手了。&lt;/p&gt;&lt;p&gt;Facebook等几个主题随时间的变化情况&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/234c14eaaf638175c295b02f4b4a840a.png" data-rawwidth="572" data-rawheight="377"&gt;&lt;p&gt;2014年4季度美国的热点主题&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/1c78192b49bc47c9e9eb41ec9479c92c.png" data-rawwidth="572" data-rawheight="443"&gt;&lt;p&gt;参考资料：&lt;/p&gt;&lt;p&gt;[1] &lt;a href="http://www.slideshare.net/xamat/machine-learning-for-qa-sites-the-quora-example"&gt;http://www.slideshare.net/xamat/machine-learning-for-qa-sites-the-quora-example&lt;/a&gt;&lt;/p&gt;&lt;p&gt;[2] &lt;a href="https://www.quora.com/What-does-a-good-answer-on-Quora-look-like-What-does-it-mean-to-be-helpful/answer/Quora-Official-Account" class=""&gt;https://www.quora.com/What-does-a-good-answer-on-Quora-look-like-What-does-it-mean-to-be-helpful/answer/Quora-Official-Account&lt;/a&gt;&lt;/p&gt;&lt;p&gt;[3] &lt;a href="https://engineering.quora.com/A-Machine-Learning-Approach-to-Ranking-Answers-on-Quora"&gt;https://engineering.quora.com/A-Machine-Learning-Approach-to-Ranking-Answers-on-Quora&lt;/a&gt;&lt;/p&gt;&lt;p&gt;[4] &lt;a href="https://engineering.quora.com/Ask-To-Answer-as-a-Machine-Learning-Problem"&gt;https://engineering.quora.com/Ask-To-Answer-as-a-Machine-Learning-Problem&lt;/a&gt;&lt;/p&gt;&lt;p&gt;[5] &lt;a href="https://data.quora.com/The-Quora-Topic-Network-1"&gt;https://data.quora.com/The-Quora-Topic-Network-1&lt;/a&gt;&lt;/p&gt;&lt;p&gt;[6] &lt;a href="https://data.quora.com/Mapping-the-Discussion-on-Quora-Over-Time-through-Question-Text"&gt;https://data.quora.com/Mapping-the-Discussion-on-Quora-Over-Time-through-Question-Text&lt;/a&gt;&lt;/p&gt;&lt;p&gt;关于动态Feed这个事情，ResysChina之前发过一系列相关文章，Facebook、Pinterest怎么做的都有讲到。关注微信公众号ResysChina，回复「feed」即可查看。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;推荐关注微信公众号【ResysChina】，中国最专业的个性化推荐技术与产品社区。更多内容会首发在微信公众号。&lt;/p&gt;★ 猜你喜欢：「&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA4OTk5OTQzMg==&amp;amp;mid=2449231140&amp;amp;idx=1&amp;amp;sn=0fd6465d892966675faae2fb93b93dcd#rd" data-title="听Quora产品团队讲应该如何给推荐系统设计UI" class="" data-editable="true"&gt;听Quora产品团队讲应该如何给推荐系统设计UI&lt;/a&gt;」&lt;/blockquote&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/21740678&amp;pixel&amp;useReferer"/&gt;</description><author>谷文栋</author><pubDate>Wed, 27 Jul 2016 00:42:08 GMT</pubDate></item><item><title>开撕：亚马逊的推荐到底行不行？</title><link>https://zhuanlan.zhihu.com/p/21622055</link><description>&lt;p&gt;亚马逊在业内有「推荐系统之王」之称，亚马逊有35%的销售额是与推荐系统相关的[1]。但是最近，微软的研究员Amit Sharma发表了一篇paper《Estimating the causal impact of recommendation systems from observational data》[2]，对这个事情提出了质疑。这篇论文分析了Amazon上4000种不同商品的相关数据，认为与我们通常归因于推荐系统的点击次数相比，实际上仅有四分之一真正是由推荐系统引起的，其他四分之三和推荐并没有关系。&lt;/p&gt;&lt;p&gt;论文里举了一个例子，如下图左图，大家主要看一下红圈标明的地方，这是Amazon的单品页上非常重要的一个推荐位「Frequently Bought Together / 经常一起购买的商品」。冬天来了，小明想买一顶帽子御寒，他在Amazon上看中了图中的这顶帽子，这个时候Amazon向小明推荐说，买这顶帽子的人通常还会买红圈里的那副手套，而恰好小明也需要一副手套，所以就一起下单了。例子中手套的销售通常被认为是推荐系统的作用。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/e3de309e43903c931f00c9f16c23fbfc.jpg" data-rawwidth="1200" data-rawheight="311"&gt;&lt;p&gt;而论文作者的观点是，即使没有推荐，如上图右图，小明因为御寒的需要，一样会寻找并购买一副手套，因此这种购买不应该计入推荐系统。作者把没有推荐系统就不会发生的点击称为「因果性点击」，而把上例中小明购买手套的点击成为「便利性点击」——有没有推荐系统手套的购买都会发生，推荐系统仅仅是带来了「便利性」。论文试图用实验的方法来证明，推荐系统带来的绝大部分点击都是这种「便利性点击」，因此推荐系统的价值很大程度上被高估了。&lt;/p&gt;&lt;p&gt;为了干这个事情，论文作者发明了一种称为「Shock-IV」的测量方法。论文的实验数据来自于Bing工具条用户的真实访问日志，包括了210万匿名用户在2013-14年间的9个月时间内对Amazon上140万商品的访问记录，并以推荐系统中最最常见的推荐形态「Customers who bought this also bought / 买了还买」作为评价目标。具体的细节我这里略去不表了，有兴趣的同学可以自己去读一下paper。论文的结果如下图。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/fff455191c8427e0402f72ace3121976.png" data-rawwidth="432" data-rawheight="264"&gt;&lt;p&gt;图中显示了使用Shock-IV方法得到的因果性点击率（CTR）的估计值（绿色曲线），同时为了对比，还给出了把便利性点击计算在内的推荐系统点击率（红色虚线）。可以看到，例如书这个品类，因果性点击率只有5%，而我们通常认为10%以上点击是来自于推荐系统。对于不同的商品类别，相比于推荐系统真实有效的点击，即因果性点击，我们通常会高估了200％的推荐效果。接下来是论文的常见套路之列举不足，然后给出了结论，他们使用的Shock-IV这套实验方法是相当data-driven的，有很大的应用价值应该推而广之。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;有人把这个实验结果po到了Quora上[3]，结果推荐领域的大神&lt;/strong&gt;&lt;strong&gt;Xavier Amatriain&lt;/strong&gt;&lt;strong&gt;怒了。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;熟悉推荐领域的人想必都知道Xavier的大名，他上一份工作是Netflix推荐团队的负责人，现在是Quora的工程VP。Xavier之所以对这篇论文很不满，一个重要的原因是他认为原论文的作者是在他们领域里受到尊重的研究人员，而这篇论文本身却既不严谨又缺乏行业认知，大牌研究人员发布不靠谱的结论，误导性非常大，因此他有必要站出来拨乱反正。&lt;/p&gt;&lt;p&gt;针对前文中「帽子-手套」的例子，Xavier认为原论文提出的问题——如果没有推荐用户会怎么做——是毫无意义的。在没有推荐的时候，用户会有两个选择：1）自主选择其他一副手套；2）抛弃你的服务，去别的地方。实际上，第二个选择是非常值得关注的，且与原论文的另一大缺陷相关：仅是简单地使用CTR来评估推荐系统。一个推荐系统的好坏不仅仅取决于有一个更好或更坏的CTR，非常重要的一点是，它有助于减轻用户寻找到「正确选择」的负担。假设两个网站A和B，在网站A里用户3秒内就找到了他想要的东西，而在网站B需要3分钟，那么显而易见地用户会更经常使用A网站。换句话说，推荐系统带来的不仅仅是简单的点击，更重要的是让用户「重复使用」。&lt;/p&gt;&lt;p&gt;原论文中对「推荐」的定义太过狭隘，暂且不说现如今很多搜索结果都是个性化过的，像Amazon这样的网站，推荐几乎已经无所不在了。而「便利性点击」恰恰正是推荐系统所追求的目标之一。推荐系统让用户生活更容易、更便利，从长期上看，用户因此会购买更多商品，或者对服务的满意度更高。所以从实践意义上看，原论文定义的问题根本就是个杯具。当我们使用A/B测试衡量一个推荐系统的效果时，我们更加看中的是推荐是否让用户「爽」了，用户使用服务爽了，就会带来更多的活跃与营收。「便利性」不是给推荐系统添乱，它是使用推荐系统应该具备的固有益处。&lt;/p&gt;&lt;p&gt;另外，原论文中说因为数据层面的限制他们做不了在线的A/B测试，很多人很多场景也都做不了，因此它们提出的Shock-IV可以作为推荐系统A/B测试的一种替代方案。Xavier的意思是，你们别闹了，并给出了他之前在前东家Netflix的一个案例，在「&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA4OTk5OTQzMg==&amp;amp;mid=2449231099&amp;amp;idx=1&amp;amp;sn=6ff30a52fbbe9d01ef022661c6325dc4&amp;amp;scene=21#wechat_redirect" data-editable="true" data-title="Netflix推荐系统的最新解读：算法、商业价值与创新" class=""&gt;Netflix推荐系统的最新解读：算法、商业价值与创新&lt;/a&gt;」一文中，Netflix发现个性化技术可以显著提高推荐影片的被接受度（Take-Rate），即推荐给用户的影片真正被播放的比率。Netflix做了一个对比分析，见下图，黑色线是基于热门度的曲线，红色线是基于个性化PVR（Personalized Video Ranker）指标的曲线，个性化推荐使得接受度有了巨大的提升。而且除此之外，比接受度提高更有意义的是，优秀的推荐技术使得用户的参与度（观看时长）与退订率都受益匪浅。Netflix的月退订率很低（很小的个位数百分比），大部分是因为支付的问题，真正主动选择退订的非常少。通过在个性化推荐领域的多年耕耘，月退订率得以降低了可观的百分比。月退订率的降低，一来有效延长了会员的付费存续期，二来也降低了为弥补流失用户所要付出的成本。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/ab89a16a8388e17af6cb6aaace8067b8.jpg" data-rawwidth="485" data-rawheight="391"&gt;&lt;p&gt;Xavier列举了他认为原论文中的不妥之处，包括，&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;实验的设定根本就是错的。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;对于推荐系统工作方式的假设也是错的。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;核心概念的定义过于苛刻，与应用的现实场景脱节。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;实验受到了这么多的假设和约束，但没有发现这些限制有任何好处。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;由于实验方法的这些限制，需要仔细考虑实验结果的局限性。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;最后得到的实验结果，并没有与任何公认的结果进行对比。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在Quora的回答里，Xavier围绕这些问题一一进行了反驳，内容很长，建议大家去仔细读一读原答案，对大家学习理解推荐系统会非常有帮助。&lt;/p&gt;&lt;p&gt;其实关于如何评价推荐系统的作用，很早以前在ResysChina论坛里同学们也有过很多的讨论。比如，如果以CTR为考核指标，把豆瓣电影单品页中「喜欢这部电影的人也喜欢」这部分换成推荐热门电影，这样这部分的点击率会提高很多。但如果考察用户点击的深度，即点击了推荐项之后又继续沿此路径发生了多少次点击，推荐系统给出的结果就要远超热门结果了。所以推荐系统从长期用户价值来看更有用处。&lt;/p&gt;&lt;p&gt;Amazon对待推荐系统价值的认知，《一键下单》书中有一段Amazon创始人贝索斯自己对它的评价，&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;我想我们能做的就是利用先进技术，例如联合过滤（推荐系统最经典的算法）以及其他技术来加快找书速度。打个比方，如果你今天走进一家书店，发现一本让你灵魂出窍的书的可能性是1/1000，我们想利用技术来了解你本人，并使这种机会增加到1/300，然后是1/100。经过几年的努力以后，使这个概率变成1/50，等等。这将为人们创造巨大的价值。再伟大的商人也没有机会逐个地了解他们的顾客，而电子商务要使这成为可能。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;而且贝索斯还曾拿推荐系统作为武器来制衡供应商，《一网打尽》中提到过这个事情，&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;亚马逊在和大型出版商谈判的时候，就会使用他们的「推荐系统」作为杀手锏。如果出版商没有达到他们的要求，亚马逊就威胁将他们的书从人机自动化推荐系统中撤下，这也就意味着他们将不会向客户推荐这本书。最开始出版商根本不知道亚马逊这样做会有什么效果，他们大多数人不知道他们销售额增长的原因正是因为他们处于显眼的推荐位置。亚马逊通过这种方法来展示其强大的市场力量。如果一家出版商不妥协，亚马逊就会关闭推荐其书目的算法，出版商的销售额一般会下降40%。然后，通常30天左右出版商就会回过头来说，「哎哟，我们怎么做这项工作？」&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;这个故事也从侧面印证了原论文的假设是多么不靠谱。简单讲，这篇被批判的paper最大的问题之一，就是把推荐仅当做「买了还买」这么一项功能来看，推荐系统现在绝不仅仅是一个算法或者一项功能了，它承载着传递用户价值的重大作用。&lt;/p&gt;&lt;p&gt;最后，关于「买了还买」这个推荐领域的经典应用，在Greg Linden的《Early Amazon》[4]也里有过相关的内容，推荐给大家。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;亚马逊有一个广为人知的功能，「买过某本书的顾客还买过」。这是发现相关书籍的绝佳途径。&lt;/p&gt;&lt;p&gt;在内部，我们管这个功能叫做「相似推荐」。通过使用这个功能，不断地从一本书跳转到另一本书，叫做「相似推荐漫游」。&lt;/p&gt;&lt;p&gt;这个功能的第一版是一位叫做Eric的攻城狮开发的，他很聪明，开发经验也很丰富。和Eric一起工作的感觉很棒，从他身上我学到了很多。&lt;/p&gt;&lt;p&gt;第一版的相似推荐功能非常受欢迎。但是它有一个问题，即所谓的「哈利波特问题」。&lt;/p&gt;&lt;p&gt;嗯，是的，就是那个哈利波特。哈利波特是那种老少通杀的畅销书，孩子会买它，大人也会买它，所有人都会买它。&lt;/p&gt;&lt;p&gt;然后你可以任选一本书。当你关注买了这本书的顾客还买过其他哪些书的时候，放心吧，其中的大多数顾客都买过哈利波特。&lt;/p&gt;&lt;p&gt;这种相似推荐是没有太大用处的。你感受一下，当你在浏览《The Psychology of Computer Programming》这本书的时候，给你推荐哈利波特是不是挺没用的。如果能够推荐《Peopleware》和《The Mythical Man Month》，就有用多了。&lt;/p&gt;&lt;p&gt;要解决这个问题并不像乍看起来那么简单。有一些显而易见的解决方案会带来另外的问题，其中一些甚至比哈利波特问题本身还要严重。&lt;/p&gt;&lt;p&gt;通过大量的实验，我发明了一种新的相似推荐方法，工作得相当不错。新方法给出的相似推荐，更新颖也更有帮助。而且与此同时，我还对程序性能做出了一些提升。整个过程非常有趣。&lt;/p&gt;&lt;p&gt;当这个新版本的相似推荐功能上线之后，贝索斯冲入我的办公室，跪倒在我面前，向我高呼，「你丫的酷毙了！你丫的酷毙了！」&lt;/p&gt;&lt;p&gt;我和我的小伙伴们都惊呆了，不知道该作何反应，即使到现在回想起来，仍然会觉得手足无措。那一刻，永远地停留在了我的记忆中。&lt;/p&gt;&lt;/blockquote&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/07b0942c3286ef06aa261e65a91346f4.jpg" data-rawwidth="702" data-rawheight="408"&gt;&lt;p&gt;&lt;b&gt;对《Early Amazon》全系列感兴趣的，请关注ResysChina微信公众号，回复「amazon」即可。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;参考资料：[1] https://www.quora.com/Was-Amazon-s-recommendation-engine-crucial-to-the-company-s-success[2] &lt;a href="https://medium.com/@amit_sharma/how-much-traffic-do-recommender-systems-actually-cause-2e0c6708801f" class="hover"&gt;https://medium.com/@amit_sharma/how-much-traffic-do-recommender-systems-actually-cause-2e0c6708801f&lt;/a&gt;[3] https://www.quora.com/What-do-Recommender-Systems-experts-think-of-the-Estimating-the-causal-impact-of-recommendation-systems-from-observational-data-paper[4] http://glinden.blogspot.com/2006/03/early-amazon-similarities.html&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;推荐关注微信公众号【ResysChina】，中国最专业的个性化推荐技术与产品社区。更多内容会首发在微信公众号。&lt;/p&gt;&lt;p&gt;猜你喜欢：「&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA4OTk5OTQzMg==&amp;amp;mid=2449231099&amp;amp;idx=1&amp;amp;sn=6ff30a52fbbe9d01ef022661c6325dc4&amp;amp;scene=21#wechat_redirect" data-editable="true" data-title="Netflix推荐系统的最新解读：算法、商业价值与创新"&gt;Netflix推荐系统的最新解读：算法、商业价值与创新&lt;/a&gt;」&lt;/p&gt;&lt;/blockquote&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/21622055&amp;pixel&amp;useReferer"/&gt;</description><author>谷文栋</author><pubDate>Sun, 17 Jul 2016 16:42:31 GMT</pubDate></item><item><title>分类问题损失函数的信息论解释</title><link>https://zhuanlan.zhihu.com/p/21562401</link><description>&lt;p&gt;分类问题的优化过程是一个损失函数最小化的过程，对应的损失函数一般称为logloss，对于一个多分类问题，其在N个样本上的logloss损失函数具有以下形式：&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/c80376d8d4c3bee45342ca15ee71da69.png" data-rawwidth="440" data-rawheight="88"&gt;&lt;p&gt;其中，yi(n)代表第n个样本是否属于第i个类别，取值为0或1，f(x(n))i代表分类模型对于第n个样本属于第i个类别的预测概率。将上面的式子稍作简化就可以得到我们常见的二分类问题下的损失函数，在这里不做展开，我们下面的讨论也都对于更为一般的多分类问题展开，而这些讨论对于二分类问题显然也同样适用。&lt;/p&gt;&lt;p&gt; 上面的损失函数，很容易从最大似然的角度来做理解，也就是说等号右边的部分，去掉负号以后，对应着模型的一个估计f在N个样本上（取了log）的似然函数，而似然函数的最大化就对应着损失函数的最小化。&lt;/p&gt;&lt;p&gt; 但是这个损失函数还有另外一个名字，叫做cross-entropy loss，从名字可以看出，这是一个信息论相关的名字，我们这篇文章就从信息论的角度，来理解一下分类问题的损失函数。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;重新认识熵（entropy）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;说起熵，大家都能知道衡量的是“数据的混乱程度”，但是它具体是如何衡量的呢？让我们首先来重新认识一下熵。&lt;/p&gt;&lt;p&gt; 现在是周五的下班高峰期，你站在北京东三环的一座天桥上面，望着一辆辆汽车穿梭而过。你现在肩负着一个任务：你需要告诉我你看到的每一辆车的品牌型号，而我们的通讯工具，是一个二进制的通信管道，里面只能传输0或者1，这个管道的收费是1￥/bit。&lt;/p&gt;&lt;p&gt; 显然你需要设计一组二进制串，每个串对应一个车型，例如1001对应的是一辆大众桑塔纳。那么你要如何设计这一组二进制串呢？具体来说，你会为丰田凯美瑞和特斯拉ModelS设计同样长度的串吗？&lt;/p&gt;&lt;p&gt; 即使你不精通概率论，你可能也不会这么做，因为你知道大街上跑着的凯美瑞肯定比ModelS多得多，用同样长度的bit来传输肯定是不经济的。你肯定会为凯美瑞设计一个比较短的串，而为ModelS设计一个长一些的串。你为什么会这么做？本质上来讲，你是在利用你对分布的先验知识，来减少所需的bit数量。那具体我们应该如何利用分布知识来对信息进行编码呢？&lt;/p&gt;&lt;p&gt; 幸运的是，香农（Shannon）老先生证明了，如果你知道一个变量的真实分布，那么为了使得你使用的平均bit最少，那么你应该给这个变量的第i个取值分配log1/yi个bit，其中yi是变量的第i个取值的概率。如果我们按照这样的方式来分配bit，那么我们就可以得到最优的数据传输方案，在这个方案下，我们为了传输这个分布产生的数据，平均使用的bit数量为：&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/0fa565cb676ee18e66627b40a95c6312.png" data-rawwidth="415" data-rawheight="89"&gt;&lt;p&gt;有没有很眼熟？没错，这就是我们天天挂在嘴边的熵（entropy）。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;交叉熵（cross entropy）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在上面的例子中，我们利用我们对数据分布y的了解，来设计数据传输方案，在这个方案中，数据的真实分布y充当了一个“工具”的角色，这个工具可以让我们的平均bit长度达到最小。&lt;/p&gt;&lt;p&gt; 但是在大部分真实场景中，我们往往不知道真实y的分布，但是我们可以通过一些统计的方法得到y的一个估计。如果我们用来设计传输方案，也就是说，我们给分布的第i个取值分配log1/yi个bit，结果会是怎样？&lt;/p&gt;&lt;p&gt; 套用之前的式子，将log中的y替换成为y^，我们可以得到，如果使用y^作为“工具”来对数据进行编码传输，能够使用的最小平均bit数为：&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/6c676ba78487f2da9e745006a1f976e8.png" data-rawwidth="435" data-rawheight="87"&gt;&lt;p&gt;这个量，就是所谓的交叉熵（cross entropy），代表的就是使用y^来对y进行编码的话，需要使用的最短平均bit串长度。&lt;/p&gt;&lt;p&gt; 交叉熵永远大于或等于熵，因为交叉熵是在用存在错误的信息来编码数据，所以一定会比使用正确的信息要使用更多的bit。只有当y^和y完全相等时，交叉熵才等于熵。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;用交叉熵衡量分类模型质量&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;现在回到分类问题上来。假设我们通过训练得到了某模型，我们希望评估这个模型的好坏。从上面信道传输的角度来看，这个模型实际上提供了对真实分布y的一个估计y^。我们说要评估这个模型的好坏，实际是是想知道我们给出的估计y^和真实的分布y相差多大，那么我们可以使用交叉熵来度量这个差异。&lt;/p&gt;&lt;p&gt; 由于交叉熵的物理意义是用y^作为工具来传输y平均需要多少个bit，那我们可以计算一下如果用y^来传输整个训练数据集需要多少个bit，首先我们看一下传输第n个样本需要多少个bit。由于估计出来的模型对于第n个样本属于第i个类的预测概率是y^i(n)，而第n个样本的真实概率分布是yi(n)，所以这一个样本也可以看做是一个概率分布，那么根据交叉熵的定义：&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/c5e1bbd1c6d40414eb3f99fe80fadacc.png" data-rawwidth="267" data-rawheight="84"&gt;&lt;p&gt;那么传输整个数据集需要的bit就是：&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/72481ff52f1bf5dbdda28ff52d99dc89.png" data-rawwidth="481" data-rawheight="87"&gt;&lt;p&gt;进一步变换可得：&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/03426a8f3a180cbdbdb0995150365d0d.png" data-rawwidth="585" data-rawheight="83"&gt;&lt;p&gt;其中&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/04a5b3df967d2f4f5979ea56c61b76e9.png" data-rawwidth="158" data-rawheight="39"&gt;对比文章最开始的logloss损失函数可知：&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/6dcc8d0325a41cac6228492f6997978c.png" data-rawwidth="232" data-rawheight="35"&gt;&lt;p&gt;也就是说，分类问题的损失函数，从信息论的角度来看，等价于训练出来的模型（分布）与真实模型（分布）之间的交叉熵（两者相差一个只和样本数据量有关的倍数N），而这个交叉熵的大小，衡量了训练模型与真实模型之间的差距，交叉熵越小，两者越接近，从而说明模型越准确。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;总结&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;通过上面的讲解，我们从信息论的角度重新认识了分类问题的损失函数。信息论和机器学习是紧密相关的两个学科，从信息论的角度来说，模型优化的本质就是在减少数据中的信息，也就是不确定性。希望这个理解角度，能够让大家对分类问题有一个更全面的认识。希望对熵有进一步了解的同学，可以读一下香农老先生的著名文章《AMathematical Theory of Communication》，有时间的同学更可以研读一下《Elements ofInformation Theory》这本巨著，一定会让你的ML内功发生质的提升。&lt;/p&gt;&lt;p&gt; 本文的灵感和部分内容来自这篇文章：http://rdipietro.github.io/friendly-intro-to-cross-entropy-loss/。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;strong&gt;本文作者：&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;张相於（zhangxy@live.com），现任当当网推荐系统开发经理，负责当当网的推荐系统、NLP算法等工作。多年来主要从事推荐系统以及机器学习相关工作，也做过反垃圾、反作弊相关工作，并热衷于探索大数据技术&amp;amp;机器学习技术在其他领域的应用实践。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;微信公众号【&lt;strong&gt;ResysChina&lt;/strong&gt;】，中国最专业的个性化推荐技术与产品社区。更多内容会首发在微信公众号。&lt;/p&gt;&lt;p&gt;猜你喜欢：「&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA4OTk5OTQzMg==&amp;amp;mid=2449231122&amp;amp;idx=1&amp;amp;sn=daae86382c7cf3290bcd3da289aea8bb&amp;amp;scene=21#wechat_redirect" data-editable="true" data-title="机器学习系统丛林迷路指南" class=""&gt;机器学习系统丛林迷路指南&lt;/a&gt;」&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/21562401&amp;pixel&amp;useReferer"/&gt;</description><author>谷文栋</author><pubDate>Mon, 11 Jul 2016 23:46:43 GMT</pubDate></item><item><title>谷歌、Facebook、亚马逊、微软、NVIDIA及BAT在深度学习方面的进展</title><link>https://zhuanlan.zhihu.com/p/21479333</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/26abf7fdd2c7414c2495cd7217a5eb59_r.jpg"&gt;&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/c7239922d51f615c7542d7891d05199e.png" data-rawwidth="808" data-rawheight="448"&gt;&lt;h2&gt;&lt;strong&gt;星星之火，可以燎原&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;深度学习一度备受冷落，真正的燎原之势始于2012年多伦多大学Geoffrey Hinton的学生Alex Krizhesky在ILSVRC（ImageNet Large Scale Visual Recognition Challenge，ImageNet大规模视觉识别竞赛，&lt;a href="http://image-net.org/challenges/LSVRC/" class=""&gt;http://image-net.org/challenges/LSVRC/&lt;/a&gt;）中使用深度学习方法一举夺得图像分类、目标定位两个项目冠军，远远拉开了与第二名（传统计算机视觉方法）成绩的差距。&lt;/p&gt;&lt;p&gt;如图1-2所示为Alex在比赛中使用的深度学习模型AlexNet结构。注意到网络分成上下两部分，分别运行在两块GPU（Graphics Processing Unit）上，其中虚线表示两块GPU之间的数据通信。事实上，该模型已成为深度学习的模板结构，一些新模型（VGG/GoogLeNet）均在AlexNet基础上改进得到。&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/c903250beb364536bf90b00894ac6530.png" data-rawwidth="744" data-rawheight="384"&gt;                                            图1-2  AlexNet结构&lt;/p&gt;&lt;p&gt;为什么深度学习在2012年而不是其他时间爆发？主要有3个有利因素：&lt;/p&gt;&lt;p&gt;（1）更大的数据集，如ImageNet。&lt;/p&gt;&lt;p&gt;（2）新的深度学习技术，如ReLU、Dropout等技术。&lt;/p&gt;&lt;p&gt;（3）新的计算硬件，如GPU。&lt;/p&gt;&lt;p&gt;我们先看看国外的深度学习有哪些进展。&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;谷歌与微软&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Google在Geoffrey Hinton等大牛的带领下，在理论与技术方面一直保持世界领先地位。利用GoogLeNet，在2014年ILSVRC中其分类错误率低至6.66%。&lt;/p&gt;&lt;p&gt;基础平台包括早期基于大规模CPU集群的DistBelief（由16000个计算节点构成）和近期开放的支持GPU加速的TensorFlow。2016年朋友圈刷屏的“阿尔法狗”（AlphaGo）也是Google 强大深度学习的具体案例之一。&lt;/p&gt;&lt;p&gt;Microsoft在2015年ILSVRC目标检测任务中使用深度残余学习框架（Deep Residual Learning Framework）取得绝对优势，赢得200个类目中194个最佳检出率，平均检出概率高达62%（2014年同一任务最好结果为37%）。基于Caffe实现的Fast-RCNN（作者为Ross Girshick）在目标识别领域占有重要地位。&lt;/p&gt;&lt;p&gt;Microsoft在基础平台方面也势头强劲，2015年推出的Azure Machine Learning Studio 有大量的机器学习算法，适合用来构建预测分析解决方案。这些算法可用于一般的机器学习，如回归分析、分类、聚类和异常检测，且每一个都可以解决不同类型的机器学习问题。为其作支撑的不仅有高可扩展性、支持CPU/GPU计算的Minerva及分布式深度学习训练系统Adam、CNTK，还有利用Catapult加速深度卷积神经网络（DCNN）的项目也在进行中。&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;Facebook、亚马逊与NVIDIA&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Facebook于2013年成立了人工智能实验室，在Yann LeCun的带领下Facebook同纽约大学数据科学中心在数据科学、机器学习、人工智能领域展开合作，代表性工作有最著名的开源深度学习项目Torch（&lt;a href="http://torch.ch/" class=""&gt;http://torch.ch/&lt;/a&gt;）和fbcunn（&lt;a href="https://github.com/facebook/fbcunn"&gt;https://github.com/facebook/fbcunn&lt;/a&gt;）。&lt;/p&gt;&lt;p&gt;Amazon本身是做IaaS平台的，看到机器学习如火如荼的发展，也迅速融入并推出了云上的机器学习服务（&lt;a href="http://aws.amazon.com/cn/machine-learning/"&gt;http://aws.amazon.com/cn/machine-learning/&lt;/a&gt;），提供一种PaaS模式。Amazon Machine Learning提供可视化的工具和向导，无须学习复杂的机器学习算法和技术。使用简单的 API即可让用户应用程序轻松获得预测能力，而无须实现自定义预测生成码或管理任何基础设施。采用Amazon内部使用的机器学习方法，非常容易扩展。而且，使用Amazon Machine Learning不需要对硬件或软件事先投入资金，只需按使用量付费。&lt;/p&gt;&lt;p&gt;另外，不得不提NVIDIA，这家老牌显卡制造商也将未来方向瞄准了深度学习，于GTC 2015、2016连续发布多款面向深度学习的GPU加速器硬件（Titan X、Tesla P100）、加速库（cuDNN）和解决方案（DIGITS DevBox、DGX-1），为深度学习的普及和更大模型的支持起到推波助澜的作用。&lt;/p&gt;&lt;p&gt;以上为国外情况，国内情况又如何呢？&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;BAT在路上&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;百度是国内较早开展深度学习研究的企业，于2013年年初创立了百度深度学习实验室（Institute of Deep Learning，IDL，&lt;a href="http://idl.baidu.com/" class=""&gt;http://idl.baidu.com/&lt;/a&gt;），斯坦福大学教授、Google大脑创始人Andrew Ng随后加入。IDL研究方向包括深度学习&amp;amp;机器学习、机器人、人机交互、3D视觉、图像识别、语音识别等，同时开展了一系列深度学习相关的创新项目，如无人机、智能自行车DuBike、自动驾驶汽车、智能眼镜BaiduEye等。&lt;/p&gt;&lt;p&gt;百度在深度学习计算平台基础设施建设方面一直走在国内互联网公司的前列，百度在ImageNet挑战中取得的成绩得益于其超级计算机Minwa（36个服务器节点，每个节点2个六核Xeon E5-2620和4个NVIDIA Tesla K40m GPU）。为了提高深度学习算法的计算速度，百度在GPU和CPU上做了很多优化，发表了一些深度学习算法GPU加速的论文（虽然中间有点小插曲）。经过这些工作，百度也意识到GPU、CPU在深度学习应用中的成本效率、能耗效率和目标间的差距。在充分考量各种芯片的特性后，可编程、低功耗并拥有超强并行计算能力的FPGA走进了百度工程师们的视野。百度开始尝试用FPGA打造AI专有芯片，并成就了第一版AI专有芯片版百度大脑——FPGA版百度大脑。这使得百度成为了全球最早将FPGA规模应用在人工智能领域的公司。&lt;/p&gt;&lt;p&gt;阿里巴巴作为电子商务巨头，很早就看到了深度学习在商品检索方面的应用价值，在阿里巴巴图像搜索的领军人物、阿里巴巴搜索事业部研究员华先胜的带领下迅速将深度学习技术成功应用到手机淘宝图像搜索业务——拍立淘中。2015年“双11”当天，上千万消费者使用了拍立淘功能，引导了数千万元的销售额。拍立淘上线一年以来，所覆盖的类目范畴已经从最开始的女装，发展到目前的男女装、鞋包、配饰、食品、数码、家居、日用百货、内衣、瓶饮等十余个类目。与通用搜索主要依靠字节不同，图像搜索被主要定义为“以图搜图”。据华先胜介绍，图像搜索的第一步是训练计算机进行图像理解，也就是通过计算机将图片中的要素，包括人像、颜色、纹理等具体特征以及深度学习产生的图像描述，转换为类似于文字的“视觉词”，编成索引之后，才能再进行第二步——图像搜索。图像搜索仍有很多未知领域有待探索。在华先胜看来，能推动图像搜索下一步突破的关键有三点：深度学习、大数据分析和大量用户使用反馈。环顾国内外，似乎只有阿里巴巴能够同时具备这三个条件。对于“拍立淘”的未来，华先胜表示，拍立淘将会拓展到更多领域，力争成为人们获取信息（包括购物、教育、娱乐、新闻、知识等）的一个快捷、有趣、有效的入口，而不仅仅是搜寻商品的入口。&lt;/p&gt;&lt;p&gt;阿里巴巴在基础平台建设方面起步虽晚，但发展迅速，利用装备NVIDIA Tesla GPU的高性能计算集群，不仅完美支撑拍立淘、搜索、OCR、绿网、神马语音、iDST等内部业务，还进一步在2015年10月14日云栖大会上正式宣布通过阿里云对外提供公共云上的HPC服务（&lt;a href="https://www.aliyun.com/product/hpc"&gt;https://www.aliyun.com/product/hpc&lt;/a&gt;），使普通用户也有机会享受高性能计算平台带来的高效性和便利性。目前越来越多的中小企业选择租用云端HPC服务器，而不是自建机房做繁杂冗长的运维工作。最新机型G4配备了双Tesla M40作为加速器，可大大提高深度学习应用的运行效率，基于Docker的快速环境部署大幅降低了客户使用深度学习框架的门槛，可谓开箱即用。&lt;/p&gt;&lt;p&gt;腾讯拥有海量的社交关系数据，在深度学习应用方面潜力巨大，目前主要应用为语音识别、图像识别和广告推荐。腾讯优图（BestImage，&lt;a href="http://open.youtu.qq.com/" class=""&gt;http://open.youtu.qq.com/&lt;/a&gt;）是腾讯旗下顶级的机器学习研发团队，专注于图像处理、模式识别、深度学习等方向，在人脸检测、五官定位、人脸识别、图像理解领域都积累了完整解决方案和领先的技术水平。&lt;/p&gt;&lt;p&gt;腾讯在深度学习基础平台方面经历多次升级逐步完善，在Mariana基础上针对多种应用打造出Mariana DNN、Mariana CNN、Mariana Cluster等基础框架，在微信语音识别、微信图像识别方面均已成功落地，在图文类效果广告点击率提升方面也取得初步的应用。&lt;/p&gt;&lt;blockquote&gt;本文内容节选自博文视点新书《深度学习—21天实战Caffe》，&lt;strong&gt;作者为阿里@卜居&lt;/strong&gt;，&lt;a href="http://blog.csdn.net/kkk584520"&gt;http://blog.csdn.net/kkk584520&lt;/a&gt; 。京东购买链接：&lt;a href="http://item.jd.com/11933529.html" class=""&gt;http://item.jd.com/11933529.html&lt;/a&gt;&lt;/blockquote&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/26abf7fdd2c7414c2495cd7217a5eb59.jpg" data-rawwidth="389" data-rawheight="520"&gt;&lt;blockquote&gt;&lt;p&gt;推荐关注微信公众号【ResysChina】，中国最专业的个性化推荐技术社区。更多内容会首发在微信公众号。&lt;/p&gt;&lt;p&gt;猜你喜欢：「&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA4OTk5OTQzMg==&amp;amp;mid=2449231187&amp;amp;idx=1&amp;amp;sn=ecdb7cc4ddd8953bd0a48e8c14d8077a#rd" class="" data-editable="true" data-title="深度学习与推荐系统"&gt;关于LDA, pLSA, SVD, Word2Vec的一些看法&lt;/a&gt;」&lt;/p&gt;&lt;/blockquote&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/21479333&amp;pixel&amp;useReferer"/&gt;</description><author>谷文栋</author><pubDate>Mon, 04 Jul 2016 06:26:55 GMT</pubDate></item><item><title>UCB算法升职记——LinUCB算法</title><link>https://zhuanlan.zhihu.com/p/21404922</link><description>&lt;h2&gt;UCB再回顾&lt;/h2&gt;&lt;p&gt;上回书说到，UCB这个小伙子在做EE(Exploit-Explore)的时候表现不错，只可惜啊，是一个不关心组织的上下文无关(context free)bandit算法，它只管埋头干活，根本不观察一下面对的都是些什么样的arm。&lt;/p&gt;&lt;p&gt;进一步送UCB去深造之前，我们再把UCB算法要解决的问题描述一下：&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;面对固定的K个item（广告或推荐物品），我们没有任何先验知识，每一个item的回报情况完全不知道，每一次试验要选择其中一个，如何在这个选择过程中最大化我们的回报？&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;UCB解决这个Multi-armed bandit问题的思路是：用置信区间。置信区间可以简单地理解为不确定性的程度，区间越宽，越不确定，反之亦反之。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;每个item的回报均值都有个置信区间，随着试验次数增加，置信区间会变窄（逐渐确定了到底回报丰厚还是可怜）。&lt;/p&gt;&lt;p&gt;每次选择前，都根据已经试验的结果重新估计每个item的均值及置信区间。&lt;/p&gt;&lt;p&gt;选择置信区间上限最大的那个item。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;“选择置信区间上界最大的那个item”这句话反映了几个意思：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;如果item置信区间很宽（被选次数很少，还不确定），那么它会倾向于被多次选择，这个是算法冒风险的部分；&lt;/li&gt;&lt;li&gt;如果item置信区间很窄（备选次数很多，比较确定其好坏了），那么均值大的倾向于被多次选择，这个是算法保守稳妥的部分；&lt;/li&gt;&lt;li&gt;UCB是一种乐观的算法，选择置信区间上界排序，如果时悲观保守的做法，是选择置信区间下界排序。&lt;/li&gt;&lt;/ol&gt;&lt;h2&gt;给UCB插上特征的翅膀&lt;/h2&gt;&lt;p&gt;UCB还是很有前途的，所以算法大神们还是有心提携它一把。&lt;/p&gt;&lt;p&gt;这不，Yahoo!的科学家们在2010年发表了一篇论文[1]，给UCB指了一条明路，同时还把改造后的UCB算法用在了Yahoo!的新闻推荐中，深造后的UCB算法现在title叫LinUCB。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/bb509cf00cfc4c610ad8127cab105f17.png" data-rawwidth="1330" data-rawheight="732"&gt;&lt;p&gt;这篇论文很有名，很多地方都有引用，在刘鹏博士的著作《计算广告》中也专门讲到了[2]。我知道，大家都很忙，尤其是面对英文论文，尤其是论文中有大量的数学公式，所以“没时间”去阅读它，所以这里我就转述一下这个算法的改造过程，以期望大家在百忙之中能够领会其精神。&lt;/p&gt;&lt;p&gt;单纯的老虎机，它回报情况就是老虎机自己内部决定的，而在广告推荐领域，一个选择的回报，是由User和Item一起决定的，如果我们能用feature来刻画User和Item这一对CP，在选择之前通过feature预估每一个arm的期望回报及置信区间，那就合理多了。&lt;/p&gt;&lt;p&gt;为UCB插上特征的翅膀，这就是LinUCB最大的特色。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;LinUCB算法做了一个假设：一个Item被选择后推送给一个User，其回报和相关Feature成线性关系，这里的“相关feature”就是context，也是实际项目中发挥空间最大的部分。&lt;/p&gt;&lt;p&gt;于是试验过程就变成：用User和Item的特征预估回报及其置信区间，选择置信区间上界最大的item推荐，观察回报后更新线性关系的参数，以此达到试验学习的目的。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;LinUCB基本算法描述如下：&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/2a723bc14fdc75d6ac8a6934057e7550.png" data-rawwidth="690" data-rawheight="546"&gt;&lt;p&gt;对照每一行解释一下：&lt;/p&gt;&lt;p&gt;0. 设定一个参数\alpha，这个参数决定了我们Explore的程度&lt;/p&gt;&lt;p&gt;1. 开始试验迭代&lt;/p&gt;&lt;p&gt;2. 获取每一个arm的特征向量xa,t&lt;/p&gt;&lt;p&gt;3. 开始计算每一个arm的预估回报及其置信区间&lt;/p&gt;&lt;p&gt;4. 如果arm还从没有被试验过，那么：&lt;/p&gt;&lt;p&gt;5. 用单位矩阵初始化Aa&lt;/p&gt;&lt;p&gt;6. 用0向量初始化ba，&lt;/p&gt;&lt;p&gt;7. 处理完没被试验过的arm&lt;/p&gt;&lt;p&gt;8. 计算线性参数\theta&lt;/p&gt;&lt;p&gt;9. 用\theta和特征向量xa,t计算预估回报, 同时加上置信区间宽度&lt;/p&gt;&lt;p&gt;10. 处理完每一个arm&lt;/p&gt;&lt;p&gt;11. 选择第9步中最大值对应的arm，观察真实的回报rt&lt;/p&gt;&lt;p&gt;12. 更新Aat&lt;/p&gt;&lt;p&gt;13. 更新bat&lt;/p&gt;&lt;p&gt;14. 算法结束&lt;/p&gt;&lt;p&gt;本来，按照上面的步骤已经可以写代码完成KPI了，但是我们都是爱学习的小伙伴，其中一些关键的地方还得弄得更明白些。&lt;/p&gt;&lt;p&gt;注意到上面的第4步，给特征矩阵加了一个单位矩阵，这就是岭回归（ridge regression），岭回归主要用于当样本数小于特征数时，对回归参数进行修正［3］。&lt;/p&gt;&lt;p&gt;对于加了特征的bandit问题，正符合这个特点：试验次数（样本）少于特征数。&lt;/p&gt;&lt;p&gt;每一次观察真实回报之后，要更新的不止是岭回归参数，还有每个arm的回报向量ba。&lt;/p&gt;&lt;h2&gt;实现LinUCB&lt;/h2&gt;&lt;p&gt;根据论文给出的算法描述，其实很好写出LinUCB的代码[5]，麻烦的只是构建特征。&lt;/p&gt;&lt;p&gt;代码如下，一些必要的注释说明已经写在代码中。&lt;/p&gt;&lt;pre&gt;&lt;code lang="python"&gt;class LinUCB:

    def __init__(self):

        self.alpha = 0.25 

        self.r1 = 1 # if worse -&amp;gt; 0.7, 0.8

        self.r0 = 0 # if worse, -19, -21

        # dimension of user features = d

        self.d = 6

        # Aa : collection of matrix to compute disjoint part for each article a, d*d

        self.Aa = {}

        # AaI : store the inverse of all Aa matrix

        self.AaI = {}

        # ba : collection of vectors to compute disjoin part, d*1

        self.ba = {}

        

        self.a_max = 0

        

        self.theta = {}

        

        self.x = None

        self.xT = None

        # linUCB



    def set_articles(self, art):

        # init collection of matrix/vector Aa, Ba, ba

        for key in art:

            self.Aa[key] = np.identity(self.d)

            self.ba[key] = np.zeros((self.d, 1))

            self.AaI[key] = np.identity(self.d)

            self.theta[key] = np.zeros((self.d, 1))

            

    """

    这里更新参数时没有传入更新哪个arm，因为在上一次recommend的时候缓存了被选的那个arm，所以此处不用传入

    

    另外，update操作不用阻塞recommend，可以异步执行

    """        

    def update(self, reward):

        if reward == -1:

            pass

        elif reward == 1 or reward == 0:

            if reward == 1:

                r = self.r1

            else:

                r = self.r0

            self.Aa[self.a_max] += np.dot(self.x, self.xT)

            self.ba[self.a_max] += r * self.x

            self.AaI[self.a_max] = linalg.solve(self.Aa[self.a_max], np.identity(self.d))

            self.theta[self.a_max] = np.dot(self.AaI[self.a_max], self.ba[self.a_max])

        else:

        # error

            pass

    

    """

    预估每个arm的回报期望及置信区间

    """

    def recommend(self, timestamp, user_features, articles):

        xaT = np.array([user_features])

        xa = np.transpose(xaT)

        art_max = -1

        old_pa = 0

        

        # 获取在update阶段已经更新过的AaI(求逆结果)

        AaI_tmp = np.array([self.AaI[article] for article in articles])

        theta_tmp = np.array([self.theta[article] for article in articles])

        art_max = articles[np.argmax(np.dot(xaT, theta_tmp) + self.alpha * np.sqrt(np.dot(np.dot(xaT, AaI_tmp), xa)))]



# 缓存选择结果，用于update

        self.x = xa

        self.xT = xaT

        # article index with largest UCB

        self.a_max = art_max

        

        return self.a_max  


&lt;/code&gt;&lt;/pre&gt;&lt;h2&gt;怎么构建特征&lt;/h2&gt;&lt;p&gt;LinUCB算法有一个很重要的步骤，就是给User和Item构建特征，也就是刻画context。在原始论文里，Item是文章，其中专门介绍了它们怎么构建特征的，也甚是精妙。容我慢慢表来。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;原始用户特征有：&lt;/li&gt;&lt;/ul&gt;&lt;blockquote&gt;&lt;p&gt;人口统计学：性别特征（2类），年龄特征（离散成10个区间）&lt;/p&gt;&lt;p&gt;地域信息：遍布全球的大都市，美国各个州&lt;/p&gt;&lt;p&gt;行为类别：代表用户历史行为的1000个类别取值&lt;/p&gt;&lt;/blockquote&gt;&lt;ul&gt;&lt;li&gt;原始文章特征：&lt;/li&gt;&lt;/ul&gt;&lt;blockquote&gt;&lt;p&gt;URL类别：根据文章来源分成了几十个类别&lt;/p&gt;&lt;p&gt;编辑打标签：编辑人工给内容从几十个话题标签中挑选出来的&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;原始特征向量都要归一化成单位向量。&lt;/p&gt;&lt;p&gt;还要对原始特征降维，以及模型要能刻画一些非线性的关系。&lt;/p&gt;&lt;p&gt;用Logistic Regression去拟合用户对文章的点击历史，其中的线性回归部分为：&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/258fa9cc52b3945262b68716f260d6f6.png" data-rawwidth="210" data-rawheight="62"&gt;&lt;p&gt;拟合得到参数矩阵W，可以将原始用户特征（1000多维）投射到文章的原始特征空间（80多维），投射计算方式：&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/6d2242d2d90afc87aa08e82f387c66a1.png" data-rawwidth="262" data-rawheight="80"&gt;&lt;p&gt;这是第一次降维，把原始1000多维降到80多维。&lt;/p&gt;&lt;p&gt;然后，用投射后的80多维特征对用户聚类，得到5个类簇，文章页同样聚类成5个簇，再加上常数1，用户和文章各自被表示成6维向量。&lt;/p&gt;&lt;p&gt;Yahoo!的科学家们之所以选定为6维，因为数据表明它的效果最好[4]，并且这大大降低了计算复杂度和存储空间。&lt;/p&gt;&lt;p&gt;我们实际上可以考虑三类特征：U（用户），A（广告或文章），C（所在页面的一些信息）。&lt;/p&gt;&lt;p&gt;前面说了，特征构建很有发挥空间，算法工程师们尽情去挥洒汗水吧。&lt;/p&gt;&lt;h2&gt;总结&lt;/h2&gt;&lt;p&gt;总结一下LinUCB算法，有以下优点：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;由于加入了特征，所以收敛比UCB更快（论文有证明）；&lt;/li&gt;&lt;li&gt;特征构建是效果的关键，也是工程上最麻烦和值的发挥的地方；&lt;/li&gt;&lt;li&gt;由于参与计算的是特征，所以可以处理动态的推荐候选池，编辑可以增删文章；&lt;/li&gt;&lt;li&gt;特征降维很有必要，关系到计算效率。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;另外，可能有人已经发现了，bandit算法有个问题，就是要求同时参与候选的arm数量不能太多，几百上千个差不多了，更多就不好处理了，如果arm更多的时候，recommend也是异步计算，这块可以深思一下，尽是工程上的事。&lt;/p&gt;&lt;p&gt;当年在学习Yahoo!这篇介绍LinUCB论文时，还一一看了其参考文献，比如这两篇，一个是关于特征处理的[6]，一个是关于降维和数据分析的[7]，有兴趣也可以看看，这里就不画重点了，高考不考。&lt;/p&gt;&lt;p&gt;[1] &lt;a href="http://www.research.rutgers.edu/~lihong/pub/Li10Contextual.pdf" class=""&gt;http://www.research.rutgers.edu/~lihong/pub/Li10Contextual.pdf&lt;/a&gt;&lt;/p&gt;&lt;p&gt;[2] 《计算广告：互联网商业变现的市场与技术》p253, 刘鹏，王超著&lt;/p&gt;&lt;p&gt;[3] &lt;a href="https://en.wikipedia.org/wiki/Tikhonov_regularization" class=""&gt;https://en.wikipedia.org/wiki/Tikhonov_regularization&lt;/a&gt;&lt;/p&gt;&lt;p&gt;[4] &lt;a href="http://www.gatsby.ucl.ac.uk/~chuwei/paper/isp781-chu.pdf" class=""&gt;http://www.gatsby.ucl.ac.uk/~chuwei/paper/isp781-chu.pdf&lt;/a&gt;&lt;/p&gt;&lt;p&gt;[5] &lt;a href="https://github.com/Fengrui/HybridLinUCB-python/blob/master/policy_hybrid.py"&gt;https://github.com/Fengrui/HybridLinUCB-python/blob/master/policy_hybrid.py&lt;/a&gt;&lt;/p&gt;&lt;p&gt;[6] &lt;a href="http://www.wwwconference.org/www2009/proceedings/pdf/p691.pdf" class=""&gt;http://www.wwwconference.org/www2009/proceedings/pdf/p691.pdf&lt;/a&gt;&lt;/p&gt;&lt;p&gt;[7] &lt;a href="http://www.gatsby.ucl.ac.uk/~chuwei/paper/isp781-chu.pdf"&gt;http://www.gatsby.ucl.ac.uk/~chuwei/paper/isp781-chu.pdf&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;本文首发微信公众号【ResysChina】，中国最专业的个性化推荐技术社区。&lt;/h2&gt;&lt;h2&gt;猜你喜欢：&lt;a href="https://zhuanlan.zhihu.com/p/21388070" data-title="「专治选择困难症——bandit算法」" class=""&gt;「专治选择困难症——bandit算法」&lt;/a&gt;&lt;/h2&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/21404922&amp;pixel&amp;useReferer"/&gt;</description><author>刑无刀</author><pubDate>Thu, 23 Jun 2016 14:30:09 GMT</pubDate></item></channel></rss>