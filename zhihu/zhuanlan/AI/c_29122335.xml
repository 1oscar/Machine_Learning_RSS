<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>混沌巡洋舰 - 知乎专栏</title><link>https://zhuanlan.zhihu.com/c_29122335</link><description>跨界思考内容供应商，与微信公众号混沌巡洋舰同属于巡洋舰科技公司。</description><lastBuildDate>Mon, 12 Sep 2016 08:17:17 GMT</lastBuildDate><generator>Ricky</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>人生意义的热力学解读</title><link>https://zhuanlan.zhihu.com/p/22397889</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/67608a6ebdc75ba06183eb17ac4f7774_r.jpg"&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;作者：许铁&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;strong&gt;热力学，物理里最热辣的主题，是一种简化复杂事物的惊人思维方式，不仅可以用于物理，更可以作为一种抽象的比喻， 来理解人生。本文是自己茶余饭后的一些思考，重在启迪。&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em&gt;受物理启发，我提出生命的本质是寻找“序”或者范式，即找到一种生命模式，能够持久的调动你所有精神能量，以至忘我境界。我说，这就是生命的意义。如同一个沙滩上的少年，从浮沙中堆起一个城堡。&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为什么人生可以用热力学阐述？ 因为人归根结底活在自己的内心活动里，内心的物质基础是神经系统，它处在与外界不断的能量和信息（记住，世界的主旋律！）交换中， 这与热力学系统极为神似。 而无论是气体还是神经系统，背后的数学原理都是自组织。即大系统的复杂性（“智慧”）是大量简单（“愚蠢”）的小单元相互作用而产生的。&lt;/p&gt;&lt;p&gt;热力学里面有两个永恒的主题，那就是能量和熵。 什么是能量？ 能量就是系统做功的能力，我们说一个人能量十足是因为它在不停的运动和做事，物理也是一样的，它说的是一个系统不停的运动和推动自身发生变化的能力。&lt;/p&gt;&lt;p&gt;什么是熵？ 对于一个复杂的系统，比如一群分子，一个人群，首先具有的性质就是不确定性。因为大量元素的情报是不可能完全掌握的(统计学核心问题)。我们把距离确定性描述这个系统所缺失的信息，叫做熵（系统每种可能状态的概率对数的期望之负值）。数学上讲就是你还需要多少比特的信息可以把系统状态完全确定，熵就是不确定性的大小。用比较文科的思维理解，高熵就对应一种我们不可知，不可控的局面，有人称之为无序（系统秩序-结构-order的丧失往往代表大量不确定可能的出现），虽然这类比喻并不完全准确。你可以想象一个无序的跳蚤市场，不同的人叫卖个人物件，你早起去市场上看，你唯一知道的是你不知道市场有什么，就是典型的高熵体系。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/d513890e48af05819357dd3fe356f0e7.png" data-rawwidth="659" data-rawheight="214"&gt;&lt;p&gt;&lt;strong&gt;图： 熵是不确定性的量度，系统自发的变化是从低熵到高熵，一个图像从清晰，逐步模糊的过程，是为时间的箭头。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;懂得熵就可以懂得信息： 信息就是反方向的熵，或者说不确定性的减少。在一个复杂系统里，你知道的信息越多，系统的随机性（自由选择）就越小。用理科的思维信息就是降维（dimensions reduction），用文科的思维信息就是有序。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;热力学的三大定律，都围绕能量和熵。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;第一定律--能量守定律&lt;/strong&gt;：系统做功的能力是不可以随便产生或减少的，而是有一定的值。如果你需要增加能量，就要和外界交换。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;第二定律-熵增加定律&lt;/strong&gt;： 孤立系统（没有能量和物质进入系统，例如整个宇宙就是一个孤立系统），熵是只增不减的。这是一个神一般的定律，指出万物演化的趋势。整个宇宙的熵增大，使得时间有了方向，或者说时间轴的对称性被打破，未来（高熵）和过去（低熵）成为了截然不同的部分。它给出宇宙一个终结的状态-失序，所有有结构的形态的崩溃，大到文明，小到细胞，都只能化作尘埃。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;第三定律， 热力学零点&lt;/strong&gt;。在此不叙。&lt;/p&gt;&lt;p&gt;热力学第二定律，所谓时间之矢，是我所有物理定律里最喜欢的。因为它指出事物的天然倾向性，那就是走向不确定性的增大（我们统称为失序）。 通常我们使用熵最大原理的时候要考虑系统的限制条件，比如热力学系统的体积，能量，求解一个在限制条件下的最优化问题（原则上可以解决所有热力学问题）。  &lt;/p&gt;&lt;p&gt;接下来说说人，刚才说生物系统和气体都是复杂系统，但是作为生物体的你和气体的本质区别是什么？&lt;strong&gt;一言以蔽之：生物体从无序向有序发展（熵减少），气体从有序向无序发展（熵增加）。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;或者说，生物体遵循逆热力学第二定律。最大化信息而最小化不确定性（无序）。何为最大化信息？ 其实就是对外界环境变化的贝叶斯学习， 或者说根据外界环境的变化，系统作出某种反应，然后通过得到的环境反馈来调整学习的过程。  这与机器学习里的增强学习异曲同工。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;无论是生命进化，还是我们出生以后学习的过程， 都是逐步从简单到复杂，增加对外界环境的掌控力-或者说增加确定性的过程。生物把它亿万年掌握的环境信息写入DNA的编码。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/ba0889fa1e1ad95092ebca8fb7d83934.png" data-rawwidth="639" data-rawheight="348"&gt;&lt;p&gt;&lt;strong&gt;图：DNA 即意外年里生物为对抗熵增，减少不确定性所凝结的生命之塔。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;但是从无序向有序是要付出代价的，代价就是为了维持自身的结构，你就要不停的导入和导出能量。&lt;/strong&gt; 为什么？想一想，自然的趋势是无序，你要使自己有序，或者说宇宙总的熵是增加的，而你的熵要减少，那就是宇宙其他的部分要为你的熵减少付出代价。怎么办？ 宇宙其它部分的熵必须增加。就是要从宇宙里导入有序（负数的熵），而把无序（熵）还给宇宙。而熵作为信息，是不能够独立存在的，它必须依托一个载体-能量。 因此最终就是作为生物体的你要让能量携带着有序（负熵）进入而携带着无序（熵）流出，自身获得秩序和结构，而把无序还给宇宙。&lt;strong&gt;这个过程吸入能量放出熵的过程在生物学上称作新陈代谢。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;单个的生物体是无法长期支撑这种代价的，系统抵抗熵增的能力随时间减弱，&lt;strong&gt;是为衰老过程， 并最终&lt;/strong&gt;淹没在熵增的洪流中，即死亡。然而群体的生命之流却可以在更长时间尺度抵抗熵增。  &lt;/strong&gt;&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/33e0653221ee73c105827dfdfe3867f6.png" data-rawwidth="590" data-rawheight="361"&gt;&lt;p&gt;&lt;strong&gt;图： 衰老与失序。年轻与俊美多与紧致有序有关，而衰老则伴随着松弛失序，或不确定性的增加。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;认知和学习的本质也是从无序到有序，减少不确定。&lt;/strong&gt; 我们的存在，无非可以分解为对外界的感知和相应的行动（Perception &amp;amp; Action）。 感知决定行动，行动的结果通过感知反馈给我们。  我们大脑的神经活动所干的主要事情，就是猜测某种行动将要产生什么样的结果。  当大脑的猜测完全不靠谱，即不确定性高。而猜测越精确，则不确定性越小。 &lt;strong&gt;认知学习的宗旨，就是精确预测，产生理想的结果（熵减）。 &lt;/strong&gt;&lt;/p&gt;&lt;p&gt;基于这种生物存在的本性，我来回答人类存在的一个基本问题： 活着的意义何在？ 其实这个问题问错了，因为不站在上帝视角，你连意义是什么都不知道。 而开启物理思维，就是开启上帝模式。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;生命皆流&lt;/strong&gt;:   生命是一个暂态过程。能量流动的过程即生命。体现在我们的意识层面，就是永恒不息的欲望。食欲满足后的爱欲，爱欲满足后的求知欲。或者我们可以管这个叫欲望守恒吧。欲望如同无序奔腾的河，意义不对应某一欲望的满足，因为欲求不满是永恒的状态。 &lt;/p&gt;&lt;p&gt;&lt;strong&gt;快乐&lt;/strong&gt;：如果意义真的存在，那么快乐是它唯一的载体。因为感知即存在，但是苦辣酸甜的感知本身是没有好坏意义的。赋予他们以好坏的，是快乐不快乐。&lt;/p&gt;&lt;p&gt;但是快乐是什么？ 神经科学里把它和一种多巴胺的化学物质联系起来。 多巴胺是大脑对行为的奖励机制。这样看来快乐只是表象，它是系统各种复杂因素综合后的一个表征量（如同热力学系统的温度）。如果你只为追求快乐而活你就注定达不到快乐，因为你没有看到他背后的深层动因。怎么才能快乐？ 请往下看。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;焦虑&lt;/strong&gt;： 焦虑与不确定性相关，因为这是生物要极端回避的状态。任何不确定的事件，躲在森林里的老虎或者明早没有准备好的考试都使我们焦虑。所以有保险业。从焦虑的对立面看，我们可以反观快乐， 快乐必然与不确定性的减少，或者说秩序的建立相关（熵减）。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;人生目的：&lt;/strong&gt;人生本无目的，我们却一定要赋予它一个目的，为什么要钻牛角尖？ 因为目的是赋予人生秩序的手段，或者说从无序中划出有序，从一大堆随机的噪声中聚沙成塔。 之后我管它叫生命之序。当然并非每一个目的都可以成为序，只有那些能你把四处发散的欲望之流收敛到一处的目的才可称作序。  &lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/578af4be74707aea690fc1408de27160.png" data-rawwidth="639" data-rawheight="421"&gt;图： 人生目的的作用是在散沙之上堆砌起绵延的沙丘。 &lt;/p&gt;&lt;p&gt;&lt;strong&gt;序从哪里来？&lt;/strong&gt; 序在我们的基因里。基因就是亿万年光阴被大自然选择的序。也正因为此，生命的序是先验的，不能由推理得来，而只可由生活经验的积累中感知得到。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;回到快乐&lt;/strong&gt;：&lt;/p&gt;&lt;p&gt;快乐有两种，一个是快感，一个是幸福。 快感是暂时性的，往往与欲望满足相关，过后却可以迅速的被空虚痛苦所抵消。 而幸福是快乐在时间的积分。 或者说持续性的快乐。  它与人生目的紧密相连。&lt;/p&gt;&lt;p&gt;持续的快乐来源于你所赋予人生的目的是否能特别有效的把你消耗的时间（能量）转化为美妙的秩序。  序就像一个魔石或者说种子，如果找的准，它就可以把你的生命能量完全旋入其中，呈现出它本来该有的结构，其乐亦无穷。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;人生意义&lt;/strong&gt;： 生命的本质即熵减。  通过确立符合自己的人生目的，最有效的把欲望之流中的无序转化为生命之序，就是人生的意义。&lt;/p&gt;&lt;p&gt;作为独立个体的意义首要找寻适合自身的序。 对于不同的个体，最优的序是不同的。 因此，要思考人生目的一类的问题，不是空想一个我要当大老板大教授，而是一种宏观结构的思维，寻找自身生命的宏观结构或格局。大老板大教授都觉得好，但是到你头上，也许只是痛苦。你可以欺骗世人，却难以欺骗自己。 而且错误的序，实现的可能非常之低。 &lt;/p&gt;&lt;p&gt;&lt;strong&gt;下一篇的故事，我要谈谈如何找寻生命的序（欢迎和铁哥微信探讨562763765）。&lt;/strong&gt;&lt;/p&gt;</description><author>许铁-巡洋舰科技</author><pubDate>Sun, 11 Sep 2016 03:26:05 GMT</pubDate></item><item><title>阴谋论为何总是错的？</title><link>https://zhuanlan.zhihu.com/p/22394270</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/accf39d4c46d27b98c67ac2a6c2137d5_r.jpg"&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;作者 代毓成&lt;/b&gt;&lt;/p&gt;&lt;p&gt;由于互联网技术的发展和普及，很多人如今将自己获取知识的方式从传统的书籍，转移到了网络，不仅是需求方，许多知识生产者也因势利导，逐渐地将思想铺陈于网络，微博微信知乎豆瓣等等平台，一个个不成熟的思想市场就此涌现，好不热闹。&lt;/p&gt;&lt;p&gt;之所以说他不成熟，不仅是很多知识领域尚存禁忌和管制，更多地，我想是许多人对知识这一基本概念仍未厘清，而容易沉浸在纷扰的噪音之中，反而失去了对重要问题的感受。&lt;/p&gt;&lt;p&gt;&lt;b&gt;因为，就知识而言，许茨的理解认为，它一定是基于“常识”的一次建构。&lt;/b&gt;没有常识，只是从观念到观念，而非真知，因为它和我们的生活没有联系。就像学习任何一门社会科学，&lt;b&gt;最主要的就是源于真实的生活体验，其次才是给予常识的二次建构，知识过程与人生体验不断反馈，所得到的观念才会更加可靠&lt;/b&gt;。而对于&lt;b&gt;阴谋论&lt;/b&gt;，一种网络上盛行的“知识”载体，我们需要理解和警惕，在上述对于“知识”的基本概念之外，&lt;b&gt;为什么他们总是错的？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;首先在思维上，&lt;/b&gt;出于很多历史原因的作用，许多国人还处于&lt;b&gt;非黑即白&lt;/b&gt;的阶段。比如当人们讨论世俗意义上的成功时，总是喜欢向两个极端靠近，要么归结于运气（或出身），要么归结于努力，而事实上，自然界中生活在色谱两级的生物总是少数，某位长者的归纳可能最为精当：“一个人的命运，当然要靠自我奋斗，但是也要考虑到历史的进程”。再比如对于许多社会问题的理解，即使学界也存在着一种冲动，要么集体主义，要么个人主义，在以前的一篇“读汪丁丁《行为经济学要义》”中我介绍过，不同社会在集体与个人之间的社会网络很可能大相径庭，没有现实世界的观察，没有对常识的感受，从知识到知识的不断演绎，所得结论并不可靠。&lt;/p&gt;&lt;p&gt;&lt;b&gt;另一方面，现实中所发生的事物，很少有简单的单因单果，而普遍是多因多果&lt;/b&gt;。如果只验证一条因果链的关系，则需要控制其他所有的因果不起作用，而现实谈何容易，社会科学的学者没有科学实验，只能从观察带来的常识出发，培养对重要性的感受，来在多因多果中判断和提高假说的可能性。&lt;/p&gt;&lt;p&gt;&lt;b&gt;而简单化思维的后果之一，就是人们在面对复杂事物时，总是习惯于拿起自己的“奥卡姆剃刀”，剥离问题的复杂度，且过于突出符合自己认知的维度。&lt;/b&gt;在简单思维之下，当事情的复杂程度超出了一些人的理解能力，阴谋论似乎就永远有市场。正如很多人讨论两国关系的时候，总是习惯过度突出某一因素的重要性，要么民族矛盾不可调和，要么国际政治只有利益。正如在《平行历史》一书中作者的考究，阴谋论总是扎根于政治、经济或社会变革之中，且总是由社会失意的人士传播，在受教育阶层和中产阶级中也很有市场，毫无疑问，它扭曲了我们对历史的解读、对现在的理解，甚至和人生体验不断地融合，极端之人而更加极端。 &lt;/p&gt;&lt;p&gt;&lt;b&gt;再者，与一些谣言不同，阴谋论的叙事往往更加宏大且讲究逻辑，一步一步水到渠成。常人面对这带有部分真相的“黑箱”，往往在很多细节处难以证伪。&lt;/b&gt;所以，阴谋论者讲故事的风格，就是利用这信息不对称，不是拿出正当的、直接的证据，而是列举大量看似与其论点相关的旁征，或是引用一些常人难以获知的且就他知道的“事实”（如很多人讨论的转基因）。&lt;/p&gt;&lt;p&gt;但是我们可以知道的是，统计学的视角下，一个理性人实现一个大的事件或策略，过于维系在偶然因素或者不切实际的假设上，总是很不靠谱。比如笔者最近看的一个纪录片《法医秘档》，就间接地讲述了这样一个道理：“你可能在一切时刻欺骗一些人，你也可能在一些时刻欺骗一切人，但你不可能在一切时刻欺骗一切人。”在技术加速迭代的今天，再精心策划的案件，也会因为一点疏忽而导致案情败露。&lt;/p&gt;&lt;p&gt;对此，波普尔早在《猜想与反驳》一书中就从逻辑上，简明且清晰地反驳了决定论的虚无。好比人与人之间的对弈，在人脑的约束下，复杂度也许存在某个阀值而可以穷尽，但回头看某个历史事件的发生，或者未来事物的发展，可是建立在未来的知识和环境之上（亦或不确定性），在这种知识和环境未曾产生以前，做出对未来准确预测的几率小之又小。换做混沌理论的道理，由于自然界的一切系统都是非线性系统（线性系统只是我们对自然界系统的近似描述），初始值的微小变量会造成最终值的云泥之别（蝴蝶效应）。&lt;/p&gt;&lt;p&gt;&lt;b&gt;所以，由于测量必然存在误差，对非线性系统的预测事实上是不可能的，同时，所谓阴谋的路径越长，露出破绽的可能性就越大，而不可能还称之为阴谋&lt;/b&gt;。就像已经被人轮了N轮的宋某人，既然他的《货币战争》所描绘的阴谋如此宏大且天衣无缝，为何早先瞒过了几乎所有人，却被宋某人发现了，而且连细节也如此清晰？&lt;/p&gt;&lt;p&gt;当然，或许坊间的个别传闻有所应验，但回到前面的概率上，我们还是应该有所防范。往小了讲，由于阴谋论的不可证伪性，无法应验的阴谋作为观念，不断融合于人生体验，接下来的代价就是受迫害的心理障碍（如相互猜忌等），以及不断加深的错误认知，许多在“文革”中度过青春期的那一代，受此影响颇深。往大了讲，当社会中弥漫着阴谋的气息，在开放社会中，都将进一步地损害社会群体的形象和利益，甚至有可能演化为极端的民粹主义回潮。&lt;/p&gt;&lt;p&gt;“知识”爆炸的年代，噪音少不了，阴谋论也总有市场。而对于它的防范，不能只停留在口号，还是应该回到知识观上。最近的一篇“汪丁丁：忙碌时代的阅读方式”讲的很好，摘录一段，特此作结：&lt;/p&gt;&lt;p&gt;&lt;i&gt;“即将进入21世纪时，教育学家们曾呼吁，在知识爆炸的时代，将高校教育原则从杜威时代的进步主义教育改造为旨在培养批判性思考能力的教育。这是因为，知识爆炸意味着，每个人大学毕业的时候，就是他所学知识过时的时候。这是德鲁克最早的观察，正是他的著作，提醒我研究知识社会的经济学问题。在知识社会，人力资本成为GDP增长的唯一要素（土地，简单劳力，物质资本的贡献少到可以忽略），这是老贝克尔上世纪末在斯坦福大学胡佛研究院的工作论文阐述的主旨。可是，新世纪的人力资本投资方式是怎样的？老贝克尔只说是教育。其实，就是要投资于批判性思考的能力。知识社会的毕业生，应当在任何新的工作情境内知道怎样获取新的知识。此即上世纪末教育界所说的： We go to school not to learn, but to learn how to learn. 一个人获得了终生自学的能力，才算是初步毕业。”&lt;/i&gt;&lt;/p&gt;&lt;p&gt;本文首发于微信公众号混沌巡洋舰（chaoscruiser）。&lt;/p&gt;&lt;p&gt;欢迎关注混沌巡洋舰，追寻自然界复杂下的简单，带你学习各路跨界干货。&lt;/p&gt;&lt;p&gt;著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。&lt;/p&gt;</description><author>许铁-巡洋舰科技</author><pubDate>Sat, 10 Sep 2016 18:43:58 GMT</pubDate></item><item><title>机器学习是如何巧妙理解我们大脑工作原理的？</title><link>https://zhuanlan.zhihu.com/p/22380557</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/8265f688c7c399294b5365561f77c1fe_r.png"&gt;&lt;/p&gt;&lt;p&gt;作者 &lt;b&gt;许铁&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;机器学习对抗复杂系统之神经科学篇&lt;/b&gt;&lt;/p&gt;&lt;p&gt;此文改编自Omri Barak教授的论文&lt;/p&gt;&lt;p&gt;机器学习和复杂系统正在诸多领域改变产业界和学术界的传统方法， 其中一个极好的例子正是给机器学习以巨大启发的神经科学本身。 我在此用一个鲜活的例子展示这个方法在该领域的神展开。 &lt;/p&gt;&lt;p&gt;&lt;strong&gt;文章的开头我想问大家一个问题， 如果你给一只猫建立一个模型， 那么最好的方法是什么？ 这个问题很深刻，大家可以边读下文边寻找答案。 &lt;/strong&gt;&lt;/p&gt;&lt;p&gt;神经科学，是一个高度依赖数据的生物学分支， 因为你要理解大脑本来就是用来计算的装置，你要研究它就首先研究它的输入和输出， 然后把它和动物的相应行为联系起来。 &lt;/p&gt;&lt;p&gt;这个故事的第一部分有关&lt;strong&gt;复杂系统&lt;/strong&gt;， 因为神经系统本质上属于&lt;strong&gt;复杂网络&lt;/strong&gt;的一种。我们希望通过在电脑上建立一个和大脑神经网络类似的复杂网络，来理解神经细胞数据到行为间的联系。 这种努力在8，90年代十分盛行。 比如最早出现的hopefield 网络解释记忆现象等。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/8c89a4a497fb2f068b91b45c75412d17.png" data-rawwidth="732" data-rawheight="524"&gt;&lt;p&gt;我们给出一个典型的例子：&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/08ed9d809732b029d87b4feeb1179d04.png" data-rawwidth="696" data-rawheight="500"&gt;此处科学家发现猴子可以经过训练对不同频率的两个声音进行比较（出错应有惩罚）， 这是一个典型的测量短期记忆能力的实验，如果猴子需要比较两个声音， 就要把第一个声音的信号放在脑子里，然后和第二个声音进行比对。&lt;b&gt;能够综合不同时间的信息进行决策可以说对生物生存至关重要， 而此实验即为其基础。 &lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;以往神经科学的研究方法可能只是描述这个行为，然后在猴子的脑子里想法放入电极，测量相应的神经信号是什么。&lt;/strong&gt;&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/5364022a14020d17fe862916c8b9bfd2.png" data-rawwidth="629" data-rawheight="398"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/168df964dc02b1cf06659bdbc85033df.png" data-rawwidth="677" data-rawheight="417"&gt;&lt;p&gt;例如我们可以看到上图中测量的神经元放电信号，这个神经元放电的频率随着声音的频率上升而上升（红色代表高频的声音），因此我们就可以根据这个臆想一个模型出来。   下图测量的细胞则相反。  你能不能根据这两个图设计个模型解释猴子的行为呢？ &lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/8b654d55fb658d60f4365bf18be4c224.png" data-rawwidth="612" data-rawheight="391"&gt;&lt;b&gt;还真的行！ 我们看到最简单的物理模型都可以解释这个现象。 &lt;/b&gt;左图中我们用山谷里的小球来描述这个模型（算法），这是把整个问题放在极低的维度上方便理解， 整个外界输入（声音）可以看成在猴子神经系统上的一个外力， 外力可以看做某种推动力让猴子的神经元状态发生定向改变，犹如小球（猴子神经系统的状态）在一个被外力塑造的山谷里趋向谷底（出现概率最大的状态，对应物理里能量最低的点），这个谷底的位置就是对第一次信号的记录（记忆），当外力（f1）消失，山谷的地形发生了变化，但外力并不马上改变。  当第二信号（f2）来到的时候，地形再次发生改变，此次的信号引起山谷的隆起，导致小球滚向新的谷底（左右各一个）， 而小球最终达到的位置这次就不仅与这次的外力有关， 还与之前外力引起的位置高度相关（综合历史信息进行决策），这无形中就实现了对两个信号进行比较（此处即最简单的图灵机），而且是用一个简单的物理系统哦。 那么如何利用我们刚说到的两种神经元（和外界信号正比或反比）来实现这个功能回路呢？  请见右图，我们甚至可以画出一个电路图来解释这个原理。 正号代表正比神经元， 负号代表反比神经元，E代表一个随时间变化的控制信号，S2根据E改变电路连接，那么你可以设计一个带有记忆功能的减法器来实现它。  &lt;/p&gt;&lt;p&gt; 然而这个方法说到头是一种类比， 很多真实的神经科学家把这个方法戏称为toy model， 而对其不屑一顾。 &lt;strong&gt;因为你无论说你电脑里的程序行为多么像大脑， 其实与真实都差距万里， 而且能够实现某种功能的算法也有很多， 你凭什么说大脑就是按你的臆想工作？&lt;/strong&gt; 用这种方法的计算神经科学家经常纠结于自己的模型需要多大程度仿真的问题上，就好像有些人说的， 你要给一只猫建立模型， 最好就是找一只猫来。&lt;/p&gt;&lt;p&gt;当然有模型还是比没有模型好很多， 毕竟它给我们点亮了生物世界和数学世界的联系。使得一个我们可能理解的数学体系得以建立在繁琐摸不到体系的生物体系之上， 让我们能够通过改变参数空间的方法与之玩耍。 &lt;/p&gt;&lt;p&gt;&lt;strong&gt;然而模型开始发挥威力的真正时刻是机器学习的介入，传统的复杂系统方法从此得到革新。为什么呢？ &lt;/strong&gt;&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/b0f24cf1184a67ae16d05c692ef0eed3.png" data-rawwidth="582" data-rawheight="323"&gt;&lt;p&gt;&lt;b&gt;因为通过机器学习， 我们有了一个强大精确的从数据反推模型的方法 ，而非之前模糊的类比。&lt;/b&gt; 机器学习的思路和之前的根本不同在于我不在一开始醉心于设计与真实系统相同的模型， 而是先用与真实模型原理大致相似的标准化模型，去学习真实的输入和输出。&lt;b&gt;此处的思维即你不在追求画出一个活灵活现的猫，而是先做一个四不像的东西， 让他去学习和猫一模一样的行为， 当这种行为真实到不可区分， 那你就认为它就是那只猫。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;一旦机器学习开始介入，模型就被赋予了预测性，而被赋予预测性的模型，可以看做在输入输出层面与真实系统不可区分， 从而解决了模型复杂度不好设定， 模型难以通过奥卡姆剃刀的缺陷。 &lt;b&gt;机器学习的模型比之前的模型更好的点在于多了cross validation的部分&lt;/b&gt;， 你用真实数据得到的模型，不仅要在已知输入输出的情况下做到像真猫一样， 还要在已知输入未知输入的情况下像一只猫， 也就是说它真的要有学习能力， 能够像真猫一样不仅可以捉到屋里墙角的老鼠，还可以捉到田间地头的老鼠。 &lt;/p&gt;&lt;p&gt;用这个方法， 我们的研究框架发生了变化。 我们先要寻找一组具体的输入输出作为研究起点。比如要研究视觉区域，你就找到一组猫和狗的照片， 然后输出需要是正确的分类。然后再进行测试。&lt;/p&gt;&lt;p&gt;与复杂系统模型方法不同的是， 机器学习的方法是一个黑箱操作的思路， 我们首先做一个标准化设备， 然后把大量输入送到这个标准化设备里， 然后让标准化系统改变参数得到一组我们想要的输出。标准化黑箱的好处是训练得到参数的方法已知因为这往往是一个巨难无比的任务，而与传统复杂系统模型只追求定性描述的需求不同。&lt;/p&gt;&lt;p&gt;如果上面的问题用机器学习的方法来解决，就变成：&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/438cf1e97f3abac76a56992d03e88241.png" data-rawwidth="734" data-rawheight="410"&gt;此处的主角是一种标准化的神经网络RNN（循环神经网络）， 我们给定在各种情况下的输入到输出的映射关系，然后在有监督学习的框架下对网络进行训练-即调整网络连接权重达到模拟这个输入和输出的过程。 而此时我们不需要设计，两种与实验相符的神经元（正比，反比如图左）就会自发浮现出来。也就是说， 机器学习出来的猫完全具备了猫的所有功能，甚至不用我们过度描摹，就长得也有些像猫了（功能和形态的对应？）。&lt;/p&gt;&lt;p&gt;我们现在有了一只会在各种场合抓老鼠的猫， 但我们毕竟不需要一只机器猫，而是要通过机器猫研究猫的行为，懂得猫是如何通过底层的元件实现功能的，毕竟电子猫比真猫要听话的多， 也可以任意让我们解剖，改变参数。 如何做呢？ 再次回到复杂系统里的动力学分析：&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/93144f39f989ec00a2d8a4bf4b0be5cd.png" data-rawwidth="860" data-rawheight="379"&gt;此处新增添的箭头是从高维神经网络到位低维动力学系统的。 还记得我们之前说的那个山坡小球的玩具模型吗？ 它的机理很完美然而可惜的是人家并不信服， 此处我们有了再一次伸张正义的机会， 我们取出我们训练好的能够与真实系统不可区分的RNN，然后用它进行“逆向工程（reverse engineering）” ，从中取出一个低维度系统， 看它的工作机理是不是符合我们的猜想。此处应有掌声，因为这里我们用到了一个多么抽象的方法，用真实数据回答了一个几乎不可能验证的假设。 &lt;/p&gt;&lt;p&gt;这里其实还有一个隐含的信仰，被训练过的黑箱被认为学习了生物系统的本质。你的RNN做任务做的再好毕竟和真实还是有区别的， 但此处我们已经达到了目前可以做到的极限。这里涉及到一个相当根本的问题， 就是机器学习的核心即在于通过数据学习得到真实系统的数学表征，而这种表征有多大程度接近真实，依然是难以量化和说清的。 &lt;/p&gt;&lt;p&gt;通过这种高维RNN到低维动力学系统的映射，我们就得到了一个解释整个系统运作的更加简单的示意图。通过学习， 一个高维混沌系统开始出现定点（fix point），定点含有系统输入输出的重要信息。此处是一个简单的二元分类器，这个分类器工作的原理正是一个动力学里的鞍点。 对于f1&amp;gt;f2 和 f1&amp;lt;f2 两种情况，我们得到一个分叉行为（bifurcation）， 一个会趋于一个是回答，一个是趋于一个否回答。某种角度，这也是机器学习里连续到离散的分类问题的一个动力学解答。 其中的物理含义与最初我们推倒的那个猜想玩具模型是一致的。 &lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/d7c72d5b3e185e3ac3e729bba488ca1d.png" data-rawwidth="751" data-rawheight="438"&gt;&lt;p&gt;此种我们看到了机器学习和复杂系统你中有我我中有你的缠绵关系。 首先机器学习是一种算法，而算法总要有一个物理实现（复杂系统）。 我们先有数据组成的表象世界， 再有算法组成的符号世界， 最后是抽象的真正解释世界机理的物理世界。这三种之间表象世界通过机器学习进入符号世界， 而符号世界又才能与物理世界巧妙的相通。 机器学习是桥梁， 复杂系统是灵魂， 而没有桥梁， 灵魂就是空洞的。&lt;/p&gt;&lt;p&gt;我们可以进一步追问机器学习方法为什么work，人脑为什么work，此处真正相通的地方到底是什么？注意我们反复在说的低维到高维，与高维到低维的问题， 现实生活中的问题往往是高维到低维的映射，比如信号（高维）-决策（往往二维）过程， 能够在高维空间里找到低维嵌入， 往往就代表神经网络建立了真实世界的模型， 正是因为这些模型，我们具有“举一反三” 和“泛化”的能力。 更深刻的， 就不是我这篇文章能涉及的了。 &lt;/p&gt;&lt;p&gt;&lt;b&gt;欢迎关注巡洋舰后续机器学习对抗复杂系统实战系列。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;加铁哥个人微信交流562763765&lt;/b&gt;&lt;/p&gt;</description><author>许铁-巡洋舰科技</author><pubDate>Fri, 09 Sep 2016 15:45:50 GMT</pubDate></item><item><title>如何运用机器学习解决复杂系统的预测问题？</title><link>https://zhuanlan.zhihu.com/p/22305458</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/c19aa4849e4cf26f72b0b73af6b63b12_r.png"&gt;&lt;/p&gt;&lt;p&gt;现实生活中预测通常难做到精准，比如股市，自然灾害， 长久的天气预测。&lt;/p&gt;&lt;p&gt;在市场这种系统里， 有&lt;b&gt;两个关键要素&lt;/b&gt;， &lt;b&gt;一个是个体和个体之间的互相作用（博弈），一个是系统与外部环境（地球资源）之间的相互作用（反馈），因此而形成复杂模式（Pattern）， &lt;/b&gt;这种模式通常很难预测。  &lt;/p&gt;&lt;p&gt;&lt;b&gt;而这种类型的系统我们通常定义为复杂系统： 由大量单元互相作用组成的系统， 由于集体行为的非线性（总体不等于个体之和）， 而形成具备无数层级的复杂组织。或者称为涌现性。  &lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;复杂科学即研究复杂系统的一套联系不同尺度现象的数学方法。&lt;/b&gt;在人类试图理解那些和自身生存最相关的东西时，而经典物理学的&lt;b&gt;还原论（把整体拆成部分）思维的却不适用&lt;/b&gt;。物理预测的核心方法是动力学方法, 即人们由实验出发抽象出引起运动改变的原因, 把这些原因量化为变量，用微分方程来描述, 从而取得对整个未来的精确解，如麦克斯韦方程组可以预测从光波的速度到磁线圈转动发电任何的电磁学现象。而你却无法通过了解市场上每个人的特性就很好的预测整个市场走势。&lt;/p&gt;&lt;p&gt;&lt;b&gt;复杂系统难以预测的原理可以从以下几方面理解：&lt;/b&gt;&lt;/p&gt;&lt;p&gt;1， &lt;strong&gt;高维诅咒:&lt;/strong&gt;  构成现实生活的系统往往被大量未知变量决定， 比如生物由无数的细胞组成。 基因，是由无数独立的单元组成的， 市场， 由无数的交易者组成， 这些用物理的描述方法来预测， 就是极高维度空间的运动问题。&lt;strong&gt;维度，首先使得再简单的方程形式都十分复杂难解。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;此处补充维度的科学定义： 维度是一个系统里可以独立变化的变量个数， 一个有非常多变量的系统，如复杂网络，假如每个变量不是互相独立，也可以是低维系统。 比如一个军营里的方阵，即使人数众多， 也会因为大家都做着一模一样的动作，而只有一个独立变量，成为一维系统。 &lt;/b&gt;&lt;/p&gt;&lt;p&gt;2， &lt;strong&gt;非线性诅咒&lt;/strong&gt;：高维度系统的维度之间具有复杂的相互作用，导致我们不能把系统分解为单一维度然后做加法的方法研究。  高维加上非线性我们将得到对初级极为敏感的混沌系统。&lt;/p&gt;&lt;p&gt;非线性的一个重要推论是组织的产生， 因为非线性，1+1可以大于2或小于2， 为组织的产生提供了理论基础。 &lt;/p&gt;&lt;p&gt;3， &lt;strong&gt;反馈诅咒&lt;/strong&gt;：  复杂系统中反馈无处不在， 即使是一个简单的一维系统， 反馈也可以使得系统的特性很丰富， 最典型的反馈是某种记忆效应， 使得系统产生复杂的路径依赖， 此刻你的现实与历史深刻关联，而关联方法导致复杂的模式产生。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;反身性&lt;/strong&gt;是一种由预测产生的特殊反馈， 当你预测股市的价格， 会引起你的交易策略变化从而影响你的预测， 是为反身性。&lt;/p&gt;&lt;p&gt;4，&lt;strong&gt; 随机诅咒&lt;/strong&gt;:  复杂系统往往含有不包含确定规律的随机噪声，加上这些噪声， 系统的行为更加难预测， 而很多时候， 我们也无法区分一个系统里发现的模式是噪声导致还是由于元件之间的相互作用。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;这四大诅咒是这些系统难以理解和预测的原因， 而这个时候， 复杂系统和机器学习的方法论&lt;/strong&gt;可以作为一种非常有力的手段帮我们从复杂性中挖掘模式。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;第一种方法叫模型驱动（Model approch）&lt;/strong&gt;， 即想办法找到事物变化的原因， 用一种降维的思路列出微分方程， 即从非常繁复的要素中化简出最重要的一个或者两个， 从而化繁琐为简单，不管三七二十一先抓住主要矛盾。其中的范例便是非线性动力学。&lt;/p&gt;&lt;p&gt;&lt;b&gt;注： 此处我们有两个基本假设让非线性动力学得到简化，一个是只讨论连续变量，另一个是不考虑系统内的随机性（无噪声项）。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;1，  如果一个系统可以化简到&lt;b&gt;一维&lt;/b&gt;， 那么你只需要研究其内部存在的&lt;b&gt;反馈性质&lt;/b&gt;并描述它即可。 负反馈导致稳定定点产生， 正反馈导致不稳定性。 很多事物多可以抽象为一维系统，包括简单环境下的人口增长问题。&lt;/p&gt;&lt;p&gt;2，  如果一个系统可以化简到&lt;b&gt;二维&lt;/b&gt;， 那么你需要研究两&lt;b&gt;个维度间的相互作用&lt;/b&gt;，最终可以互为负反馈而稳定下来，互为正反馈而爆发，或者产生此消彼长的周期轨道。 比如恋爱中的男女是个二维系统， 互为负反馈就回到普通朋友， 互为正反馈在爱欲中爆发-比如罗密欧与朱丽叶， 此消彼长那是玩捉迷藏的周期游戏。&lt;/p&gt;&lt;p&gt;3， 如果一个系统是&lt;b&gt;三维&lt;/b&gt;的， 则&lt;b&gt;混沌可能产生&lt;/b&gt;。 混沌即对初值极为敏感的运动体系。 你一旦偏离既定轨道一点， 即几乎无法回去。  &lt;/p&gt;&lt;p&gt;4， 如果一个系统&lt;b&gt;大于三维&lt;/b&gt;， 那么你需要用一个&lt;b&gt;复杂网络&lt;/b&gt;描述它的运动， 这个时候我们可以得到我们复杂系统的主角- collective phenomena &amp;amp; emergence。 复杂网络的性质主要取决于单体间相互作用的方式， 以及系统与外界交换能量的方法， 这两者又息息相关。 最终我们得到涌现。 &lt;/p&gt;&lt;p&gt;复杂网络的动力学往往混沌难以预测，对于高维混沌系统， 第一个方法也只能给出对事物定性的描述， 而我们可以祭出我们的&lt;strong&gt;第二种方法&lt;/strong&gt;: 先不管数据背后错综复杂的动因，而是直&lt;strong&gt;接以数据驱动我们的预测&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;这其中的哲学内涵即&lt;b&gt;贝叶斯分析框架&lt;/b&gt;： 即先不预测， 而是列出所有可能的结果及根据以往知识和经验每种结果发生的可能性（先验概率），之后不停吸收新观测数据， 调整每种可能结果的概率大小（后验概率），将想得到的结果概率最大化（MAP）最终做出决策。&lt;/p&gt;&lt;p&gt;如果你把贝叶斯分析的框架自动化， 让电脑完成， 你就得到机器学习的最基本框架。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;机器学习如果可以进入一个问题中， 往往要具备三个条件&lt;/strong&gt;： &lt;/p&gt;&lt;p&gt;&lt;b&gt;1，  系统中可能存在模式  &lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;2， 这种模式不是一般解析手段可以猜测到的。  &lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;3， 数据可以获取。 &lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;如果三点有一点不符，都很难运用机器学习。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;机器学习的一个核心任务即&lt;strong&gt;模式识别&lt;/strong&gt;， 也可以看出它和刚才讲的复杂系统提到的模式的关系。我们讲复杂系统难以通过其成分的分析对整体进行预测，然而由于复杂系统通常存在模式， 我们通常可以模式识别来对系统进行归类， 并预测各种可能的未来结果。比如一个投行女因为工作压力过大而自杀了， &lt;strong&gt;那么在她之前的活动行为数据（比如点击手机的某些app的频率）里是否可能存在某种模式? 这种模式是否可以判定她之后的行为类型？ &lt;/strong&gt;&lt;strong&gt;并且这个过程可否通过历史数据由计算机学习？&lt;/strong&gt;如果都可以，这就是一个机器学习问题。&lt;/p&gt;&lt;p&gt;刚才讲的几大诅咒， 高维， 非线性， 复杂反馈，随机性也称为机器学习需要核心面对的几大困难， 由此得到一系列机器学习的核心算法。&lt;/p&gt;&lt;p&gt;机器学习在现实生活中被用于非常多的方面， 最常见的如商务洞察（分类，聚类， 推荐算法）， 智能语音语义服务（时间序列处理，循环网络），  各种自动鉴别系统如人脸识别，虹膜识别 ，癌症检测（深度卷积网络），  阿尔法狗，机器人控制（深度强化学习算法）。 而由方法论分， 又可以分成有监督学习， 无监督学习， 和强化学习。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;在八月份的巡洋舰科技的《&lt;/strong&gt;&lt;b&gt;机器学习vs复杂系统特训课》中，&lt;/b&gt;&lt;strong&gt;我着重讲了几种机器学习的基本方法：&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1.    贝叶斯决策的基本思想：&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;你要让机器做决策， 一个基本的思路是从统计之前数据挖掘已有的模式（pattern）入手， 来掌握新的数据中蕴含的信息。 这个pattern在有监督学习的例子里， 就是把某种数据结构和假设结论关联起来的过程，我们通常用条件概率描述。  &lt;strong&gt;那么让机器做决策， 就是通过不停的通过新数据来调整这个数据结构（特征）与假设结果对应的条件概率。&lt;/strong&gt;通常我们要把我们预先对某领域的知识作为预设（prior），它是一个假设结果在数据收集前的概率密度函数，然后通过收集数据我们得到调整后的假设结果的概率密度函数， 被称为后验概率（posterior），最终的目标是机器得到的概率密度函数与真实情况最匹配， 即 Maximum a posterior(MAP)，  这是机器学习的最终目标。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2， 朴素贝叶斯分类器到贝叶斯网络：&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;分类，是决策的基础，商业中要根据收集客户的消费特征将客户分类从而精准营销。&lt;/strong&gt; 金融中你要根据一些交易行为的基本特征将交易者做分类。 从贝叶斯分析的基本思路出发我们可以迅速得到几种分类器。&lt;/p&gt;&lt;p&gt;&lt;b&gt;首当其冲的朴素贝叶斯分类器，&lt;/b&gt;它是机器学习一个特别质朴而深刻的模型：当你要根据多个特征而非一个特征对数据进行分类的时候，我们可以&lt;b&gt;假设这些特征相互独立（或者你先假设相互独立），然后&lt;/b&gt;&lt;b&gt;利用条件概率乘法法则得到每一个分类的概率， 然后选择概率最大的那个作为机器的判定。&lt;/b&gt;&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/769765c24a373de5793cbf8d811cbb95.png" data-rawwidth="442" data-rawheight="217"&gt;&lt;p&gt;&lt;b&gt;图：  朴素贝叶斯分类器的基本框架， c是类别， A是特征。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;如果你要根据做出分类的特征不是互相独立，而是互相具有复杂关联，&lt;/b&gt;这也是大部分时候我们面临问题的真相， 我们需要更复杂的工具即&lt;b&gt;贝叶斯网络。&lt;/b&gt; 比如你对某些病例的判定， 咳嗽， 发烧， 喉咙肿痛都可以看做扁条体发炎的症候， 而这些症候有些又互为因果， 此时贝叶斯网络是做出此类判定的最好方法。&lt;b&gt; 构建一个贝叶斯网络的关键是建立图模型 ， 我们需要把所有特征间的因果联系用箭头连在一起， 最后计算各个分类的概率。&lt;/b&gt;&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/d58d01bc0c35302e99c4379aa9e6e182.png" data-rawwidth="859" data-rawheight="455"&gt;&lt;p&gt;&lt;b&gt;图：贝叶斯网络对MetaStatic Cancer的诊断，此处的特征具有复杂因果联系&lt;/b&gt;&lt;/p&gt;&lt;p&gt;贝叶斯分析结合一些更强的假设，可以让我们得到一些经常使用的通用分类器， 如逻辑斯提回归模型，这里我们用到了物理里的熵最大假设得到玻尔兹曼分布， 因此之前简单贝叶斯的各个特征成立概率的乘积就可以转化为指数特征的加权平均。 这是我们日常最常用的分类器之一。 更加神奇的是， 这个东西形式上同单层神经网络。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/84dd25c3c2d2c9a6c0fcfe357ab94742.png" data-rawwidth="598" data-rawheight="259"&gt;&lt;p&gt;&lt;b&gt;图： logistic函数，数学形式通玻尔兹曼分布， 物理里熵最大模型的体现&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;3,    贝叶斯时间序列分析之隐马模型：&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;贝叶斯时间序列分析被用于挖掘存储于时间中的模式，时间序列值得是一组随时间变化的随机变量&lt;/b&gt;，比如玩牌的时候你对手先后撒出的牌即构成一个时间序列。 时间序列模式的预设setting即马尔科夫链， 之前动力学模式里讲到反馈导致复杂历史路径依赖，当这种依赖的最简单模式是下一刻可能出现的状态只与此刻的状态有关而与历史无关， 这时候我们得到马尔科夫链。&lt;/p&gt;&lt;p&gt;马尔科夫链虽然是贝叶斯时间序列分析的基准模型，然而现实生活中遇到的时间序列问题， 通常不能归于马尔科夫链，却可以间接的与马尔科夫链关联起来，这就是隐马过程，所谓&lt;b&gt;含有隐变量的马尔科夫过程。&lt;/b&gt;&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/451dc125ffe31395f70879e7318a29d9.png" data-rawwidth="791" data-rawheight="284"&gt;&lt;p&gt;&lt;b&gt;图： 隐马过程示意&lt;/b&gt;&lt;/p&gt;&lt;p&gt;语音识别就是一类特别能利用隐马过程的应用， 在这里语音可以看做一组可观测的时间序列， 而背后的文字是与之关联的马尔科夫链， 我们需要从可观测的量， 按照一定的概率分布反推不可观测的量， 并用马尔科夫链的观点对其建模， 从而解决从语音到文字的反推过程。 当今的语音识别则用到下面紧接讲的深度学习模型。&lt;/p&gt;&lt;p&gt;&lt;b&gt;4，  深度学习&lt;/b&gt;&lt;/p&gt;&lt;p&gt;刚刚讲的分类问题， 只能根据我们已知的简单特征对事物进行分类， 但假设我们手里的数据连需要提取的特征都不知道， 我们如何能够对事物进行分类呢？ 比如你要从照片识别人名， 你都不知道选哪个特征和一个人关联起来。 没关系， 此时我们还有一个办法， 就是&lt;b&gt;让机器自发学习特征， &lt;/b&gt;因此祭出&lt;b&gt;深度学习&lt;/b&gt;大法。通常在这类问题里， &lt;b&gt;特征本身构成一个复杂网络，下级的特征比较好确定， 而最高层的特征， 是由底层特征的组合确定的， 连我们人类自己都不能抽象出它们。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;深度学习即数据内涵的模式（特征）本身具备上述的多层级结构时候&lt;/b&gt;，我们的机器学习方法。 从以毒攻毒的角度看， 此时我们的机器学习机器也需要具有类似的多级结构，这就是大名鼎鼎的多层卷积神经网络。深度学习最大的优势是具有更高级的对“结构”进行自动挖掘的能力，比如它不需要我们给出所有的特征，而是自发去寻找最合适对数据集进行描述的特征。  一个复杂模式-比如“人脸” 事实上可以看做一个简单模式的层级叠加， 从人脸上的轮廓纹理这种底层模式， 到眼睛鼻子这样的中级模式， 直到一个独特个体这样最高级的复杂模式， 你只有能够识别底层模式，才有可能找到中级模式， 而找到中级模式才方便找到高级模式， 我们是不能从像素里一步到达这种复杂模式的。 而是需要学习这种从简单模式到复杂模式的结构，  多层网络的结构应运而生。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/00db6597ca661fb249ac946514118f6b.png" data-rawwidth="706" data-rawheight="592"&gt;&lt;p&gt;&lt;b&gt;图： 从具体特征到抽象特征逐级深入的多级神经网络&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;6，  RNN和神经图灵机&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;如果时间序列数据里的模式也包含复杂的多层级结构，&lt;/b&gt; 这里和我之前说的复杂系统往往由于反馈导致复杂的时间依赖是一致的， 那么要挖掘这种系统里的模式， 我们通常的工具就是超级前卫的&lt;b&gt;循环神经网络RNN&lt;/b&gt;，这种工具对处理高维具有复杂反馈的系统有神效， 因为它本身就&lt;b&gt;是一个高维具有复杂时间反馈的动力学系统。&lt;/b&gt;&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/b737cc872790a4bd72306814859c7066.png" data-rawwidth="515" data-rawheight="263"&gt;&lt;p&gt;&lt;b&gt;图：  循环神经网络， 过去的信息可以通过循环存储在神经元之间&lt;/b&gt;&lt;/p&gt;&lt;p&gt;当一个复杂时间序列的问题里面， 每个时间点的信息都可以对未来以任何方式产生复杂影响， 那么处理这种复杂性的一个办法就是用循环神经网络，让它自发学习这种复杂结构。 比如一个城市里的交通流， 或者人与人之间的对话。&lt;/p&gt;&lt;p&gt;&lt;b&gt;神经图灵机是在多层卷积神经网络或递归网络基础上加上一个较长期的记忆单元， 从而达到处理需要更复杂时间关联的任务&lt;/b&gt;， 比如对话机器人。  而神经图灵机最厉害的地方在于他可以通过机器学习传统的梯度下降法反向破译一个程序，  比如你写了一个python程序， 你用很多不同的输入得到很多对应的输出， 你可以把它给神经图灵机训练， 最终本来对程序丝毫无所知的神经图灵机居然可以如同学会了这个程序。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/362a2cf515c2e3219697fe1c5cc9cacb.png" data-rawwidth="819" data-rawheight="398"&gt;&lt;p&gt;&lt;b&gt;图： 神经图灵机的基本结构， 在多级神经网络或循环网络（controller）的基础上，增加一个更长时间的记忆， 记忆和神经网络之间的读入和写出装置， 整个装置都是可以被人工训练的（可微分）&lt;/b&gt;&lt;/p&gt;&lt;p&gt;复杂科学解释模式的存在， 机器学习解决模式的识别， 两个学科加在一起给我们提供了我们面对复杂问题进行预测与决策的数学框架。世间的很多事情看似随机， 却内藏规律， 这种规律谓之模式。人类喜欢规律， 喜欢在无规律中看出规律， 发明了很多占星术一类的不靠谱的学问。  同时， 一些真正的隐藏在随机中的规律 ， 却因为数据的维度太高， 变化错综复杂而不可见。机器学习可以帮助我们看的清楚一点， 而如果我们单单只满足于模式识别，而不对模式进行解释（了解其动力学机制）， 则对于一些真正复杂的问题很容易流于表面无法深入。 比如我们通过对语言本身的统计和归类依然无法设计出和人相似的聊天机器人， 而想让他最终和人相似， 了解语言产生的动力学机制本身无疑是必要的。&lt;/p&gt;&lt;p&gt;&lt;b&gt;本文为巡洋舰科技八月份的《机器学习vs复杂系统特训课》的总结，详情咨询铁哥微信（XUTie0609）&lt;/b&gt;&lt;/p&gt;&lt;p&gt;本文首发于微信公众号混沌巡洋舰（chaoscruiser）。&lt;/p&gt;&lt;p&gt;欢迎关注混沌巡洋舰，追寻自然界复杂下的简单，带你学习各路跨界干货。&lt;/p&gt;&lt;p&gt;著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。&lt;/p&gt;</description><author>许铁-巡洋舰科技</author><pubDate>Sun, 04 Sep 2016 16:40:23 GMT</pubDate></item><item><title>人物关系网络图——机器学习在复杂网络分析中的应用</title><link>https://zhuanlan.zhihu.com/p/22194429</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/b7c062b85a273b5541e3f357cbf1e3a0_r.jpg"&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;作者 郭瑞东 许铁&lt;/b&gt;&lt;/p&gt;&lt;p&gt;题图是哈利波特对应的人物关系网络。够复杂。再来看看权力的游戏&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/b8ae9e69e0a8865c6dcabaa22376dc52.jpg" data-rawwidth="2047" data-rawheight="760"&gt;&lt;p&gt;以下链接是一个更酷的关于7部星球大战的人物关系网络的可视化图（更庞大的复杂网络）&lt;/p&gt;&lt;p&gt;&lt;a href="http://assets.dtcj.com/visualization/star_war/index.html" data-editable="true" data-title="死忠粉才能看懂的星球大战关系图谱" class=""&gt;http://assets.dtcj.com/visualization/star_war/index.html&lt;/a&gt;&lt;/p&gt;&lt;p&gt;那么，直奔主题，这样的图是怎么画出来的。&lt;/p&gt;&lt;p&gt;&lt;b&gt;本文的图主要出自“Mining and modeling character networks”这篇文章&lt;/b&gt;。&lt;/p&gt;&lt;p&gt;&lt;b&gt;如果要机器来学习小说中人与人的关系， 核心方法就是挖掘对话中两个人物共同出现的频率。&lt;/b&gt;我们可以做一个简单规定， 就是一个人物出现时候， 其前15个字和后15个字之内如果出现另一个人物， 那么就算这两个人同时出现。&lt;b&gt;我们统计任意两个人物同时出现的频率，并把这些频率放入到一个巨大的表格里， 这时候我们会得到一个描述人物关系的矩阵。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这个矩阵的含义大家觉得是什么？提一下英文名就是adjacent matrix。在现实世界里，这个矩阵如果过大，就需要用mapreduce 来做奇异值分解。然后我们需要用一定的数学方法从矩阵把人物关系网络求出来。&lt;/p&gt;&lt;p&gt;&lt;b&gt;要从矩阵到网络， 我们第一个要解决的问题是什么？我们首先要确立网络的中心。&lt;/b&gt;处于网络中心的是什么？ 是小说的核心- 主角。那么如果我们把一部小说想象成描述一个江湖。那么这些人物如同构成了一个社会网络。这个网络里最重要的人，&lt;b&gt;从网络的角度看， 需要有哪些特征呢？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;首先我们可以思考是那些具有联系最多的人（和一个人直接发生的联系的个体数即复杂网络节点的度）。但是大家想一下这个方法有没有缺陷呢？ 肯定有的，如果一个看门大爷具有公司所有人的联系， 他对群体的影响力却不是很大。&lt;/p&gt;&lt;p&gt;&lt;b&gt;此处注意我们研究一个问题要明确每个概念， 比如重要性， 什么是重要？谁对你最重要， 就是谁对你影响力最大。 重要性就是影响力。&lt;/b&gt; 而其影响力只能从外界和它的联系看出： 1，和他联系的有多少重量级人物 2， 和这些人互动的频率是多少？ 是不是看门老大爷的水平？  3 ，积分， 总量是重要的。 那么单看节点的度就是不够的， 有没有别的方法？ 其他领域有无借鉴？ &lt;/p&gt;&lt;p&gt;总结一下就是要看两点， &lt;b&gt;一个是权重， 即每个连接所发生的频率，&lt;/b&gt; 如果看门大爷偶尔和领导说一句话， 那么它的权重几乎是0， 就可以排除掉。&lt;b&gt; 另一个是这些连接本身的重要性，&lt;/b&gt;  如果你只有三个连接， 他们一个是习近平， 一个是李克强，一个是xx， 那就知道你的位置了。ok 这个问题很早就被google的创始人larry page 解决掉了 ，  &lt;b&gt;这个算法就是大名鼎鼎的pagerank。&lt;/b&gt;pagerank算法是如何运算的 ， 原理并不难理解。&lt;/p&gt;&lt;p&gt;pagerank是21世纪改变人类的一大成就吧。用最简单的话来说，就是人脉决定价值，A和一群土豪做朋友，B和一群屌丝做朋友，A的价值就高于B，C只和一个屌丝做朋友，那B的价值就大于C，只不过这里ABC是网页界面，土豪指的是谷歌wiki这样的网站，屌丝指的是个人的博客。&lt;b&gt;然后这个算法就不断的测量每个界面的“人脉”，决定那个网站更重要，排在谷歌的搜索结果前端。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们还想象网站的情形， 首先你假定你是一只猴子， 随机的进入了网站构成的巨大网络，然后我们做一个最基本的假设，那就是你可以从一个网站跳到与之相邻的网站， 这个跳跃的概率等于1除以从这个网络节点的度（因为你必须做一个选择下一步去哪里， 如果你有n个选择， 那个每个选择被选中的概率是1比n）。 &lt;b&gt;你让猴子跳跃很多次，不停迭代n步之后， 你最终将得到一个你进入每一个站点的概率分布， 那个你在随机跳动里最容易进入的点， 就是网络的中心。 用数学上表示， 就是你跃迁矩阵那个对应特征值为1的特征根。&lt;/b&gt;&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/b6600509de41df4e0ddc1f2b63033bac.png" data-rawwidth="874" data-rawheight="593"&gt;&lt;p&gt;&lt;b&gt;最简单的方法是从三个网站相连的示意图开始计算。&lt;/b&gt;我们一开始看到这个图完全不知道ABC三个方框里面的数字， 所以我们就假设各自数字为三分之一。权重是方框里的数字除以从这个方框出去的边的个数。这个得出的对应某条边的数字可以理解为从一个网站点击开另一个网站的概率。&lt;/p&gt;&lt;p&gt;在某个网站上的数字大， 则说明这个网站本身比较重要， 点击人数比较多，因此从这个网站出去打开其他网站的概率也较大。&lt;b&gt;用这个方法可以得到在计算中心度的时候充分考虑到一个节点周围节点的重要性， 因为它衡量了整个网络对某个节点的影响而非只考虑直接相连的那些点&lt;/b&gt;，如果一个节点周围的点都不太有流量， 则及时与该节点相连的边数很高， 也较难有足够流量。&lt;/p&gt;&lt;p&gt;pagerank的算法的厉害之处在于&lt;b&gt;通过不停迭代一次求出所有网站的重要性 或者从复杂网络的语言说， 就是取得了每个节点的中心度。&lt;/b&gt;我们之后可以按照这些中心度给所有网络节点排序。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/1d8f141baf49e4cf7469bba0ff7fdb02.png" data-rawwidth="836" data-rawheight="285"&gt;&lt;p&gt;从上面的图可以看出，相比之前用度进行的排序， 用pagerank算法进行的排序能够更加清晰的区分哈利波特中主角和配角。但对于权力的游戏，由于这本小说本身的特性，区别并不明显。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/bbe288bc5456c62f6b109fac284ff750.png" data-rawwidth="847" data-rawheight="448"&gt;&lt;p&gt;在这篇论文里， 还比较了其他关于中心度计算的方法。&lt;b&gt;计算中心度是得到复杂网络的核心一步， 因为我们画图的时候需要把中心度最高的那个人物画在中央，  而中心度次高的画在他旁边的位置 ，这样依次向外。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;我们之后需要根据已知复杂网络的知识， 来判断所生成的网络属于何种类型。&lt;/b&gt;文中用到了机器学习的分类器来判定这个问题。此处我们给出了几种标准的复杂网络， 然后判断从小说生成的人物网络最符合哪一类标准网络。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第一类网络是preferential attachment（PA）。&lt;/b&gt;说的是具体生成网络过程中，我们一条一条边的往上加。假设一开始我们有n个节点， 然后我们要再增加第n+1个节点， 这时候我们自然要再从其他节点抽出m条边与之相连，这个抽取的概率与前述节点的度成正比。&lt;/p&gt;&lt;p&gt;&lt;b&gt;你要计算新增加的节点是否需要与某个之前节点相连，你就要看一下之前节点是否有很多条边， 边数越多， 这个连接的概率越大&lt;/b&gt;。这就是马太效应，富者越富，贫者越贫。这种网络是由它的生成过程定义的。在生成过程中充分考虑到已有的节点和边数（度）对网络构建的影响。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第二种已知网络类型是The Binomial Random Graph &lt;/b&gt;G(n, p), or Erd ̋os -R ́enyi (ER) 这是&lt;b&gt;给定整个网络的平均度数， 然后在任意两个节点之间按照这个度数决定的概率随机抽取， 决定是否把这两个点连接在一起。&lt;/b&gt;  这种方法生成的随机网络叫做Binomial Random Graph，又叫ER graph。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第三种方法， Chung-Lu model&lt;/b&gt;。(CL) 这种网络模型充分考虑了我们之前生成的小说人物网络的结构 ， 所谓&lt;b&gt;在已知给定两个节点间连线的概率，正比于这两个节点的度的乘积&lt;/b&gt;。也就是说， 这个模型最大的利用了我们之前已知小说网络的信息。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第四种模型是CFG model,&lt;/b&gt; we select a graph uniformly from the set of graphs which exactly match the target degree distribution. &lt;b&gt;即按照文章中的节点分布生成符合条件的随机网络&lt;/b&gt;，假设网络中只要3个节点，我们要考察的小说中有三个角色，哈利，罗恩和赫敏。其度分布为100 80 75，我们需要生成一个具有相同节点的度分布的网络。&lt;/p&gt;&lt;p&gt;&lt;b&gt;我们之后的任务是判定我们所生成的小说人物的网络拓扑结构&lt;/b&gt;， 最符合刚刚说的哪一类网络？如果你想到机器学习里的分类器 ， 那就对了。但是SVM是要提取数据特征的额。&lt;b&gt;此处如何提取数据的特征呢？&lt;/b&gt;&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/fbbbc857ba85eccc22c10e5aa42527f3.png" data-rawwidth="865" data-rawheight="288"&gt;&lt;p&gt;看懂这张图， 就弄明白了我们提取整个网络特征的方法。因为你要判断一个复杂网络属于哪一类给定的复杂网络类型。这里复杂网络的一个很重大的特征是motif。你可以从一个大的网络里，给定节点个数， 抽取所有小的子网络。比如上图， 你从大的网络里抽取所有三个节点的图出来，  然后三个节点间只有可能有四种连线方法，(假定节点是相同的)，我们可以统计所有三节点图里四种连线方法所占的比例。用同样的方法我们可以处理4节点图， 5节点图，得到一个巨大的关于连线方法的统计分布。&lt;/p&gt;&lt;p&gt;当然这里可用到的分类器有support vector machine，  random forest， 和boosted decision tree。因为我们也不知道这些特征哪些比较重要， 哪些不太重要， 用随机森林是一个很好的对各个特征影响进行综合的方法。&lt;/p&gt;&lt;p&gt;最后三种分类方法得到了一个比较一致的答案， 那就是我刚讲到的第三种复杂网络模型（Chung-LU）最好的描述了小说人物的网络。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/72a6d049700c6c86c67062b7871a3bca.png" data-rawwidth="820" data-rawheight="339"&gt;&lt;p&gt;可以看到三种方法取得一致意见，而且是压倒性的。得分越高，分类器认为这些横轴的模型更像待 检验的模型，即通过文本分析生成的网络。纵坐标 可以理解为 不同模型分类效果的得分。分值越高匹配度越高。得分越高，分类器认为这些横轴的模型更像待 检验的模型，即通过文本分析生成的网络。这里提到这个数字是similar aggreate results for 800 character。&lt;/p&gt;&lt;p&gt;这里是取了 800个 电影剧本， 纵轴的数字代表横轴的模型被分到同一类的次数。具体是 five fold cross validation，就是抽20%的验证。此处的训练是用100个随机生成的上述四类中每一类复杂网络， 给分类器进行训练。拿剩下的80%训练。通过训练之后， 再把从小说提取的人物网络经过分类器试验。&lt;/p&gt;&lt;p&gt;这篇文章其实已经涉及了一些自然语言处理的知识， 比如一开始的人物名字频率的分析计算， 如何猜测每个代词指代的人物等， 我们接下来进入自然语言处理部分。&lt;/p&gt;&lt;p&gt;自然语言处理是数据科学的一个分之，既然是科学，就应该遵守科学所需遵守的规矩。科学永远是来源于好奇的，我个人是哈利波特的死忠粉，看完数后会有很多问题。比如谁是书中的第二主角，是罗恩还是赫敏。要回答这个问题，我们需要数据。&lt;/p&gt;&lt;p&gt;好的科学，就是提出问题，找出如何观察计量数据，之后将数据展示出来。另外一点就是要keep your mind wide open,保持不确定的状态，接受新鲜的事物。&lt;/p&gt;&lt;p&gt;回到刚才的问题，最简单的方法是统计 罗恩 和 赫敏这两个名字在书中出现的次数。这个问题牵扯到自然语言处理中会遇到的某些核心困难。比如一个词语在不同的语境下有着不同的含义。传统的自然语言处理 是基于规则的。有学语言学的朋友， 应该知道乔姆斯基范式。一个句子可以分为主语开始，接一个动词，再接一个宾语。将英文的句子按照词性以及这样的规则，展开成一颗树的过程，就是传统的分词算法。下图是提到的分词树。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/18ba50d4acad990fbe12585541ee4573.png" data-rawwidth="793" data-rawheight="430"&gt;&lt;p&gt;近年来，随着计算性能的提升，另一种不利用语言特性的基于概率的自然语言处理开始表现出比rule base的方法更好的效果。基于概率的方法，被广泛的应用到机器翻译，搜索引擎优化中。这里推荐感兴趣的同学去看吴军的《数学之美》，其中有很多精彩的介绍。&lt;/p&gt;&lt;p&gt;我们可以用机器学习和复杂系统的方法去研究很多现实生活中的现象， 比如我们在看看的影视作品。有一些公司甚至可以利用这点开发商业产品， 比如一些制造电影电视剧的公司， 可以根据整个人物关系网络和观众喜好度的关系制定策略开发影视产品，也可以做社交网络的研究，例如去看人人网是怎么衰落的，前期后期有什么不同，可以看看知乎是怎么崛起的，大V之间的关系网又长什么样。&lt;/p&gt;&lt;p&gt;本文首发于微信公众号混沌巡洋舰（chaoscruiser）。&lt;/p&gt;&lt;p&gt;欢迎关注混沌巡洋舰，追寻自然界复杂下的简单，带你学习各路跨界干货。&lt;/p&gt;&lt;p&gt;著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。&lt;/p&gt;</description><author>许铁-巡洋舰科技</author><pubDate>Fri, 26 Aug 2016 20:18:01 GMT</pubDate></item><item><title>复杂系统的简单笔记</title><link>https://zhuanlan.zhihu.com/p/22118096</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/d3fcfb7fcda416d7beba8bfbbaa72357_r.jpg"&gt;&lt;/p&gt;&lt;p&gt;（题图来自网络）&lt;/p&gt;&lt;p&gt;&lt;b&gt;首先，与复杂系统对立的是什么？            &lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;简单系统。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;什么是简单系统？ &lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;可以用物理经典的还原论思维来简化描述其规律的系统。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;比如卫星绕地球运动， 我们只要把卫星所受到的基本作用力一一分解出来，  然后列出牛顿方程， 就可以解决掉卫星的轨迹问题。&lt;/p&gt;&lt;p&gt;&lt;b&gt;那么什么是复杂系统呢？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;而复杂系统说的是由大量单元互相作用组成的系统， 其活动呈现非线性， 往往形成具备无数层级的复杂组织。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这里主要强调的是大量互相作用的微观单元， 通过非线性效应， 得到一个性质与微观单元完全不同的宏观整体。 更强调一套联系不同尺度的数学方法。&lt;/p&gt;&lt;p&gt;现在我们看看下面这几幅图有些什么共同规律：&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/94429b6bbf78bab87865fd84dcb76ffa.png" data-rawwidth="835" data-rawheight="625"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/6875914f292683f08e7febef62a67701.png" data-rawwidth="823" data-rawheight="536"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/b36469e500f349539309e76d223049d4.png" data-rawwidth="831" data-rawheight="552"&gt;&lt;p&gt;我想这里强调的是， 尽管组成上述三幅图， 花菜， 沙丘，和河流网络的微观单元（沙子，细胞，水）非常不同，但是&lt;b&gt;他们的宏观形式在数学上却有惊人的相似性&lt;/b&gt;。&lt;/p&gt;&lt;p&gt;1967年，Mandelbrot在美国权威的《科学》杂志上发表了题为《英国的海岸线有多长？统计自相似和分数维度》（How Long Is the Coast of Britain? Statistical Self-Similarity and Fractional Dimension）的著名论文。海岸线作为曲线，其特征是极不规则、极不光滑的，呈现极其蜿蜒复杂的变化。&lt;/p&gt;&lt;p&gt;我们不能从形状和结构上区分这部分海岸与那部分海岸有什么本质的不同，这种几乎同样程度的不规则性和复杂性，说明海岸线在形貌上是&lt;b&gt;自相似的，也就是局部形态和整体态的相似&lt;/b&gt;。在没有建筑物或其他东西作为参照物时，在空中拍摄的100公里长的海岸线与放大了的10公里长海岸线的两张照片，看上去会十分相似。&lt;/p&gt;&lt;p&gt;事实上，具有自相似性的形态广泛存在于自然界中，如：连绵的山川、飘浮的云朵、岩石的断裂口、粒子的布朗运动、树冠、花菜、大脑皮层……Mandelbrot把&lt;b&gt;这些部分与整体以某种方式相似的形体称为分形(fractal)。&lt;/b&gt;1975年，他创立了&lt;b&gt;分形几何学(Fractal Geometry)&lt;/b&gt;。在此基础上，形成了&lt;b&gt;研究分形性质及其应用的科学，称为分形理论&lt;/b&gt;。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/6266d6f7cb0240f0b65728d82d98b777.png" data-rawwidth="787" data-rawheight="595"&gt;&lt;p&gt;&lt;b&gt;图中的雪崩和股市的灾难性崩盘也呈现如果在时间轴上看， 是否也具有某种相似性？这里讲到的概念是相变。&lt;/b&gt;虽然组成股市和雪山的微观粒子不同， 但是他们却具有&lt;b&gt;类似的动态特征。&lt;/b&gt;由此我们看到&lt;b&gt;复杂系统的核心魅力——那就是这些展示的现象虽然说是由性质完全不同的基本组成元素构成，但是在宏观上却表现出类似的性质， 那是因为这些基本单元的组成形式是类似的。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;那么我就简要说一下这些组织是如何形成的。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;首先，研究这些组织你无法通过只研究其单元理解。&lt;/b&gt;比如你大脑是典型的复杂系统， 你要理解大脑视觉回路是如何识别一只猫的， 你无法通过分解出每个神经细胞的概念就能够理解我们的脑神经回路是如何处理视觉信号的。 同样，社会是一个复杂系统，  你理解了人性， 却无法因此理解社会和公司的形成。&lt;/p&gt;&lt;p&gt;&lt;b&gt;复杂系统的形成主要有三个东西：&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;1， 作用（关联）  &lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt; -  不是单体的特性， 而是单体是如何相互关联形成组织的， 因为这类系统共同的特点是长程关联 。 关联往往导致1+1&amp;gt;2  或1+1&amp;lt; 2  或称为非线性 。&lt;/b&gt;  最典型的例子是市场， 复杂系统给出价格是网络相互作用导致的，我们都受到邻居影响（herding effect）相互作用非常重要。比如刚收的神经元是因为相互作用构成神经网络来处理信号的。&lt;/p&gt;&lt;p&gt;&lt;b&gt;相互作用导致协同效应。&lt;/b&gt;两个人在一起可以是1+1大于2 ， 也可以是1+1 小于2， 但基本不会是1+1=2，  前两者都可以看做是非线性的体现。比如为什么会有公司，那一定是某种合作导致的1+1大于2效应使得组织可以产生。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2， 反馈  &lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;复杂系统多描述一个系统的时间变化过程，&lt;/b&gt; 如市场价格的波动，  神经网络随时间的活动等， &lt;b&gt;研究这个时间变化过程， 往往要考虑此刻的结果对下一刻系统结果输出的影响。&lt;/b&gt;股市的反身性就是反馈的一种。&lt;/p&gt;&lt;p&gt;&lt;b&gt;反馈分为正反馈和负反馈， 负反馈导致定点平衡态。  正反馈导致不稳定性，&lt;/b&gt; 如雪崩， 股市崩盘。因为在所有复杂系统中， 都存在正反馈和负反馈。反馈带有回路的概念。一个单元通过相互作用传递给另一个单元， 反过来另一个单元又可以把信息传递回来。&lt;b&gt;反馈往往是指此刻的活动对下一刻的活动的影响。&lt;/b&gt;比如市场价格。市场价格永远围绕均衡波动。价格高，导致市场买的人少， 又降低，这是典型的负反馈。负反馈把系统维持在稳定位置。dx=-x, 这是负反馈。&lt;/p&gt;&lt;p&gt;&lt;b&gt;3， 相变 &lt;/b&gt;&lt;/p&gt;&lt;p&gt;这是复杂系统的第三个重要性质 ，而且是我们后面提到组织形成的核心。&lt;b&gt;当系统主导反馈的性质发生变化，则经历一个相变。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;相变在自然和社会中无处不在， 自然中的相变当然包括冰和水之间的转化， 也包括磁铁从一种相到另一种相的变化， 社会中的中的相变如苏联的解体， 人类历史王朝的变化更迭。这里物理里的典型例子是磁铁。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/6af7872b0ba66900fa51672c02751ecb.png" data-rawwidth="640" data-rawheight="319"&gt;&lt;p&gt;磁铁这个东西 , 并非总具有磁性 。那么具有磁性和不具备磁性的铁是什么区别呢？请看上图。&lt;/p&gt;&lt;p&gt;&lt;b&gt;磁铁有两个相， 一个是组织成分均匀一致（有序）的状态， 一个是无序和混乱的状态&lt;/b&gt;。虽然他们都是铁原子构成的。大家觉得是铁原子无序的排序会产生磁性还是有序的排序？当然是有序的， 所谓你要对外发挥一种作用，  需要齐心合力， 那个无序的构型使得每个磁针的磁性相互抵消了。&lt;/p&gt;&lt;p&gt;&lt;b&gt;这里就建立了相的概念。那么相变，就是当你改变某个外部变量， 整个系统从一个相到达另一个相的过程。&lt;/b&gt;相变理论是复杂系统研究的重要对象，  我们都知道磁铁有的有极性有的没有极性。 研究磁铁特性变化的模型被称为Ising model ，说的是paramagnetic （无磁性）到 ferromagnetic （有磁性）的变化。&lt;b&gt;这里影响一个系统相变的主要是两个要素， 一个是熵（无序性，系统信息的缺失）， 一个是某种趋同的效应&lt;/b&gt;。&lt;/p&gt;&lt;p&gt;在铁磁物质里， 每一个原子都有极性， 平行排列的极子具有指向相同方向的趋势 ，而熵无序的作用则破坏这种效应， 两种力量互相争夺，在较高温度下，熵的作用占主导，而较低温度下，有序的趋同的力量占主导。 在某个温度下，磁体的原子从无序的状态过度到完全有序的状态。 在完全有序的状态下整个磁体显现出对外的磁性。在此处，我们可以控制的外部变量就是温度。&lt;/p&gt;&lt;p&gt;温度越高， 熵就越大。  F=E-TS， 热力学系统寻找自由能最小的状态， 当温度为0，系统自由能最小的状态是一致有序的态， 温度升高， 无序的态的自由能逐步减少， 直到某个点， 称为比有序态更有优势的状态。类似的还有水到冰的相变。&lt;b&gt;也是在某个温度上， 无序和有序的交替。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;这称为临界。 所谓临界，就是相变时候的状态， 因为这个时候最特别， 你说他到底是有序还是无序呢？&lt;/b&gt;临界点上的系统属性特别复杂， 统计上我们经常看到具有标志性的肥尾分布或类似肥尾的分布， 这样的分布无处不在， 比如股市价格波动，  工资分布（帕累托）&lt;/p&gt;&lt;p&gt;&lt;b&gt;临界态极为重要 ， 为什么？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;因为系统在临界点上的属性特别复杂，丰富和有趣， 而且，更重要的， &lt;b&gt;大部分和我们息息相关的系统事实上都在某种程度处于临界态（或靠近临界态）包括大部分的生物系统， 经济系统。&lt;/b&gt;刚讲到的股市崩盘和雪崩的例子， 都是诠释了临界态。&lt;/p&gt;&lt;p&gt;至于临界态是怎么发生的，《大自然如何工作》这本书以及相关的书评可以帮助我们更好的理解，&lt;a href="https://book.douban.com/review/5430252/" class=""&gt;https://book.douban.com/review/5430252/&lt;/a&gt;。在此不再赘述。&lt;/p&gt;&lt;p&gt;&lt;b&gt;此外，所谓涌现， 是在刚才讲到的作用， 反馈， 自组织临界基础上得到的， 系统从微观到宏观， 性质属性质的突破。&lt;/b&gt; 最简单的例子是路， 所谓人走的多了就成了路， 森林中出现交错的小径是大量人物穿越所涌现出的一种现象。涌现性和相变点也有千万联系 ， 大家可以关注自组织临界（self organised criticality）的理论， 去查看更多这个领域的知识。&lt;/p&gt;&lt;p&gt;而复杂系统元素很多， 而且元素之间均有相互作用， 最好的刻画方法就是复杂网络。&lt;/p&gt;&lt;p&gt;The Product Space Conditions Development of Nations, Science 这篇文章就是运用复杂网络描绘了产业森林。在我们专栏之前的文章《从国家产业升级到职业选择--一篇Science神文的启示》有详细描述：链接：&lt;a href="https://zhuanlan.zhihu.com/p/21526637" class=""&gt;https://zhuanlan.zhihu.com/p/21526637&lt;/a&gt;&lt;/p&gt;本文首发于微信公众号混沌巡洋舰（chaoscruiser）欢迎关注混沌巡洋舰，追寻自然界复杂下的简单，带你学习各路跨界干货。著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</description><author>许铁-巡洋舰科技</author><pubDate>Mon, 22 Aug 2016 10:31:37 GMT</pubDate></item><item><title>说说随机森林</title><link>https://zhuanlan.zhihu.com/p/22097796</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/fbed6853d3c557892dc735960eb7f56e_r.png"&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;作者：郭瑞东&lt;/b&gt;&lt;/p&gt;&lt;p&gt;随机森林是机器学习中的一种常用方法，而随机森林背后的思想，更是与群体智慧，甚至“看不见的手”相互映照。&lt;/p&gt;&lt;p&gt;上世纪八十年代Breiman等人发明分类树的算法（Breiman et al. 1984），通过反复二分数据进行分类或回归，计算量大大降低。2001年Breiman把分类树组合成随机森林（Breiman 2001a），即在变量（列）的使用和数据（行）的使用上进行随机化，生成很多分类树，再汇总分类树的结果。随机森林在运算量没有显著提高的前提下提高了预测精度。随机森林对多元公线性不敏感，结果对缺失数据和非平衡的数据比较稳健，可以很好地预测多达几千个解释变量的作用（Breiman 2001b），被誉为当前最好的算法之一（Iverson et al. 2008）。&lt;/p&gt;&lt;p&gt;&lt;b&gt;随机森林顾名思义，是用随机的方式建立一个森林，森林里面有很多的决策树组成，随机森林的每一棵决策树之间是没有关联的。&lt;/b&gt;在得到森林之后，当有一个新的输入样本进入的时候，就让森林中的每一棵决策树分别进行一下判断，看看这个样本应该属于哪一类（对于分类算法），然后看看哪一类被选择最多，就预测这个样本为那一类。随机森林可以既可以处理属性为离散值的量，比如ID3算法，也可以处理属性为连续值的量，比如C4.5算法。另外，随机森林还可以用来进行无监督学习聚类和异常点检测。&lt;/p&gt;&lt;p&gt;决策树（decision tree）是一个树结构（可以是二叉树或非二叉树）。其每个非叶节点表示一个特征属性上的测试，每个分支代表这个特征属性在某个值域上的输出，而每个叶节点存放一个类别。使用决策树进行决策的过程就是从根节点开始，测试待分类项中相应的特征属性，并按照其值选择输出分支，直到到达叶子节点，将叶子节点存放的类别作为决策结果。&lt;/p&gt;&lt;p&gt;&lt;b&gt;随机森林由决策树组成，决策树实际上是将空间用超平面进行划分的一种方法，每次分割的时候，都将当前的空间一分为二，&lt;/b&gt;比如说下面的决策树（其属性的值都是连续的实数）：&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/fbed6853d3c557892dc735960eb7f56e.png" data-rawwidth="628" data-rawheight="434"&gt;&lt;p&gt;&lt;b&gt;这一颗树将样本空间划分为成的样子为：&lt;/b&gt;&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/bd9d3fe215ad812ddd3ca7133251b38a.png" data-rawwidth="577" data-rawheight="497"&gt;&lt;p&gt;&lt;b&gt;下面是随机森林的构造过程：&lt;/b&gt;&lt;/p&gt;&lt;p&gt;　　1. 假如有N个样本，则有放回的随机选择N个样本(每次随机选择一个样本，然后返回继续选择)。这选择好了的N个样本用来训练一个决策树，作为决策树根节点处的样本。&lt;/p&gt;&lt;p&gt;　　2. 当每个样本有M个属性时，在决策树的每个节点需要分裂时，随机从这M个属性中选取出m个属性，满足条件m &amp;lt;&amp;lt; M。然后从这m个属性中采用某种策略（比如说信息增益）来选择1个属性作为该节点的分裂属性。&lt;/p&gt;&lt;p&gt;　　3. 决策树形成过程中每个节点都要按照步骤2来分裂（很容易理解，如果下一次该节点选出来的那一个属性是刚刚其父节点分裂时用过的属性，则该节点已经达到了叶子节点，无须继续分裂了）。一直到不能够再分裂为止。注意整个决策树形成过程中没有进行剪枝。&lt;/p&gt;&lt;p&gt;　　4. 按照步骤1~3建立大量的决策树，这样就构成了随机森林了。&lt;/p&gt;&lt;p&gt;在建立每一棵决策树的过程中，有两点需要注意采样与完全分裂。&lt;/p&gt;&lt;p&gt;首先是两个随机采样的过程，random forest对输入的数据要进行行、列的采样。对于行采样，采用有放回的方式，也就是在采样得到的样本集合中，可能有重复的样本。假设输入样本为N个，那么采样的样本也为N个。这样使得在训练的时候，每一棵树的输入样本都不是全部的样本，使得相对不容易出现over-fitting。然后进行列采样，从M个feature中，选择m个（m &amp;lt;&amp;lt; M）。&lt;/p&gt;&lt;p&gt;之后就是对采样之后的数据使用完全分裂的方式建立出决策树，这样决策树的某一个叶子节点要么是无法继续分裂的，要么里面的所有样本的都是指向的同一个分类。一般很多的决策树算法都一个重要的步骤——剪枝，但是这里不这样干，由于之前的两个随机采样的过程保证了随机性，所以就算不剪枝，也不会出现over-fitting。&lt;/p&gt;&lt;p&gt;通过分类，子集合的熵要小于未分类前的状态，这就带来了信息增益（information gain）&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/04d2296ac9bc5ec0bcc8a41ddc3b5de6.png" data-rawwidth="691" data-rawheight="498"&gt;&lt;p&gt;&lt;b&gt;决策树有很多的优点：&lt;/b&gt;&lt;/p&gt;&lt;p&gt;a. 在数据集上表现良好，两个随机性的引入，&lt;b&gt;使得随机森林不容易陷入过拟合&lt;/b&gt;&lt;/p&gt;&lt;p&gt;b. 在当前的很多数据集上，相对其他算法有着很大的优势，两个随机性的引入，使得随机森林具有&lt;b&gt;很好的抗噪声能力&lt;/b&gt;&lt;/p&gt;&lt;p&gt;c. 它能够&lt;b&gt;处理很高维度（feature很多）的数据，并且不用做特征选择，&lt;/b&gt;对数据集的适应能力强：既能处理离散型数据，也能处理连续型数据，数据集无需规范化&lt;/p&gt;&lt;p&gt;d. 可生成一个Proximities=（pij）矩阵，用于&lt;b&gt;度量样本之间的相似性&lt;/b&gt;： pij=aij/N, aij表示样本i和j出现在随机森林中同一个叶子结点的次数，N随机森林中树的颗数&lt;/p&gt;&lt;p&gt;e. 在创建随机森林的时候，对generlization error使用的是&lt;b&gt;无偏估计&lt;/b&gt;&lt;/p&gt;&lt;p&gt;f. &lt;b&gt;训练速度快&lt;/b&gt;，可以得到变量重要性排序（两种：基于OOB误分率的增加量和基于分裂时的GINI下降量&lt;/p&gt;&lt;p&gt;g. 在训练过程中，&lt;b&gt;能够检测到feature间的互相影响&lt;/b&gt;&lt;/p&gt;&lt;p&gt;h. &lt;b&gt;容易做成并行化方法&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;i. 实现比较简单&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;随机森林主要应用于回归和分类。&lt;/b&gt;本文主要探讨基于随机森林的分类问题。随机森林和使用决策树作为基本分类器的（bagging）有些类似。以决策树为基本模型的bagging在每次bootstrap放回抽样之后，产生一棵决策树，抽多少样本就生成多少棵树，在生成这些树的时候没有进行更多的干预。而随机森林也是进行bootstrap抽样，但它与bagging的区别是：在生成每棵树的时候，每个节点变量都仅仅在随机选出的少数变量中产生。因此，不但样本是随机的，连每个节点变量（Features）的产生都是随机的。&lt;/p&gt;&lt;p&gt;许多研究表明， 组合分类器比单一分类器的分类效果好，&lt;b&gt;随机森林（random forest）是一种利用多个分类树对数据进行判别与分类的方法，它在对数据进行分类的同时，还可以给出各个变量（基因）的重要性评分，评估各个变量在分类中所起的作用。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;随机森林算法得到的随机森林中的每一棵都是很弱的，但是大家组合起来就很厉害了。我觉得可以这样比喻随机森林算法：每一棵决策树就是一个精通于某一个窄领域 的专家（因为我们从M个feature中选择m让每一棵决策树进行学习），这样在随机森林中就有了很多个精通不同领域的专家，对一个新的问题（新的输入数 据），可以用不同的角度去看待它，最终由各个专家，投票得到结果。而这正是群体智慧（swarm intelligence），经济学上说的看不见的手，也是这样一个分布式的分类系统，由每一自己子领域里的专家，利用自己独有的默会知识，去对一项产品进行分类，决定是否需要生产。随机森林的效果取决于多个分类树要相互独立，要想经济持续发展，不出现overfiting（就是由政府主导的经济增长，但在遇到新情况后产生泡沫），我们就需要要企业独立发展，独立选取自己的feature 。&lt;/p&gt;&lt;p&gt;本文首发于微信公众号混沌巡洋舰（chaoscruiser）&lt;/p&gt;&lt;p&gt;欢迎关注混沌巡洋舰，追寻自然界复杂下的简单，带你学习各路跨界干货。&lt;/p&gt;</description><author>许铁-巡洋舰科技</author><pubDate>Sat, 20 Aug 2016 10:29:33 GMT</pubDate></item><item><title>降维这件事</title><link>https://zhuanlan.zhihu.com/p/22005724</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/eec74e8d3fa0ecfe67c8baa41efd7204_r.png"&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;作者 郭瑞东&lt;/b&gt;&lt;/p&gt;&lt;p&gt;（本文来源于东哥的《该怎么看待降维这件事》，并在开头的两段摘用了东哥《浅谈大数据》中的内容。）&lt;/p&gt;&lt;p&gt;科学的进步，商业的发展，得益于数据所统领的疆域的扩展，随着之前越来越不可量化的变得可以计量。&lt;/p&gt;&lt;p&gt;&lt;b&gt;大数据不单单是指数据量的大，也不是仅仅指数据来源的广（数据的维数大），还意味着数据间的关系更加复杂（复杂网络的涌现）。&lt;/b&gt;数据中既包含有用的信号，也包含无用的噪音。但不同维度的数据可以互相验证，互为因果，从而带来数据间的有序性。数据在不断的变化中，而变化的趋势又受制于你观察数据之外的环境因素，这环境因素具有自我指称的特性。&lt;/p&gt;&lt;p&gt;数据的扩大不会必然带来视野和格局的扩大。而数据来源一旦多元，就一定要有去伪存真的步骤，去除重复，剔除噪音，清洗缺失值，使数据做的同步，准确，完整。这是当前数据处理中最耗时的步骤，而如何避免在数据清洗时过度补偿，如何避免丢弃过多有用数据，则是最需要智慧的。&lt;/p&gt;&lt;p&gt;面对庞杂的数据，降低维度似乎是一个习惯性的处理模式。&lt;b&gt;降维理念是使用较少的变量来概括性描述目标数据的特征，而降维的极致是将种种复杂的情况变为一个数&lt;/b&gt;。例如，对于得了癌症的患者，他们最想知道的是得了自己这种病的人平均还能再活几年。但是，这个终极的降维将会扭曲过多的信息。&lt;/p&gt;&lt;p&gt;这个问题的实质，是问问题的人不想，也不能知道全部的信息。资料库中有这类患者共百万人，每个人接受的治疗不同，每个人本身的身体素质不同，每个人的心态也不同，从而导致了每个人的诊断后寿命也不同。但问问题的人不是再做科学研究，他只想基于短小明确的信息做出判断。在这个时候，有用的信息必须要在一分钟之内说完。&lt;/p&gt;&lt;p&gt;&lt;b&gt;要涵盖更多的信息，我们首先要做的是分类&lt;/b&gt;。&lt;b&gt;而对于一个随机变量，最关键的不是它的统计指标，而是它的分布。&lt;/b&gt;最著名的分布有正态分布和指数分布，不同的分布，其结果天差地别。正态分布对称，尾巴不长，不太可能出现太离谱的事件。而对于指数分布，远离平均值的事件注定会发生。&lt;/p&gt;&lt;p&gt;对于上文提到的癌症患者来说，搞清楚存活时间的分布远比搞清楚平均存活时间重要的多。如果存活时间是正态分布，那么你有50%的几率活过平均存活时间，之后死神会离你越来越近。而如果是指数分布，由于其scale free的性质，当你活过了平均存活时间，你预期还能再活一个平均寿命那么长，也就是说，死神会离你越走越远。正如《反脆弱》中所说，如果一个事情存活了1000年，那么你可以预期他还可以在存活一千年。&lt;/p&gt;&lt;p&gt;事实上，癌症的存活时间更接近指数分布。理解这则信息和其背后的意义，对于癌症患者的意义，远远超过了平均存活年龄。这则信息说明，同样的治疗方法，相似的病症，却有着相差甚大的存活时间。其中肯定有些正反馈存在，不然不会有这个一个尺度一致的分布。而这个正反馈，最有可能的便是患者的心态和求生意志。更强的求生意志会带来更多的生存时间，而这会延长你的存活预期。&lt;/p&gt;&lt;p&gt;从癌症的例子，我们可以看到&lt;b&gt;降维的问题之一是忽略分布。而另一个问题则是你选择的指标可能不够基础。&lt;/b&gt;例如，按照流行的观点，对于学生来说，一维的指标意味着分数至上，对于企业来说，是利益至上，对于国家来说，是GDP至上。&lt;/p&gt;&lt;p&gt;有的人不同意这样的降维方法，说评价学生的指标应该是综合素质，20%的体育，20%的艺术，30%的修辞，30%的科学，有的人认为这个比例不对。对于国家，有的人认为GDP不能代表国家的实力，GNP才能。&lt;/p&gt;&lt;p&gt;降维的极限，是为了给出一个排名，给出一个排名，是为了给出是否进步的评价，可惜，自然界的进化不是这样的。&lt;/p&gt;&lt;p&gt;不同的基因是一个不同的维度，每一种基因的组合带来不同的适应性，进化的目的是找出最优的基因组合，使生物体有最优的适应性。不是跑的快的就一定能抓到猎物，也不是体重大的就一定能抢到妹子。&lt;/p&gt;&lt;p&gt;&lt;b&gt;生物体的降低维度，不是通过对几个维度的加减乘除，而是通过一套复杂的大网，将一个个个体的性状变成了基因组合的适应度，从而指导生物的进化。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;就比如说中国文化对世界文化的贡献，可选取的维度有中文书报的数量，中文论文的数量，使用中文的人数，中文网页的数量，要降低维度，我们需要的是让各国的文献互动，最后选出的维度是有多少中文被翻译成了外文。然后来评价各国文字相互翻译的表上中文出现的中心度。&lt;/p&gt;&lt;p&gt;PageRank算法也是在降低维度，从而形成对网站的排名。总统大选也是在降维，政治问题错综复杂，最终落到了两个人的选择。&lt;/p&gt;&lt;p&gt;PCA之所以能降低维度，如下图所示，是找到了AB两个数据点的相关冗余的部分，如果待降维的点都在坐标轴上，那么降维损失的信息量就很大了。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/79c06518b63a32d8b3ff62170841b739.png" data-rawwidth="824" data-rawheight="770"&gt;&lt;p&gt;&lt;b&gt;要避免过度降维的坏处，就要找出相互之间独立的维度来，通过现实生活中的竞争，来动态的调整不同维度间的权衡。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;对于物种，这两个独立的维度是吸引异性的魅力和让自己活下去的能力。&lt;/p&gt;&lt;p&gt;对于企业，是花在探索新领域（exploration）和花在巩固已有疆土的能力（exploitation）&lt;/p&gt;&lt;p&gt;对于学生，是之后继续学习的能力和已熟练掌握的知识&lt;/p&gt;&lt;p&gt;&lt;b&gt;多找出几个相互独立的维度，才能避免被过度降维成一个数字。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;不要总用一个简单的指标来评价别人，久而久之，你也会因此掉如自己射出的二向箔，对自己的评价也只使用那个孤立的指标。&lt;/p&gt;&lt;p&gt;&lt;b&gt;所有的降维，都会带来原始信息的损失&lt;/b&gt;。就像可以用中位数，众数，平均数来为一组随机变量降维，但无论那种降维方法，都有各自的问题。只有明白了随机变量的分布是更趋近正态还是指数，才可能降低降维带来的信息损失。&lt;/p&gt;&lt;p&gt;&lt;b&gt;代替降维的最优方法，是先构建起相互作用一个网络，看看网络中哪个节点处在中心。节点的互动包含的隐藏信息，可以在网络的构建中被展示，从而使降维所依赖的信息不止是变量之间的相关性。&lt;/b&gt;不过这需要来源多样，时间连续的数据，而这样的数据又被环境因素、采集过程等因素影响，从而影响降维的结果。&lt;/p&gt;&lt;p&gt;&lt;b&gt;本文首发于微信公众号混沌巡洋舰（chaoscruiser）&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;欢迎关注混沌巡洋舰，追寻自然界复杂下的简单，带你学习各路跨界干货。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;欢迎加铁哥微信（562763765）&lt;/b&gt;&lt;/p&gt;&lt;p&gt;（小编：昨天铁哥的机器学习与复杂系统课程中，讲到“在动力学系统预测社会经济学问题中，要注意拐点和极值点的变量”的时候小编有种醍醐灌顶的感觉。对信息的降维处理，对趋势的判断与分析，都需要快速判断哪些东西处于信息网络的中心节点上。等这两天课程结束了，相关精彩内容会整理上线，欢迎关注！）&lt;/p&gt;</description><author>许铁-巡洋舰科技</author><pubDate>Sun, 14 Aug 2016 11:03:47 GMT</pubDate></item><item><title>预测类问题与时间序列</title><link>https://zhuanlan.zhihu.com/p/21895085</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/ada2df9029e0b57fb778a205f2849808_r.png"&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;什么是所有预测类问题所共同包含的特点? &lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;模式识别。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;所谓&lt;b&gt;模式， 是在随机和无序的现象中蕴含的规律性&lt;/b&gt;（用另一个词说就是信息）， 可是我们信以为真的规律有时候却会把我们骗的团团转。比如你在书里看到受一些超市里发现买啤酒的顾客通常有较高的概率买尿布， 你就在你在的小超市里给给买啤酒的人推荐尿布， 结果最后往往是南辕北辙。 &lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/284d373b25c153073aaaa24a3386a0fc.png" data-rawwidth="692" data-rawheight="510"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/c050f1ee2eacaa10c6bf9c674abafb8d.png" data-rawwidth="748" data-rawheight="457"&gt;&lt;p&gt;图： 模式在自然和社会中无处不在&lt;/p&gt;&lt;p&gt;&lt;b&gt;所以我们不仅需要知道模式的存在， 更要理解它们为什么会存在， 以及了解挖掘它们的方法 。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这里就涉及两个基本的方法， 一个叫复杂科学（复杂系统）， 一个叫机器学习。 复杂科学试图告诉我们模式从哪里来， 机器学习试图告诉我如果突破人类的局限， 去寻找这些模式。 因此我们开发了无数有趣有用的工具。&lt;/p&gt;&lt;p&gt;而在预测类问题中，我们的目的是&lt;b&gt;从现象中识别模式，预测时间序列上的现象。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;时间序列指某个物理量对时间的函数&lt;/b&gt;。这是一个高度抽象的东西， 但是生活中无数特别重要的东西都可以用它来表述， 比如股市啊， 你一天的血糖变化啊， 你的大脑兴奋性啊，甚至你的语言， 你的思维， 历史王朝的兴衰，都可以把它看作一个离散的时间序列。 无论你是想要预测一个股市的涨落， 还是要从你一天的血糖变化里总结健康状况， 还是要让计算机识别一段语音， 你都面临的一个核心问题，  就是时间序列的理解。 而这点，恰恰是机器学习和复杂系统共同合作的典范。   &lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/91c34b3610dd43d7447ffc412f2a834c.png" data-rawwidth="964" data-rawheight="780"&gt;&lt;p&gt;图： 时间序列&lt;/p&gt;&lt;p&gt;时间序列本身无非是一堆数， 你真正要掌握的是时间序列的类型判别，然后是预测它 。&lt;b&gt;当你拿到一个时间序列， 你可以像一个侦探一样从以下几个角度去认识和挖掘它：&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;1 随机vs确定： &lt;/b&gt;&lt;/p&gt;&lt;p&gt;一个时间序列，往往是外界给与的另一个时间导致的一个东西， 而这样一个东西， 可以随外界的变化而确定， 但也可以由于更复杂的原因是不确定的。   因此， 你要有一个概率空间的概念， 首先思考这个时间序列是否是可以重复的。 &lt;/p&gt;&lt;p&gt;&lt;b&gt;2 没有记忆vs历史依赖&lt;/b&gt;&lt;/p&gt;&lt;p&gt;时间序列这一刻的状态如果只和上一刻相关， 则可以说它是没有复杂记忆的（马尔科夫过程），反之， 时间序列此刻的状态如果不仅和上一刻相关， 还和上刻，上上刻相关， 那就不具有马氏性，而是复杂历史依赖。 &lt;/p&gt;&lt;p&gt;&lt;b&gt;3 线性vs非线性&lt;/b&gt;&lt;/p&gt;&lt;p&gt;如果影响时间序列变化的因素之间相互独立， 则它们总的效果可以分解为单个因素的影响的叠加，我们称之为线性，对于线性系统我们有一套现成工具解决。 反之如果影响它的因子不能被单独拆分， 则是非线性的。一旦具有非线性， 则问题变得极为复杂，各种类型的相变， 混沌应运而生。&lt;/p&gt;&lt;p&gt;&lt;b&gt;4  问题有多少维？ 升维还是降维？ &lt;/b&gt;&lt;/p&gt;&lt;p&gt;时间序列往往一个随时间变化的高维向量， 首先你要看看你的序列是多少维度的， 然后你要做一个物理学家最常面临的决策：  是否降维？   有时候降维之后问题变得无比简单（PCA分析）， 但有时候恰好相反， 把一个低维度的东西投影到高维度才是最简单的（神经网络）。&lt;/p&gt;&lt;p&gt;&lt;b&gt;5  如果这些都给定了， 如何预测一个时间序列的走势？ &lt;/b&gt;&lt;/p&gt;&lt;p&gt;好了， 这才是核心， 如果你了解了时间序列的上述特性， 你可以试着使用一系列工具， 比如对于线性的问题， 线性回归这类非常一般的方法有时候都会得到不错的解决。 如果不具备复杂的记忆， 则隐变量马尔科夫过程HMM就可以很好的解决这个问题。 如果恰好所有的都被否定了， 则你要考虑寄出神经网络大法碰碰运气。 &lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/93fd235ca18620b0aa057a1b536e1edc.png" data-rawwidth="793" data-rawheight="327"&gt;&lt;p&gt;&lt;b&gt;6 那么有没有可能一切试过了还是不能预测？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这里复杂科学就会碰上用场， 因为你完全可能发现所有的预测方法都失控， 而真相就是问题本身包含不可预测性。 &lt;/p&gt;&lt;p&gt;比如说股市，从刚才的三个指标看， 股市是一个典型的具有巨大随机性， 复杂历史依赖，与非线性的时间序列 ，任何用简单因素预测股市的方法都是扯，即使一些最复杂的工具比如神经网络也很难取得特别好的突破。 &lt;/p&gt;&lt;p&gt;&lt;b&gt;这是为什么？  &lt;/b&gt;&lt;/p&gt;&lt;p&gt;因为股市这个系统其实处于物理里所说的某种临界态上， 首先动力学高度混沌， 收到微小因素影响就会与原有预测分道扬镳，第二它具有反身性， 即你的预测会反馈到未来里，使得最终结果更加扑朔迷离。  第三股票经常受到突发事件影响， 而如911这样的大新闻从根本上说是不可预测的黑天鹅事件。  &lt;/p&gt;&lt;p&gt;那么是不是那些研究股市的人都是瞎的？ 也不是，股市这个东西呢，你要是想赚的多， 只需要把预测的正确率提高1个百分点， 而不是要准确预测， 1个百分点对于大的机构来说， 就可能是无穷大的收入增长。 而复杂的模型，还是有可能把正确率提升1个百分点以上的 ，否则quant干什么吃呢？ &lt;/p&gt;&lt;p&gt;&lt;b&gt;7 甚至有些初看觉得特别有规律的东西， 也不是完全可预测的&lt;/b&gt;&lt;/p&gt;&lt;p&gt;比如心跳这个看似简单的问题， 首先心跳是个时间序列，然后心跳不是周期性的吗？ 那不是可以完全预测？  事实上， 如果你细致的看， 心跳还是有长短不同的间隔。而对于一些心脏病人， 它们的心跳也会显示类似混沌系统的十分复杂的模式。 而对于心跳出现偶然不齐的预测， 则可以成为预防一个人心脏病突发死亡的基础， 虽然这并非总是很简单。 &lt;/p&gt;&lt;p&gt;&lt;b&gt;8  自然语言处理与时间序列&lt;/b&gt;&lt;/p&gt;&lt;p&gt;语言， 你不要以为和数学没有关系。 当你把它转化为数字， 它也无非是一个随时间变化的高维向量。这种时间序列也是可以用精美的概率模式描述的， 而如果寄出神经网络大法，我们甚至可以发现它也是可以预测的。 这个神奇的工具叫递归神经网络（RNN）， 它真的是会试着回答你的问题的哦。  如果有一天人类真能做出突破图灵测试的AI-Machina， 估计就是以她为原件哦。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/052ebcd676c02af14d54b47f8ceb2f04.png" data-rawwidth="1141" data-rawheight="684"&gt;&lt;p&gt;&lt;b&gt;9. 随机之美&lt;/b&gt;&lt;/p&gt;&lt;p&gt;概率作为一个数学工具的存在，也描述了人在随机性面前的无力，随机性在同时赋予世界创造与毁灭世界的力量的时候所带来的悲剧之美。 在我眼里，好的科学与梵高的名画，莫扎特的音乐是异曲同工的。&lt;/p&gt;&lt;p&gt;人类发明了人工智能，人工智能又反过来促使我们自身的提高。而在进行模式识别预测未来时间点的变化的过程中，也在一步一步重构自身的世界。&lt;/p&gt;&lt;p&gt;&lt;b&gt;本文首发于微信公众号混沌巡洋舰（chaoscruiser）&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;欢迎关注混沌巡洋舰，追寻自然界复杂下的简单，带你学习各路跨界干货。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;广告：如果你&lt;/b&gt;&lt;b&gt;想对最先进的预测和决策工具进行概览式了解，&lt;/b&gt;&lt;b&gt;铁哥的复杂系统与机器学习特训课将于2016年8月13日在北京五道口附近开班，详情咨询铁哥微信（562763765）&lt;/b&gt;&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/2cb4ad3e229c28c154095ed054233e4a.png" data-rawwidth="720" data-rawheight="1280"&gt;</description><author>许铁-巡洋舰科技</author><pubDate>Sat, 06 Aug 2016 12:54:56 GMT</pubDate></item><item><title>人工智能vs人类智能小传</title><link>https://zhuanlan.zhihu.com/p/21693808</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/a24a9475e802a8227c50c92b4dd274d0_r.jpg"&gt;&lt;/p&gt;&lt;p&gt;深度网络代表的这波人工智能风潮代表的是一种局部的演进，还是未来的一扇大门打开？  &lt;/p&gt;&lt;p&gt;AI离真正的智能很遥远是因为它不能创造吗？  是因为它只擅长形式逻辑？ 是因为它没有自我意识？ &lt;/p&gt;&lt;p&gt;其实，我们连生物的智能都不了解。 现在，我们回顾一下神经科学和AI的历史， 从脑和智能的演进来看这个所谓的人工智能有多聪明。&lt;/p&gt;&lt;p&gt;要谈这个问题，我们就需要从智能说起，&lt;b&gt; 智能其实分为三个层次，对应丹内特对意识进化的三个分级： 达尔文式造物 ，斯金纳式造物， 波普尔式造物 。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;智能的第一个层次是进化&lt;/b&gt;（达尔文式），而不是自我意识这些高端装逼的东西。&lt;b&gt;智能的起点是学习，学习即对环境变化做出相应对策。&lt;/b&gt;&lt;b&gt;整个生物进化过程，就是学习的过程。&lt;/b&gt;为什么呢?   你一个小小的细菌， 也可以对环境做出趋利避害的反应， 并且通过基因突变的方法有点盲目的适应环境，这其实就是用遍历法来选择针环境变化的最佳生存策略，然后通过遗传以及下一代继续试错，将某种策略强化。 阿法狗的策略网络也是类似的道理， 通过对可选策略集合的分析进行局部最优的调整。  细菌和十亿年的 的恶略环境下棋， 把对哪些化学物质该如何转化这个信息深深的埋藏在了它的DNA里， 因此才可以有如今如此从极地到大漠的如此伟大的适应性。 大自然的这种学习方式可以看做智能1.0版， 缺陷是速度慢和读取数据量小 。我们人类模仿进化的过程创造了进化选择算法， 作为人工智能一个非常基础的部分。 &lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/e0b98ccbe9105b3c319d91a4cbfb2191.png" data-rawwidth="867" data-rawheight="822"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/72afe88359f4e531de3ac81d318d2810.png" data-rawwidth="871" data-rawheight="584"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/9a894fa4b8c93a862ea2a585373b719a.png" data-rawwidth="900" data-rawheight="727"&gt;&lt;p&gt;下面我想说的是第二阶段的智能， 斯金纳（伟大的行为心理学家）式造物。  &lt;/p&gt;&lt;p&gt;&lt;b&gt;斯金纳式造物说的是生物自己能够自主的去学习而非被动的靠基因变异适应环境。&lt;/b&gt; 这项伟大的创举背后就是大名鼎鼎的神经网络， 生物进化几十亿年的历史都是这种被动的适应环境， 直到神经网络的出现一切才悄悄发生变化。&lt;/p&gt;&lt;p&gt;&lt;b&gt;神经网络的作用简单来看， 就是一个分类器， 它可以把外界刺激分成好的和坏的， 并且趋利避害&lt;/b&gt;。拥有这个分类器， 动物终于可以在自然环境面前主动做决策，  并且趋利避害。把狮子放在要躲避的那一堆， 异性放在要接近的那一堆对于动物的生存意义之重大不言而喻。  这个分类器最开始是储存一些先天的条件反射， 比如婴儿见到目前的乳头就要吸。 而后来就出现了后天习得的条件反射， 比如著名的巴甫洛夫的狗，听到铃声就会分泌口水。没错， 后天形成的条件反射-就是学习的2.0版。&lt;/p&gt;&lt;p&gt; 然而生物神经网络是如何实现这一调整的，却一直是个迷，直到1940年Hebb提出神经科学的牛顿定律-Hebbian learning rule， 人们开始了解神经网络是如何实现这一步骤。 Hebb说组成神经网络的神经元通过不停的调整之间的突触连接来改变对外界刺激的反应，这个变化法则就是同时放电的神经元连接加强（细节来看还与放电的顺序有关）。 这就使得被一起激活的神经元形成一个基团， 比如狗听到铃声以后被喂食， 那铃声这个刺激之前狗可能没有任何反应，而之后就被划分到午餐那一类， 从而形成对铃声的条件反射。阿尔法狗深度学习的基本原件人工神经网络也是一个人为敲定的分类器， 用于做决策。 &lt;/p&gt;&lt;p&gt;&lt;b&gt;人工神经网络的训练过程同样借鉴了生物神经网络的学习过程， 根据反馈调整神经元之间连接的权重关系， 来实现对外界信号分类方法的改变， 因此调整决策（reinforcement learning 强化学习）。&lt;/b&gt;&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/403da754a7c1b7652556369f85514450.png" data-rawwidth="803" data-rawheight="671"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/392af7ecc23114cdd3f46c487fc3cdc0.png" data-rawwidth="403" data-rawheight="263"&gt;&lt;p&gt;&lt;b&gt;分类问题可以由神经网络解决：&lt;/b&gt;&lt;/p&gt;&lt;p&gt;上图的神经网络， 就是一个基本的卷积网络， 把输入的值乘以一定权重在加在一起， 再通过一个非线性的阶梯函数， 转化为0（有害），1（有利）的输出， 即决策过程。 &lt;/p&gt;&lt;p&gt;学习， 数学上叫调参：  改变w的数值即可改变分类的方法（界限）。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/8aceed42a2af0fac1ab5d8991c0f23ca.png" data-rawwidth="837" data-rawheight="687"&gt;&lt;p&gt;神经网络的分类功能， 把输入的信息（环境变化）分为有利和有害的进行决策， 环境的变化越复杂， 越体现神经网络可以任意的通过改变连接强度来调整决策“界面”  的优势, 而不需要用进化的方法上下一辈来适应环境（学习的重要性）。 当然这个学习过程需要大量数据的训练。 &lt;/p&gt;&lt;p&gt;&lt;b&gt;结论：  一个单层神经网络完全可以娴熟的应用斯金纳造物       &lt;/b&gt;&lt;/p&gt;&lt;p&gt;从第二种智能方式我们依然可以看到， 生物智能的方式是如何启发了人工智能。 &lt;/p&gt;&lt;p&gt;&lt;b&gt;智能的最高级形式波普尔造物， 对外部世界进行表征， 形成认知，信念和预期，则对应神经网络的更高级功能。 &lt;/b&gt;&lt;/p&gt;&lt;p&gt;如果仔细思考， 我们会发现这些很多包含在阿法狗使用的深度网络里。 首先， 深度网络最擅长的是对事物进行抽象（深度学习）， 在最靠近输入的层次上， 每个细胞就如同数码相机CCD上的像素，之后的每一层次都比上级网络的感受野要大， 而最终得到的效果是最深层的神经元直接处理和图像的全貌相关的特征，比如照片上的人是谁。如果换到其他地方，就是从抽象或全局特征进行决策。   &lt;/p&gt;&lt;p&gt;这个结构像极人类社会的结构， 越是高层， 越能把握和总控全局。深度网络上的“抽象概念”这个认知武器，使得阿尔法狗有对全盘棋的趋势进行判断的能力，可以迅速舍弃一些错误的方向，减少搜索的深度，即价值网络。 其实人脑所使用的算法和阿尔法狗差距没有那么大， 记得前些年有一篇著名的science文章说人类发现在高级脑区表现抽象概念-如人名的细胞，这是符合这种深度网络逐层抽象的概念。高级脑区正是对应人脑深层网络的最底层。 &lt;/p&gt;&lt;p&gt;阿尔法狗能够战胜代表棋牌巅峰智慧的围棋冠军这件事最大的意义，也在于&lt;b&gt;深度网络赋予了AI自主判断局势和形成策略，而不是靠之前的仅靠人为给定的策略遍历所有可能。&lt;/b&gt;或者说深度网络打开了波普尔造物的大门&lt;/p&gt;&lt;p&gt;当然，深度网络算法只是提取了生物神经网络的一个主要特征 ， 而几亿年进化结晶的人脑， 由于计算机能够提取并用于学习的数据量巨大， 使得它能够在学习了人脑的一个雕虫小技之后通过迭代学习迅速在某个特定任务上超越人类。   &lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/999bf6cc5165d3ce8fb7d7262110e3e0.png" data-rawwidth="879" data-rawheight="763"&gt;&lt;p&gt;就上面这个简单的历史陈述我们发现，AI说到底是一种仿生，但是这种仿生无疑会改变我们生活的方方面面， 阿尔法狗的智慧是结合了古老的细菌智慧（策略网络）+高级哺乳动物的智慧（价值网络），可谓仿生物智慧杰作。&lt;/p&gt;&lt;p&gt;一些常见问题：&lt;/p&gt;&lt;p&gt;&lt;b&gt;1.  AI到取代人类大量劳动的时候了？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;AI一定会逐步取代简单的人类劳动， 但是也会增加新的劳动出来， 比如AI设计， AI纠错 ，  以及如何利用AI做出以往实践不能的事，  AI将使得人脑从简单劳动中解放， 可以爆发中不可预计的新产业。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2，  AI没有意识， 无法预测，没有创造力， AI几乎永远无法与人类智能望其相背。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;        人类容易犯的错误之一， 就是用一些自己也无法严格定义的概念去套用机器。   “ 意识”  “  创造力”这些概念，  其实人类自身也不理解， 你站在人类的角度上， 去讨论ai有无意识这个问题， 是自己陷入了一个思维的陷阱。 因为究其根本， 我们对自己有没有意识这件事也没有一个掌控的时候， 整个这样的讨论流于空泛。     而对于这些概念的进一步掌握， 取决于神经科学的进步。虽然我比较怀疑很快强人工智能会出现， 但是即使出现， 它也不一定需要以我们人类能理解的方式产生意识， 达到目标。 说不定在另一个外星观测者看来， 我们也是无意识的， 意识不过是这个被称作“人”的东西所使用的多级神经网络里某个调节参数的辅助工具。 &lt;/p&gt;&lt;p&gt;&lt;b&gt;3，  觉得AI的运转方式一定和人脑是天壤之别的&lt;/b&gt;&lt;/p&gt;&lt;p&gt; 这也是犯了太骄傲的毛病。 因为你并不懂得人脑运算所采用的算法。  人脑这个东西， 即使是情感这些我们觉得很柔软的功能，背后也是以海量运算为背景的，而目前的科学论文证实的是， 在视皮层的运算， 很多与目前的深度网路运算是很接近的。 有的人说人是向前看的动物而机器只会向后看， 事实上呢， 人对未来的预测也来自于对过去数据的大量积累。 &lt;/p&gt;&lt;p&gt;我们并无太多证据受AI是否和我们的大脑有着相类似的运转方式， 但是有一点肯定的是，&lt;b&gt; AI的发展源自我们对自身的模仿， 而对AI的探究反过来正在帮助我们理解我们自身 ，这也是生命最终的意义。 &lt;/b&gt;&lt;/p&gt;&lt;p&gt;正如费曼所说，&lt;b&gt; 只有你知道如何制造一个东西， 你才真正理解它。 &lt;/b&gt;&lt;/p&gt;&lt;p&gt;本文首发于微信公众号混沌巡洋舰（chaoscruiser）&lt;/p&gt;&lt;p&gt;欢迎关注混沌巡洋舰，追寻自然界复杂下的简单，带你学习各路跨界干货。&lt;/p&gt;&lt;p&gt;欢迎加小编铁哥个人微信562763765&lt;/p&gt;&lt;p&gt;著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。&lt;/p&gt;</description><author>许铁-巡洋舰科技</author><pubDate>Sat, 23 Jul 2016 14:20:49 GMT</pubDate></item></channel></rss>