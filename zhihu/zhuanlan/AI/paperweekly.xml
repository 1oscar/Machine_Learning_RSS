<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>PaperWeekly - 知乎专栏</title><link>https://zhuanlan.zhihu.com/paperweekly</link><description>每周会分享N篇nlp领域好玩的paper，旨在用最少的话说明白paper的贡献。同时也运营一个公众号，PaperWeekly，欢迎大家关注。</description><lastBuildDate>Fri, 30 Sep 2016 08:16:32 GMT</lastBuildDate><generator>Ricky</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>cs.CL weekly 2016.09.19-2016.09.23</title><link>https://zhuanlan.zhihu.com/p/22602959</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-ea9f4f4503d2ed9e15a56fe56e26e98d_r.jpg"&gt;&lt;/p&gt;&lt;h1&gt;一周值得读&lt;/h1&gt;&lt;h2&gt;&lt;a href="http://120.52.73.80/arxiv.org/pdf/1609.04904v1.pdf" data-editable="true" data-title="Long-Term Trends in the Public Perception of Artificial Intelligence"&gt;Long-Term Trends in the Public Perception of Artificial Intelligence&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;本文研究了30年来纽约时报对AI的报道，研究了人们这30年来对AI的兴趣、关注度和各种各样的讨论。是一篇很有意思的文章，是一种长时间段内的舆情监测和分析。&lt;/p&gt;&lt;h2&gt;&lt;a href="http://120.52.73.77/arxiv.org/pdf/1609.04873v1.pdf" data-editable="true" data-title="Distant Supervision for Relation Extraction beyond the Sentence Boundary"&gt;Distant Supervision for Relation Extraction beyond the Sentence Boundary&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;本文研究的问题是非结构化文本中的关系抽取问题，针对传统方法在抽取关系时仅限于单个句子，本文提出了一种新的方法，从多个句子中进行关系抽取。&lt;/p&gt;&lt;h2&gt;&lt;a href="http://120.52.73.79/arxiv.org/pdf/1609.04938v1.pdf" data-editable="true" data-title="What You Get Is What You See: A Visual Markup Decompiler"&gt;What You Get Is What You See: A Visual Markup Decompiler&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;【转发较多】本文研究的问题是如何从web页面中生成html代码，以及如何从公式图片中生成latex代码，为此作者构造了两个相关的大型数据集，用了完全数据驱动的端到端训练方法得到了不错的效果。本文工作来自Harvard。&lt;/p&gt;&lt;p&gt;Demo|Dataset|Code: &lt;a href="http://lstm.seas.harvard.edu/latex/"&gt;http://lstm.seas.harvard.edu/latex/&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;&lt;a href="http://120.52.73.80/arxiv.org/pdf/1609.05244v1.pdf" data-editable="true" data-title="Select-Additive Learning: Improving Cross-individual Generalization in Multimodal Sentiment Analysis"&gt;Select-Additive Learning: Improving Cross-individual Generalization in Multimodal Sentiment Analysis&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;本文研究的内容是多模态情感分析，针对当前相关高质量数据集规模太小造成的情感依赖于个体特征的问题，提出了一种Select-Additive学习方法提高通用性。&lt;/p&gt;&lt;h2&gt;&lt;a href="http://120.52.73.78/arxiv.org/pdf/1609.05234v1.pdf" data-editable="true" data-title="Interactive Spoken Content Retrieval by Deep Reinforcement Learning"&gt;Interactive Spoken Content Retrieval by Deep Reinforcement Learning&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;本文研究的内容是DQN算法来做语音内容检索，通过人机交互来完成内容检索。DQN相比传统的RL模型明显的优势在于不依赖hand-crafted features。本文被Interspeech 2016录用。&lt;/p&gt;&lt;h2&gt;&lt;a href="http://arxiv.org/pdf/1609.05600v1.pdf" data-editable="true" data-title="Graph-Structured Representations for Visual Question Answering"&gt;Graph-Structured Representations for Visual Question Answering&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;本文研究内容为VQA，VQA的主要挑战在于对visual和text两个领域都需要理解。传统的模型中常常忽略场景中的结构和问题中的语言结构，本文针对这两个问题提出了一种图模型，取得了不错的效果。&lt;/p&gt;&lt;h2&gt;&lt;a href="http://arxiv.org/pdf/1609.05787v1.pdf" data-editable="true" data-title="Context-aware Sequential Recommendation"&gt;Context-aware Sequential Recommendation&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;用户行为建模是推荐系统中的一个关键部件，行为数据是序列数据，天然适合用RNN来建模。但实际应用中context信息(time,location,weahter)也很重要，本文针对这个问题提出了一种CA-RNN模型将context考虑在内，取得了不错效果。&lt;/p&gt;&lt;h2&gt;&lt;a href="http://120.52.73.78/arxiv.org/pdf/1609.05284v1.pdf" data-editable="true" data-title="ReasoNet: Learning to Stop Reading in Machine Comprehension"&gt;ReasoNet: Learning to Stop Reading in Machine Comprehension&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;本文研究内容为机器阅读理解，之前效果不错的方法大多数停留在有限的几轮reasoning，本文用增强学习来动态地决定是否继续读下去或者停下来进行答案选择。本文工作来自微软研究院。&lt;/p&gt;&lt;h2&gt;&lt;a href="http://120.52.73.76/arxiv.org/pdf/1609.06038v1.pdf" data-editable="true" data-title="Enhancing and Combining Sequential and Tree LSTM for Natural Language Inference"&gt;Enhancing and Combining Sequential and Tree LSTM for Natural Language Inference&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;本文研究内容为自然语言推理，作者认为LSTM类的模型潜力并没有被充分挖掘，基于此，本文在传统LSTM模型的基础上增加了syntactic parse信息，得到了更好的效果。&lt;/p&gt;&lt;h2&gt;&lt;a href="http://120.52.73.80/arxiv.org/pdf/1609.06127v1.pdf" data-editable="true" data-title="A framework for mining process models from emails logs"&gt;A framework for mining process models from emails logs&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;本文研究的内容是邮件日志的挖掘，作者提出了一种无监督的挖掘方法，并且提出了一种半自动化的邮件标注方法。&lt;/p&gt;&lt;h2&gt;&lt;a href="http://120.52.73.79/arxiv.org/pdf/1609.06686v1.pdf" data-editable="true" data-title="Character-level and Multi-channel Convolutional Neural Networks for Large-scale Authorship Attribution"&gt;Character-level and Multi-channel Convolutional Neural Networks for Large-scale Authorship Attribution&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;本文研究内容为authorship attribution，是一个典型的多分类任务。作者利用字符级别的多通道CNN模型对大规模dataset进行了建模，取得了不错的结果。作者之一来自aylien.com 公司，一家非常出色的NLP SaaS 公司。&lt;/p&gt;&lt;h2&gt;&lt;a href="http://120.52.73.76/arxiv.org/pdf/1609.06649v1.pdf" data-editable="true" data-title="Minimally Supervised Written-to-Spoken Text Normalization"&gt;Minimally Supervised Written-to-Spoken Text Normalization&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;本文研究的内容是特定语言领域知识在构建text normalization system的时候应该如何做trade-off，本文作者来自Google。&lt;/p&gt;&lt;h2&gt;&lt;a href="http://120.52.73.76/arxiv.org/pdf/1609.06380v1.pdf" data-editable="true" data-title="Recognizing Implicit Discourse Relations via Repeated Reading: Neural Networks with Multi-Level Attention"&gt;Recognizing Implicit Discourse Relations via Repeated Reading: Neural Networks with Multi-Level Attention&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;本文研究内容是如何识别隐式的discourse关系，作者提出了一种多层注意力模型，联合注意力机制和外部memory来做关系识别。本文是EMNLP2016的长文。&lt;/p&gt;&lt;h2&gt;&lt;a href="http://120.52.73.79/arxiv.org/pdf/1609.06693v2.pdf" data-editable="true" data-title="SoftTarget Regularization: An Effective Technique to Reduce Over-Fitting in Neural Networks"&gt;SoftTarget Regularization: An Effective Technique to Reduce Over-Fitting in Neural Networks&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;【转发较多】本文提出了一种新的正则化方法，通过在训练过程中调整label来实现，达到了和Dropout接近的效果。&lt;/p&gt;&lt;h2&gt;&lt;a href="http://120.52.73.77/arxiv.org/pdf/1609.06657v1.pdf" data-editable="true" data-title="The Color of the Cat is Gray: 1 Million Full-Sentences Visual Question Answering (FSVQA)"&gt;The Color of the Cat is Gray: 1 Million Full-Sentences Visual Question Answering (FSVQA)&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;本文提出了一个1 million的Visual Question Answer Dataset，数据地址：&lt;a href="http://www.mi.t.u-tokyo.ac.jp/static/projects/fsvqa/" data-editable="true" data-title="Projects - Full-Sentence Visual Question Answering"&gt;Projects - Full-Sentence Visual Question Answering&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;&lt;a href="http://arxiv.org/pdf/1609.07075v1.pdf" data-editable="true" data-title="Knowledge Representation via Joint Learning of Sequential Text and Knowledge Graphs"&gt;Knowledge Representation via Joint Learning of Sequential Text and Knowledge Graphs&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;【转发较多】当前知识表示存在两个挑战：1、如何更好地利用entity的context；2、如何发现与entity相关的句子；针对这两个问题，本文提出了一种从多个句子中学习表示的模型。给定每个entity的参考句子，首先用带池化的RNN或LSTM来encode与该entity相关的句子，然后用attention模型来衡量每个句子的信息量，最后得到entity的表示。模型在triple classification和link prediction两个任务上都取得了满意的结果。本文工作来自@刘知远THU组。&lt;/p&gt;&lt;p&gt;刘知远：我觉得这个工作的最有意思的地方是，能够为实体找到最有信息量的句子，这些句子往往是该实体的定义或描述。这样，在构建知识图谱时，我们就可以自动为新增的实体构建对应的文本描述信息了。&lt;/p&gt;&lt;h2&gt;&lt;a href="http://120.52.73.80/arxiv.org/pdf/1609.07053v1.pdf" data-editable="true" data-title="Semantic Tagging with Deep Residual Networks"&gt;Semantic Tagging with Deep Residual Networks&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;本文提出一种多语言智能tagger，模型采用了char-level和word-level的深度残差网络，在词性标注任务中取得了不错的效果，本文COLING 2016在审。&lt;/p&gt;&lt;h2&gt;&lt;a href="http://arxiv.org/pdf/1609.07028v1.pdf" data-editable="true" data-title="Image-embodied Knowledge Representation Learning"&gt;Image-embodied Knowledge Representation Learning&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;【转发较多】entity图像中包含丰富的信息，大多数传统方法并没有利用这一点，本文提出了一种知识表示模型，利用了triples和image信息，并在知识图谱补全和triple分类两个任务中取得了不错的效果。本文是一篇典型的多信息融合的文章，非常值得思考！工作同样来自@刘知远THU老师组。&lt;/p&gt;&lt;h2&gt;&lt;a href="http://120.52.73.80/arxiv.org/pdf/1609.06791v1.pdf" data-editable="true" data-title="Twitter-Network Topic Model: A Full Bayesian Treatment for Social Network and Text Modeling"&gt;Twitter-Network Topic Model: A Full Bayesian Treatment for Social Network and Text Modeling&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;推特上的推对于topic建模有以下缺点：1、短；2、非结构化；3、口语化；也有优点：1、作者；2、hashtags；3、粉丝网络。本文结合推特信息的优点提出了一种新模型。topic model是个老话题了，多源信息的融合是突破研究瓶颈一个不错的方向，本文的方法同样可借鉴于微博和其他社交网络。&lt;/p&gt;&lt;h2&gt;&lt;a href="http://120.52.73.78/arxiv.org/pdf/1609.06773v1.pdf" data-editable="true" data-title="Joint CTC-Attention based End-to-End Speech Recognition using Multi-task Learning"&gt;Joint CTC-Attention based End-to-End Speech Recognition using Multi-task Learning&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;【转发较多】Attention类模型在端到端语音识别领域取得了不错的效果，但当输入噪声非常大的的时候，识别长句子效果不是很好。CTC是另外一种不错的端到端模型，本文结合两者的优势构建模型。构建了联合模型之后，克服了之前的问题。大家都在用Attention，都说Attention好，但终究还是有些情境下attention并不能如人意。那么问题来了，到底哪些场景下attention表现不好，原因是什么？想清楚这个到底之后，改进的方法大概也就在路上了。#Attention Model的缺点#&lt;/p&gt;&lt;h1&gt;资源分享&lt;/h1&gt;&lt;h2&gt;&lt;a href="https://www.producthunt.com/topics/bots" data-editable="true" data-title="Bots - Product Hunt"&gt;Bots - Product Hunt&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;一个分享和点评各种好玩product的站点，其中一个栏目有各种各样的bot。&lt;/p&gt;&lt;h2&gt;&lt;a href="https://github.com/chewxy/gorgonia" data-editable="true" data-title="Gorgonia is a library that helps facilitate machine learning in Go"&gt;Gorgonia is a library that helps facilitate machine learning in Go&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;用Go写的机器学习开源框架。&lt;/p&gt;&lt;h2&gt;&lt;a href="https://github.com/danqi/rc-cnn-dailymail" data-editable="true" data-title="A Thorough Examination of the CNN/Daily Mail Reading Comprehension Task"&gt;A Thorough Examination of the CNN/Daily Mail Reading Comprehension Task&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;这篇paper的代码放出来了，同时包括CNN和Daily Mail的数据集。来自斯坦福Danqi Chen的工作。&lt;/p&gt;&lt;h1&gt;业界新闻&lt;/h1&gt;&lt;h2&gt;&lt;a href="https://api.ai/blog/2016/09/19/api-ai-joining-google/" data-editable="true" data-title="API.AI is joining Google!"&gt;API.AI is joining Google!&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;chatbot构建平台api.ai被Google收购了&lt;/p&gt;&lt;h2&gt;&lt;a href="https://techcrunch.com/2016/09/20/angel-ai-a-company-that-builds-chat-bots-acqui-hired-by-amazon/" data-editable="true" data-title="Angel.ai, a company that builds chat bots, acqui-hired by Amazon | TechCrunch"&gt;Angel.ai, a company that builds chat bots, acqui-hired by Amazon | TechCrunch&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;TechCrunch报道称，继api.ai被google收购之后，一家做自然语言理解的公司angel.ai也几乎被Amazon收购。&lt;/p&gt;&lt;h1&gt;广告时间&lt;/h1&gt;&lt;p&gt;PaperWeekly是一个分享知识和交流学问的民间组织，关注的领域是NLP的各个方向。如果你也经常读paper，也喜欢分享知识，也喜欢和大家一起讨论和学习的话，请速速来加入我们吧。&lt;/p&gt;&lt;p&gt;微信公众号：PaperWeekly&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-ea9f4f4503d2ed9e15a56fe56e26e98d.jpg" data-rawwidth="430" data-rawheight="430"&gt;微博账号：PaperWeekly（&lt;a href="http://weibo.com/u/2678093863" data-editable="true" data-title="PaperWeekly的微博" class=""&gt;PaperWeekly的微博&lt;/a&gt; ）每天都会分享当天arXiv cs.CL板块刷新的高质量paper&lt;/p&gt;&lt;p&gt;知乎专栏：PaperWeekly（&lt;a href="https://zhuanlan.zhihu.com/paperweekly" data-editable="true" data-title="PaperWeekly - 知乎专栏"&gt;PaperWeekly - 知乎专栏&lt;/a&gt; ）微信交流群：微信+ zhangjun168305（请备注：加群 or 加入paperweekly）&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/22602959&amp;pixel&amp;useReferer"/&gt;</description><author>张俊</author><pubDate>Sat, 24 Sep 2016 11:51:43 GMT</pubDate></item><item><title>PaperWeekly 第六期------机器阅读理解</title><link>https://zhuanlan.zhihu.com/p/22577648</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-ea9f4f4503d2ed9e15a56fe56e26e98d_r.jpg"&gt;&lt;/p&gt;&lt;h1&gt;引&lt;/h1&gt;&lt;p&gt;本期paperweekly的主题是Question Answering Models，解决这一类问题可以很好地展现AI理解人类自然语言的能力，通过解决此类dataset可以给AI理解人类语言很好的insights。问题的定义大致是，给定较长一段话的context和一个较短的问题，以及一些candidate answers，训练一些可以准确预测正确答案的模型。&lt;/p&gt;&lt;p&gt;此问题也存在一些变种，例如context可以是非常大块的knowledge base，可以不提供candidate answers而是在所有的vocabulary中搜索答案，或者是在context中提取答案。&lt;/p&gt;&lt;p&gt;基于(Recurrent) Neural Network的一些模型在这一类问题上给出了state of the art models，本期paperweekly就带领大家欣赏这一领域有趣的工作。&lt;/p&gt;&lt;h1&gt;&lt;a href="https://arxiv.org/abs/1607.04423" data-editable="true" data-title="Attention-over-Attention Neural Networks for Reading Comprehension" class=""&gt;Attention-over-Attention Neural Networks for Reading Comprehension&lt;/a&gt;&lt;/h1&gt;&lt;h2&gt;作者&lt;/h2&gt;&lt;p&gt;Yiming Cui, Zhipeng Chen, Si Wei, Shijin Wang, Ting Liu and Guoping Hu&lt;/p&gt;&lt;h2&gt;单位&lt;/h2&gt;&lt;p&gt;iFLYTEK Research, ChinaResearch Center for Social Computing and Information Retrieval, Harbin Institute of Technology, China&lt;/p&gt;&lt;h2&gt;关键词&lt;/h2&gt;&lt;p&gt;Question Answering, Attentive Readers&lt;/p&gt;&lt;h2&gt;来源&lt;/h2&gt;&lt;p&gt;arXiv, 201608&lt;/p&gt;&lt;h2&gt;问题&lt;/h2&gt;&lt;p&gt;本文优化了attention机制，同时apply question-to-document and document-to-question attention，提升了已有模型在Cloze-Style Question Answering Task上的准确率。&lt;/p&gt;&lt;h2&gt;模型&lt;/h2&gt;&lt;p&gt;本文解决的是Cloze-style question answering的问题，给定一个Document和一个Query，以及一个list的candidate answers，模型需要给出一个正确答案。&lt;/p&gt;&lt;p&gt;已有的模型大都通过比较每一个Query + candidate answer和context document的相似性来找出正确答案，这种相似性measure大都通过把query 投射到context document每个单词及所在context的相似性来获得。本文的不同之处在于模型还计算了context投射到每个query单词的相似度，进一步丰富了context和query相似度的计算。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-af08e8e9fb96b8ae0927bdc4f6b2ea8c.png" data-rawwidth="694" data-rawheight="482"&gt;&lt;/p&gt;&lt;p&gt;首先，document和query都会被model成biGRU。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-854674cf407253946e97d634e72803a4.png" data-rawwidth="468" data-rawheight="153"&gt;&lt;/p&gt;&lt;p&gt;然后使用document biGRU和query biGRU的每一个position做inner product计算，可以得到一个similarity matrix。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-293c440a77d4023981ba9375ac3d7d28.png" data-rawwidth="356" data-rawheight="58"&gt;&lt;/p&gt;&lt;p&gt;对这个matrix做一个column-wise softmax，可以得到每个query单词在每个document单词上的similarity。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-1e3f420c54d62e837a00253fe5a892d2.png" data-rawwidth="450" data-rawheight="97"&gt;&lt;/p&gt;&lt;p&gt;similarly，对这个matrix做一个row-wise softmax，可以得到每个document单词在每个query单词上的similarity。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-59b0db8160a066f9049c8da726f94fc5.png" data-rawwidth="508" data-rawheight="78"&gt;&lt;/p&gt;&lt;p&gt;取个平均就得到了每个query单词在整个context document上的similarity。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-256ea139cfabd3b6d4ca824916a352c2.png" data-rawwidth="187" data-rawheight="89"&gt;&lt;/p&gt;&lt;p&gt;然后把alpha和beta做个inner product就得到了每个context document word的probability。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-1f2f0e78e26abe31b627ed55a78b5fef.png" data-rawwidth="206" data-rawheight="62"&gt;&lt;/p&gt;&lt;p&gt;每个candidate answer的probability就是它出现在上述s中的probability之和。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-0b0e8959a461212fd2ccde576250d151.png" data-rawwidth="285" data-rawheight="79"&gt;&lt;/p&gt;&lt;p&gt;Loss Function可以定义为正确答案的log probability之和。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-6794ef52d8e7d4bb716707baacddb1a1.png" data-rawwidth="225" data-rawheight="57"&gt;&lt;/p&gt;&lt;h2&gt;资源&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="https://github.com/deepmind/rc-data" data-editable="true" data-title="cnn和daily mail datasets"&gt;cnn和daily mail datasets&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://research.facebook.com/research/babi/" data-editable="true" data-title="Children’s book test"&gt;Children’s book test&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;相关工作&lt;/h2&gt;&lt;p&gt;利用attentive readers解决question answering问题最早出自deep mind: teaching machines to read and comprehend。后来又有Bhuwan Dhingra: Gated-Attention Readers for Text Comprehension和Danqi Chen: A Thorough Examination of the CNN/Daily Mail Reading Comprehension Task，以及其他相关工作，在此不一一赘述。&lt;/p&gt;&lt;h2&gt;简评&lt;/h2&gt;&lt;p&gt;本文很好地完善了attentive reader的工作，同时考虑了query to document and document to query attentions，在几个data set上都取得了state of the art效果，思路非常清晰，在question answering问题上很有参考价值。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://120.52.73.76/arxiv.org/pdf/1608.07905v1.pdf" data-editable="true" data-title="MACHINE COMPREHENSION USING MATCH-LSTM AND ANSWER POINTER"&gt;MACHINE COMPREHENSION USING MATCH-LSTM AND ANSWER POINTER&lt;/a&gt;&lt;/h1&gt;&lt;h2&gt;作者&lt;/h2&gt;&lt;p&gt;Shuohang Wang, Jing Jiang&lt;/p&gt;&lt;h2&gt;单位&lt;/h2&gt;&lt;p&gt;Singapore Management University&lt;/p&gt;&lt;h2&gt;关键词&lt;/h2&gt;&lt;p&gt;Machine comprehension, Match-LSTM, Pointer Net&lt;/p&gt;&lt;h2&gt;来源&lt;/h2&gt;&lt;p&gt;arXiv，201608&lt;/p&gt;&lt;h2&gt;问题&lt;/h2&gt;&lt;p&gt;提出一种结合match-LSTM和Pointer Net的端到端神经网络结构，来解决SQuAD数据集这类没有候选项且答案可能是多个词的machine comprehension问题。&lt;/p&gt;&lt;h2&gt;模型&lt;/h2&gt;&lt;p&gt;本文提出的模型结合了match-LSTM(mLSTM)和Pointer Net(Ptr-Net)两种网络结构。&lt;/p&gt;&lt;p&gt;1、match-LSTM&lt;/p&gt;&lt;p&gt;mLSTM是由Wang和Jiang提出的一种解决文本蕴含识别（RTE）问题的一种神经网络结构。模型结构见下图，该模型首先将premise和hypothesis两句话分别输入到两个LSTM中，用对应LSTM的隐层输出作为premise和hypothesis中每个位置对应上下文信息的一种表示（分别对应图中的Hs和Ht）。对于hypothesis中的某个词的表示ht_i，与premise中的每个词的表示Hs计算得到一个权重向量，然后再对premise中的词表示进行加权求和，得到hti对应的上下文向量a_i（attention过程）。最后把hypothesis中该词的表示ht_i和其对应的context向量a_i拼接在一起，输入到一个新的LSTM中。该模型将两个句子的文本蕴含任务拆分成词和短语级别的蕴含识别，因此可以更好地识别词之间的匹配关系。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-721234392c72ee01ab06f67edf1b6318.png" data-rawwidth="1156" data-rawheight="520"&gt;&lt;/p&gt;&lt;p&gt;2、 Pointer networks&lt;/p&gt;&lt;p&gt;该模型与基于attention的生成模型类似。区别之处在于，pointer networks生成的结果都在输入序列中，因此pointer networks可以直接将attention得到的align向量中的每个权重直接作为预测下一个词对应的概率值。&lt;/p&gt;&lt;p&gt;3、 Sequence Model &amp;amp; Boundary Model&lt;/p&gt;&lt;p&gt;本文提出的模型结构见下图，具体到本文的神经网络结构，可以简单分为下面两部分：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-dad87a89d1400f1b400bbc2361c780fb.png" data-rawwidth="1513" data-rawheight="840"&gt;（1）Match-LSTM层：该部分将machine comprehension任务中的question作为premise，而passage作为hypothesis。直接套用上述的mLSTM模型得到关于passage每个位置的一种表示。为了将前后方向的上下文信息全部编码进来，还用相同的方法得到一个反向mLSTM表示，将两个正反方向的表示拼接在一起作为最终passage的表示。&lt;/p&gt;&lt;p&gt;（2）生成答案序列部分，论文中提出了两种生成方法：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Sequence方法与Pointer Net相同，即根据每一个时刻attention的align向量生成一个词位置，直到生成终止符为止。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Boundary方法则是利用SQuAD数据集的答案均是出现在passage中连续的序列这一特点，该方法仅生成首尾两个位置，依据起始位置和终止位置来截取passage的一部分作为最终的答案。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;本文在SQuAD数据集上进行实验，两种方法实验结果较之传统LR方法均有大幅度提升。其中Boundary方法比Sequence方法效果更好。&lt;/p&gt;&lt;h2&gt;资源&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="https://rajpurkar.github.io/SQuAD-explorer/" data-editable="true" data-title="SQuAD"&gt;SQuAD&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;相关工作&lt;/h2&gt;&lt;p&gt;数据集相关论文SQuAD: 100,000+ Questions for Machine Comprehension of Text模型相关论文Learning Natural Language Inference with LSTMPointer networks&lt;/p&gt;&lt;h2&gt;简评&lt;/h2&gt;&lt;p&gt;本篇论文提出的模型是第一个在SQuAD语料上应用端到端神经网络的模型，该模型将Match-LSTM和Pointer Networks结合在一起，利用了文本之间的蕴含关系更好地预测答案。本文提出了两种方法来生成答案，其中Boundary方法巧妙地利用SQuAD数据集的答案均是文本中出现过的连续序列这一特点，只生成答案的起始和终止位置，有效地提升了模型的效果。&lt;/p&gt;&lt;h1&gt;&lt;a href="https://arxiv.org/pdf/1607.06275v2.pdf" data-editable="true" data-title="Dataset and Neural Recurrent Sequence Labeling Model for Open-Domain Factoid Question Answering" class=""&gt;Dataset and Neural Recurrent Sequence Labeling Model for Open-Domain Factoid Question Answering&lt;/a&gt;&lt;/h1&gt;&lt;h2&gt;作者&lt;/h2&gt;&lt;p&gt;Peng Li, Wei Li, Zhengyan He, Xuguang Wang, Ying Cao, Jie Zhou, Wei Xu&lt;/p&gt;&lt;h2&gt;单位&lt;/h2&gt;&lt;p&gt;Baidu IDL&lt;/p&gt;&lt;h2&gt;关键词&lt;/h2&gt;&lt;p&gt;Question Answering, Sequence Labeling, CRF&lt;/p&gt;&lt;h2&gt;来源&lt;/h2&gt;&lt;p&gt;arXiv, 201609&lt;/p&gt;&lt;h2&gt;问题&lt;/h2&gt;&lt;p&gt;作者给出了一个新的中文的QA数据集, 并且提出了一个非常有意思的baseline model.&lt;/p&gt;&lt;h2&gt;模型&lt;/h2&gt;&lt;p&gt;1、WebQA Dataset&lt;/p&gt;&lt;p&gt;作者来自百度IDL, 他们利用百度知道和一些其他的资源, 构建了这个中文的QA数据集. 这个数据集里所有的问题都是factoid类型的问题, 并且问题的答案都只包含一个entity (但是一个entity可能会包含多个单词). 对于每个问题, 数据集提供了若干个’evidence’, 这些evidence是利用搜索引擎在网络中检索的.&lt;/p&gt;&lt;p&gt;2、Recurrent Sequence Labeling Model&lt;/p&gt;&lt;p&gt;作者把QA类型的问题看做sequence labeling问题, 给出的模型大概分三部分:&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-4382b4020263b01609342f3b296e46ad.png" data-rawwidth="741" data-rawheight="385"&gt;&lt;/p&gt;&lt;p&gt;（1）Question LSTM这部分很简单, 就是普通的单向LSTM, 对整个Question sequence进行encoding, 之后计算self-attention, 并用attention对question encoding求加权平均作为问题的representation.&lt;/p&gt;&lt;p&gt;（2）Evidence LSTMs这部分比较有意思, 首先, 作者从数据中提取出两种feature: 每个词是否在question和evidence中共同出现, 以及每个词是否同时在多个evidence中出现. 之后, 模型用一个三层的单向LSTM对evidence/quesiton/feature进行编码.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;第一层: 将evidence/question representation/feature进行连接, 放进一个正向LSTM.&lt;/li&gt;&lt;li&gt;第二层: 将第一层的结果放入一个反向LSTM.&lt;/li&gt;&lt;li&gt;第三层: 将第一层和第二层的结果进行连接, 放进一个正向LSTM.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;（3）CRF经过evidence LSTMs, question和evidence的representation已经揉在一起, 所以并不需要其他QA模型(主要是Attention Sum Reader)广泛用的, 用question representation和story representation进行dot product, 求cosine similarity. 这时候只需要对evidence representation的每一个time step进行分类就可以了, 这也是为什么作者将数据标注成IOB tagging的格式, 我们可以直接用一个CRF层对数据进行预测. 在一些实验中, 作者将答案之前的词用O1, 答案之后的词用O2进行标注, 这又给了模型关于非答案词的位置信息(正确答案是在这个词的前面还是后面).&lt;/p&gt;&lt;h2&gt;资源&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="http://idl.baidu.com/webqa.html" data-editable="true" data-title="WebQA dataset"&gt;WebQA dataset&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://github.com/baidu/Paddle" data-editable="true" data-title="Baidu Paddle"&gt;Baidu Paddle&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;相关工作&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;关于CRF进行序列标注的问题, 可以参考这篇文章.Zhiheng Huang, Wei Xu, and Kai Yu. 2015. Bidirectional LSTM-CRF models for sequence tagging. arXiv:1508.01991v1.&lt;/li&gt;&lt;li&gt;关于multi-word答案选择在SQuAD dataset上的模型, 可以参考这篇.Shuohang Wang, Jing Jiang. 2016. Machine Comprehension Using Match_LSTM and Answer Pointer. arXiv: 1608.07905v1.&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;简评&lt;/h2&gt;&lt;p&gt;首先对所有release数据集的人表示感谢.关于dataset部分, 百度利用了自己庞大的资源收集数据. 第一, 百度知道里的问题都是人类问的问题, 这一点相比于今年前半年比较流行的CNN/CBT等等cloze style的问题, 要强很多. 第二, 数据集中包含了很多由多个词组成的答案, 这也使数据集的难度大于CNN/CBT这种单个词作为答案的数据. 第三, 对于每个问题, 并没有给出备选答案, 这使得对于答案的搜索空间变大(可以把整个evidence看做是备选答案). 第四, 对于每一个问题, dataset中可能有多个supporting evidence, 这也迎合了最近multi-supporting story的趋势, 因为对于有些问题, 答案并不只在某一个单一的文章中(对于百度来说, 如果搜索一个问题, 那么答案并不一定在单一的搜索结果网页中), 那么一个好的model需要在有限的时间内对尽可能多的搜索结果进行检索.&lt;/p&gt;&lt;p&gt;关于model部分, 本文尝试将QA问题看做是序列标注问题, 某种意义上解决了multiword answer的难点. 熟悉前半年QA paper的人都会对Attention Sum Reader以及延伸出来的诸多模型比较熟悉, 由于用了类似Pointer Network的机制, 一般的模型只能从文中选择story和question的cosine similarity最高的词作为答案, 这使得multiple word answer很难处理, 尤其是当multiple answer word不连续的时候, 更难处理. 而CRF是大家都熟知的简单高效的序列标注工具, 把它做成可训练的, 并且放在end to end模型中, 看起来是非常实用的. 在Evidence LSTM的部分, 加入的两个feature据作者说非常有帮助, 看起来在deep learning 模型中加入一些精心设计的feature, 或者IR的要素, 有可能能够对模型的performance给予一定的提升. 在entropy的角度, 虽然不一定是entropy reduction, 因为这些信息其实本来已经包含在question/evidence中了, 但是有可能因为你提供给模型这些信息, 它就可以把更多精力用在一些其他的特征上?&lt;/p&gt;&lt;p&gt;另外值得一提的是, 最近Singapore Management University的Wang and Jiang也有所突破, 在SQuAD dataset(也是multiple word answer)上一度取得了state of the art的结果, 他们用的mLSTM模型也十分有趣.&lt;/p&gt;&lt;h1&gt;总结&lt;/h1&gt;&lt;p&gt;这一类model都大量使用了Recurrent Neural Network(LSTM或者GRU)对text进行encoding，得到一个sequence的hidden state vector。然后通过inner product或者bilinear term比较不同位置hidden state vector之间的similarity来计算它们是正确答案的可能性。可见Recurrent Neural Network以及对于Similarity的定义依旧是解决此类问题的关键所在，更好地改良这一类模型也是提升准确率的主流方法。笔者认为，similarity的计算给了模型从原文中搜索答案的能力，然而模型非常缺乏的是推理和思考的能力（其实也有相关工作&lt;a href="http://arxiv.org/abs/1508.05508" data-editable="true" data-title="Towards Neural Network-based Reasoning"&gt;Towards Neural Network-based Reasoning&lt;/a&gt;），如果模型能够配备逻辑思考能力，那么解决问题的能力会大大增强。非常期待有新的思路能够出现在这一领域中，令AI能够更好地理解人类语言。&lt;/p&gt;&lt;p&gt;以上为本期PaperWeekly的主要内容，感谢&lt;strong&gt;eric yuan&lt;/strong&gt;、&lt;strong&gt;destinwang&lt;/strong&gt;、&lt;strong&gt;zewei chu&lt;/strong&gt;、&lt;strong&gt;韩晓伟&lt;/strong&gt;四位同学的整理。 &lt;/p&gt;&lt;h1&gt;广告时间&lt;/h1&gt;&lt;p&gt;PaperWeekly是一个分享知识和交流学问的民间组织，关注的领域是NLP的各个方向。如果你也经常读paper，也喜欢分享知识，也喜欢和大家一起讨论和学习的话，请速速来加入我们吧。&lt;/p&gt;&lt;p&gt;微信公众号：PaperWeekly&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-ea9f4f4503d2ed9e15a56fe56e26e98d.jpg" data-rawwidth="430" data-rawheight="430"&gt;&lt;/p&gt;&lt;p&gt;微博账号：PaperWeekly（&lt;a href="http://weibo.com/u/2678093863" data-editable="true" data-title="PaperWeekly的微博"&gt;PaperWeekly的微博&lt;/a&gt; ）知乎专栏：PaperWeekly（&lt;a href="https://zhuanlan.zhihu.com/paperweekly" data-editable="true" data-title="PaperWeekly - 知乎专栏"&gt;PaperWeekly - 知乎专栏&lt;/a&gt; ）微信交流群：微信+ zhangjun168305（请备注：加群 or 加入paperweekly）&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/22577648&amp;pixel&amp;useReferer"/&gt;</description><author>张俊</author><pubDate>Fri, 23 Sep 2016 09:30:09 GMT</pubDate></item><item><title>cs.CL weekly 2016.09.12-2016.09.16</title><link>https://zhuanlan.zhihu.com/p/22471808</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/ea9f4f4503d2ed9e15a56fe56e26e98d_r.jpg"&gt;&lt;/p&gt;&lt;p&gt;本周（2016.09.12-2016.09.16）质量较高的arXiv cs.CL的paper如下：（点击标题可看原文）&lt;/p&gt;&lt;h1&gt;&lt;a href="http://120.52.73.75/arxiv.org/pdf/1609.02846v1.pdf" data-editable="true" data-title="Dialogue manager domain adaptation using Gaussian process reinforcement learning" class=""&gt;Dialogue manager domain adaptation using Gaussian process reinforcement learning&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;本文是Steve Young组的一篇大作，文中详细介绍了Gaussian process reinforcement learning框架的思路和优势，并且在多个对话领域中进行了实验并得到更好的结果。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://120.52.73.79/arxiv.org/pdf/1609.02745v1.pdf" data-editable="true" data-title="A Hierarchical Model of Reviews for Aspect-based Sentiment Analysis" class=""&gt;A Hierarchical Model of Reviews for Aspect-based Sentiment Analysis&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;本文提出用分层双向LSTM模型对网站评论数据进行观点挖掘，发表在EMNLP 2016。该作者今天在arxiv上提交了三篇同类问题不同解决方案的paper，对评论观点和情感挖掘的童鞋可作参考。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://120.52.73.79/arxiv.org/pdf/1609.03286v1.pdf" data-editable="true" data-title="Knowledge as a Teacher: Knowledge-Guided Structural Attention Networks" class=""&gt;Knowledge as a Teacher: Knowledge-Guided Structural Attention Networks&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;本文提出了用先验知识+attention network的模型，用来解决了自然语言理解存在问题：通过从少量训练数据中捕获重要子结构，来缓解测试集中的unseen data问题，同时提高理解能力。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://120.52.73.79/arxiv.org/pdf/1609.03193v2.pdf" data-editable="true" data-title="Wav2Letter: an End-to-End ConvNet-based Speech Recognition System"&gt;Wav2Letter: an End-to-End ConvNet-based Speech Recognition System&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;本文提出了一种语音识别的端到端模型，基于CNN和graph decoding，在不依赖因素对齐的前提下，输出letters。本文工作来自Facebook AI。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://120.52.73.78/arxiv.org/pdf/1609.03976v1.pdf" data-editable="true" data-title="Multimodal Attention for Neural Machine Translation"&gt;Multimodal Attention for Neural Machine Translation&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;本文通过利用image caption的多模态、多语言数据构建了一个NMT模型，模型的输入不仅是source language，还有所描述的图像，输出是target language。通过输入更多的信息，得到了更好的效果。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://120.52.73.78/arxiv.org/pdf/1609.03632v1.pdf" data-editable="true" data-title="Joint Extraction of Events and Entities within a Document Context"&gt;Joint Extraction of Events and Entities within a Document Context&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;本文针对传统信息抽取方法将event和entity分开考虑的问题，提出了在docuemnt-level context下考虑event和entity之间关系进行信息抽取的新方法，取得了非常好的结果。本文发表在NAACL2016.&lt;/p&gt;&lt;h1&gt;&lt;a href="http://120.52.73.75/arxiv.org/pdf/1609.03777v1.pdf" data-editable="true" data-title="Character-Level Language Modeling with Hierarchical Recurrent Neural Networks" class=""&gt;Character-Level Language Modeling with Hierarchical Recurrent Neural Networks&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;语言模型问题上，char-level可以很好地解决OOV的问题，但效果不如word-level，本文针对该问题提出了一种分层模型，同时兼顾word-level和char-level的优势。本文发表在nips2016。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://120.52.73.78/arxiv.org/pdf/1609.04186v1.pdf" data-editable="true" data-title="Neural Machine Translation with Supervised Attention" class=""&gt;Neural Machine Translation with Supervised Attention&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;attention机制可以动态地对齐source和target words，但准确率不如传统方法。本文提出了用传统方法作为teacher，来“教”model学习alignment，模型称为supervised attention。本文已投稿COLING2016，在审。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://120.52.73.76/arxiv.org/pdf/1609.04309v1.pdf" data-editable="true" data-title="Efficient softmax approximation for GPUs" class=""&gt;Efficient softmax approximation for GPUs&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;本文提出了一种高效的softmax近似方法，并且可以方便地进行并行计算。本文称之为adaptive softmax，根据词分布进行聚类，极大地提高了计算效率并保证了不错的准确率。本文工作来自Facebook AI Research。&lt;/p&gt;&lt;p&gt;在自然语言生成任务中常常面临word vocabulary size太大的困境，softmax的效率非常低，本文给出了一种快速计算的方法。Tomas Mikolov之前也提到过类似的思路。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://120.52.73.78/arxiv.org/pdf/1609.04779v1.pdf" data-editable="true" data-title="Characterizing the Language of Online Communities and its Relation to Community Reception"&gt;Characterizing the Language of Online Communities and its Relation to Community Reception&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;本文研究了在线社区语言的style和topic哪个更具代表性，这里style用复合语言模型来表示，topic用LDA来表示，通过Reddit Forum实验得到style比topic更有代表性。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://120.52.73.79/arxiv.org/pdf/1609.04621v1.pdf" data-editable="true" data-title="Factored Neural Machine Translation"&gt;Factored Neural Machine Translation&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;针对机器翻译领域中两个常见的问题：1、目标语言词汇表过大；2、OOV问题；利用了单词的词形和语法分解，提出了一种新的NMT模型，并取得了满意的效果。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://120.52.73.78/arxiv.org/pdf/1609.04628v1.pdf" data-editable="true" data-title="Context Aware Nonnegative Matrix Factorization Clustering"&gt;Context Aware Nonnegative Matrix Factorization Clustering&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;大多数paper都在研究NMF在聚类中的初始化和优化部分，而本文关注的点在于最后的聚类分配上。本文被 ICPR 2016全文收录。&lt;/p&gt;&lt;p&gt;以下内容为arXiv外的优质内容：&lt;/p&gt;&lt;h1&gt;&lt;a href="http://www.sigdial.org/workshops/conference17/proceedings/SIGDIAL-2016.pdf" data-editable="true" data-title="SIGDIAL 2016 Accepted Paper"&gt;SIGDIAL 2016 Accepted Paper&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;SIGdial是ACL下面的一个关于对话系统地特别兴趣小组，每年开一次会。今年的会议最近正在开，会议录用的所有paper都已经放出。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://speech.sv.cmu.edu/software.html" data-editable="true" data-title="CMU SPEECH Team Homepage" class=""&gt;CMU SPEECH Team Homepage&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;CMU SPEECH Team的主页，包括他们的开源软件Yoda和publication及其开源实现。&lt;/p&gt;&lt;h1&gt;&lt;a href="https://www.reddit.com/r/MachineLearning/comments/4zcyvk/machine_learning_wayr_what_are_you_reading_week_6/?st=ISZ6YT6D&amp;amp;sh=02bd0722" data-editable="true" data-title="Machine Learning - WAYR (What Are You Reading)" class=""&gt;Machine Learning - WAYR (What Are You Reading)&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;reddit上的这个帖子很有意思，和paperweekly想做的一个事情非常像，就是可以让读类似或者同一篇paper的童鞋得到充分交流。&lt;/p&gt;&lt;h1&gt;广告时间&lt;/h1&gt;&lt;p&gt;PaperWeekly是一个分享知识和交流学问的民间组织，关注的领域是NLP的各个方向。如果你也经常读paper，也喜欢分享知识，也喜欢和大家一起讨论和学习的话，请速速来加入我们吧。&lt;/p&gt;&lt;p&gt;微信公众号：PaperWeekly微博账号：PaperWeekly（&lt;a href="http://weibo.com/u/2678093863" data-editable="true" data-title="PaperWeekly的微博"&gt;PaperWeekly的微博&lt;/a&gt; ）每天都会分享当天arXiv cs.CL板块刷新的高质量paper知乎专栏：PaperWeekly（&lt;a href="https://zhuanlan.zhihu.com/paperweekly" data-editable="true" data-title="PaperWeekly - 知乎专栏"&gt;PaperWeekly - 知乎专栏&lt;/a&gt; ）微信交流群：微信+ zhangjun168305（请备注：加群 or 加入paperweekly）&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/22471808&amp;pixel&amp;useReferer"/&gt;</description><author>张俊</author><pubDate>Sat, 17 Sep 2016 08:28:05 GMT</pubDate></item><item><title>PaperWeekly 第五期------从Word2Vec到FastText</title><link>https://zhuanlan.zhihu.com/p/22466665</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/ded3556dca46e452ac525a5b7beecf3c_r.png"&gt;&lt;/p&gt;&lt;h1&gt;引&lt;/h1&gt;&lt;p&gt;Word2Vec从提出至今，已经成为了深度学习在自然语言处理中的基础部件，大大小小、形形色色的DL模型在表示词、短语、句子、段落等文本要素时都需要用word2vec来做word-level的embedding。Word2Vec的作者Tomas Mikolov是一位产出多篇高质量paper的学者，从RNNLM、Word2Vec再到最近流行的FastText都与他息息相关。一个人对同一个问题的研究可能会持续很多年，而每一年的研究成果都可能会给同行带来新的启发，本期的PaperWeekly将会分享其中三篇代表作，分别是：&lt;/p&gt;&lt;p&gt;1、Efficient Estimation of Word Representation in Vector Space, 20132、Distributed Representations of Sentences and Documents, 20143、Enriching Word Vectors with Subword Information, 2016&lt;/p&gt;&lt;h1&gt;&lt;a href="https://arxiv.org/pdf/1301.3781.pdf" data-editable="true" data-title="Efficient Estimation of Word Representation in Vector Space" class=""&gt;Efficient Estimation of Word Representation in Vector Space&lt;/a&gt;&lt;/h1&gt;&lt;h2&gt;作者&lt;/h2&gt;&lt;p&gt;Tomas Mikolov, Kai Chen, Greg Corrado, Jeffrey Dean&lt;/p&gt;&lt;h2&gt;单位&lt;/h2&gt;&lt;p&gt;Google Inc., Mountain View, CA&lt;/p&gt;&lt;h2&gt;关键词&lt;/h2&gt;&lt;p&gt;Word Representation, Word Embedding, Neural Network, Syntactic Similarity, and Semantic Similarity&lt;/p&gt;&lt;h2&gt;来源&lt;/h2&gt;&lt;p&gt;arXiv, 201309&lt;/p&gt;&lt;h2&gt;问题&lt;/h2&gt;&lt;p&gt;如何在一个大型数据集上快速、准确地学习出词表示？&lt;/p&gt;&lt;h2&gt;模型&lt;/h2&gt;&lt;p&gt;传统的NNLM模型包含四层，即输入层、映射层、隐含层和输出层，计算复杂度很大程度上依赖于映射层到隐含层之间的计算，而且需要指定上下文的长度。RNNLM模型被提出用来改进NNLM模型，去掉了映射层，只有输入层、隐含层和输出层，计算复杂度来源于上一层的隐含层到下一层隐含层之间的计算。&lt;/p&gt;&lt;p&gt;本文提出的两个模型CBOW (Continuous Bag-of-Words Model)和Skip-gram (Continuous Skip-gram Model)结合了上面两个模型的特点，都是只有三层，即输入层、映射层和输出层。CBOW模型与NNLM模型类似，用上下文的词向量作为输入，映射层在所有的词间共享，输出层为一个分类器，目标是使当前词的概率最大。Skip-gram模型与CBOW的输入跟输出恰好相反，输入层为当前词向量，输出层是使得上下文的预测概率最大，如下图所示。训练采用SGD。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/3b94982780b22466c499eaff3e04df65.jpg" data-rawwidth="362" data-rawheight="223"&gt;&lt;/p&gt;&lt;h2&gt;资源&lt;/h2&gt;&lt;p&gt;Code: &lt;a href="https://code.google.com/archive/p/word2vec/" data-editable="true" data-title="C++代码"&gt;C++代码&lt;/a&gt;Dataset: &lt;a href="https://sites.google.com/site/semeval2012task2/" data-editable="true" data-title="SemEval-2012"&gt;SemEval-2012&lt;/a&gt;,用来评估语义相关性。&lt;/p&gt;&lt;h2&gt;相关工作&lt;/h2&gt;&lt;p&gt;Bengio[1]在2003年就提出了language model的思路，同样是三层（输入层，隐含层和输出层）用上下文的词向量来预测中间词，但是计算复杂度较高，对于较大的数据集运行效率低；实验中也发现将上下文的n-gram出现的频率结合进去会提高性能，这个优点体现在CBOW和Skip-gram模型的输出层中，用hierarchical softmax（with huffman trees）来计算词概率。&lt;/p&gt;&lt;h2&gt;简评&lt;/h2&gt;&lt;p&gt;本文的实验结果显示CBOW比NNLM在syntactic和semantic上的预测都要好，而Skip-gram在semantic上的性能要优于CBOW，但是其计算速度要低于CBOW。结果显示用较大的数据集和较少的epoch，可以取得较好的效果，并且在速度上有所提升。与LSI和LDA相比，word2vec利用了词的上下文，语义信息更加丰富。基于word2vec，出现了phrase2vec, sentence2vec和doc2vec，仿佛一下子进入了embedding的世界。NLP的这些思想也在用于recommendation等方面，并且与image结合，将image跟text之间进行转换。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://120.52.73.76/arxiv.org/pdf/1405.4053v2.pdf" data-editable="true" data-title="Distributed Representations of Sentences and Documents" class=""&gt;Distributed Representations of Sentences and Documents&lt;/a&gt;&lt;/h1&gt;&lt;h2&gt;作者&lt;/h2&gt;&lt;p&gt;Quoc V. Le, Tomas Mikolov&lt;/p&gt;&lt;h2&gt;单位&lt;/h2&gt;&lt;p&gt;Google Inc, Mountain View, CA&lt;/p&gt;&lt;h2&gt;关键词&lt;/h2&gt;&lt;p&gt;sentence representation&lt;/p&gt;&lt;h2&gt;来源&lt;/h2&gt;&lt;p&gt;ICML 2014&lt;/p&gt;&lt;h2&gt;问题&lt;/h2&gt;&lt;p&gt;基于word2vec的思路，如何表示sentence和document？&lt;/p&gt;&lt;h2&gt;模型&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/c6dac075c8ed2bb00718673967777bb1.jpg" data-rawwidth="418" data-rawheight="245"&gt;&lt;/h2&gt;&lt;p&gt;利用one-hot的表示方法作为网络的输入，乘以词矩阵W，然后将得到的每个向量通过平均或者拼接的方法得到整个句子的表示，最后根据任务要求做一分类，而这过程中得到的W就是词向量矩阵，基本上还是word2vec的思路。&lt;/p&gt;&lt;p&gt;接下来是段落的向量表示方法：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/ef7668051ab7f574ab1e41a0f8d3f0eb.jpg" data-rawwidth="400" data-rawheight="225"&gt;依旧是相同的方法，只是在这里加上了一个段落矩阵，用以表示每个段落，当这些词输入第i个段落时，通过段落id就可以从这个矩阵中得到相对应的段落表示方法。需要说明的是，在相同的段落中，段落的表示是相同的。文中这样表示的动机就是段落矩阵D可以作为一个memory记住在词的context中遗失的东西，相当于增加了一个额外的信息。这样经过训练之后，我们的就得到了段落表示D，当然这个段落就可以是一段或者一篇文章。&lt;/p&gt;&lt;p&gt;最后一种就是没有词序的段落向量表示方法：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/a9781307fe0c25097e3674bc72d6d372.jpg" data-rawwidth="400" data-rawheight="261"&gt;从图中就可以感觉到这个方法明显和skip-gram非常相似，这里只是把重点放在了段落的表示中，通过段落的表示，来预测相应的context 词的表示。最后我们依然可以得到段落矩阵D，这样就可以对段落进行向量化表示了。但是输入起码是句子级别的表示，而输出则是词的向量表示，因此个人比较怀疑这种方法的合理性。&lt;/p&gt;&lt;h2&gt;简评&lt;/h2&gt;&lt;p&gt;这篇文章是word2vec的方法提出一年后提出的方法，因此本文并没有使用目前非常流行的word2vec的训练方法来训练词向量，而是利用word2vec的思路，提出了一种更加简单的网络结构来训练任意长度的文本表示方法。这样一方面好训练，另一方面减少了参数，避免模型过拟合。优点就是在训练paragraph vector的时候加入了一个paragraph matrix，这样在训练过程中保留了一部分段落或者文档信息。这点在目前看来也是有一定优势的。但是目前深度学习发展迅速，可以处理非常大的计算量，同时word2vec以及其变种被应用得非常普遍，因此该文章提出的方法思路大于模型，思路我们可以借鉴，模型就不具有优势了。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://120.52.73.80/arxiv.org/pdf/1607.04606v1.pdf" data-editable="true" data-title="Enriching Word Vectors with Subword Information"&gt;Enriching Word Vectors with Subword Information&lt;/a&gt;&lt;/h1&gt;&lt;h2&gt;作者&lt;/h2&gt;&lt;p&gt;Piotr Bojanowski, Edouard Grave, Armand Joulin, Tomas Mikolov&lt;/p&gt;&lt;h2&gt;单位&lt;/h2&gt;&lt;p&gt;Facebook AI Research&lt;/p&gt;&lt;h2&gt;关键词&lt;/h2&gt;&lt;p&gt;Word embedding, morphological, character n-gram&lt;/p&gt;&lt;h2&gt;来源&lt;/h2&gt;&lt;p&gt;arXiv, 201607&lt;/p&gt;&lt;h2&gt;问题&lt;/h2&gt;&lt;p&gt;如何解决word2vec方法中罕见词效果不佳的问题，以及如何提升词形态丰富语言的性能？&lt;/p&gt;&lt;h2&gt;模型&lt;/h2&gt;&lt;p&gt;word2vec在词汇建模方面产生了巨大的贡献，然而其依赖于大量的文本数据进行学习，如果一个word出现次数较少那么学到的vector质量也不理想。针对这一问题作者提出使用subword信息来弥补这一问题，简单来说就是通过词缀的vector来表示词。比如unofficial是个低频词，其数据量不足以训练出高质量的vector，但是可以通过un+official这两个高频的词缀学习到不错的vector。&lt;/p&gt;&lt;p&gt;方法上，本文沿用了word2vec的skip-gram模型，主要区别体现在特征上。word2vec使用word作为最基本的单位，即通过中心词预测其上下文中的其他词汇。而subword model使用字母n-gram作为单位，本文n取值为3~6。这样每个词汇就可以表示成一串字母n-gram，一个词的embedding表示为其所有n-gram的和。这样我们训练也从用中心词的embedding预测目标词，转变成用中心词的n-gram embedding预测目标词。&lt;/p&gt;&lt;p&gt;实验分为三个部分，分别是（1）计算两个词之间的语义相似度，与人类标注的相似度进行相关性比较；（2）与word2vec一样的词类比实验；（3）与其他考虑morphology的方法比较。结果是本文方法在语言形态丰富的语言（土耳其语，法语等）及小数据集上表现优异，与预期一致。&lt;/p&gt;&lt;h2&gt;资源&lt;/h2&gt;&lt;p&gt;源码公布在Facebook的fastText项目中：&lt;a href="https://github.com/facebookresearch/fastText" data-editable="true" data-title="GitHub - facebookresearch/fastText: Library for fast text representation and classification."&gt;GitHub - facebookresearch/fastText: Library for fast text representation and classification.&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;相关工作&lt;/h2&gt;&lt;p&gt;利用语言形态学来改进nlp的研究源远流长，本文提及的许多关于character-level和morphology的有趣工作值得参考。&lt;/p&gt;&lt;h2&gt;简评&lt;/h2&gt;&lt;p&gt;文章中提出的思路对于morphologically rich languages（例如土耳其语，词缀的使用极为普遍而有趣）来说十分有意义。词缀作为字母与单词之间的中层单位，本身具有一定的语义信息。通过充分利用这种中层语义来表征罕见词汇，直观上讲思路十分合理，也是应用了compositionality的思想。&lt;/p&gt;&lt;p&gt;利用形态学改进word embedding的工作十分丰富，但中文NLP似乎很难利用这一思路。其实个人感觉中文中也有类似于词缀的单位，比如偏旁部首等等，只不过不像使用字母系统的语言那样容易处理。期待今后也有闪光的工作出现在中文环境中。&lt;/p&gt;&lt;h1&gt;总结&lt;/h1&gt;&lt;p&gt;从Word2Vec到FastText，从word representation到sentence classification，Tomas Mikolov的工作影响了很多人。虽然有个别模型和实验结果曾遭受质疑，但终究瑕不掩瑜。word2vec对NLP的研究起到了极大地推动作用，其实不仅仅是在NLP领域中，在其他很多领域中都可以看到word2vec的思想和作用，也正是从word2vec开始，这个世界变得都被vector化了，person2vec，sentence2vec，paragraph2vec，anything2vec，world2vec。&lt;/p&gt;&lt;p&gt;以上为本期Paperweekly的主要内容，感谢memray、zhkun、gcyydxf、jell四位同学的整理。&lt;/p&gt;&lt;h1&gt;广告时间&lt;/h1&gt;&lt;p&gt;PaperWeekly是一个分享知识和交流学问的民间组织，关注的领域是NLP的各个方向。如果你也经常读paper，也喜欢分享知识，也喜欢和大家一起讨论和学习的话，请速速来加入我们吧。&lt;/p&gt;&lt;p&gt;微信公众号：PaperWeekly&lt;p&gt;http://weixin.qq.com/r/OUW0rA3ExVC6rUnP9xAr (二维码自动识别)&lt;/p&gt;微博账号：PaperWeekly（&lt;a href="http://weibo.com/u/2678093863" data-editable="true" data-title="PaperWeekly的微博"&gt;PaperWeekly的微博&lt;/a&gt; ）知乎专栏：PaperWeekly（&lt;a href="https://zhuanlan.zhihu.com/paperweekly" data-editable="true" data-title="PaperWeekly - 知乎专栏"&gt;PaperWeekly - 知乎专栏&lt;/a&gt; ）微信交流群：微信+ zhangjun168305（请备注：加群 or 加入paperweekly）&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/22466665&amp;pixel&amp;useReferer"/&gt;</description><author>张俊</author><pubDate>Fri, 16 Sep 2016 12:49:32 GMT</pubDate></item><item><title>cs.CL weekly 2016.09.05-2016.09.09</title><link>https://zhuanlan.zhihu.com/p/22390774</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/ea9f4f4503d2ed9e15a56fe56e26e98d_r.jpg"&gt;&lt;/p&gt;&lt;p&gt;本周（2016.09.05-2016.09.09）质量较高的arXiv cs.CL的paper如下：（点击标题可看原文）&lt;/p&gt;&lt;h1&gt;&lt;a href="http://120.52.73.79/arxiv.org/pdf/1609.00718v1.pdf" data-editable="true" data-title="Convolutional Neural Networks for Text Categorization: Shallow Word-level vs. Deep Character-level" class=""&gt;Convolutional Neural Networks for Text Categorization: Shallow Word-level vs. Deep Character-level&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;张潼老师的文章，通过实验对比了shallow word-level CNN（本文工作）和deep char-level CNN模型在而文本分类任务上的表现，结论是本文工作又快又准。&lt;/p&gt;&lt;p&gt;（这篇文章对于选择char-level还是word-level做文本分类非常有指导意义）&lt;/p&gt;&lt;h1&gt;&lt;a href="http://120.52.73.78/arxiv.org/pdf/1609.00565v1.pdf" data-editable="true" data-title="Skipping Word: A Character-Sequential Representation based Framework for Question Answering" class=""&gt;Skipping Word: A Character-Sequential Representation based Framework for Question Answering&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;本文用char-level CNN模型来做句子表示，然后进行question和answer之间的相关匹配学习，CIKM2016 short paper accepted。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://120.52.73.78/arxiv.org/pdf/1609.00777v1.pdf" data-editable="true" data-title="End-to-End Reinforcement Learning of Dialogue Agents for Information Access"&gt;End-to-End Reinforcement Learning of Dialogue Agents for Information Access&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;本文是微软研究软邓力老师的文章，构建了一种从知识图谱中形成response的聊天机器人KB-InfoBot，并且提出了一种端到端的增强学习训练方案。&lt;/p&gt;&lt;p&gt;（本文对于构建一个端到端的KB + task-oriented chatbot非常有启发和指导意义）&lt;/p&gt;&lt;h1&gt;&lt;a href="http://120.52.73.79/arxiv.org/pdf/1609.01462v1.pdf" data-editable="true" data-title="Joint Online Spoken Language Understanding and Language Modeling with Recurrent Neural Networks"&gt;Joint Online Spoken Language Understanding and Language Modeling with Recurrent Neural Networks&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;本文提出一种模型，将intent detection、slot filling和language modeling融合在一起进行学习，用于解决对话系统中的SLU task。本文是SIGDIAL 2016 paper。&lt;/p&gt;&lt;p&gt;用到的数据集在Dropbox有一份&lt;a href="http://t.cn/Rcbcpfl" data-editable="true" data-title="copy"&gt;copy&lt;/a&gt;&lt;/p&gt;&lt;h1&gt;&lt;a href="http://120.52.73.79/arxiv.org/pdf/1609.01454v1.pdf" data-editable="true" data-title="Attention-Based Recurrent Neural Network Models for Joint Intent Detection and Slot Filling"&gt;Attention-Based Recurrent Neural Network Models for Joint Intent Detection and Slot Filling&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;和上一篇paper是同一个作者，解决的是同一个问题。将RNN换成了attention-based RNN，被另外一个会议录取。(有点灌水的意思)&lt;/p&gt;&lt;h1&gt;&lt;a href="http://120.52.73.77/arxiv.org/pdf/1609.02116v1.pdf" data-editable="true" data-title="Ask the GRU: Multi-task Learning for Deep Text Recommendations" class=""&gt;Ask the GRU: Multi-task Learning for Deep Text Recommendations&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;本文提出了用端到端的解决方案来做paper的推荐任务，用GRU将文本序列（标题、摘要等）encode到一个latent vector中。并且通过多任务学习来完成内容推荐和条目预测两个task，取得了不错的效果。&lt;/p&gt;&lt;p&gt;&lt;b&gt;以下内容为arXiv外的优质内容：&lt;/b&gt;&lt;/p&gt;&lt;h1&gt;&lt;a href="http://www.matthen.com/research/papers/Discriminative_Methods_for_Statistical_Spoken_Dialogue_Systems_Matthew_Henderson_PhD_Thesis.pdf" data-editable="true" data-title="Discriminative Methods for Statistical Spoken Dialogue Systems" class=""&gt;Discriminative Methods for Statistical Spoken Dialogue Systems&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;剑桥大学Spoken Dialogue System组毕业的Matthew Henderson博士，师从于Steve Young教授，研究领域是对话系统中的Dialogue State Tracking，主要特色是用transfer learning来解决discriminative model的扩展性和通用性。&lt;/p&gt;&lt;p&gt;如果你对chatbot感兴趣，强烈建议好好研读一下这篇博士论文。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://cs.stanford.edu/people/karpathy/main.pdf" data-editable="true" data-title="CONNECTING IMAGES AND NATURAL LANGUAGE" class=""&gt;CONNECTING IMAGES AND NATURAL LANGUAGE&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;斯坦福大学Feifei Li的博士生Andrej Karpathy的PhD thesis，Karpathy维护着几个非常流行的开源代码库，并且有着一个影响力非常大的博客。名师出高徒，这篇博士博士论文值得一看！&lt;/p&gt;&lt;p&gt;最近，他更新了一篇博客，谈论了一些自己对读博的思考和建议。 &lt;a href="http://karpathy.github.io/2016/09/07/phd/" data-editable="true" data-title="A Survival Guide to a PhD"&gt;A Survival Guide to a PhD&lt;/a&gt;&lt;/p&gt;&lt;h1&gt;&lt;a href="https://pan.baidu.com/share/link?shareid=317480&amp;amp;uk=1594817379" data-editable="true" data-title="Mendeley Docs"&gt;Mendeley Docs&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;paper越看越多，一个优秀的paper管理工具就变得非常必要了，Mendeley是其中最优秀的代表之一。&lt;/p&gt;&lt;p&gt;Easily organize your papers, read &amp;amp; annotate your PDFs, collaborate in private or open groups, and securely access your research from everywhere.&lt;/p&gt;&lt;h1&gt;广告时间&lt;/h1&gt;&lt;p&gt;PaperWeekly是一个分享知识和交流学问的民间组织，关注的领域是NLP的各个方向。如果你也经常读paper，也喜欢分享知识，也喜欢和大家一起讨论和学习的话，请速速来加入我们吧。&lt;/p&gt;&lt;p&gt;微信公众号：PaperWeekly&lt;p&gt;http://weixin.qq.com/r/OUW0rA3ExVC6rUnP9xAr (二维码自动识别)&lt;/p&gt;&lt;/p&gt;&lt;p&gt;微博账号：PaperWeekly（&lt;a href="http://weibo.com/u/2678093863" data-editable="true" data-title="PaperWeekly的微博"&gt;PaperWeekly的微博&lt;/a&gt; ）知乎专栏：PaperWeekly（&lt;a href="https://zhuanlan.zhihu.com/paperweekly" data-editable="true" data-title="PaperWeekly - 知乎专栏"&gt;PaperWeekly - 知乎专栏&lt;/a&gt; ）微信交流群：微信+ zhangjun168305（请备注：加群 or 加入paperweekly）&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/22390774&amp;pixel&amp;useReferer"/&gt;</description><author>张俊</author><pubDate>Sat, 10 Sep 2016 13:06:12 GMT</pubDate></item><item><title>PaperWeekly第四期------基于强化学习的文本生成技术</title><link>https://zhuanlan.zhihu.com/p/22385421</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/e230b2395dd90e3491d83701bc3ec152_r.jpg"&gt;&lt;/p&gt;&lt;h1&gt;引&lt;/h1&gt;&lt;p&gt;2013年以来Deep mind团队相继在NIPS和Natures上发表了用深度增强（强化）学习玩Atari游戏，并取得良好的效果，随后Alpha go与李世乭的一战更使得深度增强学习家喻户晓。在游戏上取得了不错的成果后，深度增强学习也逐渐被引入NLP领域。本期介绍目前NLP领域较为热点的研究方向，基于强化学习的文本生成技术（NLG），共选择了三篇文章，分别为：&lt;/p&gt;&lt;p&gt;(1)《Generating Text with Deep Reinforcement Learning》应用Deep Q-Network作为生成模型用于改善seq2seq模型&lt;/p&gt;&lt;p&gt;(2) 《Deep Reinforcement Learning for Dialogue Generation》应用强化学习进行开放领域的文本生成任务，并对比了有监督的seq2seq加attention模型和基于最大互信息的模型&lt;/p&gt;&lt;p&gt;(3)《Hierarchical Reinforcement Learning for Adaptive Text Generation_lshowway》以任务为导向的户内导航对话系统用分层强化学习进行文本生成&lt;/p&gt;&lt;p&gt;以下为三篇文章的主要信息：&lt;/p&gt;&lt;h1&gt;&lt;a href="http://120.52.73.76/arxiv.org/pdf/1510.09202v1.pdf" data-editable="true" data-title="Generating Text with Deep Reinforcement Learning"&gt;Generating Text with Deep Reinforcement Learning&lt;/a&gt;&lt;/h1&gt;&lt;h2&gt;作者&lt;/h2&gt;&lt;p&gt;Hongyu Guo&lt;/p&gt;&lt;h2&gt;单位&lt;/h2&gt;&lt;p&gt;National Research Council Canada&lt;/p&gt;&lt;h2&gt;关键词&lt;/h2&gt;&lt;p&gt;Reinforcement Learning、Seq2Seq、Text Generation&lt;/p&gt;&lt;h2&gt;来源&lt;/h2&gt;&lt;p&gt;NIPS2015 Workshop (2015.10.30)&lt;/p&gt;&lt;h2&gt;问题&lt;/h2&gt;&lt;p&gt;本文提出将Deep Q-Network作为生成模型用于改善seq2seq模型，将decoding修改为迭代式的过程，实验表明本模型具有更好的泛化性。&lt;/p&gt;&lt;h2&gt;模型&lt;/h2&gt;&lt;p&gt;对seq2seq模型改进的论文层出不穷，本文率先引入深度强化学习的思想，将DQN用于文本生成。对DQN还不了解的同学可以先阅读DeepMind的论文Playing Atari with Deep Reinforcement Learning。本文的模型如下：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/eeb5b40e85d79a6db4d937aa37924be0.jpg" data-rawwidth="445" data-rawheight="251"&gt;&lt;/p&gt;&lt;p&gt;如同一般的神经网络，我们也可以把DQN当做一个黑盒来使用。只需要准备好DQN需要的四个元素s(i),a(i),r(i),s(i+1)，分别代表i时刻下state,action,reword和i+1时刻的state。&lt;/p&gt;&lt;p&gt;对照上图我们把算法解剖分为4个步骤：&lt;/p&gt;&lt;p&gt;Step 1: 先是传统的seq2seq模型。通过LSTM先把输入序列encode为一个定长向量EnSen(i)，然后作为decode阶段的初始状态依次生成新的序列DeSen(i)（decoding search使用beam search算法来 expand next words）。经过第一步我们得到初始state：(EnSen(i), DeSen(i))和action集合：每个位置的hypotheses。&lt;/p&gt;&lt;p&gt;Step 2: 接下来从hypotheses（actions）中选择一个可以获得最大reward的单词（action）作为该位置新生成的词，用新单词来代替之前的旧词，于是生成新的state：(EnSen(i), DeSen(i+1))。&lt;/p&gt;&lt;p&gt;Step 3: 接着就是标准的DQN的部分，计算Loss函数并对其应用梯度下降。&lt;/p&gt;&lt;p&gt;Step 4: 回到Step 2，对得到的state继续迭代，每一次迭代都只生成一个新词来代替旧词，直到迭代次数达到设好的值（作者将次数定为句子长度的两倍，同学们可以思考一下理由）。&lt;/p&gt;&lt;p&gt;总结DQN所需的四个元素对应如下：(1) i时刻下的state：(EnSen(i), DeSen(i))；(2) i时刻下的action：beam search得到的每个位置的hypotheses；(3) i时刻下的reword：target sentence和DeSen(i+1)的相似度（BLEU score）；(4) i+1时刻下的state：(EnSen(i), DeSen(i+1))；&lt;/p&gt;&lt;p&gt;为了更好的提取句子的特征，作者在decode阶段使用了双向LSTM。同时还在reinforcement learning中加入attention机制，可以达到先decode比较简单的部分再处理困难部分的效果。最后在生成相似句子的实验中得到了比只用LSTM decoder效果更好的结论：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/5d92477453549f38a825cf8a09fd27c3.jpg" data-rawwidth="591" data-rawheight="78"&gt;&lt;/p&gt;&lt;h2&gt;相关工作&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/1533d7282033cfba05652bf1d4f6541e.jpg" data-rawwidth="529" data-rawheight="139"&gt;&lt;/h2&gt;&lt;h2&gt;简评&lt;/h2&gt;&lt;p&gt;本文的思想其实非常符合写作的一种情况，就像贾岛推敲的故事，回想小时候刚学习写句子时，也不能一次写好，总会不断对一些词语进行修改。Google DeepMind的文章《DRAW：A Recurrent Neural Network For Image》也和本文异曲同工：画画也不是一次画好，也要不断的完善。不同之处在于本文率先引入DQN做文本生成。在机器学习各个分支下，强化学习和人类与环境的交互方式非常相似，在许多领域开始初露头角，期待看到更多将强化学习结合语言模型的应用。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://120.52.73.76/arxiv.org/pdf/1606.01541v3.pdf" data-editable="true" data-title="Deep Reinforcement Learning for Dialogue Generation" class=""&gt;Deep Reinforcement Learning for Dialogue Generation&lt;/a&gt;&lt;/h1&gt;&lt;h2&gt;作者&lt;/h2&gt;&lt;p&gt;Jiwei Li, Will Monroe, Alan Ritter, Michel Galley, Jianfeng Gao, Dan Jurafsky&lt;/p&gt;&lt;h2&gt;单位&lt;/h2&gt;&lt;p&gt;(1) Stanford University, Stanford, CA, USA(2) Microsoft Research, Redmond, WA, USA(3) Ohio State University, OH, USA&lt;/p&gt;&lt;h2&gt;关键词&lt;/h2&gt;&lt;p&gt;Reinforcement Learning、Seq2Seq、Text Generation&lt;/p&gt;&lt;h2&gt;来源&lt;/h2&gt;&lt;p&gt;arXiv.org(2016.06.25)&lt;/p&gt;&lt;h2&gt;问题&lt;/h2&gt;&lt;p&gt;本文提出利用强化学习进行开放领域的文本生成任务，并对比了有监督的seq2seq加attention模型和基于最大互信息的模型&lt;/p&gt;&lt;h2&gt;模型&lt;/h2&gt;&lt;p&gt;强化学习中的reward&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/41a37779955dd98c73489e7ae6462786.jpg" data-rawwidth="418" data-rawheight="67"&gt;&lt;/p&gt;&lt;p&gt;易被响应（Ease of answering），不容易出现对话僵局，其中 S 是无意义回答合集，s是某一时刻的响应&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/8a4cd62898e6529a1081adf455ec209b.jpg" data-rawwidth="498" data-rawheight="74"&gt;&lt;/p&gt;&lt;p&gt;信息流，若开辟新的话题，有利于对话的继续发展，隐层表示 hpi 和 hpi+1 的夹角余弦&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/d4cb3c510958387b995d38389603a7ab.jpg" data-rawwidth="470" data-rawheight="60"&gt;&lt;/p&gt;&lt;p&gt;语义连贯性，减少与对话无关问题的影响，其中，pseq2seq(a|pi,qi) 是由上一轮状态得到响应的概率，后一项是由当前产生响应通过网络生成之前的 qi 的概率。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/796302276156e6dab686864c3cdde67c.jpg" data-rawwidth="471" data-rawheight="55"&gt;&lt;/p&gt;&lt;p&gt;最终的reward是对三者加权求和，系数分别为：0.25、0.25、0.5.&lt;/p&gt;&lt;p&gt;对比试验：(1) 对话初始状态为一个SEQ2SEQ加attention的模型作为强化学习的初始状态。&lt;/p&gt;&lt;p&gt;(2) 在前面的基础上将最大互信息加入其中作为reward，对于一个给定的输入[pi,qi]，可以根据模型生成一个候选回答集合A。对于A中的每一个回答a,从预训练模型中得到的概率分布上可以计算出互信息的值 m(a,[pi,qi])。&lt;/p&gt;&lt;p&gt;(3) 将互信息训练过的模型作为初始模型，用策略梯度更新参数并加入课程学习策略，最终最多限定五轮对话。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/e230b2395dd90e3491d83701bc3ec152.jpg" data-rawwidth="537" data-rawheight="273"&gt;&lt;/p&gt;&lt;h2&gt;相关工作&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/fbf89747e22b3dde78fded6cb406f50e.jpg" data-rawwidth="618" data-rawheight="199"&gt;&lt;/h2&gt;&lt;h2&gt;简评&lt;/h2&gt;&lt;p&gt;本文作者提出了一个强化学习框架，模拟两个agent让其自动对话训练神经网络SEQ2SEQ模型，将Encoder-Decoder模型和强化学习整合，从而能保证使对话轮数增加。文中使用的模型非常简洁，reward函数定义清晰，评价指标也较为科学，可以生成信息更为丰富、易于响应的对话系统。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://www.aclweb.org/anthology/W10-4204" data-editable="true" data-title="Hierarchical Reinforcement Learning for Adaptive Text Generation"&gt;Hierarchical Reinforcement Learning for Adaptive Text Generation&lt;/a&gt;&lt;/h1&gt;&lt;h2&gt;作者&lt;/h2&gt;&lt;p&gt;Nina Dethlefs, Heriberto Cuay´ahuitl&lt;/p&gt;&lt;h2&gt;单位&lt;/h2&gt;&lt;p&gt;University of Bremen, Germany&lt;/p&gt;&lt;h2&gt;关键词&lt;/h2&gt;&lt;p&gt;NLG, 分层强化学习, 文本生成, wayfinding&lt;/p&gt;&lt;h2&gt;来源&lt;/h2&gt;&lt;p&gt;国际自然语言生成会议INLG(2010)&lt;/p&gt;&lt;h2&gt;问题&lt;/h2&gt;&lt;p&gt;在wayfinding（户内导航对话系统）领域利用分层强化学习进行文本生成。该方法的目标是对wayfinding的NLG任务整合进行优化，并在模拟系统中验证该方法的有效性。&lt;/p&gt;&lt;h2&gt;模型&lt;/h2&gt;&lt;p&gt;本文任务在wayfinding中的NLG任务有多个，且各个任务之间并非独立。从而提出应该根据用户类型，导航距离， 环境条件等作出不同的导航策略，介绍了分层强化学习。&lt;/p&gt;&lt;p&gt;文章将户内导航对话系统的文本生成问题分为四块：&lt;/p&gt;&lt;p&gt;(1) Content Selection：给不熟悉环境的用户的导航要比熟悉环境的用户的导航更细致(2) Text Structure：根据导航距离以及用户熟悉环境程度给予不同类型的导航，如大白话的，以fisrt， second…表达或者示意性的。(3) Referring Expression Generation：一间房间可以叫“A203”，也可以叫“办公室”或者“小白楼”(4) Surface Realisation：往前走可以用“go”也可以用“walk”等。&lt;/p&gt;&lt;p&gt;强化学习示意图如下，分层强化学习的思想与强化学习类似，但在强化学习的基础上加上层次，不同层次的模型处理不同层次的问题。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/84608ba0f6e25f6920b55839fdf3e5ec.jpg" data-rawwidth="275" data-rawheight="187"&gt;&lt;/p&gt;&lt;p&gt;agent根据当前状态，执行动作a与环境交互，之后环境产生一个新的状态s并返回给agent一个奖赏r（可正可负），强化学习的目标函数便是使agent获得奖赏r最大。&lt;/p&gt;&lt;p&gt;分层增强学习包含L个层，每层N个模型，如Figure 1是有15个agents的hierarchy，其中不同的agent负责不同的层次。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/5a8fb2547d568b1efa67b691486a5e87.jpg" data-rawwidth="491" data-rawheight="201"&gt;&lt;/p&gt;&lt;p&gt;每个agent定义为半马尔科夫决策过程，可以表示成一个四元组&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/7d2f305f56718569b40425f4ebea7db7.jpg" data-rawwidth="135" data-rawheight="30"&gt;&lt;/p&gt;&lt;p&gt;分别为状态集，动作集，转换函数，奖励函数。&lt;/p&gt;&lt;p&gt;奖励函数表示agent在时间t状态s是执行动作a转换到新的状态s’所获得的奖励。半马尔科夫的目标是找到policy π*，&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/e7fdd4b0397777e5d2ca885814ed9031.jpg" data-rawwidth="269" data-rawheight="54"&gt;&lt;/p&gt;&lt;p&gt;使得在从当前状态转换到新的状态获得的累计奖励最多。&lt;/p&gt;&lt;p&gt;本文使用两种奖励函数，一种着重在 interaction length， 另一种着重在alignment and variation之间的平衡（具体公式可见论文）。&lt;/p&gt;&lt;p&gt;本文是在模拟环境中进行试验，其中模拟环境包括user type（熟悉环境，不熟悉环境）， information need（高，低），length of the current route（短，中长，长），next action to perform（转，直走），current focus of attention（继续走，关注标识）。baseline为为部分agent随机选择action，即不考虑用户类型，导航距离等因素。经与baseline比较，效果较好。&lt;/p&gt;&lt;h2&gt;资源&lt;/h2&gt;&lt;p&gt;词性标注工具：&lt;a href="http://nlp.stanford.edu/software/tagger.shtml" data-editable="true" data-title="The Stanford Natural Language Processing Group" class=""&gt;The Stanford Natural Language Processing Group&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;简评&lt;/h2&gt;&lt;p&gt;将来的工作：将分层强化学习应用于其他NLG任务不足之处：实验是在模拟环境下进行的，未来应该在真实环境进行评估。&lt;/p&gt;&lt;h1&gt;总结&lt;/h1&gt;&lt;p&gt;这三篇文章皆是强化学习在NLP领域的应用，第一篇主要侧重点在于应用DQN进行文本生成，并用BLUE指标进行评价，对比传统的LSTM-decoder和加入DQN之后的结果；第二篇文章侧重点在于虚拟两个Agent，在传统Seq2Seq的基础上加入强化学习从而使得聊天能够持续下去；第三篇文章侧重点在于任务驱动的对话系统应用分层强化学习，针对不同情况进行分层处理。&lt;/p&gt;&lt;p&gt;以上为本期Paperweekly的主要内容，感谢lshowway、美好时光海苔、Tonya三位同学的整理。&lt;/p&gt;&lt;h1&gt;广告时间&lt;/h1&gt;&lt;p&gt;PaperWeekly是一个分享知识和交流学问的民间组织，关注的领域是NLP的各个方向。如果你也经常读paper，也喜欢分享知识，也喜欢和大家一起讨论和学习的话，请速速来加入我们吧。&lt;/p&gt;&lt;p&gt;微信公众号：PaperWeekly&lt;p&gt;http://weixin.qq.com/r/OUW0rA3ExVC6rUnP9xAr (二维码自动识别)&lt;/p&gt;&lt;/p&gt;&lt;p&gt;微博账号：PaperWeekly（&lt;a href="http://weibo.com/u/2678093863" data-editable="true" data-title="PaperWeekly的微博"&gt;PaperWeekly的微博&lt;/a&gt; ）知乎专栏：PaperWeekly（&lt;a href="https://zhuanlan.zhihu.com/paperweekly" data-editable="true" data-title="PaperWeekly - 知乎专栏"&gt;PaperWeekly - 知乎专栏&lt;/a&gt; ）微信交流群：微信+ zhangjun168305（请备注：加群 or 加入paperweekly）&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/22385421&amp;pixel&amp;useReferer"/&gt;</description><author>张俊</author><pubDate>Fri, 09 Sep 2016 21:34:21 GMT</pubDate></item><item><title>cs.CL weekly 2016.08.29-2016.09.02</title><link>https://zhuanlan.zhihu.com/p/22293954</link><description>&lt;p&gt;本周（2016.08.29-2016.09.02）质量较高的arXiv cs.CL的paper如下：（点击标题可看原文）&lt;/p&gt;&lt;h1&gt;&lt;a href="http://120.52.73.75/arxiv.org/pdf/1602.06023v5.pdf" data-editable="true" data-title="Abstractive Text Summarization Using Sequence-to-Sequence RNNs and Beyond" class=""&gt;Abstractive Text Summarization Using Sequence-to-Sequence RNNs and Beyond&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;一篇老文的update，seq2seq+attention的机制来解决abstractive text summarization，针对文本摘要的关键问题在基础模型中增加了对关键词、词句层次性和低频词的处理。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://120.52.73.76/arxiv.org/pdf/1608.07905v1.pdf" data-editable="true" data-title="Machine Comprehension Using Match-LSTM and Answer Pointer" class=""&gt;Machine Comprehension Using Match-LSTM and Answer Pointer&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;本文基于Match-LSTM和Answer Pointer两个模型在Stanford Question Answering Dataset (SQuAD)上得到了state-of-the-art的结果。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://120.52.73.75/arxiv.org/pdf/1608.08716v1.pdf" data-editable="true" data-title="Measuring Machine Intelligence Through Visual Question Answering"&gt;Measuring Machine Intelligence Through Visual Question Answering&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;本文指出了image caption作为评测AI效果的任务存在的缺陷，同时提出用visual QA作为评测任务更加有效，并且给出了一个大型Visual QA的数据集。数据集地址：&lt;a href="http://www.visualqa.org" data-editable="true" data-title="VQA: Visual Question Answering"&gt;VQA: Visual Question Answering&lt;/a&gt;.&lt;/p&gt;&lt;h1&gt;&lt;a href="http://120.52.73.79/arxiv.org/pdf/1609.00070v1.pdf" data-editable="true" data-title="How Much is 131 Million Dollars? Putting Numbers in Perspective with Compositional Descriptions" class=""&gt;How Much is 131 Million Dollars? Putting Numbers in Perspective with Compositional Descriptions&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;文章提出了一个好玩的任务，以一个统计数字作为上下文来生成一段简短的描述，描述的内容是一种带有这个数字的观点。整个过程分为两步：公式的构建和观点的生成。&lt;/p&gt;&lt;h1&gt;广告时间&lt;/h1&gt;&lt;p&gt;PaperWeekly是一个分享知识和交流学问的民间组织，关注的领域是NLP的各个方向。如果你也经常读paper，也喜欢分享知识，也喜欢和大家一起讨论和学习的话，请速速来加入我们吧。&lt;/p&gt;&lt;p&gt;微信公众号：PaperWeekly&lt;p&gt;http://weixin.qq.com/r/OUW0rA3ExVC6rUnP9xAr (二维码自动识别)&lt;/p&gt;&lt;/p&gt;&lt;p&gt;微博账号：PaperWeekly（&lt;a href="http://weibo.com/u/2678093863" data-editable="true" data-title="PaperWeekly的微博"&gt;PaperWeekly的微博&lt;/a&gt; ），每天会发布arXiv cs.CL高质量paper和简评。知乎专栏：PaperWeekly（&lt;a href="https://zhuanlan.zhihu.com/paperweekly" data-editable="true" data-title="PaperWeekly - 知乎专栏"&gt;PaperWeekly - 知乎专栏&lt;/a&gt; ）微信交流群：微信+ zhangjun168305（请备注：加群 or 加入paperweekly）&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/22293954&amp;pixel&amp;useReferer"/&gt;</description><author>张俊</author><pubDate>Sat, 03 Sep 2016 11:49:16 GMT</pubDate></item><item><title>PaperWeekly 第三期</title><link>https://zhuanlan.zhihu.com/p/22279528</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/d89931bc502f2f7326b1aba605d4184e_r.png"&gt;&lt;/p&gt;&lt;h1&gt;引&lt;/h1&gt;&lt;p&gt;历经半个月时间终于发布了新一期PaperWeekly，大家久等了。在这个半个月里，PaperWeekly发生了一些明显的变化。维护和运营从我一个人变成了一个十人左右的团队来一起做，小伙伴们来自全球各地，颠倒着黑夜和白天进行沟通。团队中的每个人都有一颗热爱知识和分享知识的心，都认为分享是一种美德，是一种付出，更是一种回报。可能我们不完美，但我们相信我们正在追求完美的路上坚定地走着。&lt;/p&gt;&lt;p&gt;有了更多的同学加入，PaperWeekly会更加多元化，不再受限于我个人感兴趣的方向和阅读、写作习惯。PaperWeekly会坚持每周发布一期文章，每一期的文章尽量围绕同一个topic展开，在微信公众号、官方微博和知乎专栏会同步更新，除了这一篇文章，我们还会坚持在微博上提供一个新的服务，cs.CL daily，帮助大家过滤掉arXiv cs.CL上比较水的paper，留下质量高的paper，并且用简评的方式分享在微博上，每周末会更新一篇cs.CL weekly出来，将一周值得读的cs.CL paper汇总发布。&lt;/p&gt;&lt;p&gt;PaperWeekly组织了一个高质量的NLP讨论群，只要有你相关的问题，群里的高手会第一时间站出来解答或者讨论你的问题，有的时候会给出一些开源code和相关的paper，提问者、讨论者和潜水者都会有很大的收获。分享paper导读的意义在于讨论，大家一起来讨论，才能更加充分地吸收paper里的营养，这也是我为什么组织一个讨论群的原因。&lt;/p&gt;&lt;p&gt;寒暄的话就说到这里，本期分享的topic是ACL 2016，一共10篇文章，涉及的内容包括：Logic Form、NMT、Summarization、QA、Chatbot等。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://aclweb.org/anthology/P/P16/P16-1073.pdf" data-editable="true" data-title="Sentence Rewriting for Semantic Parsing" class=""&gt;Sentence Rewriting for Semantic Parsing&lt;/a&gt;&lt;/h1&gt;&lt;h2&gt;关键词&lt;/h2&gt;&lt;p&gt;Semantic Parsing、Sentence Rewriting&lt;/p&gt;&lt;h2&gt;来源&lt;/h2&gt;&lt;p&gt;ACL 2016&lt;/p&gt;&lt;h2&gt;问题&lt;/h2&gt;&lt;p&gt;语义分析的表现形式是将自然语言（natural language）转化成逻辑形式（logic form）。因语言表达多样性的问题导致两者间存在mismatch problem。&lt;/p&gt;&lt;h2&gt;文章思路&lt;/h2&gt;&lt;p&gt;先给出一个语义分析的例子：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/72e0e629eadcca4a8bb9a987b066057d.jpg" data-rawwidth="416" data-rawheight="224"&gt;&lt;/p&gt;&lt;p&gt;给句子换个表达（How many people live in Berlin?），对应的逻辑形式就变得复杂很多(count(λx.person(x)∧live(x,Berlin)))。&lt;/p&gt;&lt;p&gt;作者认为，原句子和逻辑形式之间存在的结构不匹配导致了语义分析的困难，而结构不匹配的核心是词汇的不匹配。作者率先提出先把句子重写再转成目标逻辑形式的语义分析方案，如下图：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/e164c5bb6c5fce0fcb9250105e6f3ab4.jpg" data-rawwidth="429" data-rawheight="152"&gt;&lt;/p&gt;&lt;p&gt;针对词汇不匹配问题的两种情况分别给出基于字典和基于模板两种方法。&lt;/p&gt;&lt;p&gt;1）问题一：1-N mismatch是指一个单词（word）对应一个复合的逻辑形式（compound formula）。&lt;/p&gt;&lt;p&gt;例如daughter对应 child ∩ female。但在开放域的知识体系下，制定这些规则十分困难。于是作者提出将句子中的常用名词替换为字典（Wiktionary）中的解释，比如先把刚才的daughter转换为female child，接着再转换为逻辑形式child ∩ female就十分自然了。&lt;/p&gt;&lt;p&gt;2）问题二：N-1 mismatch是指将复杂的自然语言表达对应为单个逻辑表达。&lt;/p&gt;&lt;p&gt;例如将How many people live in Berlin?转化为λx.population(Berlin,x)的分析过程中，How many people live in被对应为逻辑式常量population。如同问题一，这样的规则实在过多，作者的思路是将复杂的表达式转化为简单的形式。&lt;/p&gt;&lt;p&gt;沿用之前的句子来了解算法流程。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/6d59c63aedf120ee27d0b61d309bb890.jpg" data-rawwidth="432" data-rawheight="98"&gt;&lt;/p&gt;&lt;p&gt;Step 1 替换实体生成候选template，例如得到模板how many people live in #y。Step 2 检索template pairs来替换模板，例如找到(a：how many people live in #y, b：what is the population of #y)的模板对，于是将b作为新模板，Step 3 把实体替换回去得到容易生成逻辑形式的what is the population of Berlin。&lt;/p&gt;&lt;h2&gt;相关工作&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/b2e89a59bcd76d62bdf840dd3c6370b8.jpg" data-rawwidth="419" data-rawheight="184"&gt;&lt;/h2&gt;&lt;h2&gt;简评&lt;/h2&gt;&lt;p&gt;如今深度学习在自然语言处理领域大红大紫，也给语义分析的方法带来更多的思考。比如ACL2016另外一篇文章Language to Logical Form with Neural Attention，就把语义分析转换为seq2seq问题，进而使用深度学习的方法来解决。如果我们把词向量这样的表示形式比喻为粗糙的连结主义，那么逻辑表达就好比精细的形式主义。两者各有优势，希望以后会有更多结合两种思想的工作出现。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://aclweb.org/anthology/P/P16/P16-1004.pdf" data-editable="true" data-title="Language to Logical Form with Neural Attention" class=""&gt;Language to Logical Form with Neural Attention&lt;/a&gt;&lt;/h1&gt;&lt;h2&gt;关键词&lt;/h2&gt;&lt;p&gt;Logical Forms, Sequence to Sequence&lt;/p&gt;&lt;h2&gt;来源&lt;/h2&gt;&lt;p&gt;ACL 2016&lt;/p&gt;&lt;h2&gt;问题&lt;/h2&gt;&lt;p&gt;如何把自然语言转化成Structured Logical Forms？&lt;/p&gt;&lt;h2&gt;文章思路&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/2263e1dd44c4bf05b226d3c3b8c69205.jpg" data-rawwidth="353" data-rawheight="213"&gt;&lt;/h2&gt;&lt;p&gt;模型总体是一个encoder-decoder架构，input sequence首先通过LSTM encoder转化成一个vector，然后这个vector通过LSTM decoder被转化成Logical Forms。在decode过程中用到了一个attention layer去获取context信息。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/2bf99675c901b85453aac1c833562a75.jpg" data-rawwidth="306" data-rawheight="301"&gt;&lt;/p&gt;&lt;p&gt;和encoder-decoder模型类似，作者提出了一种hierarchical decoder。与普通的decoder不同，首先，decode之后的sequence中存在一个特殊字符代表nonterminal。在nonterminal的基础上，decoder可以继续进行下一个layer的decoding。每一次decoding的输入不仅包含current hidden state,还包含这一个parent nonterminal的hidden state。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/d125a2f36aa2cb05f32ddc3ab0bb6f84.jpg" data-rawwidth="279" data-rawheight="146"&gt;&lt;/p&gt;&lt;p&gt;作者还使用了一种attention机制，在构建current hidden state的时候将hidden state与所有encoder中的hidden state进行对比，给每一个encoder hidden state一个weight。&lt;/p&gt;&lt;h2&gt;资源&lt;/h2&gt;&lt;p&gt;代码：&lt;a href="https://github.com/donglixp/lang2logic" data-editable="true" data-title="GitHub - donglixp/lang2logic"&gt;GitHub - donglixp/lang2logic&lt;/a&gt;Jobs和GEO数据集：&lt;a href="http://www.cs.columbia.edu/~mcollins/papers/uai05.pdf"&gt;http://www.cs.columbia.edu/~mcollins/papers/uai05.pdf&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;相关工作&lt;/h2&gt;&lt;p&gt;之前的大部分工作都采用一些parsing models，string-to-tree transformation rules，文中没有提到之前有人采用seq2seq/deep learning的方法。本文中使用的seq2seq方法主要来自Kalchbrenner, Blunsom, Cho, Sutskever 在machine translation中提出的模型。&lt;/p&gt;&lt;h2&gt;简评&lt;/h2&gt;&lt;p&gt;本文解决的是一个非常有趣的问题，将自然语言转换成结构化的Logical Forms。试想如果此模型能够很好的解决这个问题，那么将来的各种query language甚至programming languages都可以由自然语言转换而成。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://aclweb.org/anthology/P/P16/P16-1046.pdf" data-editable="true" data-title="Neural Summarization by Extracting Sentences and Words" class=""&gt;Neural Summarization by Extracting Sentences and Words&lt;/a&gt;&lt;/h1&gt;&lt;h2&gt;关键词&lt;/h2&gt;&lt;p&gt;Summarization、Hierarchical Document Encoder、Attention-based Extractor&lt;/p&gt;&lt;h2&gt;来源&lt;/h2&gt;&lt;p&gt;ACL 2016&lt;/p&gt;&lt;h2&gt;问题&lt;/h2&gt;&lt;p&gt;如何使用数据驱动的方法来做提取式摘要？&lt;/p&gt;&lt;h2&gt;文章思路&lt;/h2&gt;&lt;p&gt;本文针对的任务分为sentence和word两个level的summarization。sentence level是一个序列标签问题，每个句子有0或1两个标签，为1表示需要提取该句作为总结。而word level则是一个限定词典规模下的生成问题，词典规模限定为原文档中所有出现的词。&lt;/p&gt;&lt;p&gt;使用的模型也比较有特点，首先在encoder端将document分为word和sentence来encode，word使用CNN encode得到句子表示，接着将句子表示输入RNN得到encoder端隐藏层状态。从word到sentence的encode体现了本文的hierarchical document encoder的概念。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/1dbf5b848521e79a7f0973c1c38095a6.jpg" data-rawwidth="252" data-rawheight="272"&gt;&lt;/p&gt;&lt;p&gt;在decoder端根据任务的不同使用不同网络结构，sentence任务就是一个简单的有监督下二分类问题，使用RNN网络结构更新decoder端隐藏层状态， decoder端隐藏层状态串联encoder端隐藏层状态后接入一个MLP层再接sigmoid激活函数得到句子是否被extract的概率。&lt;/p&gt;&lt;p&gt;word任务则是使用传统的attention-based的方法来计算每个词的概率。但要注意本文的计算的attention不是word-level attention，而是encoder端sentence-level attention。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/4ebfdd69dd0959c7efce04bf69faeb15.jpg" data-rawwidth="294" data-rawheight="199"&gt;&lt;/p&gt;&lt;h2&gt;资源&lt;/h2&gt;&lt;p&gt;数据集：&lt;a href="http://homepages.inf.ed.ac.uk/s1537177/resources.html" data-editable="true" data-title="Jianpeng Cheng" class=""&gt;Jianpeng Cheng&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;相关工作&lt;/h2&gt;&lt;p&gt;之前大多数extractive methods都基于human-engineered特征来给句子建模，通常会对每个句子计算一个分数，然后再使用诸如binary classifiers，hidden Markov模型，graph-based算法或integer linear programming等方法来选择句子构成总结。&lt;/p&gt;&lt;h2&gt;简评&lt;/h2&gt;&lt;p&gt;之前基于data-driven的seq2seq模型在abstractive summarization任务上大放异彩，本文提出了使用类似的模型来解决extractive summarization任务。不过针对的依旧是single-document summarization任务，未来需要将工作拓展至multi-document summarization任务上。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://aclweb.org/anthology/P/P16/P16-2008.pdf" data-editable="true" data-title="Sequence-to-Sequence Generation for Spoken Dialogue via Deep Syntax Trees and Strings" class=""&gt;Sequence-to-Sequence Generation for Spoken Dialogue via Deep Syntax Trees and Strings&lt;/a&gt;&lt;/h1&gt;&lt;h2&gt;关键词&lt;/h2&gt;&lt;p&gt;Sequence to Sequence、Natural Language Generation、Chatbot&lt;/p&gt;&lt;h2&gt;来源&lt;/h2&gt;&lt;p&gt;ACL 2016&lt;/p&gt;&lt;h2&gt;问题&lt;/h2&gt;&lt;p&gt;如何通过小规模、未对齐语料生成对话语句？&lt;/p&gt;&lt;h2&gt;文章思路&lt;/h2&gt;&lt;p&gt;作者介绍了两个模型:&lt;/p&gt;&lt;p&gt;1、通过DA(diglogue acts)生成句法依赖树，再利用external surface realizer，生成语句。（如下图）&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/c4f596e42d0cbe2564aaa449d0318f2c.jpg" data-rawwidth="300" data-rawheight="208"&gt;&lt;/p&gt;&lt;p&gt;2、将两部分结合起来，直接生成语句。步骤如下：&lt;/p&gt;&lt;p&gt;Step 1 将DA(dialogue acts)中的每个slot(表示特定信息)表示成三元组(DA type,slot,value)并结合(下图左)&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/d740d2ced18c5f2f9817074bf7fcb472.jpg" data-rawwidth="506" data-rawheight="105"&gt;&lt;/p&gt;&lt;p&gt;Step 2 基于seq2seq generation technique生出语句或句法依赖树。Step 3 结合beam search和n-best列表重排序（list reranker）以减少输出中的不相关信息。&lt;/p&gt;&lt;h2&gt;资源&lt;/h2&gt;&lt;p&gt;代码: &lt;a href="https://github.com/UFAL-DSG/tgen" data-editable="true" data-title="GitHub - UFAL-DSG/tgen: Statistical NLG for spoken dialogue systems" class=""&gt;GitHub - UFAL-DSG/tgen: Statistical NLG for spoken dialogue systems&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;相关工作&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/f46341b6203fae0cf1e8e493b2ea9b16.jpg" data-rawwidth="415" data-rawheight="189"&gt;&lt;/h2&gt;&lt;h2&gt;简评&lt;/h2&gt;&lt;p&gt;该方法基于广泛使用的seq2seq模型，可以用未对齐的MR对(pair of meaning representation)和句子进行训练，且只要小规模的语料就可以有很好的效果。生成器可以从数据中学会slot的对齐和值，生成流利的domain style)语句，虽然语义错误还是很频繁，但还是取得了不错的成绩。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://aclweb.org/anthology/P/P16/P16-1230.pdf" data-editable="true" data-title="On-line Active Reward Learning for Policy Optimisation in Spoken Dialogue Systems"&gt;On-line Active Reward Learning for Policy Optimisation in Spoken Dialogue Systems&lt;/a&gt;&lt;/h1&gt;&lt;h2&gt;关键词&lt;/h2&gt;&lt;p&gt;Dialogue System、Reinforcement Learning、Online Active Reward Learning&lt;/p&gt;&lt;h2&gt;来源&lt;/h2&gt;&lt;p&gt;ACL 2016&lt;/p&gt;&lt;h2&gt;问题&lt;/h2&gt;&lt;p&gt;文章提出一种在线学习框架，通过高斯过程分类模型进行主动学习，训练对话策略和奖励模型，减少数据标注的花费和用户反馈中的噪声。&lt;/p&gt;&lt;h2&gt;文章思路&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/fe153e783f983fa26d47572c287cf66a.jpg" data-rawwidth="415" data-rawheight="215"&gt;&lt;/h2&gt;&lt;p&gt;框架分为三部分：对话策略、对话嵌入函数、用户反馈主动奖励模型。&lt;/p&gt;&lt;p&gt;无监督学习输入为双向LSTM，通过Encoder-Decoder模型表征用户意图，将对话的成功与否看做高斯过程的一个二元分类问题，当模型对当前结果不能评判时，主动学习，通过reward模型决定是否询问用户反馈，当模型不确定时，生成增强信号来训练策略。&lt;/p&gt;&lt;h2&gt;资源&lt;/h2&gt;&lt;p&gt;数据集：&lt;a href="http://camdial.org/~mh521/dstc/" class=""&gt;http://camdial.org/~mh521/dstc/&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;相关工作&lt;/h2&gt;&lt;p&gt;1、之前的工作有用任务完成度和对话持续情况做Reward，但任务完成度不好衡量2、用协同过滤表征用户偏好3、用逆强化学习从行为中推出reward&lt;/p&gt;&lt;h2&gt;简评&lt;/h2&gt;&lt;p&gt;用lSTM Encoder-Decoder表征用户意图，无需大规模标注语料和构建用户模拟器来进行训练，在较小的训练语料中取得了不错的效果，率先实现了在真实场景中的应用。但Reward函数只关心对话任务是否成功，模型过于简单。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://aclweb.org/anthology/P/P16/P16-1100.pdf" data-editable="true" data-title="Achieving Open Vocabulary Neural Machine Translation with Hybrid Word-Character Models" class=""&gt;Achieving Open Vocabulary Neural Machine Translation with Hybrid Word-Character Models&lt;/a&gt;&lt;/h1&gt;&lt;h2&gt;关键词&lt;/h2&gt;&lt;p&gt;Neural Machine Translation、UNK Words&lt;/p&gt;&lt;h2&gt;来源&lt;/h2&gt;&lt;p&gt;ACL 2016&lt;/p&gt;&lt;h2&gt;问题&lt;/h2&gt;&lt;p&gt;如何解决机器翻译中的未登录词问题？&lt;/p&gt;&lt;h2&gt;文章思路&lt;/h2&gt;&lt;p&gt;文章提出了一个混合（层次）模型。该模型由两部分组成，分别为：a. 传统的基于词（word level）的seq2seq模型；b. 基于字母级别（character level）的LSTM模型，由一个将字母encode成单词的encoder和一个根据状态生成低频词的decoder组成。其中a部分负责进行翻译，b部分负责处理低频词（unk）。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/eed844a1612a8d83285452ee2b8d4576.jpg" data-rawwidth="230" data-rawheight="336"&gt;&lt;/p&gt;&lt;p&gt;具体地，a部分的encoder遇到unk时，会使用character level对该低频词进行encode，并使用encode出的representation作为输入。而decoder遇到unk时，会利用attention机制将当前上下文和LSTM状态初始化character level decoder。此处的初始化采用的是文章提出的separate path模式，即利用一个MLP作为character level decoder的初始化网络。值得注意的是此处word level decoder仍会选择用作为下一步的输入。&lt;/p&gt;&lt;h2&gt;相关工作&lt;/h2&gt;&lt;p&gt;Unk问题属于NMT中长期存在问题。目前多是采取后处理的方法。今年ACL有两篇paper，分别是李航老师实验室的copynet和Bengio实验室的pointing the unknown words，但对机器翻译任务参考意义有限。另外一种思路则是加大词典，比较知名工作有On Using Very Large Target Vocabulary for Neural Machine Translation。此外该工作还借鉴了Jiwei Li的hierarchical auto encoder。&lt;/p&gt;&lt;h2&gt;简评&lt;/h2&gt;&lt;p&gt;文章思路新颖且简单明了。因为NMT中存在unk的问题，作者直接利用character level RNN来生成一个词替代unk。该工作对拼音文字有一定意义，对中日韩文的参考意义有限。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://aclweb.org/anthology/P/P16/P16-1014.pdf" data-editable="true" data-title="Pointing the Unknown Words" class=""&gt;Pointing the Unknown Words&lt;/a&gt;&lt;/h1&gt;&lt;h2&gt;关键词&lt;/h2&gt;&lt;p&gt;Neural Machine Translation、UNK Words&lt;/p&gt;&lt;h2&gt;来源&lt;/h2&gt;&lt;p&gt;ACL 2016&lt;/p&gt;&lt;h2&gt;问题&lt;/h2&gt;&lt;p&gt;如何解决机器翻译中的未登录词问题？&lt;/p&gt;&lt;h2&gt;文章思路&lt;/h2&gt;&lt;p&gt;作者在有注意力的机器翻译模型上增加了一个开关来判断和是否复制原文。&lt;/p&gt;&lt;p&gt;1、Attention-based机器翻译模型&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/6836206b755db6d279c8b0766360a2ce.jpg" data-rawwidth="333" data-rawheight="175"&gt;经典的attention model这里不再赘述。&lt;/p&gt;&lt;p&gt;2、Pointer Softmax模型&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/cef9064f7a3972c554d344a782836b4d.jpg" data-rawwidth="380" data-rawheight="203"&gt;&lt;/p&gt;&lt;p&gt;两个问题有待解决解决：a. 是否进行copy？b. copy的位置在哪？&lt;/p&gt;&lt;p&gt;先说第二个问题，作者先引入shortlist softmax和location softmax。前者来确定要从shortlist中选取哪一个单词作为输出，后者确定在哪个位置要进行copy操作。&lt;/p&gt;&lt;p&gt;再看第一个问题，作者引入一个二值变量（可以想象为一个开关）来选择使用shortlist softmax还是location softmax。当值为1的时候不进行copy操作，使用shortlist softmax来从shortlist中选一个词作为输出。当值为0的时候进行copy操作，使用location softmax，将原文的词直接copy到指定位置。&lt;/p&gt;&lt;h2&gt;资源&lt;/h2&gt;&lt;p&gt;代码：&lt;a href="https://github.com/caglar/pointer_softmax" data-editable="true" data-title="GitHub - caglar/pointer_softmax"&gt;GitHub - caglar/pointer_softmax&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;简评&lt;/h2&gt;&lt;p&gt;本文的想法很有趣，直接从原文照抄罕见词和未知词很符合日常生活中人类的处理方法。从文中实验结果来看，该模型有一定的提升效果。注意力模型的提出与对人类行为的观察密不可分，而copy机制也是从生活中提炼出来的一种有效模型，我们可以借鉴的是从人类解决问题的具体方式中进行总结和归纳不失为一种有效的解决方案。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://aclweb.org/anthology/P/P16/P16-1228.pdf" data-editable="true" data-title="Harnessing Deep Neural Networks with Logic Rules" class=""&gt;Harnessing Deep Neural Networks with Logic Rules&lt;/a&gt;&lt;/h1&gt;&lt;h2&gt;关键词&lt;/h2&gt;&lt;p&gt;CNN、RNN、First-order Logic, Iterative Distillation Method&lt;/p&gt;&lt;h2&gt;来源&lt;/h2&gt;&lt;p&gt;ACL 2016&lt;/p&gt;&lt;h2&gt;问题&lt;/h2&gt;&lt;p&gt;如何将深度学习与逻辑规则结合使用？&lt;/p&gt;&lt;h2&gt;文章思路&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/ca52f6aa241d9fa7725c356f313d102a.png" data-rawwidth="447" data-rawheight="227"&gt;&lt;/h2&gt;&lt;p&gt;系统在构建正常神经网络(student)的同时，构建了一个基于逻辑规则的训练网络(teacher)。整个网络的目标还是优化神经网络的参数变量 θ，因为新的目标损失函数结合了二者的损失，通过这种方式，教师网络的逻辑信息就能够被转移到神经网络的θ上，从而加强神经网络的性能。 在这种结构里逻辑规则是用于辅助的可选项，通过调整权重，系统可以偏向某个网络。这种模型可以将监督学习扩展到无监督学习，比如图示中，无标记的数据通过教师子网之后提取有用信息，也可以用来训练监督学习的神经网络。&lt;/p&gt;&lt;p&gt;1、训练过程&lt;/p&gt;&lt;p&gt;假设输入数据为x, y。student神经网络的参数变量是θ, 输出层是softmax，对输入xn，输出预测概率分布σ(xn)。对teacher网络，在第ｔ次迭代中基于逻辑规则的预测结果表示为sn(t)，那么新的优化目标变成了&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/1ada851124622357827bcee6b400e724.png" data-rawwidth="421" data-rawheight="101"&gt;&lt;/p&gt;&lt;p&gt;可以看出来自教师网络的反馈作为regularization加到了目标函数里，通过这种方式两个网络的信息就结合在了一起。注意教师网络在每次训练迭代中都要构建，因此整个过程被称之为iterative knowledge distillation.&lt;/p&gt;&lt;p&gt;2、教师网络&lt;/p&gt;&lt;p&gt;教师网络使用软逻辑(soft logic)来编码first-order logic的信息。soft logic在[0,1]之间的连续取值，而不是二元值{0, 1}。逻辑运算也用max, min, sum代替原来的与或非。&lt;/p&gt;&lt;p&gt;神经网络数学模型为pθ(y|x) 教师网络数学模型假设为q(y|x)。我们实际上是用基于逻辑规则的教师网络来模拟神经网络输出，因此我们希望能找到一个最优的q，使得输入尽可能满足逻辑规则的要求，同时q要尽可能接近pθ。详细推导可以参见原文，最后的优化结果就是&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/7f6f7b9551453db16adcb9c02a13fa90.png" data-rawwidth="457" data-rawheight="97"&gt;&lt;/p&gt;&lt;p&gt;λl 是每个规则的自信度(confidence)，而rl, gl 是某个规则应用于某一输入时的逻辑结果，介于0,1之间。可以看到自信度比较高的规则可以使输入更容易通过规则。&lt;/p&gt;&lt;p&gt;3、应用&lt;/p&gt;&lt;p&gt;a. 基于CNN的情感分析b. 基于BLSTM-CNN的NER任务&lt;/p&gt;&lt;h2&gt;相关工作&lt;/h2&gt;&lt;p&gt;1、Neural-symbolic systems (Garcez et al., 2012) 从给定的规则构建推理网络2、(Collobert 2011)， 利用领域知识domain knowledge提取额外特征，增强原始数据3、Knowledge distillation (Hinton et al., 2015) (Bucilu et al. 2006)4、Posterior regularization (PR) method (Ganchev et al., 2010)&lt;/p&gt;&lt;h2&gt;简评&lt;/h2&gt;&lt;p&gt;创新点在于将逻辑规则与神经网络结合，可以利用人已知的知识去引导机器学习。当数据量不足的，或者对数据进行补充时，可以将人类的知识用逻辑语言表达出来，然后通过本文提出的框架进行增强训练。本文的两个例子中都提到只用了少量规则，优化的结果虽然显示要比当前其他模型好，但是没有大幅度的提高。需要进一步验证如果使用更多的规则，能不能大幅度提高准确率。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://aclweb.org/anthology/P/P16/P16-1043.pdf" data-editable="true" data-title="Easy Questions First? A Case Study on Curriculum Learning for Question Answering" class=""&gt;Easy Questions First? A Case Study on Curriculum Learning for Question Answering&lt;/a&gt;&lt;/h1&gt;&lt;h2&gt;关键词&lt;/h2&gt;&lt;p&gt;Curriculum Learning、Self-paced Learning、Question Answering&lt;/p&gt;&lt;h2&gt;来源&lt;/h2&gt;&lt;p&gt;ACL2016&lt;/p&gt;&lt;h2&gt;问题&lt;/h2&gt;&lt;p&gt;文章讨论了Curriculum Learning在NLP领域, 尤其是在QA task里应用的可行性。&lt;/p&gt;&lt;h2&gt;文章思路&lt;/h2&gt;&lt;p&gt;文章首先对QA类型的task给出了比较general的定义: 我们可以把QA问题看做是一个经验风险最小化(ERM)问题, 我们需要最小化:&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/27e5903f5012534c885cb908b17220b3.jpg" data-rawwidth="204" data-rawheight="49"&gt;&lt;/p&gt;&lt;p&gt;其中是a正确答案, f是给定背景知识以及问题, 模型选择出的最佳答案,Ω是regularizer.&lt;/p&gt;&lt;p&gt;之后, 作者对于Curriculum Learning, 尤其是Self-paced Learning做了介绍, 并且将其引入QA task, 进而将之前的ERM问题变为:&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/0810353ef81edd235cb8915fb6274bee.jpg" data-rawwidth="277" data-rawheight="58"&gt;&lt;/p&gt;&lt;p&gt;其中v是对问题进行采样时候的权值, g是self-paced regularizer, 其中λ代表’age’, 或者说’pace’. 训练初期, 模型趋向于对简单的问题进行训练, 而随着’age’的增加, 模型越来越多地加入更复杂的问题一起训练。&lt;/p&gt;&lt;p&gt;文章给出并分析了四种流行的self-paced regularizer如Table 1:&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/b72b5a9134355f25b4b6ba48acc9903c.jpg" data-rawwidth="350" data-rawheight="168"&gt;&lt;/p&gt;&lt;p&gt;之后提出了7种新的heuristics:&lt;/p&gt;&lt;p&gt;1) Greedy Optimal (GO): 将已有的Q和一系列新的Q一起训练, 选回答正确并且loss最低的。2) Change in Objective (CiO): 将已有的Q和一系列新的Q一起训练, 选择令loss改变最小的。3) Mini-max (M2 ): 当某个新的Q与其loss最大的一个candidate answer配对时, loss最小的. (通俗地讲, 就是最差情况都没有那么糟糕的一个)。4) Expected Change in Objective (ECiO): 只拿新的Q训练, 和之前的loss改变最小的. (相比于第二种的将已有的Q和新Q一起训练)。5) Change in Objective-Expected Change in Objective (CiO - ECiO): 2)和4)的值最接近的, 按照作者的意思, 这个值反应了model见到某个新Q时surprise的程度。6) Correctly Answered (CA): 将一系列新Q在当前model上测试, 选择用最小的loss正确回答的。7) Farthest from Decision Boundary (FfDB): 只用在latent structural SVMs上, 选择答案与decision boundary最远的一个新Q。&lt;/p&gt;&lt;h2&gt;资源&lt;/h2&gt;&lt;p&gt;MCTest: &lt;a href="http://research.microsoft.com/en-us/um/redmond/projects/mctest/" data-editable="true" data-title="Machine Comprehension Test (MCTest)" class=""&gt;Machine Comprehension Test (MCTest)&lt;/a&gt;Science Textbook: &lt;a href="http://http//www.ck12.org/" data-editable="true" data-title="http://http://www.ck12.org/"&gt;http://http://www.ck12.org/&lt;/a&gt;Science question answering: &lt;a href="http://aristo-public-data.s3.amazonaws.com/AI2-Elementary-NDMC-Feb2016.zip" data-editable="true" data-title="amazonaws.com 的页面"&gt;http://aristo-public-data.s3.amazonaws.com/AI2-Elementary-NDMC-Feb2016.zip&lt;/a&gt;Simple English Wikipedia: &lt;a href="https://dumps.wikimedia.org/simplewiki/20151102/" data-editable="true" data-title="wikimedia.org 的页面"&gt;https://dumps.wikimedia.org/simplewiki/20151102/&lt;/a&gt;QANTA: &lt;a href="https://cs.umd.edu/~miyyer/qblearn/" data-editable="true" data-title="QANTA: A Deep Question Answering Model"&gt;QANTA: A Deep Question Answering Model&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;相关工作&lt;/h2&gt;&lt;p&gt;1、Curriculum Learning:&lt;/p&gt;&lt;p&gt;早在1958年[1], 就有认知科学的相关学者意识到, 对于人类学习过程, 相对于提供随机的知识,由浅及深的地给予有计划的训练样本, 可以得到更好的效果. 之后这一Curriculum Learning的想法也被引入到机器学习中[2], 其中Self-paced learning (SPL)[3][4][5]是比较常用的方法。&lt;/p&gt;&lt;p&gt;2、QA:&lt;/p&gt;&lt;p&gt;Jurafsky和Martin[6]对于QA系列问题有一个非常好的叙述, 而这篇文章突出讨论Curriculum Learning在non-convex的QA模型上的应用, 着重介绍了基于配对的模型[7][8][9]和基于深度学习的模型[10][11].基于配对的模型将每一个问题和问题附带的多个备选答案组成若干个QA对, 我们称之为假设, 然后在给定相关文章的情况下, 寻找有最可能是正确的一个假设作为答案. 基于深度学习的模型可以使用依赖关系树结构的递归神经网络, 对句子level的QA模型的结果取平均[10]; 也可以用RNN构建”长期”存储器, 通过学习对存储器进行读/写操作, 模拟一个动态的知识构建过程[11]。&lt;/p&gt;&lt;h2&gt;简评&lt;/h2&gt;&lt;p&gt;在QA task中引入Curriculum Learning旨在在训练过程中, 启发式地对于提供给模型的数据出现的顺序进行一些调整, 从而让模型从简单的, 易于学习的样本开始, 随着模型对数据的表述愈加成熟, 逐渐加入更复杂的样本. 理想状况下这会指导模型从得到一个普通的local minima, 变成得到一个”更”好的local minima, 进而利用全部数据得到一个”更更”好的local minima。&lt;/p&gt;&lt;p&gt;通常来说, 我们给予模型的heuristic并不一定能够真正帮助模型, 因为通常我们都在猜测数据以及模型的latent representation是什么, 但是这篇文章通过了一系列的实验验证, 本文阐述的heuristic确实可以帮助QA model获得更好的准确率. 这证明了引导模型由浅及深的这种思路是可行的, 我们也许可以思考一些更复杂的heuristic, 或者将其应用到其他的一些NLP tasks。&lt;/p&gt;&lt;p&gt;然而本文给出的大部分heuristic在新问题的选择上都需要比较大的时间复杂度, 对于类似MCTest这种总共只有660个文章的小型数据集来说还算比较现实, 但是对于更大更长的数据集(比如CNN数据集, 38万个文章, 很多文章都超过了一千五百个单词, 而且备选答案数量也远超MCTest的四个)时, 就显得不那么轻松了. 最简单的Attention Sum Reader[1] 在CNN数据集上, 每个epoch都需要10个多小时, 就更别说其他基于AS Reader的模型了。&lt;/p&gt;&lt;p&gt;总体来说, 相对于实用性, 这篇文章更多在于提供了一种新的思路, 也就是把Curriculum Learning相关的概念应用到QA乃至于其他NLP task中, 非常值得思考, 因此是一篇非常值得阅读的文章。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://aclweb.org/anthology/P/P16/P16-1144.pdf" data-editable="true" data-title="The LAMBADA dataset:Word prediction requiring a broad discourse context" class=""&gt;The LAMBADA dataset:Word prediction requiring a broad discourse context&lt;/a&gt;&lt;/h1&gt;&lt;h2&gt;关键词&lt;/h2&gt;&lt;p&gt;Machine Reading Comprehension、Dataset&lt;/p&gt;&lt;h2&gt;来源&lt;/h2&gt;&lt;p&gt;ACL 2016&lt;/p&gt;&lt;h2&gt;问题&lt;/h2&gt;&lt;p&gt;构建了一个难度更大的机器阅读理解数据集。&lt;/p&gt;&lt;h2&gt;构建思路&lt;/h2&gt;&lt;p&gt;以Book Corpus的小说作为数据源，构建了10222个passages，每个passage包括平均4.6句话的context和相邻着的一句target，定义的任务是通过理解context来预测target中最后一个词，平均每个passage包括约75个tokens。其中，超过80%的passage context中包括了target中需要预测的词，48%的target words是专有名词（proper nouns），37%的词是一般名词（common nouns），约7.7%的是动词。这里，专有名词和一般名词是最难猜出来的，动词有一定的概率可以不需要context，而直接从target sentence利用语言模型猜出来。&lt;/p&gt;&lt;p&gt;在处理原始数据时，作者做了一层过滤，将容易从target sentence中直接猜出target word的passages统统丢掉，将剩下的部分放在众包网站上进行人工筛选，筛选的过程比较长，目的是让留在数据集中的数据有下面的效果：通过分析passage的context可以给出正确的target word，而如果只是给定target sentence的话，是猜不出正确的target word。&lt;/p&gt;&lt;h2&gt;资源&lt;/h2&gt;&lt;p&gt;本文数据集Lambada dataset: &lt;a href="http://clic.cimec.unitn.it/lambada/" data-editable="true" data-title="cimec.unitn.it 的页面"&gt;http://clic.cimec.unitn.it/lambada/&lt;/a&gt;众包网站Crowdflower: &lt;a href="http://www.crowdflower.com/" data-editable="true" data-title="Make your data useful"&gt;Make your data useful&lt;/a&gt;原始数据集Book Corpus: &lt;a href="http://www.cs.toronto.edu/~mbweb/"&gt;http://www.cs.toronto.edu/~mbweb/&lt;/a&gt;CNN/Daily Mail dataset: &lt;a href="https://github.com/deepmind/rc-data" data-editable="true" data-title='GitHub - deepmind/rc-data: Question answering dataset featured in "Teaching Machines to Read and Comprehend'&gt;GitHub - deepmind/rc-data: Question answering dataset featured in "Teaching Machines to Read and Comprehend&lt;/a&gt;CBT dataset: &lt;a href="http://fb.ai/babi/"&gt;http://fb.ai/babi/&lt;/a&gt;MSRCC dataset: &lt;a href="https://www.microsoft.com/en-us/research/publication/the-microsoft-research-sentence-completion-challenge/" data-editable="true" data-title="The Microsoft Research Sentence Completion Challenge"&gt;The Microsoft Research Sentence Completion Challenge&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;相关数据集&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/5b0d691a539f4cf8001773af649bc8be.png" data-rawwidth="1086" data-rawheight="620"&gt;&lt;/h2&gt;&lt;h2&gt;简评&lt;/h2&gt;&lt;p&gt;大型数据集是深度学习技术发展的重要基础，数据集的质量和难度也直接关系着模型的质量和实用性。机器阅读理解的数据集有很多，包括中文和英文的数据集，每一个的构建都会带来模型的创新，随着难度不断增加，对模型也提出了更高的要求。本文在构建数据集过程中为了保证任务的难度所采取的方法是值得借鉴的。&lt;/p&gt;&lt;h1&gt;致谢&lt;/h1&gt;&lt;p&gt;本期的10篇文章由以下同学完成：&lt;/p&gt;&lt;p&gt;苏辉、Xiaoyu、胡小明、赵越、周青宇、韩晓伟、Eric Yuan、Zewei Chu、tonya、张俊。&lt;/p&gt;&lt;p&gt;感谢大家地辛勤付出。&lt;/p&gt;&lt;h1&gt;广告时间&lt;/h1&gt;&lt;p&gt;PaperWeekly是一个分享知识和交流学问的民间组织，关注的领域是NLP的各个方向。如果你也经常读paper，也喜欢分享知识，也喜欢和大家一起讨论和学习的话，请速速来加入我们吧。&lt;/p&gt;&lt;p&gt;微信公众号：PaperWeekly&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/8e2b86789f8cddf7e423e1c07d39ce0a.jpg" data-rawwidth="430" data-rawheight="430"&gt;&lt;/p&gt;&lt;p&gt;微博账号：PaperWeekly（&lt;a href="http://weibo.com/u/2678093863" data-editable="true" data-title="PaperWeekly的微博"&gt;PaperWeekly的微博&lt;/a&gt; ）知乎专栏：PaperWeekly（&lt;a href="https://zhuanlan.zhihu.com/paperweekly" data-editable="true" data-title="PaperWeekly - 知乎专栏"&gt;PaperWeekly - 知乎专栏&lt;/a&gt; ）微信交流群：微信+ zhangjun168305（请备注：加群 or 加入paperweekly）&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/22279528&amp;pixel&amp;useReferer"/&gt;</description><author>张俊</author><pubDate>Fri, 02 Sep 2016 11:27:40 GMT</pubDate></item><item><title>cs.CL weekly 2016.08.22-2016.08.26</title><link>https://zhuanlan.zhihu.com/p/22184043</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/c3c8fdc44ec223b1d89e130afa476975_r.png"&gt;&lt;/p&gt;&lt;h1&gt;简介&lt;/h1&gt;&lt;p&gt;这个栏目是将一周内arxiv cs.CL刷出的好文进行一个简单的汇总，并配有一句话总结，旨在帮助大家过滤掉cs.CL上的水文，并且为PaperWeekly团队选文提供高质量paper。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://120.52.73.78/arxiv.org/pdf/1608.05852v1.pdf" data-editable="true" data-title="Learning Word Embeddings from Intrinsic and Extrinsic Views" class=""&gt;Learning Word Embeddings from Intrinsic and Extrinsic Views&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;本文提出了一种依靠intrinsic (descriptive) and extrinsic (contextual) information来学习词向量的方法，有效解决了传统方法中对低频词学习存在的问题。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://120.52.73.78/arxiv.org/pdf/1608.06043v1.pdf" data-editable="true" data-title="Context Gates for Neural Machine Translation"&gt;Context Gates for Neural Machine Translation&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;本文提出了一种context gate来动态地控制机器翻译中source、target context对word generation的影响，实验证明在BLEU指标下比attention-based的方法提高了2.3。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://120.52.73.80/arxiv.org/pdf/1608.05777v1.pdf" data-editable="true" data-title="Topic Sensitive Neural Headline Generation"&gt;Topic Sensitive Neural Headline Generation&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;本文针对传统模型中忽略topical similarities和differences of documents的问题，提出了一种新方案，先将documents按照topics分类，每一类中的pattern比较接近，然后再做sentence level summary，得到了更好的效果。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://120.52.73.77/arxiv.org/pdf/1608.06378v1.pdf" data-editable="true" data-title="Towards Machine Comprehension of Spoken Content: Initial TOEFL Listening Comprehension Test by Machine"&gt;Towards Machine Comprehension of Spoken Content: Initial TOEFL Listening Comprehension Test by Machine&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;本文以托福听力题作为数据集，尝试对多媒体信息进行理解。听力问题是听完一段话，理解之后，进行4选1，而不是之前常见的cloze-style理解任务。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://120.52.73.79/arxiv.org/pdf/1608.07076v1.pdf" data-editable="true" data-title="A Context-aware Natural Language Generator for Dialogue Systems"&gt;A Context-aware Natural Language Generator for Dialogue Systems&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;本文的模型是一种端到端的模型，根据上下文和用户说话的方式来生成对话。是一篇SIGDIAL 2016 short paper。配套的代码已发布于&lt;a href="https://github.com/UFAL-DSG/tgen" data-editable="true" data-title="Github"&gt;Github&lt;/a&gt;&lt;/p&gt;&lt;h1&gt;About&lt;/h1&gt;&lt;p&gt;对NLP高质量原创内容和讨论感兴趣的你，赶快来关注：&lt;/p&gt;&lt;p&gt;1、PaperWeekly&lt;a href="http://weibo.com/2678093863/" data-editable="true" data-title="官方微博"&gt;官方微博&lt;/a&gt;&lt;/p&gt;&lt;p&gt;2、PaperWeekly官方微信&lt;/p&gt;&lt;p&gt;3、PaperWeekly&lt;a href="https://zhuanlan.zhihu.com/paperweekly" data-editable="true" data-title="知乎专栏"&gt;知乎专栏&lt;/a&gt;&lt;/p&gt;&lt;p&gt;4、PaperWeekly微信交流群（+微信zhangjun168305入群）&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/22184043&amp;pixel&amp;useReferer"/&gt;</description><author>张俊</author><pubDate>Fri, 26 Aug 2016 09:52:06 GMT</pubDate></item><item><title>从api.ai工作原理来看构建简单场景chatbot的一般方法</title><link>https://zhuanlan.zhihu.com/p/22139158</link><description>&lt;h1&gt;引&lt;/h1&gt;&lt;p&gt;chatbot无疑是当前非常火的一个研究领域和产品方向，简单地可以分为两类，开放域bot和封闭域bot，开放域bot倾向于解决所有的事情，而封闭域bot倾向于解决某一个细分领域中的事情，旨在用AI技术提高效率，提高生产力。现阶段的开放域bot我个人感觉更像是多个常用封闭域bot的叠加，当用户发起一个请求，系统会判断出属于哪个细分领域，然后转到相应的程序中去执行并给出反馈，顺着这个逻辑来看，研究简单场景下的chatbot是个重要的基础工作，这类研究或者产品的质量直接决定了复杂场景或者开放域bot的质量。当然逗乐型的bot并不属于本文讨论的范围。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/d35833c83746938c0418be1102f05222.png" data-rawwidth="715" data-rawheight="487"&gt;图片来自paper &lt;a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/06/williams2016dstc_overview-1.pdf" data-editable="true" data-title="The Dialog State Tracking Challenge Series- A Review" class=""&gt;The Dialog State Tracking Challenge Series- A Review&lt;/a&gt;&lt;/p&gt;&lt;p&gt;chatbot是场交互革命，也是一个多技术融合的平台。上图给出了构建一个chatbot需要具备的组件，简单地说chatbot = NLU(Natural Language Understanding) + NLG(Natural Language Generation).(本文只关注NLP相关的技术，对语音识别并无讨论)&lt;/p&gt;&lt;p&gt;对于封闭域的chatbot，NLU的工作就是DST(Dialog State Tracker)，用户给出输入之后，系统可以给出下面的形式作为state：&lt;/p&gt;&lt;p&gt;Act(Slot=Value)&lt;/p&gt;&lt;p&gt;Act表示用户行为的类型，比如请求、查询、打招呼等等；Slot表示用户输入中包含的某种Act下的Entity，比如查询酒店的位置、价格这些实体；Value是指Slot中Entity对应的值，比如位置在北边，价格在500-800之间等等。每一句话中可能包括多个Act-Slot-Value对，chatbot需要做的事情就是准确地识别出Act，并且抽取出相应的Slot和Value。&lt;/p&gt;&lt;p&gt;紧接着是NLG的部分，前几天在&lt;a href="http://rsarxiv.github.io/2016/08/16/PaperWeekly-%E7%AC%AC%E4%BA%8C%E6%9C%9F/" data-editable="true" data-title="PaperWeekly第二期"&gt;PaperWeekly第二期&lt;/a&gt;中分享了三篇paper，其中两篇正是研究基于DST的NLG问题。&lt;/p&gt;&lt;p&gt;本文首先从&lt;a href="http://rsarxiv.github.io/2016/08/21/%E4%BB%8Eapi-ai%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86%E6%9D%A5%E7%9C%8B%E6%9E%84%E5%BB%BA%E7%AE%80%E5%8D%95%E5%9C%BA%E6%99%AFchatbot%E7%9A%84%E4%B8%80%E8%88%AC%E6%96%B9%E6%B3%95/api.ai" data-editable="true" data-title="api.ai"&gt;api.ai&lt;/a&gt;这家企业提供的服务说起，通过研究其提供的封闭域bot构建技术，来提炼构建简单场景chatbot的一般方法，为构建复杂场景或者找出现有chatbot存在的技术问题和面临的技术难点打下基础。&lt;/p&gt;&lt;h1&gt;api.ai&lt;/h1&gt;&lt;h2&gt;api.ai公司介绍&lt;/h2&gt;&lt;blockquote&gt;&lt;p&gt;Api.ai provides developers and companies with the advanced tools they need to build conversational user interfaces for apps and hardware devices.&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;这家公司是一家典型的B2D公司，提供了一些工具帮助开发者轻松地开发一款bot，并且可以轻松地发布到各种message平台上。商业模式也非常简单，免费用户有一定次数的调用权限，需要大量调用的话，则付费购买，不同的权限有不同的价格，该公司也提供高级定制化服务。&lt;/p&gt;&lt;p&gt;api.ai公司成立于2010年（数据来自&lt;a href="https://www.crunchbase.com/organization/api-ai#/entity" data-editable="true" data-title="CrunchBase"&gt;CrunchBase&lt;/a&gt;），其早期业务不清楚，但可以从提供的服务中推断出早期攒了大量的用户数据，而且涉及的领域非常多，比如：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/822f16a29b4bc7fc5b0ced5ca1babe24.png" data-rawwidth="803" data-rawheight="716"&gt;&lt;/p&gt;&lt;p&gt;每个领域都有一个知识库，如果你要开发某个常用领域内的chatbot，那么这个知识库将会非常有用。&lt;/p&gt;&lt;h2&gt;重要概念和工作原理&lt;/h2&gt;&lt;h3&gt;重要概念&lt;/h3&gt;&lt;p&gt;1、Agents。这个是一个对外接口，与其他应用程序或你的app进行整合的部分。如下图：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/862ce5730fccea058b464f052db430da.png" data-rawwidth="712" data-rawheight="180"&gt;&lt;/p&gt;&lt;p&gt;2、Entities。这里的实体和引言中提到的Slot类似，是指某个特定领域内的实体，是一类东西的抽象概括，比如HotelName这一实体，对应着很多的酒店名字，凯宾斯基、如家等等。有Entity，就一定有value，chatbot中重要的一步正是从user input中抽取出对应预先设定好entity的value，是一个典型的Named Entity Recognition任务。&lt;/p&gt;&lt;p&gt;这里经典的NER任务是识别出user input中的person、time、place等等几个基本元素，api.ai将这些常见的entity定义为system级的，即默认提供了训练好的识别器，当然不仅仅限于这几类基本的；而特定领域知识库的重要作用也正是在于识别该领域内的entity。除了system level的NER之外，需要developer自定义一些entity，比如菜名，而且要给定具体的菜名和相似的表达作为samples进行训练。&lt;/p&gt;&lt;p&gt;3、Intents。这个相当于是从user input到chatbot执行某个action之间的一个映射关系，用户输入一句话之后，chatbot就可以理解其意图，是在打招呼，还是查询，还是做些别的事情。这部分api.ai提供了训练器，但是需要developer定义一些标注好的examples，标注的形式如下：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/31c5390934afe103b1f780fca0bf0e37.png" data-rawwidth="1466" data-rawheight="1160"&gt;&lt;/p&gt;&lt;p&gt;这里用户输入是book a ticket to Los Angeles on Monday，所谓标注包括两个level，一个是entity标注，一个是intent标注，前一个是为了训练NER工具，后一个是为了识别intent。这里因为LA是地名，Monday是时间，所以都会被api.ai的系统自动标注出来。&lt;/p&gt;&lt;p&gt;4、Actions。这个是由intents进行trigger的，actions就和引言中的Act类似，是一个具体的动作，比如说查询，但执行动作的时候一般都要带上具体的参数value，用户输入：“三里屯最近的阿迪达斯店在什么位置？”，chatbot首先会提取出place-&amp;gt;三里屯，query-&amp;gt;阿迪达斯店，然后转换为json丢给后台的查询服务，查询到结果后给出答案。这里的value抽取其实就是第二个概念提到的entity value。&lt;/p&gt;&lt;p&gt;5、Contexts。上下文是一个非常重要但却解决不是很好的点，api.ai提供的方式是自定义一些context condition，当condition满足时，自动trigger出context关联内容template，然后filling slots，生成response。&lt;/p&gt;&lt;h3&gt;工作原理&lt;/h3&gt;&lt;p&gt;以RSarXiv chatbot为例，简单介绍下工作原理。（注：RSarXiv是我之前写的一个arxiv paper推荐系统）&lt;/p&gt;&lt;p&gt;step 1 自定义Entity，这里我定义了两个entities，一个是keywords和subject。keywords是为search功能提供value，而subject是为update new papers功能提供value。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/278517664dda186155dcd5f359ff5ff5.png" data-rawwidth="633" data-rawheight="217"&gt;定义好subject entity之后，我给出了几个examples，同时也包括其synonyms，keywords entity类似。&lt;/p&gt;&lt;p&gt;step 2 自定义Intents，这里我定义了两个Intents，分别是update和search。下图是update的examples，是我自定义的几个例子。api.ai会根据我定义好的entity进行自动标注，比如cs.CL，today是系统默认的entity所以也进行了自动标注。自动标注是为了后台的机器学习算法对标注好的examples进行学习，以提高chatbot的NLU准确率。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/4d0f72e49ec1fb1aa681547effdbf533.png" data-rawwidth="639" data-rawheight="375"&gt;&lt;/p&gt;&lt;p&gt;接下来，我需要定义下Actions，如下图：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/73d4d50e3bf5d5b45c8702e9b180783f.png" data-rawwidth="637" data-rawheight="321"&gt;Action被称为update，必须包含的参数是subject，也就是我们上面讲到的一个entity，date参数并不是必须的。所以，这里如果用户的input被识别出是update intents的话，就必须包括subject参数，否则chatbot会trigger一个response，类似“请用户输入subject”这样的话。&lt;/p&gt;&lt;p&gt;step 3 简单测试，在界面的右侧有一个console，用来测试当前chatbot的效果，我输入update cs.CL，得到下面的效果：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/2b06d3f59031301dafb0a8766f3d636c.png" data-rawwidth="337" data-rawheight="622"&gt;chatbot识别出Intent是Update，Action是update，Parameter是date和subject，并且subject的值是cs.CL，下面的Show JSON是api.ai为developer生成的，用来与developer自己的web service进行数据交换。&lt;/p&gt;&lt;p&gt;step 4 训练。训练包括两个部分，一是训练NER，二是训练Intent Classification。训练器是api.ai提供的，但是标注数据是developer自己提供的，当然训练数据越多，标注越准，分类器的准确率就越高，chatbot的NLU准确率越高。至于训练方法，docs中没有细说，我简单猜测一下，NER可以当做Sequence Labeling任务，和Intent Recognition类似，都可以看作是多分类问题，不管是传统的分类方法还是当下流行的deep learning方法都能得到不错的准确率。随着user logs的增多，训练数据会越来越多，chatbot通过学习就会变得越来越“聪明”。但这里有个问题，training data越多，需要标注或者修改标注的数据就会越多，也是一个麻烦事儿。&lt;/p&gt;&lt;p&gt;step 5 整合、发布。api.ai支持的平台非常多，包括当下流行的message平台，还有各种操作系统平台。在message平台上提供了一键整合的功能，在操作系统上提供了SDK。这里我用了slack平台，api.ai打通了和slack的接口，也提供了webhook，连接了我之前写好的web service，只需要按照它给定的消息接口进行定义即可。&lt;/p&gt;&lt;h3&gt;demo&lt;/h3&gt;&lt;p&gt;目前RSarXiv只提供两个简单的功能，一个是update今天最新的arxiv paper，你可以通过show me new papers in cs.CL等类似的话来获取cs.CL这个领域中最新的paper；一个是search功能，你可以通过search LSTM等类似的话来获取包括LSTM这个关键词的paper。由于是一个测试用的demo，就没做什么复杂的功能。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/026f59e0668853eede457ebe43756cfc.png" data-rawwidth="635" data-rawheight="387"&gt;&lt;/p&gt;&lt;p&gt;大家如果感兴趣的话，可以留言给我或者发邮件给我(mcgrady150318@gmail.com/mcgrady150318@163.com)，我邀请大家到这个slack team中。&lt;/p&gt;&lt;h1&gt;简单场景chatbot构建方法&lt;/h1&gt;&lt;p&gt;介绍了下api.ai提供的服务，下面简单地提炼一下。&lt;/p&gt;&lt;p&gt;chatbot = NLU + NLG&lt;/p&gt;&lt;p&gt;api.ai解决的重点问题是NLU的问题，NLU也是Dialogue State Tracker(DST)的核心和基础，而DST是chatbot的核心。这里的NLU包括两个问题：&lt;/p&gt;&lt;p&gt;1、从user inputs中识别出user intent和对应的action。&lt;/p&gt;&lt;p&gt;2、从user inputs中抽取出预先设定好的entity value，作为action的parameter。&lt;/p&gt;&lt;p&gt;NLG在api.ai这里基本上通过developer在Intent中设定response，当识别出是哪个intent之后，response自然就有了，最多空一些slot，用结果进行填充。如果developer选择了webhook，即需要从自定义的web service中给定response。如下图：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/a8dcdd37586477d5bfd0ef3304d22863.png" data-rawwidth="642" data-rawheight="199"&gt;&lt;/p&gt;&lt;p&gt;跑了一个简单场景的chatbot demo之后，简单归纳下构建方法：&lt;/p&gt;&lt;p&gt;1、从特定任务中归纳出Intents、Actions、Entities。&lt;/p&gt;&lt;p&gt;2、分别编写Intents、Entities的examples，两类examples是做DST的基础，用来训练chatbot准确地识别user intents和entity parameters，至于算法，自己写也可以，用api.ai也可以。&lt;/p&gt;&lt;p&gt;3、做好DST之后，chatbot就知道用户的意图和相应的参数，丢给后台的web service去执行，并得到执行的结果，然后填充预先定义好的templates，生成response，返回给用户。&lt;/p&gt;&lt;h1&gt;结束语&lt;/h1&gt;&lt;p&gt;简单场景的chatbot关键之处在于做好DST，有一个叫Dialogue State Tracking Challenge的比赛正式为了解决这个问题而举办的。我们说，封闭域的chatbot涉及两个方面，一是NLU，一是NLG，前者通过大量的examples来学习一个分类器和抽取器，得到Dialogue State，而后者根据Dialogue State，生成合适的response。&lt;/p&gt;&lt;p&gt;NLU不是一个简单的事情，尤其是标注大量的examples不是那么容易；NLG同样也不是一个好解决的问题，预先定义的template会让chatbot受限制于template的多少，手工痕迹太重，需要一种更牛的解决方案来代替。（其实挺多paper都在做这件事情，PaperWeekly也分享过几篇相关的paper，data driven的NLG方案同样需要大量的examples做训练。）&lt;/p&gt;&lt;p&gt;Context是个挺难的事情，现有的、成熟的解决方案仍是手工来定义条件，然后根据条件来trigger。我在想，能否构建一个动态的DST，可以是一张动态hash table，也可以是一个动态graph，记录着某一个user方方面面的状态，而不仅仅是某一轮对话中抽取出的信息，而是多轮对话中的信息，不仅在intent识别中可以用到context，在生成response时也可以用到，多轮对话和个性化对话都将不是什么问题了。或者，用现在流行的表示学习思维来想这个问题的话，也许context可以是一个分布式表示，user profile也是一个表示，NLG时以context distribution为condition来做generatation。&lt;/p&gt;&lt;p&gt;本文介绍了构建简单场景下chatbot的一般方法，用api.ai确实很容易做一个chatbot，而对于复杂场景，我觉得用api.ai来开发也没有太大问题，最费时的可能是构建context trigger。api.ai因为是面向developer的，所以对于普通的用户并不适合，但对于有一定经验的developer来说，使用起来就非常简单，提供的web界面也很好用，如果说chatbot是一个平台的话，那么api.ai正像是一个开发工具，提高了开发chatbot的效率，虽然NLG和context这两个问题可以做的更好，但整体来说降低了开发chatbot的门槛，是个很有意义和钱景的服务。&lt;/p&gt;&lt;h1&gt;PaperWeekly招人广告&lt;/h1&gt;&lt;p&gt;PaperWeekly每周会分享N篇当下最流行、最有趣的NLP paper，旨在用最精炼的话说明白paper的贡献和创新。目前运营在公众号和知乎专栏两个平台上，现在的形式是每周分享一篇NLP Paper周报，偶尔也会写一些NLP相关的博客，由于本人精力和水平有限，现邀请各位对NLP技术、NLP Paper感兴趣的童鞋加入一同运营，在推进国内NLP技术发展的路上贡献一份自己的力量。&lt;/p&gt;&lt;p&gt;微信公众号：PaperWeekly&lt;/p&gt;&lt;p&gt;http://weixin.qq.com/r/OUW0rA3ExVC6rUnP9xAr (二维码自动识别)&lt;/p&gt;&lt;p&gt;知乎专栏：&lt;a href="https://zhuanlan.zhihu.com/paperweekly" data-editable="true" data-title="PaperWeekly"&gt;PaperWeekly&lt;/a&gt;&lt;/p&gt;&lt;p&gt;微信交流群：&lt;/p&gt;&lt;p&gt;群已满100人，无法扫码加群，大家加zhangjun168305，我拉大家入群。&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/22139158&amp;pixel&amp;useReferer"/&gt;</description><author>张俊</author><pubDate>Tue, 23 Aug 2016 13:44:24 GMT</pubDate></item></channel></rss>