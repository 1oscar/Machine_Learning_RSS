<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>PaperWeekly - 知乎专栏</title><link>https://zhuanlan.zhihu.com/paperweekly</link><description>每周会分享N篇nlp领域好玩的paper，旨在用最少的话说明白paper的贡献。同时也运营一个公众号，PaperWeekly，欢迎大家关注。</description><lastBuildDate>Sun, 11 Sep 2016 12:16:27 GMT</lastBuildDate><generator>Ricky</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>cs.CL weekly 2016.09.05-2016.09.09</title><link>https://zhuanlan.zhihu.com/p/22390774</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/ea9f4f4503d2ed9e15a56fe56e26e98d_r.jpg"&gt;&lt;/p&gt;&lt;p&gt;本周（2016.09.05-2016.09.09）质量较高的arXiv cs.CL的paper如下：（点击标题可看原文）&lt;/p&gt;&lt;h1&gt;&lt;a href="http://120.52.73.79/arxiv.org/pdf/1609.00718v1.pdf" data-editable="true" data-title="Convolutional Neural Networks for Text Categorization: Shallow Word-level vs. Deep Character-level" class=""&gt;Convolutional Neural Networks for Text Categorization: Shallow Word-level vs. Deep Character-level&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;张潼老师的文章，通过实验对比了shallow word-level CNN（本文工作）和deep char-level CNN模型在而文本分类任务上的表现，结论是本文工作又快又准。&lt;/p&gt;&lt;p&gt;（这篇文章对于选择char-level还是word-level做文本分类非常有指导意义）&lt;/p&gt;&lt;h1&gt;&lt;a href="http://120.52.73.78/arxiv.org/pdf/1609.00565v1.pdf" data-editable="true" data-title="Skipping Word: A Character-Sequential Representation based Framework for Question Answering" class=""&gt;Skipping Word: A Character-Sequential Representation based Framework for Question Answering&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;本文用char-level CNN模型来做句子表示，然后进行question和answer之间的相关匹配学习，CIKM2016 short paper accepted。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://120.52.73.78/arxiv.org/pdf/1609.00777v1.pdf" data-editable="true" data-title="End-to-End Reinforcement Learning of Dialogue Agents for Information Access"&gt;End-to-End Reinforcement Learning of Dialogue Agents for Information Access&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;本文是微软研究软邓力老师的文章，构建了一种从知识图谱中形成response的聊天机器人KB-InfoBot，并且提出了一种端到端的增强学习训练方案。&lt;/p&gt;&lt;p&gt;（本文对于构建一个端到端的KB + task-oriented chatbot非常有启发和指导意义）&lt;/p&gt;&lt;h1&gt;&lt;a href="http://120.52.73.79/arxiv.org/pdf/1609.01462v1.pdf" data-editable="true" data-title="Joint Online Spoken Language Understanding and Language Modeling with Recurrent Neural Networks"&gt;Joint Online Spoken Language Understanding and Language Modeling with Recurrent Neural Networks&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;本文提出一种模型，将intent detection、slot filling和language modeling融合在一起进行学习，用于解决对话系统中的SLU task。本文是SIGDIAL 2016 paper。&lt;/p&gt;&lt;p&gt;用到的数据集在Dropbox有一份&lt;a href="http://t.cn/Rcbcpfl" data-editable="true" data-title="copy"&gt;copy&lt;/a&gt;&lt;/p&gt;&lt;h1&gt;&lt;a href="http://120.52.73.79/arxiv.org/pdf/1609.01454v1.pdf" data-editable="true" data-title="Attention-Based Recurrent Neural Network Models for Joint Intent Detection and Slot Filling"&gt;Attention-Based Recurrent Neural Network Models for Joint Intent Detection and Slot Filling&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;和上一篇paper是同一个作者，解决的是同一个问题。将RNN换成了attention-based RNN，被另外一个会议录取。(有点灌水的意思)&lt;/p&gt;&lt;h1&gt;&lt;a href="http://120.52.73.77/arxiv.org/pdf/1609.02116v1.pdf" data-editable="true" data-title="Ask the GRU: Multi-task Learning for Deep Text Recommendations" class=""&gt;Ask the GRU: Multi-task Learning for Deep Text Recommendations&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;本文提出了用端到端的解决方案来做paper的推荐任务，用GRU将文本序列（标题、摘要等）encode到一个latent vector中。并且通过多任务学习来完成内容推荐和条目预测两个task，取得了不错的效果。&lt;/p&gt;&lt;p&gt;&lt;b&gt;以下内容为arXiv外的优质内容：&lt;/b&gt;&lt;/p&gt;&lt;h1&gt;&lt;a href="http://www.matthen.com/research/papers/Discriminative_Methods_for_Statistical_Spoken_Dialogue_Systems_Matthew_Henderson_PhD_Thesis.pdf" data-editable="true" data-title="Discriminative Methods for Statistical Spoken Dialogue Systems" class=""&gt;Discriminative Methods for Statistical Spoken Dialogue Systems&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;剑桥大学Spoken Dialogue System组毕业的Matthew Henderson博士，师从于Steve Young教授，研究领域是对话系统中的Dialogue State Tracking，主要特色是用transfer learning来解决discriminative model的扩展性和通用性。&lt;/p&gt;&lt;p&gt;如果你对chatbot感兴趣，强烈建议好好研读一下这篇博士论文。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://cs.stanford.edu/people/karpathy/main.pdf" data-editable="true" data-title="CONNECTING IMAGES AND NATURAL LANGUAGE" class=""&gt;CONNECTING IMAGES AND NATURAL LANGUAGE&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;斯坦福大学Feifei Li的博士生Andrej Karpathy的PhD thesis，Karpathy维护着几个非常流行的开源代码库，并且有着一个影响力非常大的博客。名师出高徒，这篇博士博士论文值得一看！&lt;/p&gt;&lt;p&gt;最近，他更新了一篇博客，谈论了一些自己对读博的思考和建议。 &lt;a href="http://karpathy.github.io/2016/09/07/phd/" data-editable="true" data-title="A Survival Guide to a PhD"&gt;A Survival Guide to a PhD&lt;/a&gt;&lt;/p&gt;&lt;h1&gt;&lt;a href="https://pan.baidu.com/share/link?shareid=317480&amp;amp;uk=1594817379" data-editable="true" data-title="Mendeley Docs"&gt;Mendeley Docs&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;paper越看越多，一个优秀的paper管理工具就变得非常必要了，Mendeley是其中最优秀的代表之一。&lt;/p&gt;&lt;p&gt;Easily organize your papers, read &amp;amp; annotate your PDFs, collaborate in private or open groups, and securely access your research from everywhere.&lt;/p&gt;&lt;h1&gt;广告时间&lt;/h1&gt;&lt;p&gt;PaperWeekly是一个分享知识和交流学问的民间组织，关注的领域是NLP的各个方向。如果你也经常读paper，也喜欢分享知识，也喜欢和大家一起讨论和学习的话，请速速来加入我们吧。&lt;/p&gt;&lt;p&gt;微信公众号：PaperWeekly&lt;p&gt;http://weixin.qq.com/r/OUW0rA3ExVC6rUnP9xAr (二维码自动识别)&lt;/p&gt;&lt;/p&gt;&lt;p&gt;微博账号：PaperWeekly（&lt;a href="http://weibo.com/u/2678093863" data-editable="true" data-title="PaperWeekly的微博"&gt;PaperWeekly的微博&lt;/a&gt; ）知乎专栏：PaperWeekly（&lt;a href="https://zhuanlan.zhihu.com/paperweekly" data-editable="true" data-title="PaperWeekly - 知乎专栏"&gt;PaperWeekly - 知乎专栏&lt;/a&gt; ）微信交流群：微信+ zhangjun168305（请备注：加群 or 加入paperweekly）&lt;/p&gt;</description><author>张俊</author><pubDate>Sat, 10 Sep 2016 13:06:12 GMT</pubDate></item><item><title>PaperWeekly第四期------基于强化学习的文本生成技术</title><link>https://zhuanlan.zhihu.com/p/22385421</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/e230b2395dd90e3491d83701bc3ec152_r.jpg"&gt;&lt;/p&gt;&lt;h1&gt;引&lt;/h1&gt;&lt;p&gt;2013年以来Deep mind团队相继在NIPS和Natures上发表了用深度增强（强化）学习玩Atari游戏，并取得良好的效果，随后Alpha go与李世乭的一战更使得深度增强学习家喻户晓。在游戏上取得了不错的成果后，深度增强学习也逐渐被引入NLP领域。本期介绍目前NLP领域较为热点的研究方向，基于强化学习的文本生成技术（NLG），共选择了三篇文章，分别为：&lt;/p&gt;&lt;p&gt;(1)《Generating Text with Deep Reinforcement Learning》应用Deep Q-Network作为生成模型用于改善seq2seq模型&lt;/p&gt;&lt;p&gt;(2) 《Deep Reinforcement Learning for Dialogue Generation》应用强化学习进行开放领域的文本生成任务，并对比了有监督的seq2seq加attention模型和基于最大互信息的模型&lt;/p&gt;&lt;p&gt;(3)《Hierarchical Reinforcement Learning for Adaptive Text Generation_lshowway》以任务为导向的户内导航对话系统用分层强化学习进行文本生成&lt;/p&gt;&lt;p&gt;以下为三篇文章的主要信息：&lt;/p&gt;&lt;h1&gt;&lt;a href="http://120.52.73.76/arxiv.org/pdf/1510.09202v1.pdf" data-editable="true" data-title="Generating Text with Deep Reinforcement Learning"&gt;Generating Text with Deep Reinforcement Learning&lt;/a&gt;&lt;/h1&gt;&lt;h2&gt;作者&lt;/h2&gt;&lt;p&gt;Hongyu Guo&lt;/p&gt;&lt;h2&gt;单位&lt;/h2&gt;&lt;p&gt;National Research Council Canada&lt;/p&gt;&lt;h2&gt;关键词&lt;/h2&gt;&lt;p&gt;Reinforcement Learning、Seq2Seq、Text Generation&lt;/p&gt;&lt;h2&gt;来源&lt;/h2&gt;&lt;p&gt;NIPS2015 Workshop (2015.10.30)&lt;/p&gt;&lt;h2&gt;问题&lt;/h2&gt;&lt;p&gt;本文提出将Deep Q-Network作为生成模型用于改善seq2seq模型，将decoding修改为迭代式的过程，实验表明本模型具有更好的泛化性。&lt;/p&gt;&lt;h2&gt;模型&lt;/h2&gt;&lt;p&gt;对seq2seq模型改进的论文层出不穷，本文率先引入深度强化学习的思想，将DQN用于文本生成。对DQN还不了解的同学可以先阅读DeepMind的论文Playing Atari with Deep Reinforcement Learning。本文的模型如下：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/eeb5b40e85d79a6db4d937aa37924be0.jpg" data-rawwidth="445" data-rawheight="251"&gt;&lt;/p&gt;&lt;p&gt;如同一般的神经网络，我们也可以把DQN当做一个黑盒来使用。只需要准备好DQN需要的四个元素s(i),a(i),r(i),s(i+1)，分别代表i时刻下state,action,reword和i+1时刻的state。&lt;/p&gt;&lt;p&gt;对照上图我们把算法解剖分为4个步骤：&lt;/p&gt;&lt;p&gt;Step 1: 先是传统的seq2seq模型。通过LSTM先把输入序列encode为一个定长向量EnSen(i)，然后作为decode阶段的初始状态依次生成新的序列DeSen(i)（decoding search使用beam search算法来 expand next words）。经过第一步我们得到初始state：(EnSen(i), DeSen(i))和action集合：每个位置的hypotheses。&lt;/p&gt;&lt;p&gt;Step 2: 接下来从hypotheses（actions）中选择一个可以获得最大reward的单词（action）作为该位置新生成的词，用新单词来代替之前的旧词，于是生成新的state：(EnSen(i), DeSen(i+1))。&lt;/p&gt;&lt;p&gt;Step 3: 接着就是标准的DQN的部分，计算Loss函数并对其应用梯度下降。&lt;/p&gt;&lt;p&gt;Step 4: 回到Step 2，对得到的state继续迭代，每一次迭代都只生成一个新词来代替旧词，直到迭代次数达到设好的值（作者将次数定为句子长度的两倍，同学们可以思考一下理由）。&lt;/p&gt;&lt;p&gt;总结DQN所需的四个元素对应如下：(1) i时刻下的state：(EnSen(i), DeSen(i))；(2) i时刻下的action：beam search得到的每个位置的hypotheses；(3) i时刻下的reword：target sentence和DeSen(i+1)的相似度（BLEU score）；(4) i+1时刻下的state：(EnSen(i), DeSen(i+1))；&lt;/p&gt;&lt;p&gt;为了更好的提取句子的特征，作者在decode阶段使用了双向LSTM。同时还在reinforcement learning中加入attention机制，可以达到先decode比较简单的部分再处理困难部分的效果。最后在生成相似句子的实验中得到了比只用LSTM decoder效果更好的结论：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/5d92477453549f38a825cf8a09fd27c3.jpg" data-rawwidth="591" data-rawheight="78"&gt;&lt;/p&gt;&lt;h2&gt;相关工作&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/1533d7282033cfba05652bf1d4f6541e.jpg" data-rawwidth="529" data-rawheight="139"&gt;&lt;/h2&gt;&lt;h2&gt;简评&lt;/h2&gt;&lt;p&gt;本文的思想其实非常符合写作的一种情况，就像贾岛推敲的故事，回想小时候刚学习写句子时，也不能一次写好，总会不断对一些词语进行修改。Google DeepMind的文章《DRAW：A Recurrent Neural Network For Image》也和本文异曲同工：画画也不是一次画好，也要不断的完善。不同之处在于本文率先引入DQN做文本生成。在机器学习各个分支下，强化学习和人类与环境的交互方式非常相似，在许多领域开始初露头角，期待看到更多将强化学习结合语言模型的应用。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://120.52.73.76/arxiv.org/pdf/1606.01541v3.pdf" data-editable="true" data-title="Deep Reinforcement Learning for Dialogue Generation" class=""&gt;Deep Reinforcement Learning for Dialogue Generation&lt;/a&gt;&lt;/h1&gt;&lt;h2&gt;作者&lt;/h2&gt;&lt;p&gt;Jiwei Li, Will Monroe, Alan Ritter, Michel Galley, Jianfeng Gao, Dan Jurafsky&lt;/p&gt;&lt;h2&gt;单位&lt;/h2&gt;&lt;p&gt;(1) Stanford University, Stanford, CA, USA(2) Microsoft Research, Redmond, WA, USA(3) Ohio State University, OH, USA&lt;/p&gt;&lt;h2&gt;关键词&lt;/h2&gt;&lt;p&gt;Reinforcement Learning、Seq2Seq、Text Generation&lt;/p&gt;&lt;h2&gt;来源&lt;/h2&gt;&lt;p&gt;arXiv.org(2016.06.25)&lt;/p&gt;&lt;h2&gt;问题&lt;/h2&gt;&lt;p&gt;本文提出利用强化学习进行开放领域的文本生成任务，并对比了有监督的seq2seq加attention模型和基于最大互信息的模型&lt;/p&gt;&lt;h2&gt;模型&lt;/h2&gt;&lt;p&gt;强化学习中的reward&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/41a37779955dd98c73489e7ae6462786.jpg" data-rawwidth="418" data-rawheight="67"&gt;&lt;/p&gt;&lt;p&gt;易被响应（Ease of answering），不容易出现对话僵局，其中 S 是无意义回答合集，s是某一时刻的响应&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/8a4cd62898e6529a1081adf455ec209b.jpg" data-rawwidth="498" data-rawheight="74"&gt;&lt;/p&gt;&lt;p&gt;信息流，若开辟新的话题，有利于对话的继续发展，隐层表示 hpi 和 hpi+1 的夹角余弦&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/d4cb3c510958387b995d38389603a7ab.jpg" data-rawwidth="470" data-rawheight="60"&gt;&lt;/p&gt;&lt;p&gt;语义连贯性，减少与对话无关问题的影响，其中，pseq2seq(a|pi,qi) 是由上一轮状态得到响应的概率，后一项是由当前产生响应通过网络生成之前的 qi 的概率。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/796302276156e6dab686864c3cdde67c.jpg" data-rawwidth="471" data-rawheight="55"&gt;&lt;/p&gt;&lt;p&gt;最终的reward是对三者加权求和，系数分别为：0.25、0.25、0.5.&lt;/p&gt;&lt;p&gt;对比试验：(1) 对话初始状态为一个SEQ2SEQ加attention的模型作为强化学习的初始状态。&lt;/p&gt;&lt;p&gt;(2) 在前面的基础上将最大互信息加入其中作为reward，对于一个给定的输入[pi,qi]，可以根据模型生成一个候选回答集合A。对于A中的每一个回答a,从预训练模型中得到的概率分布上可以计算出互信息的值 m(a,[pi,qi])。&lt;/p&gt;&lt;p&gt;(3) 将互信息训练过的模型作为初始模型，用策略梯度更新参数并加入课程学习策略，最终最多限定五轮对话。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/e230b2395dd90e3491d83701bc3ec152.jpg" data-rawwidth="537" data-rawheight="273"&gt;&lt;/p&gt;&lt;h2&gt;相关工作&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/fbf89747e22b3dde78fded6cb406f50e.jpg" data-rawwidth="618" data-rawheight="199"&gt;&lt;/h2&gt;&lt;h2&gt;简评&lt;/h2&gt;&lt;p&gt;本文作者提出了一个强化学习框架，模拟两个agent让其自动对话训练神经网络SEQ2SEQ模型，将Encoder-Decoder模型和强化学习整合，从而能保证使对话轮数增加。文中使用的模型非常简洁，reward函数定义清晰，评价指标也较为科学，可以生成信息更为丰富、易于响应的对话系统。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://www.aclweb.org/anthology/W10-4204" data-editable="true" data-title="Hierarchical Reinforcement Learning for Adaptive Text Generation"&gt;Hierarchical Reinforcement Learning for Adaptive Text Generation&lt;/a&gt;&lt;/h1&gt;&lt;h2&gt;作者&lt;/h2&gt;&lt;p&gt;Nina Dethlefs, Heriberto Cuay´ahuitl&lt;/p&gt;&lt;h2&gt;单位&lt;/h2&gt;&lt;p&gt;University of Bremen, Germany&lt;/p&gt;&lt;h2&gt;关键词&lt;/h2&gt;&lt;p&gt;NLG, 分层强化学习, 文本生成, wayfinding&lt;/p&gt;&lt;h2&gt;来源&lt;/h2&gt;&lt;p&gt;国际自然语言生成会议INLG(2010)&lt;/p&gt;&lt;h2&gt;问题&lt;/h2&gt;&lt;p&gt;在wayfinding（户内导航对话系统）领域利用分层强化学习进行文本生成。该方法的目标是对wayfinding的NLG任务整合进行优化，并在模拟系统中验证该方法的有效性。&lt;/p&gt;&lt;h2&gt;模型&lt;/h2&gt;&lt;p&gt;本文任务在wayfinding中的NLG任务有多个，且各个任务之间并非独立。从而提出应该根据用户类型，导航距离， 环境条件等作出不同的导航策略，介绍了分层强化学习。&lt;/p&gt;&lt;p&gt;文章将户内导航对话系统的文本生成问题分为四块：&lt;/p&gt;&lt;p&gt;(1) Content Selection：给不熟悉环境的用户的导航要比熟悉环境的用户的导航更细致(2) Text Structure：根据导航距离以及用户熟悉环境程度给予不同类型的导航，如大白话的，以fisrt， second…表达或者示意性的。(3) Referring Expression Generation：一间房间可以叫“A203”，也可以叫“办公室”或者“小白楼”(4) Surface Realisation：往前走可以用“go”也可以用“walk”等。&lt;/p&gt;&lt;p&gt;强化学习示意图如下，分层强化学习的思想与强化学习类似，但在强化学习的基础上加上层次，不同层次的模型处理不同层次的问题。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/84608ba0f6e25f6920b55839fdf3e5ec.jpg" data-rawwidth="275" data-rawheight="187"&gt;&lt;/p&gt;&lt;p&gt;agent根据当前状态，执行动作a与环境交互，之后环境产生一个新的状态s并返回给agent一个奖赏r（可正可负），强化学习的目标函数便是使agent获得奖赏r最大。&lt;/p&gt;&lt;p&gt;分层增强学习包含L个层，每层N个模型，如Figure 1是有15个agents的hierarchy，其中不同的agent负责不同的层次。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/5a8fb2547d568b1efa67b691486a5e87.jpg" data-rawwidth="491" data-rawheight="201"&gt;&lt;/p&gt;&lt;p&gt;每个agent定义为半马尔科夫决策过程，可以表示成一个四元组&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/7d2f305f56718569b40425f4ebea7db7.jpg" data-rawwidth="135" data-rawheight="30"&gt;&lt;/p&gt;&lt;p&gt;分别为状态集，动作集，转换函数，奖励函数。&lt;/p&gt;&lt;p&gt;奖励函数表示agent在时间t状态s是执行动作a转换到新的状态s’所获得的奖励。半马尔科夫的目标是找到policy π*，&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/e7fdd4b0397777e5d2ca885814ed9031.jpg" data-rawwidth="269" data-rawheight="54"&gt;&lt;/p&gt;&lt;p&gt;使得在从当前状态转换到新的状态获得的累计奖励最多。&lt;/p&gt;&lt;p&gt;本文使用两种奖励函数，一种着重在 interaction length， 另一种着重在alignment and variation之间的平衡（具体公式可见论文）。&lt;/p&gt;&lt;p&gt;本文是在模拟环境中进行试验，其中模拟环境包括user type（熟悉环境，不熟悉环境）， information need（高，低），length of the current route（短，中长，长），next action to perform（转，直走），current focus of attention（继续走，关注标识）。baseline为为部分agent随机选择action，即不考虑用户类型，导航距离等因素。经与baseline比较，效果较好。&lt;/p&gt;&lt;h2&gt;资源&lt;/h2&gt;&lt;p&gt;词性标注工具：&lt;a href="http://nlp.stanford.edu/software/tagger.shtml" data-editable="true" data-title="The Stanford Natural Language Processing Group" class=""&gt;The Stanford Natural Language Processing Group&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;简评&lt;/h2&gt;&lt;p&gt;将来的工作：将分层强化学习应用于其他NLG任务不足之处：实验是在模拟环境下进行的，未来应该在真实环境进行评估。&lt;/p&gt;&lt;h1&gt;总结&lt;/h1&gt;&lt;p&gt;这三篇文章皆是强化学习在NLP领域的应用，第一篇主要侧重点在于应用DQN进行文本生成，并用BLUE指标进行评价，对比传统的LSTM-decoder和加入DQN之后的结果；第二篇文章侧重点在于虚拟两个Agent，在传统Seq2Seq的基础上加入强化学习从而使得聊天能够持续下去；第三篇文章侧重点在于任务驱动的对话系统应用分层强化学习，针对不同情况进行分层处理。&lt;/p&gt;&lt;p&gt;以上为本期Paperweekly的主要内容，感谢lshowway、美好时光海苔、Tonya三位同学的整理。&lt;/p&gt;&lt;h1&gt;广告时间&lt;/h1&gt;&lt;p&gt;PaperWeekly是一个分享知识和交流学问的民间组织，关注的领域是NLP的各个方向。如果你也经常读paper，也喜欢分享知识，也喜欢和大家一起讨论和学习的话，请速速来加入我们吧。&lt;/p&gt;&lt;p&gt;微信公众号：PaperWeekly&lt;p&gt;http://weixin.qq.com/r/OUW0rA3ExVC6rUnP9xAr (二维码自动识别)&lt;/p&gt;&lt;/p&gt;&lt;p&gt;微博账号：PaperWeekly（&lt;a href="http://weibo.com/u/2678093863" data-editable="true" data-title="PaperWeekly的微博"&gt;PaperWeekly的微博&lt;/a&gt; ）知乎专栏：PaperWeekly（&lt;a href="https://zhuanlan.zhihu.com/paperweekly" data-editable="true" data-title="PaperWeekly - 知乎专栏"&gt;PaperWeekly - 知乎专栏&lt;/a&gt; ）微信交流群：微信+ zhangjun168305（请备注：加群 or 加入paperweekly）&lt;/p&gt;</description><author>张俊</author><pubDate>Fri, 09 Sep 2016 21:34:21 GMT</pubDate></item><item><title>cs.CL weekly 2016.08.29-2016.09.02</title><link>https://zhuanlan.zhihu.com/p/22293954</link><description>&lt;p&gt;本周（2016.08.29-2016.09.02）质量较高的arXiv cs.CL的paper如下：（点击标题可看原文）&lt;/p&gt;&lt;h1&gt;&lt;a href="http://120.52.73.75/arxiv.org/pdf/1602.06023v5.pdf" data-editable="true" data-title="Abstractive Text Summarization Using Sequence-to-Sequence RNNs and Beyond" class=""&gt;Abstractive Text Summarization Using Sequence-to-Sequence RNNs and Beyond&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;一篇老文的update，seq2seq+attention的机制来解决abstractive text summarization，针对文本摘要的关键问题在基础模型中增加了对关键词、词句层次性和低频词的处理。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://120.52.73.76/arxiv.org/pdf/1608.07905v1.pdf" data-editable="true" data-title="Machine Comprehension Using Match-LSTM and Answer Pointer" class=""&gt;Machine Comprehension Using Match-LSTM and Answer Pointer&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;本文基于Match-LSTM和Answer Pointer两个模型在Stanford Question Answering Dataset (SQuAD)上得到了state-of-the-art的结果。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://120.52.73.75/arxiv.org/pdf/1608.08716v1.pdf" data-editable="true" data-title="Measuring Machine Intelligence Through Visual Question Answering"&gt;Measuring Machine Intelligence Through Visual Question Answering&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;本文指出了image caption作为评测AI效果的任务存在的缺陷，同时提出用visual QA作为评测任务更加有效，并且给出了一个大型Visual QA的数据集。数据集地址：&lt;a href="http://www.visualqa.org" data-editable="true" data-title="VQA: Visual Question Answering"&gt;VQA: Visual Question Answering&lt;/a&gt;.&lt;/p&gt;&lt;h1&gt;&lt;a href="http://120.52.73.79/arxiv.org/pdf/1609.00070v1.pdf" data-editable="true" data-title="How Much is 131 Million Dollars? Putting Numbers in Perspective with Compositional Descriptions" class=""&gt;How Much is 131 Million Dollars? Putting Numbers in Perspective with Compositional Descriptions&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;文章提出了一个好玩的任务，以一个统计数字作为上下文来生成一段简短的描述，描述的内容是一种带有这个数字的观点。整个过程分为两步：公式的构建和观点的生成。&lt;/p&gt;&lt;h1&gt;广告时间&lt;/h1&gt;&lt;p&gt;PaperWeekly是一个分享知识和交流学问的民间组织，关注的领域是NLP的各个方向。如果你也经常读paper，也喜欢分享知识，也喜欢和大家一起讨论和学习的话，请速速来加入我们吧。&lt;/p&gt;&lt;p&gt;微信公众号：PaperWeekly&lt;p&gt;http://weixin.qq.com/r/OUW0rA3ExVC6rUnP9xAr (二维码自动识别)&lt;/p&gt;&lt;/p&gt;&lt;p&gt;微博账号：PaperWeekly（&lt;a href="http://weibo.com/u/2678093863" data-editable="true" data-title="PaperWeekly的微博"&gt;PaperWeekly的微博&lt;/a&gt; ），每天会发布arXiv cs.CL高质量paper和简评。知乎专栏：PaperWeekly（&lt;a href="https://zhuanlan.zhihu.com/paperweekly" data-editable="true" data-title="PaperWeekly - 知乎专栏"&gt;PaperWeekly - 知乎专栏&lt;/a&gt; ）微信交流群：微信+ zhangjun168305（请备注：加群 or 加入paperweekly）&lt;/p&gt;</description><author>张俊</author><pubDate>Sat, 03 Sep 2016 11:49:16 GMT</pubDate></item><item><title>PaperWeekly 第三期</title><link>https://zhuanlan.zhihu.com/p/22279528</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/d89931bc502f2f7326b1aba605d4184e_r.png"&gt;&lt;/p&gt;&lt;h1&gt;引&lt;/h1&gt;&lt;p&gt;历经半个月时间终于发布了新一期PaperWeekly，大家久等了。在这个半个月里，PaperWeekly发生了一些明显的变化。维护和运营从我一个人变成了一个十人左右的团队来一起做，小伙伴们来自全球各地，颠倒着黑夜和白天进行沟通。团队中的每个人都有一颗热爱知识和分享知识的心，都认为分享是一种美德，是一种付出，更是一种回报。可能我们不完美，但我们相信我们正在追求完美的路上坚定地走着。&lt;/p&gt;&lt;p&gt;有了更多的同学加入，PaperWeekly会更加多元化，不再受限于我个人感兴趣的方向和阅读、写作习惯。PaperWeekly会坚持每周发布一期文章，每一期的文章尽量围绕同一个topic展开，在微信公众号、官方微博和知乎专栏会同步更新，除了这一篇文章，我们还会坚持在微博上提供一个新的服务，cs.CL daily，帮助大家过滤掉arXiv cs.CL上比较水的paper，留下质量高的paper，并且用简评的方式分享在微博上，每周末会更新一篇cs.CL weekly出来，将一周值得读的cs.CL paper汇总发布。&lt;/p&gt;&lt;p&gt;PaperWeekly组织了一个高质量的NLP讨论群，只要有你相关的问题，群里的高手会第一时间站出来解答或者讨论你的问题，有的时候会给出一些开源code和相关的paper，提问者、讨论者和潜水者都会有很大的收获。分享paper导读的意义在于讨论，大家一起来讨论，才能更加充分地吸收paper里的营养，这也是我为什么组织一个讨论群的原因。&lt;/p&gt;&lt;p&gt;寒暄的话就说到这里，本期分享的topic是ACL 2016，一共10篇文章，涉及的内容包括：Logic Form、NMT、Summarization、QA、Chatbot等。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://aclweb.org/anthology/P/P16/P16-1073.pdf" data-editable="true" data-title="Sentence Rewriting for Semantic Parsing" class=""&gt;Sentence Rewriting for Semantic Parsing&lt;/a&gt;&lt;/h1&gt;&lt;h2&gt;关键词&lt;/h2&gt;&lt;p&gt;Semantic Parsing、Sentence Rewriting&lt;/p&gt;&lt;h2&gt;来源&lt;/h2&gt;&lt;p&gt;ACL 2016&lt;/p&gt;&lt;h2&gt;问题&lt;/h2&gt;&lt;p&gt;语义分析的表现形式是将自然语言（natural language）转化成逻辑形式（logic form）。因语言表达多样性的问题导致两者间存在mismatch problem。&lt;/p&gt;&lt;h2&gt;文章思路&lt;/h2&gt;&lt;p&gt;先给出一个语义分析的例子：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/72e0e629eadcca4a8bb9a987b066057d.jpg" data-rawwidth="416" data-rawheight="224"&gt;&lt;/p&gt;&lt;p&gt;给句子换个表达（How many people live in Berlin?），对应的逻辑形式就变得复杂很多(count(λx.person(x)∧live(x,Berlin)))。&lt;/p&gt;&lt;p&gt;作者认为，原句子和逻辑形式之间存在的结构不匹配导致了语义分析的困难，而结构不匹配的核心是词汇的不匹配。作者率先提出先把句子重写再转成目标逻辑形式的语义分析方案，如下图：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/e164c5bb6c5fce0fcb9250105e6f3ab4.jpg" data-rawwidth="429" data-rawheight="152"&gt;&lt;/p&gt;&lt;p&gt;针对词汇不匹配问题的两种情况分别给出基于字典和基于模板两种方法。&lt;/p&gt;&lt;p&gt;1）问题一：1-N mismatch是指一个单词（word）对应一个复合的逻辑形式（compound formula）。&lt;/p&gt;&lt;p&gt;例如daughter对应 child ∩ female。但在开放域的知识体系下，制定这些规则十分困难。于是作者提出将句子中的常用名词替换为字典（Wiktionary）中的解释，比如先把刚才的daughter转换为female child，接着再转换为逻辑形式child ∩ female就十分自然了。&lt;/p&gt;&lt;p&gt;2）问题二：N-1 mismatch是指将复杂的自然语言表达对应为单个逻辑表达。&lt;/p&gt;&lt;p&gt;例如将How many people live in Berlin?转化为λx.population(Berlin,x)的分析过程中，How many people live in被对应为逻辑式常量population。如同问题一，这样的规则实在过多，作者的思路是将复杂的表达式转化为简单的形式。&lt;/p&gt;&lt;p&gt;沿用之前的句子来了解算法流程。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/6d59c63aedf120ee27d0b61d309bb890.jpg" data-rawwidth="432" data-rawheight="98"&gt;&lt;/p&gt;&lt;p&gt;Step 1 替换实体生成候选template，例如得到模板how many people live in #y。Step 2 检索template pairs来替换模板，例如找到(a：how many people live in #y, b：what is the population of #y)的模板对，于是将b作为新模板，Step 3 把实体替换回去得到容易生成逻辑形式的what is the population of Berlin。&lt;/p&gt;&lt;h2&gt;相关工作&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/b2e89a59bcd76d62bdf840dd3c6370b8.jpg" data-rawwidth="419" data-rawheight="184"&gt;&lt;/h2&gt;&lt;h2&gt;简评&lt;/h2&gt;&lt;p&gt;如今深度学习在自然语言处理领域大红大紫，也给语义分析的方法带来更多的思考。比如ACL2016另外一篇文章Language to Logical Form with Neural Attention，就把语义分析转换为seq2seq问题，进而使用深度学习的方法来解决。如果我们把词向量这样的表示形式比喻为粗糙的连结主义，那么逻辑表达就好比精细的形式主义。两者各有优势，希望以后会有更多结合两种思想的工作出现。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://aclweb.org/anthology/P/P16/P16-1004.pdf" data-editable="true" data-title="Language to Logical Form with Neural Attention" class=""&gt;Language to Logical Form with Neural Attention&lt;/a&gt;&lt;/h1&gt;&lt;h2&gt;关键词&lt;/h2&gt;&lt;p&gt;Logical Forms, Sequence to Sequence&lt;/p&gt;&lt;h2&gt;来源&lt;/h2&gt;&lt;p&gt;ACL 2016&lt;/p&gt;&lt;h2&gt;问题&lt;/h2&gt;&lt;p&gt;如何把自然语言转化成Structured Logical Forms？&lt;/p&gt;&lt;h2&gt;文章思路&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/2263e1dd44c4bf05b226d3c3b8c69205.jpg" data-rawwidth="353" data-rawheight="213"&gt;&lt;/h2&gt;&lt;p&gt;模型总体是一个encoder-decoder架构，input sequence首先通过LSTM encoder转化成一个vector，然后这个vector通过LSTM decoder被转化成Logical Forms。在decode过程中用到了一个attention layer去获取context信息。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/2bf99675c901b85453aac1c833562a75.jpg" data-rawwidth="306" data-rawheight="301"&gt;&lt;/p&gt;&lt;p&gt;和encoder-decoder模型类似，作者提出了一种hierarchical decoder。与普通的decoder不同，首先，decode之后的sequence中存在一个特殊字符代表nonterminal。在nonterminal的基础上，decoder可以继续进行下一个layer的decoding。每一次decoding的输入不仅包含current hidden state,还包含这一个parent nonterminal的hidden state。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/d125a2f36aa2cb05f32ddc3ab0bb6f84.jpg" data-rawwidth="279" data-rawheight="146"&gt;&lt;/p&gt;&lt;p&gt;作者还使用了一种attention机制，在构建current hidden state的时候将hidden state与所有encoder中的hidden state进行对比，给每一个encoder hidden state一个weight。&lt;/p&gt;&lt;h2&gt;资源&lt;/h2&gt;&lt;p&gt;代码：&lt;a href="https://github.com/donglixp/lang2logic" data-editable="true" data-title="GitHub - donglixp/lang2logic"&gt;GitHub - donglixp/lang2logic&lt;/a&gt;Jobs和GEO数据集：&lt;a href="http://www.cs.columbia.edu/~mcollins/papers/uai05.pdf"&gt;http://www.cs.columbia.edu/~mcollins/papers/uai05.pdf&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;相关工作&lt;/h2&gt;&lt;p&gt;之前的大部分工作都采用一些parsing models，string-to-tree transformation rules，文中没有提到之前有人采用seq2seq/deep learning的方法。本文中使用的seq2seq方法主要来自Kalchbrenner, Blunsom, Cho, Sutskever 在machine translation中提出的模型。&lt;/p&gt;&lt;h2&gt;简评&lt;/h2&gt;&lt;p&gt;本文解决的是一个非常有趣的问题，将自然语言转换成结构化的Logical Forms。试想如果此模型能够很好的解决这个问题，那么将来的各种query language甚至programming languages都可以由自然语言转换而成。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://aclweb.org/anthology/P/P16/P16-1046.pdf" data-editable="true" data-title="Neural Summarization by Extracting Sentences and Words" class=""&gt;Neural Summarization by Extracting Sentences and Words&lt;/a&gt;&lt;/h1&gt;&lt;h2&gt;关键词&lt;/h2&gt;&lt;p&gt;Summarization、Hierarchical Document Encoder、Attention-based Extractor&lt;/p&gt;&lt;h2&gt;来源&lt;/h2&gt;&lt;p&gt;ACL 2016&lt;/p&gt;&lt;h2&gt;问题&lt;/h2&gt;&lt;p&gt;如何使用数据驱动的方法来做提取式摘要？&lt;/p&gt;&lt;h2&gt;文章思路&lt;/h2&gt;&lt;p&gt;本文针对的任务分为sentence和word两个level的summarization。sentence level是一个序列标签问题，每个句子有0或1两个标签，为1表示需要提取该句作为总结。而word level则是一个限定词典规模下的生成问题，词典规模限定为原文档中所有出现的词。&lt;/p&gt;&lt;p&gt;使用的模型也比较有特点，首先在encoder端将document分为word和sentence来encode，word使用CNN encode得到句子表示，接着将句子表示输入RNN得到encoder端隐藏层状态。从word到sentence的encode体现了本文的hierarchical document encoder的概念。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/1dbf5b848521e79a7f0973c1c38095a6.jpg" data-rawwidth="252" data-rawheight="272"&gt;&lt;/p&gt;&lt;p&gt;在decoder端根据任务的不同使用不同网络结构，sentence任务就是一个简单的有监督下二分类问题，使用RNN网络结构更新decoder端隐藏层状态， decoder端隐藏层状态串联encoder端隐藏层状态后接入一个MLP层再接sigmoid激活函数得到句子是否被extract的概率。&lt;/p&gt;&lt;p&gt;word任务则是使用传统的attention-based的方法来计算每个词的概率。但要注意本文的计算的attention不是word-level attention，而是encoder端sentence-level attention。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/4ebfdd69dd0959c7efce04bf69faeb15.jpg" data-rawwidth="294" data-rawheight="199"&gt;&lt;/p&gt;&lt;h2&gt;资源&lt;/h2&gt;&lt;p&gt;数据集：&lt;a href="http://homepages.inf.ed.ac.uk/s1537177/resources.html" data-editable="true" data-title="Jianpeng Cheng" class=""&gt;Jianpeng Cheng&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;相关工作&lt;/h2&gt;&lt;p&gt;之前大多数extractive methods都基于human-engineered特征来给句子建模，通常会对每个句子计算一个分数，然后再使用诸如binary classifiers，hidden Markov模型，graph-based算法或integer linear programming等方法来选择句子构成总结。&lt;/p&gt;&lt;h2&gt;简评&lt;/h2&gt;&lt;p&gt;之前基于data-driven的seq2seq模型在abstractive summarization任务上大放异彩，本文提出了使用类似的模型来解决extractive summarization任务。不过针对的依旧是single-document summarization任务，未来需要将工作拓展至multi-document summarization任务上。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://aclweb.org/anthology/P/P16/P16-2008.pdf" data-editable="true" data-title="Sequence-to-Sequence Generation for Spoken Dialogue via Deep Syntax Trees and Strings" class=""&gt;Sequence-to-Sequence Generation for Spoken Dialogue via Deep Syntax Trees and Strings&lt;/a&gt;&lt;/h1&gt;&lt;h2&gt;关键词&lt;/h2&gt;&lt;p&gt;Sequence to Sequence、Natural Language Generation、Chatbot&lt;/p&gt;&lt;h2&gt;来源&lt;/h2&gt;&lt;p&gt;ACL 2016&lt;/p&gt;&lt;h2&gt;问题&lt;/h2&gt;&lt;p&gt;如何通过小规模、未对齐语料生成对话语句？&lt;/p&gt;&lt;h2&gt;文章思路&lt;/h2&gt;&lt;p&gt;作者介绍了两个模型:&lt;/p&gt;&lt;p&gt;1、通过DA(diglogue acts)生成句法依赖树，再利用external surface realizer，生成语句。（如下图）&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/c4f596e42d0cbe2564aaa449d0318f2c.jpg" data-rawwidth="300" data-rawheight="208"&gt;&lt;/p&gt;&lt;p&gt;2、将两部分结合起来，直接生成语句。步骤如下：&lt;/p&gt;&lt;p&gt;Step 1 将DA(dialogue acts)中的每个slot(表示特定信息)表示成三元组(DA type,slot,value)并结合(下图左)&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/d740d2ced18c5f2f9817074bf7fcb472.jpg" data-rawwidth="506" data-rawheight="105"&gt;&lt;/p&gt;&lt;p&gt;Step 2 基于seq2seq generation technique生出语句或句法依赖树。Step 3 结合beam search和n-best列表重排序（list reranker）以减少输出中的不相关信息。&lt;/p&gt;&lt;h2&gt;资源&lt;/h2&gt;&lt;p&gt;代码: &lt;a href="https://github.com/UFAL-DSG/tgen" data-editable="true" data-title="GitHub - UFAL-DSG/tgen: Statistical NLG for spoken dialogue systems" class=""&gt;GitHub - UFAL-DSG/tgen: Statistical NLG for spoken dialogue systems&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;相关工作&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/f46341b6203fae0cf1e8e493b2ea9b16.jpg" data-rawwidth="415" data-rawheight="189"&gt;&lt;/h2&gt;&lt;h2&gt;简评&lt;/h2&gt;&lt;p&gt;该方法基于广泛使用的seq2seq模型，可以用未对齐的MR对(pair of meaning representation)和句子进行训练，且只要小规模的语料就可以有很好的效果。生成器可以从数据中学会slot的对齐和值，生成流利的domain style)语句，虽然语义错误还是很频繁，但还是取得了不错的成绩。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://aclweb.org/anthology/P/P16/P16-1230.pdf" data-editable="true" data-title="On-line Active Reward Learning for Policy Optimisation in Spoken Dialogue Systems"&gt;On-line Active Reward Learning for Policy Optimisation in Spoken Dialogue Systems&lt;/a&gt;&lt;/h1&gt;&lt;h2&gt;关键词&lt;/h2&gt;&lt;p&gt;Dialogue System、Reinforcement Learning、Online Active Reward Learning&lt;/p&gt;&lt;h2&gt;来源&lt;/h2&gt;&lt;p&gt;ACL 2016&lt;/p&gt;&lt;h2&gt;问题&lt;/h2&gt;&lt;p&gt;文章提出一种在线学习框架，通过高斯过程分类模型进行主动学习，训练对话策略和奖励模型，减少数据标注的花费和用户反馈中的噪声。&lt;/p&gt;&lt;h2&gt;文章思路&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/fe153e783f983fa26d47572c287cf66a.jpg" data-rawwidth="415" data-rawheight="215"&gt;&lt;/h2&gt;&lt;p&gt;框架分为三部分：对话策略、对话嵌入函数、用户反馈主动奖励模型。&lt;/p&gt;&lt;p&gt;无监督学习输入为双向LSTM，通过Encoder-Decoder模型表征用户意图，将对话的成功与否看做高斯过程的一个二元分类问题，当模型对当前结果不能评判时，主动学习，通过reward模型决定是否询问用户反馈，当模型不确定时，生成增强信号来训练策略。&lt;/p&gt;&lt;h2&gt;资源&lt;/h2&gt;&lt;p&gt;数据集：&lt;a href="http://camdial.org/~mh521/dstc/" class=""&gt;http://camdial.org/~mh521/dstc/&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;相关工作&lt;/h2&gt;&lt;p&gt;1、之前的工作有用任务完成度和对话持续情况做Reward，但任务完成度不好衡量2、用协同过滤表征用户偏好3、用逆强化学习从行为中推出reward&lt;/p&gt;&lt;h2&gt;简评&lt;/h2&gt;&lt;p&gt;用lSTM Encoder-Decoder表征用户意图，无需大规模标注语料和构建用户模拟器来进行训练，在较小的训练语料中取得了不错的效果，率先实现了在真实场景中的应用。但Reward函数只关心对话任务是否成功，模型过于简单。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://aclweb.org/anthology/P/P16/P16-1100.pdf" data-editable="true" data-title="Achieving Open Vocabulary Neural Machine Translation with Hybrid Word-Character Models" class=""&gt;Achieving Open Vocabulary Neural Machine Translation with Hybrid Word-Character Models&lt;/a&gt;&lt;/h1&gt;&lt;h2&gt;关键词&lt;/h2&gt;&lt;p&gt;Neural Machine Translation、UNK Words&lt;/p&gt;&lt;h2&gt;来源&lt;/h2&gt;&lt;p&gt;ACL 2016&lt;/p&gt;&lt;h2&gt;问题&lt;/h2&gt;&lt;p&gt;如何解决机器翻译中的未登录词问题？&lt;/p&gt;&lt;h2&gt;文章思路&lt;/h2&gt;&lt;p&gt;文章提出了一个混合（层次）模型。该模型由两部分组成，分别为：a. 传统的基于词（word level）的seq2seq模型；b. 基于字母级别（character level）的LSTM模型，由一个将字母encode成单词的encoder和一个根据状态生成低频词的decoder组成。其中a部分负责进行翻译，b部分负责处理低频词（unk）。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/eed844a1612a8d83285452ee2b8d4576.jpg" data-rawwidth="230" data-rawheight="336"&gt;&lt;/p&gt;&lt;p&gt;具体地，a部分的encoder遇到unk时，会使用character level对该低频词进行encode，并使用encode出的representation作为输入。而decoder遇到unk时，会利用attention机制将当前上下文和LSTM状态初始化character level decoder。此处的初始化采用的是文章提出的separate path模式，即利用一个MLP作为character level decoder的初始化网络。值得注意的是此处word level decoder仍会选择用作为下一步的输入。&lt;/p&gt;&lt;h2&gt;相关工作&lt;/h2&gt;&lt;p&gt;Unk问题属于NMT中长期存在问题。目前多是采取后处理的方法。今年ACL有两篇paper，分别是李航老师实验室的copynet和Bengio实验室的pointing the unknown words，但对机器翻译任务参考意义有限。另外一种思路则是加大词典，比较知名工作有On Using Very Large Target Vocabulary for Neural Machine Translation。此外该工作还借鉴了Jiwei Li的hierarchical auto encoder。&lt;/p&gt;&lt;h2&gt;简评&lt;/h2&gt;&lt;p&gt;文章思路新颖且简单明了。因为NMT中存在unk的问题，作者直接利用character level RNN来生成一个词替代unk。该工作对拼音文字有一定意义，对中日韩文的参考意义有限。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://aclweb.org/anthology/P/P16/P16-1014.pdf" data-editable="true" data-title="Pointing the Unknown Words" class=""&gt;Pointing the Unknown Words&lt;/a&gt;&lt;/h1&gt;&lt;h2&gt;关键词&lt;/h2&gt;&lt;p&gt;Neural Machine Translation、UNK Words&lt;/p&gt;&lt;h2&gt;来源&lt;/h2&gt;&lt;p&gt;ACL 2016&lt;/p&gt;&lt;h2&gt;问题&lt;/h2&gt;&lt;p&gt;如何解决机器翻译中的未登录词问题？&lt;/p&gt;&lt;h2&gt;文章思路&lt;/h2&gt;&lt;p&gt;作者在有注意力的机器翻译模型上增加了一个开关来判断和是否复制原文。&lt;/p&gt;&lt;p&gt;1、Attention-based机器翻译模型&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/6836206b755db6d279c8b0766360a2ce.jpg" data-rawwidth="333" data-rawheight="175"&gt;经典的attention model这里不再赘述。&lt;/p&gt;&lt;p&gt;2、Pointer Softmax模型&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/cef9064f7a3972c554d344a782836b4d.jpg" data-rawwidth="380" data-rawheight="203"&gt;&lt;/p&gt;&lt;p&gt;两个问题有待解决解决：a. 是否进行copy？b. copy的位置在哪？&lt;/p&gt;&lt;p&gt;先说第二个问题，作者先引入shortlist softmax和location softmax。前者来确定要从shortlist中选取哪一个单词作为输出，后者确定在哪个位置要进行copy操作。&lt;/p&gt;&lt;p&gt;再看第一个问题，作者引入一个二值变量（可以想象为一个开关）来选择使用shortlist softmax还是location softmax。当值为1的时候不进行copy操作，使用shortlist softmax来从shortlist中选一个词作为输出。当值为0的时候进行copy操作，使用location softmax，将原文的词直接copy到指定位置。&lt;/p&gt;&lt;h2&gt;资源&lt;/h2&gt;&lt;p&gt;代码：&lt;a href="https://github.com/caglar/pointer_softmax" data-editable="true" data-title="GitHub - caglar/pointer_softmax"&gt;GitHub - caglar/pointer_softmax&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;简评&lt;/h2&gt;&lt;p&gt;本文的想法很有趣，直接从原文照抄罕见词和未知词很符合日常生活中人类的处理方法。从文中实验结果来看，该模型有一定的提升效果。注意力模型的提出与对人类行为的观察密不可分，而copy机制也是从生活中提炼出来的一种有效模型，我们可以借鉴的是从人类解决问题的具体方式中进行总结和归纳不失为一种有效的解决方案。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://aclweb.org/anthology/P/P16/P16-1228.pdf" data-editable="true" data-title="Harnessing Deep Neural Networks with Logic Rules" class=""&gt;Harnessing Deep Neural Networks with Logic Rules&lt;/a&gt;&lt;/h1&gt;&lt;h2&gt;关键词&lt;/h2&gt;&lt;p&gt;CNN、RNN、First-order Logic, Iterative Distillation Method&lt;/p&gt;&lt;h2&gt;来源&lt;/h2&gt;&lt;p&gt;ACL 2016&lt;/p&gt;&lt;h2&gt;问题&lt;/h2&gt;&lt;p&gt;如何将深度学习与逻辑规则结合使用？&lt;/p&gt;&lt;h2&gt;文章思路&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/ca52f6aa241d9fa7725c356f313d102a.png" data-rawwidth="447" data-rawheight="227"&gt;&lt;/h2&gt;&lt;p&gt;系统在构建正常神经网络(student)的同时，构建了一个基于逻辑规则的训练网络(teacher)。整个网络的目标还是优化神经网络的参数变量 θ，因为新的目标损失函数结合了二者的损失，通过这种方式，教师网络的逻辑信息就能够被转移到神经网络的θ上，从而加强神经网络的性能。 在这种结构里逻辑规则是用于辅助的可选项，通过调整权重，系统可以偏向某个网络。这种模型可以将监督学习扩展到无监督学习，比如图示中，无标记的数据通过教师子网之后提取有用信息，也可以用来训练监督学习的神经网络。&lt;/p&gt;&lt;p&gt;1、训练过程&lt;/p&gt;&lt;p&gt;假设输入数据为x, y。student神经网络的参数变量是θ, 输出层是softmax，对输入xn，输出预测概率分布σ(xn)。对teacher网络，在第ｔ次迭代中基于逻辑规则的预测结果表示为sn(t)，那么新的优化目标变成了&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/1ada851124622357827bcee6b400e724.png" data-rawwidth="421" data-rawheight="101"&gt;&lt;/p&gt;&lt;p&gt;可以看出来自教师网络的反馈作为regularization加到了目标函数里，通过这种方式两个网络的信息就结合在了一起。注意教师网络在每次训练迭代中都要构建，因此整个过程被称之为iterative knowledge distillation.&lt;/p&gt;&lt;p&gt;2、教师网络&lt;/p&gt;&lt;p&gt;教师网络使用软逻辑(soft logic)来编码first-order logic的信息。soft logic在[0,1]之间的连续取值，而不是二元值{0, 1}。逻辑运算也用max, min, sum代替原来的与或非。&lt;/p&gt;&lt;p&gt;神经网络数学模型为pθ(y|x) 教师网络数学模型假设为q(y|x)。我们实际上是用基于逻辑规则的教师网络来模拟神经网络输出，因此我们希望能找到一个最优的q，使得输入尽可能满足逻辑规则的要求，同时q要尽可能接近pθ。详细推导可以参见原文，最后的优化结果就是&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/7f6f7b9551453db16adcb9c02a13fa90.png" data-rawwidth="457" data-rawheight="97"&gt;&lt;/p&gt;&lt;p&gt;λl 是每个规则的自信度(confidence)，而rl, gl 是某个规则应用于某一输入时的逻辑结果，介于0,1之间。可以看到自信度比较高的规则可以使输入更容易通过规则。&lt;/p&gt;&lt;p&gt;3、应用&lt;/p&gt;&lt;p&gt;a. 基于CNN的情感分析b. 基于BLSTM-CNN的NER任务&lt;/p&gt;&lt;h2&gt;相关工作&lt;/h2&gt;&lt;p&gt;1、Neural-symbolic systems (Garcez et al., 2012) 从给定的规则构建推理网络2、(Collobert 2011)， 利用领域知识domain knowledge提取额外特征，增强原始数据3、Knowledge distillation (Hinton et al., 2015) (Bucilu et al. 2006)4、Posterior regularization (PR) method (Ganchev et al., 2010)&lt;/p&gt;&lt;h2&gt;简评&lt;/h2&gt;&lt;p&gt;创新点在于将逻辑规则与神经网络结合，可以利用人已知的知识去引导机器学习。当数据量不足的，或者对数据进行补充时，可以将人类的知识用逻辑语言表达出来，然后通过本文提出的框架进行增强训练。本文的两个例子中都提到只用了少量规则，优化的结果虽然显示要比当前其他模型好，但是没有大幅度的提高。需要进一步验证如果使用更多的规则，能不能大幅度提高准确率。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://aclweb.org/anthology/P/P16/P16-1043.pdf" data-editable="true" data-title="Easy Questions First? A Case Study on Curriculum Learning for Question Answering" class=""&gt;Easy Questions First? A Case Study on Curriculum Learning for Question Answering&lt;/a&gt;&lt;/h1&gt;&lt;h2&gt;关键词&lt;/h2&gt;&lt;p&gt;Curriculum Learning、Self-paced Learning、Question Answering&lt;/p&gt;&lt;h2&gt;来源&lt;/h2&gt;&lt;p&gt;ACL2016&lt;/p&gt;&lt;h2&gt;问题&lt;/h2&gt;&lt;p&gt;文章讨论了Curriculum Learning在NLP领域, 尤其是在QA task里应用的可行性。&lt;/p&gt;&lt;h2&gt;文章思路&lt;/h2&gt;&lt;p&gt;文章首先对QA类型的task给出了比较general的定义: 我们可以把QA问题看做是一个经验风险最小化(ERM)问题, 我们需要最小化:&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/27e5903f5012534c885cb908b17220b3.jpg" data-rawwidth="204" data-rawheight="49"&gt;&lt;/p&gt;&lt;p&gt;其中是a正确答案, f是给定背景知识以及问题, 模型选择出的最佳答案,Ω是regularizer.&lt;/p&gt;&lt;p&gt;之后, 作者对于Curriculum Learning, 尤其是Self-paced Learning做了介绍, 并且将其引入QA task, 进而将之前的ERM问题变为:&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/0810353ef81edd235cb8915fb6274bee.jpg" data-rawwidth="277" data-rawheight="58"&gt;&lt;/p&gt;&lt;p&gt;其中v是对问题进行采样时候的权值, g是self-paced regularizer, 其中λ代表’age’, 或者说’pace’. 训练初期, 模型趋向于对简单的问题进行训练, 而随着’age’的增加, 模型越来越多地加入更复杂的问题一起训练。&lt;/p&gt;&lt;p&gt;文章给出并分析了四种流行的self-paced regularizer如Table 1:&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/b72b5a9134355f25b4b6ba48acc9903c.jpg" data-rawwidth="350" data-rawheight="168"&gt;&lt;/p&gt;&lt;p&gt;之后提出了7种新的heuristics:&lt;/p&gt;&lt;p&gt;1) Greedy Optimal (GO): 将已有的Q和一系列新的Q一起训练, 选回答正确并且loss最低的。2) Change in Objective (CiO): 将已有的Q和一系列新的Q一起训练, 选择令loss改变最小的。3) Mini-max (M2 ): 当某个新的Q与其loss最大的一个candidate answer配对时, loss最小的. (通俗地讲, 就是最差情况都没有那么糟糕的一个)。4) Expected Change in Objective (ECiO): 只拿新的Q训练, 和之前的loss改变最小的. (相比于第二种的将已有的Q和新Q一起训练)。5) Change in Objective-Expected Change in Objective (CiO - ECiO): 2)和4)的值最接近的, 按照作者的意思, 这个值反应了model见到某个新Q时surprise的程度。6) Correctly Answered (CA): 将一系列新Q在当前model上测试, 选择用最小的loss正确回答的。7) Farthest from Decision Boundary (FfDB): 只用在latent structural SVMs上, 选择答案与decision boundary最远的一个新Q。&lt;/p&gt;&lt;h2&gt;资源&lt;/h2&gt;&lt;p&gt;MCTest: &lt;a href="http://research.microsoft.com/en-us/um/redmond/projects/mctest/" data-editable="true" data-title="Machine Comprehension Test (MCTest)" class=""&gt;Machine Comprehension Test (MCTest)&lt;/a&gt;Science Textbook: &lt;a href="http://http//www.ck12.org/" data-editable="true" data-title="http://http://www.ck12.org/"&gt;http://http://www.ck12.org/&lt;/a&gt;Science question answering: &lt;a href="http://aristo-public-data.s3.amazonaws.com/AI2-Elementary-NDMC-Feb2016.zip" data-editable="true" data-title="amazonaws.com 的页面"&gt;http://aristo-public-data.s3.amazonaws.com/AI2-Elementary-NDMC-Feb2016.zip&lt;/a&gt;Simple English Wikipedia: &lt;a href="https://dumps.wikimedia.org/simplewiki/20151102/" data-editable="true" data-title="wikimedia.org 的页面"&gt;https://dumps.wikimedia.org/simplewiki/20151102/&lt;/a&gt;QANTA: &lt;a href="https://cs.umd.edu/~miyyer/qblearn/" data-editable="true" data-title="QANTA: A Deep Question Answering Model"&gt;QANTA: A Deep Question Answering Model&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;相关工作&lt;/h2&gt;&lt;p&gt;1、Curriculum Learning:&lt;/p&gt;&lt;p&gt;早在1958年[1], 就有认知科学的相关学者意识到, 对于人类学习过程, 相对于提供随机的知识,由浅及深的地给予有计划的训练样本, 可以得到更好的效果. 之后这一Curriculum Learning的想法也被引入到机器学习中[2], 其中Self-paced learning (SPL)[3][4][5]是比较常用的方法。&lt;/p&gt;&lt;p&gt;2、QA:&lt;/p&gt;&lt;p&gt;Jurafsky和Martin[6]对于QA系列问题有一个非常好的叙述, 而这篇文章突出讨论Curriculum Learning在non-convex的QA模型上的应用, 着重介绍了基于配对的模型[7][8][9]和基于深度学习的模型[10][11].基于配对的模型将每一个问题和问题附带的多个备选答案组成若干个QA对, 我们称之为假设, 然后在给定相关文章的情况下, 寻找有最可能是正确的一个假设作为答案. 基于深度学习的模型可以使用依赖关系树结构的递归神经网络, 对句子level的QA模型的结果取平均[10]; 也可以用RNN构建”长期”存储器, 通过学习对存储器进行读/写操作, 模拟一个动态的知识构建过程[11]。&lt;/p&gt;&lt;h2&gt;简评&lt;/h2&gt;&lt;p&gt;在QA task中引入Curriculum Learning旨在在训练过程中, 启发式地对于提供给模型的数据出现的顺序进行一些调整, 从而让模型从简单的, 易于学习的样本开始, 随着模型对数据的表述愈加成熟, 逐渐加入更复杂的样本. 理想状况下这会指导模型从得到一个普通的local minima, 变成得到一个”更”好的local minima, 进而利用全部数据得到一个”更更”好的local minima。&lt;/p&gt;&lt;p&gt;通常来说, 我们给予模型的heuristic并不一定能够真正帮助模型, 因为通常我们都在猜测数据以及模型的latent representation是什么, 但是这篇文章通过了一系列的实验验证, 本文阐述的heuristic确实可以帮助QA model获得更好的准确率. 这证明了引导模型由浅及深的这种思路是可行的, 我们也许可以思考一些更复杂的heuristic, 或者将其应用到其他的一些NLP tasks。&lt;/p&gt;&lt;p&gt;然而本文给出的大部分heuristic在新问题的选择上都需要比较大的时间复杂度, 对于类似MCTest这种总共只有660个文章的小型数据集来说还算比较现实, 但是对于更大更长的数据集(比如CNN数据集, 38万个文章, 很多文章都超过了一千五百个单词, 而且备选答案数量也远超MCTest的四个)时, 就显得不那么轻松了. 最简单的Attention Sum Reader[1] 在CNN数据集上, 每个epoch都需要10个多小时, 就更别说其他基于AS Reader的模型了。&lt;/p&gt;&lt;p&gt;总体来说, 相对于实用性, 这篇文章更多在于提供了一种新的思路, 也就是把Curriculum Learning相关的概念应用到QA乃至于其他NLP task中, 非常值得思考, 因此是一篇非常值得阅读的文章。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://aclweb.org/anthology/P/P16/P16-1144.pdf" data-editable="true" data-title="The LAMBADA dataset:Word prediction requiring a broad discourse context" class=""&gt;The LAMBADA dataset:Word prediction requiring a broad discourse context&lt;/a&gt;&lt;/h1&gt;&lt;h2&gt;关键词&lt;/h2&gt;&lt;p&gt;Machine Reading Comprehension、Dataset&lt;/p&gt;&lt;h2&gt;来源&lt;/h2&gt;&lt;p&gt;ACL 2016&lt;/p&gt;&lt;h2&gt;问题&lt;/h2&gt;&lt;p&gt;构建了一个难度更大的机器阅读理解数据集。&lt;/p&gt;&lt;h2&gt;构建思路&lt;/h2&gt;&lt;p&gt;以Book Corpus的小说作为数据源，构建了10222个passages，每个passage包括平均4.6句话的context和相邻着的一句target，定义的任务是通过理解context来预测target中最后一个词，平均每个passage包括约75个tokens。其中，超过80%的passage context中包括了target中需要预测的词，48%的target words是专有名词（proper nouns），37%的词是一般名词（common nouns），约7.7%的是动词。这里，专有名词和一般名词是最难猜出来的，动词有一定的概率可以不需要context，而直接从target sentence利用语言模型猜出来。&lt;/p&gt;&lt;p&gt;在处理原始数据时，作者做了一层过滤，将容易从target sentence中直接猜出target word的passages统统丢掉，将剩下的部分放在众包网站上进行人工筛选，筛选的过程比较长，目的是让留在数据集中的数据有下面的效果：通过分析passage的context可以给出正确的target word，而如果只是给定target sentence的话，是猜不出正确的target word。&lt;/p&gt;&lt;h2&gt;资源&lt;/h2&gt;&lt;p&gt;本文数据集Lambada dataset: &lt;a href="http://clic.cimec.unitn.it/lambada/" data-editable="true" data-title="cimec.unitn.it 的页面"&gt;http://clic.cimec.unitn.it/lambada/&lt;/a&gt;众包网站Crowdflower: &lt;a href="http://www.crowdflower.com/" data-editable="true" data-title="Make your data useful"&gt;Make your data useful&lt;/a&gt;原始数据集Book Corpus: &lt;a href="http://www.cs.toronto.edu/~mbweb/"&gt;http://www.cs.toronto.edu/~mbweb/&lt;/a&gt;CNN/Daily Mail dataset: &lt;a href="https://github.com/deepmind/rc-data" data-editable="true" data-title='GitHub - deepmind/rc-data: Question answering dataset featured in "Teaching Machines to Read and Comprehend'&gt;GitHub - deepmind/rc-data: Question answering dataset featured in "Teaching Machines to Read and Comprehend&lt;/a&gt;CBT dataset: &lt;a href="http://fb.ai/babi/"&gt;http://fb.ai/babi/&lt;/a&gt;MSRCC dataset: &lt;a href="https://www.microsoft.com/en-us/research/publication/the-microsoft-research-sentence-completion-challenge/" data-editable="true" data-title="The Microsoft Research Sentence Completion Challenge"&gt;The Microsoft Research Sentence Completion Challenge&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;相关数据集&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/5b0d691a539f4cf8001773af649bc8be.png" data-rawwidth="1086" data-rawheight="620"&gt;&lt;/h2&gt;&lt;h2&gt;简评&lt;/h2&gt;&lt;p&gt;大型数据集是深度学习技术发展的重要基础，数据集的质量和难度也直接关系着模型的质量和实用性。机器阅读理解的数据集有很多，包括中文和英文的数据集，每一个的构建都会带来模型的创新，随着难度不断增加，对模型也提出了更高的要求。本文在构建数据集过程中为了保证任务的难度所采取的方法是值得借鉴的。&lt;/p&gt;&lt;h1&gt;致谢&lt;/h1&gt;&lt;p&gt;本期的10篇文章由以下同学完成：&lt;/p&gt;&lt;p&gt;苏辉、Xiaoyu、胡小明、赵越、周青宇、韩晓伟、Eric Yuan、Zewei Chu、tonya、张俊。&lt;/p&gt;&lt;p&gt;感谢大家地辛勤付出。&lt;/p&gt;&lt;h1&gt;广告时间&lt;/h1&gt;&lt;p&gt;PaperWeekly是一个分享知识和交流学问的民间组织，关注的领域是NLP的各个方向。如果你也经常读paper，也喜欢分享知识，也喜欢和大家一起讨论和学习的话，请速速来加入我们吧。&lt;/p&gt;&lt;p&gt;微信公众号：PaperWeekly&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/8e2b86789f8cddf7e423e1c07d39ce0a.jpg" data-rawwidth="430" data-rawheight="430"&gt;&lt;/p&gt;&lt;p&gt;微博账号：PaperWeekly（&lt;a href="http://weibo.com/u/2678093863" data-editable="true" data-title="PaperWeekly的微博"&gt;PaperWeekly的微博&lt;/a&gt; ）知乎专栏：PaperWeekly（&lt;a href="https://zhuanlan.zhihu.com/paperweekly" data-editable="true" data-title="PaperWeekly - 知乎专栏"&gt;PaperWeekly - 知乎专栏&lt;/a&gt; ）微信交流群：微信+ zhangjun168305（请备注：加群 or 加入paperweekly）&lt;/p&gt;</description><author>张俊</author><pubDate>Fri, 02 Sep 2016 11:27:40 GMT</pubDate></item><item><title>cs.CL weekly 2016.08.22-2016.08.26</title><link>https://zhuanlan.zhihu.com/p/22184043</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/c3c8fdc44ec223b1d89e130afa476975_r.png"&gt;&lt;/p&gt;&lt;h1&gt;简介&lt;/h1&gt;&lt;p&gt;这个栏目是将一周内arxiv cs.CL刷出的好文进行一个简单的汇总，并配有一句话总结，旨在帮助大家过滤掉cs.CL上的水文，并且为PaperWeekly团队选文提供高质量paper。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://120.52.73.78/arxiv.org/pdf/1608.05852v1.pdf" data-editable="true" data-title="Learning Word Embeddings from Intrinsic and Extrinsic Views" class=""&gt;Learning Word Embeddings from Intrinsic and Extrinsic Views&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;本文提出了一种依靠intrinsic (descriptive) and extrinsic (contextual) information来学习词向量的方法，有效解决了传统方法中对低频词学习存在的问题。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://120.52.73.78/arxiv.org/pdf/1608.06043v1.pdf" data-editable="true" data-title="Context Gates for Neural Machine Translation"&gt;Context Gates for Neural Machine Translation&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;本文提出了一种context gate来动态地控制机器翻译中source、target context对word generation的影响，实验证明在BLEU指标下比attention-based的方法提高了2.3。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://120.52.73.80/arxiv.org/pdf/1608.05777v1.pdf" data-editable="true" data-title="Topic Sensitive Neural Headline Generation"&gt;Topic Sensitive Neural Headline Generation&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;本文针对传统模型中忽略topical similarities和differences of documents的问题，提出了一种新方案，先将documents按照topics分类，每一类中的pattern比较接近，然后再做sentence level summary，得到了更好的效果。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://120.52.73.77/arxiv.org/pdf/1608.06378v1.pdf" data-editable="true" data-title="Towards Machine Comprehension of Spoken Content: Initial TOEFL Listening Comprehension Test by Machine"&gt;Towards Machine Comprehension of Spoken Content: Initial TOEFL Listening Comprehension Test by Machine&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;本文以托福听力题作为数据集，尝试对多媒体信息进行理解。听力问题是听完一段话，理解之后，进行4选1，而不是之前常见的cloze-style理解任务。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://120.52.73.79/arxiv.org/pdf/1608.07076v1.pdf" data-editable="true" data-title="A Context-aware Natural Language Generator for Dialogue Systems"&gt;A Context-aware Natural Language Generator for Dialogue Systems&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;本文的模型是一种端到端的模型，根据上下文和用户说话的方式来生成对话。是一篇SIGDIAL 2016 short paper。配套的代码已发布于&lt;a href="https://github.com/UFAL-DSG/tgen" data-editable="true" data-title="Github"&gt;Github&lt;/a&gt;&lt;/p&gt;&lt;h1&gt;About&lt;/h1&gt;&lt;p&gt;对NLP高质量原创内容和讨论感兴趣的你，赶快来关注：&lt;/p&gt;&lt;p&gt;1、PaperWeekly&lt;a href="http://weibo.com/2678093863/" data-editable="true" data-title="官方微博"&gt;官方微博&lt;/a&gt;&lt;/p&gt;&lt;p&gt;2、PaperWeekly官方微信&lt;/p&gt;&lt;p&gt;3、PaperWeekly&lt;a href="https://zhuanlan.zhihu.com/paperweekly" data-editable="true" data-title="知乎专栏"&gt;知乎专栏&lt;/a&gt;&lt;/p&gt;&lt;p&gt;4、PaperWeekly微信交流群（+微信zhangjun168305入群）&lt;/p&gt;</description><author>张俊</author><pubDate>Fri, 26 Aug 2016 09:52:06 GMT</pubDate></item><item><title>从api.ai工作原理来看构建简单场景chatbot的一般方法</title><link>https://zhuanlan.zhihu.com/p/22139158</link><description>&lt;h1&gt;引&lt;/h1&gt;&lt;p&gt;chatbot无疑是当前非常火的一个研究领域和产品方向，简单地可以分为两类，开放域bot和封闭域bot，开放域bot倾向于解决所有的事情，而封闭域bot倾向于解决某一个细分领域中的事情，旨在用AI技术提高效率，提高生产力。现阶段的开放域bot我个人感觉更像是多个常用封闭域bot的叠加，当用户发起一个请求，系统会判断出属于哪个细分领域，然后转到相应的程序中去执行并给出反馈，顺着这个逻辑来看，研究简单场景下的chatbot是个重要的基础工作，这类研究或者产品的质量直接决定了复杂场景或者开放域bot的质量。当然逗乐型的bot并不属于本文讨论的范围。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/d35833c83746938c0418be1102f05222.png" data-rawwidth="715" data-rawheight="487"&gt;图片来自paper &lt;a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/06/williams2016dstc_overview-1.pdf" data-editable="true" data-title="The Dialog State Tracking Challenge Series- A Review" class=""&gt;The Dialog State Tracking Challenge Series- A Review&lt;/a&gt;&lt;/p&gt;&lt;p&gt;chatbot是场交互革命，也是一个多技术融合的平台。上图给出了构建一个chatbot需要具备的组件，简单地说chatbot = NLU(Natural Language Understanding) + NLG(Natural Language Generation).(本文只关注NLP相关的技术，对语音识别并无讨论)&lt;/p&gt;&lt;p&gt;对于封闭域的chatbot，NLU的工作就是DST(Dialog State Tracker)，用户给出输入之后，系统可以给出下面的形式作为state：&lt;/p&gt;&lt;p&gt;Act(Slot=Value)&lt;/p&gt;&lt;p&gt;Act表示用户行为的类型，比如请求、查询、打招呼等等；Slot表示用户输入中包含的某种Act下的Entity，比如查询酒店的位置、价格这些实体；Value是指Slot中Entity对应的值，比如位置在北边，价格在500-800之间等等。每一句话中可能包括多个Act-Slot-Value对，chatbot需要做的事情就是准确地识别出Act，并且抽取出相应的Slot和Value。&lt;/p&gt;&lt;p&gt;紧接着是NLG的部分，前几天在&lt;a href="http://rsarxiv.github.io/2016/08/16/PaperWeekly-%E7%AC%AC%E4%BA%8C%E6%9C%9F/" data-editable="true" data-title="PaperWeekly第二期"&gt;PaperWeekly第二期&lt;/a&gt;中分享了三篇paper，其中两篇正是研究基于DST的NLG问题。&lt;/p&gt;&lt;p&gt;本文首先从&lt;a href="http://rsarxiv.github.io/2016/08/21/%E4%BB%8Eapi-ai%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86%E6%9D%A5%E7%9C%8B%E6%9E%84%E5%BB%BA%E7%AE%80%E5%8D%95%E5%9C%BA%E6%99%AFchatbot%E7%9A%84%E4%B8%80%E8%88%AC%E6%96%B9%E6%B3%95/api.ai" data-editable="true" data-title="api.ai"&gt;api.ai&lt;/a&gt;这家企业提供的服务说起，通过研究其提供的封闭域bot构建技术，来提炼构建简单场景chatbot的一般方法，为构建复杂场景或者找出现有chatbot存在的技术问题和面临的技术难点打下基础。&lt;/p&gt;&lt;h1&gt;api.ai&lt;/h1&gt;&lt;h2&gt;api.ai公司介绍&lt;/h2&gt;&lt;blockquote&gt;&lt;p&gt;Api.ai provides developers and companies with the advanced tools they need to build conversational user interfaces for apps and hardware devices.&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;这家公司是一家典型的B2D公司，提供了一些工具帮助开发者轻松地开发一款bot，并且可以轻松地发布到各种message平台上。商业模式也非常简单，免费用户有一定次数的调用权限，需要大量调用的话，则付费购买，不同的权限有不同的价格，该公司也提供高级定制化服务。&lt;/p&gt;&lt;p&gt;api.ai公司成立于2010年（数据来自&lt;a href="https://www.crunchbase.com/organization/api-ai#/entity" data-editable="true" data-title="CrunchBase"&gt;CrunchBase&lt;/a&gt;），其早期业务不清楚，但可以从提供的服务中推断出早期攒了大量的用户数据，而且涉及的领域非常多，比如：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/822f16a29b4bc7fc5b0ced5ca1babe24.png" data-rawwidth="803" data-rawheight="716"&gt;&lt;/p&gt;&lt;p&gt;每个领域都有一个知识库，如果你要开发某个常用领域内的chatbot，那么这个知识库将会非常有用。&lt;/p&gt;&lt;h2&gt;重要概念和工作原理&lt;/h2&gt;&lt;h3&gt;重要概念&lt;/h3&gt;&lt;p&gt;1、Agents。这个是一个对外接口，与其他应用程序或你的app进行整合的部分。如下图：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/862ce5730fccea058b464f052db430da.png" data-rawwidth="712" data-rawheight="180"&gt;&lt;/p&gt;&lt;p&gt;2、Entities。这里的实体和引言中提到的Slot类似，是指某个特定领域内的实体，是一类东西的抽象概括，比如HotelName这一实体，对应着很多的酒店名字，凯宾斯基、如家等等。有Entity，就一定有value，chatbot中重要的一步正是从user input中抽取出对应预先设定好entity的value，是一个典型的Named Entity Recognition任务。&lt;/p&gt;&lt;p&gt;这里经典的NER任务是识别出user input中的person、time、place等等几个基本元素，api.ai将这些常见的entity定义为system级的，即默认提供了训练好的识别器，当然不仅仅限于这几类基本的；而特定领域知识库的重要作用也正是在于识别该领域内的entity。除了system level的NER之外，需要developer自定义一些entity，比如菜名，而且要给定具体的菜名和相似的表达作为samples进行训练。&lt;/p&gt;&lt;p&gt;3、Intents。这个相当于是从user input到chatbot执行某个action之间的一个映射关系，用户输入一句话之后，chatbot就可以理解其意图，是在打招呼，还是查询，还是做些别的事情。这部分api.ai提供了训练器，但是需要developer定义一些标注好的examples，标注的形式如下：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/31c5390934afe103b1f780fca0bf0e37.png" data-rawwidth="1466" data-rawheight="1160"&gt;&lt;/p&gt;&lt;p&gt;这里用户输入是book a ticket to Los Angeles on Monday，所谓标注包括两个level，一个是entity标注，一个是intent标注，前一个是为了训练NER工具，后一个是为了识别intent。这里因为LA是地名，Monday是时间，所以都会被api.ai的系统自动标注出来。&lt;/p&gt;&lt;p&gt;4、Actions。这个是由intents进行trigger的，actions就和引言中的Act类似，是一个具体的动作，比如说查询，但执行动作的时候一般都要带上具体的参数value，用户输入：“三里屯最近的阿迪达斯店在什么位置？”，chatbot首先会提取出place-&amp;gt;三里屯，query-&amp;gt;阿迪达斯店，然后转换为json丢给后台的查询服务，查询到结果后给出答案。这里的value抽取其实就是第二个概念提到的entity value。&lt;/p&gt;&lt;p&gt;5、Contexts。上下文是一个非常重要但却解决不是很好的点，api.ai提供的方式是自定义一些context condition，当condition满足时，自动trigger出context关联内容template，然后filling slots，生成response。&lt;/p&gt;&lt;h3&gt;工作原理&lt;/h3&gt;&lt;p&gt;以RSarXiv chatbot为例，简单介绍下工作原理。（注：RSarXiv是我之前写的一个arxiv paper推荐系统）&lt;/p&gt;&lt;p&gt;step 1 自定义Entity，这里我定义了两个entities，一个是keywords和subject。keywords是为search功能提供value，而subject是为update new papers功能提供value。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/278517664dda186155dcd5f359ff5ff5.png" data-rawwidth="633" data-rawheight="217"&gt;定义好subject entity之后，我给出了几个examples，同时也包括其synonyms，keywords entity类似。&lt;/p&gt;&lt;p&gt;step 2 自定义Intents，这里我定义了两个Intents，分别是update和search。下图是update的examples，是我自定义的几个例子。api.ai会根据我定义好的entity进行自动标注，比如cs.CL，today是系统默认的entity所以也进行了自动标注。自动标注是为了后台的机器学习算法对标注好的examples进行学习，以提高chatbot的NLU准确率。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/4d0f72e49ec1fb1aa681547effdbf533.png" data-rawwidth="639" data-rawheight="375"&gt;&lt;/p&gt;&lt;p&gt;接下来，我需要定义下Actions，如下图：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/73d4d50e3bf5d5b45c8702e9b180783f.png" data-rawwidth="637" data-rawheight="321"&gt;Action被称为update，必须包含的参数是subject，也就是我们上面讲到的一个entity，date参数并不是必须的。所以，这里如果用户的input被识别出是update intents的话，就必须包括subject参数，否则chatbot会trigger一个response，类似“请用户输入subject”这样的话。&lt;/p&gt;&lt;p&gt;step 3 简单测试，在界面的右侧有一个console，用来测试当前chatbot的效果，我输入update cs.CL，得到下面的效果：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/2b06d3f59031301dafb0a8766f3d636c.png" data-rawwidth="337" data-rawheight="622"&gt;chatbot识别出Intent是Update，Action是update，Parameter是date和subject，并且subject的值是cs.CL，下面的Show JSON是api.ai为developer生成的，用来与developer自己的web service进行数据交换。&lt;/p&gt;&lt;p&gt;step 4 训练。训练包括两个部分，一是训练NER，二是训练Intent Classification。训练器是api.ai提供的，但是标注数据是developer自己提供的，当然训练数据越多，标注越准，分类器的准确率就越高，chatbot的NLU准确率越高。至于训练方法，docs中没有细说，我简单猜测一下，NER可以当做Sequence Labeling任务，和Intent Recognition类似，都可以看作是多分类问题，不管是传统的分类方法还是当下流行的deep learning方法都能得到不错的准确率。随着user logs的增多，训练数据会越来越多，chatbot通过学习就会变得越来越“聪明”。但这里有个问题，training data越多，需要标注或者修改标注的数据就会越多，也是一个麻烦事儿。&lt;/p&gt;&lt;p&gt;step 5 整合、发布。api.ai支持的平台非常多，包括当下流行的message平台，还有各种操作系统平台。在message平台上提供了一键整合的功能，在操作系统上提供了SDK。这里我用了slack平台，api.ai打通了和slack的接口，也提供了webhook，连接了我之前写好的web service，只需要按照它给定的消息接口进行定义即可。&lt;/p&gt;&lt;h3&gt;demo&lt;/h3&gt;&lt;p&gt;目前RSarXiv只提供两个简单的功能，一个是update今天最新的arxiv paper，你可以通过show me new papers in cs.CL等类似的话来获取cs.CL这个领域中最新的paper；一个是search功能，你可以通过search LSTM等类似的话来获取包括LSTM这个关键词的paper。由于是一个测试用的demo，就没做什么复杂的功能。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/026f59e0668853eede457ebe43756cfc.png" data-rawwidth="635" data-rawheight="387"&gt;&lt;/p&gt;&lt;p&gt;大家如果感兴趣的话，可以留言给我或者发邮件给我(mcgrady150318@gmail.com/mcgrady150318@163.com)，我邀请大家到这个slack team中。&lt;/p&gt;&lt;h1&gt;简单场景chatbot构建方法&lt;/h1&gt;&lt;p&gt;介绍了下api.ai提供的服务，下面简单地提炼一下。&lt;/p&gt;&lt;p&gt;chatbot = NLU + NLG&lt;/p&gt;&lt;p&gt;api.ai解决的重点问题是NLU的问题，NLU也是Dialogue State Tracker(DST)的核心和基础，而DST是chatbot的核心。这里的NLU包括两个问题：&lt;/p&gt;&lt;p&gt;1、从user inputs中识别出user intent和对应的action。&lt;/p&gt;&lt;p&gt;2、从user inputs中抽取出预先设定好的entity value，作为action的parameter。&lt;/p&gt;&lt;p&gt;NLG在api.ai这里基本上通过developer在Intent中设定response，当识别出是哪个intent之后，response自然就有了，最多空一些slot，用结果进行填充。如果developer选择了webhook，即需要从自定义的web service中给定response。如下图：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/a8dcdd37586477d5bfd0ef3304d22863.png" data-rawwidth="642" data-rawheight="199"&gt;&lt;/p&gt;&lt;p&gt;跑了一个简单场景的chatbot demo之后，简单归纳下构建方法：&lt;/p&gt;&lt;p&gt;1、从特定任务中归纳出Intents、Actions、Entities。&lt;/p&gt;&lt;p&gt;2、分别编写Intents、Entities的examples，两类examples是做DST的基础，用来训练chatbot准确地识别user intents和entity parameters，至于算法，自己写也可以，用api.ai也可以。&lt;/p&gt;&lt;p&gt;3、做好DST之后，chatbot就知道用户的意图和相应的参数，丢给后台的web service去执行，并得到执行的结果，然后填充预先定义好的templates，生成response，返回给用户。&lt;/p&gt;&lt;h1&gt;结束语&lt;/h1&gt;&lt;p&gt;简单场景的chatbot关键之处在于做好DST，有一个叫Dialogue State Tracking Challenge的比赛正式为了解决这个问题而举办的。我们说，封闭域的chatbot涉及两个方面，一是NLU，一是NLG，前者通过大量的examples来学习一个分类器和抽取器，得到Dialogue State，而后者根据Dialogue State，生成合适的response。&lt;/p&gt;&lt;p&gt;NLU不是一个简单的事情，尤其是标注大量的examples不是那么容易；NLG同样也不是一个好解决的问题，预先定义的template会让chatbot受限制于template的多少，手工痕迹太重，需要一种更牛的解决方案来代替。（其实挺多paper都在做这件事情，PaperWeekly也分享过几篇相关的paper，data driven的NLG方案同样需要大量的examples做训练。）&lt;/p&gt;&lt;p&gt;Context是个挺难的事情，现有的、成熟的解决方案仍是手工来定义条件，然后根据条件来trigger。我在想，能否构建一个动态的DST，可以是一张动态hash table，也可以是一个动态graph，记录着某一个user方方面面的状态，而不仅仅是某一轮对话中抽取出的信息，而是多轮对话中的信息，不仅在intent识别中可以用到context，在生成response时也可以用到，多轮对话和个性化对话都将不是什么问题了。或者，用现在流行的表示学习思维来想这个问题的话，也许context可以是一个分布式表示，user profile也是一个表示，NLG时以context distribution为condition来做generatation。&lt;/p&gt;&lt;p&gt;本文介绍了构建简单场景下chatbot的一般方法，用api.ai确实很容易做一个chatbot，而对于复杂场景，我觉得用api.ai来开发也没有太大问题，最费时的可能是构建context trigger。api.ai因为是面向developer的，所以对于普通的用户并不适合，但对于有一定经验的developer来说，使用起来就非常简单，提供的web界面也很好用，如果说chatbot是一个平台的话，那么api.ai正像是一个开发工具，提高了开发chatbot的效率，虽然NLG和context这两个问题可以做的更好，但整体来说降低了开发chatbot的门槛，是个很有意义和钱景的服务。&lt;/p&gt;&lt;h1&gt;PaperWeekly招人广告&lt;/h1&gt;&lt;p&gt;PaperWeekly每周会分享N篇当下最流行、最有趣的NLP paper，旨在用最精炼的话说明白paper的贡献和创新。目前运营在公众号和知乎专栏两个平台上，现在的形式是每周分享一篇NLP Paper周报，偶尔也会写一些NLP相关的博客，由于本人精力和水平有限，现邀请各位对NLP技术、NLP Paper感兴趣的童鞋加入一同运营，在推进国内NLP技术发展的路上贡献一份自己的力量。&lt;/p&gt;&lt;p&gt;微信公众号：PaperWeekly&lt;/p&gt;&lt;p&gt;http://weixin.qq.com/r/OUW0rA3ExVC6rUnP9xAr (二维码自动识别)&lt;/p&gt;&lt;p&gt;知乎专栏：&lt;a href="https://zhuanlan.zhihu.com/paperweekly" data-editable="true" data-title="PaperWeekly"&gt;PaperWeekly&lt;/a&gt;&lt;/p&gt;&lt;p&gt;微信交流群：&lt;/p&gt;&lt;p&gt;群已满100人，无法扫码加群，大家加zhangjun168305，我拉大家入群。&lt;/p&gt;</description><author>张俊</author><pubDate>Tue, 23 Aug 2016 13:44:24 GMT</pubDate></item><item><title>PaperWeekly FAQ</title><link>https://zhuanlan.zhihu.com/p/22133533</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/b5fea40c59029d4f648955c56fda4deb_r.jpg"&gt;&lt;/p&gt;&lt;p&gt;Q：Why do PaperWeekly?&lt;/p&gt;&lt;p&gt;A：最初的初衷是为了督促自己看paper，然后记录下读每篇paper中get到的一些收获。因为自己一直笃信厚积薄发，相信坚持每天读一篇paper，经过一定时间的沉淀一定会有所进步，有所收获。在做PaperWeekly的同时，认识了很多志同道合的朋友，也从他们的身上学到了很多。&lt;/p&gt;&lt;p&gt;Q：PaperWeekly现在准备做什么？&lt;/p&gt;&lt;p&gt;A：paperweekly在某一段时间内有一点名不副实，因为更新速度太快，几乎做成了daily，工作日更新一篇paper，在周末的时候写一篇总结性的文章。频繁地更新占用了几乎所有的业余时间，经过一番思考，决定将PaperWeekly改版成一周一篇，回归真正的weekly，具体的形式可以参考最近的两期paperweekly，形式可能还会改变，目的是为了更好给大家提供更好的服务。&lt;/p&gt;&lt;p&gt;Q：What‘s Next？&lt;/p&gt;&lt;p&gt;A：由于个人精力和水平都非常有限，所以非常希望邀请一些志同道合的朋友来运营PaperWeekly，你可以是学生，可以是工程师，可以是老师等等。只要你热爱，并且喜欢分享知识，都可以私信我。在PaperWeekly你可以推荐一些好玩的paper，也可以推荐好玩的topic，也可以推荐自己的paper，只要你愿意，当然我更希望你可以一起加入作者团队，来写文章。&lt;/p&gt;&lt;p&gt;Q：关于方向？&lt;/p&gt;&lt;p&gt;A：目前只限定方向是NLP领域的，因为如果领域太过分散的话，大家难以讨论在一起，所以这里限定了只接受NLP领域的paper。&lt;/p&gt;&lt;p&gt;Q：PaperWeekly的周边？&lt;/p&gt;&lt;p&gt;A：在运营paperweekly之前，写了一个微信公众号、ios app和一个网站，作用都是帮助用户更方便地从arxiv搜索和推荐paper，如果你对开发感兴趣，如果你有那么一点点业余时间想要做点什么东西出来或者学点python或者web开发、或者实现一些具体的算法，可以考虑加入paperweekly的周边开发项目rsarxiv，一起将我之前写的比较naive的arxiv检索和推荐应用更加完善化。关于paper检索，我有很多很多有趣的想法，苦于没有时间和精力来实现，如果你感兴趣，请一定私信我。&lt;/p&gt;&lt;p&gt;Q：关于bot化？&lt;/p&gt;&lt;p&gt;A：最近一直在看bot的paper，前几天看着api.ai的docs，实现了一个chatbot demo，功能是基本的检索和每日paper的update，bot放在slack平台上，如果你感兴趣的话，可以考虑将你的邮箱私信给我或者发邮件给我，我的邮箱是mcgrady150318@163.com(gmail同名)，我将邀请你加入slack team，来试用下这个chatbot demo。&lt;/p&gt;&lt;p&gt;Q：关于报酬？&lt;/p&gt;&lt;p&gt;A：我可能给不了显性的报酬，但我相信用自己的业余时间来运营paperweekly，以及开发一些program，都会让你学习到很多很多东西，这些东西可能是一些小恩小惠给不了你的。另外，由于paperweekly的关系，认识一些行业大牛、媒体和投资人，如果你创业、找工作或者是需要媒体宣传，我想我可以给你一点点微弱的帮助。&lt;/p&gt;&lt;p&gt;Q：具体招聘？&lt;/p&gt;&lt;p&gt;A：PaperWeekly目前需要招聘N名作者（N可能是5左右），基本要求：对NLP感兴趣，对paper感兴趣，喜欢写东西，喜欢分享知识。周边的Program可以锻炼动手能力，因为要写一个实实在在的paper推荐系统和搜索系统，涉及的平台也比较多，包括流行的chatbot，以及一些很有趣的功能，比如多paper summary摘要等。如果你对python感兴趣，也想动手实现一个系统的话，可以考虑加入paperweekly。&lt;/p&gt;&lt;p&gt;感谢大家对paperweekly的关注和支持，希望大家可以通过交流群有所收获，找到志同道合的朋友，找到一起合作的作者，找到一个满意的工作，找到一个靠谱的合伙人。如果需要加入paperweekly群聊，请添加微信zhangjun168305，我会拉大家入群。&lt;/p&gt;</description><author>张俊</author><pubDate>Tue, 23 Aug 2016 08:50:32 GMT</pubDate></item><item><title>PaperWeekly招人启事</title><link>https://zhuanlan.zhihu.com/p/22127821</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/b5fea40c59029d4f648955c56fda4deb_r.jpg"&gt;&lt;/p&gt;&lt;p&gt;PaperWeekly每周会分享N篇当下最流行、最有趣的NLP paper，旨在用最精炼的话说明白paper的贡献和创新。目前运营在公众号和知乎专栏两个平台上，现在的形式是每周分享一篇NLP Paper周报，偶尔也会写一些NLP相关的博客，由于本人精力和水平有限，现邀请各位对NLP技术、NLP Paper感兴趣的童鞋加入一同运营，在推进国内NLP技术发展的路上贡献一份自己的力量。&lt;/p&gt;&lt;p&gt;微信公众号：PaperWeekly&lt;/p&gt;&lt;p&gt;http://weixin.qq.com/r/OUW0rA3ExVC6rUnP9xAr (二维码自动识别)&lt;/p&gt;&lt;p&gt;知乎专栏：&lt;a href="https://zhuanlan.zhihu.com/paperweekly" data-editable="true" data-title="PaperWeekly"&gt;PaperWeekly&lt;/a&gt;&lt;/p&gt;&lt;p&gt;微信交流群：&lt;/p&gt;&lt;p&gt;http://weixin.qq.com/g/A9hjSVG1RjX0GRlw (二维码自动识别)&lt;/p&gt;&lt;p&gt;群人数超过了100人，无法扫码加入了，请大家添加zhangjun168305，然后我拉大家入群。&lt;/p&gt;</description><author>张俊</author><pubDate>Mon, 22 Aug 2016 17:59:32 GMT</pubDate></item><item><title>PaperWeekly 第二期</title><link>https://zhuanlan.zhihu.com/p/22062882</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/d35833c83746938c0418be1102f05222_r.png"&gt;&lt;/p&gt;&lt;h1&gt;引&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/d35833c83746938c0418be1102f05222.png" data-rawwidth="715" data-rawheight="487"&gt;&lt;/h1&gt;&lt;p&gt;图片来自paper &lt;a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/06/williams2016dstc_overview-1.pdf" data-editable="true" data-title="The Dialog State Tracking Challenge Series- A Review" class=""&gt;The Dialog State Tracking Challenge Series- A Review&lt;/a&gt;&lt;/p&gt;&lt;p&gt;人机对话系统通常包括上面的几个部分，task-oriented chatbot重点关注的是DST和NLG问题，其中DST是核心问题，没有太多关注这个比赛，但个人理解DST的作用类似于一张user conversation logs状态表，记录着用户当前的状态，以订机票为例，这张表的key是预先设定好的slots，比如目的地、出发地、出发时间等等，与系统背后的业务数据表中的attributes相关联，不断地从user conversation中抽取相应的values来填充这个表格，或者将其定义为一个多分类任务，不断地从对话中判断这句话中包括哪些slots和values（这里的values是多个分类结果），当状态表中的信息存在空白时，bot会根据空白的slots来提问并获取values，直到获取到足够的slots，给出用户suggestion，或者进行相应的服务。&lt;/p&gt;&lt;p&gt;DST的问题解决之后，就是NLG的问题。传统的NLG采用rule-based或者template-based的方法，需要很多的手动设置，横向扩展性较差，维护成本高。最近流行的end-to-end方案很适合解决这个问题，给定用户的query，结合着当前DST，自动生成response，完全的data driven，不需要什么人工干预。&lt;/p&gt;&lt;p&gt;生成response除了rule-based和end-to-end的方法之外，工业界中更加常见的是retrieve-based的方法，即从庞大的example base中进行retrieve，一方面避免了NLG生成response时常遇到的grammatical问题，另一方面当前的IR技术很容易集成到此类bot系统中，降低了门槛。&lt;/p&gt;&lt;p&gt;本期的三篇paper中前两篇都是关于task-oriented bot的NLG问题，第三篇是在retrieve-based bot的每个细小环节中应用了deep learning技术，并且将外部的非结构化文本作为数据源，从中select responses。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://www.emnlp2015.org/proceedings/EMNLP/pdf/EMNLP199.pdf" data-editable="true" data-title="Semantically Conditioned LSTM-based Natural Language Generation for Spoken Dialogue Systems"&gt;Semantically Conditioned LSTM-based Natural Language Generation for Spoken Dialogue Systems&lt;/a&gt;&lt;/h1&gt;&lt;h2&gt;关键词：NLG、bot、自定义LSTM&lt;/h2&gt;&lt;h2&gt;来源：EMNLP 2015&lt;/h2&gt;&lt;h2&gt;问题：task-oriented bot NLG问题，给定了user query和DST，如何生成一个更好的response？&lt;/h2&gt;&lt;h2&gt;方法：&lt;/h2&gt;&lt;p&gt;首先定义了两个概念delexicalisation和lexicalisation，前一个的意思是将句子中的slot-value用特定的token来替换，像是一种抽象，比如用food来代替对话中的各种食物名称；后一个的意思是将句子中的特定token还原回具体的value。&lt;/p&gt;&lt;p&gt;本文最大的亮点在于将传统的LSTM重新定义，针对这个具体问题在LSTM cell部分中添加了一层，Dialogue Act Cell，通过gate机制来保留合适的信息，比如slot keywords，如下图：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/366ff46deb8fe7c697076ec5d98cdca7.png" data-rawwidth="364" data-rawheight="351"&gt;&lt;/p&gt;&lt;p&gt;这一层cell更像是一个keyword detectors，整个NLG仍是采用encoder-decoder框架。&lt;/p&gt;&lt;h2&gt;评论：&lt;/h2&gt;&lt;p&gt;这层Dialogue Act Cell的目的是确保在decoding部分，不会遗漏任何一个slot，所以专门增加了一层cell来encoding act、slot-value信息，在生成时作为context vector。我觉得model的这个设计与attention机制有一点类似，只是attention更加地平滑，对每个word都有一个weight，而不是本文中的gate，非0即1。整体来说，自定义的cell是一个很有启发性的思路，针对具体问题的特点，修改现有的cell结构，也许会起到非常关键的作用。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://101.110.118.75/128.84.21.199/pdf/1606.03632v1.pdf" data-editable="true" data-title="Natural Language Generation in Dialogue using Lexicalized and Delexicalized Data"&gt;Natural Language Generation in Dialogue using Lexicalized and Delexicalized Data&lt;/a&gt;&lt;/h1&gt;&lt;h2&gt;关键词：NLG、bot、自定义LSTM&lt;/h2&gt;&lt;h2&gt;来源：arXiv 2016.06.11 cs.CL&lt;/h2&gt;&lt;h2&gt;问题：task-oriented bot NLG问题，是第一篇的升级版。&lt;/h2&gt;&lt;h2&gt;方法：&lt;/h2&gt;&lt;p&gt;本文是针对第一篇文章进行的改进版，改进的地方在于不仅仅利用了delexicalisation进行训练，而且利用了lexicalisation数据，从而提高了准确率，基本的模型框架与第一篇文章类似，不同的在于输入的处理，就是dialogue act的表示，如下图：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/14800a4bf548445cceace53803f8e649.png" data-rawwidth="392" data-rawheight="223"&gt;&lt;/p&gt;&lt;p&gt;每一个act representation由两部分组成，一部分是act、slots的one-hot表示，与文章一类似的结构，另一部分是由value的每个word embedding组合而成。&lt;/p&gt;&lt;p&gt;task-oriented bot NLG存在的一个更加现实的问题是data规模太小，cover的features太少，生成质量不高，本文针对这一问题，用相似domain的、大量的reviews或者其他相关数据作为corpus预训练出一个效果不错的LM，在decoding部分采用预训练好的LM模型权重进行NLG。&lt;/p&gt;&lt;h2&gt;评论：&lt;/h2&gt;&lt;p&gt;本文中最值得借鉴的地方在于transfer learning，虽然DL效果很好，但实际应用中常常遇到data规模太小的问题，DL难以发挥作用，但如果从大量相似的domain data中学习一些表示模型，然后迁移到待解决的问题上，这是一件幸事，也就是人们常说的举一反三。混合大量的相似domain数据，会cover到更丰富的features，为DL提供了广阔的舞台。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://aclweb.org/anthology/P16-1049" data-editable="true" data-title="DocChat: An Information Retrieval Approach for Chatbot Engines Using Unstructured Documents"&gt;DocChat: An Information Retrieval Approach for Chatbot Engines Using Unstructured Documents&lt;/a&gt;&lt;/h1&gt;&lt;h2&gt;关键词：Retrieve-Based Bot，Unstructured Documents&lt;/h2&gt;&lt;h2&gt;来源：ACL 2016&lt;/h2&gt;&lt;h2&gt;问题：如何从大量非结构化文本中select出合适的response返回给用户？&lt;/h2&gt;&lt;h2&gt;方法：&lt;/h2&gt;&lt;p&gt;本文研究的问题是给定大量的非结构化的documents和用户的query，从中选择并返回一个满意的response，典型的IR问题，作者将解决方案分为三步：&lt;/p&gt;&lt;p&gt;1、response检索，根据query，从documents中找到合适的N句话作为候选。&lt;/p&gt;&lt;p&gt;2、response排序，将候选中的utterances进行排序。&lt;/p&gt;&lt;p&gt;本文大多数的工作在ranking model上，提出了7种level的features来对candidate进行打分，通过实验发现sentence-level feature最有区分度。&lt;/p&gt;&lt;p&gt;3、response触发，并不是一定可以从documents找到合适的response，所以最后添加一个分类器，来判断最优的response是否合适，合适则输出，不合适则输出空。&lt;/p&gt;&lt;h2&gt;评论：&lt;/h2&gt;&lt;p&gt;本文解决的问题思路比较简单，但中间用到了很多复杂的DL model，个人感觉有点杀鸡用牛刀。本文的思路更加适合informative式的query，并不适合娱乐和闲聊。但用外部知识，尤其是大量的非结构化的、可能还带有噪声的资源来提供response，是一个很不错的思路，弥补了只用training data或者很有限的examples存在的局限性问题，如果可以将两者进行结合，是一个非常好的实用方案。&lt;/p&gt;&lt;h1&gt;Tips&lt;/h1&gt;&lt;p&gt;引起大家的讨论是一件挺难的事情，所以这一期不再提出问题。之前有同学问如何读paper，这里简单分享一个简单的tip，后续的每一期可能都会分享一个tip。&lt;/p&gt;&lt;p&gt;1、如果刚刚进入一个领域，建议读一些这个领域的survey或review类型的paper，这类型的paper基本上会将最近的方法归类进行总结，从一个较高的层次来解读每一篇paper的贡献和优缺点，对快速了解一个领域很有帮助。如果你关注的这个领域没有survey，那么恭喜你，说明你可能走到了前沿，用关键词去google一篇或者几篇相关的new paper，读Related Work那一节，相信你会有所收获。（注：这个方法是从清华大学刘知远博士那里学来的）&lt;/p&gt;</description><author>张俊</author><pubDate>Thu, 18 Aug 2016 07:06:31 GMT</pubDate></item><item><title>pet,baby and bot</title><link>https://zhuanlan.zhihu.com/p/22033341</link><description>&lt;p&gt;本文的想法来源于某一天对家里狗子Hare一些行为以及身边两个不到3岁的小朋友一些聪明行为的观察和思考，然后将这些行为和思考与当前流行的bot联系一下，形成了本文的内容。&lt;/p&gt;&lt;p&gt;首先，从pet聊起。我家养了一只聪明的小泰迪狗，心眼特别多，会撒娇会打滚会安慰人，非常聪明，他叫Hare。Hare从两个月大到了家里，从开始什么都不会，通过一天天地训练，学会了走、跑、跳、吃饭、喝水、上厕所、坐下、握手和哭。因为他的外婆（我的丈母娘）每天都和他说很多话，教他认识很多东西，所以他可以轻松地分辨出哪个玩具叫什么名字，可以轻松地理解我们说的很多话，不只是一些口令。当我说出门不带他玩的话，他会非常悲伤、可怜地开始哭泣（真的和小孩子哭一模一样）；当我说带他出去的时候，他就会非常兴奋地上蹿下跳；当我说我要出门办事不可以带他的时候，他就乖乖坐在门口目送你走，不哭不闹。所以，我在想Hare应该不是简单地通过观察我们的脸色和语气来识别我们的情绪，他可能真的听得明白很多的话，但一定不是全部，因为他的知识很有限，对这个世界的认识也很有限。Hare的学习绝大多数是监督学习，通过一些正例和负例进行训练，大多数的训练用正例效果非常明显，唯独训练他上厕所，用了不少负例，让他吃了不少苦头，这也带来不少的好处，监督学习很花费时间，样本的量级很重要，通过大量的训练+激励让Hare养成了良好的习惯，成为了一只听话的pet。&lt;/p&gt;&lt;p&gt;我一直在思考一个问题，pet在听主人说话的时候，是听懂了某些他可以理解的关键词还是他确实听懂了整句话，到底是字面意思还是semantic level呢？我想他应该有一定的自主学习能力，做到举一反三可能很难，但举一反二还是有可能的，而不仅仅是从大量的examples中进行学习，确实能够理解一些简单的话，同一个意思的不同说法他都可以理解。科学的解释需要做些实验来研究，这里我有一些简单的解释，第一，他有大脑，虽然没有人类发达，但智商可以和5、6岁的孩子相媲美；第二，他的监督学习不仅仅是从query-response pairs这样的examples中进行，而是更多的维度，包括每一次action之后的激励reward，做对一次动作之后赢得一个奖励，做错了受到惩罚，他不仅仅从主人的语言中来理解意思，还会结合别的因素，比如语调、语境、前一个时刻他的状态等等，而且他可以看到主人的表情和动作，这些因素都可以抽象成一种context。Hare如果前一秒刚刚犯了低级错误，这一秒如果我拿一个零食的叫他过来来吃的话，他就会明白，这其中一定有诈，他一定不会过来，虽然我并没有表现出生气的样子。&lt;/p&gt;&lt;p&gt;pet的事情我们先聊到这里，接下来聊一聊baby的事情。&lt;/p&gt;&lt;p&gt;身边正好可以接触到两个不到三岁的小宝宝，一个男孩一个女孩，他们有很多聪明的行为都让我感到吃惊。先从小男孩说起，小男孩每次来一起吃饭的时候，都会给大家表演他的绝技——认车牌。走在路上，你随意指一辆车，他几乎可以不出错地说出这辆车是本田还是丰田、还是起亚，这是一个典型的有监督多分类学习任务，他的父母有意无意地教他认识各种各样的车，经过一定时间和example的积累，他不断地将准确率提升，可能大脑的发育和将deep learning模型不断地复杂化道理类似吧。学习的过程是积累知识的过程，小男孩慢慢地认识了越来越多的车子，当然这需要不断地教和学，但无疑他本身就是一个知识库（knowledge base），而且认识很多我都不认识的车子，所以当我问他那是什么车的时候，他总是能够给我一个不错的答案。&lt;/p&gt;&lt;p&gt;说完小男孩的事情，再聊一聊小女孩的事情。小女孩语言能力很强，可以说很多的话，而且很多话都非常的funny。基本上和小女孩聊天，就是一个有趣的问答过程，这里的问答不只是我问她答，还有她问我答。小女孩经常和我妈妈在一起，妈妈会教她认识各种东西，因为妈妈信基督教，会教她做祷告，保佑自己一生平安，所以说她不仅仅可以回答一些基本的认知问题，而且有自己的特殊技能，表演“祷告”，而且做的有模有样。她是个求知欲非常强的问题宝宝，她总是指着一个东西，然后开始问我，“这是个什么东西？”，她主动学习的欲望很强，这意味着她的知识库积累地很快。以上都是比较常规的，最值得思考的是她的创造力。她认识很多的动物，也知道怎么称呼这些动物，她根据家里每一个人的名字，起了相应的动物外号，这个不是谁教她的，是她自己说出来的东西；之前提到的祷告词中，原话应该是希望上帝可以赐给她一些聪明智慧，那天在给我们“表演”的时候说出来的是“给她弄一些聪明智慧”，我想这个“弄一些”一定是其他的地方学来的，但她迁移到了这个语境中，这个迁移能力是值得思考的。我们都说理解一个东西不算厉害，如果能够掌握或者控制一个东西才算真正的厉害，她如果只是简单地重复已经学会的知识，也并不稀奇，但她偶尔会有意地装糊涂，故意地说一些错的东西看你能不能识别出来她的错误，她对一些信息的掌握程度很高。&lt;/p&gt;&lt;p&gt;小盆友的创造力让人惊奇，有很多值得思考的地方，相比于pet来说，baby的学习能力更强，带给人的惊喜度更大。chatbot，一个热门的topic，一个大家每天都在谈论的东西，确实还有很长的路要走，太多的地方不能令人满意。&lt;/p&gt;&lt;p&gt;1、最简单的一问一答现在都没有做的很好，example-based和rule-based虽然可以work，但限制太大，前者被example所限制，而后者被rule所限制，而paper中近一段时间流行的所谓generative式的bot看起来好像非常智能，读过paper之后会发现仍是基于example统计的，不管多么牛的模型，都是从example中学习features，example的规模和类型都会严重制约model，而且在生成response时面临着连贯性和语言学的问题，这也是被诟病最多的地方，也就是为什么example-based retrieve式的方法仍是主流的原因。&lt;/p&gt;&lt;p&gt;2、bot应该像人一样具有学习能力，尤其是主动学习能力。现在的bot有self-taught的能力，通常比较被动，并不具备主动学习的意识和能力。bot公司宣传的学习能力也通常是指对log的挖掘，从中找到一些有用的东西存在知识库里，丰富现有的example base。bot可以试着多提一些question，而不仅仅是做answer，主动地学习一些东西。&lt;/p&gt;&lt;p&gt;3、对context的利用和分析还有很长的路要走，context有很多种，如果是纯粹的语言bot，那么就是user之前说过的话，user的情绪，user的意图等等，如果不仅仅是语言的话，正如前面在说pet时提到的，context可以包括图像、语调等等。考虑的东西越多，bot的回答质量就会越高。&lt;/p&gt;&lt;p&gt;4、前几天看了几家科技媒体对新一代微软小冰的报道，说实话丢出挺多概念的，仔细看了下是用增强学习的思路来做，和训练pet比较类似，用一个reward作为牵引，带着bot学习programmer希望bot学习的action。&lt;/p&gt;&lt;p&gt;5、人会举一反三，聪明的动物会举一反二，迁移能力很重要，bot学习过类似的东西，就应该可以做类似的事情，而不是每次都需要重新从头开始学习，如何将已经学习到的知识迁移到新的领域也是一个非常有意义的topic。&lt;/p&gt;&lt;p&gt;从pet到baby，再到bot，从动物到人类，再到机器人，有着难以跨越的鸿沟，但pet、baby的行为可以带来启发和思考，给目前仍停留在初步阶段的bot带来一丝春风，一丝希望。&lt;/p&gt;</description><author>张俊</author><pubDate>Tue, 16 Aug 2016 11:18:41 GMT</pubDate></item></channel></rss>