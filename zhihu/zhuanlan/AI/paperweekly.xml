<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>PaperWeekly - 知乎专栏</title><link>https://zhuanlan.zhihu.com/paperweekly</link><description>每周会分享N篇nlp领域好玩的paper，旨在用最少的话说明白paper的贡献。同时也运营一个公众号，PaperWeekly，欢迎大家关注。</description><lastBuildDate>Fri, 09 Sep 2016 04:16:29 GMT</lastBuildDate><generator>Ricky</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>cs.CL weekly 2016.08.29-2016.09.02</title><link>https://zhuanlan.zhihu.com/p/22293954</link><description>&lt;p&gt;本周（2016.08.29-2016.09.02）质量较高的arXiv cs.CL的paper如下：（点击标题可看原文）&lt;/p&gt;&lt;h1&gt;&lt;a href="http://120.52.73.75/arxiv.org/pdf/1602.06023v5.pdf" data-editable="true" data-title="Abstractive Text Summarization Using Sequence-to-Sequence RNNs and Beyond" class=""&gt;Abstractive Text Summarization Using Sequence-to-Sequence RNNs and Beyond&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;一篇老文的update，seq2seq+attention的机制来解决abstractive text summarization，针对文本摘要的关键问题在基础模型中增加了对关键词、词句层次性和低频词的处理。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://120.52.73.76/arxiv.org/pdf/1608.07905v1.pdf" data-editable="true" data-title="Machine Comprehension Using Match-LSTM and Answer Pointer" class=""&gt;Machine Comprehension Using Match-LSTM and Answer Pointer&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;本文基于Match-LSTM和Answer Pointer两个模型在Stanford Question Answering Dataset (SQuAD)上得到了state-of-the-art的结果。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://120.52.73.75/arxiv.org/pdf/1608.08716v1.pdf" data-editable="true" data-title="Measuring Machine Intelligence Through Visual Question Answering"&gt;Measuring Machine Intelligence Through Visual Question Answering&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;本文指出了image caption作为评测AI效果的任务存在的缺陷，同时提出用visual QA作为评测任务更加有效，并且给出了一个大型Visual QA的数据集。数据集地址：&lt;a href="http://www.visualqa.org" data-editable="true" data-title="VQA: Visual Question Answering"&gt;VQA: Visual Question Answering&lt;/a&gt;.&lt;/p&gt;&lt;h1&gt;&lt;a href="http://120.52.73.79/arxiv.org/pdf/1609.00070v1.pdf" data-editable="true" data-title="How Much is 131 Million Dollars? Putting Numbers in Perspective with Compositional Descriptions" class=""&gt;How Much is 131 Million Dollars? Putting Numbers in Perspective with Compositional Descriptions&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;文章提出了一个好玩的任务，以一个统计数字作为上下文来生成一段简短的描述，描述的内容是一种带有这个数字的观点。整个过程分为两步：公式的构建和观点的生成。&lt;/p&gt;&lt;h1&gt;广告时间&lt;/h1&gt;&lt;p&gt;PaperWeekly是一个分享知识和交流学问的民间组织，关注的领域是NLP的各个方向。如果你也经常读paper，也喜欢分享知识，也喜欢和大家一起讨论和学习的话，请速速来加入我们吧。&lt;/p&gt;&lt;p&gt;微信公众号：PaperWeekly&lt;p&gt;http://weixin.qq.com/r/OUW0rA3ExVC6rUnP9xAr (二维码自动识别)&lt;/p&gt;&lt;/p&gt;&lt;p&gt;微博账号：PaperWeekly（&lt;a href="http://weibo.com/u/2678093863" data-editable="true" data-title="PaperWeekly的微博"&gt;PaperWeekly的微博&lt;/a&gt; ），每天会发布arXiv cs.CL高质量paper和简评。知乎专栏：PaperWeekly（&lt;a href="https://zhuanlan.zhihu.com/paperweekly" data-editable="true" data-title="PaperWeekly - 知乎专栏"&gt;PaperWeekly - 知乎专栏&lt;/a&gt; ）微信交流群：微信+ zhangjun168305（请备注：加群 or 加入paperweekly）&lt;/p&gt;</description><author>张俊</author><pubDate>Sat, 03 Sep 2016 11:49:16 GMT</pubDate></item><item><title>PaperWeekly 第三期</title><link>https://zhuanlan.zhihu.com/p/22279528</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/d89931bc502f2f7326b1aba605d4184e_r.png"&gt;&lt;/p&gt;&lt;h1&gt;引&lt;/h1&gt;&lt;p&gt;历经半个月时间终于发布了新一期PaperWeekly，大家久等了。在这个半个月里，PaperWeekly发生了一些明显的变化。维护和运营从我一个人变成了一个十人左右的团队来一起做，小伙伴们来自全球各地，颠倒着黑夜和白天进行沟通。团队中的每个人都有一颗热爱知识和分享知识的心，都认为分享是一种美德，是一种付出，更是一种回报。可能我们不完美，但我们相信我们正在追求完美的路上坚定地走着。&lt;/p&gt;&lt;p&gt;有了更多的同学加入，PaperWeekly会更加多元化，不再受限于我个人感兴趣的方向和阅读、写作习惯。PaperWeekly会坚持每周发布一期文章，每一期的文章尽量围绕同一个topic展开，在微信公众号、官方微博和知乎专栏会同步更新，除了这一篇文章，我们还会坚持在微博上提供一个新的服务，cs.CL daily，帮助大家过滤掉arXiv cs.CL上比较水的paper，留下质量高的paper，并且用简评的方式分享在微博上，每周末会更新一篇cs.CL weekly出来，将一周值得读的cs.CL paper汇总发布。&lt;/p&gt;&lt;p&gt;PaperWeekly组织了一个高质量的NLP讨论群，只要有你相关的问题，群里的高手会第一时间站出来解答或者讨论你的问题，有的时候会给出一些开源code和相关的paper，提问者、讨论者和潜水者都会有很大的收获。分享paper导读的意义在于讨论，大家一起来讨论，才能更加充分地吸收paper里的营养，这也是我为什么组织一个讨论群的原因。&lt;/p&gt;&lt;p&gt;寒暄的话就说到这里，本期分享的topic是ACL 2016，一共10篇文章，涉及的内容包括：Logic Form、NMT、Summarization、QA、Chatbot等。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://aclweb.org/anthology/P/P16/P16-1073.pdf" data-editable="true" data-title="Sentence Rewriting for Semantic Parsing" class=""&gt;Sentence Rewriting for Semantic Parsing&lt;/a&gt;&lt;/h1&gt;&lt;h2&gt;关键词&lt;/h2&gt;&lt;p&gt;Semantic Parsing、Sentence Rewriting&lt;/p&gt;&lt;h2&gt;来源&lt;/h2&gt;&lt;p&gt;ACL 2016&lt;/p&gt;&lt;h2&gt;问题&lt;/h2&gt;&lt;p&gt;语义分析的表现形式是将自然语言（natural language）转化成逻辑形式（logic form）。因语言表达多样性的问题导致两者间存在mismatch problem。&lt;/p&gt;&lt;h2&gt;文章思路&lt;/h2&gt;&lt;p&gt;先给出一个语义分析的例子：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/72e0e629eadcca4a8bb9a987b066057d.jpg" data-rawwidth="416" data-rawheight="224"&gt;&lt;/p&gt;&lt;p&gt;给句子换个表达（How many people live in Berlin?），对应的逻辑形式就变得复杂很多(count(λx.person(x)∧live(x,Berlin)))。&lt;/p&gt;&lt;p&gt;作者认为，原句子和逻辑形式之间存在的结构不匹配导致了语义分析的困难，而结构不匹配的核心是词汇的不匹配。作者率先提出先把句子重写再转成目标逻辑形式的语义分析方案，如下图：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/e164c5bb6c5fce0fcb9250105e6f3ab4.jpg" data-rawwidth="429" data-rawheight="152"&gt;&lt;/p&gt;&lt;p&gt;针对词汇不匹配问题的两种情况分别给出基于字典和基于模板两种方法。&lt;/p&gt;&lt;p&gt;1）问题一：1-N mismatch是指一个单词（word）对应一个复合的逻辑形式（compound formula）。&lt;/p&gt;&lt;p&gt;例如daughter对应 child ∩ female。但在开放域的知识体系下，制定这些规则十分困难。于是作者提出将句子中的常用名词替换为字典（Wiktionary）中的解释，比如先把刚才的daughter转换为female child，接着再转换为逻辑形式child ∩ female就十分自然了。&lt;/p&gt;&lt;p&gt;2）问题二：N-1 mismatch是指将复杂的自然语言表达对应为单个逻辑表达。&lt;/p&gt;&lt;p&gt;例如将How many people live in Berlin?转化为λx.population(Berlin,x)的分析过程中，How many people live in被对应为逻辑式常量population。如同问题一，这样的规则实在过多，作者的思路是将复杂的表达式转化为简单的形式。&lt;/p&gt;&lt;p&gt;沿用之前的句子来了解算法流程。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/6d59c63aedf120ee27d0b61d309bb890.jpg" data-rawwidth="432" data-rawheight="98"&gt;&lt;/p&gt;&lt;p&gt;Step 1 替换实体生成候选template，例如得到模板how many people live in #y。Step 2 检索template pairs来替换模板，例如找到(a：how many people live in #y, b：what is the population of #y)的模板对，于是将b作为新模板，Step 3 把实体替换回去得到容易生成逻辑形式的what is the population of Berlin。&lt;/p&gt;&lt;h2&gt;相关工作&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/b2e89a59bcd76d62bdf840dd3c6370b8.jpg" data-rawwidth="419" data-rawheight="184"&gt;&lt;/h2&gt;&lt;h2&gt;简评&lt;/h2&gt;&lt;p&gt;如今深度学习在自然语言处理领域大红大紫，也给语义分析的方法带来更多的思考。比如ACL2016另外一篇文章Language to Logical Form with Neural Attention，就把语义分析转换为seq2seq问题，进而使用深度学习的方法来解决。如果我们把词向量这样的表示形式比喻为粗糙的连结主义，那么逻辑表达就好比精细的形式主义。两者各有优势，希望以后会有更多结合两种思想的工作出现。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://aclweb.org/anthology/P/P16/P16-1004.pdf" data-editable="true" data-title="Language to Logical Form with Neural Attention" class=""&gt;Language to Logical Form with Neural Attention&lt;/a&gt;&lt;/h1&gt;&lt;h2&gt;关键词&lt;/h2&gt;&lt;p&gt;Logical Forms, Sequence to Sequence&lt;/p&gt;&lt;h2&gt;来源&lt;/h2&gt;&lt;p&gt;ACL 2016&lt;/p&gt;&lt;h2&gt;问题&lt;/h2&gt;&lt;p&gt;如何把自然语言转化成Structured Logical Forms？&lt;/p&gt;&lt;h2&gt;文章思路&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/2263e1dd44c4bf05b226d3c3b8c69205.jpg" data-rawwidth="353" data-rawheight="213"&gt;&lt;/h2&gt;&lt;p&gt;模型总体是一个encoder-decoder架构，input sequence首先通过LSTM encoder转化成一个vector，然后这个vector通过LSTM decoder被转化成Logical Forms。在decode过程中用到了一个attention layer去获取context信息。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/2bf99675c901b85453aac1c833562a75.jpg" data-rawwidth="306" data-rawheight="301"&gt;&lt;/p&gt;&lt;p&gt;和encoder-decoder模型类似，作者提出了一种hierarchical decoder。与普通的decoder不同，首先，decode之后的sequence中存在一个特殊字符代表nonterminal。在nonterminal的基础上，decoder可以继续进行下一个layer的decoding。每一次decoding的输入不仅包含current hidden state,还包含这一个parent nonterminal的hidden state。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/d125a2f36aa2cb05f32ddc3ab0bb6f84.jpg" data-rawwidth="279" data-rawheight="146"&gt;&lt;/p&gt;&lt;p&gt;作者还使用了一种attention机制，在构建current hidden state的时候将hidden state与所有encoder中的hidden state进行对比，给每一个encoder hidden state一个weight。&lt;/p&gt;&lt;h2&gt;资源&lt;/h2&gt;&lt;p&gt;代码：&lt;a href="https://github.com/donglixp/lang2logic" data-editable="true" data-title="GitHub - donglixp/lang2logic"&gt;GitHub - donglixp/lang2logic&lt;/a&gt;Jobs和GEO数据集：&lt;a href="http://www.cs.columbia.edu/~mcollins/papers/uai05.pdf"&gt;http://www.cs.columbia.edu/~mcollins/papers/uai05.pdf&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;相关工作&lt;/h2&gt;&lt;p&gt;之前的大部分工作都采用一些parsing models，string-to-tree transformation rules，文中没有提到之前有人采用seq2seq/deep learning的方法。本文中使用的seq2seq方法主要来自Kalchbrenner, Blunsom, Cho, Sutskever 在machine translation中提出的模型。&lt;/p&gt;&lt;h2&gt;简评&lt;/h2&gt;&lt;p&gt;本文解决的是一个非常有趣的问题，将自然语言转换成结构化的Logical Forms。试想如果此模型能够很好的解决这个问题，那么将来的各种query language甚至programming languages都可以由自然语言转换而成。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://aclweb.org/anthology/P/P16/P16-1046.pdf" data-editable="true" data-title="Neural Summarization by Extracting Sentences and Words" class=""&gt;Neural Summarization by Extracting Sentences and Words&lt;/a&gt;&lt;/h1&gt;&lt;h2&gt;关键词&lt;/h2&gt;&lt;p&gt;Summarization、Hierarchical Document Encoder、Attention-based Extractor&lt;/p&gt;&lt;h2&gt;来源&lt;/h2&gt;&lt;p&gt;ACL 2016&lt;/p&gt;&lt;h2&gt;问题&lt;/h2&gt;&lt;p&gt;如何使用数据驱动的方法来做提取式摘要？&lt;/p&gt;&lt;h2&gt;文章思路&lt;/h2&gt;&lt;p&gt;本文针对的任务分为sentence和word两个level的summarization。sentence level是一个序列标签问题，每个句子有0或1两个标签，为1表示需要提取该句作为总结。而word level则是一个限定词典规模下的生成问题，词典规模限定为原文档中所有出现的词。&lt;/p&gt;&lt;p&gt;使用的模型也比较有特点，首先在encoder端将document分为word和sentence来encode，word使用CNN encode得到句子表示，接着将句子表示输入RNN得到encoder端隐藏层状态。从word到sentence的encode体现了本文的hierarchical document encoder的概念。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/1dbf5b848521e79a7f0973c1c38095a6.jpg" data-rawwidth="252" data-rawheight="272"&gt;&lt;/p&gt;&lt;p&gt;在decoder端根据任务的不同使用不同网络结构，sentence任务就是一个简单的有监督下二分类问题，使用RNN网络结构更新decoder端隐藏层状态， decoder端隐藏层状态串联encoder端隐藏层状态后接入一个MLP层再接sigmoid激活函数得到句子是否被extract的概率。&lt;/p&gt;&lt;p&gt;word任务则是使用传统的attention-based的方法来计算每个词的概率。但要注意本文的计算的attention不是word-level attention，而是encoder端sentence-level attention。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/4ebfdd69dd0959c7efce04bf69faeb15.jpg" data-rawwidth="294" data-rawheight="199"&gt;&lt;/p&gt;&lt;h2&gt;资源&lt;/h2&gt;&lt;p&gt;数据集：&lt;a href="http://homepages.inf.ed.ac.uk/s1537177/resources.html" data-editable="true" data-title="Jianpeng Cheng" class=""&gt;Jianpeng Cheng&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;相关工作&lt;/h2&gt;&lt;p&gt;之前大多数extractive methods都基于human-engineered特征来给句子建模，通常会对每个句子计算一个分数，然后再使用诸如binary classifiers，hidden Markov模型，graph-based算法或integer linear programming等方法来选择句子构成总结。&lt;/p&gt;&lt;h2&gt;简评&lt;/h2&gt;&lt;p&gt;之前基于data-driven的seq2seq模型在abstractive summarization任务上大放异彩，本文提出了使用类似的模型来解决extractive summarization任务。不过针对的依旧是single-document summarization任务，未来需要将工作拓展至multi-document summarization任务上。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://aclweb.org/anthology/P/P16/P16-2008.pdf" data-editable="true" data-title="Sequence-to-Sequence Generation for Spoken Dialogue via Deep Syntax Trees and Strings" class=""&gt;Sequence-to-Sequence Generation for Spoken Dialogue via Deep Syntax Trees and Strings&lt;/a&gt;&lt;/h1&gt;&lt;h2&gt;关键词&lt;/h2&gt;&lt;p&gt;Sequence to Sequence、Natural Language Generation、Chatbot&lt;/p&gt;&lt;h2&gt;来源&lt;/h2&gt;&lt;p&gt;ACL 2016&lt;/p&gt;&lt;h2&gt;问题&lt;/h2&gt;&lt;p&gt;如何通过小规模、未对齐语料生成对话语句？&lt;/p&gt;&lt;h2&gt;文章思路&lt;/h2&gt;&lt;p&gt;作者介绍了两个模型:&lt;/p&gt;&lt;p&gt;1、通过DA(diglogue acts)生成句法依赖树，再利用external surface realizer，生成语句。（如下图）&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/c4f596e42d0cbe2564aaa449d0318f2c.jpg" data-rawwidth="300" data-rawheight="208"&gt;&lt;/p&gt;&lt;p&gt;2、将两部分结合起来，直接生成语句。步骤如下：&lt;/p&gt;&lt;p&gt;Step 1 将DA(dialogue acts)中的每个slot(表示特定信息)表示成三元组(DA type,slot,value)并结合(下图左)&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/d740d2ced18c5f2f9817074bf7fcb472.jpg" data-rawwidth="506" data-rawheight="105"&gt;&lt;/p&gt;&lt;p&gt;Step 2 基于seq2seq generation technique生出语句或句法依赖树。Step 3 结合beam search和n-best列表重排序（list reranker）以减少输出中的不相关信息。&lt;/p&gt;&lt;h2&gt;资源&lt;/h2&gt;&lt;p&gt;代码: &lt;a href="https://github.com/UFAL-DSG/tgen" data-editable="true" data-title="GitHub - UFAL-DSG/tgen: Statistical NLG for spoken dialogue systems" class=""&gt;GitHub - UFAL-DSG/tgen: Statistical NLG for spoken dialogue systems&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;相关工作&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/f46341b6203fae0cf1e8e493b2ea9b16.jpg" data-rawwidth="415" data-rawheight="189"&gt;&lt;/h2&gt;&lt;h2&gt;简评&lt;/h2&gt;&lt;p&gt;该方法基于广泛使用的seq2seq模型，可以用未对齐的MR对(pair of meaning representation)和句子进行训练，且只要小规模的语料就可以有很好的效果。生成器可以从数据中学会slot的对齐和值，生成流利的domain style)语句，虽然语义错误还是很频繁，但还是取得了不错的成绩。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://aclweb.org/anthology/P/P16/P16-1230.pdf" data-editable="true" data-title="On-line Active Reward Learning for Policy Optimisation in Spoken Dialogue Systems"&gt;On-line Active Reward Learning for Policy Optimisation in Spoken Dialogue Systems&lt;/a&gt;&lt;/h1&gt;&lt;h2&gt;关键词&lt;/h2&gt;&lt;p&gt;Dialogue System、Reinforcement Learning、Online Active Reward Learning&lt;/p&gt;&lt;h2&gt;来源&lt;/h2&gt;&lt;p&gt;ACL 2016&lt;/p&gt;&lt;h2&gt;问题&lt;/h2&gt;&lt;p&gt;文章提出一种在线学习框架，通过高斯过程分类模型进行主动学习，训练对话策略和奖励模型，减少数据标注的花费和用户反馈中的噪声。&lt;/p&gt;&lt;h2&gt;文章思路&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/fe153e783f983fa26d47572c287cf66a.jpg" data-rawwidth="415" data-rawheight="215"&gt;&lt;/h2&gt;&lt;p&gt;框架分为三部分：对话策略、对话嵌入函数、用户反馈主动奖励模型。&lt;/p&gt;&lt;p&gt;无监督学习输入为双向LSTM，通过Encoder-Decoder模型表征用户意图，将对话的成功与否看做高斯过程的一个二元分类问题，当模型对当前结果不能评判时，主动学习，通过reward模型决定是否询问用户反馈，当模型不确定时，生成增强信号来训练策略。&lt;/p&gt;&lt;h2&gt;资源&lt;/h2&gt;&lt;p&gt;数据集：&lt;a href="http://camdial.org/~mh521/dstc/" class=""&gt;http://camdial.org/~mh521/dstc/&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;相关工作&lt;/h2&gt;&lt;p&gt;1、之前的工作有用任务完成度和对话持续情况做Reward，但任务完成度不好衡量2、用协同过滤表征用户偏好3、用逆强化学习从行为中推出reward&lt;/p&gt;&lt;h2&gt;简评&lt;/h2&gt;&lt;p&gt;用lSTM Encoder-Decoder表征用户意图，无需大规模标注语料和构建用户模拟器来进行训练，在较小的训练语料中取得了不错的效果，率先实现了在真实场景中的应用。但Reward函数只关心对话任务是否成功，模型过于简单。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://aclweb.org/anthology/P/P16/P16-1100.pdf" data-editable="true" data-title="Achieving Open Vocabulary Neural Machine Translation with Hybrid Word-Character Models" class=""&gt;Achieving Open Vocabulary Neural Machine Translation with Hybrid Word-Character Models&lt;/a&gt;&lt;/h1&gt;&lt;h2&gt;关键词&lt;/h2&gt;&lt;p&gt;Neural Machine Translation、UNK Words&lt;/p&gt;&lt;h2&gt;来源&lt;/h2&gt;&lt;p&gt;ACL 2016&lt;/p&gt;&lt;h2&gt;问题&lt;/h2&gt;&lt;p&gt;如何解决机器翻译中的未登录词问题？&lt;/p&gt;&lt;h2&gt;文章思路&lt;/h2&gt;&lt;p&gt;文章提出了一个混合（层次）模型。该模型由两部分组成，分别为：a. 传统的基于词（word level）的seq2seq模型；b. 基于字母级别（character level）的LSTM模型，由一个将字母encode成单词的encoder和一个根据状态生成低频词的decoder组成。其中a部分负责进行翻译，b部分负责处理低频词（unk）。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/eed844a1612a8d83285452ee2b8d4576.jpg" data-rawwidth="230" data-rawheight="336"&gt;&lt;/p&gt;&lt;p&gt;具体地，a部分的encoder遇到unk时，会使用character level对该低频词进行encode，并使用encode出的representation作为输入。而decoder遇到unk时，会利用attention机制将当前上下文和LSTM状态初始化character level decoder。此处的初始化采用的是文章提出的separate path模式，即利用一个MLP作为character level decoder的初始化网络。值得注意的是此处word level decoder仍会选择用作为下一步的输入。&lt;/p&gt;&lt;h2&gt;相关工作&lt;/h2&gt;&lt;p&gt;Unk问题属于NMT中长期存在问题。目前多是采取后处理的方法。今年ACL有两篇paper，分别是李航老师实验室的copynet和Bengio实验室的pointing the unknown words，但对机器翻译任务参考意义有限。另外一种思路则是加大词典，比较知名工作有On Using Very Large Target Vocabulary for Neural Machine Translation。此外该工作还借鉴了Jiwei Li的hierarchical auto encoder。&lt;/p&gt;&lt;h2&gt;简评&lt;/h2&gt;&lt;p&gt;文章思路新颖且简单明了。因为NMT中存在unk的问题，作者直接利用character level RNN来生成一个词替代unk。该工作对拼音文字有一定意义，对中日韩文的参考意义有限。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://aclweb.org/anthology/P/P16/P16-1014.pdf" data-editable="true" data-title="Pointing the Unknown Words" class=""&gt;Pointing the Unknown Words&lt;/a&gt;&lt;/h1&gt;&lt;h2&gt;关键词&lt;/h2&gt;&lt;p&gt;Neural Machine Translation、UNK Words&lt;/p&gt;&lt;h2&gt;来源&lt;/h2&gt;&lt;p&gt;ACL 2016&lt;/p&gt;&lt;h2&gt;问题&lt;/h2&gt;&lt;p&gt;如何解决机器翻译中的未登录词问题？&lt;/p&gt;&lt;h2&gt;文章思路&lt;/h2&gt;&lt;p&gt;作者在有注意力的机器翻译模型上增加了一个开关来判断和是否复制原文。&lt;/p&gt;&lt;p&gt;1、Attention-based机器翻译模型&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/6836206b755db6d279c8b0766360a2ce.jpg" data-rawwidth="333" data-rawheight="175"&gt;经典的attention model这里不再赘述。&lt;/p&gt;&lt;p&gt;2、Pointer Softmax模型&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/cef9064f7a3972c554d344a782836b4d.jpg" data-rawwidth="380" data-rawheight="203"&gt;&lt;/p&gt;&lt;p&gt;两个问题有待解决解决：a. 是否进行copy？b. copy的位置在哪？&lt;/p&gt;&lt;p&gt;先说第二个问题，作者先引入shortlist softmax和location softmax。前者来确定要从shortlist中选取哪一个单词作为输出，后者确定在哪个位置要进行copy操作。&lt;/p&gt;&lt;p&gt;再看第一个问题，作者引入一个二值变量（可以想象为一个开关）来选择使用shortlist softmax还是location softmax。当值为1的时候不进行copy操作，使用shortlist softmax来从shortlist中选一个词作为输出。当值为0的时候进行copy操作，使用location softmax，将原文的词直接copy到指定位置。&lt;/p&gt;&lt;h2&gt;资源&lt;/h2&gt;&lt;p&gt;代码：&lt;a href="https://github.com/caglar/pointer_softmax" data-editable="true" data-title="GitHub - caglar/pointer_softmax"&gt;GitHub - caglar/pointer_softmax&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;简评&lt;/h2&gt;&lt;p&gt;本文的想法很有趣，直接从原文照抄罕见词和未知词很符合日常生活中人类的处理方法。从文中实验结果来看，该模型有一定的提升效果。注意力模型的提出与对人类行为的观察密不可分，而copy机制也是从生活中提炼出来的一种有效模型，我们可以借鉴的是从人类解决问题的具体方式中进行总结和归纳不失为一种有效的解决方案。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://aclweb.org/anthology/P/P16/P16-1228.pdf" data-editable="true" data-title="Harnessing Deep Neural Networks with Logic Rules" class=""&gt;Harnessing Deep Neural Networks with Logic Rules&lt;/a&gt;&lt;/h1&gt;&lt;h2&gt;关键词&lt;/h2&gt;&lt;p&gt;CNN、RNN、First-order Logic, Iterative Distillation Method&lt;/p&gt;&lt;h2&gt;来源&lt;/h2&gt;&lt;p&gt;ACL 2016&lt;/p&gt;&lt;h2&gt;问题&lt;/h2&gt;&lt;p&gt;如何将深度学习与逻辑规则结合使用？&lt;/p&gt;&lt;h2&gt;文章思路&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/ca52f6aa241d9fa7725c356f313d102a.png" data-rawwidth="447" data-rawheight="227"&gt;&lt;/h2&gt;&lt;p&gt;系统在构建正常神经网络(student)的同时，构建了一个基于逻辑规则的训练网络(teacher)。整个网络的目标还是优化神经网络的参数变量 θ，因为新的目标损失函数结合了二者的损失，通过这种方式，教师网络的逻辑信息就能够被转移到神经网络的θ上，从而加强神经网络的性能。 在这种结构里逻辑规则是用于辅助的可选项，通过调整权重，系统可以偏向某个网络。这种模型可以将监督学习扩展到无监督学习，比如图示中，无标记的数据通过教师子网之后提取有用信息，也可以用来训练监督学习的神经网络。&lt;/p&gt;&lt;p&gt;1、训练过程&lt;/p&gt;&lt;p&gt;假设输入数据为x, y。student神经网络的参数变量是θ, 输出层是softmax，对输入xn，输出预测概率分布σ(xn)。对teacher网络，在第ｔ次迭代中基于逻辑规则的预测结果表示为sn(t)，那么新的优化目标变成了&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/1ada851124622357827bcee6b400e724.png" data-rawwidth="421" data-rawheight="101"&gt;&lt;/p&gt;&lt;p&gt;可以看出来自教师网络的反馈作为regularization加到了目标函数里，通过这种方式两个网络的信息就结合在了一起。注意教师网络在每次训练迭代中都要构建，因此整个过程被称之为iterative knowledge distillation.&lt;/p&gt;&lt;p&gt;2、教师网络&lt;/p&gt;&lt;p&gt;教师网络使用软逻辑(soft logic)来编码first-order logic的信息。soft logic在[0,1]之间的连续取值，而不是二元值{0, 1}。逻辑运算也用max, min, sum代替原来的与或非。&lt;/p&gt;&lt;p&gt;神经网络数学模型为pθ(y|x) 教师网络数学模型假设为q(y|x)。我们实际上是用基于逻辑规则的教师网络来模拟神经网络输出，因此我们希望能找到一个最优的q，使得输入尽可能满足逻辑规则的要求，同时q要尽可能接近pθ。详细推导可以参见原文，最后的优化结果就是&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/7f6f7b9551453db16adcb9c02a13fa90.png" data-rawwidth="457" data-rawheight="97"&gt;&lt;/p&gt;&lt;p&gt;λl 是每个规则的自信度(confidence)，而rl, gl 是某个规则应用于某一输入时的逻辑结果，介于0,1之间。可以看到自信度比较高的规则可以使输入更容易通过规则。&lt;/p&gt;&lt;p&gt;3、应用&lt;/p&gt;&lt;p&gt;a. 基于CNN的情感分析b. 基于BLSTM-CNN的NER任务&lt;/p&gt;&lt;h2&gt;相关工作&lt;/h2&gt;&lt;p&gt;1、Neural-symbolic systems (Garcez et al., 2012) 从给定的规则构建推理网络2、(Collobert 2011)， 利用领域知识domain knowledge提取额外特征，增强原始数据3、Knowledge distillation (Hinton et al., 2015) (Bucilu et al. 2006)4、Posterior regularization (PR) method (Ganchev et al., 2010)&lt;/p&gt;&lt;h2&gt;简评&lt;/h2&gt;&lt;p&gt;创新点在于将逻辑规则与神经网络结合，可以利用人已知的知识去引导机器学习。当数据量不足的，或者对数据进行补充时，可以将人类的知识用逻辑语言表达出来，然后通过本文提出的框架进行增强训练。本文的两个例子中都提到只用了少量规则，优化的结果虽然显示要比当前其他模型好，但是没有大幅度的提高。需要进一步验证如果使用更多的规则，能不能大幅度提高准确率。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://aclweb.org/anthology/P/P16/P16-1043.pdf" data-editable="true" data-title="Easy Questions First? A Case Study on Curriculum Learning for Question Answering" class=""&gt;Easy Questions First? A Case Study on Curriculum Learning for Question Answering&lt;/a&gt;&lt;/h1&gt;&lt;h2&gt;关键词&lt;/h2&gt;&lt;p&gt;Curriculum Learning、Self-paced Learning、Question Answering&lt;/p&gt;&lt;h2&gt;来源&lt;/h2&gt;&lt;p&gt;ACL2016&lt;/p&gt;&lt;h2&gt;问题&lt;/h2&gt;&lt;p&gt;文章讨论了Curriculum Learning在NLP领域, 尤其是在QA task里应用的可行性。&lt;/p&gt;&lt;h2&gt;文章思路&lt;/h2&gt;&lt;p&gt;文章首先对QA类型的task给出了比较general的定义: 我们可以把QA问题看做是一个经验风险最小化(ERM)问题, 我们需要最小化:&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/27e5903f5012534c885cb908b17220b3.jpg" data-rawwidth="204" data-rawheight="49"&gt;&lt;/p&gt;&lt;p&gt;其中是a正确答案, f是给定背景知识以及问题, 模型选择出的最佳答案,Ω是regularizer.&lt;/p&gt;&lt;p&gt;之后, 作者对于Curriculum Learning, 尤其是Self-paced Learning做了介绍, 并且将其引入QA task, 进而将之前的ERM问题变为:&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/0810353ef81edd235cb8915fb6274bee.jpg" data-rawwidth="277" data-rawheight="58"&gt;&lt;/p&gt;&lt;p&gt;其中v是对问题进行采样时候的权值, g是self-paced regularizer, 其中λ代表’age’, 或者说’pace’. 训练初期, 模型趋向于对简单的问题进行训练, 而随着’age’的增加, 模型越来越多地加入更复杂的问题一起训练。&lt;/p&gt;&lt;p&gt;文章给出并分析了四种流行的self-paced regularizer如Table 1:&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/b72b5a9134355f25b4b6ba48acc9903c.jpg" data-rawwidth="350" data-rawheight="168"&gt;&lt;/p&gt;&lt;p&gt;之后提出了7种新的heuristics:&lt;/p&gt;&lt;p&gt;1) Greedy Optimal (GO): 将已有的Q和一系列新的Q一起训练, 选回答正确并且loss最低的。2) Change in Objective (CiO): 将已有的Q和一系列新的Q一起训练, 选择令loss改变最小的。3) Mini-max (M2 ): 当某个新的Q与其loss最大的一个candidate answer配对时, loss最小的. (通俗地讲, 就是最差情况都没有那么糟糕的一个)。4) Expected Change in Objective (ECiO): 只拿新的Q训练, 和之前的loss改变最小的. (相比于第二种的将已有的Q和新Q一起训练)。5) Change in Objective-Expected Change in Objective (CiO - ECiO): 2)和4)的值最接近的, 按照作者的意思, 这个值反应了model见到某个新Q时surprise的程度。6) Correctly Answered (CA): 将一系列新Q在当前model上测试, 选择用最小的loss正确回答的。7) Farthest from Decision Boundary (FfDB): 只用在latent structural SVMs上, 选择答案与decision boundary最远的一个新Q。&lt;/p&gt;&lt;h2&gt;资源&lt;/h2&gt;&lt;p&gt;MCTest: &lt;a href="http://research.microsoft.com/en-us/um/redmond/projects/mctest/" data-editable="true" data-title="Machine Comprehension Test (MCTest)" class=""&gt;Machine Comprehension Test (MCTest)&lt;/a&gt;Science Textbook: &lt;a href="http://http//www.ck12.org/" data-editable="true" data-title="http://http://www.ck12.org/"&gt;http://http://www.ck12.org/&lt;/a&gt;Science question answering: &lt;a href="http://aristo-public-data.s3.amazonaws.com/AI2-Elementary-NDMC-Feb2016.zip" data-editable="true" data-title="amazonaws.com 的页面"&gt;http://aristo-public-data.s3.amazonaws.com/AI2-Elementary-NDMC-Feb2016.zip&lt;/a&gt;Simple English Wikipedia: &lt;a href="https://dumps.wikimedia.org/simplewiki/20151102/" data-editable="true" data-title="wikimedia.org 的页面"&gt;https://dumps.wikimedia.org/simplewiki/20151102/&lt;/a&gt;QANTA: &lt;a href="https://cs.umd.edu/~miyyer/qblearn/" data-editable="true" data-title="QANTA: A Deep Question Answering Model"&gt;QANTA: A Deep Question Answering Model&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;相关工作&lt;/h2&gt;&lt;p&gt;1、Curriculum Learning:&lt;/p&gt;&lt;p&gt;早在1958年[1], 就有认知科学的相关学者意识到, 对于人类学习过程, 相对于提供随机的知识,由浅及深的地给予有计划的训练样本, 可以得到更好的效果. 之后这一Curriculum Learning的想法也被引入到机器学习中[2], 其中Self-paced learning (SPL)[3][4][5]是比较常用的方法。&lt;/p&gt;&lt;p&gt;2、QA:&lt;/p&gt;&lt;p&gt;Jurafsky和Martin[6]对于QA系列问题有一个非常好的叙述, 而这篇文章突出讨论Curriculum Learning在non-convex的QA模型上的应用, 着重介绍了基于配对的模型[7][8][9]和基于深度学习的模型[10][11].基于配对的模型将每一个问题和问题附带的多个备选答案组成若干个QA对, 我们称之为假设, 然后在给定相关文章的情况下, 寻找有最可能是正确的一个假设作为答案. 基于深度学习的模型可以使用依赖关系树结构的递归神经网络, 对句子level的QA模型的结果取平均[10]; 也可以用RNN构建”长期”存储器, 通过学习对存储器进行读/写操作, 模拟一个动态的知识构建过程[11]。&lt;/p&gt;&lt;h2&gt;简评&lt;/h2&gt;&lt;p&gt;在QA task中引入Curriculum Learning旨在在训练过程中, 启发式地对于提供给模型的数据出现的顺序进行一些调整, 从而让模型从简单的, 易于学习的样本开始, 随着模型对数据的表述愈加成熟, 逐渐加入更复杂的样本. 理想状况下这会指导模型从得到一个普通的local minima, 变成得到一个”更”好的local minima, 进而利用全部数据得到一个”更更”好的local minima。&lt;/p&gt;&lt;p&gt;通常来说, 我们给予模型的heuristic并不一定能够真正帮助模型, 因为通常我们都在猜测数据以及模型的latent representation是什么, 但是这篇文章通过了一系列的实验验证, 本文阐述的heuristic确实可以帮助QA model获得更好的准确率. 这证明了引导模型由浅及深的这种思路是可行的, 我们也许可以思考一些更复杂的heuristic, 或者将其应用到其他的一些NLP tasks。&lt;/p&gt;&lt;p&gt;然而本文给出的大部分heuristic在新问题的选择上都需要比较大的时间复杂度, 对于类似MCTest这种总共只有660个文章的小型数据集来说还算比较现实, 但是对于更大更长的数据集(比如CNN数据集, 38万个文章, 很多文章都超过了一千五百个单词, 而且备选答案数量也远超MCTest的四个)时, 就显得不那么轻松了. 最简单的Attention Sum Reader[1] 在CNN数据集上, 每个epoch都需要10个多小时, 就更别说其他基于AS Reader的模型了。&lt;/p&gt;&lt;p&gt;总体来说, 相对于实用性, 这篇文章更多在于提供了一种新的思路, 也就是把Curriculum Learning相关的概念应用到QA乃至于其他NLP task中, 非常值得思考, 因此是一篇非常值得阅读的文章。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://aclweb.org/anthology/P/P16/P16-1144.pdf" data-editable="true" data-title="The LAMBADA dataset:Word prediction requiring a broad discourse context" class=""&gt;The LAMBADA dataset:Word prediction requiring a broad discourse context&lt;/a&gt;&lt;/h1&gt;&lt;h2&gt;关键词&lt;/h2&gt;&lt;p&gt;Machine Reading Comprehension、Dataset&lt;/p&gt;&lt;h2&gt;来源&lt;/h2&gt;&lt;p&gt;ACL 2016&lt;/p&gt;&lt;h2&gt;问题&lt;/h2&gt;&lt;p&gt;构建了一个难度更大的机器阅读理解数据集。&lt;/p&gt;&lt;h2&gt;构建思路&lt;/h2&gt;&lt;p&gt;以Book Corpus的小说作为数据源，构建了10222个passages，每个passage包括平均4.6句话的context和相邻着的一句target，定义的任务是通过理解context来预测target中最后一个词，平均每个passage包括约75个tokens。其中，超过80%的passage context中包括了target中需要预测的词，48%的target words是专有名词（proper nouns），37%的词是一般名词（common nouns），约7.7%的是动词。这里，专有名词和一般名词是最难猜出来的，动词有一定的概率可以不需要context，而直接从target sentence利用语言模型猜出来。&lt;/p&gt;&lt;p&gt;在处理原始数据时，作者做了一层过滤，将容易从target sentence中直接猜出target word的passages统统丢掉，将剩下的部分放在众包网站上进行人工筛选，筛选的过程比较长，目的是让留在数据集中的数据有下面的效果：通过分析passage的context可以给出正确的target word，而如果只是给定target sentence的话，是猜不出正确的target word。&lt;/p&gt;&lt;h2&gt;资源&lt;/h2&gt;&lt;p&gt;本文数据集Lambada dataset: &lt;a href="http://clic.cimec.unitn.it/lambada/" data-editable="true" data-title="cimec.unitn.it 的页面"&gt;http://clic.cimec.unitn.it/lambada/&lt;/a&gt;众包网站Crowdflower: &lt;a href="http://www.crowdflower.com/" data-editable="true" data-title="Make your data useful"&gt;Make your data useful&lt;/a&gt;原始数据集Book Corpus: &lt;a href="http://www.cs.toronto.edu/~mbweb/"&gt;http://www.cs.toronto.edu/~mbweb/&lt;/a&gt;CNN/Daily Mail dataset: &lt;a href="https://github.com/deepmind/rc-data" data-editable="true" data-title='GitHub - deepmind/rc-data: Question answering dataset featured in "Teaching Machines to Read and Comprehend'&gt;GitHub - deepmind/rc-data: Question answering dataset featured in "Teaching Machines to Read and Comprehend&lt;/a&gt;CBT dataset: &lt;a href="http://fb.ai/babi/"&gt;http://fb.ai/babi/&lt;/a&gt;MSRCC dataset: &lt;a href="https://www.microsoft.com/en-us/research/publication/the-microsoft-research-sentence-completion-challenge/" data-editable="true" data-title="The Microsoft Research Sentence Completion Challenge"&gt;The Microsoft Research Sentence Completion Challenge&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;相关数据集&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/5b0d691a539f4cf8001773af649bc8be.png" data-rawwidth="1086" data-rawheight="620"&gt;&lt;/h2&gt;&lt;h2&gt;简评&lt;/h2&gt;&lt;p&gt;大型数据集是深度学习技术发展的重要基础，数据集的质量和难度也直接关系着模型的质量和实用性。机器阅读理解的数据集有很多，包括中文和英文的数据集，每一个的构建都会带来模型的创新，随着难度不断增加，对模型也提出了更高的要求。本文在构建数据集过程中为了保证任务的难度所采取的方法是值得借鉴的。&lt;/p&gt;&lt;h1&gt;致谢&lt;/h1&gt;&lt;p&gt;本期的10篇文章由以下同学完成：&lt;/p&gt;&lt;p&gt;苏辉、Xiaoyu、胡小明、赵越、周青宇、韩晓伟、Eric Yuan、Zewei Chu、tonya、张俊。&lt;/p&gt;&lt;p&gt;感谢大家地辛勤付出。&lt;/p&gt;&lt;h1&gt;广告时间&lt;/h1&gt;&lt;p&gt;PaperWeekly是一个分享知识和交流学问的民间组织，关注的领域是NLP的各个方向。如果你也经常读paper，也喜欢分享知识，也喜欢和大家一起讨论和学习的话，请速速来加入我们吧。&lt;/p&gt;&lt;p&gt;微信公众号：PaperWeekly&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/8e2b86789f8cddf7e423e1c07d39ce0a.jpg" data-rawwidth="430" data-rawheight="430"&gt;&lt;/p&gt;&lt;p&gt;微博账号：PaperWeekly（&lt;a href="http://weibo.com/u/2678093863" data-editable="true" data-title="PaperWeekly的微博"&gt;PaperWeekly的微博&lt;/a&gt; ）知乎专栏：PaperWeekly（&lt;a href="https://zhuanlan.zhihu.com/paperweekly" data-editable="true" data-title="PaperWeekly - 知乎专栏"&gt;PaperWeekly - 知乎专栏&lt;/a&gt; ）微信交流群：微信+ zhangjun168305（请备注：加群 or 加入paperweekly）&lt;/p&gt;</description><author>张俊</author><pubDate>Fri, 02 Sep 2016 11:27:40 GMT</pubDate></item><item><title>cs.CL weekly 2016.08.22-2016.08.26</title><link>https://zhuanlan.zhihu.com/p/22184043</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/c3c8fdc44ec223b1d89e130afa476975_r.png"&gt;&lt;/p&gt;&lt;h1&gt;简介&lt;/h1&gt;&lt;p&gt;这个栏目是将一周内arxiv cs.CL刷出的好文进行一个简单的汇总，并配有一句话总结，旨在帮助大家过滤掉cs.CL上的水文，并且为PaperWeekly团队选文提供高质量paper。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://120.52.73.78/arxiv.org/pdf/1608.05852v1.pdf" data-editable="true" data-title="Learning Word Embeddings from Intrinsic and Extrinsic Views" class=""&gt;Learning Word Embeddings from Intrinsic and Extrinsic Views&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;本文提出了一种依靠intrinsic (descriptive) and extrinsic (contextual) information来学习词向量的方法，有效解决了传统方法中对低频词学习存在的问题。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://120.52.73.78/arxiv.org/pdf/1608.06043v1.pdf" data-editable="true" data-title="Context Gates for Neural Machine Translation"&gt;Context Gates for Neural Machine Translation&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;本文提出了一种context gate来动态地控制机器翻译中source、target context对word generation的影响，实验证明在BLEU指标下比attention-based的方法提高了2.3。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://120.52.73.80/arxiv.org/pdf/1608.05777v1.pdf" data-editable="true" data-title="Topic Sensitive Neural Headline Generation"&gt;Topic Sensitive Neural Headline Generation&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;本文针对传统模型中忽略topical similarities和differences of documents的问题，提出了一种新方案，先将documents按照topics分类，每一类中的pattern比较接近，然后再做sentence level summary，得到了更好的效果。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://120.52.73.77/arxiv.org/pdf/1608.06378v1.pdf" data-editable="true" data-title="Towards Machine Comprehension of Spoken Content: Initial TOEFL Listening Comprehension Test by Machine"&gt;Towards Machine Comprehension of Spoken Content: Initial TOEFL Listening Comprehension Test by Machine&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;本文以托福听力题作为数据集，尝试对多媒体信息进行理解。听力问题是听完一段话，理解之后，进行4选1，而不是之前常见的cloze-style理解任务。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://120.52.73.79/arxiv.org/pdf/1608.07076v1.pdf" data-editable="true" data-title="A Context-aware Natural Language Generator for Dialogue Systems"&gt;A Context-aware Natural Language Generator for Dialogue Systems&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;本文的模型是一种端到端的模型，根据上下文和用户说话的方式来生成对话。是一篇SIGDIAL 2016 short paper。配套的代码已发布于&lt;a href="https://github.com/UFAL-DSG/tgen" data-editable="true" data-title="Github"&gt;Github&lt;/a&gt;&lt;/p&gt;&lt;h1&gt;About&lt;/h1&gt;&lt;p&gt;对NLP高质量原创内容和讨论感兴趣的你，赶快来关注：&lt;/p&gt;&lt;p&gt;1、PaperWeekly&lt;a href="http://weibo.com/2678093863/" data-editable="true" data-title="官方微博"&gt;官方微博&lt;/a&gt;&lt;/p&gt;&lt;p&gt;2、PaperWeekly官方微信&lt;/p&gt;&lt;p&gt;3、PaperWeekly&lt;a href="https://zhuanlan.zhihu.com/paperweekly" data-editable="true" data-title="知乎专栏"&gt;知乎专栏&lt;/a&gt;&lt;/p&gt;&lt;p&gt;4、PaperWeekly微信交流群（+微信zhangjun168305入群）&lt;/p&gt;</description><author>张俊</author><pubDate>Fri, 26 Aug 2016 09:52:06 GMT</pubDate></item><item><title>从api.ai工作原理来看构建简单场景chatbot的一般方法</title><link>https://zhuanlan.zhihu.com/p/22139158</link><description>&lt;h1&gt;引&lt;/h1&gt;&lt;p&gt;chatbot无疑是当前非常火的一个研究领域和产品方向，简单地可以分为两类，开放域bot和封闭域bot，开放域bot倾向于解决所有的事情，而封闭域bot倾向于解决某一个细分领域中的事情，旨在用AI技术提高效率，提高生产力。现阶段的开放域bot我个人感觉更像是多个常用封闭域bot的叠加，当用户发起一个请求，系统会判断出属于哪个细分领域，然后转到相应的程序中去执行并给出反馈，顺着这个逻辑来看，研究简单场景下的chatbot是个重要的基础工作，这类研究或者产品的质量直接决定了复杂场景或者开放域bot的质量。当然逗乐型的bot并不属于本文讨论的范围。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/d35833c83746938c0418be1102f05222.png" data-rawwidth="715" data-rawheight="487"&gt;图片来自paper &lt;a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/06/williams2016dstc_overview-1.pdf" data-editable="true" data-title="The Dialog State Tracking Challenge Series- A Review" class=""&gt;The Dialog State Tracking Challenge Series- A Review&lt;/a&gt;&lt;/p&gt;&lt;p&gt;chatbot是场交互革命，也是一个多技术融合的平台。上图给出了构建一个chatbot需要具备的组件，简单地说chatbot = NLU(Natural Language Understanding) + NLG(Natural Language Generation).(本文只关注NLP相关的技术，对语音识别并无讨论)&lt;/p&gt;&lt;p&gt;对于封闭域的chatbot，NLU的工作就是DST(Dialog State Tracker)，用户给出输入之后，系统可以给出下面的形式作为state：&lt;/p&gt;&lt;p&gt;Act(Slot=Value)&lt;/p&gt;&lt;p&gt;Act表示用户行为的类型，比如请求、查询、打招呼等等；Slot表示用户输入中包含的某种Act下的Entity，比如查询酒店的位置、价格这些实体；Value是指Slot中Entity对应的值，比如位置在北边，价格在500-800之间等等。每一句话中可能包括多个Act-Slot-Value对，chatbot需要做的事情就是准确地识别出Act，并且抽取出相应的Slot和Value。&lt;/p&gt;&lt;p&gt;紧接着是NLG的部分，前几天在&lt;a href="http://rsarxiv.github.io/2016/08/16/PaperWeekly-%E7%AC%AC%E4%BA%8C%E6%9C%9F/" data-editable="true" data-title="PaperWeekly第二期"&gt;PaperWeekly第二期&lt;/a&gt;中分享了三篇paper，其中两篇正是研究基于DST的NLG问题。&lt;/p&gt;&lt;p&gt;本文首先从&lt;a href="http://rsarxiv.github.io/2016/08/21/%E4%BB%8Eapi-ai%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86%E6%9D%A5%E7%9C%8B%E6%9E%84%E5%BB%BA%E7%AE%80%E5%8D%95%E5%9C%BA%E6%99%AFchatbot%E7%9A%84%E4%B8%80%E8%88%AC%E6%96%B9%E6%B3%95/api.ai" data-editable="true" data-title="api.ai"&gt;api.ai&lt;/a&gt;这家企业提供的服务说起，通过研究其提供的封闭域bot构建技术，来提炼构建简单场景chatbot的一般方法，为构建复杂场景或者找出现有chatbot存在的技术问题和面临的技术难点打下基础。&lt;/p&gt;&lt;h1&gt;api.ai&lt;/h1&gt;&lt;h2&gt;api.ai公司介绍&lt;/h2&gt;&lt;blockquote&gt;&lt;p&gt;Api.ai provides developers and companies with the advanced tools they need to build conversational user interfaces for apps and hardware devices.&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;这家公司是一家典型的B2D公司，提供了一些工具帮助开发者轻松地开发一款bot，并且可以轻松地发布到各种message平台上。商业模式也非常简单，免费用户有一定次数的调用权限，需要大量调用的话，则付费购买，不同的权限有不同的价格，该公司也提供高级定制化服务。&lt;/p&gt;&lt;p&gt;api.ai公司成立于2010年（数据来自&lt;a href="https://www.crunchbase.com/organization/api-ai#/entity" data-editable="true" data-title="CrunchBase"&gt;CrunchBase&lt;/a&gt;），其早期业务不清楚，但可以从提供的服务中推断出早期攒了大量的用户数据，而且涉及的领域非常多，比如：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/822f16a29b4bc7fc5b0ced5ca1babe24.png" data-rawwidth="803" data-rawheight="716"&gt;&lt;/p&gt;&lt;p&gt;每个领域都有一个知识库，如果你要开发某个常用领域内的chatbot，那么这个知识库将会非常有用。&lt;/p&gt;&lt;h2&gt;重要概念和工作原理&lt;/h2&gt;&lt;h3&gt;重要概念&lt;/h3&gt;&lt;p&gt;1、Agents。这个是一个对外接口，与其他应用程序或你的app进行整合的部分。如下图：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/862ce5730fccea058b464f052db430da.png" data-rawwidth="712" data-rawheight="180"&gt;&lt;/p&gt;&lt;p&gt;2、Entities。这里的实体和引言中提到的Slot类似，是指某个特定领域内的实体，是一类东西的抽象概括，比如HotelName这一实体，对应着很多的酒店名字，凯宾斯基、如家等等。有Entity，就一定有value，chatbot中重要的一步正是从user input中抽取出对应预先设定好entity的value，是一个典型的Named Entity Recognition任务。&lt;/p&gt;&lt;p&gt;这里经典的NER任务是识别出user input中的person、time、place等等几个基本元素，api.ai将这些常见的entity定义为system级的，即默认提供了训练好的识别器，当然不仅仅限于这几类基本的；而特定领域知识库的重要作用也正是在于识别该领域内的entity。除了system level的NER之外，需要developer自定义一些entity，比如菜名，而且要给定具体的菜名和相似的表达作为samples进行训练。&lt;/p&gt;&lt;p&gt;3、Intents。这个相当于是从user input到chatbot执行某个action之间的一个映射关系，用户输入一句话之后，chatbot就可以理解其意图，是在打招呼，还是查询，还是做些别的事情。这部分api.ai提供了训练器，但是需要developer定义一些标注好的examples，标注的形式如下：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/31c5390934afe103b1f780fca0bf0e37.png" data-rawwidth="1466" data-rawheight="1160"&gt;&lt;/p&gt;&lt;p&gt;这里用户输入是book a ticket to Los Angeles on Monday，所谓标注包括两个level，一个是entity标注，一个是intent标注，前一个是为了训练NER工具，后一个是为了识别intent。这里因为LA是地名，Monday是时间，所以都会被api.ai的系统自动标注出来。&lt;/p&gt;&lt;p&gt;4、Actions。这个是由intents进行trigger的，actions就和引言中的Act类似，是一个具体的动作，比如说查询，但执行动作的时候一般都要带上具体的参数value，用户输入：“三里屯最近的阿迪达斯店在什么位置？”，chatbot首先会提取出place-&amp;gt;三里屯，query-&amp;gt;阿迪达斯店，然后转换为json丢给后台的查询服务，查询到结果后给出答案。这里的value抽取其实就是第二个概念提到的entity value。&lt;/p&gt;&lt;p&gt;5、Contexts。上下文是一个非常重要但却解决不是很好的点，api.ai提供的方式是自定义一些context condition，当condition满足时，自动trigger出context关联内容template，然后filling slots，生成response。&lt;/p&gt;&lt;h3&gt;工作原理&lt;/h3&gt;&lt;p&gt;以RSarXiv chatbot为例，简单介绍下工作原理。（注：RSarXiv是我之前写的一个arxiv paper推荐系统）&lt;/p&gt;&lt;p&gt;step 1 自定义Entity，这里我定义了两个entities，一个是keywords和subject。keywords是为search功能提供value，而subject是为update new papers功能提供value。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/278517664dda186155dcd5f359ff5ff5.png" data-rawwidth="633" data-rawheight="217"&gt;定义好subject entity之后，我给出了几个examples，同时也包括其synonyms，keywords entity类似。&lt;/p&gt;&lt;p&gt;step 2 自定义Intents，这里我定义了两个Intents，分别是update和search。下图是update的examples，是我自定义的几个例子。api.ai会根据我定义好的entity进行自动标注，比如cs.CL，today是系统默认的entity所以也进行了自动标注。自动标注是为了后台的机器学习算法对标注好的examples进行学习，以提高chatbot的NLU准确率。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/4d0f72e49ec1fb1aa681547effdbf533.png" data-rawwidth="639" data-rawheight="375"&gt;&lt;/p&gt;&lt;p&gt;接下来，我需要定义下Actions，如下图：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/73d4d50e3bf5d5b45c8702e9b180783f.png" data-rawwidth="637" data-rawheight="321"&gt;Action被称为update，必须包含的参数是subject，也就是我们上面讲到的一个entity，date参数并不是必须的。所以，这里如果用户的input被识别出是update intents的话，就必须包括subject参数，否则chatbot会trigger一个response，类似“请用户输入subject”这样的话。&lt;/p&gt;&lt;p&gt;step 3 简单测试，在界面的右侧有一个console，用来测试当前chatbot的效果，我输入update cs.CL，得到下面的效果：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/2b06d3f59031301dafb0a8766f3d636c.png" data-rawwidth="337" data-rawheight="622"&gt;chatbot识别出Intent是Update，Action是update，Parameter是date和subject，并且subject的值是cs.CL，下面的Show JSON是api.ai为developer生成的，用来与developer自己的web service进行数据交换。&lt;/p&gt;&lt;p&gt;step 4 训练。训练包括两个部分，一是训练NER，二是训练Intent Classification。训练器是api.ai提供的，但是标注数据是developer自己提供的，当然训练数据越多，标注越准，分类器的准确率就越高，chatbot的NLU准确率越高。至于训练方法，docs中没有细说，我简单猜测一下，NER可以当做Sequence Labeling任务，和Intent Recognition类似，都可以看作是多分类问题，不管是传统的分类方法还是当下流行的deep learning方法都能得到不错的准确率。随着user logs的增多，训练数据会越来越多，chatbot通过学习就会变得越来越“聪明”。但这里有个问题，training data越多，需要标注或者修改标注的数据就会越多，也是一个麻烦事儿。&lt;/p&gt;&lt;p&gt;step 5 整合、发布。api.ai支持的平台非常多，包括当下流行的message平台，还有各种操作系统平台。在message平台上提供了一键整合的功能，在操作系统上提供了SDK。这里我用了slack平台，api.ai打通了和slack的接口，也提供了webhook，连接了我之前写好的web service，只需要按照它给定的消息接口进行定义即可。&lt;/p&gt;&lt;h3&gt;demo&lt;/h3&gt;&lt;p&gt;目前RSarXiv只提供两个简单的功能，一个是update今天最新的arxiv paper，你可以通过show me new papers in cs.CL等类似的话来获取cs.CL这个领域中最新的paper；一个是search功能，你可以通过search LSTM等类似的话来获取包括LSTM这个关键词的paper。由于是一个测试用的demo，就没做什么复杂的功能。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/026f59e0668853eede457ebe43756cfc.png" data-rawwidth="635" data-rawheight="387"&gt;&lt;/p&gt;&lt;p&gt;大家如果感兴趣的话，可以留言给我或者发邮件给我(mcgrady150318@gmail.com/mcgrady150318@163.com)，我邀请大家到这个slack team中。&lt;/p&gt;&lt;h1&gt;简单场景chatbot构建方法&lt;/h1&gt;&lt;p&gt;介绍了下api.ai提供的服务，下面简单地提炼一下。&lt;/p&gt;&lt;p&gt;chatbot = NLU + NLG&lt;/p&gt;&lt;p&gt;api.ai解决的重点问题是NLU的问题，NLU也是Dialogue State Tracker(DST)的核心和基础，而DST是chatbot的核心。这里的NLU包括两个问题：&lt;/p&gt;&lt;p&gt;1、从user inputs中识别出user intent和对应的action。&lt;/p&gt;&lt;p&gt;2、从user inputs中抽取出预先设定好的entity value，作为action的parameter。&lt;/p&gt;&lt;p&gt;NLG在api.ai这里基本上通过developer在Intent中设定response，当识别出是哪个intent之后，response自然就有了，最多空一些slot，用结果进行填充。如果developer选择了webhook，即需要从自定义的web service中给定response。如下图：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/a8dcdd37586477d5bfd0ef3304d22863.png" data-rawwidth="642" data-rawheight="199"&gt;&lt;/p&gt;&lt;p&gt;跑了一个简单场景的chatbot demo之后，简单归纳下构建方法：&lt;/p&gt;&lt;p&gt;1、从特定任务中归纳出Intents、Actions、Entities。&lt;/p&gt;&lt;p&gt;2、分别编写Intents、Entities的examples，两类examples是做DST的基础，用来训练chatbot准确地识别user intents和entity parameters，至于算法，自己写也可以，用api.ai也可以。&lt;/p&gt;&lt;p&gt;3、做好DST之后，chatbot就知道用户的意图和相应的参数，丢给后台的web service去执行，并得到执行的结果，然后填充预先定义好的templates，生成response，返回给用户。&lt;/p&gt;&lt;h1&gt;结束语&lt;/h1&gt;&lt;p&gt;简单场景的chatbot关键之处在于做好DST，有一个叫Dialogue State Tracking Challenge的比赛正式为了解决这个问题而举办的。我们说，封闭域的chatbot涉及两个方面，一是NLU，一是NLG，前者通过大量的examples来学习一个分类器和抽取器，得到Dialogue State，而后者根据Dialogue State，生成合适的response。&lt;/p&gt;&lt;p&gt;NLU不是一个简单的事情，尤其是标注大量的examples不是那么容易；NLG同样也不是一个好解决的问题，预先定义的template会让chatbot受限制于template的多少，手工痕迹太重，需要一种更牛的解决方案来代替。（其实挺多paper都在做这件事情，PaperWeekly也分享过几篇相关的paper，data driven的NLG方案同样需要大量的examples做训练。）&lt;/p&gt;&lt;p&gt;Context是个挺难的事情，现有的、成熟的解决方案仍是手工来定义条件，然后根据条件来trigger。我在想，能否构建一个动态的DST，可以是一张动态hash table，也可以是一个动态graph，记录着某一个user方方面面的状态，而不仅仅是某一轮对话中抽取出的信息，而是多轮对话中的信息，不仅在intent识别中可以用到context，在生成response时也可以用到，多轮对话和个性化对话都将不是什么问题了。或者，用现在流行的表示学习思维来想这个问题的话，也许context可以是一个分布式表示，user profile也是一个表示，NLG时以context distribution为condition来做generatation。&lt;/p&gt;&lt;p&gt;本文介绍了构建简单场景下chatbot的一般方法，用api.ai确实很容易做一个chatbot，而对于复杂场景，我觉得用api.ai来开发也没有太大问题，最费时的可能是构建context trigger。api.ai因为是面向developer的，所以对于普通的用户并不适合，但对于有一定经验的developer来说，使用起来就非常简单，提供的web界面也很好用，如果说chatbot是一个平台的话，那么api.ai正像是一个开发工具，提高了开发chatbot的效率，虽然NLG和context这两个问题可以做的更好，但整体来说降低了开发chatbot的门槛，是个很有意义和钱景的服务。&lt;/p&gt;&lt;h1&gt;PaperWeekly招人广告&lt;/h1&gt;&lt;p&gt;PaperWeekly每周会分享N篇当下最流行、最有趣的NLP paper，旨在用最精炼的话说明白paper的贡献和创新。目前运营在公众号和知乎专栏两个平台上，现在的形式是每周分享一篇NLP Paper周报，偶尔也会写一些NLP相关的博客，由于本人精力和水平有限，现邀请各位对NLP技术、NLP Paper感兴趣的童鞋加入一同运营，在推进国内NLP技术发展的路上贡献一份自己的力量。&lt;/p&gt;&lt;p&gt;微信公众号：PaperWeekly&lt;/p&gt;&lt;p&gt;http://weixin.qq.com/r/OUW0rA3ExVC6rUnP9xAr (二维码自动识别)&lt;/p&gt;&lt;p&gt;知乎专栏：&lt;a href="https://zhuanlan.zhihu.com/paperweekly" data-editable="true" data-title="PaperWeekly"&gt;PaperWeekly&lt;/a&gt;&lt;/p&gt;&lt;p&gt;微信交流群：&lt;/p&gt;&lt;p&gt;群已满100人，无法扫码加群，大家加zhangjun168305，我拉大家入群。&lt;/p&gt;</description><author>张俊</author><pubDate>Tue, 23 Aug 2016 13:44:24 GMT</pubDate></item><item><title>PaperWeekly FAQ</title><link>https://zhuanlan.zhihu.com/p/22133533</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/b5fea40c59029d4f648955c56fda4deb_r.jpg"&gt;&lt;/p&gt;&lt;p&gt;Q：Why do PaperWeekly?&lt;/p&gt;&lt;p&gt;A：最初的初衷是为了督促自己看paper，然后记录下读每篇paper中get到的一些收获。因为自己一直笃信厚积薄发，相信坚持每天读一篇paper，经过一定时间的沉淀一定会有所进步，有所收获。在做PaperWeekly的同时，认识了很多志同道合的朋友，也从他们的身上学到了很多。&lt;/p&gt;&lt;p&gt;Q：PaperWeekly现在准备做什么？&lt;/p&gt;&lt;p&gt;A：paperweekly在某一段时间内有一点名不副实，因为更新速度太快，几乎做成了daily，工作日更新一篇paper，在周末的时候写一篇总结性的文章。频繁地更新占用了几乎所有的业余时间，经过一番思考，决定将PaperWeekly改版成一周一篇，回归真正的weekly，具体的形式可以参考最近的两期paperweekly，形式可能还会改变，目的是为了更好给大家提供更好的服务。&lt;/p&gt;&lt;p&gt;Q：What‘s Next？&lt;/p&gt;&lt;p&gt;A：由于个人精力和水平都非常有限，所以非常希望邀请一些志同道合的朋友来运营PaperWeekly，你可以是学生，可以是工程师，可以是老师等等。只要你热爱，并且喜欢分享知识，都可以私信我。在PaperWeekly你可以推荐一些好玩的paper，也可以推荐好玩的topic，也可以推荐自己的paper，只要你愿意，当然我更希望你可以一起加入作者团队，来写文章。&lt;/p&gt;&lt;p&gt;Q：关于方向？&lt;/p&gt;&lt;p&gt;A：目前只限定方向是NLP领域的，因为如果领域太过分散的话，大家难以讨论在一起，所以这里限定了只接受NLP领域的paper。&lt;/p&gt;&lt;p&gt;Q：PaperWeekly的周边？&lt;/p&gt;&lt;p&gt;A：在运营paperweekly之前，写了一个微信公众号、ios app和一个网站，作用都是帮助用户更方便地从arxiv搜索和推荐paper，如果你对开发感兴趣，如果你有那么一点点业余时间想要做点什么东西出来或者学点python或者web开发、或者实现一些具体的算法，可以考虑加入paperweekly的周边开发项目rsarxiv，一起将我之前写的比较naive的arxiv检索和推荐应用更加完善化。关于paper检索，我有很多很多有趣的想法，苦于没有时间和精力来实现，如果你感兴趣，请一定私信我。&lt;/p&gt;&lt;p&gt;Q：关于bot化？&lt;/p&gt;&lt;p&gt;A：最近一直在看bot的paper，前几天看着api.ai的docs，实现了一个chatbot demo，功能是基本的检索和每日paper的update，bot放在slack平台上，如果你感兴趣的话，可以考虑将你的邮箱私信给我或者发邮件给我，我的邮箱是mcgrady150318@163.com(gmail同名)，我将邀请你加入slack team，来试用下这个chatbot demo。&lt;/p&gt;&lt;p&gt;Q：关于报酬？&lt;/p&gt;&lt;p&gt;A：我可能给不了显性的报酬，但我相信用自己的业余时间来运营paperweekly，以及开发一些program，都会让你学习到很多很多东西，这些东西可能是一些小恩小惠给不了你的。另外，由于paperweekly的关系，认识一些行业大牛、媒体和投资人，如果你创业、找工作或者是需要媒体宣传，我想我可以给你一点点微弱的帮助。&lt;/p&gt;&lt;p&gt;Q：具体招聘？&lt;/p&gt;&lt;p&gt;A：PaperWeekly目前需要招聘N名作者（N可能是5左右），基本要求：对NLP感兴趣，对paper感兴趣，喜欢写东西，喜欢分享知识。周边的Program可以锻炼动手能力，因为要写一个实实在在的paper推荐系统和搜索系统，涉及的平台也比较多，包括流行的chatbot，以及一些很有趣的功能，比如多paper summary摘要等。如果你对python感兴趣，也想动手实现一个系统的话，可以考虑加入paperweekly。&lt;/p&gt;&lt;p&gt;感谢大家对paperweekly的关注和支持，希望大家可以通过交流群有所收获，找到志同道合的朋友，找到一起合作的作者，找到一个满意的工作，找到一个靠谱的合伙人。如果需要加入paperweekly群聊，请添加微信zhangjun168305，我会拉大家入群。&lt;/p&gt;</description><author>张俊</author><pubDate>Tue, 23 Aug 2016 08:50:32 GMT</pubDate></item><item><title>PaperWeekly招人启事</title><link>https://zhuanlan.zhihu.com/p/22127821</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/b5fea40c59029d4f648955c56fda4deb_r.jpg"&gt;&lt;/p&gt;&lt;p&gt;PaperWeekly每周会分享N篇当下最流行、最有趣的NLP paper，旨在用最精炼的话说明白paper的贡献和创新。目前运营在公众号和知乎专栏两个平台上，现在的形式是每周分享一篇NLP Paper周报，偶尔也会写一些NLP相关的博客，由于本人精力和水平有限，现邀请各位对NLP技术、NLP Paper感兴趣的童鞋加入一同运营，在推进国内NLP技术发展的路上贡献一份自己的力量。&lt;/p&gt;&lt;p&gt;微信公众号：PaperWeekly&lt;/p&gt;&lt;p&gt;http://weixin.qq.com/r/OUW0rA3ExVC6rUnP9xAr (二维码自动识别)&lt;/p&gt;&lt;p&gt;知乎专栏：&lt;a href="https://zhuanlan.zhihu.com/paperweekly" data-editable="true" data-title="PaperWeekly"&gt;PaperWeekly&lt;/a&gt;&lt;/p&gt;&lt;p&gt;微信交流群：&lt;/p&gt;&lt;p&gt;http://weixin.qq.com/g/A9hjSVG1RjX0GRlw (二维码自动识别)&lt;/p&gt;&lt;p&gt;群人数超过了100人，无法扫码加入了，请大家添加zhangjun168305，然后我拉大家入群。&lt;/p&gt;</description><author>张俊</author><pubDate>Mon, 22 Aug 2016 17:59:32 GMT</pubDate></item><item><title>PaperWeekly 第二期</title><link>https://zhuanlan.zhihu.com/p/22062882</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/d35833c83746938c0418be1102f05222_r.png"&gt;&lt;/p&gt;&lt;h1&gt;引&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/d35833c83746938c0418be1102f05222.png" data-rawwidth="715" data-rawheight="487"&gt;&lt;/h1&gt;&lt;p&gt;图片来自paper &lt;a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/06/williams2016dstc_overview-1.pdf" data-editable="true" data-title="The Dialog State Tracking Challenge Series- A Review" class=""&gt;The Dialog State Tracking Challenge Series- A Review&lt;/a&gt;&lt;/p&gt;&lt;p&gt;人机对话系统通常包括上面的几个部分，task-oriented chatbot重点关注的是DST和NLG问题，其中DST是核心问题，没有太多关注这个比赛，但个人理解DST的作用类似于一张user conversation logs状态表，记录着用户当前的状态，以订机票为例，这张表的key是预先设定好的slots，比如目的地、出发地、出发时间等等，与系统背后的业务数据表中的attributes相关联，不断地从user conversation中抽取相应的values来填充这个表格，或者将其定义为一个多分类任务，不断地从对话中判断这句话中包括哪些slots和values（这里的values是多个分类结果），当状态表中的信息存在空白时，bot会根据空白的slots来提问并获取values，直到获取到足够的slots，给出用户suggestion，或者进行相应的服务。&lt;/p&gt;&lt;p&gt;DST的问题解决之后，就是NLG的问题。传统的NLG采用rule-based或者template-based的方法，需要很多的手动设置，横向扩展性较差，维护成本高。最近流行的end-to-end方案很适合解决这个问题，给定用户的query，结合着当前DST，自动生成response，完全的data driven，不需要什么人工干预。&lt;/p&gt;&lt;p&gt;生成response除了rule-based和end-to-end的方法之外，工业界中更加常见的是retrieve-based的方法，即从庞大的example base中进行retrieve，一方面避免了NLG生成response时常遇到的grammatical问题，另一方面当前的IR技术很容易集成到此类bot系统中，降低了门槛。&lt;/p&gt;&lt;p&gt;本期的三篇paper中前两篇都是关于task-oriented bot的NLG问题，第三篇是在retrieve-based bot的每个细小环节中应用了deep learning技术，并且将外部的非结构化文本作为数据源，从中select responses。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://www.emnlp2015.org/proceedings/EMNLP/pdf/EMNLP199.pdf" data-editable="true" data-title="Semantically Conditioned LSTM-based Natural Language Generation for Spoken Dialogue Systems"&gt;Semantically Conditioned LSTM-based Natural Language Generation for Spoken Dialogue Systems&lt;/a&gt;&lt;/h1&gt;&lt;h2&gt;关键词：NLG、bot、自定义LSTM&lt;/h2&gt;&lt;h2&gt;来源：EMNLP 2015&lt;/h2&gt;&lt;h2&gt;问题：task-oriented bot NLG问题，给定了user query和DST，如何生成一个更好的response？&lt;/h2&gt;&lt;h2&gt;方法：&lt;/h2&gt;&lt;p&gt;首先定义了两个概念delexicalisation和lexicalisation，前一个的意思是将句子中的slot-value用特定的token来替换，像是一种抽象，比如用food来代替对话中的各种食物名称；后一个的意思是将句子中的特定token还原回具体的value。&lt;/p&gt;&lt;p&gt;本文最大的亮点在于将传统的LSTM重新定义，针对这个具体问题在LSTM cell部分中添加了一层，Dialogue Act Cell，通过gate机制来保留合适的信息，比如slot keywords，如下图：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/366ff46deb8fe7c697076ec5d98cdca7.png" data-rawwidth="364" data-rawheight="351"&gt;&lt;/p&gt;&lt;p&gt;这一层cell更像是一个keyword detectors，整个NLG仍是采用encoder-decoder框架。&lt;/p&gt;&lt;h2&gt;评论：&lt;/h2&gt;&lt;p&gt;这层Dialogue Act Cell的目的是确保在decoding部分，不会遗漏任何一个slot，所以专门增加了一层cell来encoding act、slot-value信息，在生成时作为context vector。我觉得model的这个设计与attention机制有一点类似，只是attention更加地平滑，对每个word都有一个weight，而不是本文中的gate，非0即1。整体来说，自定义的cell是一个很有启发性的思路，针对具体问题的特点，修改现有的cell结构，也许会起到非常关键的作用。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://101.110.118.75/128.84.21.199/pdf/1606.03632v1.pdf" data-editable="true" data-title="Natural Language Generation in Dialogue using Lexicalized and Delexicalized Data"&gt;Natural Language Generation in Dialogue using Lexicalized and Delexicalized Data&lt;/a&gt;&lt;/h1&gt;&lt;h2&gt;关键词：NLG、bot、自定义LSTM&lt;/h2&gt;&lt;h2&gt;来源：arXiv 2016.06.11 cs.CL&lt;/h2&gt;&lt;h2&gt;问题：task-oriented bot NLG问题，是第一篇的升级版。&lt;/h2&gt;&lt;h2&gt;方法：&lt;/h2&gt;&lt;p&gt;本文是针对第一篇文章进行的改进版，改进的地方在于不仅仅利用了delexicalisation进行训练，而且利用了lexicalisation数据，从而提高了准确率，基本的模型框架与第一篇文章类似，不同的在于输入的处理，就是dialogue act的表示，如下图：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/14800a4bf548445cceace53803f8e649.png" data-rawwidth="392" data-rawheight="223"&gt;&lt;/p&gt;&lt;p&gt;每一个act representation由两部分组成，一部分是act、slots的one-hot表示，与文章一类似的结构，另一部分是由value的每个word embedding组合而成。&lt;/p&gt;&lt;p&gt;task-oriented bot NLG存在的一个更加现实的问题是data规模太小，cover的features太少，生成质量不高，本文针对这一问题，用相似domain的、大量的reviews或者其他相关数据作为corpus预训练出一个效果不错的LM，在decoding部分采用预训练好的LM模型权重进行NLG。&lt;/p&gt;&lt;h2&gt;评论：&lt;/h2&gt;&lt;p&gt;本文中最值得借鉴的地方在于transfer learning，虽然DL效果很好，但实际应用中常常遇到data规模太小的问题，DL难以发挥作用，但如果从大量相似的domain data中学习一些表示模型，然后迁移到待解决的问题上，这是一件幸事，也就是人们常说的举一反三。混合大量的相似domain数据，会cover到更丰富的features，为DL提供了广阔的舞台。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://aclweb.org/anthology/P16-1049" data-editable="true" data-title="DocChat: An Information Retrieval Approach for Chatbot Engines Using Unstructured Documents"&gt;DocChat: An Information Retrieval Approach for Chatbot Engines Using Unstructured Documents&lt;/a&gt;&lt;/h1&gt;&lt;h2&gt;关键词：Retrieve-Based Bot，Unstructured Documents&lt;/h2&gt;&lt;h2&gt;来源：ACL 2016&lt;/h2&gt;&lt;h2&gt;问题：如何从大量非结构化文本中select出合适的response返回给用户？&lt;/h2&gt;&lt;h2&gt;方法：&lt;/h2&gt;&lt;p&gt;本文研究的问题是给定大量的非结构化的documents和用户的query，从中选择并返回一个满意的response，典型的IR问题，作者将解决方案分为三步：&lt;/p&gt;&lt;p&gt;1、response检索，根据query，从documents中找到合适的N句话作为候选。&lt;/p&gt;&lt;p&gt;2、response排序，将候选中的utterances进行排序。&lt;/p&gt;&lt;p&gt;本文大多数的工作在ranking model上，提出了7种level的features来对candidate进行打分，通过实验发现sentence-level feature最有区分度。&lt;/p&gt;&lt;p&gt;3、response触发，并不是一定可以从documents找到合适的response，所以最后添加一个分类器，来判断最优的response是否合适，合适则输出，不合适则输出空。&lt;/p&gt;&lt;h2&gt;评论：&lt;/h2&gt;&lt;p&gt;本文解决的问题思路比较简单，但中间用到了很多复杂的DL model，个人感觉有点杀鸡用牛刀。本文的思路更加适合informative式的query，并不适合娱乐和闲聊。但用外部知识，尤其是大量的非结构化的、可能还带有噪声的资源来提供response，是一个很不错的思路，弥补了只用training data或者很有限的examples存在的局限性问题，如果可以将两者进行结合，是一个非常好的实用方案。&lt;/p&gt;&lt;h1&gt;Tips&lt;/h1&gt;&lt;p&gt;引起大家的讨论是一件挺难的事情，所以这一期不再提出问题。之前有同学问如何读paper，这里简单分享一个简单的tip，后续的每一期可能都会分享一个tip。&lt;/p&gt;&lt;p&gt;1、如果刚刚进入一个领域，建议读一些这个领域的survey或review类型的paper，这类型的paper基本上会将最近的方法归类进行总结，从一个较高的层次来解读每一篇paper的贡献和优缺点，对快速了解一个领域很有帮助。如果你关注的这个领域没有survey，那么恭喜你，说明你可能走到了前沿，用关键词去google一篇或者几篇相关的new paper，读Related Work那一节，相信你会有所收获。（注：这个方法是从清华大学刘知远博士那里学来的）&lt;/p&gt;</description><author>张俊</author><pubDate>Thu, 18 Aug 2016 07:06:31 GMT</pubDate></item><item><title>pet,baby and bot</title><link>https://zhuanlan.zhihu.com/p/22033341</link><description>&lt;p&gt;本文的想法来源于某一天对家里狗子Hare一些行为以及身边两个不到3岁的小朋友一些聪明行为的观察和思考，然后将这些行为和思考与当前流行的bot联系一下，形成了本文的内容。&lt;/p&gt;&lt;p&gt;首先，从pet聊起。我家养了一只聪明的小泰迪狗，心眼特别多，会撒娇会打滚会安慰人，非常聪明，他叫Hare。Hare从两个月大到了家里，从开始什么都不会，通过一天天地训练，学会了走、跑、跳、吃饭、喝水、上厕所、坐下、握手和哭。因为他的外婆（我的丈母娘）每天都和他说很多话，教他认识很多东西，所以他可以轻松地分辨出哪个玩具叫什么名字，可以轻松地理解我们说的很多话，不只是一些口令。当我说出门不带他玩的话，他会非常悲伤、可怜地开始哭泣（真的和小孩子哭一模一样）；当我说带他出去的时候，他就会非常兴奋地上蹿下跳；当我说我要出门办事不可以带他的时候，他就乖乖坐在门口目送你走，不哭不闹。所以，我在想Hare应该不是简单地通过观察我们的脸色和语气来识别我们的情绪，他可能真的听得明白很多的话，但一定不是全部，因为他的知识很有限，对这个世界的认识也很有限。Hare的学习绝大多数是监督学习，通过一些正例和负例进行训练，大多数的训练用正例效果非常明显，唯独训练他上厕所，用了不少负例，让他吃了不少苦头，这也带来不少的好处，监督学习很花费时间，样本的量级很重要，通过大量的训练+激励让Hare养成了良好的习惯，成为了一只听话的pet。&lt;/p&gt;&lt;p&gt;我一直在思考一个问题，pet在听主人说话的时候，是听懂了某些他可以理解的关键词还是他确实听懂了整句话，到底是字面意思还是semantic level呢？我想他应该有一定的自主学习能力，做到举一反三可能很难，但举一反二还是有可能的，而不仅仅是从大量的examples中进行学习，确实能够理解一些简单的话，同一个意思的不同说法他都可以理解。科学的解释需要做些实验来研究，这里我有一些简单的解释，第一，他有大脑，虽然没有人类发达，但智商可以和5、6岁的孩子相媲美；第二，他的监督学习不仅仅是从query-response pairs这样的examples中进行，而是更多的维度，包括每一次action之后的激励reward，做对一次动作之后赢得一个奖励，做错了受到惩罚，他不仅仅从主人的语言中来理解意思，还会结合别的因素，比如语调、语境、前一个时刻他的状态等等，而且他可以看到主人的表情和动作，这些因素都可以抽象成一种context。Hare如果前一秒刚刚犯了低级错误，这一秒如果我拿一个零食的叫他过来来吃的话，他就会明白，这其中一定有诈，他一定不会过来，虽然我并没有表现出生气的样子。&lt;/p&gt;&lt;p&gt;pet的事情我们先聊到这里，接下来聊一聊baby的事情。&lt;/p&gt;&lt;p&gt;身边正好可以接触到两个不到三岁的小宝宝，一个男孩一个女孩，他们有很多聪明的行为都让我感到吃惊。先从小男孩说起，小男孩每次来一起吃饭的时候，都会给大家表演他的绝技——认车牌。走在路上，你随意指一辆车，他几乎可以不出错地说出这辆车是本田还是丰田、还是起亚，这是一个典型的有监督多分类学习任务，他的父母有意无意地教他认识各种各样的车，经过一定时间和example的积累，他不断地将准确率提升，可能大脑的发育和将deep learning模型不断地复杂化道理类似吧。学习的过程是积累知识的过程，小男孩慢慢地认识了越来越多的车子，当然这需要不断地教和学，但无疑他本身就是一个知识库（knowledge base），而且认识很多我都不认识的车子，所以当我问他那是什么车的时候，他总是能够给我一个不错的答案。&lt;/p&gt;&lt;p&gt;说完小男孩的事情，再聊一聊小女孩的事情。小女孩语言能力很强，可以说很多的话，而且很多话都非常的funny。基本上和小女孩聊天，就是一个有趣的问答过程，这里的问答不只是我问她答，还有她问我答。小女孩经常和我妈妈在一起，妈妈会教她认识各种东西，因为妈妈信基督教，会教她做祷告，保佑自己一生平安，所以说她不仅仅可以回答一些基本的认知问题，而且有自己的特殊技能，表演“祷告”，而且做的有模有样。她是个求知欲非常强的问题宝宝，她总是指着一个东西，然后开始问我，“这是个什么东西？”，她主动学习的欲望很强，这意味着她的知识库积累地很快。以上都是比较常规的，最值得思考的是她的创造力。她认识很多的动物，也知道怎么称呼这些动物，她根据家里每一个人的名字，起了相应的动物外号，这个不是谁教她的，是她自己说出来的东西；之前提到的祷告词中，原话应该是希望上帝可以赐给她一些聪明智慧，那天在给我们“表演”的时候说出来的是“给她弄一些聪明智慧”，我想这个“弄一些”一定是其他的地方学来的，但她迁移到了这个语境中，这个迁移能力是值得思考的。我们都说理解一个东西不算厉害，如果能够掌握或者控制一个东西才算真正的厉害，她如果只是简单地重复已经学会的知识，也并不稀奇，但她偶尔会有意地装糊涂，故意地说一些错的东西看你能不能识别出来她的错误，她对一些信息的掌握程度很高。&lt;/p&gt;&lt;p&gt;小盆友的创造力让人惊奇，有很多值得思考的地方，相比于pet来说，baby的学习能力更强，带给人的惊喜度更大。chatbot，一个热门的topic，一个大家每天都在谈论的东西，确实还有很长的路要走，太多的地方不能令人满意。&lt;/p&gt;&lt;p&gt;1、最简单的一问一答现在都没有做的很好，example-based和rule-based虽然可以work，但限制太大，前者被example所限制，而后者被rule所限制，而paper中近一段时间流行的所谓generative式的bot看起来好像非常智能，读过paper之后会发现仍是基于example统计的，不管多么牛的模型，都是从example中学习features，example的规模和类型都会严重制约model，而且在生成response时面临着连贯性和语言学的问题，这也是被诟病最多的地方，也就是为什么example-based retrieve式的方法仍是主流的原因。&lt;/p&gt;&lt;p&gt;2、bot应该像人一样具有学习能力，尤其是主动学习能力。现在的bot有self-taught的能力，通常比较被动，并不具备主动学习的意识和能力。bot公司宣传的学习能力也通常是指对log的挖掘，从中找到一些有用的东西存在知识库里，丰富现有的example base。bot可以试着多提一些question，而不仅仅是做answer，主动地学习一些东西。&lt;/p&gt;&lt;p&gt;3、对context的利用和分析还有很长的路要走，context有很多种，如果是纯粹的语言bot，那么就是user之前说过的话，user的情绪，user的意图等等，如果不仅仅是语言的话，正如前面在说pet时提到的，context可以包括图像、语调等等。考虑的东西越多，bot的回答质量就会越高。&lt;/p&gt;&lt;p&gt;4、前几天看了几家科技媒体对新一代微软小冰的报道，说实话丢出挺多概念的，仔细看了下是用增强学习的思路来做，和训练pet比较类似，用一个reward作为牵引，带着bot学习programmer希望bot学习的action。&lt;/p&gt;&lt;p&gt;5、人会举一反三，聪明的动物会举一反二，迁移能力很重要，bot学习过类似的东西，就应该可以做类似的事情，而不是每次都需要重新从头开始学习，如何将已经学习到的知识迁移到新的领域也是一个非常有意义的topic。&lt;/p&gt;&lt;p&gt;从pet到baby，再到bot，从动物到人类，再到机器人，有着难以跨越的鸿沟，但pet、baby的行为可以带来启发和思考，给目前仍停留在初步阶段的bot带来一丝春风，一丝希望。&lt;/p&gt;</description><author>张俊</author><pubDate>Tue, 16 Aug 2016 11:18:41 GMT</pubDate></item><item><title>PaperWeekly 2016.08.05 第一期</title><link>https://zhuanlan.zhihu.com/p/21886170</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/256fe8a763046f46f6e701dd56442450_r.png"&gt;&lt;/p&gt;&lt;h1&gt;引&lt;/h1&gt;&lt;p&gt;学术界和工业界的需求和关注点不同，学术界更加注重未知领域的探索和方法的创新，研究的问题比较抽象，而工业界更加关注实际问题，方法不管是否创新，只要能够解决问题就是好方法，所面对的问题比paper中提炼出的数学问题更加具体，需要处理的细节更多。&lt;/p&gt;&lt;p&gt;paper的水平也是良莠不齐，尤其是arxiv上刷出来的paper更是水平各异。但整体来说，读paper会带来很多的启发，可以跟踪学术界对某一类问题的研究进展，不断地更新技术。关注工业界技术的应用和产品的更迭，可以不断地提炼出新的需求、新的数学问题，从而促进学术地发展，两者其实关系非常紧密。&lt;/p&gt;&lt;p&gt;本周开始，将paperweekly进行改版，从之前的每天一篇paper，改为每周一篇，内容包括多篇paper，这些paper可能相关、也可能不那么相关，但会说清每篇paper解决的问题和解决的方法，旨在拓宽视野，带来启发。本期是改版后的第一期，形式会一直不断地改进，希望工业界和学术界的朋友都能够有所收获。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://www.kdd.org/kdd2016/papers/files/rfp0289-zhaiA.pdf" data-editable="true" data-title="DeepIntent: Learning Attentions for Online Advertising with Recurrent Neural Networks" class=""&gt;DeepIntent: Learning Attentions for Online Advertising with Recurrent Neural Networks&lt;/a&gt;&lt;/h1&gt;&lt;h2&gt;关键词&lt;/h2&gt;&lt;p&gt;在线广告、RNN、Attention&lt;/p&gt;&lt;h2&gt;来源&lt;/h2&gt;&lt;p&gt;kdd2016&lt;/p&gt;&lt;h2&gt;问题&lt;/h2&gt;&lt;p&gt;如何用deep learning模型挖掘click logs来理解用户Intent？&lt;/p&gt;&lt;h2&gt;方法&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/506d0bff11bd46874cf0c4d278cee316.png" data-rawwidth="657" data-rawheight="285"&gt;&lt;/h2&gt;&lt;p&gt;对于一个(query,ad)数据对，分别用LSTM encode，然后用下图的方法计算一个attention，得到最终的query和ad vector，构造loss function，取logs中(query,ad)作为正例d+，将ad替换为其他无关ad作为负例d-，训练的目标是让d+的score尽量大，让d-的score尽量小。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/0dea3b7574ef958e4395e7c7c6e16788.png" data-rawwidth="821" data-rawheight="415"&gt;&lt;/p&gt;&lt;h2&gt;评论&lt;/h2&gt;&lt;p&gt;工业界有着学术界无法比拟的数据，大规模的真实数据是做deep learning的基础，大型商业搜索引擎积累了大量的ad click logs，利用好这些logs可以赚到更多的钱。attention机制在2015年开始逐渐成为一种流行趋势，借鉴于人类的注意力机制，让model将更多的注意力放在需要注意的地方，而不是每一个地方。本文并没有太多model上的创新，只是简单地将流行的model应用了自己研究的领域中，对工业界更有参考价值。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://120.52.73.76/arxiv.org/pdf/1608.00318v1.pdf" data-editable="true" data-title="A Neural Knowledge Language Model"&gt;A Neural Knowledge Language Model&lt;/a&gt;&lt;/h1&gt;&lt;h2&gt;关键词&lt;/h2&gt;&lt;p&gt;语言模型、知识图谱&lt;/p&gt;&lt;h2&gt;来源&lt;/h2&gt;&lt;p&gt;arXiv cs.CL 2016.08.01&lt;/p&gt;&lt;h2&gt;问题&lt;/h2&gt;&lt;p&gt;在自然语言生成(NLG)问题中，出现次数非常少的entity该如何生成呢？&lt;/p&gt;&lt;h2&gt;方法&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/256fe8a763046f46f6e701dd56442450.png" data-rawwidth="547" data-rawheight="432"&gt;&lt;/h2&gt;&lt;p&gt;四个步骤：&lt;/p&gt;&lt;p&gt;1、Input Representation&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/d99a6cf2fc284b83c1e490a4770b1433.png" data-rawwidth="526" data-rawheight="36"&gt;&lt;/p&gt;&lt;p&gt;输入由三个部分拼接而成，第一部分是上一个time step的fact表示，第二部分是上一个time step的词表中的词表示，第三部分是上一个time step的fact description表示，这里fact就是(subject,relation,object)，知识图谱中的一条事实，而后两个部分一定会有一个全为0，因为是二选一的关系，但为了保证每一次的输入都是等长向量，所以用拼接来做。得到输入之后，用LSTM来encode。&lt;/p&gt;&lt;p&gt;2、Fact Prediction&lt;/p&gt;&lt;p&gt;通过1的结果来预测当前word可能相关的fact，得到的结果是一个index，然后从topic knowledge中获得相应的表示，这里的knowledge embedding都是用transE训练好的，在整个模型训练中并不更新。&lt;/p&gt;&lt;p&gt;3、Knowledge-Copy Switch&lt;/p&gt;&lt;p&gt;根据1和2的结果，共同来预测当前要生成的词是从词表中获取的高频词还是从knowledge中获取的entity，典型的二分类问题。&lt;/p&gt;&lt;p&gt;4、Word Generation&lt;/p&gt;&lt;p&gt;根据3的结果，来生成当前time step的词。对于词表中的高频词，和之前的生成方法一致；对于fact description中的entity词，通过预测词的position来copy这个词。&lt;/p&gt;&lt;h2&gt;评论&lt;/h2&gt;&lt;p&gt;语言模型是一个基本问题，传统的方法都有着一个尴尬之处是，会生成大量的出来，只要是涉及到NLU的问题，基本都会遇到这个问题。本文提供了一个很有启发性的方法，借助于知识图谱这种外部知识来帮助生成效果更好的话，单纯地靠model来提升效果是一件比较困难的事情，但增加一些外部信息进来则会带来更多的可能性。由于知识图谱的构建本身就是一件不易的事情，因此本文的学术意义远大于实际应用意义，为后续这种交叉式研究（知识图谱+深度学习）打开了一扇门，大家可以尝试更多的组合和可能。&lt;/p&gt;&lt;h1&gt;&lt;a href="https://arxiv.org/pdf/1607.06952v1.pdf" data-editable="true" data-title="Neural Sentence Ordering"&gt;Neural Sentence Ordering&lt;/a&gt;&lt;/h1&gt;&lt;h2&gt;关键词&lt;/h2&gt;&lt;p&gt;句子排序&lt;/p&gt;&lt;h2&gt;来源&lt;/h2&gt;&lt;p&gt;arXiv cs.CL 2016.07.23&lt;/p&gt;&lt;h2&gt;问题&lt;/h2&gt;&lt;p&gt;给定乱序的N句话，如何将其按照逻辑排列好？（貌似是英语考试中的一种题型）&lt;/p&gt;&lt;h2&gt;方法&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/434b65bb816e75faa0df0a6a7326dea9.png" data-rawwidth="650" data-rawheight="373"&gt;&lt;/h2&gt;&lt;p&gt;本文定义的问题是给定n句话，找出最优排序，将这个问题降维到二维，就是如何排列两句话的顺序。上图给出了model的思路，对两句话分别进行encode，得到两个向量表示，然后进行打分，分数表示当前顺序是正确顺序的概率。这里的encode部分，分别用了每句话中word embeddings的加权平均、RNN和CNN来表示。&lt;/p&gt;&lt;p&gt;得到两两的排序之后，本文用beam search来得到整体最优的排序。&lt;/p&gt;&lt;h2&gt;评论&lt;/h2&gt;&lt;p&gt;多文档摘要问题中通用的一种做法是从每篇文档中都提取出一句或几句重要的话，然后进行排序。在英语考试中，有一种题型是给定你打乱顺序的几段话，然后根据逻辑将其排序。本文在学术上没有什么新的东西，但本文在构建neural model的时候，用到的数据集却非常容易构建，这意味着你在工程中应用这个方法来解决排序问题是可行的方案，所以本文更加适合有句子排序应用需求的工程人员来精读。&lt;/p&gt;&lt;h1&gt;提问&lt;/h1&gt;&lt;p&gt;计算机的会议非常多，各种level的都有，arXiv上每天都可以刷出一些paper，不同类型、不同level的paper适合不同需求的人来读，我觉得好东西的标准是适合而不是在某一个具体指标上达到最大，对你有用的东西才是适合你的好东西，有些特别牛逼的东西，有着极高学术价值的东西不见得适合工程人员来读，但也不应该是那种觉得学术上的东西离工程太远，没有什么具体用的态度，从各种各样的东西汲取养分，丰富和充实自己才是硬道理。读了一些paper，也该思考一些问题了，这里提出一些比较naive的问题，欢迎大家踊跃留言和讨论。&lt;/p&gt;&lt;p&gt;1、这种out-of-vocabulary的问题是一个非常常见的问题，有哪些不错的思路可以来解决这个问题呢？&lt;/p&gt;&lt;p&gt;2、attention model几乎满大街都是，最早在机器翻译领域中开始用这种模型，虽然在其他nlp领域中都取得了不错的成绩，但目前的attention真的适合每一类具体问题吗？是不是有一点为了attention而attention的感觉？neural summarization和machine translation真的可以完全类比吗？或者说attention适合解决具有什么特征的问题呢？&lt;/p&gt;&lt;p&gt;3、信息越多，model的效果一定会越好。现在外部信息非常丰富，但是如何融合到当前流行的model中来呢？如何将特定领域内构建的知识图谱完美地与特定任务中的model进行结合呢？以task-oriented bot为例，能够将客户的领域知识与bot response功能结合起来，做成一个更加高级的bot呢？&lt;/p&gt;&lt;p&gt;这里，我抛个砖，引个玉，希望更多的人能够参与讨论和提出问题。&lt;/p&gt;</description><author>张俊</author><pubDate>Fri, 05 Aug 2016 17:11:57 GMT</pubDate></item><item><title>如果做bot</title><link>https://zhuanlan.zhihu.com/p/21775977</link><description>&lt;p&gt;最近初步地研究了下bot这个领域，有了一点浅薄的理解，于是开始想，如果我也做bot的话，解决好哪些问题才会做好这件事情？&lt;/p&gt;&lt;p&gt;1、创业是一件严肃的事情，不是儿戏，需要做好充足的准备，调研和积累都是非常重要的，只有做好100分的准备，才可能在面对各种未知的困难时不慌乱。所以，第一步就是调研，研究bot，从方方面面，比如：&lt;/p&gt;&lt;p&gt;（1）bot为什么会火？（2）国内哪些企业在做bot？他们的产品有哪些优缺点？（3）国外哪些企业在做bot？有哪些优缺点？（4）投资情况如何？投资人怎么看待这个方向？（5）bot需要哪些技术积累？&lt;/p&gt;&lt;p&gt;2、从媒体、投资人的观点来看，bot整个大方向没有错，那么到底应该做哪个子领域呢？是客服？还是技术支持？技术平台？垂直私人助理？平台上应用？可做的事情其实很多，16年开始才井喷式地炒作bot这个概念，所以今年可以当做是bot元年，既然是刚刚起步的一个领域，就有一个天然的好处，蛋糕足够大，品类足够多，看你想吃哪一块？当然也有一个天然的坏处，就是无章可循，大家都是摸着石头过河。&lt;/p&gt;&lt;p&gt;（1）国内的情况是，客服已经有很多家企业在做了，做的模式大同小异，技术方面各有特色吧，可能起步早的现在规模大一些，晚的小一些，但整体来看差异化不大。如果选择这个方向的话，必须做出差异化，研究现有方案的缺点，之前写过一篇文章，简单剖析了现有方案的缺点和可改进的点，让目前的客服bot更进一步，要么就是做一家客服bot，产品更完美、技术更好，和大家分一杯羹；要么就是提供技术支持，帮现有的bot企业更进一步，赚他们的钱。&lt;/p&gt;&lt;p&gt;（2）如果是做技术支持，典型的SaaS+B2B，用自己的技术服务来为别的企业提供支持，response generation、user modeling、context modeling、information extraction都是不错的方向，每一个做好了都有广阔的前景，以为技术支持不直接面对业务，而是帮助改进现有企业提升算法和建模能力，应用的面比较广，可以用在各种类型的bot上以及其他应用背景上。&lt;/p&gt;&lt;p&gt;（3）平台上的应用，比如slack上的bot，做一个有趣的小功能，提高team的工作效率。这个在国外非常地火，平台也很多，就像是现在ios上开发app一样，每个app都有自己的功能。我觉得这块要是做的话，很容易做出差异化，现在已经有各式各样的startups做着各式各样的bot。但整体来说，技术门槛比较低，有一点API整合的意思，但如果你将自己的技术封装成API，在上面做一个bot提供服务也是一种不错的尝试，而且产品周期特别短，但终究卖点应该还是你的技术支持，而不是这个bot。&lt;/p&gt;&lt;p&gt;（4）技术平台的话，类似的有很多帮助企业或个人构建bot在各种平台上跑，假如微信现在开放了这一块，技术平台一定大有用处，这个属于基础的工具类产品，将很复杂的技术做成人人可以轻松使用的工具是一件很有意义的事情，像是IDE的感觉，不管什么背景，只要是有想法，就可以通过这个工具来实现一个bot，如果复杂的，可能需要定制。&lt;/p&gt;&lt;p&gt;（5）特定任务的私人助理，比如帮忙管理日程、制定旅行计划之类的，术业有专攻嘛，这个最好是之前在其他平台上做类似功能的企业转型到bot这里来，有着足够的积淀，融入一些新的交互和技术来提升产品体验。&lt;/p&gt;&lt;p&gt;上面的每个子领域在国外都有模板可以参考，国内的话还比较少，所以是很大的机会，关键在于判断，在于具体情况具体分析。因为有些东西并不适合做成bot这种聊天式的交互方式，简单的几个按钮操作就可以轻松完成的事情，为什么非要打很多的字来做呢？&lt;/p&gt;&lt;p&gt;3、壁垒。你的核心竞争力是什么？什么是你会别人不会的？如果腾讯也做这个事情，你们该怎么办？你的企业增长点在哪里？如何做大？&lt;/p&gt;&lt;p&gt;这些问题是投资人最关注的问题，其实也是创业前最应该想明白的问题，如果自己都想不明白，或者很多问题难以回答的话，说明现在的情况还不适合创业或者拿投资。我认为，无论什么时候人都是最核心的竞争力，技术和交互形式日新月异，更迭很快，团队只要具有很强的学习能力，永远都不会落于下风。没有什么技术一定是只有你一人才会的，工程上的技术壁垒不应是你提出了一个举世无双、天下无敌的算法，而是你在这个领域内实践各种各样算法的经验积累。为什么说一定要专注地做好一个事情，只做这一件事情，将这件事情做到精，因为对这么细小的领域理解地如此之深的人没有几个，这是你的技术壁垒，也是企业的生存之道，也是其他大公司难以抄袭的重要原因。这个问题一定要想清楚，最重要的是人，在技术层面上，不要想着找到一个独门秘籍来打天下，而是对你所研究的问题有非常深入地理解和见解，这是最基本的也是最核心的；接下来才是如何发展和壮大的问题，这个问题需要讲故事的能力，描绘出一幅美好画面的能力。&lt;/p&gt;&lt;p&gt;我觉得人的能力是最根本的壁垒，当然会有不同看法。有的企业快速扩张，积累客户，可能觉得积累的数据和客户资源是壁垒，但我觉得如果一个新的更好用的技术出来了，而你的企业技术却没跟上的话，很容易就会被取代的，不管你是5w+，还是10w+的客户。&lt;/p&gt;&lt;p&gt;一点思考，欢迎交流。&lt;/p&gt;</description><author>张俊</author><pubDate>Fri, 29 Jul 2016 09:00:55 GMT</pubDate></item></channel></rss>