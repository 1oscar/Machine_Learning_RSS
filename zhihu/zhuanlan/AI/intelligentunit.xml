<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>智能单元 - 知乎专栏</title><link>https://zhuanlan.zhihu.com/intelligentunit</link><description>斯坦福CS231n官方教程笔记翻译连载。

深度增强学习领域论文和项目的原创思考和Demo复现。

领域内其他感兴趣论文和项目的原创思考解读。</description><lastBuildDate>Wed, 21 Sep 2016 03:15:14 GMT</lastBuildDate><generator>Ricky</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>看图说话的AI小朋友——图像标注趣谈（上）</title><link>https://zhuanlan.zhihu.com/p/22408033</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/7c2ef2d9f4d9244473a201b0b19318ec_r.jpg"&gt;&lt;/p&gt;&lt;b&gt;版权声明：本文&lt;a href="https://zhuanlan.zhihu.com/intelligentunit" class="" data-editable="true" data-title="智能单元"&gt;智能单元&lt;/a&gt;首发，本人原创，禁止未授权转载。&lt;/b&gt;&lt;blockquote&gt;&lt;b&gt;前言&lt;/b&gt;：近来&lt;b&gt;图像标注（Image Caption）&lt;/b&gt;问题的研究热度渐高。本文希望在把问题和研究介绍清楚的同时行文&lt;b&gt;通俗有趣&lt;/b&gt;，&lt;b&gt;让非专业读者也能一窥其妙&lt;/b&gt;。文中还提出了&lt;b&gt;开源构建一个基于守望先锋的中文图像标注数据集的构想&lt;/b&gt;，欢迎知友讨论参与。&lt;/blockquote&gt;&lt;h2&gt;内容列表：&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;图像标注问题简介&lt;/b&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;图像标注是什么&lt;/li&gt;&lt;li&gt;当前水平&lt;/li&gt;&lt;li&gt;价值和意义&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;b&gt;图像标注数据集&lt;/b&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;MSCOCO&lt;/li&gt;&lt;li&gt;Flickr8K和Flickr30K&lt;/li&gt;&lt;li&gt;PASCAL 1K&lt;/li&gt;&lt;li&gt;&lt;b&gt;创建一个守望先锋数据集&lt;/b&gt;？&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;b&gt;图像标注评价标准&lt;/b&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;人类判断与自动评价标准&lt;/li&gt;&lt;li&gt;Perplexity&lt;/li&gt;&lt;li&gt;BLEU&lt;/li&gt;&lt;li&gt;ROUGE&lt;/li&gt;&lt;li&gt;METEOR&lt;/li&gt;&lt;li&gt;CIDEr &lt;b&gt;&lt;i&gt;注：上篇截止处&lt;/i&gt;&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;b&gt;图像标注模型发展&lt;/b&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;百度的m-RNN&lt;/li&gt;&lt;li&gt;谷歌的NIC&lt;/li&gt;&lt;li&gt;斯坦福的NeuralTalk&lt;/li&gt;&lt;li&gt;目前的State of art&lt;/li&gt;&lt;li&gt;对几个模型的比较&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;b&gt;代码实践&lt;/b&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;CS231n的LSTM_Captioning&lt;/li&gt;&lt;li&gt;基于Numpy的NerualTalk&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;b&gt;图像标注问题展望&lt;/b&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;模型图像部分、语言部分和连接方式上的更新&lt;/li&gt;&lt;li&gt;自动评价标注的更新&lt;/li&gt;&lt;li&gt;数据集的更新&lt;/li&gt;&lt;li&gt;小结&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;h2&gt;问题简介&lt;/h2&gt;&lt;p&gt;图像标注问题其本质是视觉到语言（Visual-to-Language，即V2L）的问题，解释起来很简单，就是四个字：&lt;b&gt;看图说话&lt;/b&gt;。就像老师要求小朋友们在看图说话作业中完成的任务一样，我们也希望算法能够&lt;b&gt;根据图像给出能够描述图像内容的自然语言语句&lt;/b&gt;。然而这种对于人类实在是小事一桩的小儿科级任务，在计算机视觉领域却不能不说是一个挑战：因为图像标注问题需要在两种不同形式的信息（图像信息到文本信息）之间进行“翻译”。&lt;/p&gt;&lt;p&gt;随着深度学习领域的发展，一种将深度卷积神经网络（Deep Convolutional Neural Network）和循环神经网络（Recurrent Neural Network）结合起来的方法在图像标注问题上取得了显著的进步。由于该方法的成功，使得基于该方法的对图像标注问题研究迅速地火热起来，在2016年的&lt;a href="http://cvpr2016.thecvf.com" data-title="IEEE国际计算机视觉与模式识别会议" class="" data-editable="true"&gt;IEEE国际计算机视觉与模式识别会议&lt;/a&gt;（即IEEE Conference on Computer Vision and Pattern Recognition，缩写为&lt;b&gt;CVPR&lt;/b&gt;）上专门有一个小型会议（session）的主题就是图像标注。&lt;/p&gt;&lt;p&gt;然而在“人工智能领域取得进展”这个问题上，显然大众和专业研究者们敏感程度是大不相同的，吐槽如下图所示：&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/d2195427d901f96541ef96446961233f.jpg" data-rawwidth="990" data-rawheight="300"&gt;&lt;b&gt;研究者&lt;/b&gt;：看我们根据图像生成了描述语句咯，不是以前的标签咯，厉不厉害？！~\(≧▽≦)/~&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/4906d07619a0b44d3f7fe726207df965.jpg" data-rawwidth="400" data-rawheight="297"&gt;&lt;b&gt;热心AI的大众&lt;/b&gt;：&lt;b&gt;→_→&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/e29fa599072b844a5cb31f542d90a3e9.jpg" data-rawwidth="600" data-rawheight="312"&gt;&lt;b&gt;暴雪&lt;/b&gt;：在“智能危机”结束之后，一群被放逐的&lt;b&gt;智能机器人&lt;/b&gt;感受到了被其称为“灵魂觉醒”的升华之道。他们在&lt;b&gt;冥思其存在本质和意义多年&lt;/b&gt;之后，渐渐相信他们不止是人工智能而已，和人类一样，他们&lt;b&gt;也有灵魂&lt;/b&gt;。——摘自&lt;a href="goog_1712963362" data-editable="true" data-title="守望先锋官网英雄"&gt;守望先锋官网英雄&lt;/a&gt;&lt;a href="http://ow.blizzard.cn/heroes/zenyatta" data-editable="true" data-title="禅雅塔简介"&gt;禅雅塔简介&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/aec9b9d222cfd8d2881c3df70db50455.jpg" data-rawwidth="400" data-rawheight="300"&gt;&lt;b&gt;热心AI的大众&lt;/b&gt;：和尚放大了！&lt;b&gt;恁死对面的源氏&lt;/b&gt;！世界需要更多的英雄！&lt;/p&gt;&lt;p&gt;之所以有这种反差，是大众对于人工智能认识的起点，几乎是人工智能研究者奋斗的终极目标：）&lt;/p&gt;&lt;p&gt;回到图像标注问题，那么现在该领域最厉害的方法，到底达到了什么样的水平？我的看法是：&lt;b&gt;貌似接近人类，其实差距尚大&lt;/b&gt;。&lt;/p&gt;&lt;p&gt;为什么说貌似接近人类呢？这里引用几篇论文中表格：&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/899efcd8d9b02c2c7f7c7bd5b1038468.png" data-rawwidth="782" data-rawheight="374"&gt;上面这个表格来自于目前图像标注领域结果最好的论文：《&lt;a href="http://arxiv.org/abs/1506.01144" data-title="What Value Do Explicit High Level Concepts Havein Vision to Language Problems?" class="" data-editable="true"&gt;What Value Do Explicit High Level Concepts Havein Vision to Language Problems?&lt;/a&gt;》，作者们来自澳大利亚Adelaide大学的计算机学院。上面表格是论文中作者们展示了自己的算法和其他算法在微软的COCO数据库的测试集上取得的测试结果。其中，5-Refs和40-Refs表示的是测试集中有两个数据集，一个数据集每张图像有5个参考标注（也就是人类输入的正确语句），一个数据集每张图像有40个参考标注。&lt;/p&gt;&lt;p&gt;B-N（N=1，2，3，4），M，R和CIDEr代表的是4中不同的对于算法的自动评价标准，后文会详细介绍，这里只需要&lt;b&gt;知道得分越高越好&lt;/b&gt;。参与比较的有包含论文方法在内的4种图像标注算法和人类水平。可以看见在&lt;b&gt;14个得分中，论文方法有13个得分都超过了人类得分&lt;/b&gt;。&lt;/p&gt;&lt;p&gt;&lt;b&gt;那么是不是论文方法就已经超越人类水平了呢？在我看来，答案是否定的&lt;/b&gt;。至于为什么，原因将在后文关于&lt;b&gt;图像标注算法评价标准的小节&lt;/b&gt;中揭晓。&lt;/p&gt;&lt;p&gt;虽说我个人认为最高水平的算法也尚未超过人类表现，但是其进展是毋庸置疑的，各种算法已经能够让人类评价者觉得非常不错的图像标注了。比如在上表中提到的LRCN模型，就能根据图像生成这样的描述：&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/fc97868a916e972e0d36baefb8fa9df5.png" data-rawwidth="1580" data-rawheight="454"&gt;大家看了是不是觉得已经非常惊艳了？不要太激动，依旧存在一些惨不忍睹的：&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/4c01fe630c5e0c43fab8f461add7c2e5.png" data-rawwidth="1424" data-rawheight="396"&gt;这些错误的图像标注案例是来自斯坦福视觉实验室的论文《&lt;a href="http://arxiv.org/abs/1412.2306" data-editable="true" data-title="Deep Visual-Semantic Alignments for Generating Image Descriptions" class=""&gt;Deep Visual-Semantic Alignments for Generating Image Descriptions&lt;/a&gt;》，第一作者是Andrej Karpathy，学习了斯坦福深度学习课程CS231n 2016的同学对作为讲师的他应该很熟悉了。我们可以看见最右边的图像标注语句尤其离谱，“在路中间站着一匹马”，大兄弟，感情这马🐴是透明的咯？&lt;/p&gt;&lt;p&gt;图像标注问题如果能够得到很好的解决，那么价值是显而易见的，可以应用到&lt;b&gt;图像检索，儿童教育和视力受损人士的生活辅助等方面&lt;/b&gt;。而从学术的角度来看，当前图像标注问题的研究，促使人工智能领域的两大领域，计算机视觉和自然语言处理很好地结合，这种跨子领域的结合能够催生出更让人惊艳的方法吗？我个人表示很期待。&lt;/p&gt;&lt;h2&gt;图像标注数据集&lt;/h2&gt;&lt;p&gt;到目前为止，深度学习依旧是一种需要大量数据来进行驱动的方法。小样本学习尚未有突破性的进展，所以数据对于基于深度学习的算法依旧非常重要。在图像标准问题研究的过程中，研究者们对于基准数据库的选择偏好也在发生变化，一些数据集运用的越来越广泛，而一些数据集则越来越少地被使用。本小节将基于图像标注问题，对这些数据集做简要的介绍和对比。&lt;/p&gt;&lt;h2&gt;Microsoft COCO Caption数据集&lt;/h2&gt;&lt;p&gt;Microsoft COCO Caption数据集的推出，是建立在Microsoft Common Objects in COntext
(COCO)数据集的工作基础上的。在论文《&lt;a href="http://arxiv.org/abs/1504.00325" data-editable="true" data-title="Microsoft COCO Captions: Data Collection and Evaluation Server"&gt;Microsoft COCO Captions: Data Collection and Evaluation Server&lt;/a&gt;》中，作者们详细介绍了他们基于MS COCO数据集构建MS COCO Caption数据集的工作。&lt;/p&gt;&lt;p&gt;简要地来说，就是对于原COCO数据集中约330,000张图像，使用亚马逊公司的“&lt;b&gt;土耳其机器人（Mechanical
Turk）&lt;/b&gt;”服务，&lt;b&gt;人工地&lt;/b&gt;为每张图像都生成了至少5句标注，标注语句总共超过了约150万句。至于亚马逊的“土耳其机器人”服务，其实也就是另一种形式的雇人拿钱干活而已。&lt;/p&gt;&lt;p&gt;实际上，COCO Caption数据集包含了两个数据集：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;第一个数据集是MS COCO c5。它包含的训练集、验证集合测试集图像和原始的MS COCO数据库是一致的，只不过每个图像都带有5个人工生成的标注语句。&lt;/li&gt;&lt;li&gt;第二个数据集是MS COCO c40。它只包含5000张图片，而且这些图像是从MS COCO数据集的测试集中随机选出的。和c5不同的是，它的每张图像都有用40个人工生成的标注语句。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;之所以要做MS COCO c40数据集，是因为如果有更多的参考标注语句，很多对于算法生成的标注的自动计算标准能够和人类判断有更高的相关性。下一步可能将MS COCO验证集中所有的图像都加上40个人工生成的标注语句。&lt;/p&gt;&lt;p&gt;作者们的另一个主要工作就是搭建了一个评价服务器，实现了当前最流行的评价标准（BLEU, METEOR, ROUGE and CIDEr）。使用MS COCO Caption数据集训练并用验证机调参后，研究者可以按照固定的JSON格式：&lt;/p&gt;&lt;pre&gt;&lt;code lang="text"&gt;[{
"image_id":int,
"caption" :str,
}]&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;向服务器上传自己算法对于测试集图像生成的标注语句，服务器将自动地给出各种评价标准的得分。要上传结果，需要在&lt;a href="https://www.codalab.org/competitions/3221" data-editable="true" data-title="CodaLab"&gt;CodaLab&lt;/a&gt;注册账号，且每个账号能够提交结果的次数是有限的。微软在Github上也提供了能够在本地对验证集数据生成标注进行评价的代码，地址&lt;a href="https://github.com/tylin/coco-caption" data-editable="true" data-title="在这里"&gt;在这里&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;简言之，MS COCO Caption数据集就是针对图像标注问题创建的，图像及其标注数量大，提供了现成的评价标准计算服务器和代码。就目前发表的高水平论文来看，MS COCO Caption数据集已经越来越成为研究者的首选。&lt;/p&gt;&lt;h2&gt;Flickr8K和30K&lt;/h2&gt;&lt;p&gt;Flickr8K和Flickr30K数据集的特性从它们的命名就能很方便地猜测出来：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;图像数据来源是雅虎的相册网站Flickr；&lt;/li&gt;&lt;li&gt;数据集中图像的数量分别是8,000张和30,000张（确切地说是31,783）；&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这两个数据库中的图像大多展示的是人类在参与到某项活动中的情景。每张图像的对应人工标注依旧是5句话。这两个数据库本是同根生，所以其标注的语法比较类似。数据库也是按照标准的训练集、验证集合测试集来进行分块的。&lt;/p&gt;&lt;p&gt;相较于MS COCO Caption数据集，Flickr8K和Flickr30K数据集的明显劣势就在于其数据量不足。我个人“不乏恶意”地揣度：&lt;/p&gt;&lt;pre&gt;&lt;code lang="python"&gt;微软：他们搞图像标注都用什么数据库呀？
员工：Flickr数据集居多吧。
微软：数量多少呀？
员工：开始是8k，后来出了个30k，感觉够用了。
微软：搞个大新闻，让他们只有我们一个零头！做个330k的！
员工：好的老板，是的老板，微软大法好！&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;在论文《&lt;a href="http://arxiv.org/abs/1411.5654" data-editable="true" data-title="Learning a Recurrent Visual Representation for Image Caption Generation"&gt;Learning a Recurrent Visual Representation for Image Caption Generation&lt;/a&gt;》中作者指出：&lt;/p&gt;&lt;blockquote&gt;We observed this fine-
tuning strategy is particularly helpful for MS COCO, but
does not give much performance gain on Flickr Datasets before it overfits. The Flickr datasets may not provide enough
training data to avoid overfitting. 翻译：我们观察到这个精细调整策略在使用MS COCO数据集训练的时候效果很好，但是在Flickr数据集上算法却没有很明显的提升。可能是因为Flickr数据集没有提供足够多的数据来防止算法过拟合吧。&lt;/blockquote&gt;&lt;p&gt;眼尖的知友会发现，上面这篇论文的作者中，有一位是微软的......于是我又忍不住“邪恶”脑洞一下：&lt;/p&gt;&lt;pre&gt;&lt;code lang="python"&gt;员工：老板，论文发了！
微软：不错，黑得有水平，不留痕迹。
员工：那您看......
微软：好说好说。&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;以上虽然是玩笑话，但是数据量上的劣势，确实使Flickr数据集正逐渐失宠，14年论文中几乎都使用，现在一些高水平论文仅在补充文档中展示甚至不采用。个人还是希望Flickr数据集能够有一个比较好的更新，比如来个333k的？&lt;/p&gt;&lt;h2&gt;PASCAL 1K&lt;/h2&gt;&lt;p&gt;该数据集的图像是大名鼎鼎的PASCAL VOC challenge图像数据集的一个子集，对于其20个分类，随机选出了50张图像，共1,000张图像。然后同样适用亚马逊公司的土耳其机器人服务为每张图像人工标注了5个描述语句。一般说来，这个数据集只是用来测试的。&lt;/p&gt;&lt;p&gt;在其他论文中，还有一些诸如&lt;b&gt;IAPR TC-12&lt;/b&gt;，&lt;b&gt;SBU&lt;/b&gt;等数据集，数据采集思路都大同小异，这里就不一一介绍了。&lt;/p&gt;&lt;h2&gt;创建基于守望先锋的图像标注数据集？&lt;/h2&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/6ee0e745fcdc2659f6a54f5409351e4b.jpg" data-rawwidth="1920" data-rawheight="1030"&gt;&lt;blockquote&gt;标注：来自东方的戴眼镜的某组织领导者正在殴打来自东方某半岛的女性直播。&lt;/blockquote&gt;&lt;p&gt;脑洞简言之：&lt;b&gt;开源搭建一个简单的图像标注页面，接受玩家的游戏截图投稿和对图像的中文标注，当数据收集达到目标数量后，数据集对所有参与贡献的人开放&lt;/b&gt;。做这件事的价值有两点：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;目前为止，个人&lt;b&gt;没有看到一个基于中文的公开图像标注数据集&lt;/b&gt;。&lt;/li&gt;&lt;li&gt;基于守望先锋的故事背景，能够&lt;b&gt;吸引更多的年轻人从对游戏中人工智能的兴趣进而对真正的人工智能研究感兴趣&lt;/b&gt;。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;为啥我对守望先锋情有独钟，主要是游戏基于后人工智能危机时代的世界观设定和故事吸引。看着网易乐呵呵地说守望先锋的销量超过了暗黑破坏神3，那么守望的销量也该有300万了吧？基于这个&lt;b&gt;庞大的玩家群体&lt;/b&gt;，如果这个数据集创建项目能够在玩家中有一定影响力，那么数据集的图像和标注数量应该比较客观。&lt;/p&gt;&lt;p&gt;当然，这只是我的一个小脑洞，&lt;b&gt;欢迎认可这个脑洞的知友在评论中留言讨论&lt;/b&gt;！我个人是真心希望推动这个脑洞成真。对了，个人倾向于&lt;b&gt;使用Ruby On Rails&lt;/b&gt;来搭建网站及后台。&lt;/p&gt;&lt;h2&gt;图像标注评价标准&lt;/h2&gt;&lt;p&gt;在简介中，提到虽然在多个评价标准的得分中，最新的方法的得分已经超过人类得分，但是我仍然不认为算法的真实水平超过人类，其原因就在于这些&lt;b&gt;自动评价标准（automatic evaluation metric）&lt;/b&gt;上！&lt;/p&gt;&lt;h2&gt;人类判断与自动评价标准&lt;/h2&gt;&lt;p&gt;简而言之，算法根据图像生成出来的标注语句质量高不高？和图像内容是不是相符？语法上有没有错误？&lt;b&gt;评价这些最靠谱最权威的还是咱们人类老爷&lt;/b&gt;！而各类的&lt;b&gt;自动评价标准的目前都是尽量让自己的计算结果能够和人类判断结果相关&lt;/b&gt;。&lt;/p&gt;&lt;p&gt;论文《&lt;a href="http://www.aclweb.org/anthology/P/P14/P14-2074.xhtml" data-editable="true" data-title="Comparing Automatic Evaluation Measures for Image Description"&gt;Comparing Automatic Evaluation Measures for Image Description&lt;/a&gt;》关于这个问题就有很细致的分析。论文基于Flickr8K和E&amp;amp;K数据集，对BLEU、ROUGE、METEOR，TER几个评价标准与人类判断的相关性进行了研究，结果显示：&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/c848d3b9934448272355b67eaf6ed21c.png" data-rawwidth="724" data-rawheight="482"&gt;论文中指出：与人类判断的相关性co-efficient在0.0–0.1是不相关，0.11–0.4是弱相关，0.41–0.7是中等相关，0.71–0.90是强相关，如果在0.91–1.0那就很完美了。所以论文的结论是首先推荐METEOR，或者使用ROUGE SU-4和Smoothed BLEU。PS：由于CIDEr标准是2015发布，所以这篇论文中没有体现。&lt;/p&gt;&lt;p&gt;而在谷歌2015年的论文《&lt;a href="http://arxiv.org/abs/1411.4555" data-title="Show and Tell: A Neural Image Caption Generator" class="" data-editable="true"&gt;Show and Tell: A Neural Image Caption Generator&lt;/a&gt;》中，更是三图胜千言：&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/cda54a4f425a16b865032c9dcba879c5.png" data-rawwidth="772" data-rawheight="734"&gt;我们可以看到：在表1中，实验使用了微软的COCO数据集，3中评价标准的得分，谷歌NIC模型的得分和人类（Human）得分是不相仲伯的。在表2中，基于不同数据集统一计算BLEU-1得分，NIC的得分和人类得分也比较接近。是不是很牛了？&lt;/p&gt;&lt;p&gt;&lt;b&gt;&lt;u&gt;然而难能可贵的是人家马上就自己打自己的脸！&lt;/u&gt;&lt;/b&gt;在装了逼后，作者们&lt;b&gt;马上开始说实话&lt;/b&gt;。补充了一个基于人类判断的实验，邀请人类对于自己生成的标准语句进行评级，一共分成4个等级：&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/79db143aa3a04a40d8f9b33078690b0e.png" data-rawwidth="1912" data-rawheight="458"&gt;如上图所示，分成“描述没有错误”、“描述中有点小错误”、“多少还是和图像相关”和“和图像无关”4个等级，分别得分从4到1。那么，真实的对比就来了：&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/a9ba6674deaa9b1e05d971d4584854ca.png" data-rawwidth="884" data-rawheight="664"&gt;上图中，x坐标是BLEU得分，y坐标是表示积累分布（也就是说，输出的描述语句集合中，有百分只多少的得分大于当前的x）。其中：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Flickr-8k：NIC表示的是使用NIC模型在Flick8k测试集上跑的结果的得分曲线；&lt;/li&gt;&lt;li&gt;Pascal：NIC表示的是是使用NIC模型在Pascal测试集上跑的结果的得分曲线；&lt;/li&gt;&lt;li&gt;COCO-1k：NIC表示的是是使用NIC模型在COCO-1k测试集上跑的结果的得分曲线；&lt;/li&gt;&lt;li&gt;Flickr-8k：ref表示的是另一篇论文的结果的得分曲线，这里作为一个基准；&lt;/li&gt;&lt;li&gt;Flickr-8k：GT表示的是对Flickr-8k图像的人工标注语句同样进项人工分等级评价的结果。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;由此可见：虽然自动裁判员BLEU-4认为NIC模型的得分超出了人类得分，但是如果让人类来当裁判员，NIC还差得远哪！这一结果也印证了上一篇论文中对于不同自动评价标准的分析。&lt;/p&gt;&lt;p&gt;当然，自动评价标准也在持续发展着，2015年发布的专门面向图像标注问题的自动评价标准CIDEr就做的更好些。&lt;/p&gt;&lt;p&gt;在刚才的人类判断与自动评价标准讨论中，几个标准的名称大家都应该比较熟悉了，接下来我就简单地介绍一下，并帮助大家理解它们是如何进行计算的：&lt;/p&gt;&lt;h2&gt;Perplexity&lt;/h2&gt;&lt;p&gt;首先，&lt;b&gt;这个perplexity该翻译成中文的哪个词&lt;/b&gt;就让我反复琢磨了好些天。查阅资料的过程中，大家要么就是不翻译（非我所认同），或者翻译为&lt;b&gt;复杂度&lt;/b&gt;、&lt;b&gt;混乱度&lt;/b&gt;或者&lt;b&gt;困惑度&lt;/b&gt;等。如何翻译先按下不表，所谓“信达雅”，第一是要把事情说明白，那么我们就先来把Perplexity理解了，再来选择译名不迟：&lt;/p&gt;&lt;p&gt;关于perplexity，在维基百科上有&lt;a href="https://en.wikipedia.org/wiki/Perplexity" data-editable="true" data-title="详细的解释"&gt;详细的解释&lt;/a&gt;，但是这里我想引用的是2014年百度的论文《&lt;a href="http://arxiv.org/abs/1410.1090" data-title="Explain Images with Multimodal Recurrent Neural Networks" class="" data-editable="true"&gt;Explain Images with Multimodal Recurrent Neural Networks&lt;/a&gt;》中对perplexity的定义公式。为什么引用这篇呢？这篇论文是我读的论文中最早提出将RNN和CNN结合起来用于图像标注的，以此表示敬意。作者们在简介中也是这么说的：&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;To the best of our knowledge, this is the first work that incorporates the Recurrent
Neural Network in a deep multimodal architecture.&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;他们提出的&lt;b&gt;m-RNN&lt;/b&gt;模型也是后续论文方法的常用比较方法之一。在论文中，作者们结合图像标注任务，将perplexity定义为：&lt;/p&gt;&lt;equation&gt;log_2PPL(w_{1:L}|I)=-\frac{1}{L}\sum^L_{n=1}log_2P(w_n|w_{1:n-1},I)&lt;/equation&gt;&lt;p&gt;其中，&lt;equation&gt;L&lt;/equation&gt;是句子的长度，&lt;equation&gt;PPL(w_{1:L}|I)&lt;/equation&gt;就是根据图像&lt;equation&gt;I&lt;/equation&gt;给出的描述句子&lt;equation&gt;w_{1:L}&lt;/equation&gt;的perplexity。而&lt;equation&gt;P(w_n|w_{1:n-1},I)&lt;/equation&gt;是根据图像&lt;equation&gt;I&lt;/equation&gt;和前面的单词序列&lt;equation&gt;w_{1:n-1}&lt;/equation&gt;生成下一个单词&lt;equation&gt;w_n&lt;/equation&gt;的概率。对于此前没有接触过自然语言处理的同学（包括我）来说，此刻的感觉就是：&lt;b&gt;what fxxk ?!&lt;/b&gt;&lt;/p&gt;&lt;blockquote&gt;不要惊慌。——《&lt;a href="https://book.douban.com/subject/1394364/" data-editable="true" data-title="银河系漫游指南"&gt;银河系漫游指南&lt;/a&gt;》&lt;/blockquote&gt;&lt;p&gt;&lt;b&gt;举例子&lt;/b&gt;：下面我们用守望先锋的游戏画面来举个例子。假设知友们和玩家们很给力，前面提到的守望先锋图像标注数据集已经有了足够的数据量了，我们也成功地训练了一个图像标注模型，恩，就叫她&lt;b&gt;ATHENA&lt;/b&gt;吧！Athena是&lt;b&gt;Advanced Tactical Heroine Assistance&lt;/b&gt;的缩写！（劳资真是缩写拼凑小王子！）&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/eaa7e55ded2c3bdc3c9e44fb1f5492ac.jpg" data-rawwidth="699" data-rawheight="293"&gt;&lt;p&gt;我们将上面这张图输入模型，假设模型给出了图像标注句子：&lt;/p&gt;&lt;blockquote&gt;there are two screens on the table.&lt;/blockquote&gt;&lt;p&gt;恩，语句和图像内容相关度还不错，那么我们就计算一下PPL来评价下这个句子。首先我们应该将句子补充一下，&lt;b&gt;添加一个特殊的开始和结束符号&lt;/b&gt;：&lt;/p&gt;&lt;p&gt;&lt;b&gt;&amp;lt;STA&amp;gt;&lt;/b&gt;there are two screens on the table&lt;b&gt;&amp;lt;END&amp;gt;&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们知道，RNN生成句子的方式是采取一个单词一个单词预测的方式，那么假设咱们的词汇表里面有100个单词吧（挺少的），好了，现在从开始符号开始：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;模型根据图像，从&amp;lt;STA&amp;gt;符号开始，对词汇表中100个单词分别给出了每个单词可能为&amp;lt;STA&amp;gt;下一个单词的可能性，其中由于there单词的可能性为0.6，高于其他单词，所以最终就选择了there；&lt;/li&gt;&lt;li&gt;模型根据图像和&amp;lt;STA&amp;gt;there序列，再次对词汇表中100个单词分别给出了每个单词可能为下一个单词的可能性，其中are的可能性为0.8，高于其他单词，所以选择了are；&lt;/li&gt;&lt;li&gt;以此类推，假设two的可能性为0.3，screens的可能性为0.4，on的可能性为0.3，the的可能性为0.5，table的可能性为0.6；&lt;/li&gt;&lt;li&gt;当table出现后，模型预测下一个为&amp;lt;END&amp;gt;结束符号，句子生成结束。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;那么根据上面例子，&lt;equation&gt;L=7&lt;/equation&gt;，上面公式的右部就变成了：&lt;/p&gt;&lt;equation&gt;-\frac{1}{L}\sum^L_{n=1}log_2P(w_n|w_{1:n-1},I)=-\frac{1}{7}(log_2(0.6)+log_2(0.8)+log_2(0.3)+log_2(0.4)+log_2(0.3)+log_2(0.5)+log_2(0.6))&lt;/equation&gt;&lt;p&gt;由此可得：&lt;/p&gt;&lt;equation&gt;log_2PPL(w_{1:L}|I)=1.0845&lt;/equation&gt;&lt;p&gt;于是：&lt;/p&gt;&lt;equation&gt;PPL(w_{1:7}|I)=2^{1.0845}=2.12&lt;/equation&gt;&lt;p&gt;于是我们就得到了这个根据图像得出的标注语句的Perplexity值为2.12。那么我们的Athena的perplexity水平如何呢？这里引用一下百度这篇论文的结果表格：&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/6adb35fe9216103573556319ada4e870.png" data-rawwidth="920" data-rawheight="424"&gt;可以看见，m-RNN的PPL（即perplexity的缩写）值是6.92。那么这个分数值是低好一些还是高好一些呢？&lt;/p&gt;&lt;p&gt;我们利用刚才的例子重新算一遍，将每个单词的可能性都降低一些，就会发现perplexity值会升高。这就说明：&lt;b&gt;当模型对于下一个生成单词的确信程度降低时，perplexity值反而升高。我们当然是期望一个模型对于它预测的单词能比较有把握啊，所以perplexity值是越低越好&lt;/b&gt;。&lt;/p&gt;&lt;p&gt;到了这里，我们就可以讨论perplexity到底可以怎么翻译了，其实我个人比较赞同&lt;a href="https://www.zhihu.com/people/4735cce127addcedc38470543c4ff409" data-hash="4735cce127addcedc38470543c4ff409" class="member_mention" data-editable="true" data-title="@硅谷王川" data-hovercard="p$b$4735cce127addcedc38470543c4ff409"&gt;@硅谷王川&lt;/a&gt;在文章中的一句话：&lt;/p&gt;&lt;blockquote&gt;换言之, 聊天机器人使用的语言模型, 如果&lt;b&gt;困惑度&lt;/b&gt;足够低,那么它就能够写出流利通顺和逻辑清晰的语句。借用韩愈老师在&amp;lt;师说&amp;gt;里的话:“&lt;b&gt;机器非生而知之者，孰能无惑？&lt;/b&gt;". 语言模型里进一步解惑的工具,则来自更多的数据和更精巧的算法。&lt;/blockquote&gt;&lt;p&gt;机器非生而知之者，孰能无惑？妙！所以我&lt;b&gt;个人认为将perplexity翻译为困惑度比较好&lt;/b&gt;。&lt;/p&gt;&lt;h2&gt;BLEU&lt;/h2&gt;&lt;p&gt;BLEU是&lt;b&gt;B&lt;/b&gt;i&lt;b&gt;l&lt;/b&gt;ingual &lt;b&gt;E&lt;/b&gt;valuation &lt;b&gt;U&lt;/b&gt;nderstudy的缩写。这个计算标准在图像标注结果评价中使用是很广泛的，但是它的设计初衷并不是针对图像标注问题，而是针对机器翻译问题，它是用于分析待评价的翻译语句和参考翻译语句之间n元组的相关性的。直白地来说，它的核心思想就是：&lt;b&gt;机器翻译语句与人类的专业翻译语句越接近就越好&lt;/b&gt;。&lt;/p&gt;&lt;p&gt;&lt;b&gt;一些需要说明的符号含义&lt;/b&gt;：对于图像&lt;equation&gt;I_i&lt;/equation&gt;，模型会生成对应的标注语句&lt;equation&gt;c_i&lt;/equation&gt;，自动评价标准能够根据参考标注语句（也就是人工标注的语句）的一个集合&lt;equation&gt;S_i=\{s_{i1},...,s_{im} \}\in S&lt;/equation&gt;，对待评价的标准语句&lt;equation&gt;c_i&lt;/equation&gt;的质量做出评价。标注语句都是用&lt;b&gt;n元组（n-gram）&lt;/b&gt;来表示的，一个n元组&lt;equation&gt;w_k\in \Omega&lt;/equation&gt;是一个由一个或者多个有顺序单词组成的序列。现在一般只探索n元组从1个单词到4个单词的情况。n元组&lt;equation&gt;w_k&lt;/equation&gt;在语句&lt;equation&gt;s_{ij}&lt;/equation&gt;中出现的次数被记为&lt;equation&gt;h_k(s_{ij})&lt;/equation&gt;，n元组&lt;equation&gt;w_k&lt;/equation&gt;在待评价语句&lt;equation&gt;c_i\in C&lt;/equation&gt;中出现的次数被记为&lt;equation&gt;h_k(c_i)&lt;/equation&gt;。&lt;/p&gt;&lt;p&gt;&lt;b&gt;明确上述符号含义后，BLEU的计算公式如下：&lt;/b&gt;&lt;/p&gt;&lt;p&gt;首先计算的是全局的&lt;b&gt;n元组&lt;/b&gt;精度：其中&lt;equation&gt;k&lt;/equation&gt;指的是长度为n的可能的n元组的集合数。&lt;/p&gt;&lt;equation&gt;CP_n(C,S)=\frac{\sum_i \sum_kmin(h_k(c_i),max_{j\in m}h_k(s_{ij}))}{\sum_i \sum_kh_k(c_i)}&lt;/equation&gt;&lt;p&gt;然后计算的是简洁性惩罚值：其中&lt;equation&gt;l_C&lt;/equation&gt;是待评价语句&lt;equation&gt;c_i&lt;/equation&gt;们的总长，&lt;equation&gt;l_S&lt;/equation&gt;是全局级别的有效参考句子的总长度。如果对于一个待评价语句有多个参考语句，那么就选择让简洁性惩罚最小的那个。&lt;/p&gt;&lt;equation&gt;b(C,S)=\left\{
\begin{array}{rcl}
1           &amp;amp;      &amp;amp; {if \qquad l_C      &amp;gt;      l_S}\\
e^{1-l_S/l_C}       &amp;amp;      &amp;amp; {if \qquad l_C \leq l_S}
\end{array} \right. &lt;/equation&gt;&lt;p&gt;最终计算BLEU分数：其中&lt;equation&gt;N=1,2,3,4&lt;/equation&gt;，对于所有的&lt;equation&gt;n&lt;/equation&gt;，&lt;equation&gt;w_n&lt;/equation&gt;都是常量。&lt;/p&gt;&lt;equation&gt;BLEU_N(C,S)=b(C,S)exp\left(\sum^N_{n=1}w_nlogCP_n(C,S) \right)&lt;/equation&gt;&lt;p&gt;怎么算？同学你看懂了吗？反正我刚开始是没看懂:(，直到我看了&lt;a href="https://en.wikipedia.org/wiki/BLEU" data-editable="true" data-title="维基百科上的例子" class=""&gt;维基百科上的例子&lt;/a&gt;如下：&lt;/p&gt;&lt;p&gt;&lt;b&gt;举例子&lt;/b&gt;：假设我们现在有1个模型生成的待评价句子和2个参考句子如下：&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/1bf11b221e188a5f1bbedb83422960d6.png" data-rawwidth="762" data-rawheight="178"&gt;如果我们先来计算1元组the的精度的话，根据精度的公式：&lt;equation&gt;P=\frac{m}{w_t}=\frac{7}{7}=1&lt;/equation&gt;其中，&lt;equation&gt;m&lt;/equation&gt;怎么理解呢？就是如果一个单词是待评价句子中的，同时在在参考句子中也能找到的这个单词，那么这个单词在待评价语句中出现的次数就是&lt;equation&gt;m&lt;/equation&gt;，在现在例子中the在待评价语句中出现了，也在参考语句中出现了，所以符合条件，而在待评价语句中，the出现了7次，所以这里m=7。而&lt;equation&gt;w_t&lt;/equation&gt;是待评价句子总的单词数量，很显然&lt;equation&gt;w_t&lt;/equation&gt;的值也是7。现在就看到这个例子的奇葩之处了，看起来精度很完美，但是实际上翻译效果很差。&lt;b&gt;BLEU就是要解决这种问题&lt;/b&gt;：所以对于待评价句子中的任意一个单词，算法计算其在参考句子中出现的最大次数&lt;equation&gt;max_{j\in m}h_k(s_{ij})&lt;/equation&gt;，比如，the在参考1中出现了2次，在参考2中出现了1次，那么&lt;equation&gt;max_{j\in m}h_k(s_{ij})=2&lt;/equation&gt;。对于待评价句子，其中每个单词的出现次数&lt;equation&gt;h_k(c_i)&lt;/equation&gt;将被记为该单词的最大出现次数，比如对于the，值为7。而又因为&lt;equation&gt;min(h_k(c_i),max_{j\in m}h_k(s_{ij}))&lt;/equation&gt;，要在这两个值之间取最小值，所以值就是2了。于是，1元组the的精度分数&lt;equation&gt;CP_n(C,S)&lt;/equation&gt;就是&lt;b&gt;2/7&lt;/b&gt;了。然而在实际中，使用单个单词来比较并不是最理想的，所以BLEU使用n元组来计算，n值最高为4。1元组分数对于评价翻译并不足够。更长的元组得分对应的是语言的流畅性。接下来计算简洁性惩罚，&lt;b&gt;为啥还要引入一个简洁性惩罚呢&lt;/b&gt;？这是因为BLEU倾向于更短的句子，这样精度分数就会很高。为了解决这个问题，使用了乘以一个简洁性惩罚来防止很短的句子获得很高的分数。令&lt;equation&gt;l_S&lt;/equation&gt;为参考句子的总长度，&lt;equation&gt;l_C&lt;/equation&gt;是待评价句子的总长度，如果&lt;equation&gt;l_C&lt;/equation&gt;小于等于&lt;equation&gt;l_S&lt;/equation&gt;，那么惩罚生效，计算&lt;equation&gt;e^{1-l_S/l_C}&lt;/equation&gt;。反之，简洁性惩罚值为1。&lt;b&gt;如果有多个参考句子，那么就选取长度和待评价句子长度最接近的那个参考句子的长度&lt;/b&gt;。最后一步的计算相对比较清晰，就不过多解释了。&lt;p&gt;&lt;b&gt;一句话&lt;/b&gt;：&lt;b&gt;BLEU得分越高越好。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;ROUGE&lt;/h2&gt;&lt;p&gt;ROUGE是一个设计&lt;b&gt;用来评价文本摘要算法&lt;/b&gt;的自动评价标准集，其中有3个评价标准，分别是&lt;b&gt;ROUGE-N，ROUGE-L和ROUGE-S&lt;/b&gt;。下面逐个进行介绍：&lt;/p&gt;&lt;p&gt;&lt;equation&gt;ROUGE_N&lt;/equation&gt;是第一个ROUGE标准。根据给出的待评价句子，它对所有的参考摘要计算一个简单的n元组召回：&lt;/p&gt;&lt;equation&gt;ROUGE_n(c_i,S_i)=\frac{\sum_j \sum_kmin(h_k(c_i),h_k(s_{ij}))}{\sum_i \sum_kh_k(s_{ij})}&lt;/equation&gt;&lt;p&gt;回顾一下：n元组&lt;equation&gt;w_k&lt;/equation&gt;在语句&lt;equation&gt;s_{ij}&lt;/equation&gt;中出现的次数被记为&lt;equation&gt;h_k(s_{ij})&lt;/equation&gt;，n元组&lt;equation&gt;w_k&lt;/equation&gt;在待评价语句&lt;equation&gt;c_i\in C&lt;/equation&gt;中出现的次数被记为&lt;equation&gt;h_k(c_i)&lt;/equation&gt;。所以上面&lt;equation&gt;ROUGE_N&lt;/equation&gt;的计算还是挺容易理解的。&lt;/p&gt;&lt;p&gt;&lt;equation&gt;ROUGE_L&lt;/equation&gt;是基于longest common subsequence（LCS）的一种测量方法。所谓LCS，就是一个同时出现在两个句子中的单词集合，且单词出现的顺序也是相同的。和n元组不同的是，在单词之间可能还存在能够创建出LCS的单词。将比较的两个句子间的LCS的长度记为：&lt;equation&gt;l(c_i,s_{ij})&lt;/equation&gt;。ROUGE-L通过计算F-meansure（&lt;a href="https://en.wikipedia.org/wiki/F1_score" data-editable="true" data-title="F1 score"&gt;F1 score&lt;/a&gt;）来求得：&lt;/p&gt;&lt;equation&gt;R_l=max_j\frac{l(c_i,s_{ij})}{|s_{ij}|}&lt;/equation&gt;&lt;equation&gt;P_l=max_j\frac{l(c_i,s_{ij})}{|c_i|}&lt;/equation&gt;&lt;equation&gt;ROUGE_L(c_i,S_i)=\frac{(1+\beta^2)R_lP_l}{R_l+\beta^2P_l}&lt;/equation&gt;&lt;p&gt;&lt;equation&gt;R_l&lt;/equation&gt;是召回，&lt;equation&gt;P_l&lt;/equation&gt;是精度，&lt;equation&gt;\beta&lt;/equation&gt;一般等于1.2，在这个计算中不需要管n元组。&lt;/p&gt;&lt;p&gt;&lt;equation&gt;ROUGE_S&lt;/equation&gt;是最后一个标准，没有使用LCS或n元组，使用的是&lt;b&gt;跳跃二元组（skip bigram）&lt;/b&gt;。跳跃二元组是句子中有序的单词对，和LCS类似，在单词对之间，单词可能被跳过。比如一句有4个单词的句子，按照排列组合就可能有6种跳跃二元组。再次使用精度和召回率来计算F，将句子&lt;equation&gt;s_{ij}&lt;/equation&gt;中跳跃二元组的个数记为&lt;equation&gt;f_k(s_{ij})&lt;/equation&gt;，则计算公式如下：&lt;/p&gt;&lt;equation&gt;R_s=max_j\frac{\sum_kmin(f_k(c_i),f_k(s_{ij}))}{\sum_kf_k(s_{ij})}&lt;/equation&gt;&lt;equation&gt;P_s=max_j\frac{\sum_kmin(f_k(c_i),f_k(s_{ij}))}{\sum_kf_k(c_i)}&lt;/equation&gt;&lt;p&gt;&lt;equation&gt;GOUGE_S(c_i,S_i)=\frac{(1+\beta^2)R_sP_s}{R_s+\beta^2P_s}&lt;/equation&gt;跳跃二元组能够捕获到长距离的句子结构。在实践中，跳跃二元组计算的时候单词间最长距离为4。ROUGE-SU是在跳跃二元组基础上增加使用了1元组。&lt;/p&gt;&lt;p&gt;&lt;b&gt;一句话：ROUGE得分越高越好&lt;/b&gt;。&lt;/p&gt;&lt;h2&gt;METEOR&lt;/h2&gt;&lt;p&gt;&lt;b&gt;METEOR是用来评价机器翻译输出的标准&lt;/b&gt;。该方法基于一元组的精度和召回的调和平均（&lt;a href="https://en.wikipedia.org/wiki/Harmonic_mean" data-editable="true" data-title="Harmonic mean"&gt;Harmonic mean&lt;/a&gt;），召回的权重比精度要高一点。这个标准还有一些其他标准没有的特性，设计它是为了解决BLEU存在的一些问题。它与人类判断相关性高，而且和BLEU不同，它不仅在整个集合，而且在句子和分段级别，也能和人类判断的相关性高。在全集级别，它的相关性是0.964，BLEU是0.817。在句子级别，它的相关性最高到了0.403。&lt;/p&gt;&lt;p&gt;&lt;b&gt;METEOR的计算公式&lt;/b&gt;：其中m是&lt;b&gt;平面图（alignments）&lt;/b&gt;的集合，ch是&lt;b&gt;块（chunk）&lt;/b&gt;的数量，&lt;equation&gt;P_m&lt;/equation&gt;是精度，&lt;equation&gt;R_m&lt;/equation&gt;是召回率。&lt;/p&gt;&lt;p&gt;&lt;equation&gt;Pen=\gamma\left(\frac{ch}{m}  \right)^{\theta}&lt;/equation&gt;&lt;equation&gt;F_{mean}=\frac{P_mR_m}{\alpha P_m+(1-\alpha)R_m}&lt;/equation&gt;&lt;equation&gt;P_m=\frac{|m|}{\sum_k h_k(c_i)}&lt;/equation&gt;&lt;equation&gt;R_m=\frac{|m|}{\sum_k h_k(s_{ij})}&lt;/equation&gt;&lt;equation&gt;METEOR=(1-Pen)F_{mean}&lt;/equation&gt;&lt;b&gt;理解&lt;/b&gt;：看公式总是挺抽象的，下面我们还是看看来自维基百科的例子吧。计算的最基本单元是句子。算法首先从待评价字符串和参考字符串之间创建一个平面图如下：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/96242ff6cfe2cbb92b23f755a78c28f7.png" data-rawwidth="1096" data-rawheight="174"&gt;所谓平面图，就是1元组之间的映射集。平面图有如下的一些限制：在待评价翻译中的每个1元组必须映射到参考翻译中的1个或0个一元组，然后根据这个定义创建平面图。&lt;b&gt;如果有两个平面图的映射数量相同，那么选择映射交叉数目较少的那个&lt;/b&gt;。也就是说，上面左侧平面图会被选择。状态会持续运行，在每个状态下只会向平面图加入那些在前一个状态中尚未匹配的1元组。一旦最终的平面图计算完毕，就开始计算METEOR得分：&lt;/p&gt;&lt;p&gt;1元组精度：&lt;equation&gt;P=\frac{m}{w_t}&lt;/equation&gt;&lt;/p&gt;&lt;p&gt;其中m是在参考句子中同样存在的，待评价句子中的一元组的数量。&lt;equation&gt;w_t&lt;/equation&gt;是待评价翻译中一元组的数量。&lt;/p&gt;&lt;p&gt;1元组召回率：&lt;equation&gt;R=\frac{m}{w_r}&lt;/equation&gt;&lt;/p&gt;&lt;p&gt;m同上，&lt;equation&gt;w_r&lt;/equation&gt;是参考翻译中一元组的数量。然后使用调和平均来计算F-mean，且召回的权重是精度的9倍。&lt;equation&gt;F_{mean}=\frac{10PR}{R+9P}&lt;/equation&gt;到目前为止，这个方法只对单个单词的一致性进行了衡量，却没有对参考翻译和待评价翻译中更大的分段进行衡量。为了将其计算在内，使用更长的n元组来计算对于平面图的惩罚p。在参考和待评价句子中的没有毗连的映射越多，惩罚就越高。为了计算惩罚，1元组被分组成最少可能的&lt;b&gt;块（chunks）&lt;/b&gt;。块的定义是在待评价语句和参考语句中毗邻的一元组集合。在待评价语句和参考语句之间的毗邻映射越长，块的数量就越少。一个待评价翻译如果和参考翻译相同，那么就只有一个块。惩罚p的计算如下：&lt;/p&gt;&lt;p&gt;&lt;equation&gt;p=0.5\left(\frac{c}{u_m} \right)^3&lt;/equation&gt;其中c就是块的数量，&lt;equation&gt;u_m&lt;/equation&gt;是被映射的一元组的数量。p可以减少F-mean的值。最后&lt;equation&gt;M=(1-p)F_{mean}&lt;/equation&gt;。&lt;b&gt;计算例子&lt;/b&gt;：这里偷个懒，直接截图维基百科，可以结合这个例子对照看自己的计算是否正确。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/0c33f88db9521eab9c82afe1cf794ea3.png" data-rawwidth="1736" data-rawheight="1162"&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;一句话：METEOR得分越高越好&lt;/b&gt;。&lt;/p&gt;&lt;h2&gt;CIDEr&lt;/h2&gt;CIDEr是专门设计出来用于图像标注问题的，它是通过对每个n元组进行&lt;b&gt;Term Frequency Inverse Document Frequency (TF-IDF) &lt;/b&gt;权重计算，来衡量图像标注的一致性的。一个n元组wk在出现在参考句子sij中的次数被记为&lt;equation&gt;h_k(s_{ij})&lt;/equation&gt; ，如果出现在待评价句子中，则被记为&lt;equation&gt;h_k(c_i)&lt;/equation&gt;。CIDEr为每个n元组wk都计算TF-IDF权重&lt;equation&gt;g_k(s_{ij})&lt;/equation&gt;：&lt;equation&gt;g_k(s_{ij})=\frac{h_k(s_{ij})}{\sum_{w_l\in \Omega}}log \left(\frac{|I|}{\sum_{I_p \in I}min(1,\sum_qh_k(s_{pq}))} \right)&lt;/equation&gt;其中&lt;equation&gt;\Omega&lt;/equation&gt;是所有n元组的词汇表，I是数据集中所有图像的集合。公式第一个部分计算的是每个n元组wk的TF，公式第二部分是使用IDF来计算&lt;equation&gt;w_k&lt;/equation&gt;的稀有程度。从直观上来说，如果一些n元组频繁地出现在描述图像的参考标注中，TF对于这些n元组将给出更高的权重，而IDF则降低那些在所有描述语句中都常常出现的n元组的权重。也就是说，IDF提供了一种测量单词显著性的方法，这就是将那些容易常常出现，但是对于视觉内容信息没有多大帮助的单词的重要性打折。IDF的计算方法是：分子为数据集中图像的数量I，分母为一些图像的数量，这些图像是其任意一个描述中出现了n元组&lt;equation&gt;w_k&lt;/equation&gt;的图像，然后再对着个分数求对数。对于长度为n的n元组的CIDEr-n分数是使用待评价句子和参考句子之间的平均相似性来计算的，其中精度和召回率都要占比例：&lt;equation&gt;CIDEr_n(c_i,S_i)=\frac{1}{m}\sum_j\frac{g^n(c_i)\cdot g^n(s_{ij})}{||g^n(c_i)|||| g^n(s_{ij})||}&lt;/equation&gt;其中，&lt;equation&gt;g^n(c_i)&lt;/equation&gt;是一个由&lt;equation&gt;g_k(c_i)&lt;/equation&gt;生成的向量，对应的是所有长度为n的n元组。&lt;equation&gt;||g^n(c_i)||&lt;/equation&gt;是向量的大小。而&lt;equation&gt;g^n(s_{ij})&lt;/equation&gt;的情况类似。更长的n元组是用来获取语法性质和更丰富的语义信息的。不同长度的n元组的得分计算如下：&lt;equation&gt;CIDEr(c_i,S_i)=\sum^N_{n=1}w_nCIDEr_n(c_i,S_i)&lt;/equation&gt;&lt;p&gt;标准权重&lt;equation&gt;w_n=1/N&lt;/equation&gt;，N=4比较常用。&lt;/p&gt;&lt;p&gt;&lt;b&gt;CIDEr-D&lt;/b&gt;是修改版本，为的是让CIDEr对于gaming问题更加鲁棒。什么是Gaming问题？它是一种现象，就是一个句子经过人工判断得分很低，但是在自动计算标准中却得分很高的情况。为了避免这种情况，CIDEr-D增加了&lt;b&gt;截断（clipping）和基于长度的高斯惩罚&lt;/b&gt;：&lt;/p&gt;&lt;equation&gt;CIDEr\text{-}D_n(c_i,S_i)=\frac{10}{m}\sum_j e^{\frac{-(l(c_i)-l(s_{ij}))^2}{2\sigma^2}} \frac{min(g^n(c_i),g^n(s_{ij}))\cdot g^n(s_{ij})}{||g^n(c_i)|||| g^n(s_{ij})||}&lt;/equation&gt;其中，&lt;equation&gt;l(c_i)&lt;/equation&gt;和&lt;equation&gt;l(s_{ij})&lt;/equation&gt;分别表示的是待评价句子和参考句子的长度，&lt;equation&gt;\sigma&lt;/equation&gt;=6，分子为10是为了让得分和其他标准比较相似。最终：&lt;equation&gt;CIDEr\text{-}D(c_i,S_i)=\sum^N_{n=1}w_nCIDEr\text{-}D_n(c_i,S_i)&lt;/equation&gt;&lt;b&gt;一句话：CIDEr得分越高越好&lt;/b&gt;。&lt;h2&gt;下篇预告&lt;/h2&gt;&lt;p&gt;由于文章篇幅较长，顾分为上下篇发布。在上篇中，&lt;b&gt;介绍了图像标准问题，以及研究问题的数据集，人工和自动评价标准，并脑洞了开源创建守望先锋图像标注数据集的想法&lt;/b&gt;。&lt;/p&gt;&lt;p&gt;在下篇中，将&lt;b&gt;介绍比较几个有代表性的图像标注方法，一些代码实践，和对于图像标准问题的思考&lt;/b&gt;。&lt;/p&gt;&lt;h2&gt;作者反馈&lt;/h2&gt;&lt;ol&gt;&lt;li&gt;欢迎大家对文中的不当之处留言批评指正，共同学习提高；&lt;/li&gt;&lt;li&gt;由于希望写得有趣和通俗些，所以解释和比喻较多，行文稍显冗余，不知阅读效果如何？请批评；&lt;/li&gt;&lt;li&gt;真心想做一个基于守望先锋游戏画面的图像标注数据集，为什么特别指明用Ruby呢？因为朋友天天安利我说Ruby on rails做网站好，我对网站这一块不太懂，就信任小伙伴咯，不希望因为这个问题引战:)&lt;/li&gt;&lt;/ol&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/22408033&amp;pixel&amp;useReferer"/&gt;</description><author>杜客</author><pubDate>Tue, 20 Sep 2016 12:04:02 GMT</pubDate></item><item><title>[原创翻译]循环神经网络惊人的有效性（下）</title><link>https://zhuanlan.zhihu.com/p/22230074</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/2029a1ea020883b4d065592d14acc96e_r.jpg"&gt;&lt;/p&gt;版权声明：本文&lt;a href="https://zhuanlan.zhihu.com/intelligentunit" class="" data-editable="true" data-title="智能单元"&gt;智能单元&lt;/a&gt;首发，本人原创翻译，禁止未授权转载。 &lt;blockquote&gt;译者注：在CS231n课程笔记止步于CNN，没有循环神经网络（RNN和LSTM），实为憾事。经知友推荐，将&lt;a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/" data-title="The Unreasonable Effectiveness of Recurrent Neural Networks" class="" data-editable="true"&gt;The Unreasonable Effectiveness of Recurrent Neural Networks&lt;/a&gt;一文翻译完毕，作为补充。感谢@&lt;a href="https://www.zhihu.com/people/hmonkey" class="" data-editable="true" data-title="猴子"&gt;猴子&lt;/a&gt;，&lt;a href="https://www.zhihu.com/people/e7fcc05b0cf8a90a3e676d0206f888c9" data-hash="e7fcc05b0cf8a90a3e676d0206f888c9" class="member_mention" data-hovercard="p$b$e7fcc05b0cf8a90a3e676d0206f888c9"&gt;@堃堃&lt;/a&gt;和&lt;a href="https://www.zhihu.com/people/f11e78650e8185db2b013af42fd9a481" data-hash="f11e78650e8185db2b013af42fd9a481" class="member_mention" data-hovercard="p$b$f11e78650e8185db2b013af42fd9a481"&gt;@李艺颖&lt;/a&gt;的校对。&lt;/blockquote&gt;&lt;h2&gt;目录&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;循环神经网络&lt;/li&gt;&lt;li&gt;字母级别的语言模型&lt;/li&gt;&lt;li&gt;RNN的乐趣&lt;/li&gt;&lt;ul&gt;&lt;li&gt;Paul Graham生成器&lt;/li&gt;&lt;li&gt;莎士比亚&lt;/li&gt;&lt;li&gt;维基百科&lt;/li&gt;&lt;li&gt;几何代数&lt;/li&gt;&lt;li&gt;Linux源码&lt;/li&gt;&lt;li&gt;生成婴儿姓名&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;理解训练过程 &lt;i&gt;&lt;b&gt;译者注：下篇起始处&lt;/b&gt;&lt;/i&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;训练时输出文本的进化&lt;/li&gt;&lt;li&gt;RNN中的预测与神经元激活可视化&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;源代码&lt;/li&gt;&lt;li&gt;拓展阅读&lt;/li&gt;&lt;li&gt;结论&lt;/li&gt;&lt;li&gt;译者反馈&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;理解训练过程&lt;/h2&gt;&lt;p&gt;我们已经看见训练结束后的结果令人印象深刻，但是它到底是如何运作的呢？现在跑两个小实验来一探究竟。&lt;/p&gt;&lt;h3&gt;训练时输出文本的进化&lt;/h3&gt;&lt;p&gt;首先，观察模型在训练时输出文本的不断进化是很有意思的。例如，我使用托尔斯泰的《战争与和平》来训练LSTM，并在训练过程中每迭代100次就输出一段文本。在第100次迭代时，模型输出的文本是随机排列的：&lt;/p&gt;&lt;pre&gt;&lt;code lang="text"&gt;tyntd-iafhatawiaoihrdemot  lytdws  e ,tfti, astai f ogoh eoase rrranbyne 'nhthnee e 
plia tklrgd t o idoe ns,smtt   h ne etie h,hregtrs nigtike,aoaenns lng
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;但是至少可以看到它学会了单词是被空格所分割的，只是有时候它使用了两个连续空格。它还没学到逗号后面总是有个空格。在迭代到第300次的时候，可以看到模型学会使用引号和句号。&lt;/p&gt;&lt;pre&gt;&lt;code lang="text"&gt;"Tmont thithey" fomesscerliund
Keushey. Thom here
sheulke, anmerenith ol sivh I lalterthend Bleipile shuwy fil on aseterlome
coaniogennc Phe lism thond hon at. MeiDimorotion in ther thize."
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;单词被空格所分割，模型开始知道在句子末尾使用句号。在第500次迭代时：&lt;/p&gt;&lt;pre&gt;&lt;code lang="text"&gt;we counter. He stutn co des. His stanted out one ofler that concossions and was 
to gearang reay Jotrets and with fre colt otf paitt thin wall. Which das stimn 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;模型开始学会使用最短和最常用的单词，比如“we”、“He”、“His”、“Which”、“and”等。从第700次迭代开始，可以看见更多和英语单词形似的文本：&lt;/p&gt;&lt;pre&gt;&lt;code lang="text"&gt;Aftair fall unsuch that the hall for Prince Velzonski's that me of
her hearly, and behs to so arwage fiving were to it beloge, pavu say falling misfort 
how, and Gogition is so overelical and ofter.
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;在第1200次迭代，我们可以看见使用引号、问好和感叹号，更长的单词也出现了。&lt;/p&gt;&lt;pre&gt;&lt;code lang="text"&gt;"Kite vouch!" he repeated by her
door. "But I would be done and quarts, feeling, then, son is people...."
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;在迭代到2000次的时候，模型开始正确的拼写单词，引用句子和人名。&lt;/p&gt;&lt;pre&gt;&lt;code lang="text"&gt;"Why do what that day," replied Natasha, and wishing to himself the fact the
princess, Princess Mary was easier, fed in had oftened him.
Pierre aking his soul came to the packs and drove up his father-in-law women.
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;从上述结果中可见，模型首先发现的是一般的单词加空格结构，然后开始学习单词；从短单词开始，然后学习更长的单词。由多个单词组成的话题和主题词要到训练后期才会出现。&lt;/p&gt;&lt;h2&gt;RNN中的预测与神经元激活可视化&lt;/h2&gt;&lt;p&gt;另一个有趣的实验内容就是将模型对于字符的预测可视化。下面的图示是我们对用维基百科内容训练的RNN模型输入验证集数据（蓝色和绿色的行）。在每个字母下面我们列举了模型预测的概率最高的5个字母，并用深浅不同的红色着色。深红代表模型认为概率很高，白色代表模型认为概率较低。注意有时候模型对于预测的字母是非常有信心的。比如在&lt;a href="http://www/" data-editable="true" data-title="www 的页面"&gt;http://www&lt;/a&gt;. 序列中就是。&lt;/p&gt;&lt;p&gt;输入字母序列也被着以蓝色或者绿色，这代表的是RNN隐层表达中的某个随机挑选的神经元是否被&lt;em&gt;激活&lt;/em&gt;。绿色代表非常兴奋，蓝色代表不怎么兴奋。LSTM中细节也与此类似，隐藏状态向量中的值是[-1, 1]，这就是经过各种操作并使用tanh计算后的LSTM细胞状态。直观地说，这就是当RNN阅读输入序列时，它的“大脑”中的某些神经元的激活率。不同的神经元关注的是不同的模式。在下面我们会看到4种不同的神经元，我认为比较有趣和能够直观理解（当然也有很多不能直观理解）。&lt;/p&gt;&lt;p&gt;————————————————————————————————————————&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/2ae42139518681b8cbbe4f854fdef515.jpg" data-rawwidth="1639" data-rawheight="825"&gt;本图中高亮的神经元看起来对于URL的开始与结束非常敏感。LSTM看起来是用这个神经元来记忆自己是不是在一个URL中。&lt;/p&gt;&lt;p&gt;——————————————————————————————————————————&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/63ac60c5e0fc60017e45360516c95682.jpg" data-rawwidth="1688" data-rawheight="827"&gt;高亮的神经元看起来对于markdown符号[[]]的开始与结束非常敏感。有趣的是，一个[符号不足以激活神经元，必须等到两个[[同时出现。而判断有几个[的任务看起来是由另一个神经元完成的。&lt;/p&gt;&lt;p&gt;——————————————————————————————————————————&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/c41f6b3d378e74b45698950a95b32d29.jpg" data-rawwidth="1685" data-rawheight="398"&gt;这是一个在[[]]中线性变化的神经元。换句话说，在[[]]中，它的激活是为RNN提供了一个以时间为准的坐标系。RNN可以使用该信息来根据字符在[[]]中出现的早晚来决定其出现的频率（也许？）。&lt;/p&gt;&lt;p&gt;——————————————————————————————————————————&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/27c8e4245a2e3726f6faa3af58c15603.jpg" data-rawwidth="1668" data-rawheight="185"&gt;这是一个进行局部动作的神经元：它大部分时候都很安静，直到出现www序列中的第一个w后，就突然关闭了。RNN可能是使用这个神经元来计算www序列有多长，这样它就知道是该输出有一个w呢，还是开始输出URL了。&lt;/p&gt;&lt;p&gt;——————————————————————————————————————————&lt;/p&gt;&lt;p&gt;当然，由于RNN的隐藏状态是一个巨大且分散的高维度表达，所以上面这些结论多少有一点手动调整。上面的这些可视化图片是用定制的HTML/CSS/Javascript实现的，如果你想实现类似的，可以查看&lt;a href="http://cs.stanford.edu/people/karpathy/viscode.zip" data-editable="true" data-title="这里"&gt;这里&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;我们可以进一步简化可视化效果：不显示预测字符仅仅显示文本，文本的着色代表神经元的激活情况。可以看到大部分的细胞做的事情不是那么直观能理解，但是其中5%看起来是学到了一些有趣并且能理解的算法：&lt;/p&gt;&lt;p&gt;—————————————————————————————————————————&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/d86db8d5322c96a366e59572e01a5685.png" data-rawwidth="990" data-rawheight="865"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/25eea1bd327845168fab51e66c78d77d.png" data-rawwidth="766" data-rawheight="865"&gt;—————————————————————————————————————————&lt;/p&gt;&lt;p&gt;在预测下个字符的过程中优雅的一点是：我们不用进行任何的硬编码。比如，不用去实现判断我们到底是不是在一个引号之中。我们只是使用原始数据训练LSTM，然后它自己决定这是个有用的东西于是开始跟踪。换句话说，其中一个单元自己在训练中变成了引号探测单元，只因为这样有助于完成最终任务。这也是深度学习模型（更一般化地说是端到端训练）强大能力的一个简洁有力的证据。&lt;/p&gt;&lt;h2&gt;源代码&lt;/h2&gt;&lt;p&gt;我想这篇博文能够让你认为训练一个字符级别的语言模型是一件有趣的事儿。你可以使用我在Github上的&lt;a href="https://github.com/karpathy/char-rnn" data-editable="true" data-title="char rnn代码"&gt;char rnn代码&lt;/a&gt;训练一个自己的模型。它使用一个大文本文件训练一个字符级别的模型，可以输出文本。如果你有GPU，那么会在比CPU上训练快10倍。如果你训练结束得到了有意思的结果，请联系我。如果你看Torch/Lua代码看的头疼，别忘了它们只不过是这个&lt;a href="https://gist.github.com/karpathy/d4dee566867f8291f086" data-editable="true" data-title="100行项目"&gt;100行项目&lt;/a&gt;的高端版。&lt;/p&gt;&lt;p&gt;&lt;em&gt;题外话&lt;/em&gt;。代码是用&lt;a href="http://torch.ch/" data-editable="true" data-title="Torch7"&gt;Torch7&lt;/a&gt;写的，它最近变成我最爱的深度学习框架了。我开始学习Torch/LUA有几个月了，这并不简单（花了很多时间学习Github上的原始Torch代码，向项目创建者提问来解决问题），但是一旦你搞懂了，它就会给你带来很大的弹性和加速。之前我使用的是Caffe和Theano，虽然Torch虽然还不完美，但是我相信它的抽象和哲学层次比前两个高。在我看来，一个高效的框架应有以下特性：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;有丰富函数（例如切片，数组/矩阵操作等）的，对底层CPU/GPU透明的张量库。&lt;/li&gt;&lt;li&gt;一整个基于脚本语言（比如Python）的分离的代码库，能够对张量进行操作，实现所有深度学习内容（前向、反向传播，计算图等）。&lt;/li&gt;&lt;li&gt;分享预训练模型非常容易（Caffe做得很好，其他的不行）。&lt;/li&gt;&lt;li&gt;最关键的：没有编译过程！或者至少不要像Theano现在这样！深度学习的趋势是更大更复杂的网络，这些网络都有随着时间展开的复杂计算流程。编译时间不能太长，不然开发过程将充满痛苦。其次，编译导致开发者放弃解释能力，不能高效地进行调试。如果在流程开发完成后有个&lt;em&gt;选项&lt;/em&gt;能进行编译，那也可以。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;拓展阅读&lt;/h2&gt;&lt;p&gt;在结束本篇博文前，我想把RNN放到更广的背景中，提供一些当前的研究方向。RNN现在在深度学习领域引起了不小的兴奋。和卷积神经网络一样，它出现已经有十多年了，但是直到最近它的潜力才被逐渐发掘出来，这是因为我们的计算能力日益强大。下面是当前的一些进展（肯定不完整，而且很多工作可以追溯的1990年）：&lt;/p&gt;&lt;p&gt;在NLP/语音领域，RNN将&lt;a href="http://www.jmlr.org/proceedings/papers/v32/graves14.pdf" data-editable="true" data-title="语音转化为文字"&gt;语音转化为文字&lt;/a&gt;，进行&lt;a href="http://arxiv.org/abs/1409.3215" data-editable="true" data-title="机器翻译"&gt;机器翻译&lt;/a&gt;，生成&lt;a href="http://www.cs.toronto.edu/~graves/handwriting.html" data-editable="true" data-title="手写文本"&gt;手写文本&lt;/a&gt;，当然也是强大的语言模型 (Sutskever等) (Graves) (Mikolov等)。字符级别和单词级别的模型都有，目前看来是单词级别的模型更领先，但是这只是暂时的。&lt;/p&gt;&lt;p&gt;计算机视觉。RNN迅速地在计算机视觉领域中被广泛运用。比如，使用RNN用于&lt;a href="http://arxiv.org/abs/1411.4389" data-editable="true" data-title="视频分类"&gt;视频分类&lt;/a&gt;，&lt;a href="http://arxiv.org/abs/1411.4555" data-editable="true" data-title="图像标注"&gt;图像标注&lt;/a&gt;（其中有我自己的工作和其他一些），&lt;a href="http://arxiv.org/abs/1505.00487" data-editable="true" data-title="视频标注"&gt;视频标注&lt;/a&gt;和最近的&lt;a href="http://arxiv.org/abs/1505.02074" data-editable="true" data-title="视觉问答"&gt;视觉问答&lt;/a&gt;。在计算机视觉领域，我个人最喜欢的RNN论文是《&lt;a href="http://arxiv.org/abs/1406.6247" data-editable="true" data-title="Recurrent Models of Visual Attention"&gt;Recurrent Models of Visual Attention&lt;/a&gt;》，之所以推荐它，是因为它高层上的指导方向和底层的建模方法（对图像短时间观察后的序列化处理），和建模难度低（REINFORCE算法规则是增强学习里面策略梯度方法中的一个特例，使得能够用非微分的计算来训练模型（在该文中是对图像四周进行快速查看））。我相信这种用CNN做原始数据感知，RNN在顶层做快速观察策略的混合模型将会在感知领域变得越来越流行，尤其是在那些不单单是对物体简单分类的复杂任务中将更加广泛运用。&lt;/p&gt;&lt;p&gt;归纳推理，记忆和注意力（Inductive Reasoning, Memories and Attention）。另一个令人激动的研究方向是要解决普通循环网络自身的局限。RNN的一个问题是它不具有归纳性：它能够很好地记忆序列，但是从其表现上来看，它不能很好地在正确的方向上对其进行归纳（一会儿会举例让这个更加具体一些）。另一个问题是RNN在运算的每一步都将表达数据的尺寸和计算量联系起来，而这并非必要。比如，假设将隐藏状态向量尺寸扩大为2倍，那么由于矩阵乘法操作，在每一步的浮点运算量就要变成4倍。理想状态下，我们希望保持大量的表达和记忆（比如存储全部维基百科或者很多中间变量），但同时每一步的运算量不变。&lt;/p&gt;&lt;p&gt;在该方向上第一个具有说服力的例子来自于DeepMind的&lt;a href="http://arxiv.org/abs/1410.5401" data-editable="true" data-title="神经图灵机（Neural Turing Machines）"&gt;神经图灵机（Neural Turing Machines）&lt;/a&gt;论文。该论文展示了一条路径：模型可以在巨大的外部存储数组和较小的存储寄存器集（将其看做工作的存储器）之间进行读写操作，而运算是在存储寄存器集中进行。更关键的一点是，神经图灵机论文提出了一个非常有意思的存储解决机制，该机制是通过一个（soft和全部可微分的）注意力模型来实现的。&lt;em&gt;译者注：这里的soft取自softmax&lt;/em&gt;。基于概率的“软”注意力机制（soft attention）是一个强有力的建模特性，已经在面向机器翻译的《&lt;a href="http://arxiv.org/abs/1409.0473" data-editable="true" data-title="Neural Machine Translation by Jointly Learning to Align and Translate"&gt; Neural Machine Translation by Jointly Learning to Align and Translate&lt;/a&gt;》一文和面向问答的《&lt;a href="http://arxiv.org/abs/1503.08895" data-editable="true" data-title="Memory Networks"&gt;Memory Networks&lt;/a&gt;》中得以应用。实际上，我想说的是：&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;注意力概念是近期神经网络领域中最有意思的创新。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;现在我不想更多地介绍细节，但是软注意力机制存储器寻址是非常方便的，因为它让模型是完全可微的。不好的一点就是牺牲了效率，因为每一个可以关注的地方都被关注了（虽然是“软”式的）。想象一个C指针并不指向一个特定的地址，而是对内存中所有的地址定义一个分布，然后间接引用指针，返回一个与指向内容的权重和（这将非常耗费计算资源）。这让很多研究者都从软注意力模式转向硬注意力模式，而硬注意力模式是指对某一个区域内的内容固定关注（比如，对某些单元进行读写操作而不是所有单元进行读写操作）。这个模型从设计哲学上来说肯定更有吸引力，可扩展且高效，但不幸的是模型就不是可微分的了。这就导致了对于增强学习领域技术的引入（比如REINFORCE算法），因为增强学习领域中的研究者们非常熟悉不可微交互的概念。这项工作现在还在进展中，但是硬注意力模型已经被发展出来了，在《&lt;a href="http://arxiv.org/abs/1503.01007" data-editable="true" data-title="Inferring Algorithmic Patterns with Stack-Augmented Recurrent Nets"&gt; Inferring Algorithmic Patterns with Stack-Augmented Recurrent Nets&lt;/a&gt;》，《&lt;a href="http://arxiv.org/abs/1505.00521" data-editable="true" data-title="Reinforcement Learning Neural Turing Machines"&gt; Reinforcement Learning Neural Turing Machines&lt;/a&gt;》，《&lt;a href="http://arxiv.org/abs/1502.03044" data-editable="true" data-title="Show Attend and Tell"&gt;Show Attend and Tell&lt;/a&gt;》三篇文章中均有介绍。&lt;/p&gt;&lt;p&gt;研究者。如果你想在RNN方面继续研究，我推荐&lt;a href="http://www.cs.toronto.edu/~graves/" data-editable="true" data-title="Alex Graves"&gt;Alex Graves&lt;/a&gt;，&lt;a href="http://www.cs.toronto.edu/~ilya/" data-editable="true" data-title="Ilya Sutskever"&gt;Ilya Sutskever&lt;/a&gt;和&lt;a href="http://www.rnnlm.org/" data-editable="true" data-title="Tomas Mikolov"&gt;Tomas Mikolov&lt;/a&gt;三位研究者。想要知道更多增强学习和策略梯度方法（REINFORCE算法是其中一个特例），可以学习&lt;a href="http://www0.cs.ucl.ac.uk/staff/d.silver/web/Home.html" data-editable="true" data-title="David Silver的课程"&gt;David Silver的课程&lt;/a&gt;，或&lt;a href="http://www.cs.berkeley.edu/~pabbeel/" data-editable="true" data-title="Pieter Abbeel的课程"&gt;Pieter Abbeel的课程&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;代码。如果你想要继续训练RNN，我听说Theano上的&lt;a href="https://github.com/fchollet/keras" data-editable="true" data-title="keras"&gt;keras&lt;/a&gt;或&lt;a href="https://github.com/IndicoDataSolutions/Passage" data-editable="true" data-title="passage"&gt;passage&lt;/a&gt;还不错。我使用Torch写了一个&lt;a href="https://github.com/karpathy/char-rnn" data-editable="true" data-title="项目"&gt;项目&lt;/a&gt;，也用numpy实现了一个可以前向和后向传播的LSTM。你还可以在Github上看看我的&lt;a href="https://github.com/karpathy/neuraltalk" data-editable="true" data-title="NeuralTalk" class=""&gt;NeuralTalk&lt;/a&gt;项目，是用RNN/LSTM来进行图像标注。或者看看Jeff Donahue用&lt;a href="http://jeffdonahue.com/lrcn/" data-editable="true" data-title="Caffe"&gt;Caffe&lt;/a&gt;实现的项目。&lt;/p&gt;&lt;h2&gt;结论&lt;/h2&gt;&lt;p&gt;我们已经学习了RNN，知道了它如何工作，以及为什么它如此重要。我们还利用不同的数据集将RNN训练成字母级别的语言模型，观察了它是如何进行这个过程的。可以预见，在未来将会出现对RNN的巨大创新，我个人认为它们将成为智能系统的关键组成部分。&lt;/p&gt;&lt;p&gt;最后，为了给文章增添一点格调，我使用本篇博文对RNN进行了训练。然而由于博文的长度很短，不足以很好地训练RNN。但是返回的一段文本如下（使用低的温度设置来返回更典型的样本）：&lt;/p&gt;&lt;pre&gt;&lt;code lang="python"&gt;I've the RNN with and works, but the computed with program of the 
RNN with and the computed of the RNN with with and the code
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;是的，这篇博文就是讲RNN和它如何工作的，所以显然模型是有用的：）下次见！&lt;/p&gt;&lt;h2&gt;译者反馈&lt;/h2&gt;&lt;ol&gt;&lt;li&gt;翻译不到位的地方，欢迎知友们评论批评指正；&lt;/li&gt;&lt;li&gt;关于Torch和TensorFlow，AK本人现在在OpenAI工作主要是在用TF了，但是他对于Torch还是有很强的倾向性。这在他最新的博文中可以看到；&lt;/li&gt;&lt;li&gt;在计算机视觉方面，个人对于&lt;b&gt;图像标注&lt;/b&gt;比较感兴趣，正在入坑。欢迎有同样兴趣的知友投稿讨论；&lt;/li&gt;&lt;li&gt;想要加入翻译小组的同学，&lt;b&gt;请连续3次在评论中对我们最新的翻译做出认真的批评和指正，而后我们会小组内投票决定是否吸纳新成员：）&lt;/b&gt;这个小小的门槛是为了方便我们找到真正喜爱机器学习和翻译的同学。&lt;/li&gt;&lt;/ol&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/22230074&amp;pixel&amp;useReferer"/&gt;</description><author>杜客</author><pubDate>Tue, 13 Sep 2016 19:09:57 GMT</pubDate></item><item><title>智能单元专栏目录</title><link>https://zhuanlan.zhihu.com/p/22339097</link><description>&lt;a href="https://zhuanlan.zhihu.com/intelligentunit" class="" data-editable="true" data-title="智能单元 - 知乎专栏"&gt;智能单元 - 知乎专栏&lt;/a&gt;长期原创和翻译&lt;b&gt;深度学习和深度增强学习&lt;/b&gt;等领域高质量文章，并接受知友投稿。&lt;h2&gt;最前沿系列&lt;/h2&gt;&lt;blockquote&gt;最前沿系列解读我们认为的深度学习领域有巨大影响的论文和成果。&lt;/blockquote&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/21320865?refer=intelligentunit" class="" data-editable="true" data-title="最前沿：史蒂夫的人工智能大挑战 - 智能单元 - 知乎专栏"&gt;最前沿：史蒂夫的人工智能大挑战&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/21362413?refer=intelligentunit" class="" data-editable="true" data-title="最前沿：让计算机学会学习Let Computers Learn to Learn - 智能单元 - 知乎专栏"&gt;最前沿：让计算机学会学习Let Computers Learn to Learn&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/21470871?refer=intelligentunit" data-editable="true" data-title="最前沿：从虚拟到现实，迁移深度增强学习让机器人革命成为可能" class=""&gt;最前沿：从虚拟到现实，迁移深度增强学习让机器人革命成为可能&lt;/a&gt;！&lt;/li&gt;&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/22143664?refer=intelligentunit" data-editable="true" data-title="最前沿：深度学习训练方法大革新，反向传播训练不再唯一 - 智能单元 - 知乎专栏"&gt;最前沿：深度学习训练方法大革新，反向传播训练不再唯一 &lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;CS231n课程翻译系列&lt;/h2&gt;&lt;blockquote&gt;斯坦度CS231n：面向视觉识别的卷积神经网络，入门深度学习利器。&lt;/blockquote&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/21930884?refer=intelligentunit" class="" data-editable="true" data-title="贺完结！CS231n官方笔记授权翻译总集篇发布"&gt;贺完结！CS231n官方笔记授权翻译总集篇发布&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/20870307?refer=intelligentunit" class="" data-editable="true" data-title="获得授权翻译斯坦福CS231n课程笔记系列"&gt;获得授权翻译斯坦福CS231n课程笔记系列&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/20878530?refer=intelligentunit" data-editable="true" data-title="CS231n课程笔记翻译：Python Numpy教程" class=""&gt;CS231n课程笔记翻译：Python Numpy教程&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/20894041?refer=intelligentunit" data-editable="true" data-title="CS231n课程笔记翻译：图像分类笔记（上）" class=""&gt;CS231n课程笔记翻译：图像分类笔记（上）&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/20900216?refer=intelligentunit" data-editable="true" data-title="CS231n课程笔记翻译：图像分类笔记（下） - 智能单元 - 知乎专栏"&gt;CS231n课程笔记翻译：图像分类笔记（下）&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/20918580?refer=intelligentunit" data-editable="true" data-title="CS231n课程笔记翻译：线性分类笔记（上） - 智能单元 - 知乎专栏"&gt;CS231n课程笔记翻译：线性分类笔记（上）&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/20945670?refer=intelligentunit" data-editable="true" data-title="CS231n课程笔记翻译：线性分类笔记（中）" class=""&gt;CS231n课程笔记翻译：线性分类笔记（中）&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/21102293?refer=intelligentunit" data-editable="true" data-title="CS231n课程笔记翻译：线性分类笔记（下） - 智能单元 - 知乎专栏"&gt;CS231n课程笔记翻译：线性分类笔记（下）&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/21354230?refer=intelligentunit" class="" data-editable="true" data-title="知友智靖远关于CS231n课程字幕翻译的倡议 "&gt;知友智靖远关于CS231n课程字幕翻译的倡议 &lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/21360434?refer=intelligentunit" data-editable="true" data-title="CS231n课程笔记翻译：最优化笔记（上）" class=""&gt;CS231n课程笔记翻译：最优化笔记（上）&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/21387326?refer=intelligentunit" data-editable="true" data-title="CS231n课程笔记翻译：最优化笔记（下） - 智能单元 - 知乎专栏"&gt;CS231n课程笔记翻译：最优化笔记（下）&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/21407711?refer=intelligentunit" data-editable="true" data-title="CS231n课程笔记翻译：反向传播笔记 - 智能单元 - 知乎专栏"&gt;CS231n课程笔记翻译：反向传播笔记 &lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/21441838?refer=intelligentunit" data-editable="true" data-title="斯坦福CS231n课程作业# 1简介 - 智能单元 - 知乎专栏"&gt;斯坦福CS231n课程作业# 1简介 &lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/21462488?refer=intelligentunit" data-editable="true" data-title="CS231n课程笔记翻译：神经网络笔记1（上）" class=""&gt;CS231n课程笔记翻译：神经网络笔记1（上）&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/21513367?refer=intelligentunit" data-editable="true" data-title="CS231n课程笔记翻译：神经网络笔记1（下） - 智能单元 - 知乎专栏"&gt;CS231n课程笔记翻译：神经网络笔记1（下）&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/21560667?refer=intelligentunit" data-editable="true" data-title="CS231n课程笔记翻译：神经网络笔记 2 - 智能单元 - 知乎专栏"&gt;CS231n课程笔记翻译：神经网络笔记 2 &lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/21741716?refer=intelligentunit" data-editable="true" data-title="CS231n课程笔记翻译：神经网络笔记3（上）" class=""&gt;CS231n课程笔记翻译：神经网络笔记3（上）&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/21798784?refer=intelligentunit" data-editable="true" data-title="CS231n课程笔记翻译：神经网络笔记3（下）" class=""&gt;CS231n课程笔记翻译：神经网络笔记3（下）&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/21941485?refer=intelligentunit" data-editable="true" data-title="斯坦福CS231n课程作业# 2简介 " class=""&gt;斯坦福CS231n课程作业# 2简介 &lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/22038289?refer=intelligentunit" data-editable="true" data-title="CS231n课程笔记翻译：卷积神经网络笔记 - 猴子的文章 - 知乎专栏"&gt;CS231n课程笔记翻译：卷积神经网络笔记 &lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/21946525?refer=intelligentunit" class="" data-editable="true" data-title="斯坦福CS231n课程作业# 3简介 - 智能单元 - 知乎专栏"&gt;斯坦福CS231n课程作业# 3简介 &lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/22282421?refer=intelligentunit" data-editable="true" data-title="Andrej Karpathy的回信和Quora活动邀请 - 智能单元 - 知乎专栏"&gt;Andrej Karpathy的回信和Quora活动邀请&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/22232836?refer=intelligentunit" data-editable="true" data-title="知行合一码作业，深度学习真入门 - 智能单元 - 知乎专栏"&gt;知行合一码作业，深度学习真入门 &lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;深度增强学习系列&lt;/h2&gt;&lt;blockquote&gt;分享深度增强学习相关的资料，文章，代码及教程。&lt;/blockquote&gt;&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/20885568?refer=intelligentunit" class="" data-editable="true" data-title="Deep Reinforcement Learning 深度增强学习资源 (持续更新） - 智能单元 - 知乎专栏"&gt;Deep Reinforcement Learning 深度增强学习资源 (持续更新） &lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/20893777?refer=intelligentunit" data-editable="true" data-title="深度解读AlphaGo - 智能单元 - 知乎专栏"&gt;深度解读AlphaGo &lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/20924929?refer=intelligentunit" data-editable="true" data-title="从OpenAI看深度学习研究前沿 - 智能单元 - 知乎专栏"&gt;从OpenAI看深度学习研究前沿 &lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/21262246?refer=intelligentunit" data-editable="true" data-title="DQN 从入门到放弃1 DQN与增强学习 - 智能单元 - 知乎专栏"&gt;DQN 从入门到放弃1 DQN与增强学习&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/21263408?refer=intelligentunit" data-editable="true" data-title="你是这样获取人工智能AI前沿信息的吗？ - 智能单元 - 知乎专栏"&gt;你是这样获取人工智能AI前沿信息的吗？&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/21296798?refer=intelligentunit" class="" data-editable="true" data-title="解密Google Deepmind AlphaGo围棋算法：真人工智能来自于哪里？ - 智能单元 - 知乎专栏"&gt;解密Google Deepmind AlphaGo围棋算法：真人工智能来自于哪里？&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/21292697?refer=intelligentunit" data-editable="true" data-title="DQN 从入门到放弃2 增强学习与MDP - 智能单元 - 知乎专栏"&gt;DQN 从入门到放弃2 增强学习与MDP &lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/21340755?refer=intelligentunit" data-editable="true" data-title="DQN 从入门到放弃3 价值函数与Bellman方程 " class=""&gt;DQN 从入门到放弃3 价值函数与Bellman方程 &lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/21378532?refer=intelligentunit" class="" data-editable="true" data-title="DQN 从入门到放弃4 动态规划与Q-Learning - 智能单元 - 知乎专栏"&gt;DQN 从入门到放弃4 动态规划与Q-Learning &lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/21421729?refer=intelligentunit" data-editable="true" data-title="DQN从入门到放弃5 深度解读DQN算法 - 智能单元 - 知乎专栏"&gt;DQN从入门到放弃5 深度解读DQN算法 &lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/21434933?refer=intelligentunit" data-editable="true" data-title="DQN实战篇1 从零开始安装Ubuntu, Cuda, Cudnn, Tensorflow, OpenAI Gym - 智能单元 - 知乎专栏"&gt;DQN实战篇1 从零开始安装Ubuntu, Cuda, Cudnn, Tensorflow, OpenAI Gym &lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/21477488?refer=intelligentunit" data-editable="true" data-title="150行代码实现DQN算法玩CartPole " class=""&gt;150行代码实现DQN算法玩CartPole &lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/21547911?refer=intelligentunit" data-editable="true" data-title="DQN从入门到放弃6 DQN的各种改进 - 智能单元 - 知乎专栏"&gt;DQN从入门到放弃6 DQN的各种改进 &lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/21609472?refer=intelligentunit" data-editable="true" data-title="DQN从入门到放弃7 连续控制DQN算法-NAF " class=""&gt;DQN从入门到放弃7  连续控制DQN算法-NAF &lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/21725498?refer=intelligentunit" data-editable="true" data-title="深度增强学习之Policy Gradient方法1 - 智能单元 - 知乎专栏"&gt;深度增强学习之Policy Gradient方法1 &lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/21369441?refer=intelligentunit" data-editable="true" data-title="深度增强学习暑期学校 PPT 详解1 - 智能单元 - 知乎专栏"&gt;深度增强学习暑期学校 PPT 详解1 &lt;/a&gt;&lt;/li&gt;&lt;h2&gt;原创翻译系列&lt;/h2&gt;&lt;blockquote&gt;共同学习的翻译小组奉上值得一翻的文章。&lt;/blockquote&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/22107715?refer=intelligentunit" data-editable="true" data-title="[原创翻译]循环神经网络惊人的有效性（上）" class=""&gt;[原创翻译]循环神经网络惊人的有效性（上）&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href="https://zhuanlan.zhihu.com/p/22230074?refer=intelligentunit"&gt;[原创翻译]循环神经网络惊人的有效性（下）&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;知友投稿系列&lt;/h2&gt;&lt;blockquote&gt;欢迎知友投稿，请看投稿说明。&lt;/blockquote&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/21917736?refer=intelligentunit" data-editable="true" data-title="智能单元专栏投稿说明 - 智能单元 - 知乎专栏"&gt;智能单元专栏投稿说明&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/21341440?refer=intelligentunit" class="" data-editable="true" data-title="「无中生有」计算机视觉探奇 - 欲穷千里目 - 知乎专栏"&gt;「无中生有」计算机视觉探奇 &lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/22308032?refer=intelligentunit" data-editable="true" data-title="关于图像语义分割的总结和感悟 - 困兽的文章 - 知乎专栏"&gt;关于图像语义分割的总结和感悟 &lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;END&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/22339097&amp;pixel&amp;useReferer"/&gt;</description><author>杜客</author><pubDate>Sun, 11 Sep 2016 21:13:02 GMT</pubDate></item><item><title>深度增强学习暑期学校 PPT 详解1</title><link>https://zhuanlan.zhihu.com/p/21369441</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/6f589df38509d14f839737645322a011_r.jpg"&gt;&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/e6bbfe6ccf2febd9efdd67ab1ebf9b8f.jpg" data-rawwidth="1511" data-rawheight="1133"&gt;&lt;p&gt;这是2016年机器学习暑期学校的课程，OpenAI的John Schulman做了4次Deep Reinforcement Learning的讲座，讲座的具体链接如下：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=aUrX-rP_ss4" data-editable="true" data-title="Lecture 1"&gt;Lecture 1&lt;/a&gt;: intro, derivative free optimization&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=oPGVsoBonLM" data-editable="true" data-title="Lecture 2"&gt;Lecture 2&lt;/a&gt;: score function gradient estimation and policy gradients&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=rO7Dx8pSJQw" data-editable="true" data-title="Lecture 3"&gt;Lecture 3&lt;/a&gt;: actor critic methods&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=gb5Q2XL5c8A" data-editable="true" data-title="Lecture 4"&gt;Lecture 4&lt;/a&gt;: trust region and natural gradient methods, open problems&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;本文基于其讲座的&lt;a href="https://learning.mpi-sws.org/mlss2016/slides/2016-MLSS-RL.pdf" data-editable="true" data-title="ppt"&gt;ppt&lt;/a&gt;及视频，对讲座的内容按照ppt的顺序做一些翻译，分析和理解。&lt;/p&gt;&lt;p&gt;课程的实验材料在这里：&lt;a href="https://goo.gl/5wsgbJ"&gt;https://goo.gl/5wsgbJ&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/28f14d7ec3989c6db1061721a191cd20.jpg" data-rawwidth="1511" data-rawheight="1133"&gt;这个课程偏向于介绍Policy Gradient方法，从Andrej Karparthy的blog &lt;a href="http://karpathy.github.io/2016/05/31/rl/" class="" data-editable="true" data-title="Deep Reinforcement Learning: Pong from Pixels"&gt;Deep Reinforcement Learning: Pong from Pixels&lt;/a&gt;上说，Policy Gradient是目前更侧重的深度增强学习的方法。那么本身John Schulman最重要的工作就是TPRO，一个基于Policy Gradient的改进算法。这个算法目前在OpenAI Gym的表现非常好。&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/2c3e9b1ea2e51e37dc4280c87218cc48.jpg" data-rawwidth="1511" data-rawheight="1133"&gt;首先是整体介绍部分&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/2c8117dfc0b1805a390e728588651cc5.jpg" data-rawwidth="1511" data-rawheight="1133"&gt;&lt;h2&gt;什么是增强学习？&lt;/h2&gt;&lt;p&gt;关于什么是增强学习在我们专栏中已经有详细的介绍&lt;a href="https://zhuanlan.zhihu.com/p/21262246?refer=intelligentunit" class=""&gt;https://zhuanlan.zhihu.com/p/21262246?refer=intelligentunit&lt;/a&gt;&lt;/p&gt;&lt;p&gt;增强学习是机器学习的一个分支，不同于监督学习和无监督学习，它主要侧重于如何输出序列动作。也就是增强学习关注决策与控制。那么最基本的问题描述就是一个智能体（Agent）在未知的环境中，如何根据观察（Observation)和反馈（Reward）来调整自己行为（Action），从而使累积的反馈（Reward）最大化。注意这里说的是累积的反馈，而不是单一行为之后的反馈。这很好理解。举炒股票为例，我们一个买入卖出动作之后，当天的收益也就是Reward，但是我们看重的是比如一周之后的收益是怎样的。这就需要累积每一天的Reward。我们的目标就是希望未来的最终收益最大化。这就是增强学习要研究的问题。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/699c37bd7b0aad686021bee62c7a62e9.jpg" data-rawwidth="1511" data-rawheight="1133"&gt;&lt;h2&gt;增强学习有什么用？&lt;/h2&gt;&lt;p&gt;因为增强学习的重要在于解决决策与控制，因此机器人的控制显然是首当其冲了。那么怎么用增强学习的模型来描述机器人控制的问题呢&lt;/p&gt;&lt;ul&gt;&lt;li&gt;观察Observations：摄像头的图像，机械臂关节的角度，，&lt;/li&gt;&lt;li&gt;动作Actions：就是每个电机的输出扭矩，如果是机械臂那么就是对应每个关节的扭矩啦&lt;/li&gt;&lt;li&gt;反馈Rewards：有多种形式，主要就是看是什么任务了。比如保持平衡，移动到某个特定位置，或者服务及保护人类等等&lt;/li&gt;&lt;/ul&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/2cc0a9440ef8aea3174cac9cdb9dae75.jpg" data-rawwidth="1511" data-rawheight="1133"&gt;&lt;h2&gt;增强学习在商业上的问题&lt;/h2&gt;&lt;p&gt;既然涉及到决策，那么商业决策是显然值得研究的。&lt;/p&gt;&lt;ol&gt;&lt;li&gt;库存管理。对于一个超市来说，如何管理库存是很需要研究的，最好的情况就是所有的货物都不会积压，都正常卖出，不出现损失。这就需要考虑每个时间段如何根据当前库存购买新的货物的问题。在这个问题上，观察就是当前的库存情况，动作就是购买的每一种货物的数量，反馈就是最后的收益。&lt;/li&gt;&lt;li&gt;资源分配。比如当前有一定量的资金，那么有很多投资选择，如何分配这些投资才能使投资收益最大化呢？观察就是当前的投资及资金分配情况，动作就是分配资金，反馈就是收益。&lt;/li&gt;&lt;li&gt;运输问题。比如滴滴的算法大赛问题，就是希望能够估计出不同地区的顾客需求，从而更好的调配出租车的位置。比赛的问题只是一个预测问题。但是如何直接调配出租车那么就是一个增强学习问题了。&lt;/li&gt;&lt;/ol&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/827f9d3f0efc75c00633cf33abe89eb9.jpg" data-rawwidth="1511" data-rawheight="1133"&gt;&lt;h2&gt;游戏上的应用&lt;/h2&gt;&lt;p&gt;因为AlphaGo的出现，大家对此就比较了解了。很多游戏都是RL的问题。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;围棋。完全的信息，确定性决策（就是每次只有一个确定性的选择）。&lt;/li&gt;&lt;li&gt;Backgammon, 西洋双陆棋：图片引用自&lt;a href="http://imag.juegosdb.com/blog/images/2013/51/backgammon.jpg"&gt;http://imag.juegosdb.com/blog/images/2013/51/backgammon.jpg&lt;/a&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/0982f2efcb811acbf6e6c6b5eb6367ed.jpg" data-rawwidth="537" data-rawheight="302"&gt;这种游戏也是完全信息的，只不过需要掷骰子，因此存在随机性Stochastic。这个游戏有个著名的算法叫TD-Gammon，很早了，用了简单的神经网络实现。也就是深度增强学习其实也很有历史啦。&lt;/li&gt;&lt;li&gt;Stragego 西洋陆军棋：图片引用自&lt;a href="https://staticdelivery.nexusmods.com/mods/461/images/152-1-1398654075.jpg" class=""&gt;https://staticdelivery.nexusmods.com/mods/461/images/152-1-1398654075.jpg&lt;/a&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/36953ccb54e20f5b772517e998eaa772.jpg" data-rawwidth="500" data-rawheight="193"&gt;这种棋和我们的军棋差不多，也是下暗棋，所以是不完全信息博弈，但它的每一步是确定性的。&lt;/li&gt;&lt;li&gt;Poker 扑克，特别是德州扑克：图片引用自&lt;a href="https://i.ytimg.com/vi/oa109hO4ZxQ/maxresdefault.jpg"&gt;https://i.ytimg.com/vi/oa109hO4ZxQ/maxresdefault.jpg&lt;/a&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/2aa16c2358ed22727b0981914ccb40b9.jpg" data-rawwidth="1280" data-rawheight="720"&gt;对于这种游戏，显然是不完全信息博弈，并且每一个回合都存在随机性，大家都不知道发的什么牌。&lt;/li&gt;&lt;/ul&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/9e674e4536155881c111beb5c06aa374.jpg" data-rawwidth="1511" data-rawheight="1133"&gt;&lt;h2&gt;增强学习的解决方法&lt;/h2&gt;&lt;p&gt;那么从上面的ppt中可以看到基于RL的解决办法可以分成两大类：&lt;/p&gt;&lt;p&gt;1）策略优化Policy Optimization。就是直接优化策略&lt;equation&gt;\pi(s)&lt;/equation&gt;。这种方法又分为两种：一种称为进化Evolution方法，就是不断调整策略的参数，选择更好的参数。另一种就是策略梯度Policy Gradient。通过计算策略的梯度方向，通过梯度下降的方式来优化策略。&lt;/p&gt;&lt;p&gt;2）动态规划Dynamic Programming。这个方法就是利用价值函数Value Function来实现曲线救国。有策略迭代Policy Iteration和值迭代Value Iteration。最有名的就是Q-Learning了，DQN就是Deep Q-Learning。&lt;/p&gt;&lt;p&gt;除了上面的两种方法，第三种就综合上面两种方法形成所谓的Actor-Critic方法，也就是行动-监督方法。&lt;/p&gt;&lt;p&gt;其实，对于增强学习的问题，还有一个方法就是只使用监督学习，只是这种方法需要有现有的方法提供监督学习的样本。UC Berkerley其实这方面的成果是最多的，Guided Policy Search就属于这类监督学习的方法。如果你不是很明白，但是了解AlphaGo。AlphaGo一开始的监督学习就是利用人类棋谱做训练，这也可以达到不错的效果。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/9a8b778b70e8de7a30d99d73a62d450a.jpg" data-rawwidth="1511" data-rawheight="1133"&gt;&lt;h2&gt;什么是深度增强学习Deep RL？&lt;/h2&gt;&lt;p&gt;深度增强学习就是将增强学习中的策略Policy或者价值函数Value Function用非线性函数来近似，然后显然用深度神经网络是最好的非线性函数。那么通常就是使用随机梯度下降的方式来更新里面的参数。&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/585fada39cb030ac8bdb4ee937be4e6a.jpg" data-rawwidth="1511" data-rawheight="1133"&gt;这里将Deep RL研究的问题与人类大脑皮层的功能做对比。Deep RL类比为人类的前半部分大脑皮层，用于处理决策与控制。而大脑的后半部分则处理感知类比计算机视觉处理的功能。从这里的类比可见Deep RL研究的重要性。&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/16f25e5b2a24860097e37d4c480bee30.jpg" data-rawwidth="1511" data-rawheight="1133"&gt;接下来介绍马尔科夫决策过程&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/c470410c8e52cf359c4b515d45689ebc.jpg" data-rawwidth="1511" data-rawheight="1133"&gt;马尔科夫决策过程最基本的定义就是（S,A,P)，其中&lt;/p&gt;&lt;ul&gt;&lt;li&gt;S：状态空间&lt;/li&gt;&lt;li&gt;A：动作空间&lt;/li&gt;&lt;li&gt;&lt;equation&gt;P(r,s^`|s,a)&lt;/equation&gt;：状态转移的概率分布。也就是在当前s和动作a下，下一个时间片的状态s和反馈r会是怎样的，这通常用概率分布来表示。对于一些完全可观察的问题比如围棋，那么下一步的情况则是确定性的。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;根据问题的设定常常会定义额外的对象：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;equation&gt;\mu &lt;/equation&gt;：初始的状态分布&lt;/li&gt;&lt;li&gt;&lt;equation&gt;\lambda &lt;/equation&gt;：衰减系数。就是反馈Reward一般根据时间作用越来越小，用该系数来表示。&lt;/li&gt;&lt;/ul&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/23416bdaeab43f925e7d1e09cdbf6310.jpg" data-rawwidth="1511" data-rawheight="1133"&gt;&lt;h2&gt;篇章式设定&lt;/h2&gt;&lt;p&gt;在很多RL问题中，问题有一个欲达成的目标，也就是一个任务的时间长度是有限制的，是可以结束的，对于这种可以结束的问题，就是每运行一次实验就称为一次episode，依旧是从初始状态开始，直到最终的结束状态到达。比如：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;的士机器人到达目的地（结束状态是好的）&lt;/li&gt;&lt;li&gt;侍者机器人完成一个移动（在有限时间内）&lt;/li&gt;&lt;li&gt;移动机器人摔倒（结束状态是坏的）&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;还有其他的比如围棋就是到一盘棋下完，而玩Atari游戏就是到游戏结束。&lt;/p&gt;&lt;p&gt;那么这种问题的目标是比较好确定的，就是到任务结束时得到最大的累加反馈值。那么有没有一些问题是没有结束的呢？只能说可以有，但都可以转化为可以结束的情况。比如说机器蚂蚁走路，目标就是向前走。这个时候不管怎么样可以设定一个时间让其强制结束如果没有走到某个特定位置。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/c8ef45d5301ade8e70a3f8289587a638.jpg" data-rawwidth="1511" data-rawheight="1133"&gt;&lt;h2&gt;策略&lt;/h2&gt;&lt;p&gt;策略有两种方式表示，这个我们在之前的专栏文章中也说明过：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;一种就是确定性策略：&lt;equation&gt;a=\pi(s)&lt;/equation&gt;，也就是有一个状态s，就对应一个动作a&lt;/li&gt;&lt;li&gt;另一种就是随机分布：&lt;equation&gt;a\sim \pi(a|s)&lt;/equation&gt;，也就是即使面对同一个状态s，也存在多种动作选择可能都是较优的，因此用概率来表示选择某一个动作的可能性。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;那么深度增强学习就是要研究如何更新策略的参数来优化策略。&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/163deaf9001b372d53d63f3a76b3802f.jpg" data-rawwidth="1511" data-rawheight="1133"&gt;那么对于篇章式设定的问题，目标是非常简单可以设定的，就是累加反馈的期望值，如上面的公式表示。&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/f55d107d818aa9ea3a36c297eaab1d5c.jpg" data-rawwidth="1511" data-rawheight="1133"&gt;那么上面这个图可以更清楚的表示这个过程。大家要记住这一点。就是在MDP的框架下，时间可分割，因此就是分割成一个一个的时间片。因此可以形成&lt;equation&gt;\{s_0,a_0,s_1,r_0,a_1,s_2,r_1....\}&lt;/equation&gt;这样的时间序列数据。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/65bfc3f75b5a8ef194b3c8985f3e4bde.jpg" data-rawwidth="1511" data-rawheight="1133"&gt;&lt;h2&gt;参数化策略&lt;/h2&gt;&lt;p&gt;就是用参数来表示一个策略，比如用一个线性方程来表示策略，那么线性方程的参数就影响了这个策略。如果用&lt;equation&gt;\theta&lt;/equation&gt;来表示参数，那么参数化的策略就如下表示：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;确定性策略：&lt;equation&gt;a=\pi(s,\theta)&lt;/equation&gt;&lt;/li&gt;&lt;li&gt;随机性策略：&lt;equation&gt;\pi(a|s,\theta)&lt;/equation&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;很多不是非常理解这个带参数的策略应该是如何构建，特别是使用神经网络。神经网络的输出可是分类Classification也可以是回归Regression，取决于动作是连续还是离散。比如Atari游戏，输出就是几个离散的动作，那么就可以使用分类的神经网络。输入的是图像，输出的是几个动作的概率，这就可以用softmax来输出。那么如果是连续的动作空间，比如机器人控制基本都是连续动作，那么可以使用regression回归神经网络。网络输出可以是高斯分布的平均值及对角协方差。关于这一点在后面的CEM算法中可以有清晰的理解。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/8c6ca3d85bff3a391d6c0c85436b94a2.jpg" data-rawwidth="1511" data-rawheight="1133"&gt;&lt;h2&gt;接下来就介绍通过黑盒优化来求解增强学习问题&lt;/h2&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/0db14a0d35f9cccd994c1efd1167fd02.jpg" data-rawwidth="1511" data-rawheight="1133"&gt;&lt;h2&gt;无需导数的优化方法&lt;/h2&gt;&lt;p&gt;说到优化我们首先会想到梯度下降，但是其实有很多其他的优化的方法并不使用梯度下降。比如模拟退火，爬山法，遗传算法等等。那么这里我们就把策略Policy看做是一个黑盒，我们的目标很明确，就是让期望的反馈最大化。除了R之外，其他的信息我们都不管。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/d386a8e117d4d71871cd8cd7e563e212.jpg" data-rawwidth="1511" data-rawheight="1133"&gt;&lt;h2&gt;交叉熵方法Cross Entropy Method&lt;/h2&gt;&lt;p&gt;一种进化算法。但是却取得了很不错的效果。ppt列出了较早的将CEM方法应用到增强学习的论文。用一种带噪声的交叉熵方法。&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/88973c5434a0c6e78b81360166170168.jpg" data-rawwidth="1511" data-rawheight="1133"&gt;一个和交叉熵类似的方法叫做Covariance Matrix Adaption，简称CMA。在图形学上已经成为了一种标准算法。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/02dec73f0fd570dd5b171813536802e5.jpg" data-rawwidth="1511" data-rawheight="1133"&gt;&lt;h2&gt;交叉熵方法&lt;/h2&gt;&lt;p&gt;这里具体介绍交叉熵的方法。可以用很简单的一句话来说明：&lt;b&gt;就是每次根据当前的策略参数采样多组带噪声的新的参数，然后进行试验，选择反馈R最好的前几组参数，然后取平均作为新的参数&lt;/b&gt;。这种方法其实就是一种贪婪算法，通过纯随机的方式来寻找最佳的参数。按道理这种方法不应该和梯度下降的方法相提并论，但没想到CEM方法出奇的好。就是即使这个策略用巨大的神经网络来表示，也同样能够取得非常不错的效果。&lt;/p&gt;&lt;p&gt;有些知友可能看不明白上面的算法中的高斯分布是啥意思，其实就是选择中的几组参数的平均值就是高斯分布的平均值，而方差就是几组参数的方差。方差和平均值都用于之后再产生新的参数。&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/524e1b9750dacd213f8d5923e1957683.jpg" data-rawwidth="1511" data-rawheight="1133"&gt;CEM方法的分析&lt;/p&gt;&lt;p&gt;这边作者也没有深入的分析，只是提了几句相关的算法。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/aeb4af1189a6016f930b83a4c229a5fa.jpg" data-rawwidth="1511" data-rawheight="1133"&gt;&lt;h2&gt;策略梯度方法&lt;/h2&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/aad9dced603a37b65bce6b8abbb8712c.jpg" data-rawwidth="1511" data-rawheight="1133"&gt;&lt;h2&gt;策略梯度方法&lt;/h2&gt;&lt;p&gt;策略梯度方法的目标是和上面的CEM方法是一样的，就是最大化期望的反馈R。那么一个很直观的做法就是不断试验，采集各种状态动作数据，也就是所谓的轨迹trajectory。那么有了样本，就有得做了：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;第一种是让好的轨迹出现可能性增大&lt;/li&gt;&lt;li&gt;第二种是让好的动作出现可能性增大（actor-critic方法，GAE方法）&lt;/li&gt;&lt;li&gt;第三种是让动作趋向于好的动作（DPG，SVG方法）&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;那么这三种有什么不一样呢？第一种就是要求一系列的动作都好，比如某一次实验比较好，那么这次实验的每一个动作的可能性都增大。第二种就是只针对单一的动作。如果某一个动作的评估比较好，那么让其出现可能性增大。第三种的目标是让动作趋向好的动作，也就是有一个好的动作的目标，比如DPG使用Q值，目标就是让动作的Q值增大。那就得到好的动作了。&lt;/p&gt;&lt;p&gt;第一部分先到这里。&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/21369441&amp;pixel&amp;useReferer"/&gt;</description><author>Flood Sung</author><pubDate>Sun, 11 Sep 2016 15:25:05 GMT</pubDate></item><item><title>关于图像语义分割的总结和感悟</title><link>https://zhuanlan.zhihu.com/p/22308032</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/cb5e078e5008907cb04b300369b7d621_r.jpg"&gt;&lt;/p&gt;&lt;h2&gt;前言 &lt;/h2&gt;&lt;p&gt;
(呕血制作啊！)前几天刚好做了个图像语义分割的汇报，把最近看的论文和一些想法讲了一下。所以今天就把它总结成文章啦，方便大家一起讨论讨论。本文只是展示了一些比较经典和自己觉得比较不错的结构，毕竟这方面还是有挺多的结构方法了。&lt;/p&gt;&lt;h2&gt;介绍 &lt;/h2&gt;&lt;blockquote&gt;&lt;b&gt;图像语义分割&lt;/b&gt;，简单而言就是给定一张图片，对图片上的每一个像素点分类&lt;/blockquote&gt;

从图像上来看，就是我们需要将实际的场景图分割成下面的分割图： &lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/cb5e078e5008907cb04b300369b7d621.jpg" data-rawwidth="738" data-rawheight="472"&gt;不同颜色代表不同类别。

经过我阅读“大量”论文（羞涩）和查看&lt;a href="http://host.robots.ox.ac.uk:8080/leaderboard/displaylb.php?challengeid=11&amp;amp;compid=6" data-editable="true" data-title="PASCAL VOC Challenge performance evaluation server" class=""&gt;PASCAL VOC Challenge performance evaluation server&lt;/a&gt;，我发现图像语义分割从深度学习引入这个任务（FCN）到现在而言，一个通用的框架已经大概确定了。即： &lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/3adeadf2a20b0cc9cd68553a95f00552.png" data-rawwidth="1963" data-rawheight="781"&gt;&lt;ul&gt;&lt;li&gt;FCN-全卷积网络 &lt;/li&gt;&lt;li&gt;CRF-条件随机场 &lt;/li&gt;&lt;li&gt;MRF-马尔科夫随机场 &lt;/li&gt;&lt;/ul&gt;
前端使用FCN进行特征粗提取，后端使用CRF/MRF优化前端的输出，最后得到分割图。 &lt;p&gt;
接下来，我会从前端和后端两部分进行总结。&lt;/p&gt;&lt;h2&gt;前端 &lt;/h2&gt;&lt;h2&gt;为什么需要FCN？&lt;/h2&gt;&lt;p&gt;我们分类使用的网络通常会在最后连接几层全连接层，它会将原来二维的矩阵（图片）压扁成一维的，从而丢失了空间信息，最后训练输出一个标量，这就是我们的分类标签。 &lt;/p&gt;&lt;p&gt;
而图像语义分割的输出需要是个分割图，且不论尺寸大小，但是至少是二维的。所以，我们需要丢弃全连接层，换上全卷积层，而这就是全卷积网络了。具体定义请参看论文：&lt;a href="https://people.eecs.berkeley.edu/~jonlong/long_shelhamer_fcn.pdf" data-title="Fully Convolutional Networks for Semantic Segmentation" class="" data-editable="true"&gt;Fully Convolutional Networks for Semantic Segmentation&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;前端结构&lt;/h2&gt;&lt;h2&gt;FCN &lt;/h2&gt;&lt;p&gt;此处的FCN特指&lt;a href="https://people.eecs.berkeley.edu/~jonlong/long_shelhamer_fcn.pdf" data-title="Fully Convolutional Networks for Semantic Segmentation" class="" data-editable="true"&gt;Fully Convolutional Networks for Semantic Segmentation&lt;/a&gt;论文中提出的结构，而非广义的全卷积网络。 &lt;/p&gt;&lt;p&gt;
作者的FCN主要使用了三种技术：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;卷积化（Convolutional） &lt;/li&gt;&lt;li&gt;上采样（Upsample） &lt;/li&gt;&lt;li&gt;跳跃结构（Skip Layer） &lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;卷积化 &lt;/b&gt;&lt;/p&gt;&lt;p&gt;卷积化即是将普通的分类网络，比如VGG16，ResNet50/101等网络丢弃全连接层，换上对应的卷积层即可。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/42d85c5f7ddcb3f527666b250f62f5d6.png" data-rawwidth="630" data-rawheight="355"&gt;&lt;p&gt;&lt;b&gt;上采样 &lt;/b&gt;&lt;/p&gt;&lt;p&gt;此处的上采样即是反卷积（Deconvolution）。当然关于这个名字不同框架不同，Caffe和Kera里叫Deconvolution，而tensorflow里叫conv_transpose。CS231n这门课中说，叫conv_transpose更为合适。 &lt;/p&gt;&lt;p&gt;
众所诸知，普通的池化（为什么这儿是普通的池化请看后文）会缩小图片的尺寸，比如VGG16 五次池化后图片被缩小了32倍。为了得到和原图等大的分割图，我们需要上采样/反卷积。 &lt;/p&gt;&lt;p&gt;
反卷积和卷积类似，都是相乘相加的运算。只不过后者是多对一，前者是一对多。而反卷积的前向和后向传播，只用颠倒卷积的前后向传播即可。所以无论优化还是后向传播算法都是没有问题。图解如下：&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/c18522f52e930a3f83748a73a829f0ad.jpg" data-rawwidth="403" data-rawheight="138"&gt;&lt;p&gt;但是，虽然文中说是可学习的反卷积，但是作者实际代码并没有让它学习，可能正是因为这个一对多的逻辑关系。代码如下： &lt;/p&gt;&lt;pre&gt;&lt;code lang="text"&gt;layer {
  name: "upscore"
  type: "Deconvolution"
  bottom: "score_fr"
  top: "upscore"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 21
    bias_term: false
    kernel_size: 64
    stride: 32
  }
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;可以看到lr_mult被设置为了0. &lt;/p&gt;&lt;p&gt;&lt;b&gt;跳跃结构&lt;/b&gt;&lt;/p&gt;&lt;p&gt;（这个奇怪的名字是我翻译的，好像一般叫忽略连接结构）这个结构的作用就在于优化结果，因为如果将全卷积之后的结果直接上采样得到的结果是很粗糙的，所以作者将不同池化层的结果进行上采样之后来优化输出。具体结构如下：&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/ccb6dd0a7f207134ae7690974c3e88a5.png" data-rawwidth="1254" data-rawheight="864"&gt;&lt;p&gt;而不同上采样结构得到的结果对比如下：&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/5df8b118a7f77a2222d343a852b46034.png" data-rawwidth="594" data-rawheight="250"&gt;&lt;p&gt;当然，你也可以将pool1， pool2的输出再上采样输出。不过，作者说了这样得到的结果提升并不大。 &lt;/p&gt;&lt;p&gt;这是第一种结构，也是深度学习应用于图像语义分割的开山之作，所以得了CVPR2015的最佳论文。但是，还是有一些处理比较粗糙的地方，具体和后面对比就知道了。 &lt;/p&gt;&lt;h2&gt;SegNet/DeconvNet &lt;/h2&gt;&lt;p&gt;这样的结构总结在这儿，只是我觉得结构上比较优雅，它得到的结果不一定比上一种好。 &lt;/p&gt;&lt;p&gt;&lt;b&gt;SegNet &lt;/b&gt;&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/6cab0e3643d16ccab0a1bf1909813484.png" data-rawwidth="877" data-rawheight="250"&gt;&lt;p&gt;&lt;b&gt;DeconvNet&lt;/b&gt;&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/99f62dbfe0e39aea5674deeaa2d8363d.jpg" data-rawwidth="828" data-rawheight="313"&gt;&lt;p&gt;这样的对称结构有种自编码器的感觉在里面，先编码再解码。这样的结构主要使用了反卷积和上池化。即： &lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/c18522f52e930a3f83748a73a829f0ad.jpg" data-rawwidth="403" data-rawheight="138"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/f2da827523ecaa6b8c96b73464ba4c5c.jpg" data-rawwidth="411" data-rawheight="130"&gt;&lt;p&gt;
反卷积如上。而上池化的实现主要在于池化时记住输出值的位置，在上池化时再将这个值填回原来的位置，其他位置填0即OK。 &lt;/p&gt;&lt;h2&gt;DeepLab &lt;/h2&gt;&lt;p&gt;
接下来介绍一个很成熟优雅的结构，以至于现在的很多改进是基于这个网络结构的进行的。&lt;/p&gt;&lt;p&gt;

首先这里我们将指出一个第一个结构FCN的粗糙之处：为了保证之后输出的尺寸不至于太小，FCN的作者在第一层直接对原图加了100的padding，可想而知，这会引入噪声。 &lt;/p&gt;&lt;p&gt;
而怎样才能保证输出的尺寸不会太小而又不会产生加100 padding这样的做法呢？可能有人会说减少池化层不就行了，这样理论上是可以的，但是这样直接就改变了原先可用的结构了，而且最重要的一点是就不能用以前的结构参数进行fine-tune了。所以，Deeplab这里使用了一个非常优雅的做法：将pooling的stride改为1，再加上 1 padding。这样池化后的图片尺寸并未减小，并且依然保留了池化整合特征的特性。 &lt;/p&gt;&lt;p&gt;
但是，事情还没完。因为池化层变了，后面的卷积的感受野也对应的改变了，这样也不能进行fine-tune了。所以，Deeplab提出了一种新的卷积，带孔的卷积：Atrous Convolution.即： &lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/2ec8009452f89b7bbd9ecd519fc3e3ae.png" data-rawwidth="865" data-rawheight="543"&gt;&lt;p&gt;而具体的感受野变化如下： &lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/766fc04b86b72f7e09d8f8ff6cb648e2.png" data-rawwidth="1147" data-rawheight="711"&gt;a为普通的池化的结果，b为“优雅”池化的结果。我们设想在a上进行卷积核尺寸为3的普通卷积，则对应的感受野大小为7.而在b上进行同样的操作，对应的感受野变为了5.感受野减小了。但是如果使用hole为1的Atrous Convolution则感受野依然为7.&lt;/p&gt;&lt;p&gt;所以，Atrous Convolution能够保证这样的池化后的感受野不变，从而可以fine tune，同时也能保证输出的结果更加精细。即： &lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/39577b54b8b53802020cab6da6f9e334.png" data-rawwidth="562" data-rawheight="325"&gt;&lt;p&gt;&lt;b&gt;总结 &lt;/b&gt;&lt;/p&gt;&lt;p&gt;
这里介绍了三种结构：FCN, SegNet/DeconvNet，DeepLab。当然还有一些其他的结构方法，比如有用RNN来做的，还有更有实际意义的weakly-supervised方法等等。 &lt;/p&gt;&lt;h2&gt;后端 &lt;/h2&gt;&lt;p&gt;
终于到后端了，后端这里会讲几个场，涉及到一些数学的东西。我的理解也不是特别深刻，所以欢迎吐槽。&lt;/p&gt;&lt;p&gt;&lt;b&gt;全连接条件随机场(DenseCRF) &lt;/b&gt;&lt;/p&gt;&lt;p&gt;对于每个像素&lt;equation&gt;i&lt;/equation&gt;具有类别标签&lt;equation&gt;x_i&lt;/equation&gt;还有对应的观测值&lt;equation&gt;y_i&lt;/equation&gt;，这样每个像素点作为节点，像素与像素间的关系作为边，即构成了一个条件随机场。而且我们通过观测变量&lt;equation&gt;y_i&lt;/equation&gt;来推测像素&lt;equation&gt;i&lt;/equation&gt;对应的类别标签&lt;equation&gt;x_i&lt;/equation&gt;。条件随机场如下：&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/eb0015ceb7aac30d571cd90a47d9e22d.png" data-rawwidth="282" data-rawheight="221"&gt;&lt;p&gt;条件随机场符合吉布斯分布：(此处的&lt;equation&gt;x&lt;/equation&gt;即上面说的观测值) &lt;/p&gt;&lt;equation&gt;P(\mathbf{X=x|I})=\frac{1}{Z(\mathbf{I})}\exp(-E(\mathbf{x|I}))&lt;/equation&gt;&lt;p&gt;其中的&lt;equation&gt;E(\mathbf{x|I})&lt;/equation&gt;是能量函数，为了简便，以下省略全局观测&lt;equation&gt;\mathbf{I}&lt;/equation&gt;： &lt;/p&gt;&lt;equation&gt;E(\mathbf{x})=\sum_i{\Psi_u(x_i)}+\sum_{i&amp;lt;j}\Psi_p(x_i, x_j)&lt;/equation&gt;&lt;p&gt; 其中的一元势函数&lt;equation&gt;\sum_i{\Psi_u(x_i)}&lt;/equation&gt;即来自于前端FCN的输出。而二元势函数如下： &lt;/p&gt;&lt;equation&gt;\Psi_p(x_i, x_j)=u(x_i, x_j)\sum_{m=1}^M{\omega^{(m)}k_G^{(m)}(\mathbf{f_i, f_j)}}&lt;/equation&gt;&lt;p&gt;
二元势函数就是描述像素点与像素点之间的关系，鼓励相似像素分配相同的标签，而相差较大的像素分配不同标签，而这个“距离”的定义与颜色值和实际相对距离有关。所以这样CRF能够使图片尽量在边界处分割。&lt;/p&gt;&lt;p&gt;而全连接条件随机场的不同就在于，二元势函数描述的是每一个像素与其他所有像素的关系，所以叫“全连接”。 &lt;/p&gt;&lt;p&gt;
关于这一堆公式大家随意理解一下吧... ...而直接计算这些公式是比较麻烦的（我想也麻烦），所以一般会使用平均场近似方法进行计算。而平均场近似又是一堆公式，这里我就不给出了（我想大家也不太愿意看），愿意了解的同学直接看论文吧。 &lt;/p&gt;&lt;p&gt;&lt;b&gt;CRFasRNN&lt;/b&gt;&lt;/p&gt;&lt;p&gt;最开始使用DenseCRF是直接加在FCN的输出后面，可想这样是比较粗糙的。而且在深度学习中，我们都追求end-to-end的系统，所以CRFasRNN这篇文章将DenseCRF真正结合进了FCN中。&lt;/p&gt;&lt;p&gt;这篇文章也使用了平均场近似的方法，因为分解的每一步都是一些相乘相加的计算，和普通的加减（具体公式还是看论文吧），所以可以方便的把每一步描述成一层类似卷积的计算。这样即可结合进神经网络中，并且前后向传播也不存在问题。&lt;/p&gt;&lt;p&gt;当然，这里作者还将它进行了迭代，不同次数的迭代得到的结果优化程度也不同（一般取10以内的迭代次数），所以文章才说是as RNN。优化结果如下： &lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/40fb43fd1cc813501ed803224814f2ed.jpg" data-rawwidth="578" data-rawheight="323"&gt;&lt;p&gt;&lt;b&gt;马尔科夫随机场(MRF) &lt;/b&gt;&lt;/p&gt;&lt;p&gt;在Deep Parsing Network中使用的是MRF，它的公式具体的定义和CRF类似，只不过作者对二元势函数进行了修改：&lt;/p&gt;&lt;equation&gt;\Psi(y_i^u, y_i^v)=\sum_{k=1}^K\lambda_ku_k(i, u, j, v)\sum_{\forall{z\in{N_j}}}d(j, z)p_z^v&lt;/equation&gt;&lt;p&gt;其中，作者加入的&lt;equation&gt;\lambda_k&lt;/equation&gt;为label context，因为&lt;equation&gt;u_k&lt;/equation&gt;只是定义了两个像素同时出现的频率，而&lt;equation&gt;\lambda_k&lt;/equation&gt;可以对一些情况进行惩罚，比如，人可能在桌子旁边，但是在桌子下面的可能性就更小一些。所以这个量可以学习不同情况出现的概率。而原来的距离&lt;equation&gt;d(i,j)&lt;/equation&gt;只定义了两个像素间的关系，作者在这儿加入了个triple penalty，即还引入了&lt;equation&gt;j&lt;/equation&gt;附近的&lt;equation&gt;z&lt;/equation&gt;，这样描述三方关系便于得到更充足的局部上下文。具体结构如下： &lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/fff5f41eacdcf624556b6ce0f069600d.jpg" data-rawwidth="641" data-rawheight="307"&gt;&lt;p&gt;这个结构的&lt;b&gt;优点&lt;/b&gt;在于： &lt;/p&gt;&lt;ul&gt;&lt;li&gt;将平均场构造成了CNN &lt;/li&gt;&lt;li&gt;联合训练并且可以one-pass inference，而不用迭代&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;高斯条件随机场(G-CRF) &lt;/b&gt;&lt;/p&gt;&lt;p&gt;这个结构使用CNN分别来学习一元势函数和二元势函数。这样的结构是我们更喜欢的： &lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/920bc48dd3702825b71b0cde4b1f9e5a.jpg" data-rawwidth="1132" data-rawheight="595"&gt;&lt;p&gt;而此中的能量函数又不同于之前： &lt;/p&gt;&lt;equation&gt;E(\mathbf{x})=\frac{1}{2}\mathbf{x}^T(\mathbf{A+\lambda I)x}-\mathbf{Bx}&lt;/equation&gt;&lt;p&gt;而当&lt;equation&gt;(\mathbf{A+\lambda I)}&lt;/equation&gt;是对称正定时，求&lt;equation&gt;E(\mathbf{x})&lt;/equation&gt;的最小值等于求解： &lt;/p&gt;&lt;equation&gt;(\mathbf{A+\lambda I)x}=\mathbf{B}&lt;/equation&gt;&lt;p&gt;而G-CRF的优点在于：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;二次能量有明确全局 &lt;/li&gt;&lt;li&gt;解线性简便很多 &lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;感悟 &lt;/h2&gt;&lt;ul&gt;&lt;li&gt;FCN更像一种技巧。随着基本网络（如VGG， ResNet）性能的提升而不断进步。 &lt;/li&gt;&lt;li&gt;深度学习+概率图模型（PGM）是一种趋势。其实DL说白了就是进行特征提取，而PGM能够从数学理论很好的解释事物本质间的联系。 &lt;/li&gt;&lt;li&gt;概率图模型的网络化。因为PGM通常不太方便加入DL的模型中，将PGM网络化后能够是PGM参数自学习，同时构成end-to-end的系统。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;


完结撒花&lt;/p&gt;&lt;h2&gt;引用 &lt;/h2&gt;&lt;p&gt;[1]&lt;a href="https://people.eecs.berkeley.edu/~jonlong/long_shelhamer_fcn.pdf" data-editable="true" data-title="Fully Convolutional Networks for Semantic Segmentation" class=""&gt;Fully Convolutional Networks for Semantic Segmentation&lt;/a&gt;&lt;/p&gt;&lt;p&gt;[2]&lt;a href="http://arxiv.org/abs/1505.04366)%20%5B3%5D%5BSegNet%5D(http://arxiv.org/abs/1511.00561?context=cs" data-title="Learning Deconvolution Network for Semantic Segmentation" class="" data-editable="true"&gt;Learning Deconvolution Network for Semantic Segmentation&lt;/a&gt;&lt;/p&gt;&lt;p&gt;[3]&lt;a href="http://papers.nips.cc/paper/4296-efficient-inference-in-fully-connected-crfs-with-gaussian-edge-potentials.pdf" data-editable="true" data-title="Efficient Inference in Fully Connected CRFs with Gaussian Edge Potentials"&gt;Efficient Inference in Fully Connected CRFs with Gaussian Edge Potentials&lt;/a&gt;&lt;/p&gt;&lt;p&gt;[4]&lt;a href="http://arxiv.org/abs/1412.7062" data-title="Semantic Image Segmentation with Deep Convolutional Nets and Fully Connected CRFs" class="" data-editable="true"&gt;Semantic Image Segmentation with Deep Convolutional Nets and Fully Connected CRFs&lt;/a&gt;&lt;/p&gt;&lt;p&gt;[5]&lt;a href="http://www.robots.ox.ac.uk/~szheng/papers/CRFasRNN.pdf" data-title="Conditional Random Fields as Recurrent Neural Networks" class="" data-editable="true"&gt;Conditional Random Fields as Recurrent Neural Networks&lt;/a&gt;&lt;/p&gt;&lt;p&gt;[6]&lt;a href="http://liangchiehchen.com/projects/DeepLab.html" data-title="DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs" class="" data-editable="true"&gt;DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs&lt;/a&gt;&lt;/p&gt;&lt;p&gt;[7]&lt;a href="https://www.researchgate.net/publication/281670742_Semantic_Image_Segmentation_via_Deep_Parsing_Network" data-editable="true" data-title="Semantic Image Segmentation via Deep Parsing Network"&gt;Semantic Image Segmentation via Deep Parsing Network&lt;/a&gt;&lt;/p&gt;&lt;p&gt;[8]&lt;a href="http://arxiv.org/abs/1603.08358v1" data-title="Fast, Exact and Multi-Scale Inference for Semantic Image Segmentation with Deep Gaussian CRFs" class="" data-editable="true"&gt;Fast, Exact and Multi-Scale Inference for Semantic Image Segmentation with Deep Gaussian CRFs&lt;/a&gt;&lt;/p&gt;&lt;p&gt;[9]&lt;a href="http://arxiv.org/abs/1511.00561?context=cs" data-editable="true" data-title="SegNet"&gt;SegNet&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;转载须全文转载且注明作者和原文链接，否则保留维权权利&lt;/b&gt;&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/22308032&amp;pixel&amp;useReferer"/&gt;</description><author>困兽</author><pubDate>Sun, 04 Sep 2016 21:55:08 GMT</pubDate></item><item><title>[原创翻译]循环神经网络惊人的有效性（上）</title><link>https://zhuanlan.zhihu.com/p/22107715</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/68ada38c72be590e4d3da1fbc7a26b65_r.jpg"&gt;&lt;/p&gt;&lt;b&gt;版权声明：本文&lt;a href="https://zhuanlan.zhihu.com/intelligentunit" class="" data-editable="true" data-title="智能单元"&gt;智能单元&lt;/a&gt;首发，本人原创翻译，禁止未授权转载。 &lt;/b&gt;&lt;blockquote&gt;&lt;b&gt;译者注：&lt;/b&gt;经知友推荐，将&lt;a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/" data-title="The Unreasonable Effectiveness of Recurrent Neural Networks" class="" data-editable="true"&gt;The Unreasonable Effectiveness of Recurrent Neural Networks&lt;/a&gt;一文翻译作为CS231n课程无RNN和LSTM笔记的补充，感谢&lt;a href="https://www.zhihu.com/people/e7fcc05b0cf8a90a3e676d0206f888c9" data-hash="e7fcc05b0cf8a90a3e676d0206f888c9" class="member_mention" data-editable="true" data-title="@堃堃" data-hovercard="p$b$e7fcc05b0cf8a90a3e676d0206f888c9"&gt;@堃堃&lt;/a&gt;的校对。&lt;/blockquote&gt;&lt;h2&gt;目录&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;循环神经网络&lt;/li&gt;&lt;li&gt;字母级别的语言模型&lt;/li&gt;&lt;li&gt;RNN的乐趣&lt;/li&gt;&lt;ul&gt;&lt;li&gt;Paul Graham生成器&lt;/li&gt;&lt;li&gt;莎士比亚&lt;/li&gt;&lt;li&gt;维基百科&lt;/li&gt;&lt;li&gt;几何代数&lt;/li&gt;&lt;li&gt;Linux源码&lt;/li&gt;&lt;li&gt;生成婴儿姓名 &lt;i&gt;&lt;b&gt;译者注：上篇截止处&lt;/b&gt;&lt;/i&gt;&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;理解训练过程&lt;/li&gt;&lt;ul&gt;&lt;li&gt;训练时输出文本的进化&lt;/li&gt;&lt;li&gt;RNN中的预测与神经元激活可视化&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;源代码&lt;/li&gt;&lt;li&gt;拓展阅读&lt;/li&gt;&lt;li&gt;结论&lt;/li&gt;&lt;li&gt;译者反馈&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;原文如下&lt;/h2&gt;&lt;p&gt;循环神经网络（RNN）简直像是魔法一样不可思议。我为&lt;a href="http://cs.stanford.edu/people/karpathy/deepimagesent/" data-editable="true" data-title="图像标注"&gt;图像标注&lt;/a&gt;项目训练第一个循环网络时的情景到现在都还历历在目。当时才对第一个练手模型训练了十几分钟（超参数还都是随手设置的），它就开始生成一些对于图像的描述，描述内容看起来很不错，几乎让人感到语句是通顺的了。有时候你会遇到模型简单，结果的质量却远高预期的情况，这就是其中一次。当时这个结果让我非常惊讶是因为我本以为RNN是非常难以训练的（随着实践的增多，我的结论基本与之相反了）。让我们快进一年：即使现在我成天都在训练RNN，也常常看到它们的能力和鲁棒性，有时候它们那充满魔性的输出还是能够把我给逗乐。这篇博文就是来和你分享RNN中的一些魔法。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;我们将训练RNN，让它们生成一个又一个字母。同时好好思考这个问题：这怎么可能呢？&lt;/p&gt;&lt;/blockquote&gt;顺便说一句，和这篇博文一起，我在Github上发布了一个项目。项目基于多层的LSTM，使得你可以训练字母级别的语言模型。你可以输入一大段文本，然后它能学习并按照一次一个字母的方式生成文本。你也可以用它来复现我下面的实验。但是现在我们要超前一点：RNN到底是什么？&lt;h2&gt;循环神经网络&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;序列&lt;/strong&gt;。基于知识背景，你可能会思考：&lt;em&gt;是什么让RNN如此独特呢？&lt;/em&gt;普通神经网络和卷积神经网络的一个显而易见的局限就是他们的API都过于限制：他们接收一个固定尺寸的向量作为输入（比如一张图像），并且产生一个固定尺寸的向量作为输出（比如针对不同分类的概率）。不仅如此，这些模型甚至对于上述映射的演算操作的步骤也是固定的（比如模型中的层数）。RNN之所以如此让人兴奋，其核心原因在于其允许我们对向量的序列进行操作：输入可以是序列，输出也可以是序列，在最一般化的情况下输入输出都可以是序列。下面是一些直观的例子：&lt;/p&gt;&lt;p&gt;————————————————————————————————————————&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/2a37bd4e9b12bcc19e045eaf22fea4e5.jpg" data-rawwidth="1329" data-rawheight="416"&gt;&lt;p&gt;上图中每个正方形代表一个向量，箭头代表函数（比如矩阵乘法）。输入向量是红色，输出向量是蓝色，绿色向量装的是RNN的状态（马上具体介绍）。从左至右为：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;非RNN的普通过程，从固定尺寸的输入到固定尺寸的输出（比如图像分类）。&lt;/li&gt;&lt;li&gt;输出是序列（例如图像标注：输入是一张图像，输出是单词的序列）。&lt;/li&gt;&lt;li&gt;输入是序列（例如情绪分析：输入是一个句子，输出是对句子属于正面还是负面情绪的分类）。&lt;/li&gt;&lt;li&gt;输入输出都是序列（比如机器翻译：RNN输入一个英文句子输出一个法文句子）。&lt;/li&gt;&lt;li&gt;同步的输入输出序列（比如视频分类中，我们将对视频的每一帧都打标签）。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;注意在每个案例中都没有对序列的长度做出预先规定，这是因为循环变换（绿色部分）是固定的，我们想用几次就用几次。&lt;/p&gt;&lt;p&gt;————————————————————————————————————————&lt;/p&gt;&lt;p&gt;如你期望的那样，相较于那些从一开始连计算步骤的都定下的固定网络，序列体制的操作要强大得多。并且对于那些和我们一样希望构建一个更加智能的系统的人来说，这样的网络也更有吸引力。我们后面还会看到，RNN将其输入向量、状态向量和一个固定（可学习的）函数结合起来生成一个新的状态向量。在程序的语境中，这可以理解为运行一个具有某些输入和内部变量的固定程序。从这个角度看，RNN本质上就是在描述程序。实际上RNN是具备&lt;a href="http://binds.cs.umass.edu/papers/1995_Siegelmann_Science.pdf" data-editable="true" data-title="图灵完备性"&gt;图灵完备性&lt;/a&gt;的，只要有合适的权重，它们可以模拟任意的程序。然而就像神经网络的通用近似理论一样，你不用过于关注其中细节。实际上，我建议你忘了我刚才说过的话。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;如果训练普通神经网络是对函数做最优化，那么训练循环网络就是针对程序做最优化。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;strong&gt;无序列也能进行序列化处理&lt;/strong&gt;。你可能会想，将序列作为输入或输出的情况是相对少见的，但是需要认识到的重要一点是：即使输入或输出是固定尺寸的向量，依然可以使用这个强大的形式体系以序列化的方式对它们进行处理。例如，下图来自于&lt;a href="http://deepmind.com/" data-editable="true" data-title="DeepMind"&gt;DeepMind&lt;/a&gt;的两篇非常不错的论文。左侧动图显示的是一个算法学习到了一个循环网络的策略，该策略能够引导它对图像进行观察；更具体一些，就是它学会了如何从左往右地阅读建筑的门牌号（&lt;a href="http://arxiv.org/abs/1412.7755" data-editable="true" data-title="Ba et al"&gt;Ba et al&lt;/a&gt;）。右边动图显示的是一个循环网络通过学习序列化地向画布上添加颜色，生成了写有数字的图片（&lt;a href="http://arxiv.org/abs/1502.04623" data-editable="true" data-title="Gregor et al"&gt;Gregor et al&lt;/a&gt;）。&lt;/p&gt;&lt;p&gt;—————————————————————————————————————————&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/45a48feeee79755aa02789f4bf437e77.png" data-rawwidth="1274" data-rawheight="828"&gt;左边：RNN学会如何阅读建筑物门牌号。右边：RNN学会绘出建筑门牌号。 &lt;em&gt;译者注：知乎专栏不支持动图，建议感兴趣读者前往原文查看。&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;————————————————————————————————————————&lt;/em&gt;&lt;/p&gt;&lt;p&gt;必须理解到的一点就是：即使数据不是序列的形式，仍然可以构建并训练出能够进行序列化处理数据的强大模型。换句话说，你是要让模型学习到一个处理固定尺寸数据的分阶段程序。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;RNN的计算&lt;/strong&gt;。那么RNN到底是如何工作的呢？在其核心，RNN有一个貌似简单的API：它接收输入向量&lt;strong&gt;x&lt;/strong&gt;，返回输出向量&lt;strong&gt;y&lt;/strong&gt;。然而这个输出向量的内容不仅被输入数据影响，而且会收到整个历史输入的影响。写成一个类的话，RNN的API只包含了一个&lt;strong&gt;step&lt;/strong&gt;方法：&lt;/p&gt;&lt;pre&gt;&lt;code lang="python"&gt;rnn = RNN()
y = rnn.step(x) # x is an input vector, y is the RNN's output vector
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;每当&lt;strong&gt;step&lt;/strong&gt;方法被调用的时候，RNN的内部状态就被更新。在最简单情况下，该内部装着仅包含一个内部&lt;em&gt;隐向量&lt;/em&gt;&lt;i&gt;&lt;b&gt;h&lt;/b&gt;&lt;/i&gt;。下面是一个普通RNN的step方法的实现：&lt;/p&gt;&lt;pre&gt;&lt;code lang="python"&gt;class RNN:
  # ...
  def step(self, x):
    # update the hidden state
    self.h = np.tanh(np.dot(self.W_hh, self.h) + np.dot(self.W_xh, x))
    # compute the output vector
    y = np.dot(self.W_hy, self.h)
    return y
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;上面的代码详细说明了普通RNN的前向传播。该RNN的参数是三个矩阵：&lt;strong&gt;W_hh, W_xh, W_hy&lt;/strong&gt;。隐藏状态&lt;strong&gt;self.h&lt;/strong&gt;被初始化为零向量。&lt;strong&gt;np.tanh&lt;/strong&gt;函数是一个非线性函数，将激活数据挤压到[-1,1]之内。注意代码是如何工作的：在tanh内有两个部分。一个是基于前一个隐藏状态，另一个是基于当前的输入。在numpy中，&lt;strong&gt;np.dot&lt;/strong&gt;是进行矩阵乘法。两个中间变量相加，其结果被tanh处理为一个新的状态向量。如果你更喜欢用数学公式理解，那么公式是这样的：&lt;equation&gt;h_t=tanh(W_{hh}h_{t-1}+W_{hx}x_t)&lt;/equation&gt;。其中tanh是逐元素进行操作的。&lt;/p&gt;&lt;p&gt;我们使用随机数字来初始化RNN的矩阵，进行大量的训练工作来寻找那些能够产生描述行为的矩阵，使用一些损失函数来衡量描述的行为，这些损失函数代表了根据输入&lt;strong&gt;x&lt;/strong&gt;，你对于某些输出&lt;strong&gt;y&lt;/strong&gt;的偏好。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;更深层网络&lt;/strong&gt;。RNN属于神经网络算法，如果你像叠薄饼一样开始对模型进行重叠来进行深度学习，那么算法的性能会单调上升（如果没出岔子的话）。例如，我们可以像下面代码一样构建一个2层的循环网络：&lt;/p&gt;&lt;pre&gt;&lt;code lang="python"&gt;y1 = rnn1.step(x)
y = rnn2.step(y1)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;换句话说，我们分别有两个RNN：一个RNN接受输入向量，第二个RNN以第一个RNN的输出作为其输入。其实就RNN本身来说，它们并不在乎谁是谁的输入：都是向量的进进出出，都是在反向传播时梯度通过每个模型。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;更好的网络&lt;/strong&gt;。需要简要指明的是在实践中通常使用的是一个稍有不同的算法，这就是我在前面提到过的&lt;em&gt;长短基记忆&lt;/em&gt;网络，简称LSTM。LSTM是循环网络的一种特别类型。由于其更加强大的更新方程和更好的动态反向传播机制，它在实践中效果要更好一些。本文不会进行细节介绍，但是在该算法中，所有本文介绍的关于RNN的内容都不会改变，唯一改变的是状态更新（就是&lt;strong&gt;self.h=...&lt;/strong&gt;那行代码）变得更加复杂。从这里开始，我会将术语RNN和LSTM混合使用，但是在本文中的所有实验都是用LSTM完成的。&lt;/p&gt;&lt;h2&gt;字母级别的语言模型&lt;/h2&gt;&lt;p&gt;现在我们已经理解了RNN是什么，它们何以令人兴奋，以及它们是如何工作的。现在通过一个有趣的应用来更深入地加以体会：我们将利用RNN训练一个字母级别的语言模型。也就是说，给RNN输入巨量的文本，然后让其建模并根据一个序列中的前一个字母，给出下一个字母的概率分布。这样就使得我们能够一个字母一个字母地生成新文本了。&lt;/p&gt;&lt;p&gt;在下面的例子中，假设我们的字母表只由4个字母组成“helo”，然后利用训练序列“hello”训练RNN。该训练序列实际上是由4个训练样本组成：1.当h为上文时，下文字母选择的概率应该是e最高。2.l应该是he的下文。3.l应该是hel文本的下文。4.o应该是hell文本的下文。&lt;/p&gt;&lt;p&gt;具体来说，我们将会把每个字母编码进一个1到k的向量（除对应字母为1外其余为0），然后利用&lt;strong&gt;step&lt;/strong&gt;方法一次一个地将其输入给RNN。随后将观察到4维向量的序列（一个字母一个维度）。我们将这些输出向量理解为RNN关于序列下一个字母预测的信心程度。下面是流程图：&lt;/p&gt;&lt;p&gt;————————————————————————————————————————&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/20c6a56f097aba3de796ac62c59605bc.jpg" data-rawwidth="902" data-rawheight="725"&gt;一个RNN的例子：输入输出是4维的层，隐层神经元数量是3个。该流程图展示了使用hell作为输入时，RNN中激活数据前向传播的过程。输出层包含的是RNN关于下一个字母选择的置信度（字母表是helo）。我们希望绿色数字大，红色数字小。&lt;/p&gt;&lt;p&gt;——————————————————————————————————————————&lt;/p&gt;&lt;p&gt;举例如下：在第一步，RNN看到了字母h后，给出下一个字母的置信度分别是h为1，e为2.2，l为-3.0，o为4.1。因为在训练数据（字符串hello）中下一个正确的字母是e，所以我们希望提高它的置信度（绿色）并降低其他字母的置信度（红色）。类似的，在每一步都有一个目标字母，我们希望算法分配给该字母的置信度应该更大。因为RNN包含的整个操作都是可微分的，所以我们可以通过对算法进行反向传播（微积分中链式法则的递归使用）来求得权重调整的正确方向，在正确方向上可以提升正确目标字母的得分（绿色粗体数字）。然后进行&lt;em&gt;参数更新&lt;/em&gt;，即在该方向上轻微移动权重。如果我们将同样的数据输入给RNN，在参数更新后将会发现正确字母的得分（比如第一步中的e）将会变高（例如从2.2变成2.3），不正确字母的得分将会降低。重复进行一个过程很多次直到网络收敛，其预测与训练数据连贯一致，总是能正确预测下一个字母。&lt;/p&gt;&lt;p&gt;更技术派的解释是我们对输出向量同步使用标准的Softmax分类器（也叫作交叉熵损失）。使用小批量的随机梯度下降来训练RNN，使用&lt;a href="http://arxiv.org/abs/1502.04390" data-editable="true" data-title="RMSProp"&gt;RMSProp&lt;/a&gt;或Adam来让参数稳定更新。&lt;/p&gt;&lt;p&gt;注意当字母l第一次输入时，目标字母是l，但第二次的目标是o。因此RNN不能只靠输入数据，必须使用它的循环连接来保持对上下文的跟踪，以此来完成任务。&lt;/p&gt;&lt;p&gt;在&lt;strong&gt;测试&lt;/strong&gt;时，我们向RNN输入一个字母，得到其预测下一个字母的得分分布。我们根据这个分布取出得分最大的字母，然后将其输入给RNN以得到下一个字母。重复这个过程，我们就得到了文本！现在使用不同的数据集训练RNN，看看将会发生什么。&lt;/p&gt;&lt;p&gt;为了更好的进行介绍，我基于教学目的写了代码：&lt;a href="https://gist.github.com/karpathy/d4dee566867f8291f086" data-editable="true" data-title="minimal character-level RNN language model in Python/numpy"&gt;minimal character-level RNN language model in Python/numpy&lt;/a&gt;，它只有100多行。如果你更喜欢读代码，那么希望它能给你一个更简洁直观的印象。我们下面介绍实验结果，这些实验是用更高效的Lua/Torch代码实现的。&lt;/p&gt;&lt;h2&gt;RNN的乐趣&lt;/h2&gt;&lt;p&gt;下面介绍的5个字母模型我都放在Github上的&lt;a href="https://github.com/karpathy/char-rnn" data-editable="true" data-title="项目"&gt;项目&lt;/a&gt;里了。每个实验中的输入都是一个带有文本的文件，我们训练RNN让它能够预测序列中下一个字母。&lt;/p&gt;&lt;h3&gt;Paul Graham生成器&lt;/h3&gt;&lt;p&gt;译者注：中文名一般译为保罗•格雷厄姆，著有《黑客与画家》一书，中文版已面世。在康奈尔大学读完本科，在哈佛大学获得计算机科学博士学位。1995年，创办了Viaweb。1998年，Yahoo!收购了Viaweb，收购价约5000万美元。此后架起了个人网站paulgraham.com，在上面撰写关于软件和创业的文章，以深刻的见解和清晰的表达而著称。2005年，创建了风险投资公司Y Combinator，目前已经资助了80多家创业公司。现在，他是公认的互联网创业权威。&lt;/p&gt;&lt;p&gt;让我们先来试一个小的英文数据集来进行正确性检查。我最喜欢的数据集是&lt;a href="http://www.paulgraham.com/articles.html" data-editable="true" data-title="Paul Graham的文集"&gt;Paul Graham的文集&lt;/a&gt;。其基本思路是在这些文章中充满智慧，但Paul Graham的写作速度比较慢，要是能根据需求生成富于创业智慧的文章岂不美哉？那么就轮到RNN上场了。&lt;/p&gt;&lt;p&gt;将Paul Graham最近5年的文章收集起来，得到大小约1MB的文本文件，约有1百万个字符（这只算个很小的数据集）。&lt;em&gt;技术要点&lt;/em&gt;：训练一个2层的LSTM，各含512个隐节点（约350万个参数），每层之后使用0.5的dropout。每个数据批量中含100个样本，时间长度上截断了100个字符进行梯度的反向传播。按照上述设置，每个数据批量在TITAN GPU上的运算耗时为0.46秒（如果仅对50个字符进行BPTT，那么耗时会减半，性能的耗费几乎忽略不计）。&lt;em&gt;译者注：BPTT即Backpropagation Through Time&lt;/em&gt;。不在啰嗦，让我们看看RNN生成的文本：&lt;/p&gt;&lt;p&gt;&lt;em&gt;“The surprised in investors weren’t going to raise money. I’m not the company with the time there are all interesting quickly, don’t have to get off the same programmers. There’s a super-angel round fundraising, why do you can do. If you have a different physical investment are become in people who reduced in a startup with the way to argument the acquirer could see them just that you’re also the founders will part of users’ affords that and an alternation to the idea. [2] Don’t work at first member to see the way kids will seem in advance of a bad successful startup. And if you have to act the big company too.”&lt;/em&gt;&lt;/p&gt;&lt;p&gt;好吧，显然生成器暂时还无法替代Paul Graham，但是RNN可是完全从头开始学英语的（包括逗号，撇号和空格），而且数据集又如此的小。我还很喜欢它自己学会了如何进行引用（例如上文中的[2]）。有时候它甚至会说出一些充满智慧的洞见，比如“a company is a meeting to think to investors（公司就是一个琢磨如何让投资者打钱的会议）”。&lt;em&gt;译者注：RNN你瞎说什么大实话：）&lt;/em&gt;如果你想要查看更多细节，点击&lt;a href="http://cs.stanford.edu/people/karpathy/char-rnn/pg.txt" data-editable="true" data-title="这里"&gt;这里&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;温度&lt;/strong&gt;。在生成文本的时候，我们可以调节Softmax的温度。将温度从1降到更低的数值（比如0.5）可以让RNN更加自信的同时变得更加保守。相反，如果将温度设置的更高，结果会更加多样化，但是代价就是可能会出现错误（比如更多的拼写错误）。如果将温度设置得非常接近于0，我们就会得到最像Paul Graham说的话：&lt;/p&gt;&lt;p&gt;&lt;em&gt;“is that they were all the same thing that was a startup is that they were all the same thing that was a startup is that they were all the same thing that was a startup is that they were all the same”&lt;/em&gt;&lt;/p&gt;&lt;p&gt;看来我们陷入到连续创业的无限循环中去了。&lt;/p&gt;&lt;h2&gt;莎士比亚&lt;/h2&gt;&lt;p&gt;看起来我们可以让RNN学会如何拼写单词，但是数据中有更多的结构和样式呢？为了回答这个问题，我下载了莎士比亚的所有作品，并将它们装进一个单独的文件中，大小约4.4MB。我们现在可以训练更大的网络，这次试用的是一个3层的RNN，每层的隐节点512个。当我们训练了几个小时候，我们得到了下面的文本输出：&lt;/p&gt;&lt;pre&gt;&lt;code lang="pytb"&gt;PANDARUS:
Alas, I think he shall be come approached and the day
When little srain would be attain'd into being never fed,
And who is but a chain and subjects of his death,
I should not sleep.

Second Senator:
They are away this miseries, produced upon my soul,
Breaking and strongly should be buried, when I perish
The earth and thoughts of many states.

DUKE VINCENTIO:
Well, your wit is in the care of side and that.

Second Lord:
They would be ruled after this chamber, and
my fair nues begun out of the fact, to be conveyed,
Whose noble souls I'll have the heart of the wars.

Clown:
Come, sir, I will make did behold your worship.

VIOLA:
I'll drink it.
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;记住，RNN只知道字符，所以它学会了说话者的名字和说话内容的格式，有时候我们还会得到类似独白的文字，比如：&lt;/p&gt;&lt;pre&gt;&lt;code lang="python"&gt;VIOLA:
Why, Salisbury must find his flesh and thought
That which I am not aps, not a man and in fire,
To show the reining of the raven and the wars
To grace my hand reproach within, and not a fair are hand,
That Caesar and my goodly father's world;
When I was heaven of presence and our fleets,
We spare with hours, but cut thy council I am great,
Murdered and by thy master's ready there
My power to give thee but so much as hell:
Some service in the noble bondman here,
Would show him to her wine.

KING LEAR:
O, if you were a feeble sight, the courtesy of your law,
Your sight and several breath, will wear the gods
With his heads, and my hands are wonder'd at the deeds,
So drop upon your lordship's head, and your opinion
Shall be against your honour.
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;我个人是很难把这段话从莎士比亚的原作中分辨出来啦：）如果你喜欢莎士比亚，那可以来看看这篇&lt;a href="http://cs.stanford.edu/people/karpathy/char-rnn/shakespear.txt" data-editable="true" data-title="长达1000000字符的生成文本"&gt;长达1000000字符的生成文本&lt;/a&gt;。当然，你可以使用我提供的代码，在不同的温度设置下来生成不同的文本。&lt;/p&gt;&lt;h2&gt;维基百科&lt;/h2&gt;&lt;p&gt;我们看见LSTM能够拼写单词，复现语法结构。那么现在就提高难度，使用markdown文本对它进行训练。我使用了&lt;a href="http://prize.hutter1.net/" data-editable="true" data-title="Hutter Prize"&gt;Hutter Prize&lt;/a&gt;的100MB的数据集，数据集内容是原始的维基百科内容，然后在LSTM上训练。根据&lt;a href="http://arxiv.org/abs/1308.0850" data-editable="true" data-title="Graves等的论文"&gt;Graves等的论文&lt;/a&gt;，我使用了其中96MB用于训练，剩下的用做验证集。模型跑了有一晚上，然后可以生成维基百科文章了。下面是一些有趣的文本片段。首先，一些基本的markdown输出：&lt;/p&gt;&lt;pre&gt;&lt;code lang="pytb"&gt;Naturalism and decision for the majority of Arab countries' capitalide was grounded
by the Irish language by [[John Clair]], [[An Imperial Japanese Revolt]], associated 
with Guangzham's sovereignty. His generals were the powerful ruler of the Portugal 
in the [[Protestant Immineners]], which could be said to be directly in Cantonese 
Communication, which followed a ceremony and set inspired prison, training. The 
emperor travelled back to [[Antioch, Perth, October 25|21]] to note, the Kingdom 
of Costa Rica, unsuccessful fashioned the [[Thrales]], [[Cynth's Dajoard]], known 
in western [[Scotland]], near Italy to the conquest of India with the conflict. 
Copyright was the succession of independence in the slop of Syrian influence that 
was a famous German movement based on a more popular servicious, non-doctrinal 
and sexual power post. Many governments recognize the military housing of the 
[[Civil Liberalization and Infantry Resolution 265 National Party in Hungary]], 
that is sympathetic to be to the [[Punjab Resolution]]
(PJS)[http://www.humah.yahoo.com/guardian.
cfm/7754800786d17551963s89.htm Official economics Adjoint for the Nazism, Montgomery 
was swear to advance to the resources for those Socialism's rule, 
was starting to signing a major tripad of aid exile.]]
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;如果你注意到的话，yahoo的那个url是不存在的，是模型生造了它。还有，可以看见模型学会了对于圆括号要成对出现。模型还学会了很多markdown结构，比如标题，列表等：&lt;/p&gt;&lt;pre&gt;&lt;code lang="python"&gt;{ { cite journal | id=Cerling Nonforest Department|format=Newlymeslated|none } }
''www.e-complete''.

'''See also''': [[List of ethical consent processing]]

== See also ==
*[[Iender dome of the ED]]
*[[Anti-autism]]

===[[Religion|Religion]]===
*[[French Writings]]
*[[Maria]]
*[[Revelation]]
*[[Mount Agamul]]

== External links==
* [http://www.biblegateway.nih.gov/entrepre/ Website of the World Festival. The labour of India-county defeats at the Ripper of California Road.]

==External links==
* [http://www.romanology.com/ Constitution of the Netherlands and Hispanic Competition for Bilabial and Commonwealth Industry (Republican Constitution of the Extent of the Netherlands)]
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;有时候模型也会生成一些随机但是合法的XML：&lt;/p&gt;&lt;pre&gt;&lt;code lang="html"&gt;&amp;lt;page&amp;gt;
  &amp;lt;title&amp;gt;Antichrist&amp;lt;/title&amp;gt;
  &amp;lt;id&amp;gt;865&amp;lt;/id&amp;gt;
  &amp;lt;revision&amp;gt;
    &amp;lt;id&amp;gt;15900676&amp;lt;/id&amp;gt;
    &amp;lt;timestamp&amp;gt;2002-08-03T18:14:12Z&amp;lt;/timestamp&amp;gt;
    &amp;lt;contributor&amp;gt;
      &amp;lt;username&amp;gt;Paris&amp;lt;/username&amp;gt;
      &amp;lt;id&amp;gt;23&amp;lt;/id&amp;gt;
    &amp;lt;/contributor&amp;gt;
    &amp;lt;minor /&amp;gt;
    &amp;lt;comment&amp;gt;Automated conversion&amp;lt;/comment&amp;gt;
    &amp;lt;text xml:space="preserve"&amp;gt;#REDIRECT [[Christianity]]&amp;lt;/text&amp;gt;
  &amp;lt;/revision&amp;gt;
&amp;lt;/page&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;模型生成了时间戳，id和其他一些东西。同时模型也能正确地让标示符成对出现，嵌套规则也合乎逻辑。如果你对文本感兴趣，点击&lt;a href="http://cs.stanford.edu/people/karpathy/char-rnn/wiki.txt" data-editable="true" data-title="这里"&gt;这里&lt;/a&gt;。&lt;/p&gt;&lt;h2&gt;代数几何&lt;/h2&gt;&lt;p&gt;上面的结果表明模型确实比较擅长学习复杂的语法结构。收到这些结果的鼓舞，我和同伴&lt;a href="http://cs.stanford.edu/people/jcjohns/" data-editable="true" data-title="Justin Johnson"&gt;Justin Johnson&lt;/a&gt;决定在结构化这一块将研究更加推进一步。我们在网站Stacks上找到了这本关于代数几何的&lt;a href="http://stacks.math.columbia.edu/" data-editable="true" data-title="书"&gt;书&lt;/a&gt;，下载了latex源文件（16MB大小），然后用于训练一个多层的LSTM。令人惊喜的是，模型输出的结果几乎是可以编译的。我们手动解决了一些问题后，就得到了一个看起来像模像样的数学文档，看起来非常惊人：&lt;/p&gt;&lt;p&gt;————————————————————————————————————————&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/47e8530542991e18bdacb7c395d80b94.jpg" data-rawwidth="1343" data-rawheight="755"&gt;&lt;p&gt;生成的代数几何。这里是&lt;a href="http://cs.stanford.edu/people/jcjohns/fake-math/4.pdf" data-editable="true" data-title="源文件"&gt;源文件&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;——————————————————————————————————————————&lt;/p&gt;&lt;p&gt;这是另一个例子：&lt;/p&gt;&lt;p&gt;——————————————————————————————————————————&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/14a67f3357d9f178e711b1c6f9e2ae32.jpg" data-rawwidth="1323" data-rawheight="748"&gt;&lt;p&gt;更像代数几何了，右边还出现了图表。&lt;/p&gt;&lt;p&gt;——————————————————————————————————————————&lt;/p&gt;&lt;p&gt;由上可见，模型有时候尝试生成latex图表，但是没有成功。我个人还很喜欢它跳过证明的部分（“Proof omitted”，在顶部左边）。当然，需要注意的是latex是相对困难的结构化语法格式，我自己都还没有完全掌握呢。下面是模型生成的一个源文件：&lt;/p&gt;&lt;pre&gt;&lt;code lang="python"&gt;\begin{proof}
We may assume that $\mathcal{I}$ is an abelian sheaf on $\mathcal{C}$.
\item Given a morphism $\Delta : \mathcal{F} \to \mathcal{I}$
is an injective and let $\mathfrak q$ be an abelian sheaf on $X$.
Let $\mathcal{F}$ be a fibered complex. Let $\mathcal{F}$ be a category.
\begin{enumerate}
\item \hyperref[setain-construction-phantom]{Lemma}
\label{lemma-characterize-quasi-finite}
Let $\mathcal{F}$ be an abelian quasi-coherent sheaf on $\mathcal{C}$.
Let $\mathcal{F}$ be a coherent $\mathcal{O}_X$-module. Then
$\mathcal{F}$ is an abelian catenary over $\mathcal{C}$.
\item The following are equivalent
\begin{enumerate}
\item $\mathcal{F}$ is an $\mathcal{O}_X$-module.
\end{lemma}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这份模型输出的文本展示了一些常见错误。比如模型起了&lt;strong&gt;\begin{proof}&lt;/strong&gt;的头，结尾却是&lt;strong&gt;\end{lemma}&lt;/strong&gt;。这种错误我们就必须手动改正，错误产生的原因可能在于依赖关系过于长了：当模型完成证明后，它已经忘了自己的开头是proof还是lemma了。类似的，模型起了&lt;strong&gt;\begin{enumerate}&lt;/strong&gt;的头，却忘了结尾。我们观察到，在使用更大规模或更好的模型后，这些错误变少了。然而，以上这些错误总是存在出现的可能性的。&lt;/p&gt;&lt;h2&gt;Linux源码&lt;/h2&gt;&lt;p&gt;我想要把结构化数据的实验推到极限，所以最后一个实验我们决定使用代码。具体说来，就是从Linux在Github上的&lt;a href="https://github.com/torvalds/linux" data-editable="true" data-title="项目"&gt;项目&lt;/a&gt;提取了所有代码和能找到的头文件，把他们装进一个巨大的文件中（474MB的C代码）。我原本计划是只训练Linux的核心文件的，但是其大小只有约16MB。然后我在GPU上使用3层LSTM训练了好几天。这些模型有大约1000万的参数，这对于RNN模型来说还不算多的。实验结果超级有趣：&lt;/p&gt;&lt;pre&gt;&lt;code lang="c"&gt;/*
 * Increment the size file of the new incorrect UI_FILTER group information
 * of the size generatively.
 */
static int indicate_policy(void)
{
  int error;
  if (fd == MARN_EPT) {
    /*
     * The kernel blank will coeld it to userspace.
     */
    if (ss-&amp;gt;segment &amp;lt; mem_total)
      unblock_graph_and_set_blocked();
    else
      ret = 1;
    goto bail;
  }
  segaddr = in_SB(in.addr);
  selector = seg / 16;
  setup_works = true;
  for (i = 0; i &amp;lt; blocks; i++) {
    seq = buf[i++];
    bpf = bd-&amp;gt;bd.next + i * search;
    if (fd) {
      current = blocked;
    }
  }
  rw-&amp;gt;name = "Getjbbregs";
  bprm_self_clearl(&amp;amp;iv-&amp;gt;version);
  regs-&amp;gt;new = blocks[(BPF_STATS &amp;lt;&amp;lt; info-&amp;gt;historidac)] | PFMR_CLOBATHINC_SECONDS &amp;lt;&amp;lt; 12;
  return segtable;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这些代码看起来相当酷了。虽然我不认为这些代码能够编译，但是看着这些代码你会感觉是一个巨大的C代码库。注意RNN还不时的给自己的代码加上了注释。代码中也很少有语法错误。比如它合理地使用了字符串，指针标记等。它学会了让花括号和中括号成对出现，让代码有正确的缩进。一个常见的错误是它不能追中变量的名字：它常常使用未声明的变量（比如上面的&lt;strong&gt;rw&lt;/strong&gt;），或声明一些永不使用的变量（比如上面的&lt;strong&gt;int error&lt;/strong&gt;），或返回不存在的变量。让我们看看更多的例子，下面是一个代码片段，展示了RNN学习到的更多的操作：&lt;/p&gt;&lt;pre&gt;&lt;code lang="c"&gt;/*
 * If this error is set, we will need anything right after that BSD.
 */
static void action_new_function(struct s_stat_info *wb)
{
  unsigned long flags;
  int lel_idx_bit = e-&amp;gt;edd, *sys &amp;amp; ~((unsigned long) *FIRST_COMPAT);
  buf[0] = 0xFFFFFFFF &amp;amp; (bit &amp;lt;&amp;lt; 4);
  min(inc, slist-&amp;gt;bytes);
  printk(KERN_WARNING "Memory allocated %02x/%02x, "
    "original MLL instead\n"),
    min(min(multi_run - s-&amp;gt;len, max) * num_data_in),
    frame_pos, sz + first_seg);
  div_u64_w(val, inb_p);
  spin_unlock(&amp;amp;disk-&amp;gt;queue_lock);
  mutex_unlock(&amp;amp;s-&amp;gt;sock-&amp;gt;mutex);
  mutex_unlock(&amp;amp;func-&amp;gt;mutex);
  return disassemble(info-&amp;gt;pending_bh);
}

static void num_serial_settings(struct tty_struct *tty)
{
  if (tty == tty)
    disable_single_st_p(dev);
  pci_disable_spool(port);
  return 0;
}

static void do_command(struct seq_file *m, void *v)
{
  int column = 32 &amp;lt;&amp;lt; (cmd[2] &amp;amp; 0x80);
  if (state)
    cmd = (int)(int_state ^ (in_8(&amp;amp;ch-&amp;gt;ch_flags) &amp;amp; Cmd) ? 2 : 1);
  else
    seq = 1;
  for (i = 0; i &amp;lt; 16; i++) {
    if (k &amp;amp; (1 &amp;lt;&amp;lt; 1))
      pipe = (in_use &amp;amp; UMXTHREAD_UNCCA) +
        ((count &amp;amp; 0x00000000fffffff8) &amp;amp; 0x000000f) &amp;lt;&amp;lt; 8;
    if (count == 0)
      sub(pid, ppc_md.kexec_handle, 0x20000000);
    pipe_set_bytes(i, 0);
  }
  /* Free our user pages pointer to place camera if all dash */
  subsystem_info = &amp;amp;of_changes[PAGE_SIZE];
  rek_controls(offset, idx, &amp;amp;soffset);
  /* Now we want to deliberately put it to device */
  control_check_polarity(&amp;amp;context, val, 0);
  for (i = 0; i &amp;lt; COUNTER; i++)
    seq_puts(s, "policy ");
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;注意在第二个函数中，比较了&lt;strong&gt;tty == tty&lt;/strong&gt;，这永远为真。但这次至少参数名出现在了函数体中。在最后一个函数中，没有返回值，因为函数的声明有void，所以倒也正确。 然而，前面两个函数声明为void确有返回值，这又是一种因为依赖过长产生的常见错误。&lt;/p&gt;&lt;p&gt;有时候模型决定生成新的文件。这通常是非常让人惊喜的部分：模型首先引用了GUN许可，进行了一些导入操作，生成一些宏，然后开始进入代码：&lt;/p&gt;&lt;pre&gt;&lt;code lang="c"&gt;/*
 *  Copyright (c) 2006-2010, Intel Mobile Communications.  All rights reserved.
 *
 *   This program is free software; you can redistribute it and/or modify it
 * under the terms of the GNU General Public License version 2 as published by
 * the Free Software Foundation.
 *
 *        This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 *   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 *
 *  GNU General Public License for more details.
 *
 *   You should have received a copy of the GNU General Public License
 *    along with this program; if not, write to the Free Software Foundation,
 *  Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
 */

#include &amp;lt;linux/kexec.h&amp;gt;
#include &amp;lt;linux/errno.h&amp;gt;
#include &amp;lt;linux/io.h&amp;gt;
#include &amp;lt;linux/platform_device.h&amp;gt;
#include &amp;lt;linux/multi.h&amp;gt;
#include &amp;lt;linux/ckevent.h&amp;gt;

#include &amp;lt;asm/io.h&amp;gt;
#include &amp;lt;asm/prom.h&amp;gt;
#include &amp;lt;asm/e820.h&amp;gt;
#include &amp;lt;asm/system_info.h&amp;gt;
#include &amp;lt;asm/setew.h&amp;gt;
#include &amp;lt;asm/pgproto.h&amp;gt;

#define REG_PG    vesa_slot_addr_pack
#define PFM_NOCOMP  AFSR(0, load)
#define STACK_DDR(type)     (func)

#define SWAP_ALLOCATE(nr)     (e)
#define emulate_sigs()  arch_get_unaligned_child()
#define access_rw(TST)  asm volatile("movd %%esp, %0, %3" : : "r" (0));   \
  if (__type &amp;amp; DO_READ)

static void stat_PC_SEC __read_mostly offsetof(struct seq_argsqueue, \
          pC&amp;gt;[1]);

static void
os_prefix(unsigned long sys)
{
#ifdef CONFIG_PREEMPT
  PUT_PARAM_RAID(2, sel) = get_state_state();
  set_pid_sum((unsigned long)state, current_state_str(),
           (unsigned long)-1-&amp;gt;lr_full; low;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这里面有太多有趣的地方可以讨论，我几乎可以写一整个博客，所以我现在还是暂停，感兴趣的可以查看&lt;a href="http://cs.stanford.edu/people/karpathy/char-rnn/linux.txt" data-editable="true" data-title="这里"&gt;这里&lt;/a&gt;。&lt;/p&gt;&lt;h2&gt;生成婴儿姓名&lt;/h2&gt;&lt;p&gt;让我们再试一个。给RNN输入一个包含8000个小孩儿姓名的文本文件，一行只有一个名字。（名字是从&lt;a href="http://www.cs.cmu.edu/afs/cs/project/ai-repository/ai/areas/nlp/corpora/names/" data-editable="true" data-title="这里"&gt;这里&lt;/a&gt;获得的）我们可以把这些输入RNN然后生成新的名字。下面是一些名字例子，只展示了那些没有在训练集中出现过的名字：&lt;/p&gt;&lt;p&gt;&lt;em&gt;Rudi Levette Berice Lussa Hany Mareanne Chrestina Carissy Marylen Hammine Janye Marlise Jacacrie Hendred Romand Charienna Nenotto Ette Dorane Wallen Marly Darine Salina Elvyn Ersia Maralena Minoria Ellia Charmin Antley Nerille Chelon Walmor Evena Jeryly Stachon Charisa Allisa Anatha Cathanie Geetra Alexie Jerin Cassen Herbett Cossie Velen Daurenge Robester Shermond Terisa Licia Roselen Ferine Jayn Lusine Charyanne Sales Sanny Resa Wallon Martine Merus Jelen Candica Wallin Tel Rachene Tarine Ozila Ketia Shanne Arnande Karella Roselina Alessia Chasty Deland Berther Geamar Jackein Mellisand Sagdy Nenc Lessie Rasemy Guen Gavi Milea Anneda Margoris Janin Rodelin Zeanna Elyne Janah Ferzina Susta Pey Castina&lt;/em&gt;&lt;/p&gt;&lt;p&gt;点击&lt;a href="http://cs.stanford.edu/people/karpathy/namesGenUnique.txt" data-editable="true" data-title="这里"&gt;这里&lt;/a&gt;可以查看更多。我个人最喜欢的名字包括“Baby” (哈)， “Killie”，“Char”，“R”，“More”，“Mars”，“Hi”，“Saddie”，“With”和“Ahbort”。这真的蛮有意思，你还可以畅想在写小说或者给创业公司起名字的时候，这个能给你灵感。&lt;/p&gt;&lt;p&gt;&lt;b&gt;上篇截止&lt;/b&gt;。&lt;/p&gt;&lt;h2&gt;译者反馈&lt;/h2&gt;&lt;ol&gt;&lt;li&gt;翻译不到位的地方，欢迎知友们评论批评指正；&lt;/li&gt;&lt;li&gt;在计算机视觉方面，个人对于&lt;b&gt;图像标注（image caption）&lt;/b&gt;比较感兴趣，正在入坑。欢迎有同样兴趣的知友投稿讨论；&lt;/li&gt;&lt;li&gt;感谢&lt;a href="https://www.zhihu.com/people/157deec64cc5e062b2207aeece42f50f" data-hash="157deec64cc5e062b2207aeece42f50f" class="member_mention" data-hovercard="p$b$157deec64cc5e062b2207aeece42f50f"&gt;@七月&lt;/a&gt;和&lt;a href="https://www.zhihu.com/people/39ed720d0b87cdc8c5dbe25618c51646" data-hash="39ed720d0b87cdc8c5dbe25618c51646" class="member_mention" data-hovercard="p$b$39ed720d0b87cdc8c5dbe25618c51646"&gt;@陈子服&lt;/a&gt; 的细节指正。&lt;/li&gt;&lt;/ol&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/22107715&amp;pixel&amp;useReferer"/&gt;</description><author>杜客</author><pubDate>Tue, 06 Sep 2016 20:31:35 GMT</pubDate></item><item><title>Andrej Karpathy的回信和Quora活动邀请</title><link>https://zhuanlan.zhihu.com/p/22282421</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/1b4d5e3761721c42438fbee54ccc8696_r.jpg"&gt;&lt;/p&gt;大家好：&lt;p&gt;关注我们CS231n翻译项目的知友应该知道，之所以开始这个翻译，也是因为得到了&lt;a href="http://cs.stanford.edu/people/karpathy/" class="" data-editable="true" data-title="Andrej Karpathy"&gt;Andrej Karpathy&lt;/a&gt;的授权。&lt;/p&gt;&lt;p&gt;这次翻译项目完结邮件了他，顺便问他有没有什么对学习CS231n的小伙伴们说的？邮件部分截取如下：&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/b3b88f5c66a44a82ec7ee541cc3aad2f.png" data-rawwidth="1590" data-rawheight="819"&gt;AK表示其实也没啥好说的，非常高兴能够分享这些知识，请&lt;b&gt;好好利用它来让这个世界变得更美好！&lt;/b&gt;最后表示感谢。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Session活动邀请&lt;/b&gt;：&lt;b&gt;下周四（9月8日）AK会在Quora上做一个类似知乎live的Session&lt;/b&gt;，貌似是基于文字的问答活动。活动地址&lt;a href="https://www.quora.com/session/Andrej-Karpathy/1" data-title="在这里" class=""&gt;在这里&lt;/a&gt;。感兴趣的同学可以去&lt;b&gt;提提问，捧捧场&lt;/b&gt;。这里也是义务为他做推广，因为我非常&lt;b&gt;佩服他坚持高质量分享知识的行为&lt;/b&gt;。&lt;/p&gt;&lt;p&gt;注：Andrej Karpathy的个人情况点&lt;a href="http://cs.stanford.edu/people/karpathy/"&gt;这里&lt;/a&gt;。&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/22282421&amp;pixel&amp;useReferer"/&gt;</description><author>杜客</author><pubDate>Sun, 04 Sep 2016 22:36:10 GMT</pubDate></item><item><title>知行合一码作业，深度学习真入门</title><link>https://zhuanlan.zhihu.com/p/22232836</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/6e060188cc1571a89456af45670d51a9_r.jpg"&gt;&lt;/p&gt;&lt;b&gt;版权声明：文章为本人在&lt;a href="https://zhuanlan.zhihu.com/intelligentunit" class="" data-editable="true" data-title="智能单元"&gt;智能单元&lt;/a&gt;专栏原创首发，禁止未授权转载。&lt;/b&gt;&lt;h2&gt;前言&lt;/h2&gt;&lt;p&gt;这是一篇号召深度学习爱好者&lt;b&gt;共同学习、讨论和完成&lt;/b&gt;斯坦福深度学习课程&lt;b&gt;CS231n的3个编程大作业&lt;/b&gt;的召集令。&lt;/p&gt;&lt;p&gt;在过去的3个多月中，我们翻译完成了CS231n的官方课程笔记并汇总在《&lt;a href="https://zhuanlan.zhihu.com/p/21930884?refer=intelligentunit" data-editable="true" data-title="CS231n官方笔记授权翻译总集篇发布" class=""&gt;CS231n官方笔记授权翻译总集篇发布&lt;/a&gt;》一文中，得到了大家的支持。期间也有不少同学私信各种和编程作业相关的问题，这说明还是有不少的想要入门深度学习的同学希望通过完成编程作业来加深自己对于课程知识内容的理解。&lt;/p&gt;&lt;p&gt;同时很多同学也始终在私信是否有交流群，我也反复回答自己并没有建交流群。个人始终认为交流应该是“&lt;b&gt;慎思而明辨之&lt;/b&gt;”，学习主静，需要&lt;b&gt;沉下心来看课程、笔记和论文，完整地啃完一部分内容后，再和人交流，这样的交流才是有质量的，对人对己都有益&lt;/b&gt;。而这样有质量的交流，最好是写文章来互动。为了促进互动，我在“&lt;b&gt;学习互动&lt;/b&gt;”部分提出了一些思路。&lt;/p&gt;&lt;h2&gt;动机&lt;/h2&gt;&lt;p&gt;&lt;b&gt;为什么&lt;/b&gt;要完成这3个编程作业？&lt;/p&gt;&lt;blockquote&gt;&lt;b&gt;行之明觉精察处便是知，知之真切笃实处便是行。&lt;/b&gt;——王阳明&lt;/blockquote&gt;&lt;p&gt;对于想要深度学习入门的同学来说，CS231n的编程作业能够引导学习者&lt;b&gt;由浅入深地在实践中理解深度学习中常用的算法模型，训练与调参方法和常用的技巧套路&lt;/b&gt;等。&lt;/p&gt;&lt;p&gt;相较于直接阅读各大开源框架源码来学习，个人认为通过完成作业来入门有以下几个好处：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;难度循序渐进&lt;/b&gt;。小作业设置是从线性分类模型实现开始，到神经网络模型，再到循环神经网络模型。而基于Jupyter Notebook的作业脚本单个小作业中，也是将一个小作业切分成很多块，让学习者逐个顺序实现。&lt;/li&gt;&lt;li&gt;&lt;b&gt;实现实验并重&lt;/b&gt;。每个小作业就是一个实验：你需要初始化设置，读取数据集，然后实现算法模型，检查模型是否实现正确，训练模型，调参，最后分析评价算法性能。在这个过程中，你既要聚焦在核心的函数实现，又会跟着作业安排的顺序来完成实验，掌握算法实验的套路。&lt;/li&gt;&lt;li&gt;&lt;b&gt;细节设置平衡&lt;/b&gt;。作业使用Python语言，基于Numpy库来实现。一些常用的基础函数功能课程已经实现，学习者只需要聚焦实现最核心的函数，且不会陷入到特别底层的细节。这样就在工程实践与概念理解中得到了一个平衡。&lt;/li&gt;&lt;li&gt;&lt;b&gt;应用丰富有趣&lt;/b&gt;。目前相当热门的Prisma所使用的图像风格化，谷歌的DeepDream，以及图像标注等应用都在作业中有原型实现。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;作业概述&lt;/h2&gt;&lt;p&gt;CS231n一共有3个大作业，作业简介我们已经翻译并发布：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/21441838?refer=intelligentunit" data-editable="true" data-title="斯坦福CS231n课程作业# 1简介 - 智能单元 - 知乎专栏" class=""&gt;斯坦福CS231n课程作业# 1简介 - 智能单元 - 知乎专栏&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/21941485?refer=intelligentunit" class="" data-editable="true" data-title="斯坦福CS231n课程作业# 2简介 - 智能单元 - 知乎专栏"&gt;斯坦福CS231n课程作业# 2简介 - 智能单元 - 知乎专栏&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/21946525?refer=intelligentunit" class="" data-editable="true" data-title="斯坦福CS231n课程作业# 3简介 - 智能单元 - 知乎专栏"&gt;斯坦福CS231n课程作业# 3简介 - 智能单元 - 知乎专栏&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;只需要&lt;b&gt;按照简介中的指导&lt;/b&gt;下载作业代码（文中有链接），安装完配置环境（非常简单！），就可以愉快地开始做作业了。&lt;/p&gt;&lt;p&gt;对于入门的同学来说，&lt;b&gt;作业的完成需要一些前置的知识学习，单就课程内资源来说&lt;/b&gt;：&lt;/p&gt;&lt;p&gt;Assignment #1中的5个小作业包含了&lt;b&gt;knn、SVM、Softmax、一个两层的神经网络和特征提取&lt;/b&gt;。你需要学习课程视频1-4课，阅读&lt;a href="https://zhuanlan.zhihu.com/p/20878530?refer=intelligentunit" class="" data-editable="true" data-title="Python Numpy教程"&gt;Python Numpy教程&lt;/a&gt;，&lt;a href="https://zhuanlan.zhihu.com/p/20894041?refer=intelligentunit" class="" data-editable="true" data-title="图像分类笔记（上）"&gt;图像分类笔记（上）&lt;/a&gt;&lt;a href="https://zhuanlan.zhihu.com/p/20900216?refer=intelligentunit" class="" data-editable="true" data-title="（下）"&gt;（下）&lt;/a&gt;，线性分类笔记&lt;a href="https://zhuanlan.zhihu.com/p/20918580?refer=intelligentunit" class="" data-editable="true" data-title="（上）"&gt;（上）&lt;/a&gt;&lt;a href="https://zhuanlan.zhihu.com/p/20945670?refer=intelligentunit" class="" data-editable="true" data-title="（中）"&gt;（中）&lt;/a&gt;&lt;a href="https://zhuanlan.zhihu.com/p/21102293?refer=intelligentunit" class="" data-editable="true" data-title="（下）"&gt;（下）&lt;/a&gt;，最优化笔记&lt;a href="https://zhuanlan.zhihu.com/p/21360434?refer=intelligentunit" class="" data-editable="true" data-title="（上）"&gt;（上）&lt;/a&gt;&lt;a href="https://zhuanlan.zhihu.com/p/21387326?refer=intelligentunit" class="" data-editable="true" data-title="（下）"&gt;（下）&lt;/a&gt;，以及&lt;a href="https://zhuanlan.zhihu.com/p/21407711?refer=intelligentunit" class="" data-editable="true" data-title="反向传播笔记"&gt;反向传播笔记&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;Assignment #2中的4个小作业包含了&lt;b&gt;全连接神经网络，卷及神经网络和一些最新的优化方法&lt;/b&gt;，你需要学习课程视频5-9课，阅读神经网络笔记1&lt;a href="https://zhuanlan.zhihu.com/p/21462488?refer=intelligentunit" class="" data-editable="true" data-title="（上）"&gt;（上）&lt;/a&gt;&lt;a href="https://zhuanlan.zhihu.com/p/21513367?refer=intelligentunit" class="" data-editable="true" data-title="（下）"&gt;（下）&lt;/a&gt;，&lt;a href="https://zhuanlan.zhihu.com/p/21560667?refer=intelligentunit" class="" data-editable="true" data-title="神经网络笔记2"&gt;神经网络笔记2&lt;/a&gt;，神经网络笔记3&lt;a href="https://zhuanlan.zhihu.com/p/21741716?refer=intelligentunit" class="" data-editable="true" data-title="（上）"&gt;（上）&lt;/a&gt;&lt;a href="https://zhuanlan.zhihu.com/p/21798784?refer=intelligentunit" class="" data-editable="true" data-title="（下）"&gt;（下）&lt;/a&gt;，以及&lt;a href="https://zhuanlan.zhihu.com/p/22038289?refer=intelligentunit" class="" data-editable="true" data-title="卷积神经网络笔记"&gt;卷积神经网络笔记&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;Assignment #3中的4个小作业包含了&lt;b&gt;RNN，LSTM，图像标注模型，图像生成模型&lt;/b&gt;等，你需要学习课程视频10-11课。这部分课程没有给出笔记，后续我们可能寻找一些较好的内容加以翻译补充。&lt;/p&gt;&lt;h2&gt;学习互动&lt;/h2&gt;&lt;p&gt;&lt;b&gt;推进进度&lt;/b&gt;：3个大作业共包含13个小作业。我们用一个比较宽松的进度来推进，今年还有将近4个月的时间，那么我们&lt;b&gt;从9月5日开始起算&lt;/b&gt;，平均一个月完成3个左右的小作业。也就是说&lt;b&gt;每个小作业1-2周的时间学习、讨论并完成&lt;/b&gt;。从给我个人的经验来看，这个速度即使是对于零基础的同学，也是足够的啦。&lt;/p&gt;&lt;p&gt;&lt;b&gt;互动方式&lt;/b&gt;：我们会按照小作业顺序发布完成作业所做的理论学习，具体实现解读文章。同样，&lt;b&gt;任何愿意按照上述进度进行作业学习的同学，都可以从自己对于理论的不同理解，核心函数不同的实现方式，遇到问题及解决问题的收获，对专栏进行投稿。而各种疑问，也可以在对应文章的评论中进行讨论&lt;/b&gt;。&lt;/p&gt;&lt;p&gt;&lt;b&gt;建不建群&lt;/b&gt;：我的个人意见是不太想建，因为自己精力有限，建了没办法良好管理与互动。但是大家也可以提意见，&lt;b&gt;如果大部分愿意一起学习的同学想要建一个群，同时有比较热心的同学能在群里面不时给大家介绍一下情况&lt;/b&gt;，那么还是可以考虑一下。ps：但是我可能基本是潜水。&lt;/p&gt;&lt;h2&gt;最后&lt;/h2&gt;&lt;p&gt;最近读曾国藩家书，看到一个有趣的学习方法：&lt;/p&gt;&lt;blockquote&gt;予定&lt;b&gt;刚日读经&lt;/b&gt;，&lt;b&gt;柔日读史&lt;/b&gt;之法。——曾国藩&lt;/blockquote&gt;&lt;p&gt;所谓刚日，是说人的情绪亢阳激越的日子。柔日，是指人情绪卑幽忧昧的日子。而经主常，史生变。所以咱在感觉能打10个的状态时，就要读一些经书，让我们能够平和沉静。在我们感觉比较低落忧郁的日子，就看看史书，从波澜壮阔的历史中激扬斗志。&lt;/p&gt;&lt;p&gt;具体到现在，我看可以修改为“&lt;b&gt;刚日写码，柔日知乎&lt;/b&gt;”。&lt;b&gt;状态好的日子&lt;/b&gt;就看论文写代码，发现自己的不足从而提升自己，储才养望。&lt;b&gt;状态一般创造力不强时&lt;/b&gt;，可以对已经完成的事情做一个总结，以书面的形式发出来，对自己工作的总结积累和与别人探讨，一总结发现自己之前还是有很多收获的，所以不用心情那么低落；&lt;/p&gt;&lt;p&gt;最后说一句，预定是9月5日开始，大家有什么意见请尽情提吧。&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/22232836&amp;pixel&amp;useReferer"/&gt;</description><author>杜客</author><pubDate>Wed, 31 Aug 2016 14:51:35 GMT</pubDate></item><item><title>最前沿：深度学习训练方法大革新，反向传播训练不再唯一</title><link>https://zhuanlan.zhihu.com/p/22143664</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/6f589df38509d14f839737645322a011_r.jpg"&gt;&lt;/p&gt;&lt;h2&gt;1 前言&lt;/h2&gt;&lt;p&gt;众所周知，在深度学习中我们使用反向传播算法进行训练。可能在任意一门深度学习课程中，反向传播都是必学的内容。我们使用反向传播计算每个参数的梯度，从而能够使用各种梯度下降方法SGD，Adam，RMSProp等来更新参数。基本上可以说反向传播算法是深度学习算法的基础。目前所有的深度学习应用，都基于反向传播算法进行训练。&lt;/p&gt;&lt;p&gt;但是，我们人类的大脑是这样学习的吗？&lt;/p&gt;&lt;p&gt;诚然现在的神经科学还无法告诉我们真正的答案，但我们凭我们的常识想想，我们大脑真正的神经网络会需要这样先前向传播一下，再反向传播一下然后更新神经元？这未免太不“科学”了。直观的想象我们大脑的神经元应该都是单独的个体，通过与周围的神经元交流来改变自己。但是对于反向传播算法，这种方法最大的缺点就是更新速度。前面的神经元需要等着后面的神经网络传回误差数据才能更新，要是以后搞个10000+层的神经网络，这显然就太慢了。所以，&lt;/p&gt;&lt;p&gt;能不能异步的更新参数？&lt;/p&gt;&lt;p&gt;甚至，每个参数能够同时更新？&lt;/p&gt;&lt;p&gt;或者差一点，只要前向传播一下就能更新参数？&lt;/p&gt;&lt;p&gt;这些问题要是能解决那就是game changing了。&lt;/p&gt;&lt;p&gt;那么现在DeepMind又开挂了，最新2016年8月18号出来的问题第一次解决了上面的问题。&lt;/p&gt;&lt;p&gt;文章题目：Decoupled Neural Interfaces using Synthetic Gradients &lt;/p&gt;&lt;p&gt;文章链接：&lt;a href="https://arxiv.org/pdf/1608.05343.pdf" data-editable="true" data-title="arxiv.org 的页面" class=""&gt;https://arxiv.org/pdf/1608.05343.pdf&lt;/a&gt; （本文图片都引用自文章）&lt;/p&gt;&lt;h2&gt;2 What is the idea?&lt;/h2&gt;&lt;p&gt;如果我们陷入在反向传播的思维中，我们就完全无法想象如果没有从后面传回来梯度误差，我们该怎么更新参数。DeepMind打破这种思路，如果不传回来，我们可以&lt;/p&gt;&lt;p&gt;&lt;b&gt;合成梯度！也就是Synthetic Gradients！&lt;/b&gt;&lt;/p&gt;&lt;p&gt;也就是我们可以预测梯度。如果我们预测得准确，那么就可以直接更新了。&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/6bd8df82a8791c6e437263668d21b4e4.png" data-rawwidth="1990" data-rawheight="752"&gt;看上图，一般的反向传播如图b所示，从后到前依次传递梯度（绿色的线），然后更新参数。那么这里，我们使用一个M来预测梯度（蓝色的线），然后更新参数。我们传给M当前层的输出，然后M返回给我们梯度。&lt;/p&gt;&lt;p&gt;那么怎么预测梯度？&lt;/p&gt;&lt;p&gt;&lt;b&gt;就用神经网络来预测！&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;也就是每一层的神经网络对应另一个神经网络M，每个M来调控每一层的神经网络更新！&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;这套方法称为 Decoupled Neural Interfaces(DNI), 也就是将神经网络分解训练的意思。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;那么不管是MLP，CNN还是RNN或者其他各种结构的神经网络，因为都是以层为单位，都可以使用神经网络来合成梯度，也就是都可以使用这样的方法来实现训练。&lt;/p&gt;&lt;h2&gt;3 合成梯度的M神经网络是如何训练的？&lt;/h2&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/7223b3b3fd0b96029c8044ade57b5f0d.png" data-rawwidth="1778" data-rawheight="702"&gt;合成梯度的M神经网络用来输出估计的梯度误差。那么要训练M就需要有一个梯度误差来做目标，但是这里没有完全的反向传播，如何得到真实的梯度误差？作者采用一个tradeoff，利用下一层神经网络的估计梯度误差来计算本层的梯度误差，并利用这个误差作为目标训练M。如上图所示，&lt;equation&gt;f_i&lt;/equation&gt;输出&lt;equation&gt;h_i&lt;/equation&gt;到&lt;equation&gt;M_{i+1}&lt;/equation&gt;，然后&lt;equation&gt;M_{i+1}&lt;/equation&gt;输出估计的梯度误差&lt;equation&gt;\hat{\delta_i}&lt;/equation&gt;，接下来利用&lt;equation&gt;\hat{\delta_i}&lt;/equation&gt;来更新&lt;equation&gt;f_i&lt;/equation&gt;的参数。接下来&lt;equation&gt;h_i&lt;/equation&gt;输入到下一层神经网络&lt;equation&gt;f_{i+1}&lt;/equation&gt;中，同理得到该层的估计梯度误差&lt;equation&gt;\hat{\delta}_{i+1}&lt;/equation&gt;，然后利用&lt;equation&gt;\hat{\delta}_{i+1}&lt;/equation&gt;通过&lt;equation&gt;\delta_i = f^`_{i+1}(h_i)\hat{\delta}_{i+1}&lt;/equation&gt;也就是i+1层的梯度乘以梯度误差从而得到i层的梯度误差&lt;equation&gt;\delta_i&lt;/equation&gt;,然后就可以使用&lt;equation&gt;\delta_i&lt;/equation&gt;更新M了。所以M神经网络的训练需要BP。&lt;/p&gt;&lt;h2&gt;4 看结果&lt;/h2&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/c9edd09e655b6baa1aaa49025b146992.png" data-rawwidth="1956" data-rawheight="876"&gt;上图是MNIST的训练，采用全连接网络FCN或者CNN进行训练。从结果上可以看到，DNI特别是cDNI（就是将数据的标签作为神经网络M的输入）效果蛮好的（略低于反向传播），但是训练速度比原来采用反向传播的快，特别看上面的曲线橙色部分，比灰色的反向传播快了非常多。&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/91fc6553e5d87aac17561dc550beffcb.png" data-rawwidth="2046" data-rawheight="774"&gt;上面这图是针对RNN的训练，一个是Repeat Copy复制任务，一个是语言模型的训练。因为RNN的梯度计算面临无穷的循环，所以一般采用一定的时间间隔来计算梯度。那么这里，DNI的效果远远超过了BPTT（Back Propagation Through Time). 速度两倍以上。&lt;/p&gt;&lt;p&gt;从上面的结果可以看出，采用DNI进行训练相比反向传播竟然速度快，效果好。要是预测梯度的神经网络能提前训练好，估计又能快不少吧！&lt;/p&gt;&lt;h2&gt;5 One More Thing&lt;/h2&gt;&lt;p&gt;DeepMind不仅仅做到不需要反向传播，甚至更进一步，连前向传播也不用，直接异步更新每一层的参数。怎么做的？&lt;/p&gt;&lt;p&gt;&lt;b&gt;不仅仅预测梯度，我们还预测输入！&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/8826d3fcd18e292a08ddb3b84202649a.png" data-rawwidth="1996" data-rawheight="566"&gt;上图的I是每一层的输入预测神经网络，用来预测上一层的输出。&lt;/p&gt;&lt;p&gt;这样做对于MNIST的训练也能达到2%的误差，只是慢了一点。估计主要的慢是在I和M的模型训练上。这里4层隐藏层就有6个额外的神经网络了。&lt;/p&gt;&lt;h2&gt;6 这个成果意味着什么？&lt;/h2&gt;&lt;p&gt;&lt;b&gt;神经网络模块化了&lt;/b&gt;&lt;/p&gt;&lt;p&gt;每一层网络都可以看成独立的一个模块，模块与模块之间相互通信，从而实现学习。而学习训练不再需要同步，可以异步。也就是说每个模块都可以独立训练。Paper中也做了异步训练的实验，可以随机的训练神经网络中的不同层，或者有两个神经网络需要相互配合的，都可以异步训练。这是这个成果最大的意义，将能够因此构建出完全不一样的神经网络模型，训练方式发生完全的改变。&lt;/p&gt;&lt;h2&gt;7 存在的问题&lt;/h2&gt;&lt;p&gt;大家都可以注意到，虽然这个idea能够使主神经网络不再使用反向传播算法，&lt;b&gt;但是I和M的神经网络都是依靠反向传播算法进行更新！也就是反而多了好多个小的神经网络。&lt;/b&gt;但是这个方法如果不考虑I和M（主要是M）的训练，那么显然将会非常的快。那么，I比较难，涉及到具体的输入，但是有没有可能能够预训练M呢？或者换一个角度思考，我们人类大脑的神经元是否是相互独立，每一个神经元都有自己的一套学习机制在里面，能够自主改变？这些很值得我们思考。&lt;/p&gt;&lt;h2&gt;8 一点感想&lt;/h2&gt;&lt;p&gt;因为神经网络什么都能学习，所以用神经网络来更新神经网络也不足为怪。之前的&lt;a href="https://zhuanlan.zhihu.com/p/21362413?refer=intelligentunit" class="" data-editable="true" data-title="最前沿：让计算机学会学习Let Computers Learn to Learn - 智能单元 - 知乎专栏"&gt;最前沿：让计算机学会学习Let Computers Learn to Learn - 智能单元 - 知乎专栏&lt;/a&gt;就是使用神经网络来做梯度更新的工作。这里是使用神经网络来合成梯度。所以，如果把上一篇的成果结合进来，神经网络大部分都是神经网络自己在训练了！&lt;/p&gt;&lt;blockquote&gt;&lt;b&gt;这是深度学习基本学习机制的大变革，一步一步迈向人类的大脑！&lt;/b&gt;&lt;/blockquote&gt;&lt;p&gt;补充：DeepMind官网给出了一个介绍DNI的博客：&lt;a href="https://deepmind.com/blog#decoupled-neural-interfaces-using-synthetic-gradients"&gt;https://deepmind.com/blog#decoupled-neural-interfaces-using-synthetic-gradients&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;版权声明：本文为原创文章，未经允许不得转载！&lt;/h2&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/22143664&amp;pixel&amp;useReferer"/&gt;</description><author>Flood Sung</author><pubDate>Sat, 27 Aug 2016 15:59:24 GMT</pubDate></item><item><title>贺完结！CS231n官方笔记授权翻译总集篇发布</title><link>https://zhuanlan.zhihu.com/p/21930884</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/0dee7274beed25bd4abbcd76cb7d9576_r.jpg"&gt;&lt;/p&gt;&lt;blockquote&gt;哈哈哈！我们也是不谦虚，几个“业余水平”的网友，怎么就“零星”地把这件事给搞完了呢！&lt;b&gt;总之就是非常开心&lt;/b&gt;，废话不多说，进入正题吧！&lt;/blockquote&gt;&lt;h2&gt;CS231n简介&lt;/h2&gt;&lt;p&gt;CS231n的全称是&lt;a href="http://vision.stanford.edu/teaching/cs231n/index.html" data-editable="true" data-title="CS231n: Convolutional Neural Networks for Visual Recognition" class=""&gt;CS231n: Convolutional Neural Networks for Visual Recognition&lt;/a&gt;，即&lt;b&gt;面向视觉识别的卷积神经网络&lt;/b&gt;。该课程是&lt;a href="http://vision.stanford.edu/index.html" data-editable="true" data-title="斯坦福大学计算机视觉实验室" class=""&gt;斯坦福大学计算机视觉实验室&lt;/a&gt;推出的课程。需要注意的是，目前大家说CS231n，大都指的是2016年冬季学期（一月到三月）的最新版本。&lt;/p&gt;&lt;p&gt;&lt;b&gt;课程描述&lt;/b&gt;：请允许我们引用课程主页上的&lt;b&gt;官方描述&lt;/b&gt;如下。&lt;/p&gt;&lt;blockquote&gt;计算机视觉在社会中已经逐渐普及，并广泛运用于搜索检索、图像理解、手机应用、地图导航、医疗制药、无人机和无人驾驶汽车等领域。而这些应用的核心技术就是图像分类、图像定位和图像探测等视觉识别任务。近期神经网络（也就是“深度学习”）方法上的进展极大地提升了这些代表当前发展水平的视觉识别系统的性能。本课程将深入讲解深度学习框架的细节问题，聚焦面向视觉识别任务（尤其是图像分类任务）的端到端学习模型。在10周的课程中，学生们将会学习如何实现、训练和调试他们自己的神经网络，并建立起对计算机视觉领域的前沿研究方向的细节理解。最终的作业将包括训练一个有几百万参数的卷积神经网络，并将其应用到最大的图像分类数据库（ImageNet）上。我们将会聚焦于教授如何确定图像识别问题，学习算法（比如反向传播算法），对网络的训练和精细调整（fine-tuning）中的工程实践技巧，指导学生动手完成课程作业和最终的课程项目。本课程的大部分背景知识和素材都来源于&lt;a href="http://image-net.org/challenges/LSVRC/2014/index" data-editable="true" data-title="ImageNet Challenge" class=""&gt;ImageNet Challenge&lt;/a&gt;竞赛。&lt;/blockquote&gt;&lt;p&gt;&lt;b&gt;课程内容&lt;/b&gt;：官方课程安排及资源获取请点击&lt;a href="http://vision.stanford.edu/teaching/cs231n/syllabus.html" data-editable="true" data-title="这里" class=""&gt;这里&lt;/a&gt;，课程视频请在Youtube上查看&lt;a href="https://www.youtube.com/channel/UCPk8m_r6fkUSYmvgCBwq-sw" class="" data-editable="true" data-title="Andrej Karpathy"&gt;Andrej Karpathy&lt;/a&gt;创建的&lt;a href="https://www.youtube.com/playlist?list=PLkt2uSq6rBVctENoVBg1TpCC7OQi31AlC" data-editable="true" data-title="播放列表" class=""&gt;播放列表&lt;/a&gt;，也可私信我们获取云盘视频资源。通过查看官方课程表，我们可以看到：CS231n课程资源主要由&lt;b&gt;授课视频与PPT&lt;/b&gt;，&lt;b&gt;授课知识详解笔记&lt;/b&gt;和&lt;b&gt;课程作业&lt;/b&gt;三部分组成。其中：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;授课视频15课&lt;/b&gt;。每节课时约1小时左右，每节课一份PPT。&lt;/li&gt;&lt;li&gt;&lt;b&gt;授课知识详解笔记共9份&lt;/b&gt;。光看课程视频是不够的，深入理解课程笔记才能比较扎实地学习到知识。&lt;/li&gt;&lt;li&gt;&lt;b&gt;课程作业3次&lt;/b&gt;。其中每次作业中又包含多个小作业，完成作业能确保对于课程关键知识的深入理解和实现。&lt;/li&gt;&lt;li&gt;&lt;b&gt;课程项目1个&lt;/b&gt;。这个更多是面向斯坦福的学生，组队实现课程项目。&lt;/li&gt;&lt;li&gt;&lt;b&gt;拓展阅读若干&lt;/b&gt;。课程推荐的拓展阅读大多是领域内的经典著作节选或论文，推荐想要深入学习的同学阅读。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;课程评价&lt;/b&gt;：我们觉得赞！很多人都觉得赞！当然也有人觉得不好。具体如何，大家搜搜CS231n在网络，在知乎上的评价不就好了嘛！&lt;b&gt;个人认为&lt;/b&gt;：入门深度学习的&lt;b&gt;一门良心课&lt;/b&gt;。&lt;b&gt;适合绝大多数&lt;/b&gt;想要学习深度学习知识的人。&lt;/p&gt;&lt;p&gt;&lt;b&gt;课程不足&lt;/b&gt;：课程后期从RCNN开始就没有课程笔记。&lt;/p&gt;&lt;h2&gt;课程学习方法&lt;/h2&gt;&lt;p&gt;三句话总结：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;看授课视频形成概念，发现个人感兴趣方向。&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;读课程笔记理解细节，夯实工程实现的基础。&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;码课程作业实现算法，积累实验技巧与经验。&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;引用一下学习金字塔的图，意思大家都懂的：&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/77465c8318e6c4d40df274b92602d83f.png" data-rawwidth="519" data-rawheight="423"&gt;&lt;h2&gt;我们的工作&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;完成了CS231n全部9篇课程知识详解笔记的翻译&lt;/b&gt;：&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;原文：&lt;a href="http://cs231n.github.io/python-numpy-tutorial" data-editable="true" data-title="[python/numpy tutorial]" class=""&gt;[python/numpy tutorial]&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;翻译：&lt;a href="https://zhuanlan.zhihu.com/p/20878530?refer=intelligentunit" data-editable="true" data-title="Python Numpy教程" class=""&gt;Python Numpy教程&lt;/a&gt;。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;我们将使用Python编程语言来完成本课程的所有作业。Python是一门伟大的通用编程语言，在一些常用库（numpy, scipy, matplotlib）的帮助下，它又会变成一个强大的科学计算环境。我们期望你们中大多数人对于Python语言和Numpy库比较熟悉，而对于没有Python经验的同学，这篇教程可以帮助你们快速了解Python编程环境和如何使用Python作为科学计算工具。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;原文：&lt;a href="http://cs231n.github.io/classification" data-editable="true" data-title="[image classification notes]" class=""&gt;[image classification notes]&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;翻译：&lt;a href="https://zhuanlan.zhihu.com/p/20894041?refer=intelligentunit" data-editable="true" data-title="图像分类笔记（上）" class=""&gt;图像分类笔记（上）&lt;/a&gt;&lt;a href="https://zhuanlan.zhihu.com/p/20900216?refer=intelligentunit" data-title="（下）" class="" data-editable="true"&gt;（下）&lt;/a&gt;。&lt;/p&gt;&lt;blockquote&gt;该笔记是一篇介绍性教程，面向非计算机视觉领域的同学。教程将向同学们介绍图像分类问题和数据驱动方法，内容列表：&lt;ul&gt;&lt;li&gt;图像分类、数据驱动方法和流程&lt;/li&gt;&lt;li&gt;Nearest Neighbor分类器&lt;/li&gt;&lt;ul&gt;&lt;li&gt;k-Nearest Neighbor &lt;i&gt;译者注：上篇翻译截止处&lt;/i&gt;&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;验证集、交叉验证集和超参数调参&lt;/li&gt;&lt;li&gt;Nearest Neighbor的优劣&lt;/li&gt;&lt;li&gt;小结&lt;/li&gt;&lt;li&gt;小结：应用kNN实践&lt;/li&gt;&lt;li&gt;拓展阅读&lt;/li&gt;&lt;/ul&gt;&lt;/blockquote&gt;&lt;p&gt;原文：&lt;a href="http://cs231n.github.io/linear-classify" data-editable="true" data-title="[linear classification notes]"&gt;[linear classification notes]&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;翻译：线性分类笔记&lt;a href="https://zhuanlan.zhihu.com/p/20918580?refer=intelligentunit" data-title="（上）" class="" data-editable="true"&gt;（上）&lt;/a&gt;&lt;a href="https://zhuanlan.zhihu.com/p/20945670?refer=intelligentunit" data-editable="true" data-title="（中）"&gt;（中）&lt;/a&gt;&lt;a href="https://zhuanlan.zhihu.com/p/21102293?refer=intelligentunit" data-editable="true" data-title="（下）"&gt;（下）&lt;/a&gt;。&lt;/p&gt;&lt;blockquote&gt;我们将要实现一种更强大的方法来解决图像分类问题，该方法可以自然地延伸到神经网络和卷积神经网络上。这种方法主要有两部分组成：一个是&lt;b&gt;评分函数（score function）&lt;/b&gt;，它是原始图像数据到类别分值的映射。另一个是&lt;b&gt;损失函数（loss function）&lt;/b&gt;，它是用来量化预测分类标签的得分与真实标签之间一致性的。该方法可转化为一个最优化问题，在最优化过程中，将通过更新评分函数的参数来最小化损失函数值。内容列表：&lt;ul&gt;&lt;li&gt;线性分类器简介&lt;/li&gt;&lt;li&gt;线性评分函数&lt;/li&gt;&lt;li&gt;阐明线性分类器 &lt;i&gt;译者注：上篇翻译截止处&lt;/i&gt;&lt;/li&gt;&lt;li&gt;损失函数&lt;/li&gt;&lt;ul&gt;&lt;li&gt;多类SVM&lt;/li&gt;&lt;li&gt;Softmax分类器&lt;/li&gt;&lt;li&gt;SVM和Softmax的比较&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;基于Web的可交互线性分类器原型&lt;/li&gt;&lt;li&gt;小结&lt;/li&gt;&lt;/ul&gt;&lt;/blockquote&gt;&lt;p&gt;原文：&lt;a href="http://cs231n.github.io/optimization-1" data-editable="true" data-title="[optimization notes]"&gt;[optimization notes]&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;翻译：最优化笔记&lt;a href="https://zhuanlan.zhihu.com/p/21360434?refer=intelligentunit" data-editable="true" data-title="（上）"&gt;（上）&lt;/a&gt;&lt;a href="https://zhuanlan.zhihu.com/p/21387326?refer=intelligentunit" data-editable="true" data-title="（下）" class=""&gt;（下）&lt;/a&gt;。&lt;/p&gt;&lt;blockquote&gt;该笔记介绍了图像分类任务的第三个关键部分：最优化。内容列表如下：&lt;ul&gt;&lt;li&gt;简介&lt;/li&gt;&lt;li&gt;损失函数可视化&lt;/li&gt;&lt;li&gt;最优化&lt;/li&gt;&lt;ul&gt;&lt;li&gt;策略#1：随机搜索&lt;/li&gt;&lt;li&gt;策略#2：随机局部搜索&lt;/li&gt;&lt;li&gt;策略#3：跟随梯度 &lt;i&gt;译者注：上篇截止处&lt;/i&gt;&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;梯度计算&lt;/li&gt;&lt;ul&gt;&lt;li&gt;使用有限差值进行数值计算&lt;/li&gt;&lt;li&gt;微分计算梯度&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;梯度下降&lt;/li&gt;&lt;li&gt;小结&lt;/li&gt;&lt;/ul&gt;&lt;/blockquote&gt;&lt;p&gt;原文：&lt;a href="http://cs231n.github.io/optimization-2" data-editable="true" data-title="[backprop notes]"&gt;[backprop notes]&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;翻译：&lt;a href="https://zhuanlan.zhihu.com/p/21407711?refer=intelligentunit" data-editable="true" data-title="反向传播笔记"&gt;反向传播笔记&lt;/a&gt;。&lt;/p&gt;&lt;blockquote&gt;该笔记本将帮助读者&lt;b&gt;对反向传播形成直观而专业的理解&lt;/b&gt;。反向传播是利用链式法则递归计算表达式的梯度的方法。理解反向传播过程及其精妙之处，对于理解、实现、设计和调试神经网络非常关键。内容里列表如下：&lt;ul&gt;&lt;li&gt;简介&lt;/li&gt;&lt;li&gt;简单表达式和理解梯度&lt;/li&gt;&lt;li&gt;复合表达式，链式法则，反向传播&lt;/li&gt;&lt;li&gt;直观理解反向传播&lt;/li&gt;&lt;li&gt;模块：Sigmoid例子&lt;/li&gt;&lt;li&gt;反向传播实践：分段计算&lt;/li&gt;&lt;li&gt;回传流中的模式&lt;/li&gt;&lt;li&gt;用户向量化操作的梯度&lt;/li&gt;&lt;li&gt;小结&lt;/li&gt;&lt;/ul&gt;&lt;/blockquote&gt;&lt;p&gt;原文：&lt;a href="http://cs231n.github.io/neural-networks-1/" data-editable="true" data-title="Neural Nets notes 1"&gt;Neural Nets notes 1&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;翻译：神经网络笔记1&lt;a href="https://zhuanlan.zhihu.com/p/21462488?refer=intelligentunit" data-editable="true" data-title="（上）"&gt;（上）&lt;/a&gt;&lt;a href="https://zhuanlan.zhihu.com/p/21513367?refer=intelligentunit" data-editable="true" data-title="（下）" class=""&gt;（下）&lt;/a&gt;。&lt;/p&gt;&lt;blockquote&gt;该笔记介绍了神经网络的建模与结构，内容列表如下：&lt;ul&gt;&lt;li&gt;不用大脑做类比的快速简介&lt;/li&gt;&lt;li&gt;单个神经元建模&lt;ul&gt;&lt;li&gt;生物动机和连接&lt;/li&gt;&lt;li&gt;作为线性分类器的单个神经元&lt;/li&gt;&lt;li&gt;常用的激活函数 &lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;神经网络结构&lt;ul&gt;&lt;li&gt;层组织&lt;/li&gt;&lt;li&gt;前向传播计算例子&lt;/li&gt;&lt;li&gt;表达能力&lt;/li&gt;&lt;li&gt;设置层的数量和尺寸&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;小节&lt;/li&gt;&lt;li&gt;参考文献&lt;/li&gt;&lt;/ul&gt;&lt;/blockquote&gt;&lt;p&gt;原文：&lt;a href="http://cs231n.github.io/neural-networks-2/" data-editable="true" data-title="Neural Nets notes 2"&gt;Neural Nets notes 2&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;翻译：&lt;a href="https://zhuanlan.zhihu.com/p/21560667?refer=intelligentunit" data-editable="true" data-title="神经网络笔记2"&gt;神经网络笔记2&lt;/a&gt;。&lt;/p&gt;&lt;blockquote&gt;该笔记介绍了数据的预处理，正则化和损失函数，内容列表如下：&lt;ul&gt;&lt;li&gt;设置数据和模型&lt;ul&gt;&lt;li&gt;数据预处理&lt;/li&gt;&lt;li&gt;权重初始化&lt;/li&gt;&lt;li&gt;批量归一化（Batch Normalization）&lt;/li&gt;&lt;li&gt;正则化（L2/L1/Maxnorm/Dropout）&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;损失函数&lt;/li&gt;&lt;li&gt;小结&lt;/li&gt;&lt;/ul&gt;&lt;/blockquote&gt;&lt;p&gt;原文：&lt;a href="http://cs231n.github.io/neural-networks-3/" data-editable="true" data-title="Neural Nets notes 3" class=""&gt;Neural Nets notes 3&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;翻译：神经网络笔记3&lt;a href="https://zhuanlan.zhihu.com/p/21741716?refer=intelligentunit" data-editable="true" data-title="（上）"&gt;（上）&lt;/a&gt;&lt;a href="https://zhuanlan.zhihu.com/p/21798784?refer=intelligentunit" data-editable="true" data-title="（下）"&gt;（下）&lt;/a&gt;。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;该笔记讲解了神经网络的动态部分，即神经网络学习参数和搜索最优超参数的过程。内容列表如下：&lt;/p&gt;&lt;li&gt;梯度检查&lt;/li&gt;&lt;li&gt;合理性（Sanity）检查&lt;/li&gt;&lt;li&gt;检查学习过程&lt;ul&gt;&lt;li&gt;损失函数&lt;/li&gt;&lt;li&gt;训练集与验证集准确率&lt;/li&gt;&lt;li&gt;权重：更新比例&lt;/li&gt;&lt;li&gt;每层的激活数据与梯度分布&lt;/li&gt;&lt;li&gt;可视化 &lt;i&gt;译者注：上篇翻译截止处&lt;/i&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;参数更新&lt;ul&gt;&lt;li&gt;一阶（随机梯度下降）方法，动量方法，Nesterov动量方法&lt;/li&gt;&lt;li&gt;学习率退火&lt;/li&gt;&lt;li&gt;二阶方法&lt;/li&gt;&lt;li&gt;逐参数适应学习率方法（Adagrad，RMSProp）&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;超参数调优&lt;/li&gt;&lt;li&gt;评价&lt;ul&gt;&lt;li&gt;模型集成&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;总结&lt;/li&gt;&lt;li&gt;拓展引用&lt;/li&gt;&lt;/blockquote&gt;&lt;p&gt;原文：&lt;a href="http://cs231n.github.io/convolutional-networks/" data-editable="true" data-title="ConvNet notes" class=""&gt;ConvNet notes&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;翻译：&lt;a href="https://zhuanlan.zhihu.com/p/22038289?refer=intelligentunit" data-editable="true" data-title="卷积神经网络笔记"&gt;卷积神经网络笔记&lt;/a&gt;。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;内容列表：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;结构概述&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;用来构建卷积神经网络的各种层&lt;/b&gt;&lt;ul&gt;&lt;li&gt;卷积层&lt;/li&gt;&lt;li&gt;汇聚层&lt;/li&gt;&lt;li&gt;归一化层&lt;/li&gt;&lt;li&gt;全连接层&lt;/li&gt;&lt;li&gt;将全连接层转化成卷积层&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;卷积神经网络的结构&lt;/b&gt;&lt;ul&gt;&lt;li&gt;层的排列规律&lt;/li&gt;&lt;li&gt;层的尺寸设置规律&lt;/li&gt;&lt;li&gt;案例学习（LeNet / AlexNet / ZFNet / GoogLeNet / VGGNet）&lt;/li&gt;&lt;li&gt;计算上的考量&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;拓展资源&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/blockquote&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;完成了3个课程作业页面的翻译&lt;/b&gt;：&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;原文：&lt;a href="http://cs231n.github.io/assignments2016/assignment1/" data-editable="true" data-title="[Assignment #1]" class=""&gt;[Assignment #1]&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;翻译：&lt;a href="https://zhuanlan.zhihu.com/p/21441838?refer=intelligentunit" data-editable="true" data-title="CS231n课程作业#1简介" class=""&gt;CS231n课程作业#1简介&lt;/a&gt;。&lt;/p&gt;&lt;blockquote&gt;作业内容：实现k-NN，SVM分类器，Softmax分类器和两层神经网络，实践一个简单的图像分类流程。&lt;/blockquote&gt;&lt;p&gt;原文：&lt;a href="http://cs231n.github.io/assignments2016/assignment2/" data-editable="true" data-title="[Assignment #2]"&gt;[Assignment #2]&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;翻译：&lt;a href="https://zhuanlan.zhihu.com/p/21941485?refer=intelligentunit" data-title="CS231n课程作业#2简介" class="" data-editable="true"&gt;CS231n课程作业#2简介&lt;/a&gt;。&lt;/p&gt;&lt;blockquote&gt;作业内容：练习编写反向传播代码，训练神经网络和卷积神经网络。&lt;/blockquote&gt;&lt;p&gt;原文：&lt;a href="http://cs231n.github.io/assignments2016/assignment3/" data-editable="true" data-title="[Assignment #3]" class=""&gt;[Assignment #3]&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;翻译：&lt;a href="https://zhuanlan.zhihu.com/p/21946525?refer=intelligentunit" data-editable="true" data-title="CS231n课程作业#3简介"&gt;CS231n课程作业#3简介&lt;/a&gt;。&lt;/p&gt;&lt;blockquote&gt;作业内容：实现循环网络，并将其应用于在微软的COCO数据库上进行图像标注。实现DeepDream等有趣应用。&lt;/blockquote&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;帮助知友&lt;a href="https://www.zhihu.com/people/313544833f1060900fcb4f6a75c9f6b6" data-hash="313544833f1060900fcb4f6a75c9f6b6" class="member_mention" data-title="@智靖远" data-editable="true" data-hovercard="p$b$313544833f1060900fcb4f6a75c9f6b6"&gt;@智靖远&lt;/a&gt;发起了在Youtube上合力翻译课程字幕的倡议&lt;/b&gt;：&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;原文：&lt;a href="https://zhuanlan.zhihu.com/p/21354230?refer=intelligentunit" data-title="知友智靖远关于CS231n课程字幕翻译的倡议" class="" data-editable="true"&gt;知友智靖远关于CS231n课程字幕翻译的倡议&lt;/a&gt;。当时，&lt;a href="https://www.zhihu.com/people/313544833f1060900fcb4f6a75c9f6b6" data-hash="313544833f1060900fcb4f6a75c9f6b6" class="member_mention" data-title="@智靖远" data-editable="true" data-hovercard="p$b$313544833f1060900fcb4f6a75c9f6b6"&gt;@智靖远&lt;/a&gt;已经贡献了他对第一课字幕的翻译，目前这个翻译项目仍在进行中，欢迎各位知友积极参与。具体操作方式在倡议原文中有，请大家点击查看。&lt;/p&gt;&lt;p&gt;有很多知友私信我们，询问为何不做字幕。现在统一答复：&lt;b&gt;请大家积极参加&lt;a href="https://www.zhihu.com/people/313544833f1060900fcb4f6a75c9f6b6" data-hash="313544833f1060900fcb4f6a75c9f6b6" class="member_mention" data-title="@智靖远" data-editable="true" data-hovercard="p$b$313544833f1060900fcb4f6a75c9f6b6"&gt;@智靖远&lt;/a&gt;的字幕翻译项目。&lt;/b&gt;他先进行的字幕贡献与翻译，我们&lt;b&gt;不能夺人之美&lt;/b&gt;。&lt;b&gt;后续，我们也会向该翻译项目进行贡献&lt;/b&gt;。&lt;/p&gt;&lt;h2&gt;翻译团队&lt;/h2&gt;&lt;p&gt;CS231n课程笔记的翻译，始于&lt;a href="https://www.zhihu.com/people/928affb05b0b70a2c12e109d63b6bae5" data-hash="928affb05b0b70a2c12e109d63b6bae5" class="member_mention" data-editable="true" data-title="@杜客" data-hovercard="p$b$928affb05b0b70a2c12e109d63b6bae5"&gt;@杜客&lt;/a&gt;在一次回答问题“&lt;a href="https://www.zhihu.com/question/41907061" data-editable="true" data-title="应该选择TensorFlow还是Theano？" class=""&gt;应该选择TensorFlow还是Theano？&lt;/a&gt;”中的机缘巧合，在&lt;a href="https://zhuanlan.zhihu.com/p/20870307?refer=intelligentunit" data-editable="true" data-title="取得了授权"&gt;取得了授权&lt;/a&gt;后申请了知乎专栏&lt;a href="https://zhuanlan.zhihu.com/intelligentunit" data-editable="true" data-title="智能单元 - 知乎专栏"&gt;智能单元 - 知乎专栏&lt;/a&gt;独自翻译。随着翻译的进行，更多的知友参与进来。他们是&lt;a href="https://www.zhihu.com/people/584f06e4ed2edc6007e4793179e7cdc1" data-hash="584f06e4ed2edc6007e4793179e7cdc1" class="member_mention" data-title="@ShiqingFan" data-editable="true" data-hovercard="p$b$584f06e4ed2edc6007e4793179e7cdc1"&gt;@ShiqingFan&lt;/a&gt;，@&lt;a href="https://www.zhihu.com/people/hmonkey" class="" data-editable="true" data-title="猴子"&gt;猴子&lt;/a&gt;，&lt;a href="https://www.zhihu.com/people/e7fcc05b0cf8a90a3e676d0206f888c9" data-hash="e7fcc05b0cf8a90a3e676d0206f888c9" class="member_mention" data-editable="true" data-title="@堃堃" data-hovercard="p$b$e7fcc05b0cf8a90a3e676d0206f888c9"&gt;@堃堃&lt;/a&gt;和&lt;a href="https://www.zhihu.com/people/f11e78650e8185db2b013af42fd9a481" data-hash="f11e78650e8185db2b013af42fd9a481" class="member_mention" data-editable="true" data-title="@李艺颖" data-hovercard="p$b$f11e78650e8185db2b013af42fd9a481"&gt;@李艺颖&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;&lt;b&gt;大家因为认同这件事而聚集在一起&lt;/b&gt;，牺牲了很多个人的时间来进行翻译，校对和润色。而翻译的质量，我们不愿意自我表扬，还是&lt;b&gt;请各位知友自行阅读评价&lt;/b&gt;吧。现在笔记翻译告一段落，下面是&lt;b&gt;团队成员的简短感言&lt;/b&gt;：&lt;/p&gt;&lt;p&gt;&lt;a href="https://www.zhihu.com/people/584f06e4ed2edc6007e4793179e7cdc1" data-hash="584f06e4ed2edc6007e4793179e7cdc1" class="member_mention" data-editable="true" data-title="@ShiqingFan" data-hovercard="p$b$584f06e4ed2edc6007e4793179e7cdc1"&gt;@ShiqingFan&lt;/a&gt; ：一个偶然的机会让自己加入到这个翻译小队伍里来。CS231n给予了我知识的源泉和思考的灵感，前期的翻译工作也督促自己快速了学习了这门课程。虽然科研方向是大数据与并行计算，不过因为同时对深度学习比较感兴趣，于是乎现在的工作与两者都紧密相连。Merci!&lt;/p&gt;&lt;p&gt;@&lt;a href="https://www.zhihu.com/people/hmonkey" class="" data-editable="true" data-title="猴子"&gt;猴子&lt;/a&gt;：在CS231n翻译小组工作的两个多月的时间非常难忘。我向杜客申请加入翻译小组的时候，才刚接触这门课不久，翻译和校对的工作让我对这门课的内容有了更深刻的理解。作为一个机器学习的初学者，我非常荣幸能和翻译小组一起工作并做一点贡献。希望以后能继续和翻译小组一起工作和学习。&lt;/p&gt;&lt;p&gt;&lt;a href="https://www.zhihu.com/people/e7fcc05b0cf8a90a3e676d0206f888c9" data-hash="e7fcc05b0cf8a90a3e676d0206f888c9" class="member_mention" data-editable="true" data-title="@堃堃" data-hovercard="p$b$e7fcc05b0cf8a90a3e676d0206f888c9"&gt;@堃堃&lt;/a&gt; ：感谢组内各位成员的辛勤付出，很幸运能够参与这份十分有意义的工作，希望自己的微小工作能够帮助到大家，谢谢！&lt;/p&gt;&lt;p&gt;&lt;a href="https://www.zhihu.com/people/f11e78650e8185db2b013af42fd9a481" data-hash="f11e78650e8185db2b013af42fd9a481" class="member_mention" data-editable="true" data-title="@李艺颖" data-hovercard="p$b$f11e78650e8185db2b013af42fd9a481"&gt;@李艺颖&lt;/a&gt; ：当你真正沉下心来要做一件事情的时候才是学习和提高最好的状态；当你有热情做事时，并不会觉得是在牺牲时间，因为那是有意义并能带给你成就感和充实感的；不需要太过刻意地在乎大牛的巨大光芒，你只需像傻瓜一样坚持下去就好了，也许回头一看，你已前进了很多。就像老杜说的，我们就是每一步慢慢走，怎么就“零星”地把这件事给搞完了呢？&lt;/p&gt;&lt;p&gt;&lt;a href="https://www.zhihu.com/people/928affb05b0b70a2c12e109d63b6bae5" data-hash="928affb05b0b70a2c12e109d63b6bae5" class="member_mention" data-editable="true" data-title="@杜客" data-hovercard="p$b$928affb05b0b70a2c12e109d63b6bae5"&gt;@杜客&lt;/a&gt; ：做了一点微小的工作，哈哈。&lt;/p&gt;&lt;h2&gt;未来工作&lt;/h2&gt;&lt;p&gt;目前通过大家的反馈，之后会有新的创作方向，会更多与大家互动，敬请期待吧！&lt;/p&gt;&lt;h2&gt;感谢&lt;/h2&gt;&lt;p&gt;感谢&lt;b&gt;所有给我们的翻译提出过批评指正的知友&lt;/b&gt;，每篇文章末尾处的译者反馈部分我们都列出了大家的具体指正与贡献；&lt;/p&gt;&lt;p&gt;感谢&lt;b&gt;所有给我们的翻译点赞的知友&lt;/b&gt;，你们的赞是我们的精神粮食；&lt;/p&gt;&lt;p&gt;感谢&lt;b&gt;给文章赞赏小钱钱的知友&lt;/b&gt;，谢谢老板们：）&lt;/p&gt;&lt;h2&gt;最后&lt;/h2&gt;&lt;p&gt;&lt;b&gt;恳请大家点赞和分享到其他社交网络上&lt;/b&gt;，让更多&lt;b&gt;想要入门与系统学习深度学习&lt;/b&gt;的小伙伴能够看到这篇总集。同时，也欢迎大家在来专栏分享你的知识，发现志同道合的朋友！&lt;/p&gt;&lt;p&gt;&lt;b&gt;这个世界需要更多的英雄！&lt;/b&gt;&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/21930884&amp;pixel&amp;useReferer"/&gt;</description><author>杜客</author><pubDate>Thu, 25 Aug 2016 15:47:00 GMT</pubDate></item></channel></rss>