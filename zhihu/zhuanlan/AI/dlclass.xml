<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>深度学习大讲堂 - 知乎专栏</title><link>https://zhuanlan.zhihu.com/dlclass</link><description>推送深度学习的最新消息，包括最新技术进展，使用以及活动</description><lastBuildDate>Fri, 02 Sep 2016 15:15:29 GMT</lastBuildDate><generator>Ricky</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>美国人文与科学院Poggio院士谈神经科学与人工智能</title><link>https://zhuanlan.zhihu.com/p/22282572</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/bc3055c293d2920aecdd51a79ddae84e_r.png"&gt;&lt;/p&gt;深度学习大讲堂致力于推送人工智能，深度学习方面的最新技术，产品以及活动。请关注我们的知乎专栏！&lt;p&gt;&lt;b&gt;摘要&lt;/b&gt;&lt;/p&gt;&lt;p&gt;CCAI2016大会期间，美国人文与科学院Poggio院士介绍了从脑启发的视觉认知模型H-max到深度学习的变迁，从宏观维度上阐述了神经科学与深度学习研究的紧密联系，并通过介绍CBMM的组织结构与研究目标，展望了神经科学与智能科学研究相互融合的未来。&lt;/p&gt;&lt;p&gt;&lt;b&gt;导读&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Tomaso A. Poggio教授任职于MIT麦戈文脑、计算机科学与人工智能实验室，同时他也是美国人文与科学院院士。Poggio院士长期从事脑认知科学方面的研究，他所带领的实验室认为不论从自然角度还是人工角度，学习一直都是解决智能问题的核心。学习是了解大脑运转规律的途径，进而才可能制造智能的机器。故此，该实验室采用多学科融合的方式研究大脑学习的相关问题。目前该实验室的研究重点为大脑运作机制以及如何把该原理结合统计学运用于数学和计算机科学。&lt;/p&gt;&lt;p&gt;本次CCAI2016大会，Poggio院士带来的报告题目是《The Science and The Engineering of Intelligence》，系统阐释了智能科学与智能工程的概念，并提出智能工程的发展依赖于智能科学基础研究的进步。同时他也介绍了MIT CBMM（the MIT Center of Brain, Minds and Machines）的研究目标——促进神经科学、计算机科学、机器学习多领域协同发展。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/7de3f9ec9afab6eb5468beabecd9ed10.jpg" data-rawwidth="300" data-rawheight="444"&gt;&lt;p&gt;图1. Poggio教授主页上的照片&lt;/p&gt;&lt;p&gt;&lt;b&gt;背景回顾：Hubel &amp;amp; Wiesel的发现&lt;/b&gt;&lt;/p&gt;&lt;p&gt;回顾历史，今天大红大紫的深度学习模型的神经科学鼻祖可以追溯到 Hubel和Wiesel 于1959年通过研究猫的视觉皮层感受野提出的视觉神经系统的层级结构模型 ，即从简单细胞到复杂细胞、超复杂细胞的层级信息处理结构。&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/88be9a86b8d92fa0cb2fc5835472d5ab.jpg" data-rawwidth="510" data-rawheight="169"&gt;Hubel和Wiesel的研究成果在1981年获得诺贝尔生理学或医学奖，获奖理由是“their discoveries concerning information processing in the visual system”, 即他们关于觉系统信息处理机制的发现。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/4b629927d28053a47c1176b37c6f98ac.jpg" data-rawwidth="748" data-rawheight="667"&gt;&lt;p&gt;图3. Hubel和Wiesel在1981年获得诺贝尔奖之后进行庆祝&lt;/p&gt;&lt;p&gt;&lt;b&gt;2 H-MAX与大脑&lt;/b&gt;&lt;/p&gt;&lt;p&gt;1999年，在LeCun发明LeNet之后的一年，人工神经网络的研究进入了第二次凛冽的寒冬。Poggio另辟蹊径，提出了大脑皮层中物体识别的层级模型H-max。简单来说，H-max是一个生物启发的计算机视觉模型，一定程度上受到了Hubel &amp;amp; Wiesel模型的启发。 H-max模型的一种实现是将简单细胞S1实现为Gabor滤波器，复杂细胞C1实现为Max-Pooling，组合特征细胞S2实现为加权和，复杂组合特征细胞C2实现为Max-Pooling。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/6d26ef45c3b668010dd2afe06dc943c0.png" data-rawwidth="642" data-rawheight="496"&gt;&lt;p&gt;图4. H-max模型示意图，摘自&lt;a href="http://maxlab.neuro.georgetown.edu/hmax.html"&gt;http://maxlab.neuro.georgetown.edu/hmax.html&lt;/a&gt;&lt;/p&gt;&lt;p&gt;实际上，H-max模型的层级结构与大脑中的视觉通路具有一定的相似性。在大脑中存在一个从视网膜到LGN（侧膝体）再到初级视觉皮层最后到高级功能区的一个视觉通路，如下图所示。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/51a8728f86ab9fa862211e2726481026.png" data-rawwidth="1202" data-rawheight="668"&gt;&lt;p&gt;图5. 大脑视觉通路图解，摘自北京大学黄铁军教授讲座PPT&lt;/p&gt;&lt;p&gt;在Poggio院士的讲座中，给出了一张利用大脑中的ventral stream（腹通路，被认为和视觉通路紧密相关）来解释H-max有效性的图示，见下图。需要指出的是，虽然从结构和功能上H-max都和大脑的视觉通路有很多相似性，但是简单的将H-max理解为模拟了大脑的视觉机制并不准确。大脑的结构和机制更加复杂，比如注意力机制、反馈机制、更复杂的神经元连接等，这些都是H-max模型未能建模的。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/0e728ac3399f3d47f5822891be582ecd.jpg" data-rawwidth="1280" data-rawheight="960"&gt;&lt;p&gt;图6. 借助大脑的Ventral Stream机制解释层级的前向视觉模型的有效性&lt;/p&gt;&lt;p&gt;&lt;b&gt;从Hubel-Wiesel的发现到深度学习&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Poggio院士在讲座中总结了从Hubel-Wiesel的发现到深度学习（主要是卷积网络）的发展历史。领域前辈的智慧在这一页PPT中熠熠发光。这里面代表性的工作有福岛邦彦的神经认知机Neocognitron，有LeCun的LeNet，Poggio的H-max，以及2011年Freeman和Simoncelli发表在Nature上的工作Metamers of the ventral stream等。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/584e54d24e81fef0ae3bb143e8962348.jpg" data-rawwidth="1280" data-rawheight="960"&gt;&lt;p&gt;图7. 从Hubel-Wiesel的发现到卷积网络&lt;/p&gt;&lt;p&gt;万变不离其宗，Poggio梳理出了视觉皮层、视觉模型与深度学习网络之间的共性：层级结构。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/d63994b194d95422ecc72a3fd7eb6852.jpg" data-rawwidth="1280" data-rawheight="960"&gt;&lt;p&gt;图8. 层级结构是H-max和深度学习的共同信仰&lt;/p&gt;&lt;p&gt;&lt;b&gt;CBMM的终极理想&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Poggio院士近年来的工作重心放在了CBMM （Center of Brain, Mind and Machine）研究中心。CBMM位于MIT，拥有堪称豪华的研究阵容，研究人员来自Caltech、NYU、MIT、Mobileye和Deepmind等知名研究机构。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/6e70b909c0d51c854c5e7773d7a1491c.jpg" data-rawwidth="1280" data-rawheight="960"&gt;&lt;p&gt;图9. 堪称豪华的CBMM研究团队&lt;/p&gt;&lt;p&gt;CBMM的主要使命是推动对智能的理解——理解大脑如何产生心智、大脑如何工作和如何构建智能机器。CBMM的主要目标是在理解智能的科学上取得进步从而更好的进行智能的工程化。Poggio院士的理想和信仰，坐落在神经科学与人工智能融合的王冠之上。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/5ad6f5721e6bd746b2667b644b481c27.jpg" data-rawwidth="1280" data-rawheight="960"&gt;&lt;p&gt;图10. CBMM打通神经科学与人工智能的终极理想&lt;/p&gt;&lt;p&gt;&lt;b&gt;致谢：&lt;/b&gt;本文作者在此感谢CSDN的赠票和优秀的会议组织，以及深度学习大讲堂的特邀记者邀约。此外，感谢中科院计算所博士生邬书哲对本文技术内容的修订。&lt;/p&gt;&lt;p&gt;&lt;b&gt;参考资料：&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;[1] &lt;/b&gt;&lt;a href="http://cbcl.mit.edu/people/poggio/poggio-new.htm" class=""&gt;http://cbcl.mit.edu/people/poggio/poggio-new.htm&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;[2] &lt;/b&gt;Riesenhuber, M. &amp;amp; Poggio, T. (1999). Hierarchical Models of Object Recognition in Cortex. Nature Neuroscience 2: 1019-1025.&lt;/p&gt;&lt;p&gt;&lt;b&gt;[3]&lt;/b&gt;&lt;a href="http://cbmm.mit.edu/" class=""&gt;http://cbmm.mit.edu/&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;该文章属于“深度学习大讲堂”原创，如需要转载，请联系&lt;a href="https://www.zhihu.com/people/guo-dan-qing" data-editable="true" data-title="@果果是枚开心果. " class=""&gt;@果果是枚开心果. &lt;/a&gt;&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;作者简介：&lt;/b&gt;&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/d48e3f42e09143f4aa45dabf5e65c761.jpg" data-rawwidth="123" data-rawheight="122"&gt;&lt;p&gt;&lt;b&gt;尚静，&lt;/b&gt;毕业于复旦大学金融工程专业，现任紫牛基金投资经理。90后野生动物一只，认知神经科学与人工智能学习者与爱好者，欢迎高智商理工生一起交流，请注明自身特质和兴趣点，微信号jingzi12300。&lt;/p&gt;&lt;p&gt;&lt;b&gt;原文链接：&lt;a href="http://mp.weixin.qq.com/s?__biz=MzI1NTE4NTUwOQ==&amp;amp;mid=2650325367&amp;amp;idx=1&amp;amp;sn=5995e48a6913112c61a823a75e1bed22&amp;amp;scene=0#wechat_redirect" data-editable="true" data-title="美国人文与科学院Poggio院士谈神经科学与人工智能"&gt;美国人文与科学院Poggio院士谈神经科学与人工智能&lt;/a&gt;&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;欢迎大家关注我们的微信公众号，搜索微信名称：深度学习大讲堂&lt;/b&gt;&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/a29f11daca9717751e639f2c3a3f8b93.jpg" data-rawwidth="346" data-rawheight="67"&gt;</description><author>程程</author><pubDate>Fri, 02 Sep 2016 15:00:05 GMT</pubDate></item><item><title>近期GAN的模型和理论发展</title><link>https://zhuanlan.zhihu.com/p/22265724</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/a07e88c3e83f8389f66a8dd9c5e85825_r.jpg"&gt;&lt;/p&gt;深度学习大讲堂致力于推送人工智能，深度学习方面的最新技术，产品以及活动。请关注我们的知乎专栏！&lt;p&gt;&lt;b&gt;摘要&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在过去一两年中，生成式模型 Generative Adversarial Networks（GAN）的新兴为生成式任务带来了不小的进展。尽管 GAN 在被提出时存在训练不稳定等诸多问题，但后来的研究者们分别从模型、训练技巧和理论等方面对它做了改进。本文旨在梳理这些相关工作。&lt;/p&gt;&lt;p&gt;尽管大部分时候，有监督学习比无监督的能获得更好的训练效果。但真实世界中，有监督学习需要的数据标注（label）是相对少的。所以研究者们从未放弃去探索更好的无监督学习策略，希望能从海量的无标注数据中学到对于这个真实世界的表示（representation）甚至知识，从而去更好地理解我们的真实世界。&lt;/p&gt;&lt;p&gt;评价无监督学习好坏的方式有很多，其中生成任务就是最直接的一个。只有当我们能生成/创造我们的真实世界，才能说明我们是完完全全理解了它。然而，生成任务所依赖的生成式模型（generative models）往往会遇到两大困难。首先是我们需要大量的先验知识去对真实世界进行建模，其中包括选择什么样的先验、什么样的分布等等。而建模的好坏直接影响着我们的生成模型的表现。另一个困难是，真实世界的数据往往很复杂，我们要用来拟合模型的计算量往往非常庞大，甚至难以承受。&lt;/p&gt;&lt;p&gt;而在过去一两年中，有一个让人兴奋的新模型，则很好地避开了这两大困难。这个模型叫做 Generative Adversarial Networks（GAN），由 [1] 提出。在原始的 GAN paper [1] 中，作者是用博弈论来阐释了 GAN 框架背后的思想。每一个 GAN 框架，都包含着一对模型 —— 一个生成模型（G）和一个判别模型（D）。因为 D 的存在，才使得 GAN 中的 G 不再需要对于真实数据的先验知识和复杂建模，也能学习去逼近真实数据，最终让其生成的数据达到以假乱真的地步 —— D 也无法分别 —— 从而 G 和 D 达到了某种纳什均衡。[1] 的作者曾在他们的 slides 中，给出过一个比喻：在 GAN 中，生成模型（G）和判别模型（D）是小偷与警察的关系。G 生成的数据，目标是要骗过身为警察的判别模型（D）。也就是说，G 作为小偷，要尽可能地提高自己的偷窃手段，而 D 作为警察也要尽可能地提高自己的业务水平防止被欺骗。所以，GAN 框架下的学习过程就变成了一种生成模型 （G） 和判别模型 （D） 之间的竞争过程 —— 随机从真实样本和由生成模型 （G） 生成出的 “假样本” 中取一个，让判别模型 （D） 去判断是否为真。所以，体现在公式上，就是下面这样一个 minmax 的形式。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/1018e170944090c4e00a4e619b4460df.jpg" data-rawwidth="643" data-rawheight="53"&gt;&lt;p&gt;然而，GAN 虽然不再需要预先建模，但这个优点同时也带来了一些麻烦。那就是尽管它用一个 noise z 作为先验，但生成模型如何利用这个 z，是无法控制的。也就是说，GAN 的学习模式太过于自由了，使得 GAN 的训练过程和训练结果很多时候都不太可控。为了稳定 GAN ，后来的研究者们分别从 heuristic 、 模型改进和理论分析的角度上提出了许多训练技巧和改进方法。&lt;/p&gt;&lt;p&gt;比如在原始 GAN 论文 [1] 中，每次学习参数的更新过程，被设为 D 更新 k 回， G 才更新 1 回，就是出于减少 G 的 “自由度” 的考虑。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/f86fa2f7d52336cb1ebc95ce4c2bb888.jpg" data-rawwidth="663" data-rawheight="382"&gt;&lt;p&gt;另一篇重量级的关于 GAN 训练技巧的研究的工作便是 Deep Convolutional Generative Adversarial Networks（DCGAN）[6] 。[6] 中总结了许多对于 GAN 这的网络结构设计和针对 CNN 这种网络的训练经验。比如，他们用 strided convolutional networks 替代传统 CNN 中的 pooling 层，从而将 GAN 中的生成模型 （G）变成了 fully differentiable 的，结果使得 GAN 的训练更加稳定和可控。&lt;/p&gt;&lt;p&gt;为了提高训练的稳定性，另一个很自然的角度就是改变学习方法。把纯无监督的 GAN 变成半监督或者有监督的。这便可以为 GAN 的训练加上一点点束缚，或者说加上一点点目标。[2] 中提出的 Conditional Generative Adversarial Nets （CGAN）便是十分直接的模型改变，在生成模型（G）和判别模型（D）的建模中均引入 conditional variable y，这个 y 就是数据的一种 label。也因此，CGAN 可以看做把无监督的 GAN 变成有监督的模型的一种改进。这个简单直接的改进被证明非常有效，并广泛用于后续的相关工作中。&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/3b6c35178f34a004368770cda3ea41cd.jpg" data-rawwidth="696" data-rawheight="363"&gt;第三种改进 GAN 过于自由的思路，和第一种会比较相似。既然太难控制 GAN 的学习，不如我们就拆解一下，不要让 GAN 一次学完全部的数据，而是让 GAN 一步步完成这个学习过程。具体到图片生成来说就是，不要让 GAN 中的生成模型（G）每次都直接生成一整张图片，而是让它生成图片的一部分。这个思想可以认为是 DeepMind 也很有名的工作 DRAW 的一种变形。DRAW 的论文 [3] 开篇就说，我们人类在绘制一张图片时，很少是一笔完成的。既然我们人类都不是这样，为什么我们要寄希望于机器可以做到呢？论文 [4] 中提出的 LAPGAN 就是基于这个思想，将 GAN 的学习过程变成了 sequential “序列式” 的。 具体上，LAPGAN 采用了 Laplacian Pyramid 实现了 “序列化” ，也因此起名做 LAPGAN 。值得一提的是，这个 LAPGAN 中也有 “残差” 学习的思想（与后来大火的 ResNet 也算是有一点关联）。在学习序列中，LAPGAN 不断地进行 downsample 和 upsample 操作，然后在每一个 Pyramid level 中，只将残差传递给判别模型（D）进行判断。这样的 sequential + 残差结合的方式，能有效减少 GAN 需要学习的内容和难度，从而达到了 “辅助” GAN 学习的目的。&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/a07e88c3e83f8389f66a8dd9c5e85825.jpg" data-rawwidth="653" data-rawheight="234"&gt;另一个基于 sequential 思想去改进 GAN 的工作来自于 [5] 中的 GRAN。与 LAPGAN [4] 每一个 sequential step（Pyramid level）都是独立训练的不同的是，GRAN 把 GAN 和 LSTM 结合，让 sequence 中的每一步学习和生成能充分利用上一步的结果。具体上来看，GRAN 的每一步都有一个像 LSTM 中的 cell，C_t，它决定了每一步生成的内容和结果；GRAN 中的 h_{c,t} 也如 LSTM 一样，代表着 hidden states 。既然是结合 LSTM 和 GAN，那么说完了 LSTM 方面的引入，便是 GAN 方面的了。GRAN 将 GAN 中生成模型（G）的先验也进行了建模，变成了 hidden of prior h_z；然后将 h_z 和 h_{c,t} 拼接（concatenate）之后传递给每一步的 C_t。&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/0fa9a42dfc752b18e5ca801523d3e8d8.jpg" data-rawwidth="698" data-rawheight="250"&gt;最后一种改进 GAN 的训练稳定性的方式则更加贴近本质，也是最新的研究成果。这便是号称 openAI 近期五大突破之一的 infoGAN [7] 。InfoGAN [7] 的出发点是，既然 GAN 的自由度是由于仅有一个 noise z，而无法控制 GAN 如何利用这个 z。那么我们就尽量去想办法在 “如何利用 z” 上做文章。于是，[7] 中将 z 做了拆解，认为 GAN 中生成模型（G）应该包含的 “先验” 分成两种： （1）不能再做压缩的 noise z；（2）和可解释地、有隐含意义的一组隐变量 c_1, c_2, …, c_L，简写为 c 。这里面的思想主要是，当我们学习生成图像时，图像有许多可控的有含义的维度，比如笔划的粗细、图片的光照方向等等，这些便是 c ；而剩下的不知道怎么描述的便是 z 。这样一来，[7] 实际上是希望通过拆解先验的方式，让 GAN 能学出更加 disentangled 的数据表示（representation），从而既能控制 GAN 的学习过程，又能使得学出来的结果更加具备可解释性。为了引入这个 c ，[7] 利用了互信息的建模方式，即 c 应该和生成模型 （G）基于 z 和 c 生成的图片，即 G ( z,c )，高度相关 —— 互信息大。利用这种更加细致的隐变量建模控制，infoGAN 可以说将 GAN 的发展又推动了一步。首先，它们证明了 infoGAN 中的 c 对于 GAN 的训练是有确实的帮助的，即能使得生成模型（G）学出更符合真实数据的结果。其次，他们利用 c 的天然特性，控制 c 的维度，使得 infoGAN 能控制生成的图片在某一个特定语义维度的变化。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/ee7f92800471ba9ef9a6507a36897bfe.jpg" data-rawwidth="636" data-rawheight="743"&gt;&lt;p&gt;然而实际上， infoGAN 并不是第一个将信息论的角度引入 GAN 框架的工作。这是因为，在 infoGAN 之前，还有一个叫做 f-GAN [8] 的工作。并且，GAN 本身也可以从信息论角度去解释。如本文开篇所说，在原始 GAN 论文 [1] 中，作者是通过博弈论的角度解释了 GAN 的思想。然而，GAN 的生成模型（G）产生的数据和真实数据就可以看做一颗硬币的两面。当抛硬币抛到正面时，我们就将一个真实数据样本展示给判别模型（D）；反之，则展示由生成模型 （G）生成的“假”样本。而 GAN 的理想状态是，判别模型（D）对于硬币的判断几乎等同于随机，也就是生成模型（G）产生的数据完全符合真实数据。那么这时候，GAN 的训练过程实际在做的就是最小化这颗硬币和真实数据之间的互信息。互信息越小，判别模型（D）能从观察中获得的信息越少，也就越只能像 “随机” 一样猜结果。既然有了这样一个从互信息角度的对于 GAN 的理解，那么是否能对 GAN 进行更进一步的改造呢？其实是可以的。比如可以把针对互信息的建模更进一步地泛化为基于 divergence 的优化目标。这方面的讨论和改进可以见论文 [8]，f-GAN 。&lt;/p&gt;&lt;p&gt;上面这些对于 GAN 的改进工作都几乎是在短短一年半时间内完成的，尤其是近半年。这里面最大的原因就在于 GAN 相较于以前的 generative models，巧妙地将 “真假” 样本转换为一种隐性的 label，从而实现了一种 “无监督” 的生成式模型训练框架。这种思想也可以从某种程度上看做 word2vec 中 Skip-Gram 的一种变形。未来，不仅仅是 GAN 的更多改进值得被期待，无监督学习和生成式模型的发展也同样值得关注。&lt;/p&gt;&lt;p&gt;&lt;b&gt;References:&lt;/b&gt;&lt;/p&gt;&lt;p&gt;1.《Generative Adversarial Nets》&lt;/p&gt;&lt;p&gt;2.《Conditional Generative Adversarial Nets》&lt;/p&gt;&lt;p&gt;3.《DRAW: A Recurrent Neural Network For Image Generation》&lt;/p&gt;&lt;p&gt;4.《Deep Generative Image Models using a Laplacian Pyramid of Adversarial Networks》&lt;/p&gt;&lt;p&gt;5.《Generating Images with Recurrent Adversarial Networks》&lt;/p&gt;&lt;p&gt;6.《Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks》&lt;/p&gt;&lt;p&gt;7.《InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets》&lt;/p&gt;&lt;p&gt;8.《f-GAN: Training Generative Neural Samplers using Variational Divergence Minimization》&lt;/p&gt;&lt;p&gt;&lt;b&gt;该文章属于“深度学习大讲堂”原创，如需要转载，请联系&lt;a href="https://www.zhihu.com/people/guo-dan-qing" data-editable="true" data-title="@果果是枚开心果. "&gt;@果果是枚开心果. &lt;/a&gt;&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;作者简介：&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/0dd2f070b05fccf451b2f649d3f98c0d.jpg" data-rawwidth="115" data-rawheight="122"&gt;&lt;b&gt;李嫣然，&lt;/b&gt;香港理工大学在读博士生，研究方向为自然语言理解与对话生成。微信公众号“程序媛的日常”主要发起人之一（小S）。&lt;/p&gt;&lt;p&gt;&lt;b&gt;原文链接：&lt;a href="http://mp.weixin.qq.com/s?__biz=MzI1NTE4NTUwOQ==&amp;amp;mid=2650325352&amp;amp;idx=1&amp;amp;sn=90fb15cee44fa7175a804418259d352e&amp;amp;scene=0#wechat_redirect" class="" data-editable="true" data-title="近期GAN的模型和理论发展"&gt;近期GAN的模型和理论发展&lt;/a&gt;&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;欢迎大家关注我们的微信公众号，搜索微信名称：深度学习大讲堂&lt;/b&gt;&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/a29f11daca9717751e639f2c3a3f8b93.jpg" data-rawwidth="346" data-rawheight="67"&gt;</description><author>程程</author><pubDate>Thu, 01 Sep 2016 11:29:19 GMT</pubDate></item><item><title>基于深度学习的视觉实例搜索研究进展</title><link>https://zhuanlan.zhihu.com/p/22265265</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/a4b9332e9731cb25578e17522897c087_r.jpg"&gt;&lt;/p&gt;深度学习大讲堂致力于推送人工智能，深度学习方面的最新技术，产品以及活动。请关注我们的知乎专栏！&lt;p&gt;&lt;b&gt;摘要&lt;/b&gt;&lt;/p&gt;&lt;p&gt;近些年，深度学习在各种计算机视觉任务上都取得了重大的突破，其中一个重要因素就是其强大的非线性表示能力，能够理解图像更深层次的信息。本文对基于深度学习的视觉实例搜索方法做了简单的总结和概括，希望能给读者们带来启发。&lt;/p&gt;&lt;p&gt;&lt;b&gt;前言&lt;/b&gt;&lt;/p&gt;&lt;p&gt;给定一张包含某个物体的查询图片，视觉实例搜索的任务就是从候选的图片库中找到那些与查询图片包含相同物体的图片。与一般的图像搜索相比，实例搜索的搜索条件更为苛刻——是否包含相同的物体，如同一款衣服，同一辆车等等。该问题具有非常广泛的应用前景，如商品搜索，车辆搜索和基于图像的地理位置识别等。举个例子，移动商品图像搜索就是通过分析利用手机相机拍摄的商品照片，从商品库中找到相同或相似的商品。&lt;/p&gt;&lt;p&gt;然而在实际场景中，由于姿态，光照和背景等干扰因素，所以两张包含相同物体的图像往往在外观上差异很大。从这个角度来看，视觉实例搜索的本质问题就是应该学习什么样的图像特征从而使得包含相同物体的图像在特征空间上是相似的。&lt;/p&gt;&lt;p&gt;近些年，深度学习在各种计算机视觉任务上都取得了重大的突破，其中就包括视觉实例搜索任务。本文主要对基于深度学习的实例搜索算法（下面简称为“深度实例搜索算法”）进行剖析和总结，文章分为四个部分：第一部分总结了经典视觉实例搜索算法的一般流程；第二部分和第三部分分别从两个方面去介绍近些年主要的深度实例搜索算法；端到端的特征学习方法和基于CNN特征的特征编码方法；第四部分将通过总结在2015年首届阿里巴巴大规模图像大赛（Alibaba Large-scale Image Search Challenge, ALISC）中出现的相关方法，介绍一些实践中可以提高实例搜索性能的技巧和方法。&lt;/p&gt;&lt;p&gt;&lt;b&gt;经典视觉实例搜索算法的一般流程&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在深度学习流行之前，典型的实例搜索算法一般分为三个阶段：首先在给定的图像密集地提取局部不变特征，然后将这些局部不变特征进一步地编码为一个紧凑的图像表示，最后将查询图像与候选图像库中的图像进行相似度计算（基于第二步得到的图像表示），找到那些属于同一实例的图片。&lt;/p&gt;&lt;p&gt;1. 局部不变特征。局部不变特征的特点就是提取图像局部区域的细节信息，不关心全局信息，并对该局部区域内的光线变化、几何变换具有一定的不变性。这对实例搜索非常有意义，因为目标物体可以伴随着几何变换出现图像中的任何区域。在早期的工作中，很多实例搜索方法采用的是SIFT特征。&lt;/p&gt;&lt;p&gt;2. 特征编码。对局部特征进一步地编码有两方面的意义：挖掘这些局部特征之间的相关信息，增强可判别能力；单一紧凑的特征向量更易于实现索引，提高搜索速度。目前常见的方法有VLAD（vector of locally aggregated descriptors），Fisher Vectors，triangular embedding等。在这里，本文简单地介绍下VLAD方法（在本文后面多次出现）：&lt;/p&gt;&lt;p&gt;a）VLAD方法首先利用k-means得到包含k个中心的码本，然后每个局部特征被指派给离它最近的中心点（我们将这一步称为hard-assignment，之后会相关文章对此进行改进），最后将这些局部特征与其指派的中心点之间的残差累和作为最终的图像表示。从上面可以看出，VLAD方法有无序的特性——不关心局部特征的空间位置，因此可以进一步解耦全局空间信息，对几何变换具有很好的鲁棒性。&lt;/p&gt;&lt;p&gt;3. 相似度计算。一种直接的做法是根据距离函数计算特征之间的距离，例如欧式距离，余弦距离等。另一种是学习相应的距离函数，例如LMNN、ITML等度量学习方法。&lt;/p&gt;&lt;p&gt;&lt;b&gt;总结：&lt;/b&gt;经典视觉实例搜索算法的性能往往受限于hand-crafted特征的表示能力。当深度学习应用在实例搜索任务时，主要就是从特征表示入手，即如何提取更加具有判别性的图像特征。&lt;/p&gt;&lt;p&gt;&lt;b&gt;端到端的特征学习方法&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;NetVLAD: CNN architecture for weakly supervised place recognition  （CVPR 2016）&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这篇文章是来自于INRIA 的Relja Arandjelović等人的工作。该文章关注实例搜索的一个具体应用——位置识别。在位置识别问题中，给定一张查询图片，通过查询一个大规模的位置标记数据集，然后使用那些相似的图片的位置去估计查询图片的位置。作者首先使用Google Street View Time Machine建立了大规模的位置标记数据集，随后提出了一种卷积神经网络架构，NetVLAD——将VLAD方法嵌入到CNN网络中，并实现“end-to-end”的学习。该方法如下图所示：&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/776d355801adbda59e07c8ac9dca8f35.jpg" data-rawwidth="671" data-rawheight="151"&gt;原始的VLAD方法中的hard-assignment操作是不可微的（将每个局部特征指派给离它最近的中心点），因此不可以直接嵌入到CNN网络里，并参与误差反向传播。这篇文章的解决方法就是使用softmax函数将此hard-assignment操作转化为soft-assignment操作——使用1x1卷积和softmax函数得到该局部特征属于每个中心点的概率/权重，然后将其指派给具有最大的概率/权重的中心点。因此NetVLAD包含了三个可以被学习参数，，其中是上面1x1卷积的参数，用于预测soft-assignment，表示为每个簇的中心点。并在上图的VLAD core层中完成相应的累积残差操作。作者通过下图给我们说明NetVLAD相比于原始的VLAD的优势：（更大的灵活性——学习更好的簇中心点）&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/b5461307f5878545b7436bca67fcc855.jpg" data-rawwidth="549" data-rawheight="240"&gt;&lt;p&gt;这篇文章的另一个改进工作就是Weakly supervised triplet ranking loss。该方法为了解决训练数据可能包含噪声的问题，将triplet ranking loss中正负样本分别替换为潜在的正样本集（至少包含一张正样本，但不确定哪张）和明确的负样本集。并且在训练时，约束查询图片和正样本集中&lt;b&gt;最可能是正样本&lt;/b&gt;的图片之间的特征距离比查询图片与所有负样本集内的图片之间的特征距离要小。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Deep Relative Distance Learning: Tell the Difference Between Similar Vehicles （CVPR 2016）&lt;/b&gt;&lt;/p&gt;&lt;p&gt;接下来的这篇文章关注的是车辆识别/搜索问题，来自于北京大学Hongye Liu等人的工作。如下图所示，这个问题同样可以被看成实例搜索任务。&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/d5ce3aa0f204fb5af3892d855efade3f.jpg" data-rawwidth="684" data-rawheight="451"&gt;和很多有监督的深度实例搜索方法一样，这篇文章旨在将原始的图片映射到一个欧式特征空间中，并使得在该空间里，相同车辆的图片更加聚集，而非同类的车辆图片则更加远离。为了实现该效果，常用的方法是通过优化triplet ranking loss，去训练CNN网络。但是，作者发现原始的triplet ranking loss存在一些问题，如下图所示：&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/3b92a0b882b5c971aff65333568a4ef1.jpg" data-rawwidth="680" data-rawheight="140"&gt;对于同样的样本，左边的三元组会被损失函数调整，而右边的三元组则会被忽视。两者之间的区别在于anchor的选择不一样，这导致了训练时的不稳定。为了克服该问题，作者用coupled clusters loss（CCL）去替代triplet ranking loss。该损失函数的特点就是将三元组变成了一个正样本集和一个负样本集，并使得正样本内的样本相互聚集，而负样本集内的样本与那些正样本更加疏远，从而避免了随机选择anchor样本所带来的负面影响。该损失函数的具体效果如下图所示：&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/19bb2003307e0bb1273bdec445760a33.jpg" data-rawwidth="676" data-rawheight="267"&gt;&lt;p&gt;最后这篇文章针对车辆问题的特殊性，并结合上面所设计的coupled clusters loss，设计了一种混合的网络架构，并构建了相关的车辆数据库去提供所需的训练样本。&lt;/p&gt;&lt;p&gt;&lt;b&gt;DeepFashion: Powering Robust Clothes Recognition and Retrieval with Rich Annotations （CVPR 2016）&lt;/b&gt;&lt;/p&gt;&lt;p&gt;最后的这篇文章同样是发表在CVPR 2016上，介绍了衣服识别和搜索，同样是与实例搜索相关的任务，来自于香港中文大学Ziwei Liu等人的工作。首先，本篇文章介绍了一个名为DeepFashion的衣服数据库。该数据库包含超过800K张的衣服图片，50个细粒度类别和1000个属性，并还额外提供衣服的关键点和跨姿态/跨领域的衣服对关系（cross-pose/cross-domain pair correspondences），一些具体例子如下图所示：&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/6e83aa32595babb92b0e906c762a024e.jpg" data-rawwidth="693" data-rawheight="291"&gt;然后为了说明该数据库的效果，作者提出了一种新颖的深度学习网络，FashionNet——通过联合预测衣服的关键点和属性，学习得到更具区分性的特征。该网络的总体框架如下所示：&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/f12f99f503deb37122f4125abf2b683d.jpg" data-rawwidth="683" data-rawheight="337"&gt;&lt;p&gt;FashionNet的前向计算过程总共分为三个阶段：第一个阶段，将一张衣服图片输入到网络中的蓝色分支，去预测衣服的关键点是否可见和位置。第二个阶段，根据在上一步预测的关键点位置，关键点池化层（landmark pooling layer）得到衣服的局部特征。第三个阶段，将“fc6 global”层的全局特征和“fc6 local”的局部特征拼接在一起组成“fc7_fusion”，作为最终的图像特征。FashionNet引入了四种损失函数，并采用一种迭代训练的方式去优化。这些损失分别为：回归损失对应于关键点定位，softmax损失对应于关键点是否可见和衣服类别，交叉熵损失函数对应属性预测和三元组损失函数对应于衣服之间的相似度学习。作者分别从衣服分类，属性预测和衣服搜索这三个方面，将FashionNet与其他方法相比较，都取得了明显更好的效果。&lt;/p&gt;&lt;p&gt;&lt;b&gt;总结：&lt;/b&gt;当有足够多的有标注数据时，深度学习可以同时学习图像特征和度量函数。其背后的思想就是根据给定的度量函数，学习特征使得特征在该度量空间下具有最好的判别性。因此端到端的特征学习方法的主要研究方向就是如何构建更好的特征表示形式和损失函数形式。&lt;/p&gt;&lt;p&gt;&lt;b&gt;基于CNN特征的特征编码方法&lt;/b&gt;&lt;/p&gt;&lt;p&gt;本文在上面部分介绍的深度实例搜索算法，主要关注数据驱动的端到端特征学习方法及相对应的图像搜索数据集。接下来，本文关注于另一个问题：当没有这些相关的搜索数据集时，如何提取有效的图像特征。为了克服领域数据的不足，一种可行的策略就是在CNN预训练模型（训练在其他任务数据集上的CNN模型，比如ImageNet图像分类数据集）的基础上，提取其中某一层的特征图谱（feature map），对其进行编码得到适用于实例搜索任务的图像特征。本部分将根据近些年相关的论文，介绍一些主要的方法（特别的，本部分中所有的CNN模型都是基于ImageNet分类数据集的预训练模型）。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Multi-Scale Orderless Pooling of Deep Convolutional Activation Features （ECCV 2014）&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这篇文章发表在ECCV 2014上，是来自于北卡罗来纳大学教堂山分校Yunchao Gong和伊利诺伊大学香槟分校Liwei Wang等人的工作。 由于全局的CNN特征缺少几何不变性，限制了对可变场景的分类和匹配。作者将该问题归因于全局的CNN特征包含了太多的空间信息，因此提出了multi-scale orderless pooling (MOP-CNN)——将CNN特征与无序的VLAD编码方法相结合。&lt;/p&gt;&lt;p&gt;MOP-CNN的主要步骤为，首先将CNN网络看作为“局部特征”提取器，然后在多个尺度上提取图像的“局部特征”，并采用VLAD将这些每个尺度的“局部特征”编码为该尺度上的图像特征，最后将所有尺度的图像特征连接在一起构成最终的图像特征。提取特征的框架如下所示：&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/601ddd371c0c635f170b2c0408352919.jpg" data-rawwidth="682" data-rawheight="328"&gt;作者分别在分类和实例搜索两个任务上进行测试，如下图所示，证明了MOP-CNN相比于一般的CNN全局特征有更好的分类和搜索效果。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/4be2d5e3eae9d9bdbe271c51aad918c2.jpg" data-rawwidth="693" data-rawheight="363"&gt;&lt;p&gt;&lt;b&gt;Exploiting Local Features from Deep Networks for Image Retrieval （CVPR 2015 workshop）&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这篇文章发表在CVPR 2015 workshop上，是来自于马里兰大学帕克学院Joe Yue-Hei Ng等人的工作。近期的很多研究工作表明，相比于全相连层的输出，卷积层的特征图谱（feature map）更适用于实例搜索。本篇文章介绍了如何将卷积层的特征图谱转化为“局部特征”，并使用VLAD将其编码为图像特征。另外，作者还进行了一系列的相关试验去观察不同卷积层的特征图谱对实例搜索准确率的影响。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/a4b9332e9731cb25578e17522897c087.jpg" data-rawwidth="684" data-rawheight="457"&gt;&lt;p&gt;&lt;b&gt;Aggregating Deep Convolutional Features for Image Retrieval（ICCV 2015）&lt;/b&gt;&lt;/p&gt;&lt;p&gt;接下来这篇文章发表在ICCV 2015上，是来自于莫斯科物理与技术学院Artem Babenko和斯科尔科沃科技学院Victor Lempitsky的工作。从上面两篇文章可以看出，很多深度实例搜索方法都采用了无序的编码方法。但包括VLAD，Fisher Vector在内的这些编码方法的计算量通常比较大。为了克服该问题，这篇文章设计了一种更加简单，并且更加有效的编码方法——Sum pooing。Sum pooling的具体定义如下所示：&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/aca8dac35b892213fef0b714515fa45d.jpg" data-rawwidth="629" data-rawheight="111"&gt;&lt;p&gt;其中就是在卷积层在空间位置上的局部特征（这里提取局部特征的方法，与上篇文章一致）。在使用sum pooling后，对全局特征进一步地执行PCA和L2归一化得到最终的特征。作者分别与Fisher Vector，Triangulation embedding和max pooling这些方法进行比较，论证了sum pooling方法不仅计算简单，并且效果更好。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Where to Focus: Query Adaptive Matching for Instance Retrieval Using Convolutional Feature Maps （arXiv 1606.6811）&lt;/b&gt;&lt;/p&gt;&lt;p&gt;最后这篇文章目前发在arXiv上，是来自于澳大利亚昆士兰大学Jiewei Cao等人的工作。正如本文在开头部分所提到的，杂乱的背景对实例搜索影响非常大。为了克服该问题，这篇文章在上篇文章所提出的sum-pooling方法的基础上，提出了一种被称为query adaptive matching (QAM)的方法去计算图像之间的相似度。该方法的核心在于对图像的多个区域执行池化操作，并创建多份特征去表达图像。然后在匹配时，查询图像将分别与这些区域的特征比较，并将最佳匹配分数作为两张图像之间相似度。那么接下的问题是如何去构建这些区域。&lt;/p&gt;&lt;p&gt;作者首先提出了两种方法——Feature Map Pooling和Overlapped Spatial Pyramid Pooling (OSPP)，去得到图像的base region。然后通过对这些base region不断地合并，以找到最好的相似度评分为目标，构建出目标区域。其中最吸引人的地方在于，作者将整个合并的过程，转化为了对一个优化问题的求解。下图显示了QAM方法的部分结果及对应图像的特征映射。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/91393d394791e2722f31b7c448361233.jpg" data-rawwidth="673" data-rawheight="387"&gt;&lt;p&gt;&lt;b&gt;总结：&lt;/b&gt;在某些实例搜索任务中，由于缺少足够的训练样本，所以不能直接 “端到端”的去学习图像特征。这时候，如何将现成的CNN特征编码为适合实例搜索的图像表示就成为该领域的一个热门研究方向。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2015年首届阿里巴巴大规模图像搜索大赛总结&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在介绍完近些年一些主要的深度实例搜索方法后，在接下来的部分，本文将通过总结在阿里巴巴大规模图像搜索大赛中出现的相关方法，来介绍一些实践中可以提高视觉实例搜索性能的技巧和方法。&lt;/p&gt;&lt;p&gt;阿里巴巴大规模图像搜索大赛由阿里的图像搜索组所主办，要求参赛队伍从海量的图片库中找出那些与查询图片包含相同物体的图片。这次比赛提供了以下两类数据用于训练：约200W张图片的训练集（类别级标签及相对应的属性），1417张验证查询图片及相对应的搜索结果（总共约10W张）。在测试时，给定3567张查询图片，参赛队伍需从约300W张图片的评测集中（无标签），搜索出那些符合要求的图片，评价指标为基于top 20的mAP （ mean  Average  Precision）。&lt;/p&gt;&lt;p&gt;首先简单介绍我们的方法——Multi-level Image Representation for Instance Retrieval，该方法取得了这次比赛的第三名。很多方法都是用最后一个卷积层或全连接层的特征进行检索，而由于高层的特征已经损失了很多细节信息（对于更深的网络，损失更严重），所以实例搜索时不是很精准，如下图所示，即整体轮廓相似，但细节则差距很大。&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/1c1fcc829691b40d164b90591a2b2a04.jpg" data-rawwidth="672" data-rawheight="200"&gt;为了克服该问题，我们将CNN网络中不同层的特征图谱（feature map）进行融合，这不仅利用了高层特征的语义信息，还考虑了低层特征的细节纹理信息，使得实例搜索更精准。如下图所示，我们的实验主要基于GoogLeNet-22网络，对于最后的8层特征图（从Inception 3b到Inception 5b），首先使用最大池化对这些不同尺度的特征图分别进行子采样（转换为相同尺寸的特征图），并使用的卷积对这些采样结果进一步地处理。然后对这些特征图做线性加权（由的卷积完成），最后在此基础上，使用sum pooling得到最终的图像特征。在训练时，我们根据所提供的训练数据，通过优化基于余弦距离的triplet ranking loss来端到端学习这些特征。因此在测试时，可以直接使用特征之间的余弦距离来衡量图像的相似度。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/43d3d933fdd6236f647affe8f7a61dba.jpg" data-rawwidth="710" data-rawheight="441"&gt;&lt;p&gt;另外，借鉴于训练SVM分类器时使用了难分样本挖掘的思想，我们的方法首先在前向计算时，计算当前训练批次中所有潜在三元组的损失（从当前训练批次中选取两张相同类别的图片和一张不同类别的图片构成潜在三元组），然后找到那些“困难”的三元组（更大的损失），最后在反向计算时，使用这些“困难”的三元组进行误差传播，从而取得更好的训练效果。&lt;/p&gt;&lt;p&gt;接下来简单总结其他队伍的相关方法。在端到端的特征学习方法中，除了triplet ranking loss，contrastive loss（对应于Siamese network）也是常见的损失函数。除此之外，还有一些方法值得我们关注，可以显著地提高搜索性能：&lt;/p&gt;&lt;p&gt;&lt;b&gt;(一)  同款图挖掘&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在有监督的机器学习方法中，更多的数据可能就意味着更高的准确率。因此来自于中科院计算所的团队提出，先根据ImageNet预训练模型的特征，在类别级训练集上聚类，然后通过阀值，挖掘出更多地同款图，最后用这些同款图去训练CNN网络，学习图像特征。该方法实现简单，并且可以显著地提高搜索的性能。&lt;/p&gt;&lt;p&gt;&lt;b&gt;(二)  目标检测&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在实例检索中，复杂的背景噪声直接影响了最终的搜索性能。因此很多队伍首先尝试使用目标检测（比如faster-rcnn）定位感兴趣的区域，然后在进一步地学习特征，比较相似度。另外，当没有bounding box训练数据时，弱监督的目标定位也是一种有效的方法。&lt;/p&gt;&lt;p&gt;&lt;b&gt;(三) 一阶池化特征和二阶池化特征融合&lt;/b&gt;&lt;/p&gt;&lt;p&gt;二阶池化方法通过捕捉图像二阶统计变量，如协方差等，往往可以取得更好的搜索准确率。来自大连理工的李培华教授所带领的团队在CNN网络的基础上，将一阶池化特征和二阶池化特征融合，取得非常出色的成绩。&lt;/p&gt;&lt;p&gt;&lt;b&gt;(四) 联合特征学习和属性预测&lt;/b&gt;&lt;/p&gt;&lt;p&gt;该方法和本文在第三部分所提到的DeepFashion类似，同时学习特征和预测图片的属性（多任务训练），从而得到更具区分性的特征。&lt;/p&gt;&lt;p&gt;&lt;b&gt;致谢：&lt;/b&gt;本文作者感谢所有匿名审稿专家的辛勤工作，对本文所提出了建设性的修改意见，改善了文章的专业性和可读性。&lt;/p&gt;&lt;p&gt;&lt;b&gt;该文章属于“深度学习大讲堂”原创，如需要转载，请联系&lt;a href="https://www.zhihu.com/people/guo-dan-qing" data-editable="true" data-title="@果果是枚开心果. "&gt;@果果是枚开心果. &lt;/a&gt;&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;作者简介：&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/28a1b5f6dc8e2f6b01870b060adfdeea.jpg" data-rawwidth="117" data-rawheight="119"&gt;&lt;b&gt;邓启力，&lt;/b&gt;哈尔滨工业大学深圳研究生院计算机系硕士研究生二年级，导师为“鹏城学者”徐勇教授。研究兴趣为深度学习与计算机视觉。曾获2015年首届阿里巴巴大规模图像搜索大赛二等奖，总排名第三名。个人邮箱：dengql_hitsz@163.com。&lt;/p&gt;&lt;p&gt;&lt;b&gt;原文链接：&lt;a href="http://mp.weixin.qq.com/s?__biz=MzI1NTE4NTUwOQ==&amp;amp;mid=2650325339&amp;amp;idx=1&amp;amp;sn=9554c2ba8e7f3177d552a174803f89c1&amp;amp;scene=0#wechat_redirect" data-editable="true" data-title="基于深度学习的视觉实例搜索研究进展" class=""&gt;基于深度学习的视觉实例搜索研究进展&lt;/a&gt;&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;欢迎大家关注我们的微信公众号，搜索微信名称：深度学习大讲堂&lt;/b&gt;&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/a29f11daca9717751e639f2c3a3f8b93.jpg" data-rawwidth="346" data-rawheight="67"&gt;</description><author>程程</author><pubDate>Thu, 01 Sep 2016 11:19:47 GMT</pubDate></item><item><title>【CCF-GAIR特别报道】深度对话周志华教授和颜水成博士</title><link>https://zhuanlan.zhihu.com/p/22192139</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/fa026d906405c3e68d1aa1369acc910d_r.jpg"&gt;&lt;/p&gt;深度学习大讲堂致力于推送人工智能，深度学习方面的最新技术，产品以及活动。请关注我们的知乎专栏！&lt;p&gt;&lt;b&gt;摘要&lt;/b&gt;&lt;/p&gt;&lt;p&gt;2016年8月12、13日深圳CCF-GAIR大会期间，深度学习大讲堂采访了南京大学周志华教授和360首席科学家颜水成博士，就深度学习的应用、与经典机器学习技术的关系、来自神经科学研究的启发、深度学习的未来发展等问题进行了深入探讨。&lt;/p&gt;&lt;p&gt;&lt;b&gt;导读&lt;/b&gt;&lt;/p&gt;&lt;p&gt;CCF-GAIR全球人工智能与机器人峰会由中国计算机学会主办，雷锋网承办，深圳市政府指导。多达1500人参与了本届CCF-GAIR大会，他们是人工智能、机器人、智能驾驶等领域的从业者、研究者和各路科技媒体。&lt;/p&gt;&lt;p&gt;深度学习是目前人工智能领域一个最热门的主题，本次CCF-GAIR大会期间，深度学习大讲堂作为特邀技术媒体在大会期间采访了南京大学周志华教授和360首席科学家颜水成博士，访谈内容涵盖深度学习的应用、深度学习与经典机器学习技术的关系、神经科学研究对深度学习的启发意义、深度学习的未来发展等深度技术问题。&lt;/p&gt;&lt;p&gt;&lt;b&gt;1. 对话南京大学周志华教授&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;背景介绍：&lt;/b&gt;&lt;/p&gt;&lt;p&gt;周志华，男，1973年11月生。现任南京大学计算机科学与技术系副主任、南京大学计算机软件新技术国家重点实验室常务副主任、机器学习与数据挖掘研究所 (LAMDA) 所长，校、系学术委员会委员。国际计算机学会(ACM) 杰出科学家，国际人工智能学会 (AAAI) 、国际电气电子工程师学会 (IEEE) 、国际模式识别学会 (IAPR)、国际工程技术学会 (IET/IEE)、中国计算机学会 等学会的会士 (Fellow)。主要从事人工智能、机器学习、数据挖掘、模式识别等领域的研究工作。主持多项科研课题，出版英文著作一部，主编文集多部，获发明专利十余项，在一流国际期刊和顶级国际会议发表论文百余篇，被引用万余次。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/6e72825abf68c0b67098d1388498de82.jpg" data-rawwidth="395" data-rawheight="258"&gt;&lt;p&gt;在微博上，周志华教授一贯言辞犀利又不失风趣。例如周老师层转发过图1名为专业深度学习调试的网图。周老师还配了一个犀利旁白“有点幽默，但很朴实：深度学习现在差不多就是民工活。调来调去，刷来刷去，文章发得飞快，貌似热闹，但有多少是能积淀下来的实质真进展，又有多少是换个数据就不靠谱了的蒙事撞大运？何曾见过调试SVM核函数3元一个？&lt;b&gt;既缺乏清澈干净的内在美感，再不致力于去伪存真正本清源，只图热闹好看，迟早把arXiv变成废纸堆”。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;此微博一出，立刻在社交网络上引发了热议，既有拥趸的转发呼应，也有反对者的犀利评论。周志华教授最后总结发言是“深度学习本身有很多重要的问题值得研究。年轻学生还是要尽量让自己沉静下来，多思考些深入的问题，不要急，否则浮几年下来就没根了。&lt;b&gt;严肃的机器学习研究不是靠调参刷分”。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;社交网络上的周志华教授保持着对深度学习的冷静观察和批判性思考，那么周志华教授如何看待自己学术成果的实际应用，如何看待深度学习与经典机器学习方法的关系，又对深度学习存在的问题做了哪些思考，请看下面的访谈。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/b3b41d20c2bdbb81d3d65569b5868545.jpg" data-rawwidth="660" data-rawheight="471"&gt;Q: 您在过去二十年中一直从事机器学习理论研究，比如多示例学习和集成学习，除了理论研究之外，您的工作成果有哪些实际中的应用？A：计算机科学是一个应用驱动的学科，中国几乎所有大一点的互联网公司、通讯公司，甚至包括一些跨国的企业，都和我们有合作。机器学习不是做一个具体的事情，而是在一些数据分析的任务中，遇到一些困难的问题，是用现成的技术解决不了的，我们会设计提供解决方案。用户往往看到的只是例如防火墙、金融理财产品，但是背后的数据分析问题是可以由我们来利用机器学习技术解决的。&lt;/p&gt;&lt;p&gt;Q：您如何看待深度学习的进展对经典机器学习方法的启发意义？A： 机器学习中很多方法都是相同的，所谓深度学习，可以把它看成一种语言。深度学习并不是与过去的方法截然不同的，而是一种描述方式。深度学习中融入了很多以往的机器学习方法的机理，也融合了很多过去的方法，包括一些共性的理论问题也都是一样的。&lt;/p&gt;&lt;p&gt;Q：您如何看待在深度学习应用过程中“性能不够、加层来凑”的说法？A：这个看法其实不是很对。增加了层数，不是说学习性能一定会变好。层数增加使得模型的复杂度更高，可以吃下去更多的数据，但是性能不一定会变好。比如一个问题本来只需要100层的网络，如果做到120层性能反而可能会变坏。&lt;/p&gt;&lt;p&gt;Q：是不是意味着模型复杂度要和样本复杂度匹配？A：要恰当的好，过犹不及。&lt;/p&gt;&lt;p&gt;Q：是否有量化评价深度网络复杂度的方法？A：复杂度的评价是有方法的，可以从参数的数目、学习理论的角度来做。但是神经网络的机理，其中有很多trick, 许多启发式的试错的做法。很多人去试，试出了很多不错的做法。做应用的门槛相对低，甚至培训几个星期就可以做。但是做理论有很高的门槛，需要多年的培养。现在虽然试出很多的方法，但是没有足够多的做理论的人一个个去分析。一定要找到共性的东西，才能做理论分析。现在的问题是，大家都盲目的去试，最后都报告出来很有用，理论分析就跟不上了。&lt;/p&gt;&lt;p&gt;Q：用一句话来赞美或者批判深度学习？A：其实，既不用赞美也不用批评深度学习，这是一个很自然的技术发展过程。机器学习每过五年、十年，就会有一种新的技术在当时变得非常流行。比如说90年代的统计学习，2000年的概率图模型以及2010年以来的深度学习。&lt;/p&gt;&lt;p&gt;Q：深度学习目前最大的问题是什么A：我认为目前深度学习领域中最大的问题是理论的研究没有跟上，很多的技术大家都只是在尝试，缺乏比较严格的理论分析。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2. 对话360首席科学家颜水成博士&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;背景介绍：&lt;/b&gt;&lt;/p&gt;&lt;p&gt;颜水成博士，360 首席科学家，360 人工智能研究院院长。曾在新加坡国立大学领导机器学习与计算机视觉实验室。颜水成博士的主要研究领域是计算机视觉，深度学习与多媒体分析。他的团队在五年内曾7次问鼎计算机视觉领域顶级竞赛PASCAL VOC 和 ILSVRC的世界冠军和亚军奖项。他的团队所提出的“Network in Network” 对深度学习产生了很大的推动力，曾被Google在深度学习领域的代表性工作GoogLeNet引用并进一步发展为Inception结构。2015年，颜水成博士从新加坡国立大学离职，全职加入360，完成了从工业界到学术界的华丽转身。&lt;/p&gt;&lt;p&gt;作为一个互联网公司人工智能研究院的领军人物，颜水成博士的研究自然离不开深度学习的落地。那么颜水成博士如何看待深度学习在学术界的火爆？最满意的工作什么?对深度学习的未来发展有哪些前瞻性的判断?请看下面的访谈。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/10d639493abcf7e02e04dbd6b6ec0f55.jpg" data-rawwidth="655" data-rawheight="465"&gt;Q：如何看待深度学习在工业界的火爆？A：深度学习带来的诸多变化，起因是在视觉分析、语音识别等任务中的深度学习技术所达到的性能超过了商业应用最低的bound。例如，在深度学习出现之前，已经有人脸识别的研究，比如嵌入式设备上的人脸检测、识别技术，但是总体上没有达到很多工业级场景中定义的最低性能需求。近几年来深度学习与人脸识别的结合则彻底改变了这一现状。以我之前在新加坡国立大学计算机视觉与学习研究组的例子，我们做了三年Pascal VOC, 每年性能上涨只有不到两个点。但是在2012年的ImageNet竞赛中，基于深度学习的AlexNet的结果比上一年的最好方法的top-5错误率下降了10个百分点以上。&lt;/p&gt;&lt;p&gt;Q：为了实现端上的智能，深度学习算法需要做什么改进？A： 实现端上的智能，一个重要的前提是需要考虑终端设备的运算能力的限制（由于智能设备对成本非常敏感，大多数情况下对CPU芯片的计算速度有限制）。深度学习算法的计算量普遍较高，解决这个问题，主要思路有两个：1. 重新定义网络结构，设计小的和特殊的网络，例如Network in Network。2. 设计新的计算模型，在精度不降低的情况下，降低计算量。例如，我们目前在做的一个工作，用一个小网络去预测卷积运算哪些位置不用算，类似于attention机制。这种做法可以称之为More is less, 虽然网络结构变复杂了，但是计算量减少了。&lt;/p&gt;&lt;p&gt;Q：：对于您在深度学习领域中众多的工作，哪一项是您自己最满意的？A：&lt;b&gt;我个人最满意的工作是Network in Network。&lt;/b&gt;我经常和学生说，如果一年能做出一个工作，类似1x1的卷积核这样，成为深度网络中的一个标准结构，是非常有价值的。&lt;/p&gt;&lt;p&gt;Q：对于深度学习领域的其它工作，您最欣赏的是哪一个？A：孙剑老师的Deep Residual Network。&lt;/p&gt;&lt;p&gt;Q：您如何看待类脑计算的研究，或者说如何看待神经生物学研究对深度学习研究的启发意义？A：这是一个好问题。我一直认为神经生物学对计算机视觉具有重要的启发意义，但是这个领域的发展却并没有我们想象中的那么快。首先，我个人很欣赏神经生物学模型对计算机视觉计算模型的启发。我们有一个未发表的工作是把图像分类的过程看成一个偏微分方程求解的过程。大脑里面看到一副图像，并不是由一个单纯的前向传递过程来最后输出类别是牛或者马。&lt;b&gt;生物的信号传导是一个连续的过程，在识别过程中存在反馈机制，我们的工作正是要在物体识别的过程中引入反馈机制。&lt;/b&gt;遗憾的是，当我们把偏微分方程时序上离散化求解之后，会等价于一个前向网络，有点类似recurrent neural network。所以虽然这个工作的Motivation很好，但是最后求解依旧还是会等价于一个前向网络，反馈变成了另外一种层面上的前向计算。&lt;/p&gt;&lt;p&gt;Q：您如何看待深度学习在学术上的发展方向？A：我认为是无监督学习和自学习。应该说，无监督学习的进展非常糟糕。即便是最近非常火的对抗性训练，也并不是所有问题都适用，比如人脸识别就依旧还依赖于监督学习。针对无监督学习这个问题，我最近的一个假设是人最初的认知过程是通过运动来获得的。据说Baby开始的时候像青蛙一样，只能看到动的物体。最近我和合作者投稿PAMI的工作Learning to Segment Human by Watching Videos就尝试从video中进行无监督学习，利用motion segmentation进行分割，形成物体的概念，这些是同一个物体。人可能是从运动中逐步形成物体的概念的。因此要想进行无监督学习，可以从运动开始。另外一个就是自学习。我在这方面的一个代表性工作是Baby Learning。只需要少量的标注样本，也就是小样本学习，然后再做自学习。Baby Learning做了三年，最后终于做出来了，因为我坚信这个是对的。第一次投稿CVPR，六个AC开会毙掉了我们的文章，原因是题目可能会引发误解，Baby不一定真的是这样学习的。第二次改了名字，叫Towards Computational Baby Learning，最后被ICCV2015录用，但是遗憾的是错过了时机没有拿到Oral。&lt;/p&gt;&lt;p&gt;&lt;b&gt;我目前的努力方向是把无监督学习和自学习结合起来。我想只要扎进去研究，不管外边怎么说，一定可以做出很棒的工作。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;致谢：&lt;/b&gt;深度大讲堂微信公众号在此感谢雷锋网给予了本届CCF-GAIR赠票，并且对对采访工作进行了大力的支持，同时也感谢CCF-GAIR大会的组织者雷锋网的辛苦奉献，组织了一场高质量的人工智能盛会。此外，感谢紫牛基金尚静和猎豹机器人蒋超共同参与了对360首席科学家颜水成博士的采访。&lt;/p&gt;&lt;p&gt;&lt;b&gt;该文章属于“深度学习大讲堂”原创，如需要转载，请联系&lt;a href="https://www.zhihu.com/people/guo-dan-qing" class="" data-editable="true" data-title="@果果是枚开心果"&gt;@果果是枚开心果&lt;/a&gt;. &lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;原文链接：&lt;a href="http://mp.weixin.qq.com/s?__biz=MzI1NTE4NTUwOQ==&amp;amp;mid=2650325320&amp;amp;idx=1&amp;amp;sn=46bf96254385ac5dc98c483652fe281c&amp;amp;scene=0#wechat_redirect" data-editable="true" data-title="【CCF-GAIR特别报道】深度对话周志华教授和颜水成博士"&gt;【CCF-GAIR特别报道】深度对话周志华教授和颜水成博士&lt;/a&gt;&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;欢迎大家关注我们的微信公众号，搜索微信名称：深度学习大讲堂&lt;/b&gt;&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/a29f11daca9717751e639f2c3a3f8b93.jpg" data-rawwidth="346" data-rawheight="67"&gt;</description><author>程程</author><pubDate>Fri, 26 Aug 2016 17:06:52 GMT</pubDate></item><item><title>【青年学者专栏】递归神经网络(Recurrent Neural Network)学习</title><link>https://zhuanlan.zhihu.com/p/22191239</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/a5a6afde66dec7f7eac7bfd44e2b6c94_r.jpg"&gt;&lt;/p&gt;深度学习大讲堂致力于推送人工智能，深度学习方面的最新技术，产品以及活动。请关注我们的知乎专栏！&lt;b&gt;摘要&lt;/b&gt;&lt;p&gt;递归神经网络(Recurrent Neural Network, RNNs)的研究最近取得了很大进展，成功应用包括手写识别、语音识别、自然语言处理以及计算机视觉等一系列问题。本文介绍了递归神经网络的基本原理与近期进展，并对若干代表性工作进行了回顾。&lt;/p&gt;&lt;p&gt;&lt;b&gt;导读&lt;/b&gt;&lt;/p&gt;&lt;p&gt;递归神经网络（RNN）是目前最流行的几种深度学习网络结构之一，因其递归处理历史信息和建模历史记忆的功能特点而特别适用于处理时间、空间序列上有强关联的信息。2016年Gartner智能机器成熟度曲线图中目前处于发展途上的NLP和NLG（以及基于此的智能客服、交流机器人、音频/视频理解等领域）都是典型的RNN应用方向，截至2016年3月，全球已经有将近300家企业活跃于NLP、NLG应用领域。&lt;/p&gt;&lt;p&gt;除了应用在NLP、NLG领域，RNN在计算机机视觉领域也发挥着日益重要的作用。本期青年学者专栏由东南大学的崔振副教授为大家带来递归神经网络学习专题，文章总结了RNN的技术框架与发展脉络梳理，系统介绍了其在计算机视觉领域的最新研究进展，是RNN在计算机视觉领域的一个前沿技术综述。&lt;/p&gt;&lt;p&gt;（本导读由线性资本提供）&lt;/p&gt;&lt;p&gt;递归神经网络(Recurrent Neural Network, RNNs)的研究最近取得了很大进展。其(成功)应用包括手写识别[Graves09]、语音识别[Graves13]、自然语言处理[Sutskever11][Sutskever14]以及计算机视觉等一系列问题。从生物机理上来看，这种类型的网络可以认为对神经系统的环式连接(recurrent connection)的一种简单模拟。环式连接(recurrent connection)在新大脑皮质(neocortex)上是普遍存在的，从侧面反映了人类学习是一个动态变化的过程。因而对它的建模是有重要意义的。&lt;/p&gt;&lt;p&gt;事实上，递归（/循环）思想已经融入许多模式识别和机器学习方法。例如，更抽象的看，深层神经网络中重复的层级结构（如卷积神经网络“卷积(convolution)+池化(pooling)”层）；级联式(cascade)模型中重复的迭代操作（如级联式形状回归）；迭代优化方法（如Adaboost）等。&lt;/p&gt;&lt;p&gt;另外，我们知道“图像/图像集（视频）中上下文纹理（texture）信息的关联性是普遍存在的”。首先，单个图像内部的空间区域之间存在大范围的(long-range)相互依赖性。其次，图像集内部不同图像之间存在一定的纹理关联性，例如一个人不同姿态的人脸图像或同一主题的视频片段。编码这种依赖关系对图像内部的结构描述、以及图像之间（即时域）的关联关系对图像/图像集的表示和分析是十分重要的。而这些上下文纹理关联性可以转化为结构化的循环依赖关系，即采用递归神经网络表示。&lt;/p&gt;&lt;p&gt;RNN通常用于描述动态时间行为序列，将状态在自身网络中循环传递，可以接受更为广泛的时序序列结构输入。不同于前馈深层神经网络，RNN更重视网络的反馈作用。由于存在当前状态和过去状态的连接，RNN可以具有一定的记忆功能。当前代表性的递归神经网络包括传统RNN模型，长短期记忆神经网络(long short-term memory, LSTM) [Hochreiter97]以及GRU(gated recurrent unit)模型[Cho14], 如图1所示。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/a5a6afde66dec7f7eac7bfd44e2b6c94.jpg" data-rawwidth="592" data-rawheight="212"&gt;LSTM模型包括输入门(input gate)、输出门(output gate)、忘记门(forget gate)和专门的记忆存储单元(memory cell)，适合于处理和预测时间序列中间隔和延迟非常长的重要事件。GRU模型可以看作是LSTM的变种。Chung等[Chung15]对LSTM和GRU进行了广泛的评测发现：LSTM中最重要的是忘记门，其次是输入门，最后是输出门；GRU相比于LSTM更加具有竞争力。&lt;p&gt;RNN通常用来建模视频序列以及它们之间的依赖关系。其优点是可以用RNN将一段视频编码为固定长度的表示，进而可以采用另外的RNN解码器作用于不同的任务。例如，建模视频表示的无监督RNN学习[Srivastava15]和视频序列预测的递归CNN网络[Donahue15]等。另外，利用序列帧的时间信息，RNN可以应用于视频序列中显著点检测以及行为识别等问题。Gregor等[Gregor15]通过模拟人类视觉关注机制修订了自编码机框架来重复迭代生成图像。Mnih等[Mnih14]提出自适应地选取显著区域的动态视觉控制系统，它可以在不需要任何训练信息情况下实现跟踪比较简单的目标。Yang等[Yang15]采用循环自编码机的策略学习大规模网上视频数据中的重要视频事件。为了捕获视频序列中的运动行为信息，微分(differential)递归神经网络[Veeriah15]在LSTM中引入了两个状态的差信息来描述前后帧之间的信息变化量。针对人体行为任务，Du等[Du15]建立了基于人体骨架(skeleton)的分层RNN网络模型，Fragkiadaki等[Fragkiadaki15]提出了ERD(encoder-recurrent-decoder)网络模型。RNN也被尝试应用于视频目标跟踪任务，以建立序列帧的动态依赖性[Gan15][Ondruska16]。此外，Huang等[Huang15]提出了基于双向RNN网络的视频超分辨率(super-resolution, SR)方法。&lt;/p&gt;&lt;p&gt;RNN也用来建模图像空间域的依赖性。这仅需要采用一些规则遍历二维平面以形成能使用RNN描述的序列，其代表性模型是多维RNN模型[Graves09a]。目前主要的应用领域包括场景标注(scene labeling)[Pinheiro14][Liang15]和图像分割(segmentation)。Pinheiro等[Pinheiro14]重复利用CNN网络模型的场景标注方法，Shuai等[Shuai15]和Byeon等[Byeon15]利用四个方向的RNN子网络来完成图像标注任务，Liang等[Liang15][Liang15a]提出带有层内反馈连接的卷积神经网络并应用于场景标注和物体识别。Visin等[Visin15a]提出了不断堆积多层RNN模型的Reseg网络以用于图像分割任务。此外，通过利用RNN建模大范围(long-range)依赖性的能力，Theis等[Theis15]提出了基于空间LSTM的纹理合成方法。&lt;/p&gt;&lt;p&gt;RNN最近也用来生成描述图像文字的跨模态任务[Mao2015][Karpathy15] [Chen15]。它们通常采用RNN网络建模语句，CNN网络提取图像特征表示，并尝试设置跨模态嵌入层以完成模态之间的交互。&lt;/p&gt;&lt;p&gt;通过观察可以发现，上述RNN基本上是建模数据序列的，可以统称为时间递归神经网络(recurrent neural network, RNN)。除此之外，另一种网络是结构递归神经网络(recursive neural network, RNN)。这类网络通常用来建模循环或迭代的学习过程。Socher等[Socher11]采用RNN建模树形结构的图像内容解析(parsing)过程。Zheng等[Zheng15]将复杂的条件随机场建模为RNN网络，并成功应用于图像分割任务。最近，Visin等[Visin15]提出了Renet网络，它重新设计CNN为多层RNN模型，并在物体分类上获得了可以与CNN相匹配的性能。&lt;/p&gt;&lt;p&gt;针对RNN网络的训练，常用方法是采用BPTT(back propagation through time)梯度下降方法。但由于需要学习长期的依赖性，RNN训练通常伴随着梯度衰退缓慢和梯度爆炸增长现象[Pascanu13]。为了避免这些问题，可以采用特有的一些策略[Bengio13a]，如梯度截断(clipping)。此外，为了缓解训练RNN模型的共适应(co-adaptation)问题，Zaremba等[Zaremba15]提出了如何在RNN中正确使用dropout策略。针对一阶梯度收敛慢的问题，基于Hessian矩阵的二阶优化方法[Martens11][Cho15]最近也被提出。&lt;/p&gt;&lt;p&gt;除此之外，一些学者对RNN模型本身进行了初步探索。Pascanu等[Pascanu14]在RNN网络的不同位置增加深度以形成不同类型深层网络。Jozefowicz等[Jozefowicz15]对LSTM和GRU进行了系统性的实验比较，并进一步提出了一些性能可与之匹配的RNN变种。另外，文献[Lipton15]回顾了最近RNN的相关工作。&lt;/p&gt;&lt;p&gt;&lt;b&gt;下面简单介绍最近的一些文章/工作：&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;1.Recurrent Attentional Networks for Saliency Detection&lt;/b&gt;&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/9e44b8b52769333bd189998b2acd267a.jpg" data-rawwidth="674" data-rawheight="781"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/99431ea3589a90f0e0354c867703ae70.jpg" data-rawwidth="621" data-rawheight="57"&gt;本文在常用的convolutional-deconvolution neural network（CNN-DeCNN）方法的基础上提出了一种recurrent attentional convolutional-deconvolution neural network (RACDNN)的方法用于检测图像中的显著区域。该方法将递归神经网络（RNN）的思想用于CNN-DeCNN的框架中，相比于传统的CNN-DeCNN方法具有以下优点：&lt;p&gt;1.在处理多尺度情况下的物体时，RACDNN可以实现精细的显著区域检测，而CNN-DeCNN方法难以达到很好的效果。&lt;/p&gt;&lt;p&gt;2.在RACDNN迭代检测的过程中，之前迭代的信息可以为本轮迭代时的显著区域检测提供上下文信息。即图像中距离较远的子区域之间可以提供相关信息。&lt;/p&gt;&lt;p&gt;算法流程：&lt;/p&gt;&lt;p&gt;1.用在ImageNet上训练好的CNN-DeCNN生成粗略的显著区域检测结果。&lt;/p&gt;&lt;p&gt;2. 用空间转换矩阵生成RNN的输入图像序列，序列中的图像为原图像的子区域。&lt;/p&gt;&lt;p&gt;3.子区域图像序列送入两层的RNN中，对于RNN第一层的输出用DeCNN进行解码，并使用解码的结果对粗略显著检测结果中对应于该子区域的部分进行细化。RNN第一层可以表示为：&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/009b604807fde3b9abc23b48f40e808a.jpg" data-rawwidth="310" data-rawheight="64"&gt;&lt;p&gt;4.RNN的第二层的输出用于生成空间转换矩阵。空间转换矩阵用于生成RNN的输入图像子区域序列，以及生成RNN第一层的解码结果对应于粗略的显著检测结果的位置。 RNN的第二层可表示为：&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/5726ea7dbd8a74a7812c7d356c682afb.jpg" data-rawwidth="267" data-rawheight="54"&gt;粗略的显著区域检测结果细化后即得到最终的显著检测结果。&lt;p&gt;&lt;b&gt;2.Structure Inference Machines: Recurrent Neural Networks for Analyzing Relations in Group Activity Recognition&lt;/b&gt;&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/f05f82d605682291bbe93f5cf7aebdea.jpg" data-rawwidth="676" data-rawheight="212"&gt;本文的任务是完成对图像中群体的行为识别。通过将整幅图像的场景以及图中的每个人都视为节点，本文将图模型的思想整合到深度神经网络中提出了Structure Inference Machine（SIM）。SIM对个体到个体，个体到场景，以及场景到个体之间的信息传递（message passing）进行建模，从而对群体行为进行分析。该方法流程为：&lt;p&gt;1.对于给定的图片，将整幅图像以及图像中的个人送入CNN中得到节点的描述，并对节点之间的信息传递进行初始化。&lt;/p&gt;&lt;p&gt;2.对节点之间的信息建立RNN模型。通过对各个节点间的信息传递进行反复迭代，从而获得观测节点的边缘分布。节点间的信息传递可分为三类：（1）从个体节点到个体节点的信息传递，（2）从图像节点到个体节点的信息传递，（3）从个体节点到图像节点的信息传递&lt;/p&gt;&lt;p&gt;3.计算节点之间的门限函数。对各个节点之间的信息传递设置门限从而学习到整体的结构信息。&lt;/p&gt;&lt;p&gt;4.最后，对各个节点预测该节点的行为类别。&lt;/p&gt;&lt;p&gt;&lt;b&gt;3.ReNet: A Recurrent Neural Network Based Alternative to Convolutional Networks&lt;/b&gt;&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/f1aa46b3e401aaff99e7fe9e84e758b7.jpg" data-rawwidth="690" data-rawheight="221"&gt;本文采用递归神经网络（RNN）代替卷积神经网络中的卷积层和池化（pooling）层，提出了一种新的网络：ReNet。相比于原网络，改进后的网络优点在于：卷积操作仅能利用到图像的局部信息，而ReNet在处理图像时，之前扫描过的图像序列的信息可以传播到当前状态下，从而该操作可以利用到整幅图像的整体信息。&lt;p&gt;ReNet一层的具体操作为：首先将一幅图像分成若干个互不重叠的子区域，然后按照一定的方向对图像区域进行扫描，并按顺序输入RNN层并更新RNN层的隐状态，该过程可以表述为：&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/4b1a7eca8b2f54dc05dedd4bd1704e15.jpg" data-rawwidth="592" data-rawheight="130"&gt;&lt;p&gt;重复堆积该层并加入全连接层和Softmax层就可以组成深层的ReNet网络。&lt;/p&gt;&lt;p&gt;&lt;b&gt;4.Recurrent Convolutional Network for Video-based Person Re-Identification&lt;/b&gt;&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/29e8296119573c8f3d8f518a203ec23c.jpg" data-rawwidth="684" data-rawheight="393"&gt;本文将CNN和RNN网络相结合，提出了一种鉴定视频中人的身份的网络。在CNN的基础上加入RNN使得该网络可以处理视频序列，而在RNN层上加入时域池化（Temporal Pooling）层使得该网络可以处理任意长度的视频，缓解RNN的强判别性的状态向后几帧偏移，以及解决视频序列的多尺度问题。本文使用的时域池化操作包含时域平均池化和时域最大池化两种。&lt;p&gt;在训练阶段，CNN的输入为彩色图像以及该图像对应的光流图。两段视频被同时输入到该网络，而两段视频中的人可以是相同身份或不同身份。该网络采用了两种损失函数联合对网络参数进行调整。总的损失函数可以表示如下：&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/5fa82d8fb9e8ad3aa862c85e1e5999dc.jpg" data-rawwidth="445" data-rawheight="176"&gt;E在两组视频所包含的人的身份相同或不同时分别对应不同的输出，而则为Softmax函数。&lt;p&gt;在测试时，对于输入的视频提取时域池化层输出的特征，并使用该特征通过计算马氏距离来确定视频中人的身份。&lt;/p&gt;&lt;p&gt;&lt;b&gt;5.Recurrent Face Aging&lt;/b&gt;&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/e3f84ce117cf9fb03180eb5d1850ee77.jpg" data-rawwidth="695" data-rawheight="261"&gt;本文解决一个比较难的问题，即跨年龄人脸的验证和识别问题。在本文中，提出了一种基于递归神经网络的recurrent face aging (RFA) 网络框架。该框架可以确定从0~80 岁的人脸变化。&lt;p&gt;由于缺乏同一个人不同年龄的带标签的人脸数据，传统的人脸老化模型一般是将年龄分割成离散的组。一个人某个年龄的人脸数据直接由其相邻的另一个不同年龄的数据经过特征变换获得。然而，这些方法忽视了相邻年龄组之间固有的进化状态。合成之后的人脸往往具有一些重影尾迹。因为人脸老化是一个平滑的过程，所以它更适合采用平滑变化的状态来估计人脸的年龄。&lt;/p&gt;&lt;p&gt;这种思路与递归神经网络的思想相合。所以本文采用基于GRU的递归神经网络模型来模拟这种年龄缓慢变化的状态。&lt;/p&gt;&lt;p&gt;&lt;b&gt;6.Recurrent Shape Regression&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这是我们组的工作，形状检测可以建模为一个渐进式的非线性回归过程，如图(a)展示的级联式形状回归模型。依据当前第t步估计的形状，采用特征提取函数抽取表示当前形状的表观纹理特征，然后通过回归函数预测接下来的形状。在若干个迭代阶段(stage)之后，期望估算的形状逼近于真实形状。显然，级联式回归存在一些不足之处：(i)每一个回归阶段是相对孤立的；(ii)每一个阶段的回归子一旦训练好之后则固定不变。这意味着每一回归子拥有自己特有的定义空间。如果上一阶段的输出在当前阶段的定义空间之内，则形状预测能顺利进行，否则，其预测的形状很容易发散。&lt;/p&gt;&lt;p&gt;我们拟采取的研究方案是构建递归形状模型，如图(b)所示每一阶段使用共享的模型。&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/b8663b8ecd92a10e8057a1b106a45e2d.jpg" data-rawwidth="597" data-rawheight="147"&gt;但这个模型可以根据当前形状而进行动态调整，即建立形状依赖的回归子。我们拟将该动态回归子参数化如下&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/979b849bdd9e2b15963ff9f9ae055962.jpg" data-rawwidth="269" data-rawheight="44"&gt;&lt;p&gt;该递归形状回归框架与基本步骤如图5所示。&lt;/p&gt;&lt;p&gt;针对形状依赖的回归子，可以借鉴三路神经网络(3-way neural network)进行参数化如下：&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/399afef6684aea77f2cdcbc604f32860.jpg" data-rawwidth="292" data-rawheight="43"&gt;其中“.”表示逐元素的相乘操作，是一般的S型函数，是矩阵形式的参数。&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/ff1941a0f2b6788f5b520c8b4c888249.jpg" data-rawwidth="610" data-rawheight="224"&gt;一阶递归形状回归。在(a)中，每个递归单元包括两个基本步骤：动态回归子学习(橘色线条)和形状预测(黑色虚线)。模型参数包括&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/92dd0a5e19a4d1fa9e7b5bf03a739374.jpg" data-rawwidth="212" data-rawheight="41"&gt;&lt;p&gt;它们在整个回归过程中作为共享模型。&lt;/p&gt;&lt;p&gt;进一步，可以建立回归子&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/84d3356032baf5a928d9b19468d20634.jpg" data-rawwidth="216" data-rawheight="45"&gt;之上的回归操作，即高阶回归子。高阶回归子表示状态变化的二阶信息，因此可以建模更为复杂的数据。其形式化可以表示为，&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/b68c93d5ad6a53b4ba213bf1f8638254.jpg" data-rawwidth="255" data-rawheight="41"&gt;最后，可以构建一个端到端的一体式递归网络。这将涉及到形状索引的特征梯度计算问题。对此我们将特征提取过程建模为可以进行梯度反向传播的神经网络。一种直接的做法是采用现有的卷积神经网络，如VGG，GoogLeNet等。但缺点是需要花费很高的计算代价，以致于形状检测速度较慢。另一种方法构建简单的基于统计特征的学习网络，如图所示构建类似于梯度直方图特征的神经网络。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/799f3a700d158bac71cc08782f6ef0ec.jpg" data-rawwidth="546" data-rawheight="165"&gt;&lt;b&gt;7.Recurrently Target-Attending Tracking&lt;/b&gt;&lt;p&gt;本文主要贡献有：(i)多方向空间递归神经网络生成候选目标区域的置信图谱, 以便预测可信区域、抑制噪声区域；(ii) 提出正则化的关联滤波器(Correlation Filter, CF), 以加权跟踪滤波器学习过程；(iii) 提出低复杂度的封闭形式的解，通过因子化分解矩阵，将原解从复杂度&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/758466dd4e92fbdb46db6b9ea6e713f2.jpg" data-rawwidth="203" data-rawheight="39"&gt;。整个框架如下图。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/5ce2ee2e272db1d45ff97ab314c74ed4.jpg" data-rawwidth="597" data-rawheight="464"&gt;&lt;b&gt;致谢：&lt;/b&gt;在本文写作过程中，张桐、李阳参与了文献整理和文章修订，在此表示感谢。此外，感谢深度学习大讲堂青年学者专栏的邀请。&lt;p&gt;&lt;b&gt;该文章属于“深度学习大讲堂”原创，如需要转载，请联系&lt;a href="https://www.zhihu.com/people/guo-dan-qing" data-editable="true" data-title="@果果是枚开心果. "&gt;@果果是枚开心果. &lt;/a&gt;&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;作者简介：&lt;/b&gt;&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/42beee9e0c3190f3871ae7aba539ab3d.jpg" data-rawwidth="114" data-rawheight="118"&gt;&lt;b&gt;崔振，&lt;/b&gt;Zhen Cui Received the Ph.D. degree in computer science from Institute of Computing Technology (ICT), Chinese Academy of Science (CAS), Beijing, in Jun. 2014. He was a Research Fellow in the Department of Electrical and Computer Engineerning at National University of Singapore (NUS) from Sep. 2014 to Nov. 2015. He also spent half an year as a Research Assistant on Nanyang Technological University (NTU) from Jun. 2012 to Dec. 2012. Now he is an Associate Professor of Southeast University, China. His research interests cover computer vision, pattern recognition and machine learning, Especially focusing on deep learning, manifold learning, sparse coding, face detection/alignment/recognition, object tracking, image super resolution, emotion analysis, etc. More details can be found in &lt;a href="http://aip.seu.edu.cn/zcui/" data-editable="true" data-title="seu.edu.cn 的页面"&gt;http://aip.seu.edu.cn/zcui/&lt;/a&gt; .&lt;p&gt;&lt;b&gt;青年学者专栏介绍：&lt;/b&gt;&lt;/p&gt;&lt;p&gt;深度学习大讲堂青年学者专栏面向在人工智能领域取得博士学位，在科研机构任职、年龄四十周岁以内的青年教师，提供一个系统性介绍个人研究成果、分析研究领域发展趋势的原创内容发布平台。青年学者专栏第一季由线性资本提供赞助，设置以下两个奖项：&lt;/p&gt;&lt;p&gt;1. 最受关注文章奖：根据文章发表后一周内的阅读人数（以微信后台七天阅读量统计数据为准）对单篇阅读量进行排序，给予阅读量靠前文章的作者“最受关注文章奖”。&lt;/p&gt;&lt;p&gt;2.最佳文章奖：在一季文章发表结束之后由公众号粉丝参与投票，按得票高低授予“最佳文章奖”。&lt;/p&gt;&lt;p&gt;&lt;b&gt;奖项设置：&lt;/b&gt;&lt;/p&gt;&lt;p&gt;1.最受关注文章奖奖品设置：&lt;/p&gt;&lt;p&gt;线性资本纪念T恤一件+王淮签名《打造Facebook》一本。&lt;/p&gt;&lt;p&gt;2.最佳文章奖奖品设置：&lt;/p&gt;&lt;p&gt;Rokid一台&lt;/p&gt;&lt;p&gt;http://weixin.qq.com/r/r0grM8bEXpshrYJQ9x29 (二维码自动识别)&lt;/p&gt;&lt;p&gt;&lt;b&gt;原文链接：&lt;a href="http://mp.weixin.qq.com/s?__biz=MzI1NTE4NTUwOQ==&amp;amp;mid=2650325311&amp;amp;idx=1&amp;amp;sn=fa4cedfffe6cd0ecd0158fd60ad5d95d&amp;amp;scene=0#wechat_redirect" class="" data-editable="true" data-title="【青年学者专栏】递归神经网络(Recurrent Neural Network)学习"&gt;【青年学者专栏】递归神经网络(Recurrent Neural Network)学习&lt;/a&gt;&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;欢迎大家关注我们的微信公众号，搜索微信名称：深度学习大讲堂&lt;/b&gt;&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/a29f11daca9717751e639f2c3a3f8b93.jpg" data-rawwidth="346" data-rawheight="67"&gt;</description><author>程程</author><pubDate>Fri, 26 Aug 2016 16:48:57 GMT</pubDate></item><item><title>一箭N雕：多任务深度学习实战</title><link>https://zhuanlan.zhihu.com/p/22190532</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/e699c849e7a73a2d154e191b9ecce583_r.jpg"&gt;&lt;/p&gt;深度学习大讲堂致力于推送人工智能，深度学习方面的最新技术，产品以及活动。请关注我们的知乎专栏！&lt;b&gt;1、多任务学习导引&lt;/b&gt;&lt;p&gt;多任务学习是机器学习中的一个分支，按1997年综述论文Multi-task Learning一文的定义：Multitask Learning (MTL) is an inductive transfer mechanism whose principle goal is to improve generalization performance. MTL improves generalization by leveraging the domain-specific information contained in the training signals of related tasks. It does this by training tasks in parallel while using a shared representation。翻译成中文：&lt;b&gt;多任务学习是一种归纳迁移机制，基本目标是提高泛化性能。多任务学习通过相关任务训练信号中的领域特定信息来提高泛化能力，利用共享表示采用并行训练的方法学习多个任务。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;顾名思义，多任务学习是一种同时学习多个任务的机器学习方法，如图1所示，多任务学习同时学习了人类和狗的分类器以及男性和女性的性别分类器。&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/b1de394956e26f05b0b26fe456e2790f.jpg" data-rawwidth="602" data-rawheight="399"&gt;进一步的，图2所示为单任务学习和多任务学习的对比。在单任务学习中，每个任务采用单独的数据源，分别学习每个任务单独的模型。而多任务学习中，多个数据源采用共享表示同时学习多个子任务模型。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/14958f1dd0c41e7cc38d807d899c88fb.jpg" data-rawwidth="654" data-rawheight="238"&gt;多任务学习的基本假设是多个任务之间具有相关性，因此能够利用任务之间的相关性互相促进。例如，属性分类中，抹口红和戴耳环有一定的相关性，单独训练的时候是无法利用这些信息，多任务学习则可以利用任务相关性联合提高多个属性分类的精度，详情可参考文章Maryland大学Hand等人的论文Attributes for Improved Attributes: A Multi-Task Network for Attribute Classification。&lt;p&gt;&lt;b&gt;2、多任务深度学习&lt;/b&gt;&lt;/p&gt;&lt;p&gt;近年来，在深度学习技术的推动下计算机视觉领域取得了突飞猛进的进展。本质上说，深度学习是多层的神经网络，对输入进行了层级的非线性表示，来自网络可视化的证据表明，深度网络的层级表示从语义上从底层到高层不断递进。深度网络强大的表示能力，使得多任务深度学习有了施展的空间。图3所示为多任务深度网络结构示意图。Input x表示不同任务的输入数据，绿色部分表示不同任务之间共享的层，紫色表示每个任务特定的层，Task x表示不同任务对应的损失函数层。在多任务深度网络中，低层次语义信息的共享有助于减少计算量，同时共享表示层可以使得几个有共性的任务更好的结合相关性信息，任务特定层则可以单独建模任务特定的信息，实现共享信息和任务特定信息的统一。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/491dfbb620d09b16164ba118fd7dd846.jpg" data-rawwidth="654" data-rawheight="428"&gt;在深度网络中，多任务的语义信息还可以从不同的层次输出，例如GoogLeNet中的两个辅助损失层。另外一个例子比如衣服图像检索系统，颜色这类的信息可以从较浅层的时候就进行输出判断，而衣服的样式风格这类的信息，更接近高层语义，需要从更高的层次进行输出，这里的输出指的是每个任务对应的损失层的前一层。&lt;p&gt;&lt;b&gt;3、多任务深度学习应用案例&lt;/b&gt;&lt;/p&gt;&lt;p&gt;目前，多任务深度学习已经广泛应用于人脸识别、细粒度车辆分类、面部关键点定位与属性分类等多个领域，以下讲介绍其中的代表性论文。&lt;/p&gt;&lt;p&gt;&lt;b&gt;3.1人脸识别网络 DeepID2&lt;/b&gt;&lt;/p&gt;&lt;p&gt;香港中文大学汤晓鸥组发表在NIPS14的论文Deep Learning Face Representation by Joint Identification-Verification，提出了一种联合训练人脸确认损失和人脸分类损失的多任务人脸识别网络DeepID2，网络结构如下图所示：&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/d6ead51e61685a5aa2540dc15de658ca.jpg" data-rawwidth="656" data-rawheight="245"&gt;DeepID2中共有两个损失函数，分别为人脸分类损失函数，对应于Caffe中的SoftmaxLoss：&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/fe13cfada0e1117d4396ccdb945c0dc4.jpg" data-rawwidth="554" data-rawheight="89"&gt;另外一个是人脸确认损失函数，对应于Caffe中的Contrastive Loss：&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/66457fd21f15d577410c21a1009625e0.jpg" data-rawwidth="655" data-rawheight="105"&gt;&lt;b&gt;3.2细粒度车辆分类网络&lt;/b&gt;&lt;p&gt;这里介绍一个比较有趣的将SoftmaxLoss和TripletLoss结合在一个网络中进行多任务训练的方法Embedding Label Structures for Fine-Grained Feature Representation，目前文章发表于arXiv。作者将这个网络用于细粒度车辆分类上，提醒注意的是为了计算Tiplet Loss，特征进行了L2范数归一操作，网络结构如下图所示：&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/249eecc91d0bb8a603fe159da0bb4999.jpg" data-rawwidth="656" data-rawheight="257"&gt;&lt;b&gt;3.3物体检测网络Faster R-CNN&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在物体检测网络Faster R-CNN中也有多任务学习的应用。Faster R-CNN的网络结构如下图6所示，包含两个任务，分别为窗口回归和窗口分类，其中RPN模块的卷积层在两个任务之间共享。Faster R-CNN的最新版本支持整体端到端训练，可以同时检测多类物体，是目前最具代表性的目标检测框架，同时也是多任务深度学习的一个典型应用。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/f8c550c87113abff9227d76ea7596465.jpg" data-rawwidth="417" data-rawheight="458"&gt;&lt;b&gt;3.4面部关键点定位与属性分类网络TCDCN&lt;/b&gt;&lt;p&gt;面部关键点估计和头部姿态以及人脸属性（是否戴眼镜、是否微笑和性别）之间有着紧密的联系，香港中文大学汤晓鸥组发表于ECCV14的工作Facial Landmark Detection by Deep Multi-task Learning利用多任务学习方法联合进行人脸面部关键点定位和属性预测，网络结构如下图7所示。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/60de2c4a83c508fe4188ce440ccdcd75.jpg" data-rawwidth="653" data-rawheight="279"&gt;&lt;b&gt;4、基于Caffe实现多任务学习的小样例&lt;/b&gt;&lt;p&gt;本节在目前广泛使用的深度学习开源框架Caffe的基础上实现多任务深度学习算法所需的多维标签输入。默认的，Caffe中的Data层只支持单维标签，为了支持多维标签，首先修改Caffe中的convert_imageset.cpp以支持多标签：&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/cab4344739d2a63ddf586f3c1a43cd6b.jpg" data-rawwidth="677" data-rawheight="391"&gt;这样我们就有了多任务的深度学习的基础部分数据输入。为了向上兼容Caffe框架，本文摒弃了部分开源实现增加Data层标签维度选项并修改Data层代码的做法，直接使用两个Data层将数据读入，即分别读入数据和多维标签，接下来介绍对应的网络结构文件prototxt的修改，注意红色的注释部分。&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/5a3c8a2e1b8a8b85d7ee918ba2129eb6.jpg" data-rawwidth="680" data-rawheight="755"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/79172b5ac11d1240bcb277c29e0b842d.jpg" data-rawwidth="680" data-rawheight="453"&gt;特别的，slice层对多维的标签进行了切分，为每个任务输出了单独的标签。&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/7b2c36e796dc05a284a6770d9717026b.jpg" data-rawwidth="680" data-rawheight="390"&gt;另外一个值得讨论的是每个任务的权重设置，在本文实践中五个任务设置为等权重loss_weight:0.2。一般的，建议所有任务的权重值相加为1，如果这个数值不设置，可能会导致网络收敛不稳定，这是因为多任务学习中对不同任务的梯度进行累加，导致梯度过大，甚至可能引发参数溢出错误导致网络训练失败。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/b3fb3264d7335ac49b383edcccb9f9bf.jpg" data-rawwidth="680" data-rawheight="200"&gt;本文的完整代码可在作者个人的github主页下载：&lt;p&gt;&lt;a href="https://github.com/HolidayXue/CodeSnap/blob/master/convert_multilabel.cpp" data-title="CodeSnap/convert_multilabel.cpp at master · HolidayXue/CodeSnap · GitHub" class="" data-editable="true"&gt;CodeSnap/convert_multilabel.cpp at master · HolidayXue/CodeSnap · GitHub&lt;/a&gt;&lt;/p&gt;&lt;p&gt;多任务损失函数层的网络结构示意图如下图所示：&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/d95df53e1f489dab9e3b3beee4ce2dc2.jpg" data-rawwidth="661" data-rawheight="318"&gt;&lt;b&gt;5. 总结&lt;/b&gt;&lt;/p&gt;&lt;p&gt;本文回顾了多任务学习的基本概念，并讨论了多任务深度学习的基本思想和应用案例。最后以开源深度学习平台Caffe为例讨论了多任务深度学习的实现，并给出了开源代码。&lt;/p&gt;&lt;p&gt;&lt;b&gt;致谢&lt;/b&gt;&lt;/p&gt;&lt;p&gt;本文在投稿之后经历了三轮修改，其中一轮公众号编辑部初审，一轮双盲评审大改和一轮单盲评审小修，两名审稿专家对原文进行了全面仔细的阅读，帮助作者修正了文章的若干理论表述，给出了建设性的提高可读性的修改意见。在此本文作者对全体审稿人表示感谢，并对深度学习大讲堂公众号编辑部耐心细致的审稿服务表示感谢。&lt;/p&gt;&lt;p&gt;&lt;b&gt;该文章属于“深度学习大讲堂”原创，如需要转载，请联系&lt;a href="https://www.zhihu.com/people/guo-dan-qing" class="" data-editable="true" data-title="@果果是枚开心果"&gt;@果果是枚开心果&lt;/a&gt;. &lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;作者简介：&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/b7b1da49d45ed76497817fac9674fe7b.jpg" data-rawwidth="262" data-rawheight="330"&gt;&lt;strong&gt;薛云峰&lt;/strong&gt;，(&lt;a href="https://github.com/HolidayXue" data-editable="true" data-title="HolidayXue (HolidayXue) · GitHub" class=""&gt;HolidayXue (HolidayXue) · GitHub&lt;/a&gt;)，主要从事视频图像算法的研究，就职于浙江捷尚视觉科技股份有限公司担任深度学习算法研究员。捷尚致力于视频大数据和视频监控智能化，现诚招业内算法和工程技术人才，招聘主页&lt;a href="http://www.icarevision.cn/job.php" data-editable="true" data-title="浙江捷尚视觉科技股份有限公司--安全服务运营商"&gt;浙江捷尚视觉科技股份有限公司--安全服务运营商&lt;/a&gt;，联系邮箱：hr@icarevision.cn&lt;/p&gt;&lt;p&gt;&lt;b&gt;原文链接：&lt;a href="http://mp.weixin.qq.com/s?__biz=MzI1NTE4NTUwOQ==&amp;amp;mid=2650325281&amp;amp;idx=1&amp;amp;sn=97779ff0da06190d6a71d33f23e9dede&amp;amp;scene=0#wechat_redirect" data-editable="true" data-title="一箭N雕：多任务深度学习实战" class=""&gt;一箭N雕：多任务深度学习实战&lt;/a&gt;&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;欢迎大家关注我们的微信公众号，搜索微信名称：深度学习大讲堂&lt;/b&gt;&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/a29f11daca9717751e639f2c3a3f8b93.jpg" data-rawwidth="346" data-rawheight="67"&gt;</description><author>程程</author><pubDate>Fri, 26 Aug 2016 16:01:44 GMT</pubDate></item><item><title>天津大学深度学习一线实战研讨班干货总结与资源下载</title><link>https://zhuanlan.zhihu.com/p/22174260</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/b39c056117ec2b1394b642a3887ec970_r.jpg"&gt;&lt;/p&gt;深度学习大讲堂致力于推送人工智能，深度学习方面的最新技术，产品以及活动。请关注我们的知乎专栏！&lt;p&gt;&lt;strong&gt;摘要&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;本文总结了2016年7月16、17日由天津大学主办，南开大学和深度学习大讲堂联合协办的深度学习一线实战暑期研讨班的干货内容，包括六场深度学习实战技术讲座，两场赞助商特别宣讲，讲座Slides可下载同时提供录播视频。&lt;/p&gt;&lt;p&gt;&lt;b&gt;讲座1. 深度学习基础&lt;/b&gt;&lt;/p&gt;&lt;p&gt;主讲人为中科院计算所VIPL实验室的博士生刘昕。本次讲座介绍了深度学习的基本概念和在计算机视觉领域取得的诸多革命性进步，从大历史的视角回顾了人工神经网络的研究的两次寒冬和三次兴起，从微观技术细节的角度介绍了深度学习的基础结构模块、损失函数和优化算法。&lt;/p&gt;&lt;p&gt;&lt;b&gt;总结深度学习带来的方法革命：&lt;/b&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/1cca2bce7c0ab3296c573a6474b1eb18.jpg" data-rawwidth="645" data-rawheight="194"&gt;&lt;b&gt;回归深度学习的历史进展：&lt;/b&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/9b7868e39f344d58718f025aa00b98f8.jpg" data-rawwidth="669" data-rawheight="443"&gt;&lt;b&gt;总结深度学习的基础知识：&lt;/b&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/2411669b9948f86700f65fa2ed61b9e8.jpg" data-rawwidth="679" data-rawheight="390"&gt;&lt;b&gt;讲座2. CNN基础与Caffe实践&lt;/b&gt;&lt;/p&gt;&lt;p&gt;主讲人为中科院计算所VIPL实验室的博士生刘昕。本次讲座从时间的轴线回顾了卷积神经网络（CNN）的演化脉络，总结了四条结构演化路径。从一线实战的角度，介绍了CNN的应用策略和开源深度学习平台Caffe的使用技巧。&lt;/p&gt;&lt;p&gt;&lt;b&gt;CNN的演化脉络：&lt;/b&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/d418487d83d6ba51973f47c4105b2a21.jpg" data-rawwidth="681" data-rawheight="409"&gt;&lt;b&gt;总结Caffe的核心概念：&lt;/b&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/566ab370c697f8b6b7957e64094ad5c8.jpg" data-rawwidth="556" data-rawheight="359"&gt;&lt;b&gt;深度学习火爆之余的反思：&lt;/b&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/929850b850548b9d7f91663b25f76cb5.jpg" data-rawwidth="533" data-rawheight="360"&gt;&lt;b&gt;讲座3. 人脸识别实战应用案例与经验分享&lt;/b&gt;&lt;/p&gt;&lt;p&gt;主讲人为上海银晨科技的技术总监刘海波。上海银晨科技是一家以人脸识别技术的行业应用为特色的人工智能创新公司。本次讲座是上海银晨科技在人脸识别领域16年的实战经验总结。&lt;b&gt;对人脸识别应用模式的总结：&lt;/b&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/add425acc38502d57e2bb55cc4eaac56.jpg" data-rawwidth="682" data-rawheight="479"&gt;&lt;b&gt;总结人脸识别的技术难点：&lt;/b&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/7b2418ebc31fd51dc6e033a4853e7702.jpg" data-rawwidth="667" data-rawheight="421"&gt;&lt;b&gt;讲座4. 人工智能时代的创业机会&lt;/b&gt;&lt;/p&gt;&lt;p&gt;主讲人为将门联合创始人兼CTO沈强。将门是一家新型创业服务机构，CEO高欣欣、CTO沈强均曾供职于微软创投加速器。本次讲座中，将门CTO沈强分析了国内人工智能企业的创业图谱并对踌躇满志的人工智能创业者给出了中肯的建议。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/a08b5e0a384a6b1e94a63d7ad6e1d91a.jpg" data-rawwidth="550" data-rawheight="444"&gt;&lt;b&gt;国内人工智能初创企业图谱：&lt;/b&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/e05187ff792a9b71682bdb7f18b2873d.jpg" data-rawwidth="669" data-rawheight="362"&gt;&lt;b&gt;讲座5. 阿里云HPC助力人工智能发展&lt;/b&gt;&lt;/p&gt;&lt;p&gt;来自阿里云的技术专家游亮作为工业界特邀嘉宾介绍了阿里云HPC及其在人工智能工业级应用中的加速作用。&lt;b&gt;讲座照片：&lt;/b&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/27cad9cbf524e7c99792031f508dd561.jpg" data-rawwidth="652" data-rawheight="435"&gt;&lt;b&gt;讲座6. 目标检测一唱三叹：更准、更快、更智能&lt;/b&gt;&lt;/p&gt;&lt;p&gt;主讲人为中科院计算所VIPL实验室的博士生邬书哲。目标检测的任务是在给定的图像中判断指定类别的物体是否存在，如果存在则确定其位置和大小，这在现实场景中具有非常广泛的应用。本次报告中介绍了两类目前最为有效的检测框架：Faster R-CNN和Cascade CNN，并对基于半监督学习的目标检测进行简单的介绍。&lt;/p&gt;&lt;p&gt;&lt;b&gt;目标检测的基本思路：&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/17aae2a91bb755d01a78fbf03a42cfe8.jpg" data-rawwidth="642" data-rawheight="414"&gt;&lt;b&gt;Py-Faster-RCNN应用ResNet进行物体检测的实战案例：&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/fcea8d4b69c454a1e1d74e172f40d2c3.jpg" data-rawwidth="478" data-rawheight="444"&gt;&lt;b&gt;人脸检测实战案例：&lt;/b&gt;&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/64f93e8bc1a5febff9a27520f744c13b.jpg" data-rawwidth="654" data-rawheight="451"&gt;&lt;b&gt;讲座7.全卷积网络:实现与应用&lt;/b&gt;&lt;p&gt;主讲人为上海大学沈为博士组研究生赵凯。（FCN）是卷积神经网络的扩展结构，能够高效解决需要像素级理解的场景，例如语义分割、边缘检测、骨架检测等。本报告中介绍FCN的算法原理、在骨架检测方面的扩展工作、源码实现与训练技巧。&lt;b&gt;全卷积网络与经典CNN的对比，从图像级理解到像素级理解：&lt;/b&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/22148f5bc76d8a05765111af22f83e3c.jpg" data-rawwidth="672" data-rawheight="368"&gt;&lt;b&gt;FCN中反卷积层的关键细节：&lt;/b&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/c690fa185599d045d95147fe63d5f73c.jpg" data-rawwidth="658" data-rawheight="352"&gt;&lt;b&gt;主讲人 CVPR16 工作 Object Skeleton Extraction in Natural Images by Fusing Scale-associated Deep Side Outputs 介绍： &lt;/b&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/ed03be2f893bc9431caf4f6f8dba0f40.jpg" data-rawwidth="670" data-rawheight="290"&gt;&lt;b&gt;讲座8. Deep哈希实现案例&lt;/b&gt;&lt;/p&gt;&lt;p&gt;主讲人为中科院计算所VIPL实验室的博士生刘昊淼。哈希算法的目标是用紧致的二值码表示图像，从而高效地进行图像检索任务。随着深度学习的崛起，出现了很多将图像表示学习和二值码学习结合在一起的深度哈希算法。本报告将介绍一些比较有代表性的深度哈希算法，并介绍其代码实现。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Hash算法介绍：&lt;/b&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/a2502ca4eb55fa4e18f7f6f3844b4ee9.jpg" data-rawwidth="656" data-rawheight="359"&gt;&lt;b&gt;主讲人CVPR16工作DSH方法框架介绍：&lt;/b&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/7dd4aceef442787b40675c090cf2e51d.jpg" data-rawwidth="654" data-rawheight="357"&gt;&lt;b&gt;关键实验结果：&lt;/b&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/ed3326f940082ee775779698d927124c.jpg" data-rawwidth="631" data-rawheight="360"&gt;&lt;strong&gt;致谢&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;感谢本次活动的主办方天津大学机器学习与数据挖掘实验室和协办方南开大学媒体计算实验室的大力支持，感谢天津大学胡清华教授、朱鹏飞副教授、张长青博士，南开大学程明明副教授，感谢所有的志愿者。&lt;b&gt;该文章属于“深度学习大讲堂”原创，如需要转载，请联系&lt;a href="https://www.zhihu.com/people/guo-dan-qing" class="" data-editable="true" data-title="@果果是枚开心果"&gt;@果果是枚开心果&lt;/a&gt;. &lt;/b&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/fc3cd584f8e1e7369da11010b0055ec1.jpg" data-rawwidth="652" data-rawheight="461"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/7c741c2bc3c42df444c9b6d0ec71e04c.jpg" data-rawwidth="690" data-rawheight="308"&gt;&lt;b&gt;赞助商将门二维码：&lt;/b&gt;&lt;/p&gt;&lt;p&gt;http://weixin.qq.com/r/ZUi-p3jElCXrrTzE9x13 (二维码自动识别)&lt;/p&gt;&lt;b&gt;赞助商紫牛基金二维码：&lt;/b&gt;&lt;p&gt;http://weixin.qq.com/r/yjgbA4nES9Q0rc1g923Y (二维码自动识别)&lt;/p&gt;&lt;b&gt;Slides及视频下载：&lt;/b&gt;资源页面：&lt;a href="http://datasci.tju.edu.cn/data/index1?sukey=3997c0719f1515200399a26940a285f019a686a850fcc3d81290e00ce57e15e915fbabfbca74f113889c6a7bc0ce4a23" data-editable="true" data-title="Publications"&gt;Publications&lt;/a&gt;&lt;p&gt;&lt;b&gt;原文链接：&lt;/b&gt;&lt;b&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzI1NTE4NTUwOQ==&amp;amp;mid=2650325267&amp;amp;idx=1&amp;amp;sn=e89cfce72e1af9c32bd8be2440a9cfba&amp;amp;scene=0#wechat_redirect" data-editable="true" data-title="天津大学深度学习一线实战研讨班干货总结与资源下载" class=""&gt;天津大学深度学习一线实战研讨班干货总结与资源下载&lt;/a&gt;&lt;/b&gt;&lt;b&gt;欢迎大家关注我们的微信公众号，搜索微信名称：深度学习大讲堂&lt;/b&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/a29f11daca9717751e639f2c3a3f8b93.jpg" data-rawwidth="346" data-rawheight="67"&gt;&lt;/p&gt;</description><author>程程</author><pubDate>Thu, 25 Aug 2016 15:55:38 GMT</pubDate></item><item><title>深度学习中的激活函数导引</title><link>https://zhuanlan.zhihu.com/p/22142013</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/ffa57442611ce65a1665de8e844de768_r.jpg"&gt;&lt;/p&gt;深度学习大讲堂致力于推送人工智能，深度学习方面的最新技术，产品以及活动。请关注我们的知乎专栏！&lt;p&gt;&lt;b&gt;摘要&lt;/b&gt;&lt;/p&gt;&lt;p&gt;近年来，深度学习在计算机视觉领域取得了引人注目的成果，其中一个重要因素是激活函数的发展。新型激活函数ReLU克服了梯度消失，使得深度网络的直接监督式训练成为可能。本文将对激活函数的历史和近期进展进行总结和概括。&lt;/p&gt;&lt;p&gt;&lt;b&gt;激活函数的定义与作用&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在人工神经网络中，神经元节点的激活函数定义了对神经元输出的映射，简单来说，神经元的输出（例如，全连接网络中就是输入向量与权重向量的内积再加上偏置项）经过激活函数处理后再作为输出。加拿大蒙特利尔大学的Bengio教授在 ICML 2016 的文章[1]中给出了激活函数的定义：激活函数是映射 h:R→R，且几乎处处可导。&lt;/p&gt;&lt;p&gt;神经网络中激活函数的主要作用是提供网络的非线性建模能力，如不特别说明，激活函数一般而言是非线性函数。假设一个示例神经网络中仅包含线性卷积和全连接运算，那么该网络仅能够表达线性映射，即便增加网络的深度也依旧还是线性映射，难以有效建模实际环境中非线性分布的数据。加入（非线性）激活函数之后，深度神经网络才具备了分层的非线性映射学习能力。因此，激活函数是深度神经网络中不可或缺的部分。&lt;/p&gt;&lt;p&gt;&lt;b&gt;激活函数的历史发展与近期进展&lt;/b&gt;&lt;/p&gt;&lt;p&gt;从定义来看，几乎所有的连续可导函数都可以用作激活函数。但目前常见的多是分段线性和具有指数形状的非线性函数。下文将依次对它们进行总结。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Sigmoid&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Sigmoid 是使用范围最广的一类激活函数，具有指数函数形状 。正式定义为：&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/d2d1335c99df1923da4f228da3da9bdd.jpg" data-rawwidth="704" data-rawheight="654"&gt;可见，sigmoid 在定义域内处处可导，且两侧导数逐渐趋近于0，即：&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/5f8e0c7f461bef0a54428044b8e5a38a.jpg" data-rawwidth="325" data-rawheight="109"&gt;Bengio 教授等[1]将具有这类性质的激活函数定义为软饱和激活函数。与极限的定义类似，饱和也分为左饱和与右饱和：左饱和：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/be5a0620bf869ba91a44220a7173655d.jpg" data-rawwidth="326" data-rawheight="94"&gt;右饱和：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/80a6f2edd14d4653bd6402eab62b1119.jpg" data-rawwidth="291" data-rawheight="94"&gt;与软饱和相对的是硬饱和激活函数，即：f'(x)=0，当 |x| &amp;gt; c，其中 c 为常数。&lt;p&gt;同理，硬饱和也分为左饱和和右饱和。常见的 ReLU 就是一类左侧硬饱和激活函数。Sigmoid 的软饱和性，使得深度神经网络在二三十年里一直难以有效的训练，是阻碍神经网络发展的重要原因。具体来说，由于在后向传递过程中，sigmoid向下传导的梯度包含了一个f'(x) 因子（sigmoid关于输入的导数），因此一旦输入落入饱和区，f'(x) 就会变得接近于0，导致了向底层传递的梯度也变得非常小。此时，网络参数很难得到有效训练。这种现象被称为梯度消失。一般来说， sigmoid 网络在 5 层之内就会产生梯度消失现象[2]。梯度消失问题至今仍然存在，但被新的优化方法有效缓解了，例如DBN中的分层预训练，Batch Normalization的逐层归一化，Xavier和MSRA权重初始化等代表性技术。Sigmoid 的饱和性虽然会导致梯度消失，但也有其有利的一面。例如它在物理意义上最为接近生物神经元。 (0, 1) 的输出还可以被表示作概率，或用于输入的归一化，代表性的如Sigmoid交叉熵损失函数&lt;/p&gt;&lt;p&gt;&lt;b&gt;tanh&lt;/b&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/adbf164a53f8341cbf3a08c301b99b59.jpg" data-rawwidth="620" data-rawheight="598"&gt;可见，tanh(x)=2sigmoid(2x)-1，也具有软饱和性。Xavier在文献[2]中分析了sigmoid与tanh的饱和现象及特点，具体见原论文。此外，文献 [3] 中提到tanh 网络的收敛速度要比sigmoid快。因为 tanh 的输出均值比 sigmoid 更接近 0，SGD会更接近 natural gradient[4]（一种二次优化技术），从而降低所需的迭代次数。&lt;/p&gt;&lt;p&gt;&lt;b&gt;ReLU&lt;/b&gt;&lt;/p&gt;&lt;p&gt;虽然2006年Hinton教授提出通过分层无监督预训练解决深层网络训练困难的问题，但是深度网络的直接监督式训练的最终突破，最主要的原因是采用了新型激活函数ReLU[5, 6]。与传统的sigmoid激活函数相比，ReLU能够有效缓解梯度消失问题，从而直接以监督的方式训练深度神经网络，无需依赖无监督的逐层预训练，这也是2012年深度卷积神经网络在ILSVRC竞赛中取得里程碑式突破的重要原因之一。ReLU的 正式定义为：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/0effc747d9b2fee78c14e390743fab69.jpg" data-rawwidth="659" data-rawheight="621"&gt;可见，ReLU 在x&amp;lt;0 时硬饱和。由于 x&amp;gt;0时导数为 1，所以，ReLU 能够在x&amp;gt;0时保持梯度不衰减，从而缓解梯度消失问题。但随着训练的推进，部分输入会落入硬饱和区，导致对应权重无法更新。这种现象被称为“神经元死亡”。&lt;/p&gt;&lt;p&gt;ReLU还经常被“诟病”的一个问题是输出具有偏移现象[7]，即输出均值恒大于零。偏移现象和 神经元死亡会共同影响网络的收敛性。本文作者公开在arxiv的文章[8]中的实验表明，如果不采用Batch Normalization，即使用 MSRA 初始化30层以上的ReLU网络，最终也难以收敛。相对的，PReLU和ELU网络都能顺利收敛，这两种改进的激活函数将在后面介绍。实验所用代码见&lt;a href="https://github.com/Coldmooon/Code-for-MPELU/" data-editable="true" data-title="GitHub - Coldmooon/Code-for-MPELU: Code for Improving Deep Neural Network with Multiple Parametric Exponential Linear Units" class=""&gt;GitHub - Coldmooon/Code-for-MPELU: Code for Improving Deep Neural Network with Multiple Parametric Exponential Linear Units&lt;/a&gt; 。&lt;/p&gt;&lt;p&gt;ReLU另外一个性质是提供神经网络的稀疏表达能力，在Bengio教授的Deep Sparse Rectifier Neural Network[6]一文中被认为是ReLU带来网络性能提升的原因之一。但后来的研究发现稀疏性并非性能提升的必要条件，文献 RReLU [9]也指明了这一点。&lt;/p&gt;&lt;p&gt;PReLU[10]、ELU[7]等激活函数不具备这种稀疏性，但都能够提升网络性能。本文作者在文章[8]中给出了一些实验比较结果。首先，在cifar10上采用NIN网络，实验结果为 PReLU &amp;gt; ELU &amp;gt; ReLU，稀疏性并没有带来性能提升。其次，在 ImageNet上采用类似于[11] 中model E的15 层网络，实验结果则是ReLU最好。为了验证是否是稀疏性的影响，以 LReLU [12]为例进一步做了四次实验，负半轴的斜率分别为1，0.5，0.25,  0.1，需要特别说明的是，当负半轴斜率为1时，LReLU退化为线性函数，因此性能损失最大。实验结果展现了斜率大小与网络性能的一致性。综合上述实验可知，ReLU的稀疏性与网络性能之间并不存在绝对正负比关系。&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/1248c4bdbc1285fc1ab1586c25f65c51.jpg" data-rawwidth="690" data-rawheight="311"&gt;&lt;b&gt;PReLU&lt;/b&gt;&lt;/p&gt;&lt;p&gt;PReLU [10]是ReLU 和 LReLU的改进版本，具有非饱和性：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/b4b11ec05caefa5709936aad0c30f18c.jpg" data-rawwidth="717" data-rawheight="677"&gt;与LReLU相比，PReLU中的负半轴斜率a可学习而非固定。原文献建议初始化a为0.25，不采用正则。个人认为，是否采用正则应当视具体的数据库和网络，通常情况下使用正则能够带来性能提升。&lt;/p&gt;&lt;p&gt;虽然PReLU 引入了额外的参数，但基本不需要担心过拟合。例如，在上述cifar10+NIN实验中， PReLU比ReLU和ELU多引入了参数，但也展现了更优秀的性能。所以实验中若发现网络性能不好，建议从其他角度寻找原因。&lt;/p&gt;&lt;p&gt;与ReLU相比，PReLU收敛速度更快。因为PReLU的输出更接近0均值，使得SGD更接近natural gradient。证明过程参见原文[10]。&lt;/p&gt;&lt;p&gt;此外，作者在ResNet 中采用ReLU，而没有采用新的PReLU。这里给出个人浅见，不一定正确，仅供参考。首先，在上述LReLU实验中，负半轴斜率对性能的影响表现出一致性。对PReLU采用正则将激活值推向0也能够带来性能提升。这或许表明，小尺度或稀疏激活值对深度网络的影响更大。其次，ResNet中包含单位变换和残差两个分支。残差分支用于学习对单位变换的扰动。如果单位变换是最优解，那么残差分支的扰动应该越小越好。这种假设下，小尺度或稀疏激活值对深度网络的影响更大。此时，ReLU或许是比PReLU更好的选择。&lt;/p&gt;&lt;p&gt;&lt;b&gt;RReLU&lt;/b&gt;&lt;/p&gt;&lt;p&gt;数学形式与PReLU类似，但RReLU[9]是一种非确定性激活函数，其参数是随机的。这种随机性类似于一种噪声，能够在一定程度上起到正则效果。作者在cifar10/100上观察到了性能提升。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Maxout&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Maxout[13]是ReLU的推广，其发生饱和是一个零测集事件（measure zero event）。正式定义为：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/8358833218327d45cdd3f19a33d5479b.jpg" data-rawwidth="684" data-rawheight="109"&gt;&lt;/p&gt;&lt;p&gt;Maxout网络能够近似任意连续函数，且当w2,b2,…,wn,bn为0时，退化为ReLU。 其实，Maxout的思想在视觉领域存在已久。例如，在HOG特征里有这么一个过程：计算三个通道的梯度强度，然后在每一个像素位置上，仅取三个通道中梯度强度最大的数值，最终形成一个通道。这其实就是Maxout的一种特例。&lt;/p&gt;&lt;p&gt;Maxout能够缓解梯度消失，同时又规避了ReLU神经元死亡的缺点，但增加了参数和计算量。&lt;/p&gt;&lt;p&gt;&lt;b&gt;ELU&lt;/b&gt;&lt;/p&gt;&lt;p&gt;ELU[7]融合了sigmoid和ReLU，具有左侧软饱性。其正式定义为：&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/1f9dfafa84713629c9c9d7f83a65ae7f.jpg" data-rawwidth="658" data-rawheight="561"&gt;&lt;p&gt;右侧线性部分使得ELU能够缓解梯度消失，而左侧软饱能够让ELU对输入变化或噪声更鲁棒。ELU的输出均值接近于零，所以收敛速度更快。经本文作者实验，ELU的收敛性质的确优于ReLU和PReLU。在cifar10上，ELU 网络的loss 降低速度更快；在 ImageNet上，不加 Batch Normalization 30 层以上的 ReLU 网络会无法收敛，PReLU网络在MSRA的Fan-in （caffe ）初始化下会发散，而 ELU 网络在Fan-in/Fan-out下都能收敛 。实验代码见&lt;a href="https://github.com/Coldmooon/Code-for-MPELU/" data-editable="true" data-title="GitHub - Coldmooon/Code-for-MPELU: Code for Improving Deep Neural Network with Multiple Parametric Exponential Linear Units" class=""&gt;GitHub - Coldmooon/Code-for-MPELU: Code for Improving Deep Neural Network with Multiple Parametric Exponential Linear Units&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;论文的另一个重要贡献是分析了Bias shift 现象与激活值的关系，证明了降低Bias shift 等价于把激活值的均值推向0。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Noisy Activation Functions&lt;/b&gt;&lt;/p&gt;&lt;p&gt;engio教授在ICML 2016 提出了一种激活策略[1]，可用于多种软饱和激活函数，例如 sigmoid和 tanh。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/c86a421c50eb93422b429359352e4d6e.jpg" data-rawwidth="665" data-rawheight="763"&gt;当激活函数发生饱和时， 网络参数还能够在两种动力下继续更新：正则项梯度和噪声梯度。引入适当的噪声能够扩大SGD的参数搜索范围，从而有机会跳出饱和区。在激活函数中引入噪声的更早工作可追溯到[5]，但文献[5]的工作并不考虑噪声引入的时间和大小。本篇的特点在于，只在饱和区才引入噪声，且噪声量与饱和程度相关——原式与泰勒展开式一次项之差 δ。算法1中g表示sigmoid，用于归一化 δ。注意，ReLU的 δ恒为0，无法直接加噪声，所以作者把噪声加在了输入上。&lt;p&gt;&lt;b&gt;CReLU&lt;/b&gt;&lt;/p&gt;&lt;p&gt;CReLU [14]是Wenling Shang 发表在 ICML 2016的工作，本篇同样提出了一种激活策略:&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/9ac0d477f5f93582d101fbe34efdab5b.jpg" data-rawwidth="650" data-rawheight="77"&gt;其中，[] 表示 ReLU（其他亦可）。&lt;/p&gt;&lt;p&gt;作者在观察第一层滤波器（filter）时发现，滤波器相位具有成对现象（pair-grouping phenomenon）。这一发现揭示了网络的底层学到了一些冗余滤波器来提取输入的正负相位信息的可能性。因此可以考虑采用适当的操作移除这些冗余滤波器。对此，作者提出了CReLU，将激活函数的输入额外做一次取反，等价于将输入相位旋转180°。这种策略可以看作在网络中加入相位的先验。实验在cifar10上观察到能以更少的参数获得性能提升。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/8fee4c646e207612a5af2b8519e69f62.jpg" data-rawwidth="670" data-rawheight="179"&gt;使用CReLU时，要有意识的将滤波器数量减半，否则， 网络参数变为2倍。&lt;/p&gt;&lt;p&gt;&lt;b&gt;MPELU&lt;/b&gt;&lt;/p&gt;&lt;p&gt;MPELU[8]是我们组的工作，将分段线性与ELU统一到了一种形式下。在NIN+CIFAR10，本文作者发现ELU与LReLU性能一致，而与PReLU差距较大。经过分析，ELU泰勒展开的一次项就是LReLU。当在ELU前加入BN让输入集中在0均值附近， 则ELU与LReLU之差——泰勒展开高次项会变小，粗略估计，约55.57%的激活值误差小于0.01。因此，受PReLU启发，令α可学习能够提高性能。此外，引入参数β能够进一步控制ELU的函数形状。正式定义为：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/db68b78cc73afce863882909ed5c3e52.jpg" data-rawwidth="660" data-rawheight="593"&gt;α 和 β可以使用正则。α, β 固定为1时，MPELU 退化为 ELU； β 固定为很小的值时，MPELU 近似为 PReLU；当α=0，MPELU 等价于 ReLU。&lt;/p&gt;&lt;p&gt;MPELU 的优势在于同时具备 ReLU、PReLU和 ELU的优点。首先，MPELU具备ELU的收敛性质，能够在无 Batch Normalization 的情况下让几十层网络收敛。其次，作为一般化形式， MPELU较三者的推广能力更强。简言之，MPELU = max(ReLU, PReLU, ELU)。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/e88b386770bf13be03d3abc1b0a7fcd5.jpg" data-rawwidth="592" data-rawheight="177"&gt;当前对ELU网络普遍采用的初始化方法是 MSRA。这在实际中是可行的，只是不具备理论解释性。我们的工作利用泰勒公式和MSRA的推导过程，为ELU网络初始化提供了理论解释。此外，Dmytro 提出了 LSUV[15]，理论上可以用于 ELU/MPELU 的初始化。但在30/52层ELU网络上，发现 LSUV 会导致ELU网络在几次迭代之内发散，网络文件见&lt;a href="https://github.com/Coldmooon/Code-for-MPELU/" data-editable="true" data-title="GitHub - Coldmooon/Code-for-MPELU: Code for Improving Deep Neural Network with Multiple Parametric Exponential Linear Units" class=""&gt;GitHub - Coldmooon/Code-for-MPELU: Code for Improving Deep Neural Network with Multiple Parametric Exponential Linear Units&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;&lt;b&gt;总结&lt;/b&gt;&lt;/p&gt;&lt;p&gt;深度学习的快速发展，催生了形式各异的激活函数。面对琳琅满目的成果，如何做出选择目前尚未有统一定论，仍需依靠实验指导。一般来说，在分类问题上建议首先尝试 ReLU，其次ELU，这是两类不引入额外参数的激活函数。然后可考虑使用具备学习能力的PReLU和本文作者提出的MPELU，并使用正则化技术，例如应该考虑在网络中增加Batch Normalization层。本文围绕深度卷积神经网络结构，对十余种激活函数进行了总结，相关代码可在作者的github主页上下载：&lt;a href="https://github.com/Coldmooon/Code-for-MPELU/" data-editable="true" data-title="GitHub - Coldmooon/Code-for-MPELU: Code for Improving Deep Neural Network with Multiple Parametric Exponential Linear Units" class=""&gt;GitHub - Coldmooon/Code-for-MPELU: Code for Improving Deep Neural Network with Multiple Parametric Exponential Linear Units&lt;/a&gt;。个人浅见如有疏漏之处，请诸位读者不吝斧正。&lt;/p&gt;&lt;p&gt;&lt;b&gt;致谢&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这是一次严肃又愉快的写作过程，本文作者在撰稿过程中得到了两位审稿人的建设性意见，改善了文章的可读性，并提示了若干重要的引证文献，在此特表感谢！&lt;/p&gt;&lt;p&gt;&lt;b&gt;参考文献&lt;/b&gt;1.         Gulcehre, C., et al., Noisy Activation Functions, in ICML 2016. 2016.2.         Glorot, X. and Y. Bengio. Understanding the difficulty of training deep feedforward neural networks. AISTATS 2010.3.         LeCun, Y., et al., Backpropagation applied to handwritten zip code recognition. Neural computation, 1989. 1(4): p. 541-551.4.         Amari, S.-I., Natural gradient works efficiently in learning. Neural computation, 1998. 10(2): p. 251-276.5.         Nair, V. and G.E. Hinton. Rectified linear units improve Restricted Boltzmann machines. ICML 2010.6.         Glorot, X., A. Bordes, and Y. Bengio. Deep Sparse Rectifier Neural Networks.AISTATS 2011.7.         Djork-Arné Clevert, T.U., Sepp Hochreiter. Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs). ICLR 2016.8.         Li, Y., et al., Improving Deep Neural Network with Multiple Parametric Exponential Linear Units. arXiv preprint arXiv:1606.00305, 2016.9.         Xu, B., et al. Empirical Evaluation of Rectified Activations in Convolutional Network. ICML Deep Learning Workshop 2015.10.      He, K., et al. Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification. ICCV 2015.11.       He, K. and J. Sun Convolutional Neural Networks at Constrained Time Cost. CVPR 2015.12.       Maas, A.L., Awni Y. Hannun, and Andrew Y. Ng. Rectifier nonlinearities improve neural network acoustic models. in ICML 2013.13.       Goodfellow, I.J., et al. Maxout Networks.  ICML 2013..14.       Shang, W., et al., Understanding and Improving Convolutional Neural Networks via Concatenated Rectified Linear Units.ICML 2016.15.       Mishkin, D. and J. Matas All you need is a good init. ICLR 2016.&lt;b&gt;该文章属于“深度学习大讲堂”原创，如需要转载，请联系&lt;a href="https://www.zhihu.com/people/guo-dan-qing" class="" data-editable="true" data-title="@果果是枚开心果"&gt;@果果是枚开心果&lt;/a&gt;. &lt;/b&gt;&lt;b&gt;作者简介：&lt;/b&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/955bfb9618c0d83283599517280aa7d3.jpg" data-rawwidth="114" data-rawheight="121"&gt;&lt;strong&gt;李扬&lt;/strong&gt;，北京邮电大学电子工程学院通信与网络中心实验室博士生，导师范春晓教授。本科毕业于合肥工业大学光信息科学与技术专业，硕士师从北京邮电大学杨义先教授学习并从事信息安全项目研发。2015年转向深度学习领域，目前专注于深度学习及其在目标检测的应用。&lt;/p&gt;&lt;p&gt;&lt;b&gt;原文链接：&lt;a href="http://mp.weixin.qq.com/s?__biz=MzI1NTE4NTUwOQ==&amp;amp;mid=2650325236&amp;amp;idx=1&amp;amp;sn=7bd8510d59ddc14e5d4036f2acaeaf8d&amp;amp;scene=0#wechat_redirect" data-editable="true" data-title="深度学习中的激活函数导引" class=""&gt;深度学习中的激活函数导引&lt;/a&gt;&lt;/b&gt;&lt;b&gt;欢迎大家关注我们的微信公众号，搜索微信名称：深度学习大讲堂&lt;/b&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/a29f11daca9717751e639f2c3a3f8b93.jpg" data-rawwidth="346" data-rawheight="67"&gt;&lt;/p&gt;</description><author>程程</author><pubDate>Tue, 23 Aug 2016 15:57:13 GMT</pubDate></item><item><title>深度学习在人脸识别中的应用 ——优图祖母模型的“进化”</title><link>https://zhuanlan.zhihu.com/p/22141522</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/eac65675007d25f9975091dbb7817924_r.jpg"&gt;&lt;/p&gt;深度学习大讲堂致力于推送人工智能，深度学习方面的最新技术，产品以及活动。请关注我们的知乎专栏！&lt;p&gt;&lt;b&gt;该文章授权转载自公众号“腾讯优图”&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;序言——“弱弱”的人工智能&lt;/b&gt;&lt;/p&gt;&lt;p&gt;说到人工智能（Artificial Intelligence, AI）人们总是很容易和全知、全能这样的词联系起来。大量关于AI的科幻电影更给人工智能蒙上一层神秘的色彩。强如《黑客帝国》、《机械公敌》中的AI要翻身做主人统治全人类。稍弱点的《机械姬》里EVA懂得利用美貌欺骗中二程序员，杀死主人逃出升天。最不济也可以蠢萌蠢萌的像WALL·E能陪玩、送礼物还能谈个恋爱。&lt;/p&gt;&lt;p&gt;其实人工智能这个词在1956年达特茅斯会议上正式诞生时，目标就是想要让机器的行为看起来像是人所表现出的智能行为一样的“强”人工智能。然而人工智能的研究是高度技术性和专业性的，各分支领域都是深入且各不相通的，因而涉及范围极广。正是这种复杂属性，导致人们对人工智能的研究进程总是磕磕碰碰，反复地经历过分乐观的浪潮与极度悲观的寒冬。时至今日，想要完成全知、全能的强人工智能仍然只是一个长远目标。&lt;/p&gt;&lt;p&gt;虽然目前的技术水平还远不能实现强人工智能，但在一些非常特定的领域里，弱人工智能技术正在经历前所未有的迅猛发展，达到或已超越人类的最高水平。例如深蓝、Alpha Go分别在国际象棋和围棋领域击败世界冠军。例如自然语言理解、语音识别和人脸识别接近、达到甚至超越普通人的识别水平。虽然这些弱人工智能技术并不能真正地推理、理解和解决问题，但是面对特定的任务它们所给出的“判断”看起来是具有智能的。而正是这些看似“弱弱”的人工智能技术，在悄悄的改变人类生活的方方面面。它们以点带面完成越来越多的“简单任务”，为人们提供更加简洁、方便和安全的服务。&lt;/p&gt;&lt;p&gt;人脸识别正是众多“弱弱”的人工智能技术之一。通过看人的面孔识别其身份，对每一个正常的人来说都是再简单不过的。如果强行将人脸识别的难度和下围棋来比，应该没有人会觉得人脸识别更难。然而从计算机的角度来看，至少在输入数据的复杂度上人脸识别是远超围棋单步走子决策的。如图1(a)所示，一张Angelababy的图像在计算机看来，其实就是一个数字矩阵如图1(b)。数字矩阵的每个元素取值范围是0-255的整数。通常人脸识别算法所需的输入图像至少在以上，大的可能达到。理论上不同的可能输入共有种（每个像素的取值范围为0-255）。而围棋任意单步走子的可能局面上限为(每个棋盘格只能有黑子，白子，无子三种情况)，远远小于人脸识别。无论是围棋还是人脸识别，通过遍历完整的输入空间来做出最优的决策，就计算复杂度而言都是完全无法接受的。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/53ce60e568f3230c05a97f75651de5c0.jpg" data-rawwidth="631" data-rawheight="248"&gt;&lt;p&gt;其实对几乎所有人工智能问题，如何通过更高层次的抽象来理解输入从而更快速的做出决策都是解决问题的关键所在。近十年来引领新一波人工智能浪潮的核心技术“深度学习”就是这样一种方法，它通过少则近几层多则上百层人工神经网络不断地对高维的输入数据块进行抽象与理解并最终做出“智能”的决策。单凭深度学习技术可能仍然难以完成全知全能的“强”人工智能，但它却是完成任何特定“弱”智能任务的一把牛刀。正是看到深度学习技术如此巨大的潜力，国际互联网巨头Google，Facebook，Microsoft纷纷抢先布局，国内互联网领袖BAT也不惜资源进行技术储备，作为腾讯内部顶级的机器学习研发团队，优图也投入精英人力专注于深度学习技术的研发与产品落地。&lt;/p&gt;&lt;p&gt;本文着重以人脸识别为例介绍深度学习技术在其中的应用，以及优图团队经过近五年的积累对人脸识别技术乃至整个人工智能领域的一些认识和分享。&lt;/p&gt;&lt;p&gt;&lt;b&gt;回顾——人脸识别的“浅”时代&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在介绍深度学习技术在人脸识别中的应用之前，我们先看看深度学习技术兴起前的“浅”时代人脸识别技术。前面提到高维输入是所有类人工智能问题的一个普遍难题，学界称之为“维数灾难”（The curse of dimensionality）。其实在机器自动人脸识别技术研究的早期研究者们尝试过用一些非常简单的几何特征来进行人脸识别, 如图2所示（请原谅图片的质量，摘自93年的一篇人脸识别领域奠基之作[1]）。&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/a31d664de3a0738cf4dbebad25107691.jpg" data-rawwidth="304" data-rawheight="473"&gt;这样的朴素想法具有特征维数少的优点，所以不会遭遇维数灾难问题。然而由于稳定性差、区分能力弱和难以自动化等原因，这种做法很早就被抛弃。研究人员们发现，设计各种几何特征，折腾大半天还不如直接比较像素区域的差别准确，也就是所谓的模板匹配技术。然而，直接比对像素误差有个很容易想到的缺点，不同人脸区域对区分人的身份的重要性并不一样。事实上研究[2]表明眉毛和眼睛是区分人身份最重要的区域，其次是嘴巴，而大片脸颊区域所包含的身份信息是有限的。如图3所示，人类最难鉴别身份的是去掉眉毛和眼睛的人脸。&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/a61575087f9deafc43727dae9fb704f8.jpg" data-rawwidth="370" data-rawheight="170"&gt;为了解决这样的问题，很长时间人脸识别都非常依赖于判别性特征的学习，最有代表性的工作莫过于fisherfaces[3]，所谓判别性信息就是那种独一无二特征，就好像图4中所示，成龙的大鼻子，姚晨的大嘴，李咏的招牌马脸，姚明的魔性笑容。总而言之，只要能找到你独特的“气质”就能更好的认识你。&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/b12cd7ee2828d17094db650df2613a3a.jpg" data-rawwidth="693" data-rawheight="257"&gt;判别性特征的想法非常直观有效也取得了一定成功，但是由于人脸的像素特征非常不稳定，不同拍摄设备和拍摄场景、不同的光照条件和拍摄角度等都会造成相同人脸的像素差异巨大。想要在各种复杂影响因素下找到一张人脸稳定且独特的特征就很难了。为了解决这些问题，研究人员开始研究比简单像素值更加稳定的图像描述子。其中比较主流的一种描述子Gabor描述子借鉴了人类大脑的视觉皮层中对视觉信息进行预处理的过程。大脑皮层中对视觉信息加工处理的操作主要有两种，一种是在简单细胞中进行的线性操作，一种是在复杂细胞中进行的非线性汇聚。如图5所示的是MIT大脑和认知科学学院人工智能实验室的主任Poggio教授提出的一个叫HMAX[4]的类脑视觉信息处理流程：&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/13e89f6339ece6883b1ab9ca2f84eba1.jpg" data-rawwidth="703" data-rawheight="554"&gt;&lt;p&gt;这其中的简单单元“S1 units”和“S2 units”进行了一种叫做Gabor小波滤波的操作。而复杂单元“C1 units”和“C2 units”进行了一种叫做Max Pooling的取局部区域最大值的操作。事实上除却直接使用事先设定的Gabor滤波器，HMAX等价于一个四层的神经网络，实际上已经初步具备了现代深度模型的雏形。&lt;/p&gt;&lt;p&gt;在深度学习诞生前的“浅”时代，人脸识别研究人员不断改进预处理过程、使用更好的描述子，提取更有判别性的特征，这些都在慢慢的提高计算机识别人脸的能力。然而直到深度学习横空出世前，“浅”时代的各种人脸识别方法，对人类本身所具有的人脸识别能力仍然望尘莫及。&lt;/p&gt;&lt;p&gt;&lt;b&gt;拥抱——人脸识别的“深”时代&lt;/b&gt;&lt;/p&gt;&lt;p&gt;要赋予计算机完整的人脸识别能力，除了能认识人外其实还有几步非常重要的预处理过程。如图6所示，完整的人脸自动识别算法需要能自己从图像里找到哪有人脸，学界称之为人脸检测？哪里是眼睛鼻子嘴，学界称之为人脸特征点定位？最后才是提取前面说到的具有判别性的特征进行身份的识别，即狭义上的人脸识别。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/b73fd75c330c275b03c22da627c3d3f0.jpg" data-rawwidth="695" data-rawheight="169"&gt;&lt;p&gt;在深度学习出现以前关于人脸检测、特征点定位和人脸识别这三个子任务的研究都是相对独立的展开的。从上个世纪90年代开始到2010年左右，经过不断的摸索，研究人员们对每个子任务都发现了一些比较有效的特征与方法的组合来解决问题如图7所示。然而由于研究人员需要根据每个子任务本身的特点设计不同的特征，选择不同的机器学习方法，因此技术的发展相对缓慢。&lt;/p&gt;&lt;p&gt;从2012年左右，受深度学习在整个机器视觉领域迅猛发展的影响，人脸识别的“深”时代正式拉开序幕。短短的四年时间里，基于深度卷积神经网络的方法不断在这三个子任务中刷新人工智能算法的世界记录。人脸识别“浅”时代让人眼花缭乱的各种技术和方法仿佛一页之间成为历史。人脸识别研究人员，不需要在挖空心思的设计特征，也不需要担心后面需要什么样的学习算法。所有的经验的积累过程转换为了深度神经网路算法自动学习过程。这正式深度学习算法最大的优点：自动学习对特定任务最有用的特征！&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/a17fd978db96f407f012b30b7fe23b24.jpg" data-rawwidth="686" data-rawheight="459"&gt;考察一个单项的“弱”人工智能技术是否成熟，达到乃至超过人类的平均水平应该是一个比较通用的准则。说到这里不得不提一个人脸识别的标准评测数据库LFW（Labeled Face in the Wild）数据库。在2014年，Facebook使用一个叫做DeepFace的深度学习方法，第一次在LFW数据库上接近人类的识别水平（DeepFace:  97.35%  VS.  Human: 97.53%）,其结果如图8所示：&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/25b61dd14af52699061bb43624ddffa3.jpg" data-rawwidth="685" data-rawheight="200"&gt;&lt;p&gt;“Talk is cheap, show me the code”,自从DeepFace在人脸识别领域一战成名，让研究人员们看到了超越人类识别能力的曙光。随着几大开源深度学习项目（例如CAFFE，TORCH, TensorFlow）的发展壮大，基于深度学习的方法真正如雨后春笋般席卷整个人脸识别领域。事实也证明深度学习确实能够做到，短短一年以后就有很多基于深度学习的方法在LFW数据库上超过人类的识别能力，例如优图的人脸识别算法就在15年取得当时世界第一的99.65%准确率。&lt;/p&gt;&lt;p&gt;深度学习为什么如此神奇，能在短短的几年时间里一统江湖呢？抛开技术细节不谈，原理上来说最为关键的两个因素就是：层级式抽象和端到端可学习。&lt;/p&gt;&lt;p&gt;在回顾“浅”时代人脸识别方法历史时曾经介绍了基于几何特征的方法（图2）和基于判别性特征的方法（图4）。下图这些特征无疑都是针对人脸的某种抽象。由于原始图像输入的搜索空间巨大，只有通过恰当的抽象缩小搜索范围，才能最终做出合理的决策。对一个复杂的概念想要通过一层的抽象就将所有结构梳理清楚会是很难甚至不可能的，而深度神经网络这种多层结构给自底向上的逐级抽象提供了天然的模具。只要将足够多的数据输入到具有多层结构的深度神经网络并告知它你想要的输出结果，网络可以自动的学习中间层的抽象概念，如图9所示，好奇的研究人员将一个能够识别1000类物体的神经网络中的特征进行了可视化：&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/a95ec4e5ca35607a12ec1da42556079a.jpg" data-rawwidth="674" data-rawheight="280"&gt;&lt;p&gt;从图中可以看到在深度神经网络的第一层有点类似人类科学家积累多年经验找到的Gabor特征。第二层学习到的是更复杂的纹理特征。第三层的特征更加复杂，已经开始出现一些简单的结构，例如车轮、蜂窝、人头。到了第四、五层机器输出的表现已经足以让人误以为它具备一定的智能，能够对一些明确的抽象概念例如狗、花、钟表、甚至键盘做出特别的响应。研究人员们积累几年甚至十几年设计出来的特征例如Gabor、SIFT，其实可以通过深度神经网络自动的学习出来（如图9中“Layer 1”），甚至自动学习出它的人类“爸爸”难以言喻的更高层次抽象。从某种意义上来说，人工智能科学家就是机器的父母，需要“教”机器宝宝认识这个世界。谁都希望自己有个聪明宝宝，只用教它“知其然”，它自己慢慢总结消化然后“知其所以然”。深度神经网络就像个聪明的机器宝宝自己会学习、会抽象、会总结。&lt;/p&gt;&lt;p&gt;端到端可学习，乍一听这个名词可能觉得头有点“方”，其实可以简单理解为全局最优。图7中总结了在“浅”时代，人脸识别的各个子问题都需要通过两个甚至更多个步骤来完成，而多个步骤之间完全独立的进行优化。这是典型贪心规则，很难达到全局最优。事实上，受限于优化算法深度神经网络也很难达到全局最优解，但是它的优化目标是全局最优的。近几年深度学习在各种任务上的成功经验，表明机器宝宝也是需要有梦想的，直接对准“远方”的全局最优目标进行学习，即使得不到最优解也也远远好过小碎步的局部贪心算法。想要达到真正的“强”人工智能，深度神经网络还有很长的路要走，星爷的名言对神经宝宝同样适用，做人没有梦想和咸鱼有什么分别。&lt;/p&gt;&lt;p&gt;&lt;b&gt;进击——优图祖母模型的“进化”&lt;/b&gt;&lt;/p&gt;&lt;p&gt;随着深度神经网络的机器学习技术的发展，在LFW人脸数据库上,三、四年前让所有机器学习算法宝宝们望尘莫及的人类识别能力早已被超越。虽然优图也曾在LFW上取得99.65%超越人类平均水平的好成绩，但是我们清楚的明白刷库还远远不够，在实际场景中的应用更重要也更具挑战性，在实践中优图已经根据落地需求对各种应用场景和应用类型做出了细分，以便实现各种场景下人脸识别任务的各个击破。目前在落地应用中，常见的照片场景类型有生活照，自拍照、监控视频、门禁闸机、西方人及其他人种照片，如图10所示。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/62d17326a71114b4bd5eaf6273cc10cb.jpg" data-rawwidth="700" data-rawheight="304"&gt;互联网上有海量的人脸照片，通过搜索引擎优图也积累了海量带身份标注的互联网人脸数据。这部分数据无论从人数，图像数、数据多样性上都是最好的，为优图人脸识别技术的研发提供了基础条件。随着人脸识别技术的日渐成熟，实际业务中涌现出大量新场景下的应用需求，例如微众银行的核身业务，会议签到业务都涉及证件照和手机自拍照的比对，公安的监控需要视频监控数据与证件照的比对。不同场景下获取的人脸图像存在巨大差异，如何对人脸识别模型进行快速调整，在各个不同场景下快速落地就成为一个非常具有挑战性的问题。 为了在日趋白热化的市场竞争中占得先机，优图在三年深耕人脸识别和深度学习的基础上建立了自己在场景迁移与适应上的一整套方法论。这个方法论可以用一句话来概括：祖母模型的“进化”。这句话有两个关键点。首先我们需要建立适用于一般场景的、功能强大的人脸识别模型，也就是祖母模型。其次祖母模型通过“进化”来适应新场景下的人脸识别。 &lt;p&gt;&lt;b&gt;建立祖母模型家族&lt;/b&gt;&lt;/p&gt;&lt;p&gt;祖母模型并不特指一个深度神经网络模型，而是具有某种结构特点的一类神经网络模型，因此更为合适的叫法应该是祖母模型族。不同业务场景下的应用，用户对人脸识别的速度和精度可能有不一样的需求。祖母模型族必须像一个兵器库，既包含能够快速发射的机关枪也需要杀伤力强大冷却时间长的原子弹。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/6c385e12dcadaa81e5cdd2385aa842e5.jpg" data-rawwidth="695" data-rawheight="312"&gt;目前最为流行的深度神经网络结构大致可以归为三类：1.直线型（如AlexNet，VGGNet）；2.局部双分支型（ResNet）；3.局部多分支型（GoogleNet）。其中直线型网络结构设计最为简单，但是当网络深度超过20后这种结构的网络将变的难以优化。局部多分支型网络模型能力强，计算效率更高，但是设计也最为复杂。在建立祖母模型家族的初期，我们选择了模型能力相对较强设计又相对简单的局部双分支型网络ResNet来构建优图人脸识别的祖母模型族。一方面ResNet本身具有强大的学习能力，是去年深度学习领域最新的研究进展。MSRA凭借一个152 层的ResNet深度网络摘取了图像识别领域最具影响力的ImageNet2015竞赛多个单项的第一名。另一方面ResNet设计相对简单，一个最大的特点就是识别能力基本与神经网络深度成正比。神经网络的深度又与计算复杂度直接相关，这就为训练不同识别精度与运行速度的多个模型从而建立祖母模型族提供了极大的方便。当选定了祖母模型的网络结构后，我们将其在数据量最大的互联网生活照数据集上训练，以保证祖母模型的通用人脸识别能力，图12所示。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/b0bfbd74c64f2387344c09ddc76756f0.jpg" data-rawwidth="694" data-rawheight="311"&gt;在基于局部双分支模型族建立完成后，我们也开始尝试使用更复杂的局部多分支组件来进一步提高模型效率，丰富我们的祖母模型族。&lt;/p&gt;&lt;p&gt;&lt;b&gt;祖母模型的“进化”&lt;/b&gt;&lt;/p&gt;&lt;p&gt;迁移学习是近些年来在人工智能领域提出的处理不同场景下识别问题的主流方法。相比于浅时代的简单方法，深度神经网络模型具备更加优秀的迁移学习能力。并有一套简单有效的迁移方法，概括来说就是在复杂任务上进行基础模型的预训练（pre-train），在特定任务上对模型进行精细化调整（fine-tune）。套用在人脸识别问题上，只需要将训练好的优图祖母模型在新场景的新数据上进行精细化调整。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/1714d276e6b3cedb070216d23253899e.jpg" data-rawwidth="644" data-rawheight="283"&gt;这种传统的迁移学习方法确实能帮助祖母模型更好的完成新场景下的人脸识别任务。但这只能算特异化，无法将迁移学习中学到的新信息反馈给祖母模型。迁移之后的特异化模型只能应用在特定场景，在原集合上的性能甚至可能会大幅下降。在没有深度学习的“浅”时代，模型没有同时处理多个场景的能力，这可能是最好的适应新场景的方法。然而在实践中我们发现，由于深度神经网络的强大表达能力，完全可以在迁移学习过程中保持祖母模型的通用性能。采用增量学习的方式进行新场景的适应，在完成新场景下识别的同时也能保持其他场景下的能力，从而得到通用性更好的优图祖母模型，即优图祖母模型的“进化”。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/ca29a86a6568adfee9cc8bcfeed6f8d4.jpg" data-rawwidth="666" data-rawheight="373"&gt;随着各个场景下的数据不断积累，优图祖母模型将不断进化，变的更加强大。 后续我们将根据业务需求，继续积累在新场景下的人脸识别能力。并尝试将这种深度神经网络的神奇“进化”能力推广到更多的问题上。通过不断进化，祖母模型变的越来越聪明，也许有一天我们真的能创造出全知全能的“优图大脑”！&lt;/p&gt;&lt;p&gt;&lt;b&gt;作者简介：&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;腾讯优图，&lt;/b&gt;隶属于腾讯社交网络事业群（SNG），专注于图像处理、模式识别、机器学习、数据挖掘、深度学习、音频语音分析等领域开展技术研发和业务落地。团队成员大都来自清华、北大、中科院、上海交大、南大等国内顶级院校的博士和硕士，皆具有较深的学术研究背景和较强的工程实践能力。目前团队在人脸、图像、音频等领域已经拥有数十项业内领先的技术，具备千亿规模的多媒体大数据计算能力。在腾讯内部，优图为公司超过五十个业务提供相关的技术支持，并在财付通、微众银行、水印相机、QQ空间、QQ音乐、天天P图等明星产品中成功落地。诚招算法和工程技术人才，工作地点上海，招聘邮箱：youtu@tencent.com。&lt;/p&gt;&lt;p&gt;&lt;b&gt;欢迎大家关注我们的微信公众号，搜索微信名称：深度学习大讲堂&lt;/b&gt;&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/a29f11daca9717751e639f2c3a3f8b93.jpg" data-rawwidth="346" data-rawheight="67"&gt;</description><author>程程</author><pubDate>Tue, 23 Aug 2016 15:35:23 GMT</pubDate></item><item><title>Bengio教授的深度学习终极思考：文化、进化与迷因</title><link>https://zhuanlan.zhihu.com/p/22049891</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/7138b514eda846f9aaca84e9ee650ebd_r.jpg"&gt;&lt;/p&gt;深度学习大讲堂致力于推送人工智能，深度学习方面的最新技术，产品以及活动。请关注我们的知乎专栏！&lt;p&gt;&lt;b&gt;关于作者&lt;/b&gt;&lt;/p&gt;&lt;p&gt;首次看到Bengio教授这篇论文是在[对话机器学习大神Yoshua Bengio（下）]&lt;/p&gt;这篇论文是提问时候偶然提到的，按照Question中说法：&lt;strong&gt;您(Bengio)是机器学习领域唯一公开的以深度学习来研究社会学的科学家。&lt;/strong&gt;&lt;p&gt;所以相对于Hinton教授给我们带来生物神经方面的New Idea和Surprise（Hinton有剑桥认知心理学学士学位)从社会、文化角度扩展Deep Learning是非常有必要的，Bengio教授把重点放在了这个方向，其实和他的研究经历有关。他是神经网络(Forward-NN、Recurrent-NN)在自然语言处理(NLP)方向上推广的重要贡献人之一。[Bengio03]如果你曾经品读过他的100页大论文 [Learning Deep Architectures for AI] ，就会不得不佩服Bengio教授的思想。&lt;/p&gt;&lt;p&gt;如果说Hinton创立了Deep Learning，那么Bengio就是Deep Learning最好的布道师和奠基人。&lt;/p&gt;&lt;p&gt;作为一位坚持不加入任何商业公司的纯粹学者、Quora最受欢迎的机器学习专家，他对Deep Learning和AI的贡献非常大。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/7138b514eda846f9aaca84e9ee650ebd.jpg" data-rawwidth="629" data-rawheight="247"&gt;&lt;b&gt;学习情结&lt;/b&gt;&lt;b&gt;1.1 学习的两大动机&lt;/b&gt;我们为何而学习？消磨人生？显然不是。&lt;/p&gt;&lt;p&gt;人类的学习情结大致由两方面构成：&lt;/p&gt;&lt;p&gt;&lt;b&gt;(I) Predictive Criterion(预测):&lt;/b&gt;我们会不自觉的受到[时间访问局部性]的浸染，即当前遭遇的知识(Context)很有可能在近期再次相遇(Encounter)。显然，如果不对当前的Context进行剖析，那么意味着未来多次相遇时，无法做出预测(Prediction)，得不偿失。贪心机制会诱导我们尽早地对不确定的Context学习，用成语来讲就是“ 亡羊补牢，未为迟也”。&lt;/p&gt;&lt;p&gt;&lt;b&gt;(II) Reward Criterion(激励)：&lt;/b&gt;一些与生存有关的问题会被独立诱导学习。比如吃货在获取[如何满足口福]方面，显然有很强的积极性。又比如，为了满足生理需求，人类在[性知识]方面的探索可谓是五花八门。其中(I)广泛见于“监督学习”、“非监督学习”，(II)的相关工作由“强化学习”完成。&lt;/p&gt;&lt;p&gt;&lt;b&gt;1.2 预测学习算法&lt;/b&gt;“预测”显然在学习进程中处于主体地位，也是神经网络拟合模型的起源。 预测的相对确定性建立在，以当前参数θ对不确定性样本评估的[误差]的[期望]:&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/abdf6d0a342a0ab6cdb2959cdd2d7b37.jpg" data-rawwidth="568" data-rawheight="59"&gt;期望积分形式不是很直观，它有更亲切的表达形式：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/fdd8584bc2634435dd364adf9bafa671.jpg" data-rawwidth="390" data-rawheight="72"&gt;我们熟知的大部分监督学习算法，其优化目标基本都是min Criterion(θ)显然，当θOptimization≈θReal，我们认为Optimization过程引导Agent完成了学习任务。&lt;/p&gt;&lt;p&gt;&lt;b&gt;1.3 假设：优化&lt;/b&gt;你觉得(II)是否很功利？显然是，我们人类只会贪婪地朝满足自己的目标发展，这是骨子里的[目标性]。&lt;/p&gt;&lt;p&gt;你觉得(I)是否很功利？显然也是，数学式不会给我们反驳的机会，这也是骨子里的[目标性]。综合(I)(II)，Bengio提出了第一个假设：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/b62eab0bab0ea60ae32b90e14b1a800a.jpg" data-rawwidth="587" data-rawheight="112"&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;推理、然后误入歧途&lt;/b&gt;&lt;b&gt;2.1 瞬时速度与平均速度&lt;/b&gt;&lt;/p&gt;&lt;p&gt;考虑一个高一物理题：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/90653ba9955547570b96ba59709839b5.jpg" data-rawwidth="573" data-rawheight="81"&gt;&lt;b&gt;解：&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;平均速度=0/10=0m/s&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;瞬时速度=2330/10=233m/s&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这是一个有趣的问题，因为从微观上来讲，这个人很努力地跑，大家心知肚明。但是，从宏观上来讲，他其实在原地踏步，浪费时间。这样的问题在自然界是普遍存在的，贯穿[人类文明]的发展。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2.2 微观视点：推理&lt;/b&gt;推理(Inference)过程是相当微观、细致的，起码它是神经元级别的变化。&lt;/p&gt;&lt;p&gt;非线性分类模型的拓扑结构，基本都有隐变量(Latent variables)。&lt;/p&gt;&lt;p&gt;隐变量经过非线性的激活(重视or不重视)，变成隐元(Hidden Units)，(注：SVM的隐元即支持向量)。&lt;/p&gt;&lt;p&gt;隐元介于输入和输出之间，包含着对输入的[编码信息]，解释(explain)着当前的观测样本。&lt;/p&gt;&lt;p&gt;在Forward-NN里，隐元只和上一层隐元(或输入)连接[前向连接]，在Recurrent-NN里，隐元还和当前层隐元连接[递归连接]。&lt;/p&gt;&lt;p&gt;推理是迭代的(iterative)，时间尺度为[秒级]，不停地修改[Configurations]，尽可能认同更多的(agree more)观测样本。&lt;/p&gt;&lt;p&gt;每次瞬时的变化(change)，意味着心智状态(state of mind)的瞬变。&lt;/p&gt;&lt;p&gt;变化的跳跃范围可能很大，因为神经元数量众多，且很敏感，容易牵一发而动全身。不像学习，是一个徐徐渐进的过程。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2.3 宏观视点：学习&lt;/b&gt;学习是一个渐进、积累的过程，时间尺度为[分钟级]。&lt;/p&gt;&lt;p&gt;推理算是学习的子过程，个人用一个有趣数学式来表达：Learning(t)=∫Inference(t)dt即对推理过程函数中的[时间]进行积分，得到学习过程函数。回到瞬时速度和平均速度问题，众多推理过程可能是雄心勃勃的，但是构成的学习过程却可能是毫无意义的。&lt;/p&gt;&lt;p&gt;正如积分最倒霉的是积成了[零]，只要积分曲线(面)具有对称性。推理过程显然也可以呈现对称性，而且是大量地对称性。&lt;/p&gt;&lt;p&gt;网络上的一个著名励志段子：当你的所拥有的知识撑不起你的野心时，你只能 静下心去努力学习 原地打转。闭门造车的推理，即便花了时间，得到的其实还是[零]。&lt;b&gt;2.4 局部最小值：上帝也无法逃离？&lt;/b&gt;[局部最小值]算是神经网络的经典宿敌了，自上个世纪90年代始，以Vapnik为首的统计机器学习数学家就不断对此炮轰猛击。&lt;/p&gt;&lt;p&gt;在今天看来，[局部最小值]或许并不是神经网络的过错，大量证据表明，人类在自然学习过程中本身就会出现局部最小值。    至于SVM为什么能绕开了[局部最小值]，和Vapnik这位大数学家有关，他用求解最优分隔平面巧妙地变换了神经网络的目标函数。&lt;/p&gt;&lt;p&gt;从网络拓扑结构来看，SVM仅算是单隐层神经网络的特例。&lt;/p&gt;&lt;p&gt;凸优化、自适应隐元(支持向量)、完备的数学体系，真的让SVM从本质上脱离了神经网络吗？在[论文2.7节]中，Bengio对此发出的疑问：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/4c16bef2ba96e3e72253b083553ba501.jpg" data-rawwidth="609" data-rawheight="96"&gt;&lt;b&gt;2.5 假设：局部下降&lt;/b&gt;既然人类自然学习本身就存在局部最小值，那么是如何掉进去的，又如何从中逃逸？来看Bengio的第二个假设：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/457e17cf7565f950b631f30f85e2b165.jpg" data-rawwidth="608" data-rawheight="71"&gt;即是说，学习过程依赖于对[误差]的不断局部下降，这是一个徐徐渐进的过程。[论文2.7节]最后有一个观点很突兀：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/6cb612f0435941e6b07ba05dfb1ac14d.jpg" data-rawwidth="608" data-rawheight="71"&gt;即是说，神经推理过程不会陷入[局部最小值]，神经元可以随时大幅度变化自己，根本没有机会结识[局部最小值]。&lt;/p&gt;&lt;p&gt;那么问题就肯定出在学习过程了，个人总结出&lt;b&gt;四个关键点：&lt;/b&gt;&lt;b&gt;(I)&lt;/b&gt; 首先，根据Bengio的假设，学习过程显然是间断的，少有学习任务能够一气呵成。&lt;b&gt;(II) &lt;/b&gt;一旦间断，就肯定需要[断点续传]，每次选择一个局部的方向继续工作。&lt;b&gt;(III) &lt;/b&gt;在学习后期，学习速率通常会变得很慢（比如厌学了)，导致学习几乎停滞不前了。&lt;b&gt;(IV)&lt;/b&gt; 知识是有限的，尤其是在解决世界难题上(如NP完全问题)，一部分人仍然会固执地坚持似乎不正确的解(N=NP)。(II)显然不能保证，当前由贪心原则选择的[最速下降路径]一定是[通往全局最小值路径]的子路径。因为函数曲面必然存在大量[局部最小值]，所以搜索必然不会恰好选择[通往全局最小值路径]，而是在中间就落入局部最小值。 这是为什么[局部最小值]不可避免的自然原因。当然，Bengio还指出的更坏的情况，当前[最速下降路径]，甚至不能保证会到达[局部最小值]。依据是[随机梯度下降]与[批梯度下降]。我们知道，[随机梯度下降]没有选择全部样本来学习，而是逐部分学习，最后会下降到离[批梯度下降]稍远的偏移位置。这是[断点续传]策略造成的不可避免型[精度误差]，Bengio称该偏移位置为[Effective Local Minima]。(III)的解释可从二阶下降的牛顿法角度观察，学习速率由二阶Hessian矩阵控制：Δxt=Ht^−1⋅gt随着[误差]的不断减小Ht^-1近似也在减小，学习速率的下降似乎是无法挽回的。以至于最后，学习进程几乎处于停滞状态，此时很大可能在某个局部最小值附近，于是就出不来了。从社会角度来看，出自[对话机器学习大神Yoshua Bengio（下）]中的Q&amp;amp;A：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/771a38734186825e91fd7b8067ef0c83.jpg" data-rawwidth="579" data-rawheight="185"&gt;对于(IV)，我们都知道： “失败乃成功之母”。失败是必然有的，说明你掌握的知识有限。物理学巨匠牛顿说过：“如果说我看得比别人更远些，那是因为我站在巨人的肩膀上。”随着越来越多的先辈在[局部最小值]中摸爬滚打，我相信，在未来，我们的子孙肯定会到达[全局最小值]。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2.6 逃逸策略&lt;/b&gt;尽管在自然学习过程中，陷入局部最小值不可避免，但人类目前至少存在两个途径来逃逸。&lt;b&gt;策略一：绞尽脑汁，豁然开朗&lt;/b&gt;当我们被一个问题所困时，[绞尽脑汁]往往会从其他方向找到突破点。该策略是有实验依据的，由Bengio组在2014年(本论文写成2年后)发现：当参数(神经元)的维度很高时，局部最小值会蜕变成鞍点：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/f9fbc3b080a2e2887cd4b01369703c22.jpg" data-rawwidth="574" data-rawheight="250"&gt;参数高维，即每层中神经元个数很多，VC维超级大，会出现和直觉相悖的现象：几乎不存在局部最小值。&lt;/p&gt;&lt;p&gt;Bengio对此的解释： [2015蒙特利尔深度学习暑期学校之自然语言处理篇.哈工大SCIR]&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/8ce14b15597244d4436d6db8b1511b10.jpg" data-rawwidth="574" data-rawheight="185"&gt;Hinton教授的Dropout方法，实际上把已经神经网络变成了一个动态平均结构，这与生物神经网络是类似的。&lt;/p&gt;&lt;p&gt;尽管这时候模型总VC维已经庞大的无法直视，但是只要擅加稀疏和屏蔽，瞬时的结构风险是并不大的。&lt;/p&gt;&lt;p&gt;生物神经网络的Dropout稀疏率达95%以上，也就说，同时有95%的神经元被屏蔽，仅有5%是在工作的。&lt;/p&gt;&lt;p&gt;[绞尽脑汁] 似乎能够强行降低稀疏率，立刻提高维度，寻求鞍点来突破。(仅个人假设)&lt;/p&gt;&lt;p&gt;当从局部最小值逃逸后，人会放松下来，又把稀疏率提高，服从结构风险最小化原则。&lt;/p&gt;&lt;p&gt;这时候，只要保持一个愉悦的心情，学习就会有效得多。如果继续保持重压，那么过拟合显然不可避免的。    正所谓：打骂(神经元数量使用特别多）出来的清华北大，不是残就是废（过拟合）。&lt;/p&gt;&lt;p&gt;&lt;b&gt;策略二：知识扩充&lt;/b&gt;这大概是最普遍的方法了，大量的局部最小值由于“知识有限，智商不足以解答”而产生。    “知识有限”不仅直接体现在观测样本上(如Cifar10相对于ImageNet)，还间接体现在“归纳的中间结果”上。&lt;/p&gt;&lt;p&gt;比如在数学证明时，缺乏对前置定理的了解，你几乎是无法进行下一步推导的。这也是本篇论文讨论的重点，[文化浸染是如何协助从局部最小值中逃逸的？]&lt;/p&gt;&lt;p&gt;&lt;b&gt;深度结构与层次抽象表达&lt;/b&gt;&lt;b&gt;3.1 莫名其妙的功臣——Hubel&amp;amp;Wiesel&lt;/b&gt;几乎大部分关于Deep Learning资料，开篇必引1981年诺贝尔生理学或医学奖获得者, Hubel&amp;amp;Wiesel。&lt;/p&gt;&lt;p&gt;他们在1974年经典之作[Visual-field representation in layer IV of monkey striate cortex]，可以说是万恶之源。&lt;/p&gt;&lt;p&gt;至于深度神经网络的最初构想是否真的与Hubel&amp;amp;Wiesel的工作有关，并没有确切证据。但拿诺奖来贴金，这是非常划算的买卖。&lt;/p&gt;&lt;p&gt;&lt;b&gt;3.2 抽象观点&lt;/b&gt;对RBM的可视化是简单的，但是对DBN的可视化确实艰难的。因为第二层以上参数学习的是经过non-linearity变换后的特征。    Bengio弟子之一Dumitru Erhan在2009年提出了对深度网络可视化的方法，用实验验证了深度结构的逐层抽象能力。[Erhan10]&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/85ccf40f558720e0c12822b5a20ffcf1.jpg" data-rawwidth="572" data-rawheight="202"&gt;&lt;b&gt;3.3 函数观点&lt;/b&gt;&lt;/p&gt;&lt;p&gt;神经元在每层时，都有一个对应的表达函数，深度越大，函数积链越长，后一层的函数链，其实是由前一层的函数链递推得到。&lt;/p&gt;&lt;p&gt;这像极了现代程序设计方法——按功能设计子函数、增大代码重用率。尽管单隐层神经网络被证明可将任何函数拟合至精度为1/n [Barron 1993]，但是正如我们不会写出单函数代码一样，这并没有意义。&lt;/p&gt;&lt;p&gt;单隐层结构本身就不是科学的，起码它缺少神经元[复用](re-use)机制，效果不会很好。Bengio组的另一个研究热点即使探索深度的[等效性]，当前呼声较高的是这个假设：Theorems on advantage of depth:Some functions compactly represented with k layers may require exponential size with 2 layers.&lt;/p&gt;&lt;p&gt;(Hastad et al 86&amp;amp;91, Bengio et al 2007,Bengio&amp;amp;Delalleau 2011, Braverman 2011,Pascanu et al 2014, Montufar et al 2014)   以SVM为例，当搜索空间无限庞大时，K层神经网络的搜索范围与2n2n个支持向量等效，这时候选择SVM是不妥的。   &lt;/p&gt;&lt;p&gt;反之，要是研究如何拟合sinxsinx，SVM和K层神经网络几乎是难分伯仲。这显然又回到了NFL(No Free Lunch)上，既不可盲目支持深度神经网络，更不可盲目排斥深度神经网络。&lt;/p&gt;&lt;p&gt;[复用]机制让神经网络结构变得很灵活，副作用也很明显，它服从于乘法原理。从图论观点来看，假设每个结点连出两条路径，那么到达深度nn的结点就有2n2n条路径，复杂度呈指数级增长。&lt;/p&gt;&lt;p&gt;大量的可选择路径，让模型在搜索过程中，不停陷入形形色色的局部最小值当中，这似乎是无法避免的。&lt;/p&gt;&lt;p&gt;&lt;b&gt;3.4 层次抽象与层次理解&lt;/b&gt;回忆一下，当你初逢《高等数学》，你是如何理解积分这样高级概念的：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/9b4f6e77b80f7ae395cc0e1b122f3146.jpg" data-rawwidth="571" data-rawheight="374"&gt;关于这个“世界”的表达，不同的人会产生不同的抽象，让自身去更好地理解。&lt;/p&gt;&lt;p&gt;虽然抽象内容各不相同，但这种行为是共性的——层次结构、分布联系、深度计算。&lt;/p&gt;&lt;p&gt;鉴于此，Bengio提出第三个假设：&lt;/p&gt;&lt;p&gt;Deep Abstractions Hypothesis：Higherlevel abstractions in brains are representedby deeper computations (going through more areas or more computational steps insequence over the same areas).&lt;/p&gt;&lt;p&gt;&lt;b&gt;在计算模型中捕风捉影&lt;/b&gt;&lt;b&gt;4.1 非监督学习、监督学习&lt;/b&gt;数据挖掘最常见的思路：先聚类，定模式。后分析，精结果。这种主动意识的行为，真的没有潜意识在诱导嘛？    &lt;/p&gt;&lt;p&gt;考虑一个小学低年级的奥数题：&lt;/p&gt;&lt;p&gt;&lt;b&gt;找规律，并填空。&lt;/b&gt;&lt;b&gt;0、1、1、2、3、5、8、13、21、34、__、__、__。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;尽管我们对斐波那契数列耳熟能详，但世界上似乎还没有任何一种聚类算法能够发现这种规律。&lt;/p&gt;&lt;p&gt;那些年，愚昧无知的我们又是如何解决这个问题的呢？&lt;/p&gt;&lt;p&gt;&lt;b&gt;答案无非就是：&lt;/b&gt;&lt;b&gt;在数次失败、偶然恰好尝试[斐波那契公式]时，假设这是这种[概念]是对的，用给定数据计算多个实例x~，用x~去验证x，只要∑(x~−x)^2=0，即我们的[概念]发现的模式没有任何错误，则认为，解答正确，并且记忆这种解法。 &lt;/b&gt;&lt;/p&gt;&lt;p&gt;很不凑巧，这恰是RBM/AutoEncoder的思路，而我们的潜意识似乎正好在使用它。    对斐波那契数列规律的五花八门探索，不仅基本不是最优的，更多还是错的(与学习任务南辕北辙)。如果碰巧有个模式是对的，那么对后续的学习就轻松许多，或是不用学习、或是作为一种暗示和引导。&lt;/p&gt;&lt;p&gt;据此两点，Bengio提出第一、第二观测现象：&lt;/p&gt;&lt;b&gt;4.2 搜索之殇&lt;/b&gt;神经网络并没有什么奇妙的内涵，它本质仍然是一个[启发式穷举搜索模型]。类似于A*，它的启发式方向是[贪心策略：最速下降]。    但这个穷举，是一个连续实数型的无尽穷举，是一个曲面复杂的连续函数的生成。&lt;p&gt;类比于[深度优先搜索]，我们都知道，随着深度的增加，会出现越来越恶劣的情况。而神经网络同样有这样的厄运，这在上个世纪90年代，是被各界广为批判的，相关实验在[Erhan09]中。&lt;/p&gt;&lt;p&gt;据此，Bengio提出第三观测现象：Observation O3: directly training all the layers together would not only make it difficult to exploit all the extra modeling power of a deeper architecture but would actually get worse results as the number of layers is increased.    O3仍然有一些其它的佐证，最形象的要属[Erhan09]中对同结构，随机初始化的各个神经网络，追踪多个训练阶段，    剥离输出层，将最后的隐层输出降维，且2D可视化，得到轨迹线图：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/782ce6616c72bec71159ece455cec31d.jpg" data-rawwidth="579" data-rawheight="285"&gt;这个轨迹线隐含着两点有趣的现象：&lt;/p&gt;&lt;p&gt;&lt;b&gt;(I)&lt;/b&gt; 不同初始化的神经网络，选择了独立的搜索方向，陷入了独自的局部最小值中，彼此不会重合。&lt;/p&gt;&lt;p&gt;&lt;b&gt;(II)&lt;/b&gt; 没有预训练的神经网络，杂乱无章地在乱跑。&lt;/p&gt;&lt;p&gt;据此，Bengio提出第四、第五观测现象:&lt;/p&gt;&lt;p&gt;&lt;b&gt;Observation O4: &lt;/b&gt;No two trajectories end up in the same local minimum. This suggests that the number of functional local minima (i.e. corresponding to different functions, each of which possibly corresponding to many instantiations in parameter space) must be huge.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Observation O5:  &lt;/b&gt;A training trick (unsupervised pre-training) which changes the initialconditions of the descent procedure allows one to reach much better local minima, and these better local minima do not appear to be reachable by chance alone (note how the regions in function space associated with the two “flowers” have no overlap at all, in fact being at nearly 90 degrees from each other in the highdimensional function space).&lt;/p&gt;&lt;p&gt;&lt;b&gt;4.3 假设：从模型走向人类&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Bengio根据以上的Observation作了三个伟大的假设，他认为：人类和现在的神经网络模型一样愚蠢，饱受[局部最小值]与[难以驾驭深度结构]的折磨。&lt;/p&gt;&lt;p&gt;前提条件：[One Single Human Learner]，当然这个条件是不存在的，除非世界上除你以外的人都死光了根据 Local Descent Hypothesis、O4、O5，Bengio提出局部最小值假设：Local Minima Hypothesis：Learning of a single human learner is limited by effective local minima.结合O3，有对于训练深度结构的艰难假设:&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/b1405a38608fc6aba02f44886873cdd5.jpg" data-rawwidth="578" data-rawheight="76"&gt;最后，是一个关于徒有深度结构、却几乎不能利用之来逐层抽象的假设：Abstractions Harder Hypothesis：A single human learner is unlikely to discover high-level abstractions by chance because these are represented by a deepsub-network in the brain.这些看起来有些天方夜谭，人类怎么可能像机器学习模型那样愚蠢？但如果从史前时代开始，世界上就你一个人，你保持不死状态直到今天，没准今天真和模型一样愚蠢。而之所以没有出现这种情况，是因为[社会文化浸染]与[有性繁殖]，让我们的进化地如此强大。&lt;b&gt;社会：神经网络们的互联网E时代&lt;/b&gt;&lt;b&gt;5.1 双脑聊天&lt;/b&gt;考虑这样一个场景：那年，牛顿还没见过苹果长什么样子，也不知道什么为红色。他偶然来到果园，指着树上的红苹果，问山德士上校：“我听说果园里有苹果，这是苹果嘛？”上校回答道：“你看，这种颜色叫红色，而红色的球状的物体是就是苹果。”牛顿继续问：“味道怎么样？”上校冷笑道：“你来KFC品尝一下我们的苹果鸡腿堡不就行了。”    将这个场景用神经网络模型表示：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/0a07c021dd59fd7d5ad6cdd1faadfdd3.jpg" data-rawwidth="597" data-rawheight="335"&gt;牛顿在未经过任何学习的情况下，直接从上校口中获取关于苹果的[颜色][形状]，这是一件非常不可思议的事。因为从目前的模型来看，要让神经网络监督训练[颜色][形状]，仍然需要大费周章。&lt;/p&gt;&lt;p&gt;然而，此时牛顿还不知道苹果的[味道]，所以当他看见一个[红色的皮球]，会认为这是苹果，上前咬一口，咸咸的，所以牛顿可能得出了这样一个真理，[苹果是红色的、圆的、咸咸的]，而[红色的、圆的、甜甜的]的物体肯定不是苹果。&lt;/p&gt;&lt;p&gt;看完上面的笑话，我们一般会觉得，牛顿其实也很蠢。如果没人告诉他[苹果是甜甜的]，那么他可能一辈子会把[红色的皮球]错认为是[红色的苹果]，掉进一个局部最小值中。&lt;/p&gt;&lt;p&gt;其实事情不比那么糟，牛顿起码有一个方法，让[红色的、圆的、甜甜的]的物体也被他认为是苹果:只要他不知道[苹果是可以吃的]，即，牛顿的神经网络中，扔掉关于[味道]的隐层，让网络深度变浅。&lt;/p&gt;&lt;p&gt;这不禁让我们想起了 O3 , 错误地直接训练多层网络，会让结果变糟，此时浅层结构胜于深度结构。&lt;/p&gt;&lt;p&gt;但，如果牛顿使用了正确的方法，比如真的去KFC吃了苹果鸡腿堡，那么就会认为[红色的、圆的、咸咸的]肯定不是苹果，这比直接舍弃[苹果是可以吃的]有效地多，此时深度结构远胜于浅层结构，符合O1。&lt;/p&gt;&lt;p&gt;&lt;b&gt;5.2 信息交流，让世界更美好&lt;/b&gt;&lt;/p&gt;&lt;p&gt;    牛顿认知苹果，归功于山德士上校苦口婆心的教导，以口头语言形式。&lt;/p&gt;&lt;p&gt;从信息论观点来看，我们认为汉语的信息量比英语大，大部分语言的信息量要比行为动作要大。&lt;/p&gt;&lt;p&gt;即上校用四书五经而不是美式英语向牛顿解释，牛顿收获可能更大。&lt;/p&gt;&lt;p&gt;上校用美式英语而不是肢体动作向牛顿解释，牛顿收获可能更大。&lt;/p&gt;&lt;p&gt;但无论如何，只要[交流](Communication)能够传递到另一方的神经网络当中，成功消除神经元混沌，就足够了。&lt;/p&gt;&lt;p&gt;当然，我们还是希望能够实现信息量更丰富(Richer)的[交流]，也许偶然之中，就能突破自己的其它[局部最小值]。&lt;/p&gt;&lt;p&gt;[交流]不仅仅局限于人类，动物之间那些[危险警示]，也可视为[交流]，这样，愚蠢的动物才能有效学习如何保护自己。    据此，Bengio提出引导学习假设：brain can learn high-level abstractions if humans, which act as hints or indirect supervision for these high-level abstractions. &lt;/p&gt;&lt;p&gt;&lt;b&gt;5.3 交流背后的那些事&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在牛顿的识别苹果神经网络中，关于[颜色][形状]的隐层，被山德士上校给替换了。这不过只是瞬时行为，然而仅仅就结束了嘛？显然不是。牛顿回去之后，将今天的收获见闻回想了一遍，对苹果有了更深的认识。在神经网络中，我们假设：&lt;strong&gt;[回想]&lt;/strong&gt;过程发出了一个训练信号(Train Signal)，牛顿的神经元立刻开始飞舞起来，经过多轮的推理(Inference)，将[颜色][形状][味道]三个隐层的值给[Fine-Tune]下，降低了识别错误率。显然，因为牛顿爱思考的性格，[交流]触发了牛顿的学习机制。这倒是能解释，为什么同样的老师上了同样的课，学生有的考上了清华，有的成了家里蹲。&lt;b&gt;5.4 交流引发强大的心智活动&lt;/b&gt;&lt;/p&gt;&lt;p&gt;[交流]在神经系统中产生最频繁的效应就是[虚拟环境]，通俗点就是“不在场却能身临其境”。&lt;/p&gt;&lt;p&gt;经[交流]直接修改的神经网络，上下协调性不佳，需要[Fine-Tuning]，可能还需要一些新样本来强化记忆理解。&lt;/p&gt;&lt;p&gt;Hinton教授认为生物神经元普遍包含两种方向的计算。&lt;/p&gt;&lt;p&gt;这是一个证明RBM和AutoEncoder合理性的突破点，因为大多数情况下，需要在“判别模型”和“生成模型”间快速切换。[虚拟环境]的产生可以用“生成模型”来解释，只要将前向传播的方向逆置，从[颜色]到[形状]、[味道]，生成“苹果”，就能在没有看见苹果的情况下，脑中浮现出苹果。&lt;/p&gt;&lt;p&gt;[交流]将关于世界的[概念](Concept)传播，传播通道的带宽是有限的，这意味着将产生[竞争]。&lt;/p&gt;&lt;p&gt;比如，我们在接受[地球是圆的]同时，会排斥[地球是方的]、[地球是三角形的]。&lt;/p&gt;&lt;p&gt;[竞争]是自然界的标准法则，所谓优胜劣汰，适者生存.最后留下的[概念]在族群(Population)神经网络的[局域网]中，成为霸主，此时[概念]进化为[信仰]。[信仰]同[深度结构]类似，是一把双刃剑。&lt;/p&gt;&lt;p&gt;正确的[信仰]，如哥白尼的[日心说]，有助于我们走出关于天体运动的[局部最小值]。错误的[信仰]，如亚里士多德的[力是维持物体运动的原因]，则会长期把我们囚禁在[局部最小值]中。&lt;/p&gt;&lt;p&gt;&lt;b&gt;5.5 外传：合理的课程学习&lt;/b&gt;&lt;/p&gt;&lt;p&gt;该部分是Bengio个人的一个小研究，基于 Guided Learning Hypothesis. , 即学习过程是可以被引导的。&lt;/p&gt;&lt;p&gt;课程顺序学习制度是人类在学习任务上的经验总结，一个实例如下：&lt;strong&gt;CTSC(国际信息学奥林匹克竞赛中国队选拔赛)1997 [选课]，背景描述：&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在选修课程中，有些课程可以直接选修，有些课程需要一定的基础知识，必须在选了其它的一些课程的基础上才能选修。例如《Frontpage》必须在选修了《Windows操作基础》之后才能选修。我们称《Windows操作基础》是《Frontpage》的先修课。&lt;/p&gt;&lt;p&gt;从感觉上来看，先修课制度划定了学习进程的任务次序，具有[由浅入深性]、[无后效性]，保证学习进程循序渐进。&lt;/p&gt;&lt;p&gt;同时，让学习任务也具有深度结构，这是一个合理的层次抽象策略( 从简单抽象(子抽象)到复杂抽象(组合抽象) ) 。&lt;/p&gt;&lt;p&gt;据此，Bengio假设，如果在机器学习任务中，能够将样本的学习难度划分，重新安排学习顺序，那么就会有更好的效果。&lt;/p&gt;&lt;p&gt;因为学习是局部渐进的，所以低难度的学习样本，目标函数曲面较为简单，能够较为接近[全局最小值]。&lt;/p&gt;&lt;p&gt;再次，使用中、高难度的样本，函数曲面逐渐复杂，最后仍然会落入[局部最小值]中，不过位置更接近[局部最小值]。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/5846e100e3ab1b2ba0e1813bbee6116a.jpg" data-rawwidth="585" data-rawheight="358"&gt;&lt;b&gt;进化论 与 迷因论&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;6 .1 理查德·道金斯的迷因论&lt;/b&gt;&lt;/p&gt;&lt;p&gt;理查德·道金斯(Richard Dawkins)大概是世界上最野心勃勃、最不为人知的生物进化学家了。在他的研究中，最令人难忘的工作就是提出“迷因论”，[果壳网]有一篇很好的翻译介绍。&lt;/p&gt;&lt;p&gt;&lt;b&gt;6.2 搜索观点&lt;/b&gt;&lt;/p&gt;&lt;p&gt;几乎世界万物的生命进程都可以看作是一个搜索进程。&lt;/p&gt;&lt;p&gt;基因的进化是在搜索——  不断舍弃劣等基因，探索高等基因。(历程：几十万年）&lt;/p&gt;&lt;p&gt;迷因的进化是在搜索——  在数量爆炸性的文化中，寻找传承不息的迷因子。(历程：几十年、几百年、几千年)&lt;/p&gt;&lt;p&gt;学习的进化是在搜索——  个体为将所掌握的知识统一，琢磨一个支点去平衡它们。(历程：几分钟、几小时、几天)&lt;/p&gt;&lt;p&gt;推理的进化是在搜索——  神经元为了协调神经关系，不断变化自己。（历程：几毫秒，几秒）&lt;/p&gt;&lt;p&gt;这些搜索策略，因为大自然的馈赠，获得了足以并行搜索的条件。基因的并行在于[有性繁殖]，一个家族生生不息的繁衍，一起推动着这个家族基因的并行搜索进程。迷因的并行在于[宿主传播]，显然，知乎的一条回答，能够在短时间内进入数以千计人的脑中，加深“膜蛤”印象。&lt;/p&gt;&lt;p&gt;学习的并行在于[个体交流]，一个经典案例就是   “牛顿是如何认知苹果是红色的、圆圆的、甜甜的？”推理的并行在于[神经网络]，神经元彼此连接着，构成神经网络，而神经冲动无时无刻不在产生，瞬息万变。&lt;/p&gt;&lt;p&gt;自然界的四大并行搜索是可怕的，它们之间层层叠加，协助人类以最快的速度从[局部最小值]中逃逸，无限逼近[全局最小值]。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/5100db87d58540df2b45ce59d51cd239.jpg" data-rawwidth="525" data-rawheight="322"&gt;&lt;b&gt;6.3 先有鸡，还是先有蛋&lt;/b&gt;&lt;/p&gt;&lt;p&gt;尽管迷因子看起来无所不能，但仔细分析，道金斯仅给出迷因的两种特性：[自由脑入侵]与[噪声复制] (noisy copy)这两种特性只能描述迷因子发展的中间状态，一个很严肃的问题必须被考虑：最早的迷因子无从复制，又如何而来？&lt;/p&gt;&lt;p&gt;该问题一定程度上等效于哲学上的“鸡生蛋，还是蛋生鸡？”&lt;/p&gt;&lt;p&gt;显然，要解决这个疑问，就必须从迷因论中跳出来，在其他领域寻找论据。&lt;/p&gt;&lt;p&gt;最先、也是最容易产生的一种假设，就是迷因起源于它的栖息地——脑，由神经网络而生。如果这种假设是正确的，那么迷因就获得第三种特性 [迷因重组]。&lt;/p&gt;&lt;p&gt;[迷因重组]的想法显然效仿于[基因重组]，[基因重组]是[有性繁殖]生物体内在的一种可怕技术人类的基因数量只有5万，且[基因突变]的频率太低，但是一旦这些基因排列组合，产生的基因型数量是庞大到无法计算的。&lt;/p&gt;&lt;p&gt;[迷因重组]更加可怕，人的一生接触的迷因子显然不止5万，所以[迷因重组]可以产生大量的崭新迷因子。&lt;/p&gt;&lt;p&gt;这似乎能解释迷因子的起源问题。&lt;/p&gt;&lt;p&gt;&lt;b&gt;6.4 迷因计算模型&lt;/b&gt;&lt;/p&gt;&lt;p&gt;    [噪声复制]尽管看起来是像是一条毒瘤链，实际上它的速度是可怜的。&lt;/p&gt;&lt;p&gt;Bengio用了这样一个例子：一种迷因，在某轮传播中连接N个人，产生N个复制体。如果现在有M个人，且M&amp;gt;N，那么按照并行计算的概念，产生的M个复制体，会让下轮的迷因传播速度提升M/N倍。     这看起来很有道理，画成图应该是这样：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/8ea7c00dcdb3e10b8a1ed3599f21b454.jpg" data-rawwidth="605" data-rawheight="363"&gt;从图上来看，显然是不符合上文关于人类“交流”的假设的，所以应该是这样：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/a7686d18c08ab7f94b5c16bca78fc6c3.jpg" data-rawwidth="583" data-rawheight="295"&gt;对于其中的某个人，他可能在短时间内，[连续]与[同轮]的人交换信息，这部分可以用一个子图描述：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/52cc5db55dddc71c084582b680a2ed07.jpg" data-rawwidth="599" data-rawheight="405"&gt;现在，让我们考虑一个更疯狂的想法，假如某人在每次交流时，对迷因的看法都不同，那么在这颗分治树上，叶子结点(最终的想法)与非叶结点(曾经的想法)对迷因都是有贡献的。 考虑对于深度为n的二叉树，总结点数的计算公式: N=2^n−1，这样，迷因子的传播速度，就可以呈指数级增长。&lt;/p&gt;&lt;p&gt;这只是理论上的最好传播效果，Bengio指出，实际交流跨度不会很大，所以这棵分治树的规模是有限的。&lt;/p&gt;&lt;p&gt;据此，Bengio提出迷因分治传播假设：Memes Divide-and-Conquer Hypothesis. Language, individual learning, and the recombination of memes constitute an efficient evolutionary recombination operator, and this gives rise to rapid search in the space of memes, that helps humans build up better high-level internal representations of their world.   &lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/8ba01f5eb8d4d242ab0e1c635595c5e9.jpg" data-rawwidth="581" data-rawheight="500"&gt;&lt;b&gt;该文章属于“深度学习大讲堂”原创，如需要转载，请联系&lt;a href="https://www.zhihu.com/people/guo-dan-qing" class="" data-editable="true" data-title="@果果是枚开心果"&gt;@果果是枚开心果&lt;/a&gt;. &lt;/b&gt;&lt;b&gt;作者简介：&lt;/b&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/5d3ffda1db1a21b6caabf20a1959a15b.jpg" data-rawwidth="81" data-rawheight="80"&gt;&lt;strong&gt;潘汀，&lt;/strong&gt;合肥工业大学计算机专业大三本科生，中科院计算所VIPL组2017级推免生。原ACM-ICPC算法竞赛选手，2015年获CCPC铜牌。2015年初开始研究机器学习，研究兴趣集中于对深度学习理论、应用(CV&amp;amp;NLP)及系统架构设计的综合探索。关于深度学习在面部情感分析方面应用的论文被《自动化学报》录用。&lt;b&gt;原文链接：&lt;a href="http://mp.weixin.qq.com/s?__biz=MzI1NTE4NTUwOQ==&amp;amp;mid=2650325171&amp;amp;idx=1&amp;amp;sn=e721c69dffb6e4bb873b2c9f513e3a00&amp;amp;scene=0#wechat_redirect" class=""&gt;http://mp.weixin.qq.com/s?__biz=MzI1NTE4NTUwOQ==&amp;amp;mid=2650325171&amp;amp;idx=1&amp;amp;sn=e721c69dffb6e4bb873b2c9f513e3a00&amp;amp;scene=0#wechat_redirect&lt;/a&gt;&lt;/b&gt;&lt;b&gt;欢迎大家关注我们的微信公众号，搜索微信名称：深度学习大讲堂&lt;/b&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/a29f11daca9717751e639f2c3a3f8b93.jpg" data-rawwidth="346" data-rawheight="67"&gt;&lt;/p&gt;</description><author>程程</author><pubDate>Wed, 17 Aug 2016 12:36:42 GMT</pubDate></item></channel></rss>