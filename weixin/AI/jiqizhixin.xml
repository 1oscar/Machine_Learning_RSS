<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>机器之心</title>
    <link>http://www.iwgc.cn/list/670</link>
    <description>人与科技的美好关系</description>
    <item>
      <title>深度 | 欧洲计算机视觉会议（ECCV）开幕在即，抢先看Facebook将展示哪些视觉新技术（附论文）</title>
      <link>http://www.iwgc.cn/link/3020418</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自 Facebook Research&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;作者：Kelly Berschauer&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：武竞、吴攀、李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;本周第 14 届机器视觉欧洲大会（European Conference on Computer Vision（ECCV））将在阿姆斯特丹召开。作为机器视觉的顶级大会，Facebook 研究员们正在着手向他们的同辈们学习，并通过文献、海报、把特殊兴趣小组召集到专题研讨会和教程中（点击阅读原文，下载全部论文）。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Facebook 人工智能研究（FAIR）的科学家 Pedro O. Pinheiro、Tsung-Yi Lin、Ronan Collobert 和 Piotr Dollár 将展示他们的论文「学习精炼对象分割（Learning to Refine Object Segments）」，这篇论文在今年早期的一篇博客中被强调。这篇论文提出了用一个全新的自上而下（top-down）的精炼方法来增强前馈网络并进行图像分割。通过这种简单、快速、高效的方法，这篇论文展示了本周第 14 届欧洲计算机视觉会议（European Conference on Computer Vision（ECCV））将在阿姆斯特丹召开。作为机器视觉的顶级大会，Facebook 研究员们正在着手向他们的同辈们学习，并通过文献、海报、把特殊兴趣小组召集到专题研讨会和教程中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Facebook 人工智能研究（FAIR）的科学家 Pedro O. Pinheiro、Tsung-Yi Lin、Ronan Collobert 和 Piotr Dollár 将展示他们的论文「学习精炼对象分割 Learning to Refine Object Segments」，这篇论文在今年早期的一篇博客中被强调。这篇论文提出了一种全新的自上而下（top-down）的精炼方法来增强用来图像分割的前馈网络。通过这种简单、快速、高效的方法，这篇论文展示了自下而上/自上而下的结构是怎样高效的生成高保真图像掩码（mask）的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除了展示论文，Facebook 团队还作了&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718853&amp;amp;idx=1&amp;amp;sn=17462cfef179876db1f9d29dbd95ba2c&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718853&amp;amp;idx=1&amp;amp;sn=17462cfef179876db1f9d29dbd95ba2c&amp;amp;scene=21#wechat_redirect"&gt; DeepMask+SharpMask 以及 MultiPathNet &lt;/a&gt;的代码和演示，并将它们公开，希望能够对机器视觉领域的发展起到帮助。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;值得注意的是，今年是第二届 ImageNet 和 COCO 视觉识别挑战联合研讨会（ImageNet and COCO Visual Recognition Challenges Joint Workshop），由 Facebook 人工智能研究的研究员 Ross Girshick 和 Piotr Dollár，康奈尔大学的 Tsung-Yi Lin 和 Yin Cui，布朗大学的 Genevieve Patterson，以及 Caltech 的 Matteo Ruggero Ronchi 联合举办。「对于我，研讨会是大会中最有意思的环节，它让我看到领域中最前沿的工作，特别是那些具有挑战的工作。」Ross Girshick 说，「这些竞争性挑战是在学界和业界广泛的研究合作中产生的，能帮助确定视觉识别未来研究的方向。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;研讨会的目的是展示 2016 年 ImageNet 大尺度视觉识别挑战赛（ImageNet Large Scale Visual Recognition Challenge（ILSVRC））和常见对象 2016 识别挑战赛（Common Objects in Context (COCO) 2016 Detection Challenge）的方法和成果。具有最成功和创新性方法的挑战赛参与者被邀请到会场，向众多研究者分享他们的研究成果。另外，今年 COCO 大会的挑战赛是关键点挑战（2016 Keypoint Challenge），这个挑战赛要求在没有控制的条件下，定位出人的关键点。此次关键点挑战赛使用了一个相对低探索设置（under-explored setting），包含了探测出人和定位他们的关键点，所以我们可以期待最后的结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Facebook 人工智能研究科学家 Laurens van der Maaten 也被邀请在研讨会期间的网络和社交媒体平台上发表演讲，演讲的题目为「不通过注释数百万图像而学习解决视觉（Learning to Solve Vision without Annotating Millions of Images）」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Facebook ECCV 论文：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;论文：Learning to Refine Object Segments&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;作者：Pedro Pinheiro、Tsung-Yi Lin、Ronan Collobert、Piotr Dollar&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：对象分割同时需要对象级别的信息（object-level information）和低级别像素数据（low-level pixel data）。这对于前馈神经网络来说是一个挑战：卷积网络的浅层（lower layers）捕获丰富的空间信息，而深层（upper layers）编码对象级别的内容，同时深层（upper layers）编码对象级别的内容（但是对如姿势和外形等因素是不变的）。在这篇论文中，我们提出了一种全新的自上而下（top-down）的精炼方法来增强用来图像分割的前馈网络。这种自下而上/自上而下的结构能够高效生成高保真对象掩码（mask）。与跳过连接相似，我们的方法最大化的使用了网络中所有层的特征。与跳过连接不同的是，我们的方法不尝试在每一层输出独立的预测。取而代之的是，我们首先在一个前馈网络传递（feedforward pass）中输出一个粗糙的『掩码编码』（mask encoding），然后在一个自上而下的传递中精炼这个掩码编码，在依次的浅层中利用特征。这个方法简单、快速、高效。建立在用最近的 DeepMask 网络生成对象的基础上，我们展示了在不同设置下表示精确度的平均召回率（recall）有 10-20% 的提升。除此以外，通过优化全局的网络结构，我们的方法 SharpMask 比原来的 DeepMask 网络快了 50%（在 .8s 一张图片的速度下）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;论文：Polysemous Codes&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;作者：Matthijs Douze、Herve Jegou、 Florent Perronnin&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：&lt;/span&gt;&lt;span&gt;这篇论文考虑了在压缩空间中近似最近邻搜索的问题。我们引入了多义编码（polysemous code）, 它同时提供了产品量化的距离估计质量和用 Hamming 距离的二进制编码的有效对比。这个设计是由 90 年代提出用来建立信道优化的量化矢量器（vector quantizers）的算法启发的。在搜索时间上，这个双重方法加速了搜索。大多数索引化的向量被 Hamming 距离过滤，使得只有部分向量被一个非对称距离估计器排序。这个方法是对如反向多索引（inverted multi-index）的特征空间粗糙分区的一个补充。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;论文：Learning Visual Features from Large Weakly Supervised Data&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;作者：Armand Joulin, Laurens van der Maaten, Allan Jabri, and Nicolas Vasilache, Facebook AI Research&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：在大型有监督数据集上训练的卷积网络可以生成视觉特征，这些特征构成了当前许多最先进的计算机视觉问题的基础。这些视觉特征的进一步提升很可能将需要甚至更大型的人工标注的数据集，这极大地限制了进步的速度。在这篇论文中，我们探索了利用大规模弱标注图像集学习良好的视觉特征的潜力。我们在一个包含了 1 亿张 Flickr 照片和评论的数据集上训练了卷积网络，结果发现这些网络可以得出在许多视觉问题上表现良好的特征。我们还表明这些网络可以适当地获取词相似度（word similarity）和学习不同语言之间的对应。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;论文：Revisiting Visual Question Answering Baselines&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;作者：Allan Jabri、Armand Joulin、Laurens van der Maaten&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：视觉问题回答（VQA，Visual question answering）是目前评估图像理解系统能力与缺陷的一种有趣学习设定。最近提出的很多 VQA 系统包括注意力或记忆机制，用来进行「推理」。此外，对多选择 VQA 任务而言，几乎所有的这些系统都训练一个多类的图像分类器和问题特征，来预测答案。此论文质疑这些常见实践的价值，并基于二分类开发出一种简单的备用模型。该方法不再是将答案作为竞争选择的结果，我们的模型将答案作为输入并预测 image-question-answer 三重态是否正确。我们在 Visual7W Telling 和 VQA Real Multiple Choice 任务上评估该模型，发现该模型的简单版本也相当具有竞争力。我们最好的模型在 Visual7W Telling 任务上取得了 65.8% 的准确率，可相比于面向 VQA Real Multiple Choice 任务提出的最复杂的系统。此外，我们探索了该模型的变体，并研究模型在这两个数据集上的迁移性。我们也给出了最好模型的误差分析，结果表明如今 VQA 系统的关键问题在于缺乏问题和答案中产生的概念的可视化 grounding 和 Localization。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;论文：Shuffle and Learn: Unsupervised Learning using Temporal Order Verification&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;作者：Ishan Misra、Larry Zitnick、Martial Hebert&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：在此论文中，我们提出一种从视频中的源时空信号（raw spatiotemporal signals）学习视觉表征的方法。我们的表征是在没有监督语义标签的情况下学习的。我们将此方法制定为无监督时序验证任务，即我们测定来自视频的画面序列是否是正确的时序。在此任务中，没有语义标签，我们使用卷积神经网络学习强大的视觉表征。这些表征包含对从 ImageNet 这样的监督数据集中学到的表征的补充信息。保质的结果显示我们的方法能捕捉时间上变化的信息，比如人类的动作。当被用为动作识别的预训练时，我们的方法在没有 UCF 101 或者 HMDB51 这样的外部数据的情况下，能在学习上有重大收获。为了证明它对人类姿势的敏感性，我们在 FLIC 和 MPII 数据集上展示了对人类姿势动作评估的结果，可与使用更具监督性的方法相抗衡或者有更好的结果。我们的方法也能与监督表征相结合，更大的提高准确率。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 11 Oct 2016 12:29:42 +0800</pubDate>
    </item>
    <item>
      <title>深度 | 人工智能改变MIDI创作：谷歌Magenta项目是如何教神经网络编写音乐的？</title>
      <link>http://www.iwgc.cn/link/3020419</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自 FastCompany&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：TINA AMIRTHA&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：Rick、李泽南&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;谷歌和一些科学家正在利用 30 年的的数字音乐标准 MIDI 来教神经网络编写音乐。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今年 5 月，谷歌研究科学家 Douglas Eck 离开了他在硅谷的办公室，前往北卡罗莱纳州大烟山深处参加 Moogfest 艺术节，那里汇集了音乐、艺术和技术爱好者。Eck 向参加艺术节的资深音乐迷们讲述了其团队通过训练计算机来帮助音乐人编写音乐的新成果——在一首歌中生成和弦、创造过渡，以及精心设计反复的旋律。总有一天，机器可以学会完全靠自己去写一首歌。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Eck 还不能在艺术节上表演——这项活动深受 Moog 合成器的传奇创造者以及音乐人与电音咖们的影响——他只是简单介绍一下其团队充满挑战性的项目。要「学习」如何创造艺术和音乐，Eck 及其同事需要用户们使用 MIDI 来向机器供给大量数据，这是一种通常用来为小体量电子游戏提供背景音乐的数字音乐格式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;多年来，研究人员一直在进行人工智能生成音乐的试验。索尼法国计算机科学实验室中的科学家们最近发布了两首号称首次用人工智能生成的流行歌曲，它们是由其内部的人工智能算法创作（尽管它们是由一位人类音乐家 Benoît Carré 改编和作词的。）。他们的人工智能平台 FlowMachines 在过去也使用 MIDI 创作了爵士乐和古典乐。Eck 在 Moogfest 的讲话揭开了谷歌研究项目 Magenta 的序幕，这项研究旨在从音乐入手编写出可以学习如何生成艺术的代码。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;音乐的欣赏与创作是值得追求的，研究人员说，因为这两项活动都可以帮助智能系统夺得智能的圣杯：认知。正如计算机正开始从简单地读取文本发展为理解语音，计算机或许会开始有条不紊地理解并生成自己的音乐。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「通过学习文本，你可以学到很多语言相关的知识。MIDI 则相当于我们的音乐文本。我们对音乐创作和音乐感知了解得越多，我们就越能理解沟通和认知的普遍而重要的方面，」Eck 说，他目前是谷歌 Magenta 项目的研究科学家。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;摧毁计算机，赋予创造性&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;由于合成器在 7、80 年代得到普及，工程师们开始尝试在电子乐器之间进行交互的做法。其结果就是乐器数字接口（Musical Instrument Digital Interface/MIDI）的诞生，很快，音乐行业在 1983 年将其作为技术标准。设计者 Dave Smith 和 Ikutaro Kakehashi 免除了它的版税，让世人可以自由使用 MIDI。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「多年以后，我认为我做了正确的事，」Smith 在 2013 年告诉《财富》杂志。「我们希望确保所有人都参与进来，所以我们决定不向任何想要使用它的公司收费。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;很快，个人计算机都获得了读取和存储 MIDI 文件的功能，复杂抽象的音乐作品被缩小成为一种机器可读的紧凑数据格式（一首 4 MB 的 MP3 歌曲在 MIDI 中将仅仅占据几百 KB）。MIDI 已成为从键盘和鼓乐器到 MIDI 吉他、成套的电子鼓乐器这些电子乐器的标准。由 MIDI 创作的音乐带动了舞曲、电子乐、House 音乐和 drum&amp;amp;bass 的兴起，并出现在大多数的电视和电影配乐中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;MIDI 是音乐的符号化表示，就像文本是语言的符号化表示一样。「MIDI 本身不含有声音——它只是乐谱，」精通 MIDI 的音乐人 Jonathan Lee 说道。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一个 MIDI 链接可以携带多达 16 通道的数据，其中信息包含音符、音调和速度、音量、颤音、音频平移、提示和节奏等等。乐器还可以通过预先录制的音轨（SoundFonts）还原声音，它存储在一个单独的文件中。这种格式为音乐人提供了极大的自由度，可以让新手进行复杂的编曲，有些人甚至可以用它来构建复杂的管弦乐曲目。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不仅数字乐器仍然在使用这个 30 岁的、5pin 接口的 MIDI 连接，所有的现代计算机甚至是 Chrome 浏览器都可以通过一个 USB 适配器来从 MIDI 设备中接收数据。这种格式的音乐自 20 世纪 90 年代的 GeoCities 个人主页和 Doom 这样的热门游戏中发展起来。在当今更加先进的硬件条件下，数字采样器和最近类似「Black MIDI」的运动中，像 Lee 一类的 MIDI 音乐人更能够将通常是数千或数百万个音符充满一份数字乐谱，从头到尾只留有少数空白地带。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Lee 曾发布的最受欢迎的歌曲——TheSuperMarioBros2，其 YouTube 频道上有 160 万的点击量——包含 760 万个音符。在 YouTube 上播放听起来就像磕了药的 Philip Glass；在诸如 Piano From Above 或 Synthesia 的 MIDI 软件上播放听起来就像是要把你的计算机炸毁。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「90% 的计算机都无法播放它，」Lee 说。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Lee 是一名来自休斯敦的 17 岁男生，他说自己在试验这些 Black MIDI 音乐的过程中烧坏了父母笔记本电脑的内存和 CPU。最终他不得不为自己买了一台能经受住其考验的游戏主机。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Lee 相信 Black MIDI 音乐及其密集复杂的计算机指令可以促使工程师们开发出高效的软件，占用更少的内存而更多依赖 CPU 的处理能力。这样可以减少计算机在处理大量任务时崩溃的情况。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;深度学习与音乐&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不像录音文件，MIDI 文件是计算机科学家梦想中的学习材料；它们很小，可以在互联网上找到，而且免除了版税，可以成为用于训练人工智能机器的无限资源。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;训练计算机的前沿技术是深度学习，即使用神经网络的人工学习，它是一种存储信息的方法，近似于大脑和神经系统处理信息的过程。在计算机视觉中，深度学习已成为其标准的机器学习技术，计算机懂得在图像中寻找什么样的形状，科学家知道计算机在这个过程中会如何通过一个神经网络来学习。你可以在 Deep Dream 算法里看到反向推演的过程。谷歌工程师 Alexander Mordvintsev、Christopher Olah 和 Mike Tyka 使用公司的图像识别软件来产生「幻觉」中脱离日常场景的图像，这种图像是通过该软件在网络上找到的图片进行运算后获得的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibOMQ6FYyxsjWqjEP7yFd5ucibB7jQt0Dv1KHfQq26MIfKMgE8IDth8DVUHmlskNwxU1Sffmqw8e7Q/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Deep Dream 算法颠倒了图像的识别过程，它以其他图像模式来「观察（seeing）」图像。由 MIDI 音乐和其他输入数据供给的音乐算法可以通过一个模拟方法来编写歌曲。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;令科学家更加困扰的是计算机如何以及是否能够感知一些更主观的东西，比如音乐流派、和弦和情绪。听音乐可以帮助计算机达到这个更高层次的认知级别。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今年七月，伦敦大学玛丽皇后学院的一个科学家团队报告称，他们训练了一个神经网络来判断音乐流派，在输入了 6600 首三种流派（民谣、舞曲、hip-hop）的歌曲后发现，准确度达到 75%。然后他们剖析了计算机的神经网络层，来找出神经网络从巴赫到 Eminem 的歌曲中时在每一层中学到了什么。研究人员发现计算机一开始在神经网络的低层次感受基本节奏，如鼓点，而在最高层次学习更为抽象的概念，比如和声模式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外，不使用 MIDI 或其他种类的记谱法，研究者将从 8 千首歌曲中提取的 8 万个原音频信号的样品也输入进其学习算法中。这一决定可能反映了 MIDI 和其他合成音乐方法作为机器训练材料的局限性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不同人声在 MIDI 中是不存在区别的，「你的波士顿口音，和别人的德克萨斯州或明尼苏达州的口音在其中无法体现。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「类似 MIDI 这样的数字工具，有时它在建模音乐的古典元素方面（比如和弦、节奏，或者结构和形式）拥有很大潜力，」Eric Humphrey 说，他是纽约大学的音乐和音频研究实验室的前博士研究员，现在是 Spotify 的机器学习高级研究员。「但真正有趣的是，MIDI 并非需要擅长于音色或作品效果方面的建模。」除了其他原因外，这意味着「MIDI 并不能很好地编码很多流行音乐和现代音乐。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「在表现力和细节表达上，MIDI 存在缺陷，不同人声的区别在其中无法体现。你的波士顿口音，和别人的德克萨斯州或明尼苏达州的口音在其中没有区别。」Humphrey 说。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了理解在一首歌里出现的多种特性，谷歌研究人员从图像识别领域得到启发，他们开始着手建立新的深度学习模型来生成音乐，而没有考虑从 MIDI 中学到的艺术形式中可能会失去什么。这个夏天，Magenta 项目的研究员 Anna Huang 设计了一个神经网络，让它在巴赫众赞歌小节中进行作曲，在此之前她已删除了部分小节中的声音内容。Huang 及其团队最初希望如果一个音乐家已经写了一首歌的开始和结束，就使用计算机语音生成技术来完成其中间部分。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但研究人员发现，重新使用语音生成机器学习模型后出现了两个新问题。第一，音乐是各式各样的；几台乐器和几种声音即可随意演奏。在语音识别中，计算机基本只需学习一个人的说话方式。第二，音乐家在创作时可能不会以线性方式来谱曲，相反他们会选择回到前面的小节并填补上空白。另一方面，口语以逻辑序列的形式来建立想法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了解决第一个问题，研究人员从图像识别领域得到启发。他们构建了一种教计算机重构图像中的空白的机器学习模型，一种称为「图像修复（inpainting）」的方法。他们认为，如果计算机可以同时识别一张图像中的三个 RGB 值，那么他们就在其新模型中把每个声音当做一个单独的 RGB 值来处理。为了解决第二个问题，他们决定写一个使计算机随机生成旋律的算法，而不是按顺序生成。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该团队用几个巴赫众赞歌 MIDI 片段来训练他们的计算机，其中包括女高音、女中音和男中音声部，这是他们从作品的不同节点处随机截取的。在修改后的小节中的任何一个给定时间，该计算机将「听到」1 至 3 个声音。然后研究人员会测试计算机在逐一取走一首巴赫变奏曲中的每一个声部直到取完的过程中学会了什么。该小组保留了计算机的 28 层神经网络用于从之前生成的每一个声音中生成新的声音。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;iframe class="video_iframe" data-vidtype="1" style="   z-index:1; " height="375" width="500" frameborder="0" data-src="https://v.qq.com/iframe/preview.html?vid=y03358wludo&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0" allowfullscreen=""&gt;&lt;/iframe&gt;&lt;/span&gt;&lt;em style="color: rgb(136, 136, 136); line-height: 1.75em; text-align: center;"&gt;&lt;span&gt;谷歌的 Magenta 生成的声音&lt;/span&gt;&lt;/em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最终，谷歌研究人员对计算机的新工作的整个美学标准感到满意。分析巴赫众赞歌的结果使谷歌认识到这种方式可以训练计算机解决音乐的不和谐问题、寻找更好的和弦，最终学会音调。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但他们的模型只对一些现实世界的音乐风格方面进行了数字近似。一方面，他们的模型没有考虑音高范围——比如女高音或男高音歌手等专业歌唱家——的自然限度。在某些方面，计算机反映了声线中的音高与音调保持了一致。该团队正在研究新的方法来更好地将这些人类特征编码为其机器学习模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;要做到这一点，它需要更多的音乐来「教学」。除了产生可以更广泛地用于人工智能的新研究，Magenta 项目的工程师们还对发展与音乐人群体之间的合作充满热情。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;iframe class="video_iframe" data-vidtype="1" style="   z-index:1; " height="375" width="500" frameborder="0" data-src="https://v.qq.com/iframe/preview.html?vid=h0335q912gt&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0" allowfullscreen=""&gt;&lt;/iframe&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今年八月，该团队更新了音乐人和 Tensorflow（谷歌的开源人工智能软件）之间的一个接口。&lt;/span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;新版本允许音乐人将谷歌的人工智能模型连接到它们自己的合成器和 MIDI 控制器上，以实时制作人工智能生成的音乐。同时软件开发者也可以连接自己的人工智能模型来代替谷歌的模型，以期在 Magenta 社区中注入一些非谷歌的想法从而引发更多试验。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;与此同时，Lee 继续做着自己的 Black MIDI 品牌并发布在 YouTube 上。他的 MIDI 创作将一些新奇的「非艺术（note art）」——比如漩涡、字母，甚至摩尔斯电码——编织进乐谱的视觉效果中。一些作品更富自然中的数学韵律——一个叫「Pi」的视频包含了整整 3,141,592 个音符，时长 3 分 14 秒，而另一个视频「Fractal Images」描述了一组称为曼德尔布罗特集的数学方程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;iframe class="video_iframe" data-vidtype="1" style="   z-index:1; " height="375" width="500" frameborder="0" data-src="https://v.qq.com/iframe/preview.html?vid=o0335fzar5u&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0" allowfullscreen=""&gt;&lt;/iframe&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;em style="color: rgb(136, 136, 136); line-height: 1.75em;"&gt;&lt;span&gt;Lee 的 MIDI 作品「Pi」&lt;/span&gt;&lt;/em&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当得知谷歌正在寻找一些人将 MIDI 文件贡献到其新的人工智能项目中时，Lee 非常渴望参与进来。他计划调动整个 Black MIDI 社区将自己的文件上传到该项目中。如果那些超级密集的 MIDI 文件不会使电脑崩溃，也许他们可以教计算机一些有关如何写自己的 Black MIDI 歌曲的知识。「我们要用优质内容把它淹没，」他说。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 11 Oct 2016 12:29:42 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 2016伦敦深度学习峰会观感：人工智能面临的三大难题</title>
      <link>http://www.iwgc.cn/link/3020420</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自 The Verge&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;作者：James Vincent&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李泽南、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 9 月份伦敦举行的深度学习会议上，保持谦卑这个主题在演讲者的发言中不约而同地出现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尽管像谷歌这样的公司还在自信地表示我们已生活在「人工智能时代」，语音和图形识别领域的突破不断出现，这些前沿的 AI 研究看来大有希望，但仍前路漫漫。那些像电影中一样的数字语音助手并不代表我们已经创造了真正的人工智能。研究人员仍面临着各种问题：缺乏足够的数据来训练深度学习系统；无法制造同时处理多项任务的人工智能；不知道如何让这些系统运转起来。在 2016 年，机器学习领域已经出现了高效的工具，但这些工具内部机制难以解释，训练成本高昂，甚至对于它们的创造者而言也是一个谜。以下列出了机器学习领域目前面临的最大挑战：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;先收集数据，然后获得人工智能&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们都知道，人工智能需要获取数据进行训练以感知世界，但往往忽略到底需要多少数据。「仅仅获取人类用于理解和识别所需的信息量是不够的，这些系统需要数百乃至数千倍这样的信息以供训练，」Sheffield 大学的教授，亚马逊人工智能团队成员 Neil Lawrence 说道，「纵观应用级深度学习的成功案例，你会发现他们都获得了海量数据。」在语音和图像识别领域，这种现象尤为明显。像谷歌和 Facebook 这样的大型公司可以随心所欲地截取大量数据「例如你在安卓手机上用于语音搜索的音频」，这种优势让他们可以创造更有效的新工具。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Lawrence 认为：「数据就像工业革命时代的煤一样举足轻重。」他以 Thomas Newcomen 作为比喻，这位发明家在 1712 年发明了蒸汽机的原型—用煤作燃料，比众所周知的詹姆斯瓦特早 60 年。Newcomen 的发明并不完美，相比瓦特的机器，前者低效而昂贵。人工智能或许也处在这样一个时代，人们还只能努力从矿藏中不断挖掘矿石作为燃料，抵消机器本身的缺陷。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibOMQ6FYyxsjWqjEP7yFd5uj2icpYAUZ5NH3CfTRLy36o4rib9rehZJf6hzibXpicIPGYibXCmqaJqaaicQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Facebook 的开源图像识别工具&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;全世界有很多 Newcomen 一样的发明者正为他们的机器学习模型而努力，他们也许富有创造力，但没有大数据的帮助，他们的梦想或许难以实现。像谷歌，Facebook 和微软这样的大公司是今天的数据煤矿。他们的海量数据可以让他们应对仍然低效的机器学习系统，同时改进它们。规模较小的创新企业或许拥有好的想法，但没有数据的帮助，一切都难以成真。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「在令用户反感的情况下强制获取数据是不道德的行为。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谈到如何获取数据，这个行业面临着更加尖锐的矛盾。在医疗领域，假如需要训练一个使用 X 光照片识别肿瘤的人工智能，数据肯定难以获取。正如 Lawrence 所说的，棘手的问题是「在令用户反感的情况下强制获取数据是不道德的行为。」（这也是阻碍谷歌和英国国民医疗服务机构之间合作的最大原因）。Lawrence 认为，最终的解决之道，在于提高深度学习系统的效率，让机器使用更少的数据满足训练要求。就像三个世纪前瓦特所做的一样，这可能需要另外一个 60 年。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;只有昆虫需要特化--人工智能必须能够同时应付多任务处理&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;深度学习面临的另一个重要问题：事实上，目前的系统几乎都是一根筋。「当它们被训练后，这些而机器可以高效地执行类似识别图片中的猫、玩雅达利视频游戏这样的任务，」谷歌深度学习科学家 Raia Hadsell 说道，「然而能够同时分辨图像，玩『太空入侵』同时听音乐的神经网络，甚至理论方向都还未问世。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个问题比你想象的还要严重，当谷歌 DeepMind 在去年 2 月宣布他们的系统可以玩 49 款雅达利游戏的时候，这的确是一个了不起的成就。但每当他们的系统通关一个游戏后，研究人员都需要重新训练神经网络，好让它能够应付另一个。正如 Hadsell 指出的，还没有人工智能可以同时学会多款不同游戏的玩法，对于机器而言，不同游戏的玩法会互相干扰。你可以让神经网络依次学习，但你会发现它会忘记在这之前的那款游戏的玩法。「想让人工智能真正获得智慧，我们需要让它能够学习多种任务的处理。」Hadsell 说道，「然而我们甚至无法让机器学会不同游戏。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;要解决这个问题，我们可能会需要一种先进神经网络，它可以整合一些不同的深度学习系统，作为接收者，为它们传递信息。在六月公开发表的一篇论文中，Hadsell 和他的团队展示了他们的先进神经网络如何适应并学习玩「Pong」，一种细节复杂的游戏「在其中一关，屏幕颜色会反转；在另一关，摇杆的反应力度会改变」，他们的先进神经网络比其他同类能够更快地学会这款游戏并顺利通关。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibOMQ6FYyxsjWqjEP7yFd5uoEBiba0ecnHNRR9HFjDIq28pkiaicXeq0F4QdZnZJ5jO8KXxmzzRJ24xw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是一种很有前途的方法，而且在最近的一些实验中它甚至被应用到了机器臂上——将它们的学习过程从好几周加速到了仅仅一天。但是，仍还存在一些显著的限制，正如 Hadsell 指出的那样：渐进的神经网络不能简单地不断向它们的记忆中加入新任务。如果你不断将系统集中到一起，或早或晚你都将会得到一个「太大以致于难以处理」的模型，她说。而那就是将不同的任务按本质上相似的方式进行管理的时候——创造出一个人类水平的智能，它能够写诗、解微分方程和设计一款完成不同的椅子。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;只有你能展示你的工作方式的时候才是真正的智能&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一个重大的挑战是理解人工智能是如何得出它们的结论的。神经网络通常对观察者来说是难以理解的。尽管我们知道它们是如何创建的和输入它们的信息，但它们得出特定决策的原因却通常是无法解释的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;弗吉尼亚理工学院给出了这个问题的一个很好的展示。研究者创造了针对神经网络的「眼部追踪系统」，它可以在一开始就记录计算机正在检测哪些像素。这些研究者向他们的神经网络展示了一张卧室的照片，然后问该人工智能：「什么遮住了窗户？」他们发现这个人工智能根本不会去看窗户，而是在看地板。然后，如果它发现了一张床，它就会给出答案：「是窗帘遮住了窗户。」这正好是正确的，但这只是因为该网络接受训练的数据很有限而已。根据它曾经看过的照片，这个神经网络总结得出：如果是在卧室，那么窗户上就会有窗帘。所以当它看到一张床时，它就停止检查了——在它眼里，它已经看到了窗帘。这在逻辑上说得过去，但也很可笑。还有很多卧室没有窗帘！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;眼部追踪是了解网络内部部分工作方式的一种方法，而另一种方法则是从项目一开始就在深度学习系统构建更多的一致性（coherence）。实现此目标的一种方法是重新使用一种老旧的已经不再流行的机器学习方法——符号人工智能（symbolic AI），或者叫做良好的老式人工智能（GOFAI：Good Old-Fashioned Artificial Intelligence），帝国理工大学的认知机器人学教授 Murray Shanahan（他也是电影《机械姬》的科学顾问）如是说。这种方法基于一个假设：心智活动可以简化成基本的逻辑，其中世界是由复杂的符号词典定义的。通过结合这些符号——其代表了行为、事件、物体等等——你就能合成思维。（如果按这种方式创造人工智能听起来是一件很怪异的、不可能完成的任务，那想象一下在运行于磁带上的计算机上实现它。）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Shanahan 的提议是我们将 GOFAI 的符号描述和深度学习结合起来。这将为系统提供一个理解世界的起点，而不只是向其馈送数据然后等着它们发现其中的模式。他说，这可能不仅能解决人工智能的透明性问题，而且还能解决 Hadsell 提出的迁移学习问题。「可以说 Breakout 和 Pong 是非常相似的，因为它们都有拍子和球，但人类水平的认知是在更加惊人的尺度上得出这种类型的联系的，」Shanahan 说，「就好像原子结构和太阳系结构之间的联系一样。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Shanahan 及其帝国理工大学的团队正在研究这种新方法（他们将其称为深度符号强化学习（deep symbolic reinforcement learning）），并且已经发表了一些小实验。这种方法仍处于起步阶段，它能否扩展到更大的系统和不同类型的数据上还有待观察。但是，它很可能会得到更大的发展。毕竟，深度学习本身也曾是人工智能中一个无人问津的领域，直到近年来有了廉价的数据和充裕的处理能力之后深度学习才迎来爆发。也许是时候从人工智能的过去再次引爆一种方法了，以便将人工智能的能力应用到新的环境中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心经授权编译，机器之心系今日头条签约作者，本文首发于头条号，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 11 Oct 2016 12:29:42 +0800</pubDate>
    </item>
    <item>
      <title>特写 | 从Y Combinator到OpenAI，纽约客万字讲述Sam Altman的天定命运（上篇）</title>
      <link>http://www.iwgc.cn/link/3009686</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自纽约客&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Tad Friend&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：机器之心编辑部&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote style="white-space: normal;"&gt;&lt;p&gt;&lt;em style="color: rgb(136, 136, 136);"&gt;&lt;span&gt;本文为《纽约客》最新一期文章，介绍了 YC 孵化器 CEO、OpenAI 联合创始人 Sam Altman。文中包含了众多科技投资、Open AI 人工智能研究的独家内容，是不可错过的一篇特写。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;五月的一个温柔夜晚，硅谷三十个顶级企业家齐聚在旧金山 Berlinetta Lounge 的一间私人会客室里。Paul Graham 望着 Instacart, DoorDash, Docker, 和 Stripe 的创始人们，他们都身着连帽衫黑色牛仔裤。Paul Graham 突然说道，「这就是硅谷，就在我们脚下。」所有的创始人都来自 Y Combinator（简称 YC），Graham 是这家创业公司孵化器的创始人之一。YC 为创业者提供为期三个月的训练营，一年开两场，让创业新手学会如何创办一家「独角兽公司」—像 Valleyspeak 那样的市值 10 亿美元的公司。今年，大约有 13000 家新兴的软件公司申请进入 YC，成功入选的只有 240 家，比考进斯坦福还要难一倍。而 YC 在成功孵化出 13000 家创业公司后，成为一座权力——特权——之岛。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQXA6DfvmAhrhynJ5Kv8I3Av0Z0w1tM6VbaSoicZGspLcTYUDlbh0dJZqXhyOIRAQkwGUK2UeDmoA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;房间里嘈杂的一边，Graham 正在兴致满满地鼓励着几个不可能的方案。另一边安静的角落里，是全神贯注于计算的 Sam Altman。2014 年，Graham 选择 Altman 作为他的继任者，YC 的总裁。时年 31 岁的 Altman 比他小了 20 岁。两人的友情非常深厚，都对 YC 有着宗教般的热情，都爱穿工装短裤。Graham 说什么，Altman 就照做。在 Graham 的桌子上，他和其他几个人讨论着如何才能阻止 Trump，最后决定求助外援专家：Chris Lehane，前白宫律师，现在就职于 YC 旗下的公司 Airbnb。Altman 宣称，「最好方法就是支持希拉里。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;体重 130 磅的 Altman，安静时像个衣服架子，激动时像只头上长角的猫头鹰。即便在效率至上的硅谷，他也像个局外人。他快速翻阅着邮件及会议，好像身上绑了个定时炸弹；毫不眨眼地盯着员工，让他们加快速度，跟一群花栗鼠一样。Altman 对很多 YC 的公司生产的应用程序的细节缺乏兴趣；他感兴趣的是它们对世界的潜在影响。为了做决策，他会下载他需要的所有资料，比如说，城市规划或核聚变。Stripe 的 CEOPatrick Collison 把 Altman 的大脑比作一个狂欢节上的抓娃娃机，「看起来四处游荡，但关键时刻一抓就中。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最近一名博主问 Altman，「怎样才能让阿斯伯格综合症患者获得帮助，以及怎样才能伤害你？」Altman 告诉我，「他的回答是，『我他妈就跟你一样，没得阿斯伯格综合症！』但是事后一想，我能明白他为什么认为我会。因为我所处的位置太奇怪了。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我对技术的兴趣很窄，对不感兴趣的东西没什么耐心：聚会以及大多数人。当有人看着照片然后说，『哦，他感觉到了这个这个和这个，』所有这些微妙的情绪，我看着就像外星人的阴谋一样。」Altman 的强大之处是他清晰的思维，能用直觉把握复杂的事物。他最大的弱点是对低效率的人完全没兴趣，很不幸，我们大多数都是这样的人。我刚开始和 Altman 接触时，他一副很警惕的样子，不过慢慢就松懈下来了。经过几天的相处之后，我提起他似乎从来都不去男厕所，他说，「我会去练习上洗手间这回事，好让你们这些人类意识不到我是个人工智能。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;接管 YC 时，他继承的是一个正在萌芽中巨人。风投家 Chris Dixon 告诉我，「他们创造了有史以来最伟大的商业模式。因为在几乎没有资金的情况下」——YC 给每家公司仅仅 120 万美元，这些钱要包含公司所有支出——「他们在一大批硅谷最好的公司中都获取了 7% 的股权。」总体上，YC 下面的公司总市值 800 亿美元，估值在过去五年涨了 17 倍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然而 Altman 决定几乎重组一切。在 Berlinetta Lounge，新官上任三把火。但他发现只有当新领导「重建」公司时，更换 CEO 才有意义。「我是故意这么做的，」他说。在与加速器的其他十六个合作伙伴确认之后，Altman 有了新举措，启动了一项资金支持更加早期的创业公司，并在它们成长的过程中给予持续的支持。YC 不会再让探险者们划着破船摇晃出海，而是组成铁甲舰队以帝国的气势出征。一年之内孵化的不再是几百家公司，而是成千上万家公司。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;跟硅谷里的每个人一样，Altman 自称要拯救世界；但又和几乎所有人不同的是，他已经有了计划。「YC 有时会直接指导技术课程，」他说。「消费者是上帝。但最终只要我们说，『我们是虚拟现实的狂热爱好者，』就会有足够多的人看重我们，大学生也会开始学习这个领域的东西。」他曾在一篇博文中写道，占领主导之后，「科学似乎要玩完了」，并呼吁从能源、生物技术、人工智能、机器人技术、和其他八个领域的应用。最终，曾经的书呆子 YC 成了如今的强势 geek。晚餐桌上，坐在 Altman 对面的是一家研究核裂变的创业公司的 CEO 正在敦促一家量子计算创业公司的创始人让其基于人造原子的机器投入市场：「这些计算机将会将我们的产品研发周期缩短 10 到 20 倍。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一个合伙人，Jonathan Levy 告诉我，去年两个 YC 的合伙人告诉他，「慢一点，冷静一下！」而「Sam 却说，『是的，你说的对！』—然而他并没有慢下来，还做了另外做了一些我们一度不了解的事情。」是的，他在这段时间里建立的 YC Research，一个非营利组织，其最初资金来源于一笔 1000 万美元的个人赠与。YC Research 做了一些登月计划的纯研究。Altman 还与 Tesla 和 SpaceX 的 CEO 联合创办了非营利性的 OpenAI，其目标是防止人工智能一不小心会消灭人类。风投家 Marc Andreessen 说过，「在 Sam 的领导下，YC 的野心等级上升了 10 倍。」Paul Graham，晚餐后很快离开了，他要去英国度年假。Graham 告诉我，Altman 正在尝试通过沉淀「癌症治疗、核裂变、超音速客机以及人工智能等多个领域技术进展」，全面改变我们的生活方式：「我认为他的目标是创造整个未来。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Altman 正在硅谷之外的地方建立一个新的中心，想要替代硅谷的地位。这是一个超级资本企业家协会，里面的企业家会互助起来拯救这个破碎的世界。每个人都在警告他不要这么做。硅谷奖励过度的野心，但有希望它能「集中火力」制造世界上最好的游艇租赁平台或干邑送货服务。Reid Hoffman，一名行业领先的风投家曾警告过，「雄心勃勃是件好事，但硅谷的传统是，当一个人想改造一片区域时，最终的结果会很糟糕。」Altman 餐后照例饮下一杯酒后，也警告那些胆小鬼：「只有在经济不断增长中，民主才能运行下去，经济不恢复增长，民主试验会失败。所以我必须考虑 YC 对经济增长至关重要。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2016 年创办一家创业公司就和 1996 年组建一支摇滚乐队或1971 年发动一场越南战争差不多。自 2005 年 YC 建立以来，各个地方的孵化器如雨后春笋般出现，帮助创业公司从一行代码发展成为一家真正的公司，以换取 5% 到 7% 的创业股权。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在加速器还未出现的上世纪九十年代，创业公司通常由一群处于事业发展中期的工程师或者在创业的企业家做起来的，他们从风投那里找来数百万美元的资金，然后悄悄地干上几年。后来由于网络主机的价格暴跌，以及个人电脑和手机的激增，像 Mark Zuckberg 或者 Larry Page 和 Sergey Brin 那样的大学辍学生突然开始在自己的笔记本上创办公司。Paul Graham 是一个天才的程序员，他把自己的创业公司卖给了雅虎，赚了 5000 万美元，是第一批紧随这股创业趋势的人之一。他那篇 2005 年的文章「How to Start a Startup」，与 Steven Blank 的「The Four Steps to the Epiphany」还有 Eric Ries 的「The LeanStartup」，这三篇文章，一时间塑造了现代企业家的精神：自我举荐；从一个「可行性最低的产品」开始，然后快速迭代；宁要十个狂热粉丝也不要一万个只是喜欢谈不上爱的客户。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Graham 与他的妻子和两个朋友在马萨诸塞州剑桥市共同创立了 Y Combinator（得名于一个不起眼的数学函数），这既是他们的一个暑期投资实验，也是重新想象暑期工作的一个激进的尝试。在 Graham 的著作《Hackers &amp;amp; Painters》中，他计算得到：在一家创业公司，聪明的 hacker 可以比平均水平的办公室职员完成多 36 倍的工作——而且他们也将最终颠覆我们所知的就业。他让这个听起来很有爱国心和有意思；一个技术寡头怎么会出错呢？「hacker 是不遵守规则的，」他写道，「这正是 hacking 的本质，这也是美国做派（American-ness）的本质。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Graham 可以衡量申请者的技术能力，而他的妻子Jessica Livingston 则是一位出色的个性判断者。他们非常看重 20 多岁中期的人，Graham 写道：这个年纪的人的优势包括「耐力、贫穷、无根、同事和无知」。首批的八家公司（其中包括 Sam Altman 和两位朋友创立的移动应用 Loopt）平均每位创始人得到的 6000 美元，外加 Graham 的建议和家常煨鸡块，以及在那个夏季结束时可以向他的富有的朋友做十五分钟推销的承诺。这八家公司中包括 Reddit——现在已经价值 6 亿美元，而两年后的一批公司中还包括现已价值 100 亿美元的 Dropbox。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;2014 年，Altman 在斯坦福大学教授一个班级上提到，估计一家创业公司的成功几率的公式是「差不多类似于理念乘以产品乘以执行乘以团队乘以运气，其中运气是一个位于 0 到 10,000 之间的随机数字」。现在价值 300 亿美元的 Airbnb 的兴起似乎就充满了运气的因素。当它在 2009 年接触 YC 时，它通过销售新奇的谷物（Obama O』s 和 Cap』n McCains）所赚到的钱已经超过了其在床和早餐预订服务上所赚的钱。Graham 觉得这些创始人的想法是非常没有前途的，以至于他试图说服他们转而做支付。而将该公司转变成了一家全球生活空间的联合收割机的事件则是一场侥幸：Barry Manilow 的鼓手正在旅行，并问他是否可以把他的房子租出去而不提供早餐。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然而 Airbnb 的 CEO Brian Chesky 为该公司成功加入 Y Combinator 做出了很大的贡献。「当我们进入 YC 时，我们并不清楚我们之后是否还能生存下去，」Chesky 说。「而到了最后却成了：我们能否成为下一个市场，下一个 eBay？」这种极大增长的雄心壮志部分产生于这些创始人向 Altman（他当时还是 YC 一位不拿工资的导师和融资专家）展示一个幻灯片的时候，他们希望这个幻灯片能给他们保证 50 万美元的种子轮（即初始轮）资金。（公司通常在 YC 之后进行种子轮融资，一旦他们达到一个实际的里程碑后进行 A 轮融资，然后是 B 轮，以此类推。）「我们将我们的预计收入限制在 3000 万美元，」Chesky 说，「而 Sam 说，把那些 M 去掉换成 B。」（译者注：指将「百万（million）」换成「十亿（billion）」。）Altman 回忆曾经对他们说：「要么是你不相信你在这些剩下的幻灯片上的每句话，要么就是你觉得惭愧，或者是我数学不好。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2012 年对北美加速器的一项研究发现其中近半数都不能孵化出一家创业公司获得风险投资，尽管 Tech Stars 和 500 Startups 等少数几家加速器有几家价值数亿美元的公司，但 Y Combinator 已经孵化了至少 10 亿美元——而且至少有 11 家这样的。为数百家 YC 公司提供了投资的天使投资人 Ron Conway 告诉我说这家加速器是科技行业的明日世界（Tomorrowland）：「当我的团队在 YC 遇到 Airbnb 时，那是我们第一次思考共享经济。而当我们遇到 DoorDash 和 Instacart 时，我们说：『哦，上帝啊，原来有一种叫做按需经济的东西！』」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;随着 YC 成长，它搬迁到了山景城的一个远郊的办公室隔间，在旧金山南方一小时车程，在那里 YC 与一家名叫 Anybots 的公司共享办公空间。（在这间办公室里面，这些创始人必须小心谨慎不要被机器人碾压。）这家加速器很快就扩展到了第二个隔间，位于街对面，而现在这栋建筑也快达到消防规范的限制了。Altman 将 YC 比作谷歌的母公司 Alphabet，这是 Altman 的雄心壮志的体现；Alphabet 也由很多独立的互相合作的单元组成，也有一个类似的「登月」部门（moon-shot division）——X 研究组。他最近发了一条推文说 YC 帝国已经达到了 Alphabet 市值的 14%，而 Alphabet 的市值是世界上最高的公司之一，并且还在增长。「还有很长的路要走……」这是一个显失公平的比较：YC 对其公司的平均所有权，在被后续的风险投资稀释后只有 3%。然而 Altman 告诉我：「和谷歌不一样，随着我们越来越大，我们的发展也越来越快。我们会在十年内赶上它们。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于许多创业者来说，YC 提供了他们希望他们能有的大学经历。Michael Seibel 是最近负责这些批的 YC 合伙人，他已经经历这个项目两次了，他说：「P.G.」——指 Paul Graham——「过去常常在每批开始告诉每个人：『这里的一些人会出现在你的婚礼上，』对 300 个陌生人说这样话是件很怪异的事情。但几乎我所有的伴郎都在 YC。这让你想起了什么？大学。」Y Combinator 的创始人在每间隔一周的周二到这栋楼里面参加集体办公时间，而且还有额外的单独一个小时与他们指派的合伙人（那些教授）一起办公，然后他们一起在富美加长桌上吃面（食堂），听取 Marissa Mayer 和 Mark Zuckerberg 这些成功人士（访问学者）的观点。最后，他们在 Demo Day 上展示（为自己的观点辩护），看能筹到钱（合格）还是不能拿到钱（失败）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个课程故意搞得很斯巴达。一位 YC 合伙人 Kevin Hale 说：「我们对创业公司的要求非常简单，但要做到也很难。一，做人们想要的东西，」——这是 Graham 的一个短语，其被印在了给创业者的灰色 T 恤上——「二，你要做的所有事情就是和你的客户交流并打造东西。」YC 一家量子计算创业公司的创始人 Chad Rigetti 告诉我他的办公室墙壁完全是一片素白，「这样我的团队的神经元就不会因为外部刺激而偶然放电。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这里的伦理也得到了合议的明确。YC 在阻挡恶棍和恶霸方面很自豪。「我们很擅长将混蛋删选出去，」Graham 告诉我，「事实上，比起筛选失败者，我们更擅长筛选搅屎棍。他们都是从作为失败者开始的——而有的会逐渐变成失败者。」这家加速器还认为巨大的财富很亲睐解决一个紧急问题的副产品。这种利他主义和野心的交织是硅谷自我形象的一个标志性特征。Graham 在一篇文章《Mean People Fail（自私的人会失败）》中写道：忽略 Jeff Bezos 和 Larry Ellison 这种可能的反例，「自私会让你愚蠢」并让优秀的人不愿意为你工作。因此，在创业公司，「带有改善世界的渴望的人带有天然的优势。」这是双赢的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Graham 写道，一位创业者的首要目标应该是做到「拉面盈利（ramen profitable）」：节俭开支，晚餐吃得起拉面就够了。「你不会想要给这些创业者超过他们生存所需的东西，」Jessica Livingston 说，「资源精简迫使你专注。如果一个基金给我们提供 3 亿美元给创业者，我们不会接受。」（YC 的 17 位合伙人中许多人的财富都是来自于他们自己的创业公司——拿着仅仅 24,000 美元的工资，大部分都是通过股票补偿得到的。）这种逻辑达到极端会认为你甚至不应该从 YC 拿钱，而且许多成功的创业公司确实没有。增长最快的 500 家私营企业 Inc. 500 中只有 20% 拿了外部融资。但 YC 的证明和帮助你做大做强的承诺是很难被拒绝的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 Ralston 的柚子树旁边，Omer Sadika 和 Sebastian Wallin 一边品尝着开胃小菜，一边比较他们关于推出自己的安全公司 Secful 和 Castle 的压力的笔记。「我们目前每天睡觉最多五小时，」Sadika 说。Wallin 嘀咕道：「我已经忘了今天是几号了。」这两个男人都在计划搬到硅谷；Sadika 来自以色列，而 Wallin 来自马尔莫。「我们的客户在这里，」Sadika 说。而 Wallin 指出：「而且你离 Airbnb 和 Stripe 的企业家仅一步之遥。」YC 提供了进入硅谷的即时通道——硅谷这个地方，尽管说是精英的社区，却通常需要来自一个同事的「热情引荐」，而且这个同事通常是一位白人男性。这个聚会的所有早期的进入者都是男人；这一批的女性创业者当时正在参加一个关于作为一位女性创始人的难题的演讲。YC 比其它许多科技界的组织都更具多样性，但它也知道自己还有很长的路要走。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在一个火坑较远的一边，Shypmate（一款可以帮你和飞机乘客链接起来的应用，他们可以便宜地帮你的包裹从加纳带到尼日利亚）的两位创始人正在吐槽。Kwadwo Nyarko 说：「我们在享受旅行者的好处，就像他们说的，他们的行李箱从来没有装满过。」Perry Ogwuche 喃喃地说：「YC 告诉我们，『和你的客户交谈』，但我们很难找到我们客户。」Altman 走过去加入了他们，就像生日派对的魔术师一样尽责。「所以，你们有什么爱好？」他问。Ogwuche 不知所措地说：「我们工作然后我们去健身房。你的爱好呢？」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「嗯，我喜欢赛车，」Altman 说，「我有五辆，包括两辆迈凯轮和一辆老款特斯拉。我喜欢在加利福利亚上空驾驶租来的飞机。哦，还有一个很奇怪的——我为幸存做准备。」看到他们不明所里，他解释说：「我的问题是当我的朋友喝醉了，他们说起话来就好像世界就要完蛋了。在五年前荷兰一家实验室修改了 H5N1 禽流感病毒使其极具传染性之后，一种致命的合成病毒在未来二十年内被释放出来的概率就变得，呃，不再是零了。另一个最流行的情形是人工智能攻击我们以及国家之间为争夺稀缺资源使用核武器进行战争。」Shypmate 的这两位创始人看起来神情严肃。「我尽量不在这方面想太多，」Altman 说，「但我有枪、黄金、碘化钾、抗生素、电池、水、来自以色列国防军的防毒面具，还有在大苏尔（Big Sur）的一大块我可以飞过去的土地。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Altman 的母亲 Connie Gibstine 是一位皮肤科医生，她告诉我：「Sam 的内心确实有很多糟糕的东西。他会打电话然后说他的头很痛——他会在谷歌上搜索，所以他也有一些网络疑病症。我必须不断向他再次确认他没有脑膜炎或淋巴瘤，只是因为压力而已。」如果疫情确实爆发了，Altman 的后备计划是与他的朋友、亿万富豪风险资本家 Peter Thiel 飞往 Thiel 在新西兰的房子。Thiel 告诉我：「Sam 并不信特定的宗教，但他在文化上非常犹太人——一个乐观主义者也是一个活命主义者，他总是觉得事情总是会变得非常糟糕，而且世界上没有任何地方能让你深深感到有在家的感觉。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Altman 每年都会列表写出当年的目标，他每过几周都会回看一遍。这份列表总是包含一个高难度的体能挑战—每周进行一次 100 长的英里自行车骑行，50 个连续引体向上，同时也有一系列工作计划。今年，因为 YC，目标列表中的目标包含了「保持与合作伙伴的关系，将业务扩展至中国，如何将公司规模再扩展两倍。」这份最新的清单中也包含了提醒自己要资助阐释那些反直觉的量子物理现象的视频（QM 实验/物理讲解），也包括一个小提示告诉自己重读赫芬顿邮报上一篇向死者表示哀悼的文章「我希望这能让自己更开心一点」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他非常早熟，富有行动力。在他还是一个孩子的时候，在圣路易斯，他截获了幼儿园的系统后台信号，8 岁就已学会编程和拆解苹果电脑。这台苹果电脑成为他与世界的重要连接「在二十一世纪头十年的美国中西部地区作为一名同性恋长大并不是最可怕的事情。」他告诉我。「发现美国在线的聊天室可以改进才是，更不用说当时你只有十一二岁了。」当他 16 岁，和父母出柜的时候，他的母亲十分震惊。她告诉我「Sam 的那套性别和技术理论总是让我无语。」在教会在他所在的 John Burroughs 预科学校抵制了交友集会之后，Altman 写了一封公开信给整个社区，宣布他是一个同性恋，让学校明确它对于不同意见的态度。Altman 在预科学校的辅导员 Madelyn Gray 说道：「Sam 的做法改变了我们，这就像有人打开了一扇大门，让所有不同类型的孩子们终于能够走进世界。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他进入了斯坦福大学，在那里学习了两年计算机科学，直到他和两名同学肄业全身心投入 Loopt，这是一种和朋友分享地理位置信息的手机应用。,Altman 在 YC 中「年轻人领导年长者」的经验帮助了他，Loopt 成为了第一批进驻 Y Combinator 的创新企业。他是一个强有力的执行者：迅捷而宽容，但有时也显得愤怒。如果你和他擦肩而过，他会装作要拿着 ice-nine 加进你的食物（在 Kurt Vonnegut 的小说 Cat's Cradle 中，这是一种可以毁灭所有含水物体的可怕物质）。Paul Graham 如此理解 Altman 早期的成功秘诀「Sam 简直动力无穷」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Altman 在那个夏天不停地工作，让他得了坏血病。随后，他设法摆脱和移动运营商的无尽会议，和他们达成了协议，让他们的 app 的估值飙升至 1.75 亿美元。然而，Loopt 一直未获消费者青睐。「从乐观角度来看，分享位置信息是非常有意义的，」Altman 说道。「悲观地来看，人们也许更喜欢躺在沙发上消磨时间--不幸的是这才是真实情况。你永远不能让人们去做他们不想做的事。」在 2012 年，他和其他创始人以 4300 万美元的价格卖掉了公司，这个价格让投资他们的风投机构亏了钱。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Altman 在 Loopt 的联合创始人之一 NickSivo，曾经也是他的男朋友，但在公司被卖之后两人分手了。Altman 说，「我以为我非常爱他，打算和他结婚。」无所事事之下，他建立了一个小的风投基金 Hydrazine Capital。他募集了 2100 万美金，包括来自 Peter Thiel 的重大投资和出售 Loopt 之后的 500 万美元，然后投资了 YC 75% 的基金。他有在混乱中发现机会的诀窍。Altman 告诉我他带领了 Reddit 的 B 轮融资，一个长期无组织的 YC graduate，因为「你想要在混乱中投资某种程度上绝望的公司，你要先治疗上面的疣，也因为这些疣，这样的公司才被低估。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;仅仅四年，Hydrazine 的价值就翻了 10 倍。但尽管有这样的成功，Altman 退出了风投。他说，「你要努力找一家有你没你都能成功的公司，然后说服该公司接受你的投资而不是他人的投资，价格还要低。我不喜欢站在企业家的对立面。」对 Golcondan 财富谨慎的科技文化（也就是认为 10 亿美元是一 buck），他决定摆脱除了舒适享受之外的一切事物：旧金山教会区的 4 居室、汽车、Big Sur 财产、1000 万美元的储蓄，储蓄年利润就能覆盖自己的生活成本。剩下的就用来改善人类。像一家陷入困境的创业公司一样，Altman 做了一个激进的决定。有两个孩子的 Paul Graham 和 Jessica Livingston 因管理 YC 而精疲力尽，当时开始寻找继任者。Livingston 说，「我们没有一个表单说谁该运行 YC，但 Sam 在上面。那就 Sam 吧。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Graham 说，「我在厨房问 Sam，你想接手 YC 吗？然后他笑了，像是有戏。我从未见过 Sam 无所顾忌的笑，这种笑就像是你成功将一团纸仍入垃圾篓一样。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Altman 想要创建一个万亿美元的大集团，推动世界的前进。然后，他认识到，「没有重大科学进步，不可能有万亿美元的企业。」所以，他开了面向硬科技的批次，研究这样公司面临的科学和工程难题，并吸收最优希望的一批。在 2014 年，Altman 帮助说服了自动驾驶汽车公司 Cruise 的 CEO Kyle Vogt 做 YC；然后，在 Cruise 有资金难题之后，他投资了 300 万美元。在 3 月份，通用汽车 12.5 亿美元的价格收购了 Cruise。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;来源：http://www.newyorker.com/magazine/2016/10/10/sam-altmans-manifest-destiny&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Mon, 10 Oct 2016 18:22:15 +0800</pubDate>
    </item>
    <item>
      <title>特写 | 从Y Combinator到OpenAI，纽约客万字讲述Sam Altman的天定命运（下篇）</title>
      <link>http://www.iwgc.cn/link/3009687</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自纽约客&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Tad Friend&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：机器之心编辑部&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote style="line-height: 25.6px; white-space: normal;"&gt;&lt;p&gt;&lt;em style="color: rgb(136, 136, 136);"&gt;&lt;span&gt;&lt;em style="line-height: 28px; text-align: justify; white-space: pre-wrap; color: rgb(136, 136, 136);"&gt;&lt;span&gt;本文为《纽约客》最新一期文章，介绍了 YC 孵化器 CEO、OpenAI 联合创始人 Sam Altman。文中包含了众多科技投资、Open AI 人工智能研究的独家内容，是不可错过的一篇特写。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Altman 一直想要开始自己的核能源公司，现在他有了YC 来资助自己能找到的最好的核裂变与融合创业公司。然后，他个人也投资这些公司，成为董事。致力于社交的创业公司有数千家，但致力于核裂变与融合的创业公司不多于 20 家，Altman 说，「难事其实要比易事容易。因为人们感觉它有趣，就想要提供帮助。一家移动 app？你也就看一眼。一家火箭公司？每个人都想要进入太空。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Graham 曾写道在咨询创业公司时常援用的创始人是Steve Jobs 和Altman，「在设计问题上，我会问『Steve 会怎么做？』在策略或野心的问题上，我会问『Altman 会怎么做。』」在危机中的创始人首先呼叫 Altman，依靠他在硅谷最受欢迎的银行的快速交易的本领。他会说，「我呼叫 Brain，并解决了问题。」他把 Sam 比喻为 Brain Chesky（有能力将人看为棋子，并摸清下棋的路数。）YC 的一个创始人告诉我，「因为 Sam 能看见未来，我们就想让他告诉我们接下来会发生什么。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;挪威创业公司 Konsus 的这两位创始人和 Altman 抵达 YC 在旧金山市场南区的新站点时，他们就想朝圣者迈向山顶神社一样庄重。当时做商业与数据输入或网页设计的自由职业者对接服务的 Konsus 正处于寒冬期。尽管在 Demo Day 之后融资了 160 万美金之后，创始人仍旧充满焦虑。Fredrik Thomassen 说，他们想要获得永久的基金，Sondre Rasch 也提到为了省钱他选择主导郊区附近的 12 企业家的集体宿舍。所以，他们真的需要买工程计算机吗？这两个胡子邋遢，瘦的不成样子的人盯上了 Altman。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Altman 冷淡的说，「这是犯得较少的错误之一，试图太过节省。但如果有人能做到的，那就是斯堪的纳维亚人（挪威一人种）。所以，买计算机。」公司的两位创始人认真的店点了点头。从见过 Altman 之后，他们就很尊敬他。那时，他们对 Konsus 公司业务的解释是「公司将办公任务发给我们，基于技能和时间方便性，我们及时将这些任务分配给世界各地的顶尖自由职业者。」Altman 即刻问道，「那你们不就是按需临时代理吗？」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Thomassen 说，「我们当然会说质量，因为自由职业者的工作质量就是我们的不同之处。我们需要某种标准进行测量。」Altman 回应说，「重复使用和客户维系将会追踪质量问题，不需要创造新的复杂的度量标准。所以不用做。」Thomassen 列了一个表向 Altman 咨询「在接下来 3 个月中，哪些是我们最可能做错的？」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Altman 发现他们过分紧张并鼓励道：他相信，「做到最好的创始人都非常偏执，充满危机感。」他告诉他们，「从定义上来说，创始人喜欢开始新的事物。但做商业意味着 10 几年的刻苦。」而且并非讽刺的说道，「大部分人能做很多事，但很少能不屈不挠的做一些事。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Altman 简要的预知使得一个 YC 创始人称他为「创业公司的尤达大师。」企业家满怀沉重的来见他，15 分钟后就出来，问题得以解决。他的大部分建议都遵循 YC 透明度的标准规则：如果你担心投资者对 setback 的反应，「告诉他们」；你对潜在客户的沉默预示感到迷惑，「问他们」；棘手的问题引发他做出判断；「在竞争对手击败你之前，不要一直担心对方，」Altman 在午餐桌上这样告诉 Elucify 的创始人，「竞争对手是萦绕在你梦想中的最后怪兽中的一个。」几分钟后，他又开始了与加拿大自动驾驶公司 Varden Labs 的电话交流。在这家公司创始人告诉 Altman 自己的融资忧虑时，穿着大口袋短裤、灰色连帽衫的 Altman 挥舞着青铜时代的剑（买来作为送给 Paul Graham 的礼物）说，「融资 5000 万，」两手持剑猛地一划，「你要么需要一项重大技术突破，要么大客户要走。」他荡开想象的对手，无情的前行。那长期计划呢？这家公司的创始人问道，「无论你做什么一直考虑多增加一个零，不要再做多考虑。」一击命中心脏。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;四年前，在与旧金山北部的朋友为期一整天的徒步旅行中，Altman 放下了人类是非凡的的观念。在他们讨论人工智能发展状况的时候，Altman 意识到「认为在 13 年内不会有能够复制我们大脑的硬件的看法是毫无理由的。当然，一些事仍觉得专属人类——创造力、什么时候灵光一闪、同时感觉悲喜交加，但计算机将会有自己的期望和目标系统。当我意识到智能能被模拟时，我放弃了人类独一无二的观念，这也没有我想象的那样受创。」他凝视了一会儿，「成为一台机器有一定的优势。人类被输入-输出率所限制，每秒只学习 2 比特，丢失大量数据。而对机器而言，我们看起来肯定像是被减速的 whale songs。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Altman 与 Elon Musk 建立的非盈利组织OpenAI 是对人类主导的结局的对冲，一种战略防御构想，防止我们受到自己创造的事物的伤害。OpenAI 诞生于 Musk 持有的人工智能将意外的清除人类的信念。管理缺乏人类价值观的强大系统的难题得到了「paperclip maximizer」的例证，这是瑞典哲学家 Nick Bostrom 2003 年提出的场景。如果你告诉一个有全权的人工智能做尽可能多的回形针，且不给其他指令，它能耗尽地球所有的资源做回形针，包括我们体内的原子，假设它们不会完全的杀死我们，从而保证做更多回形针的任务不会被终止。OpenAI 特别担心谷歌 DeepMind 科技追求的强人工智能会监控全球竞争者，Musk 告诉我，「如果他们开发的人工智能扭曲了，我们就有风险会有永久的强大的独裁者。有一点的性格缺陷，它可能就会谋杀所有的人工智能研究员作为第一步行动。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Altman 说，「我们不打算开放所有代码，但也不要尝试做任何纠正，这只会使其更糟糕。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Amodei 问道，「那我们的目标是什么？」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Brokman 说，「我们目前的目标是做如今最好的事，这个说法有点模糊。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能技术如今看起来还不是全能的。微软发布聊天机器人 Tay 之后，Twitter 上的流氓用户马上就教会她发布类似「毒死犹太人」、「开打种族战争」之类的言论；最近发布的第一首软件生成的流行音乐「爸爸的车」，听起来像一群电子人披头士成员作曲。而然，Musk 告诉我：「现在没看见机器人杀手上街并不意味着我们就不该提防着。」苹果的 Siri、亚马逊的 Alexa 以及微软的 Cortana 为数百万人充当副手，实时翻译和自动驾驶技术也被想当然地信赖。Y Combinator 甚至开始使用一个叫做 Hal9000 的人工智能机器人来筛选申请：这个 bot 的神经网络通过评估之前的申请和这些公司的成果来训练自身。我问 Altman 说：「它寻找什么？」他回答：「我不知道。神经网络让人不安的就是这一点——你不知道神经网络在做什么，它也无法告诉你。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;OpenAI 在 6 月宣布了最近的目标，包括可以布置、打扫餐桌的家务机器人。长远目标之一是开发一个通用的、可以通过图灵测试的人工智能系统——这个系统可以通过推理和反应的方式让人相信他就是人。不过 Altman 也相信一个真正的通用人工智能应该不止于欺骗；它应该去创造，为了自己的求知欲和创造与，在量子物理上做出新发现或者发明一种新的艺术形式。很多人工智能研究者通过告诉系统「那是狗，不是猫」来纠正错误，OpenAI 致力于让系统自己学习各种事务的原理。「就像婴儿吗？」我问 Altman。他说：「很多人都忘了婴儿学习任何有意义的东西都要好几年。如果人工智能研究者在开发一个算法，而无意中碰到一个人类婴儿，研究者可能看烦了，觉得这个算法不管用而放弃它。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Altman 认为 OpenAI 的使命是照顾好自己的「神童」，一直等到他可以由世界来「抚养」。他一直在阅读詹姆斯·麦迪逊关于制宪会议的评论来获得这种转变上的指导。Altman 说：「我们正在计划让世界上大量的地区来选举代表，成立新的管理委员会。因为我不在其中，我可能要说：为什么这些混蛋可以决定我的生活？」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 Altman 管理下，Y Combinator 逐步变成了一个类似联合国的机构，他本人也越来越多地做出「秘书长级」的决定。也许，把人类托付给一个看起来不怎么对其他人感兴趣的人是有道理的。「Sam 为世界的计划基于想法，而不是人。」Peter Thiel 说，「这就是它有力的原因——它不会被主流人群的意见绑架。」当然，催生 OpenAI 就是强大的动力和强大的漠不关心的结合：如果一个老谋深算的人工智能不关心我们的意见，它又如何保护我们？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今年春季，Altman 在旧金山一个贸易展览上私下和国防部部长Ashton Carter 会面。Altman 穿上了他唯一一件西装夹克，灰色的夹克尺码颇大，还是他的助手为了一次香港之行使了小伎俩才给他量的。Carter 身着细条纹正装，开门见山地说：「瞧，很多人认为我们国防部又大又官僚。现在还出了斯诺登。」Carter 意指政府对待爱德华·斯诺登的方式，「不过我们想和你在硅谷进行合作，利用你的专长。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「当然，那太好了。」Altman 说，「你可能是世界上最大的一个客户了。」国防部明年的研发预算，超过了苹果、Google、英特尔预算综合的两倍。「不过很多初创公司因为要花一年来等你回复而很受挫。」Carter 把自己的食指指向自己的太阳穴，仿佛扣动了手中一把枪的扳机。Altman 继续说：「如果你能设立一个联络点，两周之内能够在就与 YC 公司开始试运行项目上做出决定，那再好不过。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「太好了。」Carter 说，看了一眼他七个助手中写下记录的一个。「还有呢？」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Altman 想了一会，说：「如果你或者你的副职之一能够来 YC 讲话，会有很大帮助。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我亲自来。」Carter 答应道。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;大家出来的时候，前微软高管、现国防部数字部门的领导 Chris Lynch 告诉 Altman：「要是谈谈 OpenAI 就好了」Altman 含糊地点了点头。2017 年美国军方预算中，有 300 亿美元被、划拨给了人机合作，即 Centaur Warfighting 计划，下一年中还有自己判定目标的远程导弹。Lynch 后来向我透露，OpenAI 系统会非常合适。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于将 OpenAI 产品交给 Lynch 和 Carter，Altman 有点犹豫：「我毫不掩饰地热爱这个国家，这是世界上最伟大的国家，」他说。在斯坦福大学时，他参与了 DARPA 一个涉及无人直升机的研究项目。「但有些东西我们绝对不会和国防部一起做。」他补充说，「我的一个朋友说，『能将我们从国防部的手里救下来的事情是：尽管他们有很多钱，但他们能力不是很强。』但我觉得很矛盾，因为他们有世界上最好的网络控制力。」在扫清混乱的本能的驱动下，Altman 想要帮助增强我们的军事力量，然后捍卫我们的世界免受新出现的力量的破坏。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 Demo Day 之后，它们的平均估值增至 1000 万美元。为什么短短三个月内这些公司的估值会跃升近 6 倍？人们对此有一些理论。其中一个是最好的创业者适合最好的加速器，而 YC 擅长选出那些无论如何都会成功的创业者。负责过过去几批的 Paul Buchheit 说：「这完全在于创业者自己。Facebook 有 Mark Zuckerberg，而 MySpace 只有一群猴子。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这样的必然结果是 Y Combinator 教会了它的公司如何在 Demo Day 上讲故事，从而让这些公司更有吸引力。很钦佩 YC 的风险资本家 Chris Dixon 说：「这些创业者得到了很好的训练，他们知道该如何对我们进行反向工程，一直到展示领域专长和讲述能够显示他们的毅力和勇气的关于他们的背景的趣闻。」在这个冬季批，开始保持着和以往差不多的调性：将自己和一家有名的独角兽公司链接起来（「我们是保姆行业的 Uber……非洲的 Stripe……医疗行业的 Slack」）或如果没有合适的类比，就说「X 坏了。未来 Y 会修复 X。我们正在做 Y。」然后夹杂着耐人寻味的流行语来表达你的陈述：我们「利用技术以一种完全自动化的方式来实现个性化」（实际上是：个性化洗发水）。Paul Graham 很高兴地承认了这一点，还不忘阐述理念：「我们帮助让糟糕的创业者和优秀的创业者看起来不一样。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一种理论是 YC 的确让这些公司更为优秀，通过教会他们增长高于一切，这些公司不会因为和科技媒体打交道、参加大会或者对代码进行无关紧要的修补而分心。YC 对于收入的黄金标准是每周增长 10%，即一年增长 142 倍。如果达不到，那就证明有其他的增长方式。在 Demo Day 上，有一家公司曾宣布他们有「50% 的口碑增长」，虽然没人知道那是什么。Sebastian Wallin 告诉我说，他的安全公司 Castle 募集到了 180 万美元资金，因为：「我们成功地找到了显示增长的方式。我们尝试了跟踪产品的安装情况，数据看起来不好。所以我们监测了被保护账户数量，这个数据在 YC 课程期间一直保持大约 30% 的增长，而 40% 的账户都是 YC 公司的账户。这是一个完美的童话般的故事。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;长时间快速发展即使在科技界中也难得一现，因为这需要通过不停创新来维持。不受控制地快速发展反而有可能让公司陷入困境。去年，在 Reddit 的一系列危机之后，Altman 在其董事会上说服了联合创始人 Steve Huffman，让他重新担任首席执行官。Huffman 说道：「我就任后立即跟 Sam 说『不要跟我扯增长率的事，我不能控制它』。像 Facebook，Airbnb 这样著名的初创公司，一开始都不知道他们增长的原因，并需要在增长停滞之前弄清楚。增长掩盖了所有问题。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;也许，YC 最决定性的理论是他们的关系网和其他所有理论背道而驰。YC 毕业的「校友」们认为他们就像财阀，一系列紧密联系的公司互相帮助。「YC 有他自己的经济体系，」Harj Taggar，Triplebyte 的联合创始人说道，这家公司帮助程序员申请 YC 系公司的工作。每年春天，创始人们来到 YC Camp，在旧金山以北的红杉林中，只为了互相保持关系，对于科技工作者而言，波西米亚风格的树林只意味着可以在户外尽情「释放膀胱的压力」。当 Altman 一开始找到 Kyle Vogt，Cruise 的首席执行官时，Vogt 已经在 YC 运营过一家创业公司，所以他明白其中的道理，他对我说：「我和五个曾在 YC 中创业两次以上的朋友们谈过，『值得再试一次吗？你会因为其品牌收获更高的估值，因为在他们的关系网中可以获得更多好处吗？』所有人都说了是。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;确实没有什么反理论（counter-theory）。「打击 YC 的是，在 Demo Day 那天，他们的用户仅仅是 YC 的公司，这完全解释了为什么他们都增长的如此之快。但是你有多大能耐能让一千多家公司都愿意使用你的产品呢！」不仅仅是 YC 的创业公司可以让 Airbnb 和 Stripe 去使用它们的应用程序；而且这个校友网络一窝蜂的成硅谷最大的公司。YC 的 121 家创业公司中，有很多在过去年中都被 Facebook、苹果和谷歌吸收了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然而，Altman 担心这个网络的异常高效会成为一个问题。在二月，他给最近的几批从训练班毕业的创业者发了一封邮件，警告一些已经有点自大和头衔的创业者。然后他告诉我，「如果这些公司仅仅依靠 YC 的名声才能保持活力，那么这对这些公司以及硅谷来说都是坏消息。烂公司迅速消亡对每个人都是更好的事情。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 Altman 家的一个晚上，他的弟弟 Max 和 Jack 正取笑说到他 35 岁时应该竞选 2020 年的总统。28 岁的 Max 说：「Sam，谁会比你更好呢？」Altman 试图不那么激烈地改变下话题，27 岁的 Jack 说，「这不是单纯的过家家。我确实认为技术需要一个好的候选人。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「让我们派去同性恋犹太佬吧！」Altman 说。「那会凑效的！」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Jack 盯着书架上一个叫「Samurai」的棋盘游戏说：「」当我们还是小孩子的时候，Sam 会赢得每一场 Samurai 游戏，因为他总是宣称自己是 Samurai 的领袖：「我必须赢，而且我主宰一切。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Altman 反击道，「你现在想玩国际象棋快棋吗？」，然后 Jack 笑了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Max 在 Y Combinator 孵化的 Zenefits 公司工作；Jack 联合创立了一家绩效管理公司Lattice，这家公司刚刚脱离了 YC 的孵化。这两个兄弟在三年前与 Altman 一起暂时搬进 YC 后就从未离开过。Altman 最近雇了一位设计师来将其灰色的宜家沙发升级为灰色的凉亭沙发，还挂了一些装帧精美的从外太空拍摄的照片，但房子仍然维持一种高档学生公寓的感觉。他的妈妈告诉我，「我觉得 Sam 喜欢让兄弟们待在自己的身边是因为他们理解他的情绪，并能够以别人做不到的方式提供反对声音。但其中的权利格局很微妙，而我想让它在爆发之前结束。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今年三月，Altman 写了一篇博文宣布自己投资了一家叫 Asana 的公司；他正领导着一个 500 万美元的 C 轮融资。为了团结你的员工，他写道，拥有明确的任务和目标很关键，这样可以清楚地与他们进行交流，并进行频繁的考核，而「Asana 是在这 3 个领域中战胜其他对手的最佳途径。」当 Jack Altman 阅读该博文后，他给 Sam 发短信说，「哎哟！」Lattice 是在推销说自己才是这些领域中战胜其他对手的最佳途径。然后 Jack 打给了他们的父母，他们都很吃惊。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「你还在生我的气吗，Jack？」现在 Altman 问道。当 Altman 意识到这个问题——「我在匆忙中写下了这篇博文，是 Asana 让我这么做的，而我已经听到了这么多 Jack 的推销，我一定已经多少吸收了他的一些言论」——时，他打给他的兄弟向其道歉并指出如何修复它。他解释说他当时并没有察觉到冲突：「我将 Asana 作为一个待办事项列表来使用。Lattice 没有这项功能。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「他不是恶意的，」Jack 后来告诉我。「那只是 Sam 在以每分钟一百万英里的速度前进。Sam 后来确实开玩笑说，『我们会把你粉碎，』「但我们已经处在修补阶段了。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 Altman 做 pasta 和 Marcella Hazan 的番茄酱时，Jack 又开始玩小孩子的游戏了。「今年冬天在 YC 的时候，当 Sam 将要来谈话时，每个人都会看着我。所有这些不了解 Sam 的人都把他当做... 不是当做碧昂丝，而是——」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「公平地说，你所过的生活几乎并没有你能做到的那样荒唐，」Jack 说。「你可以开一辆迈凯伦——」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「多去去 French Laundry（著名餐厅-译注）——」Max 插了一句。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「驾驶飞机飞在全加州上空，或者购买数万美元的化石，」Jack 总结道。其各项罪名成立的哥哥正俯在 pasta 汤前。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尽管 Altman 显然享受于经营 YC，但有时他似乎想知道在他迅速崛起的职业生涯中是否落下了一些东西。在其 Loopt YC 夏季项目过后的许多年里，他都无法忍受曾赖以度日的方便面或星巴克的咖啡冰淇淋；现在那些味道让他充满了渴望。今年春天，他看到 Nick Sivo 历经了一个新公司的诞生，这件事搅动起 Altman 少年时期积在心底的东西。当我跟这两人一起说话时，Altman 说，「我还把 Nick 给我的感觉冻结在 18 岁，而且我觉得他对我的看法也是一样。」Sivo 说，「我真的不明白你是什么意思。」「像一个无人认识和在意的大学生，」Altman 惆怅地说。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;推动世界的前进可能最终会开启巨大价值，但其代价昂贵。为了积聚必要的资金，Altman 静静地向硅谷更深处挖掘：他已经开始使 Y Combinator 变得更像一个投资公司。YC 一直以一个温柔、有益的天使投资人的形象出现，一个反对那些购买后就力求丰厚回报的冷酷的风险资本家的力量。Paul Graham 曾发表了一篇文章叫「风投蚕食统一理论（A Unified Theory of VC Suckage），」而早期 YC 项目的一个发言人搭起了一个标题为「风投：没有灵魂的撒旦代理人或只是笨拙的强奸犯？」的幻灯片。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过签署合同确保能够减轻风投们对公司财务状况的束缚，YC 已经帮助把权力移交给了企业家。这也完全以数字等级的形式给创业者提供了风险投资的书面评估。自从 Bryce Roberts 把他的入场标记借给一个非正式会员以来，其风险企业连续四年都未曾被邀请参加路演，他说：「他们的打压工具就是给你们贴标签。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;风投们已经认识到，如果他们要想试图对 YC 的顶尖企业进行注资，就必须提供公平条款，代表其初创公司努力工作，并给予 YC 要求的任何好处。许多人私下抱怨 YC 提价。有些人抱怨该加速器太达尔文主义（优胜劣汰-译注）。一个知名的风险投资人告诉我，「该程序对一批四强企业有好处，但对其余 46 家企业来说就太糟糕了，因为当他们来看我的时候，我就知道他们已经被红杉和 Andreessen Horowitz 抛弃了。」Andreessen Horowitz 的联合创始人 Ben Horowitz 指出，这种有利于顶尖创业企业的动态机制不是 YC 的专属：「创始人想从他们手里拿到钱的那些家伙拔得选秀头筹，其他所有人挑拣剩余的。这是资本主义！干你他妈的工作或者被干掉。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Altman 的投资方法已经由 Peter Thiel 塑造成型，他是一个 48 岁的自由论者，PayPal 和 Palantir 的联合创始人，曾暗中资助那起使得 Gawker Media 破产的诉讼案件，并试图通过摄入人类生长激素来延长自己的寿命。（最近，他一直想弄明白如果仅仅使用年轻人的血液是否可能会更好。）作为一位重要的风险资本家，Thiel 在很多方面都是 Paul Graham 的对立面，他并不赞成少量狂热用户和“拉面盈利”的想法，而是支持无法阻挡的指标和即时垄断。但这两人分享了他们对长远看待创始人品质和公司前景的关注：在 5 年或 10 年内，其产品的市场规模能否扩大 100 倍？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;多年来，YC 都在讨论对其企业进行后续投资，帮助它们进一步扩大规模并受益于规模。去年，Altman 提出了一个总量 40 或 50 亿美元的贷款池，以及一个 20 至 30 亿美元的增长基金。「我们都告诉 Sam 那大得有点疯狂，」一位 YC 骨干回忆到。Altman 最终同意了这个说法。「那些反对我的人竟然是对的——你无法真正向 YC 的各公司部署 50 亿美元，」他说。「至少现在还不行。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首个 YC 连续增长基金——一笔相对谦逊的 7 亿美元——于去年九月推出。而增长基金的投资者将会对 3 倍于基金规模的回报率感到高兴，Altman 希望的是一个前所未闻的 10 倍回报率。YC 将主要领导后续融资，但其三分之一的钱都用于维护 YC 在其所有企业中那 7% 的股份，这些企业会在他们毕业后进行资金募集。（如果 YC 只投资其最喜欢的企业，风投们就会作出其余都是二流企业的推论。）经营 YC 的 Ali Rowghani 将这种偏好行为描述为一个巨大的竞争优势：「增长的投资人花费他们 80% 到 90% 的时间来采购交易，像日本的捕鱼船队一样绕着地球旋转。我们是在不断进货的水族馆里钓鱼。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是对许多风险投资而言，YC 更像是一艘停泊在中国南海的驱逐舰。Bryce Roberts 说，「这已经成为一种破坏沙山路（Sand Hill Road）」——硅谷顶级风投公司驻留的地方——的方法。「如果 Sam 没有把它说出来，他也是在盘算。当你能够拥有 25% 的 Airbnb 时为什么只要 7% 呢？」令人担心的是，YC 不久将为如此多的初创企业提供从摇篮到上市（cradle-to-I.P.O）的全套基金，这会将大量风险投资挤出行业。这会大大减少其他初创企业的资金和技术资源——而把更多力量集中在 YC 手里。一位前列的风险投资者说，「在某些时候，他们将开始在 A 轮和 B 轮挑选出其最好的公司。我只是假设他们的计划就是破坏一切并接管这个世界。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当我向 Altman 提出这一想法时，他疯了。「在我经营 YC 时我们是不会领导 A 轮融资的！」他宣布。「这将给我们挑选最优公司的程序造成无法挽回的损害。」然而，帮助编写建立 YC 法律框架的 YC 合伙人 Jonathan Levy 观察道，「文件中有足够多可以做出优化的余地。看，Sam 很尊重红杉吗？是的。他是否认为他能做得更好？绝对地。他会做得更好吗？必须地。我是否能看到 Sam 接管整个风投系统？毫无疑问。原计划将会有一个例外，接着是两个，然后该系统就将改变。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在一次去纽约的旅行中，Altman 在一个星期六顺便去了趟我的公寓，讨论技术如何改变我们对于自己是谁的看法。他蜷缩在沙发上，膝盖抵住下巴，说，「我记得，当 Deep Blue 在 1997 年击败 Garry Kasparov 时，为什么任何人都不再在意国际象棋了？现在我对我们输给 DeepMind 的 AlphaGo 这一事实感到很伤心，」（AlphaGo 最近打败了世界围棋冠军）「我是人类团队的一员。我没有一个很好的逻辑原因来解释为什么我很难过，排除掉人类更擅长的事物梯队持续收缩这个原因，」过了一会儿，他补充说，「『忧郁』是一个比『悲伤』更好的词。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;硅谷的许多人都痴迷于模拟假设，该争论认为我们作为现实的经历实际上是由一台计算机上编造的；两个技术届的亿万富翁已经走了很远的路来秘密地聘用科学家致力于将我们从模拟中解放出来。对 Altman 来说，危险不是来自于我们可能的创造者，而是来自于我们自己的创造物。「这些手机已经控制了我们，」他告诉我，正对着自己的 iPhone SE 皱眉。「融合已经开始——而融合是我们的最佳行动方案。任何不带融合的版本都将会有冲突：我们奴役人工智能或者人工智能奴役我们。完全疯狂的融合版本是将我们自己的大脑上传到云端。我喜欢这个版本，」他说。「我们需要提升人类的层次，因为我们的后代将要么征服银河，要么在宇宙中永远地熄灭意识。活着多神奇！」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一些未来学家——da Vinci、Verne、von Braun——想象着几十年或几个世纪后的技术。Altman 则评定着目前的主动权和威胁，然后专注于务实的行动来推进或阻碍它们。Paul Graham 的技术计划没能阻止唐纳德·川普，而是 Altman 在沉思川普问题数月之后，最近宣布了一个叫 VotePlz 的无党派项目，旨在获得年轻人的选票。将选举视为一个技术问题——什么是得到最多回报的最少代码？——Altman 及其三个联合创始人通过为 9 个摇摆不定的州的年轻人提供注册表格和邮票来专注于帮助他们注册。在选举日当天，VotePlz 的应用程序甚至可能被设定成呼叫一辆 Uber 载你去投票。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;合成病毒？Altman 正在 YC Research 中筹划一个可以阻止它们的合成生物学研究单位。衰老与死亡？他希望资助一个致力于异种共生的公司，把青春血液的回春灵药作为一种注射剂。「如果它凑效的话，」他说，「你仍然会死亡，但你可以在 120 岁时都相当健康，然后迅速老去。」人类的衰老？他正在考虑建立一个研究小组来为我们的最终继任者做准备，无论它将是一个人工智能还是增强版的智人。这个想法将会集结机器人、控制论、量子计算、人工智能、合成生物学、基因组学、太空旅行以及哲学领域的思想者，探讨科技与人类置换的伦理。目前，那些领域的领袖会在 Altman 的房子里半定期地举行会议；该组织戏称自己为契约（Covenant）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Altman 凝视着前方，情绪偶尔会笼罩在他那无瑕的面罩上。他告诉我，「如果你认为所有人类的生命都具有相等的价值，而且认为 99.5% 的生命将发生在未来，那么我们应该把我们所有的时间都用于思考未来。」他的声调下降了。「但我确实更关心我的家人和朋友，」他问我会允许多少陌生人死亡——或者被我亲手杀害，这看起来对他而言在理智上更为诚实——为了拯救我爱的人。由于我考虑过这个问题，他说他会牺牲十万条生命。我告诉他我自己的这一数字会更大。「这是一个缺陷，」他宣布说，无法正视。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他更喜欢把创新的结构视为一个系统问题。即刻的挑战是计算机会使我们大多数人失业。&lt;/span&gt;&lt;span&gt;Altman &lt;/span&gt;&lt;span&gt;的补救措施是&lt;/span&gt;&lt;span&gt; YC Research &lt;/span&gt;&lt;span&gt;的一项五年期的研究——基本收入项目（&lt;/span&gt;&lt;span&gt;Basic Income project&lt;/span&gt;&lt;span&gt;），计划于&lt;/span&gt;&lt;span&gt; 2017 &lt;/span&gt;&lt;span&gt;年启动，一个突然流行起来的古老思想：给每个人足够的钱去生活。扩大在加拿大尼托巴省、乌干达等地的早期试验规模，&lt;/span&gt;&lt;span&gt;YC &lt;/span&gt;&lt;span&gt;将给奥克兰的多达一千个人每年大约&lt;/span&gt;&lt;span&gt; 1.2 &lt;/span&gt;&lt;span&gt;万至&lt;/span&gt;&lt;span&gt; 2.4 &lt;/span&gt;&lt;span&gt;万美元。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个想法的问题与预想的一样基础：为什么那些不需要津贴的人会拿到钱？难道免费鼓励了人们懒惰吗？而里面的算术令人震惊的：如果你给每个美国人&lt;/span&gt;&lt;span&gt; 24,000 &lt;/span&gt;&lt;span&gt;美元，年账单将会高达&lt;/span&gt;&lt;span&gt; 8 &lt;/span&gt;&lt;span&gt;万亿美元——是联邦财政税收的两倍。然而，&lt;/span&gt;&lt;span&gt;Altman &lt;/span&gt;&lt;span&gt;告诉我们，最让人们担忧的是「如果劳动力成本降低为零」——因为机器人已经取代了所有的工作。人们生活所需成本也会急剧下降。如果我们能用上核能那么电力就是免费的，那么交通费用会大大减少。人们的花费将从用电转为食物和水。人们现在在获取好的教育上花费了大量钱财，而如今你可以通过手机就可以在大多数事情上成为专家。所以，如果一个美国的四口之家需要&lt;/span&gt;&lt;span&gt; 7 &lt;/span&gt;&lt;span&gt;万美元才能生活的快乐，这也正是你常听到的金额数目。那么在未来十到二十年内，这一数目将会出现数量级上的下降。除去住房的支出外，一个家庭只需花费&lt;/span&gt;&lt;span&gt; 3,500 &lt;/span&gt;&lt;span&gt;到&lt;/span&gt;&lt;span&gt; 4,000 &lt;/span&gt;&lt;span&gt;美元即可拥有开心的生活。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;span&gt;在最好的情况下，科技将带来强有力的改革，&lt;/span&gt;&lt;span&gt;Altman &lt;/span&gt;&lt;span&gt;不需要在少数和多数中作出选择。当人工智能重新改造经济时，他告诉我：「我们将拥有无止尽的财富，大量工作岗位将被替代。所以基本的收入就能满足生活所需。在此基础上，薪水将会逐渐变为零，每一百万人中就会有一个人能够创造出下一家苹果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在接近冬季训练营快结束时，YC 合伙人和团队开展了一个全面会议。Paul Buchheit，负责的合伙人讲到创业者们的调查结果。人们对于食物（没有足够的选择给不吃茄科食物的人）和咖啡（速溶的）都有怨言。最主要的批评，Buchheit 说，是这一批里有 127 个公司。「YC 觉得太多了，我们也都有同样的感觉。创业者并非是一群学生或农场里放牧的动物。他们是下一个 Mark Zuckerberg。他们是一群对于我们的成功至关重要的人，因为他们爱我们。」他总结道，「我的目标是下一场训练营中只能有 100 个公司。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;后来，Altman 跟我说，将精力完全放在创业者身上是不对的。「当我接管时，」他说，「我测量了公司与 YC 相处的愉快程度，但这样的衡量其实是不对的。」为了保证我们能够获得并保留最好的投资者，我们现在还衡量合伙人的开心程度——现在是 4.38 比上 5——「与一家没有成功的公司是否会对我们的爱感到不开心。」。风投人相信他们的回报遵循着一个「power law」，百分之九十的收入来自于一两个公司。这就意味着他们暗地里希望其他跟随的公司快快垮掉，而不是像「僵尸」一样蹒跚的跟着耗费资源。Altman 指出 YC 仅有约五分之一的公司垮台，又说：「我们应该更加冒险，所以我们公司的倒闭率会高达百分之九十。如果你对回报足够乐观，你会愿意选取这一群中最好的公司来集资。他承认：「这样可能会使其他的公司都失去信心，你也不能由此建立一个有用的网络。」而从另一方面讲，一个有着 3 或 4 个 YC 公司的网络将会很有帮助。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于过多和过快加大规模的担忧现在仍广泛存在。Drew Houston，Dropbox 的创始人之一，告诉我们有才华的创始者并非是无穷的。「从某种程度上说，第 10,001 号公司，是在向他人承认你曾被拒绝过」Marc Andreessen，他的风投公司将 50% 的资金投资给 YC 公司。他说：「综合来看，YC 正在逐渐扩张的过程中也逐渐更加挑剔。同时，由于他们有着越来越强的吸引力，他们也渐渐获得了一群有质量保证的常规创始者。」但是他又讲到：「争论在于：他们是否将网络延伸到了临界点？这是天才和疯子混合在一起。」在巨大的成功下，Valley 的指导思想有了冲突之处：他们的规模中排除了统一化的优秀和紧密的网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Altman 承认了 YC 网络中的缺陷。数百个初创的公司希望能够在 Patrick Collison 的 Stripe 公司说得上话。提及 Stripe 刚刚指派了一名联系人到 YC 关联的咨询公司，他表示希望 YC 的其他的锚定公司也能够照着这样做。他们应该尽快。从这个冬天开始，YC 协会将成为一个创业公司学校，一个为所有想要来参与的公司提供免费，线上，10 周课程的地方。他们不会拿到资金，但他们可以学到和在批公司相同的东西。Altman，负责掌控这个启动的项目，相信这是在一年里最快将数以千计创始者带入网络中的办法。他说：「如果我们创造更多规模，10 倍数量的创业公司，尽管我没有他们的所有权，但他们一定会在我或许不能预测到的地方帮到 YC。」同时，夏季批次，包括协会以内共计 170 个公司，超过了冬季批次。而在冬天，YC 将把编程工作从每周一晚增加到每周两晚，以跟上更快的增长步伐。Altman 计划明年建立 YC 中国，并将 YC 印度纳入考虑。他说：「总有一天，YC 会比我现在接手时还要大百倍或者更多。」尽管我们会犯错误，但没有人能够阻止我们的步伐。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Altman 的掌管让一些 YC 的人们怀念起过去 YC 如家庭般的友情之中。一位YC 的忠实拥护者告诉我：「Sam 把荣耀看得太重，他将他的个人品牌放在第一位。在 P.G 的管理下，我们有家一样的感觉，但现在我们只感受到一个个组织以及人与人间的疏离。Sam 总是在向上管理，但作为一个组织的领导者，他应该向下管理。」当我告诉 Altman 这样的批评后，他说：「我当然应在管理组织上做得更好——这正是我在 Loopt 里最大的缺点，对此我也有些无能为力。我不希望每周一对一的讨论你的工作前途，但我觉得在做出正确的大决定的前提下，管理中有一些小的混乱是可以的。毕竟他们给我们带来了全部收入」他提到，「我的脑中缺乏一条回路，这条回路让我在乎人们怎么看我，这是天生的。多数人人们希望被其他人接受，因而他们不会冒险去做那些让他们看起来很疯狂的事。尽管实际上这样做让他们错误的估计了风险。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最近，YC 开始计划一个项目用来测试建立自己的实验城市的可能性。它可能位于美国，也可能在国外，会为科技成果进行最优化设计：道路可能只允许无人驾驶汽车通行。「它就像在 YC 之外建立的一所大学，一所未来的大学。」Altman 说，「十万英亩的土地，五到十万的居民。我们建立基础设施，并提出可负担的新生活概念：没我有人会在房地产上花钱。」他强调这仅仅只是一个想法，但他已经开始找寻潜在的合适地点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你能想象这个大都市可以成为人工智能运行的后人类城市的典范，一个 21 世纪的雅典，或者是为精英服务的带警卫的社区，一个隔绝外界混乱的堡垒。对 Altman 来说探索未来究竟会有些什么的最佳方式就是自己去创造一个未来。他在 OpenAI 做的头几件事之一就是把 Admiral Hyman Rickover 的话印在会议室的墙上。「人生的伟大目标不在于知而在于行。」Rickover 的名言。「我相信这是每个人的义务去活得像世界的命运取决于他一样，我们必须为了未来而活，而不是为了个人的舒适或成功。」同样来自 Rickover。Altman 回数了 Rickover 为了建造美国核海军所克服的困难。「不可思议」他评价道，但在片刻的思考停顿后，他又补充说：「在他生命的尾声，上到一定的年纪之后，他也确实说过该把这一切沉于海底。这有一些值得思考的东西在里面。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em style="color: rgb(136, 136, 136); line-height: 28px; text-align: justify; white-space: pre-wrap;"&gt;&lt;span&gt;来源：http://www.newyorker.com/magazine/2016/10/10/sam-altmans-manifest-destiny&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Mon, 10 Oct 2016 18:22:15 +0800</pubDate>
    </item>
    <item>
      <title>技术| DeepMind语音生成模型WaveNet的TensorFlow实现</title>
      <link>http://www.iwgc.cn/link/3009688</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自github&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote style="white-space: normal;"&gt;&lt;p&gt;&lt;em style="color: rgb(136, 136, 136);"&gt;&lt;span&gt;九月的时候，DeepMind 公布了一个机器学习语音生成模型 WaveNet，详情参阅机器之心的报道&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719022&amp;amp;idx=1&amp;amp;sn=3eeb1958e695388817dd32b0d228ced9&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719022&amp;amp;idx=1&amp;amp;sn=3eeb1958e695388817dd32b0d228ced9&amp;amp;scene=21#wechat_redirect"&gt;《DeepMind 最新生成模型 WaveNet，将机器合成语音水平与人类差距缩小 50%》&lt;/a&gt;。近日，GitHub 用户 ibab 发布了一个 WaveNet 的实现，机器之心在这里对其介绍文档 README.md 进行了介绍编译。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;项目地址：&lt;span&gt;https://github.com/ibab/tensorflow-wavenet&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是用于音频生成的 WaveNet 生成式神经网络架构的一种 TensorFlow 实现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;WaveNet 神经网络架构可以直接生成原始音频波形，能够在文本转语音和常规的音频生成上得到出色的结果。（具体介绍请参阅前言中链接的介绍文章）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该网络可在给定所有之前的样本和可能的额外参数的条件下，通过建模条件概率（conditional probability）来生成音频波形的下一个样本。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在一个音频处理步骤之后，其输入波形会被量化到一个固定的整数范围内。然后这个整数振幅（integer amplitudes）会被独热（one-hot）编码以生成一个形状的张量（num_samples, num_channels）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一个卷积层只能获得当前和之前的输入，然后减少信道维度（channel dimension）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该网络的内核被构建为一个因果扩张层（causal dilated layers）的堆叠，其中每一层都是一个扩张的卷积（dilated convolution，即带有 hole 的卷积），它只能获取当前和过去的音频样本。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所有层的输出通过一系列密集的后处理层（postprocessing layers）被结合起来并扩展回原来的信道数量，后面再跟上一个 softmax 函数将这些输出转换成一个分类分布（categorical distribution）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其损失函数是每个时间步骤的输出和其下一个时间步骤的输入之间的交叉熵（cross-entropy）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这个 repository 中，该网络的实现可以在 wavenet.py 文件中找到。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;要求&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在运行本训练脚本之前需要先安装 TensorFlow。支持 TensorFlow 0.10 和当前的 master 版本。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此外，为了读取和写入音频还必须安装 librosa。（地址：https://github.com/librosa/librosa）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;安装所需的 Python 包（TensorFlow 之外的），运行&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;pip install -r requirements.txt&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;训练网络&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你可以使用任何包含 .wav 文件的语料库。我们目前主要使用的 VCTK 语料库。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;VCTK 语料库地址：http://homepages.inf.ed.ac.uk/jyamagis/page3/page58/page58.html&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;备用地址：http://www.udialogue.org/download/cstr-vctk-corpus.html&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了训练该网络，执行&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;python train.py—data_dir=corpus&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其中 corpus 是包含 .wav 文件的目录。本脚本会递归式地收集该目录下的所有 .wav 文件。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你可以通过运行&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;python train.py—help&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;查看每个训练配置上的文档。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;模型的参数的配置可以在 wavenet_params.json 中找到，这些配置需要在训练过程和生成过程中保持一致。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;生成音频&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;由 @jyegerlehner 基于来自 VCTK 语料库的 speaker 280 所生成的样本输出：https://soundcloud.com/user-731806733/speaker-p280-from-vctk-corpus-1&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你可以使用之前训练好的模型通过执行 generate.py 脚本来生成音频，运行：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;python generate.py—samples 16000 model.ckpt-1000&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其中 model.ckpt-1000 需要是之前保存的模型。你可以在 logdir 中找到这些。使用—samples 参数设定你需要生成的样本的数量（默认是 1 秒生成 16000 个）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;生成的波形可以使用 TensorBoard 回放，或使用—wav_out_path 参数存储成 .wav 文件：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;python generate.py—wav_out_path=generated.wav --samples 16000 model.ckpt-1000&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除了—wav_out_path，通过 --save_every 也可以每 n 个样本保存一次进行中的 .wav 文件：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;python generate.py—wav_out_path=generated.wav --save_every 2000 --samples 16000 model.ckpt-1000&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;快速生成是默认开启的。它使用了来自 Fast Wavenet repository（地址：https://github.com/tomlepaine/fast-wavenet）的实现。你可以通过这个链接了解其工作方式。这可以将生成样本所需的时间减少到几分钟。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;关闭快速生成：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;python generate.py—samples 16000 model.ckpt-1000 --fast_generation=false&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;运行测试&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;安装测试要求：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;pip install -r requirements_test.txt&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;运行测试套件：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;./ci/test.sh&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;缺少的功能&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前还没有调节说话者 ID 等额外信息的功能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQXA6DfvmAhrhynJ5Kv8I38ibRltibzciaAJGkVDGDQxKvlvdPmibcjVwgrD19MMn5Lic3leKwRpPLic0w/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Mon, 10 Oct 2016 18:22:15 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 如何正确区分人工智能界面和聊天机器人？</title>
      <link>http://www.iwgc.cn/link/3009690</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自VentureBeat&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李泽南&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;时至今日，人工智能已经进入了生活的方方面面，他们也在影响着创业公司。面对市面上数量众多标榜「人工智能」的产品，我们需要保持怀疑。「它们真的是人工智能产品吗？」什么是人工智能聊天机器人？Siri 是一个聊天机器人吗？Viv 会使用人工智能为我预订机票吗？越来越多这样的问题需要获得解答。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;em style="color: rgb(136, 136, 136);"&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这里有一项简单的测试，向几种聊天机器人提出一些随机，不相关的问题，来观察它们的反应。人工智能不仅意味着让电脑获得人类的思考和学习方式，它更使得程序有能力理解和解决问题。如果向普通计算机提出一个问题，它不会做出反应，因为它无法理解。但如果你对一个人工智能程序发出同样指令，你会收到多种不同回复。目前的人工智能仍然不能代替人类所有的工作，在很多情况下，它们需要人类来指挥才能完成任务。以网页制作和聊天机器人程序为例，思考一下，他们到底是不是人工智能？如果是，其中人工智能应用程度如何？以下的解释可以区别人工智能界面和人工智能聊天机器人的不同。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;人工智能界面&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能界面背后存在一定的人工智能或计算智能。它是人工智能和普通用户界面的混合体，通常这些界面只有简单的页面设计。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能界面正被很多创业公司使用，它可以完成多种任务，这些界面可以在 Slack 和 Messenger 中的机器人中找到。以包含人工智能的网页设计软件 Weps 为例，这家创新企业使用人工智能界面让用户在 Weps 提出的固定问题中选择答案来构建网页。这其中没有用到多少人工智能，它没有输入框，用户只能在一些已经写好的答案中进行选择。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQXA6DfvmAhrhynJ5Kv8I3aiaiaKDibY6ANp9H3tVtAQFhibNEHg14mQJE146HTcv9ibibiaLZks6aicQCrw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个界面不断向用户提供相关建议的按钮，但这并不是基于人工智能。当然，这种方式相比普通的用户界面显得更有效率，其后的代码和智能链接起到了作用。通常，不同计算机界面需要进行专业设计，包含大量信息，以满足不同行业和使用情况的需求。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些因素也使得人工智能界面可以更好地理解用户所需，提供个性化或指导性的交互体验。但是，尽管这种类型的用户界面背后有人工智能的帮助，它们也无法和人工智能聊天机器人相比。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;人工智能聊天机器人&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前存在两种聊天机器人；脚本机器人和人工智能机器人。脚本机器人中不包含任何人工智能，而人工智能机器人是建立在神经语言程序学「Neuro Linguistic Programming，NLP」和机器语言「Machine Language」之上的。后者拥有人类的学习和信息接受能力，因而更具效率。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些高效的机器运算速度可比人类快 1000 倍，而且能得到更加精确的结果。人工智能聊天机器人比任何人工智能界面更加高级。如果考虑到易用性，A.I. 聊天机器人也更有优势，因为用户界面只能提供固定的选项。在使用人工智能聊天机器人时，你可以输入你自己的回答。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;使用人工智能聊天机器人，我们可以创造更多的可能性。当它们变得更加易用，我们也开始习惯使用之后，是时候进入超级智能的时代了？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;RightClick.io 是一个独立的人工智能聊天机器人，它使用聊天界面，通过人工智能来帮助人们创建网页。这种聊天机器人可以利用自身智慧理解和解答问题。以下是和 RightClick 的一些对话。你可以在聊天界面中询问关于制作网页的各种问题，但测试中的问题都是普通的聊天内容。你会发现聊天机器人有能力通过人工智能来回答这些问题，并没有出现任何预先写好的固定回复。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQXA6DfvmAhrhynJ5Kv8I3ibBHIxPdNIOzybJ93qMumWMfYUJhyVfLGiaEMwI6Dv1bUaxUvTIdhzog/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Mon, 10 Oct 2016 18:22:15 +0800</pubDate>
    </item>
    <item>
      <title>机器之心北美系列技术分享活动——UCLA站报名开启！</title>
      <link>http://www.iwgc.cn/link/3009692</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibQXA6DfvmAhrhynJ5Kv8I3qSv8pSJkb33TibO5OZPib5lq9XlFzmgMVbwVhyEf7EZRiazKtmVjcL6yQ/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器之心北美系列活动已经成功举办了波士顿、多伦多、滑铁卢和蒙特利尔四站，中国人工智能公司进行了 9 场演讲，场均有 50-100 名华人留学生和从业者参加。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;接下来，UCLA、西雅图和埃德蒙顿三站将如期举行，其中 UCLA 的活动已经开始报名（报名地址在文末），无法在场的小伙伴也可以通过视频直播的方式进行观看（直播地点见文末）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;UCLA场次信息&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;美西时间：2016年10月12日，PM 6:30-9:00 &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;地点：Boelter Hall Penthouse (8500), 580 Portola Plaza, Los Angeles, CA 90095&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Agenda&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;6:30 - &amp;nbsp;7:00 Pizza &amp;amp; Social&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;7:00- 7:30 &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;Ming Yang 杨铭：&amp;nbsp;From Computer Vision Research to Product: Challenges and Opportunities&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Co-founder &amp;amp; Vice President of&amp;nbsp;Horizon Robotics Inc.（地平线机器人）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Dr. Ming Yang is the Co-founder &amp;amp; Vice President of Horizon Robotics Inc. He is one of the founding members of the Facebook Artificial Intelligence Research (FAIR) and a former senior researcher at NEC Labs America. Dr. Yang is a well-recognized researcher in computer vision and machine learning. His research interests include object tracking, face recognition, massive image retrieval and multimedia content analysis. Dr. Yang owns 14 US patents, and has over 50 publications in top international conferences and journals with more than 3600 citations, h-index 29. During his tenure at Facebook, Dr. Yang led the deep learning research project “DeepFace”, which had a significant impact in the deep learning research community and got widely reported by various media including Science Magazine, MIT Tech Review and Forbes. Dr. Ming Yang received his B.Eng. and M.Eng. degree from the Department of Electrical Engineering at Tsinghua University and Ph.D. degree from the Department of Electrical Engineering and Computer Science at Northwestern University.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;This talk will cover both a brief introduction of Horizon Robotics and the learning in developing products primarily using computer vision techniques. Artificial intelligence startup Horizon Robotics, founded in June 2015, strives to innovate turn-key solutions that integrate software, hardware, and cloud systems, to make human life more convenient, safe, and fun. In productionizing image recognition techniques, especially using deep convolutional neural networks, the major technical challenges include, but not limited to, the balance between computational efficiency and recognition accuracy (i.e., the cost vs. performance), the trade-off of developing time against functionalities, the issues on product consistency, reliability and the deliverables. Nevertheless, the rapid advance of computer vision technology opens up more business opportunities such as smart home and autonomous driving, etc.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;7:30 - 8:00 &amp;nbsp;杜力：智能物联网 (I2OT)&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Kneron AI芯片架构研发&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;杜力11年本科毕业于东南大学信息工程专业，凭借优异的成绩，被加州大学洛杉矶分校录取，攻读博士学位，博士期间从事高性能传感电路和复杂数字电路系统的研究，在国际一流期刊，会议上，发表论文数篇，其研究成果被Spacemos公司产业化。13年6月起加入美国高通公司，任高级工程师。16年9月起，加入Kneron公司，从事AI芯片架构的研发。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Kneron 是一家专注于深度学习研发的公司， 总部设立在美国加州的圣地亚哥市，同时在深圳，台北设有研发和销售分部。Kneron致力于为人们生活，出行，工作等方方面面提供智慧服务， 包括智能软件开发，智能硬件加速，以及智能生态系统的构建。公司由多位资深创业者创立，技术团队多来自于全球知名的消费电子企业，如三星电子，高通，英特尔等，以及知名高校的博士毕业生，如UCLA，USC，MIT等。 技术团队拥有丰富的产品研发以及项目运营的经验。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本次活动杜力将与大家分享智能物联网(I2OT)的概念：使用为嵌入式系统优化的人工智能系统，AI可以与物联网结合，使人工智能进入到日常生活的方方面面。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;8:00 - 8:30 &amp;nbsp; 丁晓伟&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;VoxelCloud Cofounder&lt;/span&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Xiaowei Ding cofounded a artificial intelligence for medicine startup, VoxelCloud Inc., with Prof. Demetri Terzopoulos (FRS, FRSC, IEEE &amp;amp; ACM Fellow, Distinguished Chancellor's Professor of Computer Science). I also hold an assistant researcher position at UCLA Computer Science Department.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;8:30 - 9:00 &amp;nbsp;黄泽铧 ： 图森的自动驾驶之路&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;图森科技合伙人，研究员&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;卡内基梅隆大学机器人学硕士，北京航空航天大学本科研究生期间参与研发驾驶员监控系统，技术用于美国通用汽车产品。大学期间曾研发可穿戴手势识别腕带，获多项大奖。现在担任图森北美人脸与深度学习团队负责人。本次活动黄泽铧将和大家分享自动驾驶的历史发展和关键技术。并向大家介绍图森在自动驾驶方面所取得的成果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;UCLA站联合主办&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQXA6DfvmAhrhynJ5Kv8I3ERGpy2aeCvSklKzUsYDyjk3iaMzE0kYyugLAFp8GmgS1VnkrVf8swqg/0?wx_fmt=png"/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;矽说由各大名校精英创建，旨在提供高质量的电子行业前沿信息，并致力于工程师社区的建设，为工程师说话。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;本站支持及协办单位&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;PlusYoou普创&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;UCI&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;CaltechC&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;直播链接 &lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;a style="font-size: 14px; color: rgb(171, 25, 66); text-decoration: none;"&gt;&lt;span&gt;https://zoom.us/j/197804272&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;点击「阅读原文」进行报名。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Mon, 10 Oct 2016 18:22:15 +0800</pubDate>
    </item>
    <item>
      <title>深度 | 分布式深度学习：神经网络的分布式训练</title>
      <link>http://www.iwgc.cn/link/2990664</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自 skymind&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;作者：Alex Black 、Vyacheslav Kokorin&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：Xuwen Wang、Xavier Massa、吴攀、李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;本文编译自 Skymind 的技术博客，作者是深度学习工程师 Alex Black 和 Vyacheslav Kokorin。按照计划，《Distributed Deep Learning》系列文章一共有三篇，本文是其中的第一篇，后续的文章机器之心还将继续跟进。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是关于「神经网络的分布训练」的三篇系列文章中的第一部分。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在第一部分，我们将看到如何在 GPU 上用分布式计算大大加速深度学习模型的训练速度，并讨论近期该领域上的一些挑战和近期的研究。同时，我们还要考虑：在什么时候，神经网络的分布式训练是适合或不适合特定的案例的？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在第二部分，我们将上手式地看看在 Apache Spark 上的 Deeplearning4j 的网络训练的实现，并从头到尾展示一个「如何在实践中执行训练」的例子。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，在第三部分我们将探索 Deeplearning4j 的 Spark 实现的背后情况，并讨论使用 Apache Spark 时的一些涉及到最大化训练表现的执行和设计挑战。同时，我们还将看看 Spark 如何与本地的高性能的计算库和 Deeplearning4j 所使用的堆外内存（off-heap memory）管理互相配合。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;介绍&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在大型数据集上进行训练的现代神经网络架构可以跨广泛的多种领域获取可观的结果，领域涵盖从语音和图像认知、自然语言处理、到业界关注的诸如欺诈检测和推荐系统这样的应用等各个方面。但是训练这些神经网络模型在计算上有严格要求。尽管近些年来 GPU 硬件、网络架构和训练方法上均取得了重大的进步，但事实是在单一机器上，网络训练所需要的时间仍然长得不切实际。幸运的是，我们不仅限于单个机器：大量工作和研究已经使有效的神经网络分布式训练成为了可能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;我们将从并行式/分布式的训练计算这两种方法开始说起。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9b5Tx7I5AxuWSRBmyfY1894jicd2zaUJzjouJlDb7PcksDc5ficp7hUeTefvEFOictX3G3xO0DxV4zQ/0?wx_fmt=png"/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在模型并行（model parallelism）中，在分布式系统中的不同机器分别负责在单个网络的不同部分计算——例如每层神经网络可能会被分配到不同的机器。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在数据并行（data parallelism）中，不同的机器有着整个模型的完全拷贝；每个机器只获得整个数据的不同部分。计算的结果通过某些方法结合起来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当然，这些方法并不是互相排斥的。想象一个多 GPU 系统的集群，我们可以对每个机器使用模型并行（将模型分拆到各个 GPU 中），并在机器间进行数据并行。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9b5Tx7I5AxuWSRBmyfY189wbsedM2dscYu47GibNnxv8nE26xsIvIEklGjqgm7OibPFjZ8Yu3SoJ3w/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尽管在实践中模型并行可以取得良好的效果，但数据并行毫无争议是分布式系统中最适的方法，而且也一直是更多研究的焦点。首先，实现性、容错性和好的集群利用率让数据并行比模型并行更加简单。在分布式系统的情况下模型并行是让人感兴趣且的确有一些优点的（诸如对于大模型的可扩展性）。但这里我们将主要目光放在数据并行上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;数据并行（Data Parallelism）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;分布式训练中的数据并行方法在每一个 worker machine 上都有一套完整的模型，但分别对训练数据集的不同子集进行处理。数据并行训练方法均需要一些整合结果和在各工作器（worker）间同步模型参数的方法。在文中我们将讨论一些不同的方法，而这些方法间的基本差异在于：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;参数平均 vs. 基于更新（梯度）的方法&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;同步 v s. 异步的方法&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;集中式 vs. 分布式的同步&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Deeplearning4j 最近在 Spark 上的实现是同步的参数平均，其中 Spark 驱动器和规约操作（Spark driver and reduction operations）取代了参数服务器。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;参数平均（Parameter Averaging）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;参数平均化是概念上最为简单的数据并行方法。使用参数平均时，训练按照如下方式执行：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 根据模型配置随机初始化网络参数&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 将现有的参数的一个副本分配给每一个 worker machine&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3. 在该数据的一个子集上对每一个 worker 进行训练&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4. 从每一个 worker 的平均参数上设立一个全局参数&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;5. 当还需要处理更多数据时，回到第 2 步&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第 2 步到第 4 步的过程如下图所示。在这个图表中，W 表示神经网络中的参数（权重，偏置）。下标用作指出参数的版本，以及每个 worker machine 有需求的位置。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9b5Tx7I5AxuWSRBmyfY189qGJhpA1icCoxkrtlO1nN9vP0KevLZAib3931AdLnbUvaa5iatoEsIdyZQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;事实上，要证明一个参数平均化的受限版本与单个机器上的训练在数学上是完全相同的是十分简单的；这些限制是每个 minibatch 之后的参数平均，没有更新器（updater）（如没有动量等——只是通过学习率加倍），而且每个 worker 会处理同样数量的样本。对于数学爱好者，证明如下。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;假设有一个含有n个 worker 的集群，其中每个 worker 有m个样本，总的在平均化中就有nm个样本。如果我们将所有nm个样本在同一机器上以学习率α进行处理，那么我们的权重更新规律满足如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9b5Tx7I5AxuWSRBmyfY1890NXzWVANIujFuLf5QdMHBfSSQoQKXM6su6LDLCLtv78tP7eldOs7GA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在，如果我们换做将 m 个样本分配到n个 worker 上执行学习（worker 1拿到样本 1 到 m，worker 2 拿到样本 m+1 到 2m，以此类推），那么就有：&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9b5Tx7I5AxuWSRBmyfY189KpDQYBmKteUNiabDIQxiad08lD6OENR3XHicEwKCmy9G3FDxew7DSpbpg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当然，这个结果并不能付诸实践（平均化每个minibatch和不使用诸如动量或者RMSProp这样的 updater 都是欠妥的。因为执行和收敛是分开说明的）。但这提供了第一感觉去思考：为什么参数平均可以有好的效果，特别是当参数频繁平均的时候？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在，参数平均化在概念上已经十分简单，但我们也略过了一些复杂的地方。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先，我们如何执行平均化呢？最为简单的方式是在每次迭代后简单均值化参数。尽管这种方法有效，但我们会发现这样做的成本会特别高。网络通信和同步成本会超过我们从额外的机器中所获得好处。因而，参数平均化的实现通常有多于 1 个的平均化周期（veraging period，就每个 worker 的minibatch数量而言）逐渐执行。然而，如果我们平均化的频率过低，每个 worker 中的本地参数之间的区别会过大，导致平均化后的模型较差。这里的直观知识是：N 个不同局部极小值的均值不能保证是一个局部极小值&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9b5Tx7I5AxuWSRBmyfY189yOvZ0Iwl18EjaBRsdS7S8d2sTBr13DrUZFjMQtPLz6c237ib9FKy6Kw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;是什么导致了平均化周期那么长？这个问题暂时还不能得到决定性的回答。且由于与其他超参数（如学习率、minibatch大小和 worker数量）的相互影响，情况变得更为复杂。一些该课题上的初步研究（如[8]）表明：每10-20个minibatch（每个 worker）排序的平均化周期仍然可以很好的执行。不过模型精确性当然会随着平均化周期的增加而降低。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;与最优化方法相关的附加难题，例如 adagrad，动量和 RMSProp。这些优化方法（在 Deeplearning4j 又称作更新器（updater））已被证明能在神经网络训练的过程中极大地提升收敛性能。然而，这些更新器也有内部状态（通常一个网络参数中有 1-2 个状态值）。我们应该也将这些状态算入均值吗？将这些内部更新器状态平均会造成每个 worker 的更快速的收敛，但代价是比原来总量多 2 倍或者更多的网络传输。有些研究工作也在试图在参数服务器层面上应用相似的「更新器」机制，而不只是在每一个 worker 上应用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;异步随机梯度下降&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;还有一个概念上同参数平均化相似的方法是：「基于更新的」数据并行化（‘update based’ data parallelism）。两者的基本区别在于：我们不会将参数从 worker 传递给参数服务器，而是传递更新（例如：梯度柱型的学习率和动量（gradients post learning rate and momentum））。这就得到了这样形式的更新：&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9b5Tx7I5AxuWSRBmyfY189meDBA2PKfPxeS74p8IyHickd9DcnqribaYGrg7icZH2mMQdXVID9FBSkA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其中λ是比例因子（可类比于学习率超参数）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;结构上，该方法和参数平均化相似：&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9b5Tx7I5AxuWSRBmyfY1893SFSJ2MRO1OaDLtia3MoSZtdqUatAOGXEuVWzF20hOhZ1XVNG57tiasw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于训练神经网络中数学熟悉的读者可能会注意到：在参数平均化和基于更新的方法之间有直接的相似之处。如果我们再次定义损失函数为L，参数向量W能以 i+1 的迭代以学习率 α 进行简单 SGD 训练而得到：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9b5Tx7I5AxuWSRBmyfY189pxtIniaVbvia2Mb6o9TDX48fIAias0Txj7NJL6S20IGFvvK0PRD7Mhdmg/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其中 &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9b5Tx7I5AxuWSRBmyfY189Dojh1ppwqv1YNicJk1NrPQQJxUmmTBsDBXaViaHUq6ujEBgbaq3cTtzQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;具有 n 个参数&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在，如果我们采取上述的权重更新规则，对于n个执行器让 λ=1/n，同时再次强调（仅使用学习率为 α 的 SGD），其更新是：&lt;span&gt;Δ&lt;span&gt;W&lt;/span&gt;&lt;span&gt;&lt;span&gt;i&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;&lt;span&gt;j&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;α&lt;/span&gt;&lt;span&gt;∇&lt;span&gt;L&lt;/span&gt;&lt;span&gt;j ，&lt;/span&gt;&lt;/span&gt;那么：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9b5Tx7I5AxuWSRBmyfY189Suwy5mOwNicpPwuiauubaEviau5f0L0oYfX9JvutTm5sZpic54352hibibAA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;结果，在参数平均化和基于更新的数据并行间有一个等式，当参数同步更新时（最后一部分是关键），这个等式也适用于多个平均化步骤以及其他更新器（不仅仅是简单的SGD）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当我们放松同步更新的要求时，基于更新的数据并行变得越来越有趣（毫无疑问它更有用）。即在更新∆Wi,j 被计算的时候就应用于参数向量（而不是等待所有 worker 的 N ≥ 1 次迭代）。我们获得了异步随机梯度下降算法（async SGD）。async SGD 有两个主要优点：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;首先，我们有潜在可能在整个分布式系统中获得更高的通量：worker 可以将更多时间花在执行有用的计算而不是等待参数平均化步骤完成。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;其次，worker 有可能可以集成来自其它 worker 的信息（参数更新），这比使用同步（每 N 个步骤）更新更快。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些优点也不是毫无代价的。通过在参数向量中引入异步更新，我们也引入了一个新问题，也就是过期梯度问题（stale gradient problem）。过期梯度问题很简单：梯度（更新）的计算需要时间，在一个 worker 完成这些计算并将结果应用于全局参数向量前，这些参数可能已经更新过许多次了。这个问题以下图展现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9b5Tx7I5AxuWSRBmyfY189xWZD8UU02ns8J6VW1lWlVVFeU0VhrvlEBBI3Wwfvv34G8XE615IofA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一个异步 SGD的朴素实现会造成梯度的过期值（staleness value）很高。例如，Gupta et al. 2015 [3]表明平均梯度的过期值与执行器的数目相等。若有N个执行器，那么就意味着这些梯度在应用到全局参数向量时会晚 N 个步骤。这在现实世界造成的影响是：高梯度过期值会极大减缓网络收敛，甚至完全阻止一些配置的收敛。早期的异步 SGD 实现（例如谷歌的DistBelief系统[2]）没有考虑到这个影响，因而导致学习效率很低。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;多数的异步随机梯度下降的变体都保持着相同的基本方法，但采取一些不同的策略来最小化过期梯度所造成的影响，同时试图保持高的集群利用率。应该注意的是参数平均化并不是由于算法的同步性本身而受到过期梯度问题的影响。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一些处理处理过期梯度的方法包括：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;根据梯度值的延迟度，对于每一个更新的 ∆Wi,j，独立缩放每一个λ值。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;实施「软」同步规则 ( [9] )。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;利用同步去限制延迟度。例如，在 [4] 中所示的系统中，它会在有必要的情况下对较快的学习器进行延迟，以确保整体最大的延迟度小于一个阀值。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些方法已被证实，能够改善朴素异步 SGD 算法的收敛情况。其中，最值得注意的是前两个方法：基于延迟度来缩放更新（延时梯度对参数向量影响较小）以及「软」同步法。「软」同步法 [9] 是一个相当简单的方法——它不立即更新全局参数向量，而是会等待以从 n 个学习器中收集 s 个 ∆Wj 更新（s 是一常数，1 ≤ s ≤ n）。参数的更新规则如：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9b5Tx7I5AxuWSRBmyfY189ibK3MHfkh1T18RlueCYGTJcWxnQlK4wJOkCdO3YWa8wGISHtxOFFcTA/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其中λ(ΔWj)是一个基于延迟度的缩放因子，是一个标量。[9] 提出了&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其中 τ 是一个基于延迟度的整数，满足 τ≥1。同时还有其他方法（见 [6] 中的例子）。若将软同步法和基于延迟的缩放法结合，则其表现会好于两者单独的表现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;注意，若给定 s = 1 以及 λ(·) 为宜常数，我们得到朴素异步 SGD 算法 [2]；相似地，若给定 s=n，我们则会得到另外一个与同步参数平均算法相似但不相同的算法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;分布式异步梯度下降法&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;[7] 提出了另一种更为有趣的备选架构，以执行神经网络的分布式训练。我将这个方法称作分布式异步梯度下降法（尽管作者并未使用该术语）。这篇论文在以下两大方面很有趣：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 在该模型中，没有中心的参数服务器——取而代之的，是点对点的参数传输以对于学习器之间进行更新。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 更新被极大地压缩了——以至于网络的通信尺度减小了三个数量级。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9b5Tx7I5AxuWSRBmyfY189ib18D8kia7CmzCv0E6flQ9YldMthlwRnbwZgDnBMthjZweqpRFCgId2Q/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在一个标准的数据并行执行（使用参数平均或异步 SGD）中，神经网络的转存尺寸与参数向量尺寸大小相同（因为我们要不然传输参数向量的复本，要不然每个参数传输一个梯度值）。尽管压缩参数或更新的想法并非完全新颖，但该方法以一种优于传统的机制（例如应用一个压缩编码或转为 16 浮点表示）实现了压缩。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;这个架构设计的优势在于，更新的向量 δi,j 有以下性质：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 稀疏性：在每个向量 δi,j 中，只有部分的梯度值是相互关联的（也就是其余的值是被设为 0 的）——稀疏项使用整数进行索引。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 量化为一个位：稀疏更新向量每一个分量的值取 +τ 或 −τ。这个 τ 值对向量中的所有分量都相同，因此仅需要一个位就可以区别两个选项。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3. 整数索引（即 1 中所提到的用来索引稀疏矩阵）部分地被使用熵编码，以进一步缩减更新的大小（作者给出了在额外计算的情况下有额外三倍的缩减，尽管该处获益可能不值得额外的计算）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此外，考虑到该压缩方法是有损的，因而原更新向量 ΔWi,j 与压缩／量化更新的向量 δi,jδi,j 的差将不被简单地忽略，而是被储存在一个残差向量 rj 中（ j代表每次执行）。而残差向量将被加到原来的更新上，也就是说，每一步我们量化并传输一个经过压缩的 ΔWi,j+rj 并更新合适的 rj。由此，原始的更新向量 ΔWi,j 中的信息被完整的传输了并没有损失。换句话说，（每个参数的）大更新都将被以比小更新更高的速度动态传输。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;由此产生了两个问题：一个是，这种方法能多大程度上压缩神经网络的参数？另一个是，这种方式的精度如何？答案出乎你意料：它能超出你预料地压缩，但精度略低于你预期。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如这个在 strom 论文中呈现的例子：一个有约1460万个参数的模型，经过不同程度压缩后的情况：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9b5Tx7I5AxuWSRBmyfY1894yCRLiawn981BspjJUkficVrbJB3sbsPpxc7OoZiaY1z9FT9ibacOuXpug/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;更大的 τ 值，将会带来更大的压缩率。例如， 当 τ= 15时，对每个数据包，其更新大小仅有4.5KB！但相应的，模型准确率也会因此而下降。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尽管结论很惊人，但该方法也有如下的问题：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. Strom在论文中写道，收敛情况在训练之初可能出现问题。但使用更少的训练节点和使用一部分案例好像可以帮助解决该问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 压缩和量化过程需要消耗时间：在对每个数据包处理的过程中，这些过程导致了额外的计算与储存。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3. 这一过程引入了需要考的额外的超参数：如何设定 τ值？需要在更新数据的时候使用熵编码吗？（尽管参数平均法和异步SGD都引入了额外的超参数。）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，就笔者所知，暂时还没有异步SGD和分布式异步SGD的实验比较。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;分布式神经网络训练：哪种方法最好？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们已经看到，有多种方法来训练分布式神经网络，其中每个类型也有不少变体。因此，我们应该在实践中应该使用哪一个？不幸的是，我们没有一个很明确的答案。但我们可以给出如下的评判标准，来确定不同方法中最好的那个：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;最快的训练速度（每秒最多或最少可以训练多少个例子）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;在无限样例下可达到的最大精度&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;在有限时间下可达到的最大精度&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;在有限样例下可达到的最大精度&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;最大可达到的准确度对历元的给定数量的&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外，这些问题的答案将可能取决于许多因素，如神经网络的大小和类型、集群的硬件性能，使用特征（如压缩），以及训练方式的具体实施方法和配置。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9b5Tx7I5AxuWSRBmyfY1899TENfaNGBcPfy0hZXdLm0cOiazOeJvkseF21QSYAb70yVZytiaUichaYg/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;也就是说，我们能从该研究中总结出如下内容：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;同步参数平均法（或等价说，基于同步的更新）在每一次遍历中的与整体的准确率方面，特别是对很小的平均周期，表现更好。参见 [9] 中所示的」硬同步」结果，或在 N＝1 的平均周期下同步平均法在单机训练上的表现。但是，额外的同步花费意味着这个方法在每次迭代中需要花费更多的时间。也就是说，如 InfiniBand 的更快的神经网络连接还需要花费很多精力，以使该同步方法具有竞争力（详见 [5]）。但是，甚至在商业硬件上，我们也能见到基于 DL4J 的同步参数的，很好集群利用。增加压缩步骤，应该会进一步减少网络通讯的花费。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;也许参数平均（和一般的同步方法）最大的问题，就是所谓的「最慢执行」效应：即同步系统在完成每次迭代之前，需要等待最慢的执行者。因此，当工作机数量增加时，同步系统的表现不会更好。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在实践中已证明，只要梯度延时被适当处理，异步 SGD 将是一个很好的训练方案。另外一些方法（如前面所述」软同步」的方法），根据其所使用的超参数的不同，可被视为朴素异步 SGD 和同步执行之间的桥梁。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;基于集中参数的异步 SGD 实现，可能会引入通信瓶颈（相比之下，同步方法可以利用剪枝或类似算法，能一定程度上避免这方面的沟问题）。将全部的参数分为 N 等份，使用 N 个参数服务器处理每一份数据，从概念上说，这是一个更为直接的解决该问题的方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最终，分布式异步 SGD 是一个很有前景的想法，尽管这还需要很多研究才能让我们不容置疑地推荐它，而非」标准」的异步 SGD。此外，许多在 [7] 中所示的想法（如压缩、量化等）可以被用于异步 SGD 中，以优化传统的参数服务器的设置。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;该何时使用分布式深度学习&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对每种使用情况，分布式深度学习往往不都是最好的选择。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;分布式学习并非廉价——与在单独的机器上相比，因为诸如同步、数据与参数的网络传输等问题，分布式系统往往有一个日常开销。要使分布式训练变得值得，我们需要利用好分布式系统的计算优势来抵消这笔开销。此外，在分布式训练上，设定（包括准备与载入训练数据）及调参都将会变得更为复杂。因此，我们的建议简单明了：在训练时间可以接受的情况下，都（不使用分布式训练而）在单机上训练神经网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;神经网络的训练时间因为这两种原因而变得很长：网络的大小非常之大（每次迭代都很费时）及数据量非常之多。通常来说，这两种情况将同时出现——因为「大网络、少数据」或「小网络、大数据」的情况往往导致欠拟合或过拟合，不能有很好的泛化效果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在某些情况下，多 GPU 系统应该首先被考虑（如 Deeplearning4j 的 Parallel-Wrapper 系统可以让神经网络在单机上轻松进行同步训练）。基于多 GPU 系统对模型进行同步运算对大型网络也是可行的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外一个要考虑的方面是，网络传输（耗时）与计算（耗时）之比。分布式训练在网络传输（耗时）与计算（耗时）之比较低时，会比较高效。因为每层的计算量很少，小的、层数少的网络并不适用于分布训练。有参数共享的网络（如 CNN 或 RNN）往往适用于分布式训练：因为它们每个参数计算量远远高于，如多层感知机或自编码体系架构的计算量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Part2 预告：在 Apache Spark 上部署 Deeplearning4j 的深度学习网络&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在我们介绍分布式深度学习系列文章中，我们将在第三篇的第二部分仔细探讨 Deeplearning4j 的机遇 Apache Spark 的参数平均法的实现，并通过一个例子来演示如何在 Spark 集群上来训练神经网络。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;参考文献：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[1] Kai Chen and Qiang Huo. Scalable training of deep learning machines by incremental block training with intra-block parallel optimization and blockwise model-update filtering. In 2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 5880–5884. IEEE, 2016.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[2] Jeffrey Dean, Greg Corrado, Rajat Monga, Kai Chen, Matthieu Devin, Mark Mao, Andrew Senior, Paul Tucker, Ke Yang, Quoc V Le, et al. Large scale distributed deep networks. In Advances in Neural Information Processing Systems, pages 1223–1231, 2012.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[3] Suyog Gupta, Wei Zhang, and Josh Milthrope. Model accuracy and runtime tradeoff in distributed deep learning. arXiv preprint arXiv:1509.04210, 2015.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[4] Qirong Ho, James Cipar, Henggang Cui, Seunghak Lee, Jin Kyu Kim, Phillip B. Gibbons, Garth A Gibson, Greg Ganger, and Eric P Xing. More effective distributed ml via a stale synchronous parallel parameter server. In C. J. C. Burges, L. Bottou, M. Welling, Z. Ghahramani, and K. Q. Weinberger, editors, Advances in Neural Information Processing Systems 26, pages 1223–1231. Curran Associates, Inc., 2013.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[5] Forrest N Iandola, Khalid Ashraf, Mattthew W Moskewicz, and Kurt Keutzer. Firecaffe: near-linear acceleration of deep neural network training on compute clusters. arXiv preprint arXiv:1511.00175, 2015.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[6] Augustus Odena. Faster asynchronous sgd. arXiv preprint arXiv:1601.04033, 2016.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[7] Nikko Strom. Scalable distributed dnn training using commodity gpu cloud computing. In Sixteenth Annual Conference of the International Speech Communication Association, 2015.http://nikkostrom.com/publications/interspeech2015/strom_interspeech2015.pdf.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[8] Hang Su and Haoyu Chen. Experiments on parallel training of deep neural network using model averaging. arXiv preprint arXiv:1507.01239, 2015.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[9] Wei Zhang, Suyog Gupta, Xiangru Lian, and Ji Liu. Staleness-aware async-sgd for distributed deep learning. IJCAI, 2016.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Sun, 09 Oct 2016 13:28:27 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 神经机器翻译再立新功：实时机器翻译取得重大进展（附论文）</title>
      <link>http://www.iwgc.cn/link/2990665</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自 Slator&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Marion Marking&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：权利、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;前段时间，谷歌报告了其在神经机器翻译上所取得的重大研究进展，并也实现了 Google Translate 应用上汉语-英语翻译的商品化（参阅《&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719470&amp;amp;idx=1&amp;amp;sn=3368dea980517ea7d7942967da2740dc&amp;amp;chksm=871b0090b06c89863620be4e75c757940d03d8a43cd3c1d9a8309b6594c1bccd769cab193177&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719470&amp;amp;idx=1&amp;amp;sn=3368dea980517ea7d7942967da2740dc&amp;amp;chksm=871b0090b06c89863620be4e75c757940d03d8a43cd3c1d9a8309b6594c1bccd769cab193177&amp;amp;scene=21#wechat_redirect"&gt;谷歌翻译整合神经网络：机器翻译实现颠覆性突破&lt;/a&gt;》和《&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719511&amp;amp;idx=1&amp;amp;sn=88bbb6bb3d28b3f0f62c5c5929968444&amp;amp;chksm=871b0169b06c887f302dc791c67f19ce4ba49c43744e11341b7bb225d9e22443ebf9e3b70339&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719511&amp;amp;idx=1&amp;amp;sn=88bbb6bb3d28b3f0f62c5c5929968444&amp;amp;chksm=871b0169b06c887f302dc791c67f19ce4ba49c43744e11341b7bb225d9e22443ebf9e3b70339&amp;amp;scene=21#wechat_redirect"&gt;谷歌神经网络翻译系统发布后，我们和Google Brain的工程师聊了聊&lt;/a&gt;》）；近日，来自纽约大约、香港大学和卡内基梅隆大学的研究者又报告了神经机器翻译在实时机器翻译上的突破。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尽管机器学习技术发展迅猛，但谷歌也承认机器翻译还是会犯人类永远不会犯的错误。这一问题增加了实时输入的挑战，让问题变得十分棘手。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;实时机器翻译的使用范围涵盖消费者应用（如 Skype Translator）到有望能够帮助专业语言学家显著提高生产力的自适应机器翻译工具。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在2016年10月3日发表的一篇论文《Learning to Translate in Real-time with Neural Machine Translation》（点击阅读原文下载）中，研究人员说他们「第一次」能够证明某些算法可以「在同步翻译上表现得非常好，比以前的基于分割的算法好得多。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9b5Tx7I5AxuWSRBmyfY189OAiag19XS95YEoMN2yJ4NZulFiaGGrOjdrZpZB8eibibj59vxyb14VuDicw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Graham Neubig&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「这项研究的最终目标是语音，」Graham Neubig 告诉 Slator。Neubig　是卡耐基梅隆大学语言技术研究所的助理教授，他与香港大学博士 Jiatao Gu，讲座教授 Victor O.K. Li　和纽约大学的助理教授 Kyunghyun Cho 合作进行了这项研究。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9b5Tx7I5AxuWSRBmyfY189e2V1lASwMbeQJIvrTZiao1zPxnBrG5OsR1dNEEicVChKu3WD065elMug/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;Kyunghyun Cho&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9b5Tx7I5AxuWSRBmyfY189QMGCQ86jT7FQSeqGuhtyqsghiaPpN8icuYwQSLk1rjqXPkh2dtAS1H8Q/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Victor O.K. Li&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Neubig 解释说：「同步机器翻译是一项能够在说话或是打字的同时实时进行语句翻译的技术。以语音为例，在完整的句子结束之前进行翻译是很重要的，因为一个讲话者说完一句话需要 10－20 秒，这就意味着需要这么长时间翻译器才能够向用户开始提供翻译内容。这种滞后意味着诸如使用语音翻译技术作为中介流畅地参加一个多方会谈是困难的。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;根据 Neubig 所言，在过去解决这种滞后的一种方法是将输入分割成较短的段而不是直接处理整个句子，然后将各段独立地进行翻译。如果能够找到一个好的分割位置（「比如，在可以彼此分开翻译的短语之间」），就可以减少滞后。这种技术相较之前更快，但是仍然降低了流畅度。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9b5Tx7I5AxuWSRBmyfY189vUEsRSvib6ibc09WDUIwSRp5LhDjHWx7icriasb6oMDQyGZg0BrwcKNM7Q/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然而，这项研究的与众不同之处是它使用了神经机器翻译（NMT）框架（图2），能够「自动学习什么时候开始翻译词以及什么时候等待更多的输入。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你愿意，可以想象一个等待翻译打字的 NMT 系统，它尝试根据&lt;/span&gt;&lt;span&gt;所有已经输入的单词生成下一个单词的翻译。接着，根据神经网络现在的状态（「以及我们对下个翻译的置信度，」Neubig 说），它将会自动决定这个单词是否应当被输出或是等待另外的输入。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「如果答案是『是，输出单词，』那么输出单词同时返回到 1。如果答案是『否，我们不够确定，』那么停止输入同时返回到2，」Neubig 说道。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他补充说，为了系统能够正确地工作，他们要问自己：我们怎样才能为这项工作设计出合适的机器学习算法？我们怎么来确定翻译的便捷性和准确性之间的平衡？我们怎么能恰到好处地搜索最佳翻译？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「这些问题的答案就是本篇论文中技术内容的关键部分，」Neubig 说道。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他指出，「在我们的实验中，我们首次证明了这些算法能在同步翻译上表现得非常好，远远优于之前的基于分割的算法。我们认为这一表现的主要原因在于我们的方法记忆了之前所有输入的单词，并且在选择下一个要翻译的单词的时候对之前所有单词进行了考量，而这对以前基于分割的方法来说并不容易。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;下文是 Slator 对 Graham Neubig 采访关键部分的摘录:&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Slator：在第６章，你提到同步翻译是相关工作的典型应用，但是你的论文基本聚焦在文本输入而不是语音输入。那么这项研究的主要实际应用是什么呢？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Neubig&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：这项研究的最终目标是语音。在这项工作中我们处理文本因为这更易于起步；因为在处理语音的时候还有附加的事项需要考虑，例如语音识别结果导致的附加的不确定性。我们对于在将来能处理语音绝对地感兴趣，这也是我们将要做的事&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Slator：为什么你会选择聚焦在　NMT 的这一特定的应用场景？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Neubig：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;首先，因为这是语音翻译的一个非常重要的问题。其次，因为 NMT 非常适于处理这个问题。NMT 的工作方式是预测句子的下一个单词并且一次一个地输出它们——这正是我们在同步机器翻译系统中所需要的。在这里也考虑了其他很多有趣的算法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;Slator：因为主语和动词之间间距的长短，所以专门选择了德译英的语言组合（图１）吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9b5Tx7I5AxuWSRBmyfY189sv46PK4TEUWkvibJS2J83oyxMPbqY2tcUbp1FFnrQibGH5LCgzp86C5w/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Neubig：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;是的，这是选择这个语言对的主要原因。先前的同步翻译的工作也因为这个原因聚焦在大量重新排列的语言对上，例如 德语－英语 和 日语－英语。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;Slator：如果在德译英中，一旦真正的动词出现在句末，而模型选择了一个明显被误译了的动词，这样的话会发生什么？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Neubig：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;这是一个非常有趣的问题，我们之前并没有考虑到。真人的同步翻译会返回并改正他们的错误，但是现在还没有机器可以做到这一点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Slator：你预计这项研究会有什么影响？另外你打算怎样进行接下来的工作？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Neubig&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：我希望这项研究最终的影响会是语音翻译，当它实现的时候你就不需要为平滑、流畅的输出结果等待很长一段时间。当然，这项工作仅仅是这个方向的一步，在实现这个目标之前，诸如怎样将现有的方法和语音识别系统和合为一体等考虑是要被处理的事。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Slator：你在论文结尾致谢了 Facebook、三星、谷歌、微软和 Nvidia 这些科技巨头？能告诉我们原因吗？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Neubig：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;这些公司给予了 Kyunghyun 或 Graham 从事与同步 NMT 密切相关的或是通用的 NMT 研究的赞助。然而我们显然不能够代替这些公司发言，我认为他们有兴趣为推进他们认为有前景的研究或教育领域而向学术界提供赞助。不过他们可能会也可能不会这个特定的项目感兴趣。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Slator：特别的，Nvidia 赞助这样一个研究的利害关系是什么？为神经网络、人工智能等等部署的　GPU 已经成为他们业务的一个如此大的推动力了吗？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Neubig：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我认为他们的确为机器学习使用 GPU 而感到兴奋；但是，当然，再次说明，我们不能代替他们发言。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Sun, 09 Oct 2016 13:28:27 +0800</pubDate>
    </item>
  </channel>
</rss>
