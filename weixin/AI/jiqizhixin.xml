<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>机器之心</title>
    <link>http://www.iwgc.cn/list/670</link>
    <description>人与科技的美好关系</description>
    <item>
      <title>深度 | Yann LeCun提交ICLR 2017论文汇总：从生成对抗网络到循环实体网络等</title>
      <link>http://www.iwgc.cn/link/3414016</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自OpenReview&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李泽南、杜夏德、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;em style="color: rgb(136, 136, 136);"&gt;&lt;span&gt;国际学习表征会议 ICLR 2017 的论文提交已经于近日结束。作为机器学习领域的顶级会议之一，ICLR 自然也得到了很多重量级研究者和机构的亲睐。据大概统计，ICLR 2017 已经收到了大约 500 篇论文，这些论文都已经开放 open review，任何人都可以在&lt;span&gt; http://openreview.net/group?id=ICLR.cc/2017/conference &lt;/span&gt;看到所有提交的论文。机器之心之前已经整理过了几篇重要的提交给 ICLR 2017 的论文&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720367&amp;amp;idx=3&amp;amp;sn=15551131dbd1d1fad15d2752dd78fe83&amp;amp;chksm=871b0c11b06c8507b17d846e7d09b8fc4f0f12267d2f7dd019afa3d0ca3345a8774041ef5c84&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720367&amp;amp;idx=3&amp;amp;sn=15551131dbd1d1fad15d2752dd78fe83&amp;amp;chksm=871b0c11b06c8507b17d846e7d09b8fc4f0f12267d2f7dd019afa3d0ca3345a8774041ef5c84&amp;amp;scene=21#wechat_redirect"&gt;《谷歌 ICLR 2017 论文提出超大规模的神经网络：稀疏门控专家混合层》&lt;/a&gt;、&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720285&amp;amp;idx=5&amp;amp;sn=583751084a6855b35f684f582afd7976&amp;amp;chksm=871b0c63b06c857523341e94380cd6b87e84502854886f7aa8fa40ff665166db4ffda8a5ea1b&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720285&amp;amp;idx=5&amp;amp;sn=583751084a6855b35f684f582afd7976&amp;amp;chksm=871b0c63b06c857523341e94380cd6b87e84502854886f7aa8fa40ff665166db4ffda8a5ea1b&amp;amp;scene=21#wechat_redirect"&gt;《Vicarious 在 ICLR 2017 提交无监督学习论文，提出层级组合特征学习》&lt;/a&gt;、&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720257&amp;amp;idx=3&amp;amp;sn=4dfc480bfc70691f5baa44a75a0c1b82&amp;amp;chksm=871b0c7fb06c85696574d7f15d160afd3f45aa669bad4d1589f908c2fe0f56a3f34946bb6e73&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720257&amp;amp;idx=3&amp;amp;sn=4dfc480bfc70691f5baa44a75a0c1b82&amp;amp;chksm=871b0c7fb06c85696574d7f15d160afd3f45aa669bad4d1589f908c2fe0f56a3f34946bb6e73&amp;amp;scene=21#wechat_redirect"&gt;《OpenAI 最新论文：神经 GPU 的扩展和限制》&lt;/a&gt;。这篇文章将介绍 Yann LeCun 参与的在 ICLR2017上提交的所有论文（共 5 篇）。点击文末「阅读原文」可下载这 5 篇论文。&lt;/span&gt;&lt;/em&gt;&lt;br/&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8g4RL7srjDrnlKGuexhib3l4pdq1zWQzsMJiaTATvtvzy9qr7eI96dpC06tDAibCwNoEcgPIPEWUu6Q/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;论文：基于能量的生成对抗网络&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8g4RL7srjDrnlKGuexhib3l6V2OY9vJuHHsHHfI4hqhceMpJ5puDsCIHl5jcdyK5nQumRZ4X0b7ug/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：&lt;/span&gt;&lt;span&gt;我们在这里介绍「基于能量的生成对抗网络（Energy-based Generative Adversarial Network，简称 EBGAN）」模型，该网络将 GAN 框架中的鉴别器（discriminator）视为与数据流形（data manifold）和其它所有更高能量的区域的低能量区域相关联的能量函数（energy function）。和概率 GAN 类似，需要训练一个生成器（generator）来产生具有最小能量的对比样本，同时还要训练该能量函数将高能量分配给那些生成的样本。将鉴别器视为能量函数让我们可以在通常的二元判别网络之外还能使用范围广泛的架构和损失函数。在 EBGAN 的所有实例中，其中之一是沿着作为重构误差（reconstruction error）的能量使用一个自动编码器（auto-encoder）。我们研究表明这种形式的 EBGAN 能在训练过程中得到比通常的 GAN 更稳定的表现。我们也表明只需训练一个单尺度（single-scale）的架构就能生成高分辨率的图像。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;论文：用循环实体网络跟踪世界状态&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8g4RL7srjDrnlKGuexhib3lmBicX7xNtlg0hPIfrYF7mKiaHa9VtXZrrNeU5QTwEicEjx2xDGKwp7j9w/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：我们提出一个新的模型，循环实体网络（Recurrent Entity Network (EntNet)）。它配备了一个动态的长期记忆，能让它随着接收新数据来维持和更新世界的状态的表征。在语言理解任务中，它能一边读取数据一边运行推理，不像 Sukhbaatar 等人在 2015 年提出的记忆网络（Memory Network）(Sukhbaatar et al., 2015) 需要要求它回答或回应某个问题。它很像 Graves 等人分别在 2014 和 2016 年提出的神经图灵机器（Neural Turing Machine）或者可微神经计算机（Differentiable Neural Computer），可以保持一个固定大小的记忆并能学习去定位，基于内容读取数据，写下操作过程。然而，和这些模型不一样的是，它有一个简单的并行架构，能够同时更新若干个记忆位置。该 EntNet 在 bAbI 任务上实现了目前最佳的水平，并且是第一个能在 10000 个训练样本场景中解决所有任务的方法。我们证明了它能在大量事实支持的条件下解决推理任务，这是其他方法无法办到的。它还可以概括过去的训练水平。在实践中，它还能被使用到大规模的数据集中，比如 Children』s Book Test，在这个数据集处理任务中，该模型的表现极具竞争力，它能一次读取儿童书的故事。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;论文：深度学习中 Hessian 的奇异性&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8g4RL7srjDrnlKGuexhib3lFDKDp8CdtWLo4lCibsJkXmwu7EW0h24vDbU0SNibs8lDp2YXgDKFOc5A/0?wx_fmt=png"/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们分别在训练前后检查了一个损失函数的 Hessian 特征值。观察到的特征值分为两部分：主体部分集中在 0 附近，边缘值散落在 0 周边较远的位置。我们的实验证据显示主体部分的特征值过于参数化，而边缘区域的特征值指示了输入数据的复杂性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;论文：Entropy-SGD：偏压梯度进入宽河谷&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本论文提出了一种训练深度神经网络的优化算法：Entropy-SGD。这种方法的灵感来自于能量图景（energy landscape）局部几何关系的解决方案，这种方案在梯度下降中发现。具有低泛化误差（generalization error）的局部极值在 Hessian 中具有很大比例的几乎为零的特征值，正特征值或负特征值则非常少。我们利用这一观察来构建基于局部熵的目标，其有利于位于能量图景的平坦区域中的良好可概括的解，同时避免位于尖锐山谷（sharp valleys）中的不可概括的解。我们的算法类似于 SGD 的两个嵌套循环，其中我们使用 Langevin dynamics 来在每次更新权重时计算局部熵的梯度。本研究证明了将局部熵并入目标函数中可形成更为平滑的能量图景，同时它均衡的稳定性展示了比 SGD 更好的泛化边界。在竞争性基线中的的实验结果表明，Entropy-SGD 可以提升泛化性能，有增加训练准确性的潜力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;论文：停止时间中的普遍性&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8g4RL7srjDrnlKGuexhib3l6IStkbBsw1cDicjYfBypKXTu3Pm3P7Z2r2AajdpzicB2jCtfiaF8kk3YA/0?wx_fmt=png"/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：作者提出了应用于 spin glasses 和深度学习这两种随机系统的优化算法的停止时间（通过达到给定精度的迭代次数测量）经验分布。对于一个我们采用了优化流程（optimization routine）和随机图景（random landscape）形式的算法，停止时间（halting time）的波动遵循一个分布，该分布能在输入彻底变化后仍然不变。我们观察两个主要类：在谷歌搜索、人类做决策时、QR 因式分解和 spin glasses 中出现的 Gumbel 形式的分布；以及出现在共轭梯度方法、带有 MNIST 数据输入的深度网络和带有随机数据输入的深度网络的高斯形式的分布。对于其的实验表明：存在一类分布——其停止时间在某些条件下与底层分布无关。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译文章，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号或作者获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 08 Nov 2016 12:13:40 +0800</pubDate>
    </item>
    <item>
      <title>专栏 | 2016年欧洲计算机视觉大会纪要（ECCV’16 Recap）</title>
      <link>http://www.iwgc.cn/link/3414017</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心专栏&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;作者：魏秀参&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;计算机视觉（Computer Vision, CV）是人工智能领域的一个重要研究子领域。随着近年来 CV 学界研究成果在业界产生的巨大产业影响，计算机视觉受到越来越多的关注。机器之心曾整理报道过&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719772&amp;amp;idx=2&amp;amp;sn=9540989a7862ef93d1e5146a7b5641c9&amp;amp;chksm=871b0262b06c8b74bcd961a7bfe45076a92c1d9456af235f8e84a4bce6e15d120f295cab5576&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719772&amp;amp;idx=2&amp;amp;sn=9540989a7862ef93d1e5146a7b5641c9&amp;amp;chksm=871b0262b06c8b74bcd961a7bfe45076a92c1d9456af235f8e84a4bce6e15d120f295cab5576&amp;amp;scene=21#wechat_redirect"&gt;ECCV‘2016的各项最佳论文奖&lt;/a&gt;。本文为机器之心专栏作者魏秀参记录下的大会纪要。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;同计算机其他研究领域一样，CV 依然有着较浓厚的「会议情节」，其中每年一届的 Computer Vision and Pattern Recognition (CVPR)、两年一届的 International Conference on Computer Vision (ICCV) 和同样两年一届的 European Conference on Computer Vision (ECCV) 并称 CV 领域的三大顶会，其中 ICCV 和 ECCV 奇偶年交替召开。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;笔者有幸参加了 2016 年欧洲计算机视觉大会（ECCV 2016），在此将大会纪要同大家分享。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8g4RL7srjDrnlKGuexhib3l2CTrtnnOiaibrXRwSIB6hmEYoAeym2fdiaf3NnF28ib9bn24etow74EWcQ/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本次 ECCV 在素有「北方威尼斯」之称的荷兰迷幻浪漫都市阿姆斯特丹举办，会议历时九天（10 月 8 日至 10 月 16 日），可谓「饕餮盛宴」，其中主会从 11 日到 14 日持续四天，其余时间为 workshop 日程。值得一提的是，多媒体领域顶会 ACM Multimedia（ACM MM）于 15 日至 19 日接续 ECCV，同样在阿姆斯特丹举办，真是让人过足了 AI 瘾。此外，城市中不时弥漫开来的大麻气味无疑给这两大会徒添了一种别样的神秘气息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;ECCV 主会&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8g4RL7srjDrnlKGuexhib3l3ZvykRl6XLcXSkWyPI1xoA3r8zQLtb5LsQVWKqsZ8ic8z6N9Q5Uojtw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本次 ECCV 主会在始建于 1887 年的皇家剧场 Carré举行，注册参会人数约 1700 人。有效投稿数为 1561 篇，共 74 位 Area Chairs 和 1163 位审稿人（Reviewers），录用论文 415 篇，录用比例 26.6％，其中 28 篇为 Oral（占 1.8%），45 篇为 Spotlight（2.9%）。收录论文的主题仍然延续传统，覆盖了计算机视觉和模式识别的各个方向，包括：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;3D computer vision&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Computational photography, sensing and display&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Face and gesture&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Low-level vision and image processing&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Motion and tracking&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Optimization methods&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Physics-based vision, photometry and shape-from-X&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Recognition: detection, categorization, indexing, matching&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Segmentation, grouping and shape representation&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Statistical methods and learning&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Video: events, activities and surveillance&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Applications&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其中，深度学习（DL）、3D、视频相关等为热门方向。而审稿人方面，也是 DL、3D 等方向审稿人居多，特别是深度学习，异军突起。（PS：但是审稿人多并不一定是好事。由于不同研究背景的研究人员都进入 DL 领域，导致 DL 审稿人给出的审稿意见参差不齐，不同意见间的「方差」很大。）相比之下，审稿人最少的 Sensors 领域人数只是 DL 的七分之一。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8g4RL7srjDrnlKGuexhib3lgkOsYqQ8wibAznnfN1mibXcUqI6JSaed9ibH9HETE3oAD4Tic9owrXg33A/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8g4RL7srjDrnlKGuexhib3l1ib4ZjvWic9OLnKMuBa3y3OsSRY6EmUfXTScukNYlDibLNQJ5Yv7uicSBA/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;主会日程基本半天一个单元，每个单元中前场分别是 Oral 和 Spotlight 报告，接下来则是 Poster 环节。有关 Oral、Spotlight 和 Poster paper 具体内容可参见 ECCV 2016 主页。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;ECCV Workshops&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本次依托 ECCV 举办的 workshop 共有 26 个，一些在当地酒店举办，一些在阿姆斯特丹大学举办。Workshop 中比较吸引人眼球的还属「Joint ImageNet and MS COCO Visual Recognition Challenge」了。这次 ImageNet 竞赛比较显著的一个特征即今年的获胜者基本是华人团队，如商汤（SenseTime）、海康威视（HIK Vision）、360 AI，公安部三所等。另外，比赛结果中并未见 Google、微软、百度等公司的身影。在此也祝贺在各项比赛细类中取得名次的队伍！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外，笔者也有幸作为 team director 参加了 Apparent Personality Analysis 竞赛，历时两个多月，我们的参赛队（NJU-LAMDA）在 86 个参赛者，其中包括有印度「科学皇冠上的瑰宝」之称的 Indian Institutes of Technology（IIT）和荷兰名校 Radboud University 等劲旅中脱引而出，斩获第一。关于竞赛细节，可参看近期我们发布在「深度学习大讲堂」的竞赛经验分享。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;晚宴和颁奖&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;由于阿姆斯特丹是运河城市且沿海，ECCV 晚宴特地选定在「Ocean Diva 号」游轮上举行。各国人工智能研究者济济一堂，好不热闹！只是「晚宴」并不如我们想象中的中式会议晚宴那么丰富甚至奢华，国外会议晚宴一般都是以啤酒、饮料穿插以小吃、汉堡为主。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8g4RL7srjDrnlKGuexhib3l36E5D8QYibeclDOZUiaAdydPUlSCmpGckfAzIItWuYgjnJa6Rs5m2PIA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;晚宴的重要时刻即大会颁奖，本次的最佳论文及提名，和最佳学生论文均授予了传统计算机视觉研究问题，而非深度学习。一则可以看出深度学习相关研究目前难度日益加大，欲做出有突破性进展的工作不易；二则可以看出 CV 大佬有意扶持传统研究问题，维护 CV 生态平衡，不致 DL 一家独大。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8g4RL7srjDrnlKGuexhib3liasrc5eUM3icDWAJ8lxlxQT1GwO5Uq5Sha08lWN556Tgb1gQNGbYl9qQ/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外，Koenderink Prize（ECCV「十年最佳论文」）授予了著名的 SURF: Speeded up robust features (ECCV 2006) (Herbert Bay, Tinne Tuytelaars and Luc Van Gool) 和 Machine learning for high-speed corner detection (ECCV 2006) (Edward Rosten and Tom Drummond)。值得一提的是，在宣布 SURF 获奖之际当即引来一片欢呼，可见其工作深入人心之甚。PAMI Everingham Prize（CV 领域的最佳贡献奖）分别授予了 ImageNet 数据集团队和 Ramin Zabih 以表彰其在开源数据集，和服务 Computer Vision Foundation 上的卓越贡献。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;干货时间&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;开会数日，笔者有心记录了一些会议观察，在此与君共享。不过受个人研究兴趣影响，以上内容不免有所偏颇，望诸君选择性参考。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 这次会上大佬们如 Jitendra, Cordelia 在力推 self-supervised learning（基于 robot 反馈机制，例如，机械手臂戳一下物体，从 sensor 或视频中获得反馈，可以看作是用 robot 来探知世界吧），最近 arxiv 也有一篇类似的 https://arxiv.org/abs/1605.07157；另外，很多利用 side information，如利用声音辅助视觉，这样的工作在本次 ECCV 上也屡见不鲜；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 冠名弱监督学习（Weakly supervised learning）的工作非常多了，但是「弱监督」的内涵却是个圆其说，不像机器学习中有明确的定义；因此，以后基于弱监督设定的计算机视觉问题还应该有做的空间；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3. 底层视觉（Low-level vision）问题／任务极少，几乎没有，不像 ICCV 2015 还有若干篇的样子；而且一些工作开始用 DL 去做 low-level vision 的东西，比如 Ming-Hsuan Yang 在这次会上的两篇利用 DL 技术学习底层视觉中的滤波器（Filters）。（http://faculty.ucmerced.edu/mhyang/papers/eccv16_joint_filter.pdf 和 http://faculty.ucmerced.edu/mhyang/papers/eccv16_rnn_filter.pdf）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4. 传统细粒度图像相关工作几乎没有，只有一篇做细粒度图像任务的新问题，即细粒度场景图像分类（Fine-grained scene classification）（https://arxiv.org/abs/1607.07614）；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;5. 有两篇 image colorization 作为 oral paper，不知是否是巧合；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;6. Question answering 这类问题相比 ICCV 少了很多，但隐式做 visual-text 的工作还是占了一定比例；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;7. 下面几篇文章做的问题比较有趣：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;a) Amodal instance segmentation, Ke Li and Jitendra Malik.（构造新数据集，做了新问题）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;b) Automatic Attribute Discovery with Neural Activations, Sirion Vittayakorn, University of North Carolina at Chapel Hill; Takayuki Umeda, NTT; Kazuhiko Murasaki, NTT; Kyoko Sudo, NTT; Takayuki Okatani, Tohoku University; Kota Yamaguchi, Tohoku University&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;c) Pixel-Level Domain Transfer, Donggeun Yoo, KAIST; Namil Kim, KAIST; Sunggyun Park, KAIST; Anthony Paek, Lunit Inc.; In So Kweon, KAIST (根据衣服生成买家秀，或反过来，在真实场景下，从模特照片中生成产品照片)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，总结来说，这次参会最明显也是最微妙的一个感受就是，多数工作在开会前都没有看过。而不像前两年参加顶会时发现绝大多数文章已经是 arxiv 上读过很久的工作，甚至已经跑过源码，去开会也只是和作者当面聊聊天，甚至当时还有一种顶会更新速度落后于 arxiv 的感受。ECCV'16 这一现象恰恰说明深度学习研究的发展慢慢从当初的白炽化走向正常化，从着急忙慌的在 arxiv 上占坑走向踏踏实实的顶会发表。另外也从侧面显示了深度学习研究难度的提升，就拿 arxiv 举例，一年前几乎每天都能看到有令人 exciting 的文章更新出来，而近期不仅发布文章的数量有所下降，重要的是有趣的文章更是难得一见。这次会上也与众多老友把酒言欢，同时也认识了很多新朋友，期待下次的 CV 大趴，我们 CVPR'17 再见。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;10 月 30 日于澳大利亚阿德莱德&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（题图为笔者摄于 Zaandam 风车村）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;作者简介：&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;魏秀参：南京大学计算机系机器学习与数据挖掘所（LAMDA）博士生，研究方向为计算机视觉和机器学习。曾在国际顶级期刊和会议发表多篇学术论文，并多次获得国际计算机视觉相关竞赛冠亚军，另撰写的「Must Know Tips/Tricks in Deep Neural Networks」受邀发布于国际知名数据挖掘论坛 KDnuggets 等. 微博 ID：Wilson_NJUer&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心专栏文章，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号或作者获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 08 Nov 2016 12:13:40 +0800</pubDate>
    </item>
    <item>
      <title>资源 | 斯坦福自然语言工具CoreNLP更新，下载3.7.0版本</title>
      <link>http://www.iwgc.cn/link/3414018</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Stanfordnlp&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;著名的斯坦福自然语言工具 CoreNLP 有了最新的更新，此次更新的 CoreNLP 下载包大小为 536MB，包括 CoreNLP code jar、CoreNLP &amp;nbsp;model jar、运行 CoreNLP 所需的库、该项目的文档/源代码。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;项目地址：&lt;/span&gt;&lt;span&gt;http://stanfordnlp.github.io/CoreNLP/&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;斯坦福 CoreNLP 提供一系列自然语言分析工具。它能给出单词的基础形式，单词在语言中的成分，单词是否是公司、人的名字，规范化日期、时间、数量词等，根据短语和单词的依存关系组成语句结构，表明哪些名词短语指代同一实体，指明情感成分，提取这些内容之间的开放性关系，等等一系列用途。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你有以下需求，就可以使用斯坦福 CoreNLP：&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;需要一个有宽泛范围语法分析工具的融合型工具包；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;对任意文本进行快速、可靠的分析；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;总体而言最高质量的文本分析；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;支持一系列主要的（人类）语言；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;可与多种主要的编程语言对接；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;可作为简单的网页服务来运行；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;斯坦福 CoreNLP 是一个融合框架。其目标是能最简单的将语言学分析工具应用到文本中。一个 CoreNLP 工具管道通过两行代码就能在一些简单文本上运行。其设计高度灵活、可延展。你可以改变其中无效的工具，加入有效的工具。斯坦福 CoreNLP 融合了斯坦福多种 NLP 工具，包括 part-of-speech（POS）tagger、命名实体识别器（NER）、解析器、conference resolution 系统、情感分析、bootstrapped 模式学习和开放信息提取工具。它的分析能为高层次的、特定领域的文本理解应用提供基础构造。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8g4RL7srjDrnlKGuexhib3lQKjcYvyPbnWa7eiaeXp8wFBMSE73icpWL4Q82I3RcDDiaiboVbB9lGtpLg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此次更新的 CoreNLP 下载包大小为 536MB，包括 CoreNLP code jar、CoreNLP model jar、运行 CoreNLP 所需的库、该项目的文档/源代码。此外该项目还提供了早期版本的下载。下图是 3.7.0（beta）支持下载的语言：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8g4RL7srjDrnlKGuexhib3lPwJW2XeuoQk0wjSHPjcORXruZegyUnutleS6eqkkqYxegsyeDicIQ0Q/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;工具包的基础分布能为较好剪辑英语的分析提供模型文件夹，但该引擎能兼容其他语言模型。我们提供了阿拉伯语、汉语、法语、德语、西班牙语的打包模型。我们也提供了一个包含斯坦福所有英语模型的 jar，它包含各种变体模型，尤其是有一个处理非常规英语（例如，大部分或全部单词都是大写或小写的形式）的优化模型。该工具包也支持其他语言的第三方。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在编程语言上，斯坦福 CoreNLP 使用 Java 编写。从命令行使用斯坦福 CoreNLP 的方式有很多，通过 Java 编程 API、大部分编程语言的第三方 API 或者通过 CoreNLP Server。它能在 Linux、OS X 和 Windows 上运行。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 08 Nov 2016 12:13:40 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 东芝宣布时域神经网络技术：要让低功率物联网设备也能深度学习</title>
      <link>http://www.iwgc.cn/link/3414019</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自phys.org&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8g4RL7srjDrnlKGuexhib3luNnEFMIf3BcT03KicbUpNXG33LULDoshnYxnByISqltxQjs5hQ3gLmA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 1：时域神经网络（Time Domain Neural Network）&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了追求其在物联网和大数据分析领域的未来，东芝公司正在开发一种时域神经网络（TDNN/Time Domain Neural Network），采用了超低功耗的神经形态半导体电路，可用于执行深度学习的运算。TDNN 由大量使用了东芝自家的模拟技术的微型处理单元构成，这让它和传统的数字处理器不一样。TDNN 在 11 月 8 日的 A-SSCC 2016（2016 年亚洲固态电路会议）上报告了出来——这是由 IEEE 赞助的一个在日本举办的国际性半导体电路技术会议。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;深度学习需要大量的计算，所以通常需要在高功率的高性能处理上运行。但是，如果要将深度学习和物联网边缘设备（IoT edge device）（如传感器和智能手机）结合起来，就需要非常高能效的 IC（集成电路）——它可以执行大量所需的运算，同时仅需消耗极少的能量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在冯诺依曼型的计算机架构中，大部分能量都消耗在了将数据在片上或片外存储设备与处理单元之间的传递之中。减少数据移动的一种最有效的方式是使用大量处理单元，其中每一个都仅处理与其接近的一个数据。这些数据点在将输入信号（比如猫的照片）转换成输出信号（比如识别照片中有猫）的过程中会有一个权重。数据点离目标输出越近，其获得的权重就越高。该权重是自动化引导深度学习过程的一个参数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;生物大脑也有相似的架构。在生物大脑中，神经元之间的耦合强度（权重数据）内建于突触（处理单元）之中。在大脑里面，突触是神经元之间的连接，每一个都有不同的强度。这些强度（权重）决定了通过该连接的信号。突触可以通过这种方式执行某种形式的计算处理。这种架构被称作是完全空间展开架构（fully spatially unrolled architecture）；它很有吸引力，但也有一个明显的缺点——将其复制到芯片上需要大量的算术电路（arithmetic circuits），而且会很快变大到难以承受的程度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;东芝的 TDNN 从 2013 年开始开发，使用了时域的模拟和数字混合的信号处理（TDAMS/time-domain analog and digital mixed signal processing）技术，可以实现处理单元的小型化。在 TDAMS 中，比如加法这样的算术运算可以通过使用像模拟信号一样的数字信号通过逻辑门的延迟时间来有效地执行。使用这项技术，用于深度学习的处理单元可以仅有完全空间展开架构的 3 个逻辑门和 1 bit 内存即可。东芝已经制造出了一款用于概念验证的芯片，其使用了 SRAM（静态随机存取存储器）单元作为内存，并且已经证明能够用来识别手写数字。其每条指令的能量消耗是 20.6 fJ，仅有之前一场顶级会议上报道的成绩的 1/6.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;东芝计划将 TDNN 开发成一种电阻式随机存取存储器（ReRAM/resistive random access memory），以进一步提升能量和数据的效率。其目标是得到一款能够在边缘设备上实现高性能深度学习技术的 IC。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;原文链接：http://phys.org/news/2016-11-toshiba-advances-deep-extremely-power.html&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，机器之心系今日头条签约作者，本文首发于头条号，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 08 Nov 2016 12:13:40 +0800</pubDate>
    </item>
    <item>
      <title>深度 | 数据和算法像人一样有偏见，你还愿意让人工智能帮你投票吗？</title>
      <link>http://www.iwgc.cn/link/3399371</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自World Economic Forum&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李泽南、曹瑞&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;em style="text-align: justify; color: rgb(136, 136, 136);"&gt;&lt;span&gt;2016 美国大选将至，一些研究者和从业者也趁着这股热潮推出了一些基于数据预测大选结果的人工智能程序，但就像人类自己一样，它们所支持的总统候选人也都不一样（一些俄罗斯人开发的一个人工智能程序会选择特朗普当总统 :O）。未来，如果算法成为了我们日常生活的管家，我们可以让算法来帮助我们选出总统吗？&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;想象一下 2020 年的普通一天，人工智能助手唤你起床，为你端上已准备好的早餐，都是你最喜欢的食物。在晨跑中，播放器会自动播放符合你喜好的最新歌曲。上班路上，电子助手会根据你过去的阅读品味，自动向你推送新闻以供阅读。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你阅览着新闻，注意到总统选举马上就要来了，人工智能参考了你过去的政治看法和本州其他选民的意见，向你推荐了一位民主党候选人。你的手机上，一条弹出信息询问你是否需要 AI 助手帮你准备投票所需文件，你点击「同意」，然后关掉屏幕，继续自己的生活。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;人工智能：呆板的数据机器&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;AI 个人助手在几年前已经走进现实，对于我们来说，把履行公民义务的重任交与它们还是显得有些不合适——即使人工智能几乎总是知道在特定的时刻给我们最好的建议。通过足量的数据学习，人工智能可以为每个人提供准确的，个性化的建议，甚至比你最亲密朋友的建议更完美。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Alphabet 董事长埃里克·施密特坚信，人工智能的发展会让每个人都会变得更聪明，更有能力，更为成功。人工智能已经展现出了巨大潜力，有希望帮助解决人类社会面临的各种复杂挑战，如气候变暖，人口增长和人类发展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然而机器展现出的潜力也带来了担忧。有调查显示，34% 的人表示自己害怕人工智能，而 24% 的人认为人工智能会对社会造成负面影响。相比较未知的恐惧，人工智能对于数据的依赖带来了现实的隐患，GWI 的研究表明，63% 的民众担心他们的个人信息被科技公司滥用。最近 Oxford Internet Institute 的研究显示，人们对于让人工智能助手打理自己生活的方式持谨慎态度，特别是当这些助理提出自己的建议，却又不告诉你它推理过程的时候。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这里，我们没有必要混淆数学与魔法。人工智能并不是在你手机里生活的神秘生物。但我们往往会忘记，人工智能一直在读取我们的个人资料，通过复杂的数学模型，自动推断我们的兴趣、位置、习惯、财务和健康。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;开发者的角色&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当前关于算法与人类的很多讨论都围绕着设计者在算法中的作用——人工智能创造者的潜在意识和偏差是否会被编码进帮我们做出决定的算法中。很多人担心开发者的个人偏见会被带入算法，其中一点点微妙的歧视就会让部分人群的利益受到侵害——也许还有更坏的结果，科技平台会演变成弱势群体难以逾越的门槛。即使算法和写算法的人没有偏见，没有人能够保证训练算法的数据中一切都是平等的，现实世界本身存在着偏见，数据集中的内容也会对人工智能框架产生影响。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;持这一观点的决策者和专家们经常误解人工智能算法出错的原因。他们不断指责开发者，却忽略了自我学习系统的局限性。将错误推给别人是一种自然反应，特别是在你无法理解这些技术时。算法的偏差很少来自于开发它们的工程师。事实上，在大部分情况下，问题的根源出自训练算法的数据，这才是构建未来人工智能社会所要担心的真正危险。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;算法决定论&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;回想一下机器学习到底是怎么工作的，通过应用统计学技术，我们可以开发自动识别数据中特征的算法。为了达到这个目的，系统需要经过巨大数据集的训练，训练模型的数据越多，预测准确率越高。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在个性化数字应用中，这些统计学习技术被用来建立算法，为用户提供个性化服务，计算机阅读了我们的使用模式、品味、偏好、人格特征和社交图谱，随后建立起对于人类的数字观感。计算机形成的社交身份并不基于你的个性或选择，相反，这种虚拟身份来自于你的可统计数据点，和它们的机器解释。这种代替，无论多么复杂，都是人工智能对人类的不完美数字表达。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能只能查找历史数据，为用户所需做出建议。这就是为什么今年 8 月，一个视觉识别神经网络通过 1400 万张照片的训练后预测唐纳德·特朗普将会赢得本届美国总统大选。鉴于这个数据集中并没有女性美国总统，AI 可能判断性别是识别模型的相关特征。但即使排除这一点，如果让这个俄罗斯人训练的人工智能投票的话，它肯定会投特朗普。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicsPeIvLZsUJgazZo1ias2IuJNEAvGv5NRwWHicibDZweMHAlvrox2VYj1kckWjNETR3GXk45A1eKMcg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这样的推论会导致越来越僵化的推荐系统，它倾向于不断强化现有的看法，就像社交网络中的反射效应一般。「个性化」使每个人都被贴上了标签，让现实生活和网络世界互相割裂。计算机不断地推荐「你喜欢的」内容，用户获得的信息在不知不觉中被算法误导，人类或许在人工智能真正觉醒之前就已深陷其中了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;动态的人生&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们的身份是动态的，复杂而充满矛盾的。根据我们的社会背景，我们总会拥有者几个不同的身份，这意味着我们需要用到几种不同的 AI 助理——在学校或工作中的，在酒吧或教堂里的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除了通常的自我介绍，我们在网络中可能也需要以不同的身份展现自我，和不同的群体展开互动。我们不希望自己在社交网络中被随意查看，我们也不希望自己在寻找新奇事物时，还要担心朋友和家人的窥视。如果我们想要试试不同的社会身份，会发生什么？4Chan 创始人 Chris Poole 说道：「这不是你在和谁分享的问题，这有关你与他人分享什么样的内容。身份就像一个棱镜，别人通过它来看你会呈现无数不同的面貌。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;区分不同的自我表达阶层，绘制不同社交环境下的身份，对于人工智能而言是一个巨大挑战。很多时候，人类面临的问题不在于算法设计——我们连自己是什么都还没弄清楚。但人工智能助手总会给我们一个答案：关于过去的我们。身份的变化在这样的环境中变得越来越难，我们的生活习惯和信念被自我强化的循环锁定，算法构建的《土拨鼠日》出现了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们在日常生活中越依赖于个性化算法，我们的个性就会越被计算所磨灭，我们所读，我们所见，我们生活的方式都将被机器所决定。通过专注于现状，接管探索信息和偶遇陌生人的渠道，用过去发生过的事情试图再一次讨好自己，这就是算法决定论的世界。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当过去照进未来，人类赖以生存的自发性，开放与进取变得逐渐稀缺。温斯顿·丘吉尔曾经的话变成了这样：我们塑造了算法，然后，算法塑造了我们。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicsPeIvLZsUJgazZo1ias2IuYJGwhR0KoMia0kGcPp8GEIz7ueE3Lsaic7iamj2ib8UgXbfiajpibtbG8p2A/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;如何阻止未来&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在今天，现实世界中的人工智能应用已经融入到了日常生活的方方面面——而人们对这一科技的兴趣也是越发浓厚。但是有两个主要的挑战正让未来变得难以触及。从科技进步的角度来讲，不同应用之间的数据交换上缺乏互通性标准，而具备这一点能够防止彻底的个性化。要是想要真正有用的话，机器学习系统需要更多的个人数据——而这些数据现在都被孤立地分散在一些有竞争力的科技公司的专业数据库当中。那些掌握数据的公司就掌握了权利。一些公司，最著名的比如说像 Apple 和 Viv，已经开始通过与第三方服务结合的实验来扩大自己的势力范围。最近，一些最大的科技公司宣布了与人工智能研究的主要合作，这样就可以将益处带给大多数人，而不仅仅是少数人。这将会对今后建立对人工智能的普遍信任至关重要。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从社会的角度来看，人类似乎对人工智能的急速发展有一种莫名的反感。人们担心会失去对人工智能助手的控制。信任是我们控制能力的一种直接表现。试图对生产力进行一些微小的改进，却要赌上关系和名誉，大多数人都不愿意这样做。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当然，在早期，人工智能助手的行为方式可能并不是它的人类制造者所期望的。有先例证明，一些失败的人工智能实验会减少对弱人工智能（narrow AI）解决方案和聊天机器人（conversational bots）的信任。Facebook、微软和谷歌纷纷在 2016 年建立了它们的机器人平台，但过早呈现在人们面前的人工智能科技，因其有限的功能、应用和定制化让用户大失所望。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一直困扰我们的恐惧——人工智能科技的后果，也因为很多科幻小说中所描述的有意识、暴戾的人工智能统治世界的反乌托邦场景而加剧。但是我们所面对的未来，既不会像是人工智慧网络「天网」（Skynet），也不会像乔治·奥威尔的《1984》里一样：而更可能会像是《美丽新世界》（A Brave New World）中所描述的一个享乐主义的社会，在那里，科技的地位仍然是需要为普遍的幸福和自我放纵所服务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicsPeIvLZsUJgazZo1ias2Iu2HNia0xTsL27niczVuXYIDgHaaAvL8coPibtn5TXRLUhbHwH8GksVYDJw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;未来导向型机制&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;科技发展的脚步从未停滞，但希望仍在。2016 年全球杰出青年社区（Global Shapers Community）的年度调查显示，在年轻人眼中，人工智能已经成为了主要的科技发展趋势。此外，21% 的调查对象表示他们支持人形机器人的权利，而且在东南亚，支持的呼声尤为高涨。年轻人们似乎对于人工智能在我们日常生活中所扮演的角色持非常乐观的态度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在欧洲，欧盟的《一般数据保护条例》（General Data Protection Regulation，简称 GDPR）让用户有机会要求对基于分析的算法决策进行解释，限制了绝对形式的算法决策。该条例有望于 2018 年 5 月之前在所有欧盟国家实施。这样的机制能够限制资料搜集，强调了人类可解释性（human Interpretability）在算法设计中不容忽视的重要性。但是，这是否会对一些大型科技公司现行的算法实践带来主要的变化，还尤未可知。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;每天都有关于我们每个人的成千上万个算法决策——从 Netflix 的电影推荐、Facebook 上的好友建议，到保险风险评估和信用评分。就各方面而言，人们自己应该有责任对关于自己的算法决策进行跟踪和仔细审查，或者说我们可能需要将此编码到他们使用的数字平台设计当中？责任是非常重要的一点，准确来说是因为在大范围内进行估量和实施是非常困难的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因此，在一头栽进这个未知的领域之前，我们需要回答一个问题：我们想让人类和人工智能之间的关系成为什么样子？反思这些问题，我们才会设计出非决策性的、透明并且有责任感的算法，这些算法能够辨别出个体当中复杂、发展和多方面的本质。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Mon, 07 Nov 2016 14:44:05 +0800</pubDate>
    </item>
    <item>
      <title>基础 | 机器学习入门必备：如何用Python从头实现感知器算法</title>
      <link>http://www.iwgc.cn/link/3399372</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自machinelearningmastery&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：Terrence L、武竞、Xavier Massa&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;br/&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;感知器算法是最简单的人工神经网络形式之一。感知器是一个单神经元的模型，可以用于两个类别的分类问题，也能为以后开发更大的神经网络奠定基础。在本教程中，你将了解到如何利用 Python 从头开始实现感知器算法。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在完成本教程后，你将学会：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如何训练感知器的网络权重&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如何利用感知器做出预测&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如何对于现实世界的分类问题实现感知器算法&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;让我们开始吧。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;概述&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本节简要介绍了感知器算法和 Sonar 数据集，我们将会在后面应用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;感知器算法&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;感知器的灵感来自于被称为神经元的单个神经细胞的信息处理过程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;神经元通过其树突接受输入信号，并将电信号向下传递到细胞体内。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过类似的方式，感知器从训练数据的样本中接受输入信号，训练数据被加权并在称为激活（activation）的线性方程中进行组合。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicsPeIvLZsUJgazZo1ias2IuR58uk06pl1hs3qIsAAqyAXl4jJS9TUgu9XqAy9jQ0S7cNUGkuhLGUQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然后，使用诸如阶跃传递函数（step transfer function）的传递函数将激活变换为输出值或预测。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicsPeIvLZsUJgazZo1ias2Iu2cXKNFv1vfsAtD4syvAIKOYHBnn6d0m00jAS9oz8LlBOZYKsWRg8Zg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以这种方式，感知器是用于具有两个类（0 和 1）的问题的分类算法，其中可以使用线性方程来分离这两个类。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;它与以类似方式进行预测的线性回归和 logistic 回归密切相关（例如输入的加权和）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;感知器算法的权重必须使用随机梯度下降算法从训练数据中估计。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;随机梯度下降&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;梯度下降是通过跟随成本函数（cost function）的梯度来最小化函数的过程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这涉及了解成本的形式以及导数，使得从给定的点你可以知道梯度并且可以在该方向上移动，比如下坡到最小值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在机器学习中，我们可以使用一种技术来评估和更新称为随机梯度下降的每次迭代的权重，以最小化我们的训练数据模型的误差。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这种优化算法的工作方式是每次向模型显示每个训练实例。模型对训练实例进行预测，计算误差并更新模型以便减少下一预测的误差。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该过程可以用于在模型中找到能使训练数据上模型误差最小的权重集合。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于感知器算法，每次迭代，权重（w）使用以下等式更新：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicsPeIvLZsUJgazZo1ias2IuCR15qgicJ3zgQ2CzAgmSkoK19p5ssuTGnsLwNnSukqJCtLHG52meDOQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其中w是正在被优化的权重，learning_rate是必须配置的学习速率（例如 0.01），（expected - predicted）是在归因于权重的训练数据上的模型的预测误差，x是输入值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;S&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;onar 数据集&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们将在本教程中使用的数据集是 Sonar 数据集。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是一个描述了声呐啾啾叫声并返回不同服务的试探的数据集。60 个输入变量是在不同角度的返回强度。这是一个二元分类问题，需要一个模型来区分金属圆柱体和岩石。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;它是一个很好理解的数据集。所有的变量是连续的，通常在 0 到 1 的范围内。因此，我们不必对输入数据进行归一化，这通常是使用感知器算法的一个好地方。输出变量是字符串「M」（表示矿 mine）和「R」（表示岩石 rock），我们需要将其转换为整数 1 和 0。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过在数据集（M 或 Mines）中预测具有最多观测值的类，零规则算法（Zero Rule Algorithm）可以实现 53％的精度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你可以在 UCI Machine Learning repository：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://archive.ics.uci.edu/ml/datasets/Connectionist+Bench+(Sonar,+Mines+vs.+Rocks)）&lt;/span&gt;&lt;span&gt;中了解有关此数据集的更多信息。你也可以免费下载数据集，并将其放在工作目录中，文件名为 sonar.all-data.csv。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;教程&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个教程分为三个部分：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1.作出预测&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2.训练网络权重&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3.将 Sonar 数据集建模&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些步骤将带给你实现和应用感知器算法到你自己的分类预测建模问题的基础。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1. 作预测&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一步是开发一个可以进行预测的函数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这将会需要在随机梯度下降中的候选权重值的评估以及在模型被最终确定之后，我们希望开始对测试数据或新数据进行预测。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面是一个名为 predict() 的函数，用于预测给定一组权重的行的输出值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一个权重始终是偏差，因为它是独立的，不负责特定的输入值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicsPeIvLZsUJgazZo1ias2IuMrXeLicnjIkPD4dweYXbr8a7jz0tRU6JQtZzSPJM45hlE1axSzznqNw/0?wx_fmt=png"/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们可以设计一个小数据集来测试我们的预测函数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicsPeIvLZsUJgazZo1ias2IucnkwaNuPyMzA1etI2PQuQq2bS27VanfQ2VbGX4Th2crFRJ3FuKialSw/0?wx_fmt=png"/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们也可以使用之前准备好的权重来为这个数据集做预测。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;将所有这些集中起来，我们就可以测试我们的 predict() 函数了，如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicsPeIvLZsUJgazZo1ias2Iu6YiaMuicXM9pSxLIZ4KAscevJicrCNgMA34sBzpBjnz5rxicyib0FmEA6Ng/0?wx_fmt=png"/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该函数有两个输入值 X1、X2 和三个权重参数 bias、w1 及 w2。该问题的激活函数有如下的形式：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicsPeIvLZsUJgazZo1ias2IuzBpTY21RHjUKGjw27bFc9mdjnct7qtFdERT6FVm9I5XSDggdm1XxTA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;或者，我们能够手动地选择权重值：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicsPeIvLZsUJgazZo1ias2Iuj6OicNIlSzibiaJ4gNfCb6nFqb16SMkJQdf9K667f8pR7JNQzpQdEjpBw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;运行这个函数，我们将会得到与期望输出值 (**y**) 相符合的预测值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicsPeIvLZsUJgazZo1ias2Iu26ylV03nTicsSeIibHqv7iaiaY8pgSLk3kuAXKVuqbPysqYJjEqicPL04Dg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在，我们已经准备好使用随机梯度下降法（SGD）来最优化我们的权重值。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2. 训练神经权重&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们可以使用 SGD，来估计出对于训练集的权重值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;SGD 有两个参数：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;学习率（Learning Rate）：用来限制每次更新中权重项修正值的大小。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;迭代次数（Epochs）：在训练集上训练同时更新权重项的次数。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这两个参数，和训练集一起，都将会是预测函数的输入参数。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这个函数中，我们需要运行三个循环：&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 对于每次迭代进行循环；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 对于一次迭代中，训练集的每一行进行循环；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3. 对于每一行中，每一个值进行循环。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如你所见，我们在每一次迭代中，对训练集每一行中每一个权值都进行更新。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们基于现有情况模型预测的「误差」，来对权重值进行更新。误差，是由候选权值计算出来的预测值与（数据集中的）期望值的差。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对每一个输入属性，都有一个权重值，并且这些权_重值都连续更新_。如：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicsPeIvLZsUJgazZo1ias2IuAUaJJPicgMicUkWX5MF8ibzp4ich0J9nMRdY5p5sBS8wZrq6lhHkxHjGdw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;偏差项以一种相似的方式更新，不过因为它本身就不与特定的输入值有关，因而在式子中没有输入值的项。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicsPeIvLZsUJgazZo1ias2Iu63iarVI5iaR7MVP9IQN2mhhSuc0ribCoQR9YlJ6lOSfREJQaViboGpsfzg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在，我们把所有的内容组合到一起。如下所示，在 train_weights() 函数中，它使用 SGD 方法，计算对于给定训练集的权重值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicsPeIvLZsUJgazZo1ias2IunAMYCGjib2ru5eSHzTRib6zBsGDdlf6LMnx5pzCqDY4xSbvIGsD5BZLw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如你所见，我们也在每次迭代中，记录下了平方误差之和（这始终是一个正值）。因而我们能在外循环的每次迭代中，print 一些有用的信息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们也可以在我们上面创建的小规模数据集上，对该函数进行测试。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicsPeIvLZsUJgazZo1ias2IueN9D4GWkC01Xht9OicCCR62qlGUkYQsSswrgFiaPOs9e4TT8m3RgOjdA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们将使用 0.1 的学习率和 5 次迭代，也就是把参数在训练集上更新五次，来训练这个模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;运行这个案例，它将会在每一次迭代结束后，显示出该次迭代后的平方误差和，并在完成所有迭代后，显示最后的权重集。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicsPeIvLZsUJgazZo1ias2IuiaPeXF9F8yEg9KQ79AQObDNwmsn4h46icGh3xnGwWaM8XP4S8gnjUqkQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你可以看到，这个算法很快学会了「解决」这个问题。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在我们来试试看，如何在一个实际的数据集上应用这个算法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3. 对声纳数据集进行建模&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这一节中，我们将使用 SGD 方法，对一个声纳数据集，训练一个感知器模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在该例子中，我们假定，在当前的工作目录下，有一名为&lt;strong&gt;sonar.all-data.csv&lt;/strong&gt; 的文件，存储着该数据集。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先该数据集被载入。数据集中字符串格式的数据被转换为数值型，同时输出值从字符串被转换了 0 或 1 的两个整数值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过&lt;strong&gt; load_csv(), str_column_to_float()及str_column_to_int() &lt;/strong&gt;三个函数，我们实现了对数据集的读取及预处理。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们使用「k 倍交叉验证法」（k-fold cross validation）来对学习后的模型在未知数据集上的表现进行评估。也就是说，我们需要建立 k 个模型并估计各模型的平均误差。分类准确性将被用于模型的评估工作中。这些工作在 &lt;strong&gt;cross_validation_split(), accuracy_metric() 及 evaluate_algorithm() &lt;/strong&gt;函数中被完成。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们将会使用上面设置的&lt;strong&gt; predict()&lt;/strong&gt; 和&lt;strong&gt; train_weights()&lt;/strong&gt;函数来训练该模型。同时，我们将会用一个新函数&lt;strong&gt; perceptron() &lt;/strong&gt;来将它们组合在一起。如下是完整的例子。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicsPeIvLZsUJgazZo1ias2IuBsLw6loicYRnj1tu2icZsicHpzNzkOg8UQMiaXHIRjZjMDwm7ZfickCa2jQ/0?wx_fmt=png"/&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicsPeIvLZsUJgazZo1ias2IuuaXykSWI0a7wmb1ch9xpLmqnog2icNTv1mFeicZJYuDJZ95siaP0zVUbw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicsPeIvLZsUJgazZo1ias2IupcDG0JWt0OcqaEK0DP12o6gUU1AY05amW7V5DJnGxBG5jJQrCTzUDg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在交叉验证中，我们取 k 为 3——也就是对每一块数据，都有 208/3 约 70 个记录，会在每次迭代中被用于计算。我们取 0.1 的学习率及 500 的训练迭代次数，来训练模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你可以尝试你自己的参数，并且看看你的结果能否战胜我的分数。运行这个例子，将会显示对 3 倍交叉验证中每一块的分数，以及平均的分类正确率。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们可以看到，这个正确率约为 73%，高于由仅考虑主要类的零规则算法（Zero Rule Algorithm）得到的 50% 的正确率基准值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicsPeIvLZsUJgazZo1ias2Iu66FVpT5THHaNaPYibpuT0p7bQp98MlESvqBiby0FFKVrR256ZfMxAx8g/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;拓展&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这一节列举了关于该入门指导的拓展内容，你可以考虑深入探究其中的一些内容。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;调试样例参数。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;尝试着去调整包括学习率、迭代次数乃至于数据预处理的方法，以使模型在该数据集上，得到更高的分数。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;批量化进行随机梯度下降。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;修改随机梯度下降的算法，使得我们能记录下每一次迭代的更新值，并且在迭代结束的时候再基于记录的更新值来更新权重值。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;额外的分类问题。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;将文中提到的技巧，应用于 UCI 机器学习数据集中其他数据。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;回顾&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在该教程中，你学习了如何从零开始，用 Python 实现，基于随机梯度下降的感知器算法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你学会了：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如何对一个二元分类问题进行预测。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如何使用随机梯度下降，对一系列的权重值进行最优化。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如何将这个技巧，应用到一个实际的分类预测模型。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Mon, 07 Nov 2016 14:44:05 +0800</pubDate>
    </item>
    <item>
      <title>学界 | 谷歌ICLR 2017论文提出超大规模的神经网络：稀疏门控专家混合层（附论文）</title>
      <link>http://www.iwgc.cn/link/3399373</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自ICLR2017&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicsPeIvLZsUJgazZo1ias2IuV0x4q713CXvCrUDcPnX6znymZSFvbg27yzdd9dQiaP6YHVocadEcv5g/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：神经网络吸收信息的能力受限于其参数的数量。在这篇论文中，我们提出一种新类型的层——稀疏门控专家混合层（Sparsely-Gated Mixture-of-Experts(MoE)），它能够在仅需增加一点计算的基础上被用于有效提升模型的能力。这种层包含了多达数万个前向的子网络（feed-forward sub-networks，被称为专家（expert）），总共包含了多达数百亿个参数。一个可训练的门网络（gating network）可以确定这些专家的稀疏组合以用于每一个样本。我们将这种 MoE 应用到了语言建模任务上——在这种任务中，模型能力对吸收训练语料库中可用的大量世界知识而言是至关重要的。我们提出了将 MoE 层注入堆叠 LSTM（stacked LSTM）的新型语言模型架构，得到的模型的可用参数数量可比其它模型多几个数量级。在语言建模和机器翻译基准上，我们在更低的成本上实现了可与当前最佳表现媲美或更好的结果，其中包括在 1 Billion Word Language Modeling Benchmark 上测得的 29.9 的困惑度（perplexity），以及在 WMT』14 En to Fr（英法翻译）和 En to De（英德翻译）上分别得到了 40.56 和 26.03 的 BLEU 分数。 &amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicsPeIvLZsUJgazZo1ias2Iuic44HqiaPwSJj32u5pU9YBYu3jJo3I6D6hITribTRaZhtfN1O62alyMiaA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;图 1：一个嵌入在语言模型中的专家混合（MoE/Mixture of Experts）层。在这里例子中，其稀疏门函数（sparse gating function）可以选择两个专家（expert）来执行计算。它们的输出由该门网络（gating network）的输出进行调制。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Mon, 07 Nov 2016 14:44:05 +0800</pubDate>
    </item>
    <item>
      <title>历史 | 神灵庇佑的11月：图灵机、Firefox 和Windows的诞生时刻</title>
      <link>http://www.iwgc.cn/link/3399374</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Fortune&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：杜夏德、蒋思源&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;在世界的不同地方，人们都有幸运时间的说法，不管那是按生肖计算还是要看星座。11 月上半月无疑是计算机科学领域的幸运月。自 1936 年以来，就像有计算机之神的庇佑一样，计算机领域内的很多具有历史里程碑意义的大事件都集中发生在 11 月的上半月，其中包括：阿兰·图灵提出了现代计算机的前身「图灵机」、松下发布第一款手持式计算机、微软宣布开发 Windows 操作系统、IBM 宣布实现磁盘小型化的突破性技术、火狐推出 1.0 版本……这个 11 月，让我们简单回顾一下那些塑造了我们今日的数字生活的 11 月。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicsPeIvLZsUJgazZo1ias2IusqbFC0pc925icqgBhTtia5rx531x0Ae3JA9K72EpjDibtcDodHnqcBicUA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;在 2015 年 3 月香港的一场拍卖预览会上，来自阿兰·图灵的笔记本中的一页在他的肖像前展示&lt;/span&gt;&lt;/em&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1991 年 11 月 8 日&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这一天，历史上第一次图灵测试在波士顿计算机博物馆举行。Thinking Software 的总裁 Joseph Weintraub 用他的软件骗过了 10 位裁判员中的 5 位，赢得了这场比赛。他的软件可以像人那样展开异想天开的对话。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;关于 Weintraub 的软件，Mark Halpern 在「图灵测试的麻烦」中写道：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;这款程序在测试过程中被称为终结者 5（T5），它发表的言论比大多数计算机驱动的终端说的话更有趣（这不算夸赞），但对于这些程序来说，就是完美的标准。它主要靠的是「非定向疗法」的策略，多年前该策略由 Joseph Weizenbaum 与 Kenneth Colby 提出，在这个策略中程序可以从输入的数据中挑出一小段（例如，「I wish I knew more about X」中的 X），将这一小段插入预先录制好的回复（「Why are you interested in X?」）中 ... 值得注意的是，五名裁判发现 T5 是人类，包括两名把人类说话当成计算机的裁判。总体上来说，裁判的表现让我们得出一个不太好的总结，T5 无法深入到持续的对话中，缺乏人类常识，它们无法与人类分享酸甜苦乐，与它们聊天的感觉跟照着镜子和自己说话一样，终究无法驱逐孤独的感觉。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是 Weintraub 的软件（T5）与裁判之间的「异想天开的对话片段」：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;裁判 3：告诉我你理想中完美世界是什么样的？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;T5： 想法总比现实多，你是一个心不在焉的教授吗？你自己是怎么想象一个完美世界的？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;裁判 2：Hi，你住在哪里？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;T5： 你耳朵没问题吧？有时我真希望自己就是一个程序分析师... 请继续，我发现这个太有趣了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;上世纪 50 年代，阿兰·图灵在其论文「计算机器和智能（Computing Machinery and Intelligence）」中提出「模拟游戏」时，他引用了著名的「洛芙莱斯夫人异议（Lady Lovelace』s Objection）」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;我们所了解的关于 Babbage 分析机的绝大部分细节都来自于 Lady Lovelace 的回忆录（1842）。她在回忆录中写道，「分析机不会自命为任何东西，它可以做任何我们知道如何命令它执行的事情。」Hartree 曾引用过这句话，他补充道：「这并不是说不可能做出一台可『自我思考』以的电子设备，或者从生物学角度上说，人们可以建立一个条件反射，作为'学习'的基础。根据最近的技术进展来看，无论理论上是否成立，它都是刺激 一个让人兴奋的刺激问题。但是机器似乎不太可能立即就掌握这项技能。」&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;我非常同意 Hartree。人们会注意到他的意思并不是机器无法掌握这个技能。分析机是一个通用的数码计算机，所以，如果它的存储量和速度能满足要求，它就可以通过适当的编程来模拟出来。或许伯爵夫人和 Babbage 没有想到这些。他们也没必要在任何情况下都对外声称自己做过的所有事情... 罗浮莱斯夫人异议的另一个版本中说到，一个机器「永远不会做出真正的新东西。」就像那句谚语中说的「太阳底下无新事」。谁敢肯定自己的「原创作品」不是经过接受教育之后产生的成果，或否定它受到一些众所周知的准则影响呢？还有一个更好的版本是，机器从来不会「给我们惊喜」。这种说法更加具挑衅，可以直接反驳。机器经常给我惊喜，大部分是因为我没做好充分的计算来决定让机器做什么，或者就是因为即便我做好了计算，也是匆忙草率的，风险很大。或许我该对我自己说，「我想这里的电压应该和那里的一样，不管怎样，让我们假设它是一样的。」我常常出错，这是很自然的事情，而且结果让我惊喜常常是因为实验结束的时候已经忘了假设。我的讲座主题总是关于我那些邪恶的方法，但是当我要明我所经历的惊喜时，请不要怀疑我。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;Bringsjord、Bello 和 Ferruci &lt;/span&gt;在《Creativity, the Turing Test, and the (Better) Lovelace Test》中写道：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;不幸的是，打造能够通过（图灵测试）的计算系统的尝试……已经转到浅显的符号操作上，这些操作不管是怎么设计的，都是用来骗人的。这种系统的人类创造者很了解他们只是在尝试欺骗那些与他们的系统进行互动的人，让他们相信这些系统真正是有心智的。而这样做的根本问题是：图灵测试的结构是为了培养骗子。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;几个月后，Nuance Communications 赞助了第一轮的威诺格拉德模式挑战赛（Winograd Schema Challenge），这是图灵测试的一个替代选择。其结果是：机器在代词解析（pronoun resolution）上达到了 58.33% 的正确率，相对而言，人类的准确率是 90.9%。即便如此，谷歌的「人工智能机器（artificial intelligence machine）」还是因为变得「极其愤怒（exasperated）」并「打断了人类询问者」的对话而成为了新闻头条：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2004 年 11 月 9 日&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Firefox 1.0 发布。Firefox（火狐）得名于生活在喜马拉雅山东部和中国西南部的一种动物——红狐。它在发布首日就获得了 100 万的下载量，10 天下载量达到了 1000 万，而在一年之后 Firefox 1.5 发布之前，其下载量已经超过了 1 亿。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1981 年 11 月 10 日&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;松下推出了 The Link 手持式计算机（不知道可不可以简称「手机」？），它带有一块键盘但没有屏幕。它可以被连接到一台电视机或通过电话拨号连接到一台主机计算机。它的尺寸为 9」x4」，重 21 盎司（大约 595 克），售价 600 美元。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1983 年 11 月 10 日&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;微软宣布 Windows——「一个窗口管理器和图形设备界面」，并表示其将在四月份将软件交付给经销商（尽管像 Windows 这样的产品是很难预料的，可能需要更长的时间）。Martin Campbell-Kelly 和 William Aspray 在《Computer: A History of the Information Machine》中写道：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Microsoft Windows 是最近出现的用于 PC 的新操作系统。微软在 1981 年 9 月开始研发一个图形用户界面项目，在此不久之前盖茨拜访了苹果公司的史蒂夫·乔布斯，并看到了正在开发之中的 Macintosh 原型计算机。这个微软项目被命名为 Interface Manager，但是一场名为「让我们的名字基本上能定义这种通用范例」的市场营销项目中，他们将其名字改成了 Windows。他们估计这个系统需要 6 个程序员开发几年的时间。事实证明他们严重低估了。当 Windows 的版本 1 在 1985 年 10 月发布时……据估计该程序包含了 110,000 条指令，用了 8 0 位程序员几年的时间才完成。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1997 年 11 月 11 日&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;IBM 发布了第一个带有巨磁阻（Giant Magnetoresistive (GMR)）磁头的大容量个人计算机磁盘驱动器，这使磁盘驱动器能够进一步小型化。2007 年的诺贝尔物理学奖就颁给了在 1988 年为巨磁电阻效应（GMR effect）做出巨大贡献的 Albert Fert 和 Peter Grünberg&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1936 年 11 月 12 日&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;阿兰·图灵（Alan Turing）将他的论文《论可计算性数字，一种判定问题的应用》（On Computable Numbers, with an Application to the Entscheidungsproblem）提交给伦敦数学学会（London Mathematical Society）。在论文中，图灵描述了一种后来被称之为「图灵机（Turing Machine）」的通用机器，这是一种理想化的计算设备，它能够执行任何数学计算并表达成算法。历史学家 Thomas Haigh 反对现在日益流行的「图灵发明了现代计算机」说法，他说「事实上，图灵没有发明计算机（Communications of the ACM, January 2014）」。下面是 Haigh 的具体观点：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;我们迫切相信 20 世纪 40 年代的计算机运动是由人们对通用图灵机的渴望催生的，从更广泛的角度来看，这种信念反映出我们更愿意看见理论计算机科学能够驱动整体计算的发展。如果认为是图灵创立了计算机科学，那么对计算机科学本身也是一种过度简化，这样一来我们也能肯定地说他发明了计算机。在这种观点下，计算机仅仅是通用图灵机的基本理论思想的一种实现过程，因为它是通用的并且能交换地存储数据和指令... 然而关注历史上的计算机，将其作为逻辑思维的体现，却忽视其发明者在发明计算机时面临的有限资源和对未验证技术所作出的权衡，这种做法本身就剥离了理解计算机历史和发展所需要的信息。电子工程特别是内存技术的发展创造了一个良好的氛围，在这个氛围下考虑以电子方式储存指令的高速电子计算才有意义。反过来，关于设计这些机器的最佳方法的想法也驱动了计算机组件技术和工程方法的发展。通用图灵机自从 20 世纪 50 年代以来就对计算机理论学家充满了吸引力并明确地向前发展，因为它脱离了复杂的计算机功能结构，也脱离了可计算性与设计和工程的解耦问题。这不论在技术上还是社会上都对计算理论家们有很大的作用。然而矛盾的是世界好像对寻找计算机在数学概念上的准确表达充满了兴趣，因为这样就可以避免那些建造并运行一台真正计算机所需要面对的各种各样问题。在计算理论学家眼里，软硬件是可以互换的，但对具有历史眼光的人来说并不这样。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人们总是渴望将技术创新的起源归根于「科学」而不是「工程（engineering）」，这种渴望超越了人们对于从杂乱中提取抽象总结的欲望。好像一切都与科学的威望有关，科学有很高的社会地位，而工程恰恰相反。1915 年，三元高真空管的发明成就了第一通越洋电话，为了庆祝这一成功，美国电话电报公司发了一条广告，宣称这是「科学的胜利」，&lt;span&gt;「&lt;/span&gt;不是工程的胜利」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Mon, 07 Nov 2016 14:44:05 +0800</pubDate>
    </item>
    <item>
      <title>重磅论文 | 如何通过机器学习解读唇语？DeepMind要通过LipNet帮助机器「看」懂别人说的话</title>
      <link>http://www.iwgc.cn/link/3388468</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自oxml.co.uk&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;em style="color: rgb(136, 136, 136);"&gt;&lt;span&gt;还记得经典科幻电影《2001 太空漫游》中的飞船主控计算机 Hall 吗？它具有依靠阅读说话人的嘴唇运动理解其所表达的内容的能力，这种能力也在推动那个幻想故事的情节发展中起到了至关重要的作用。近日，牛津大学、Google DeepMind 和加拿大高等研究院（CIFAR）联合发布了一篇同样具有重要价值的论文，介绍了利用机器学习实现的句子层面的自动唇读技术 LipNet。该技术将自动唇读技术的前沿水平推进到了前所未有的高度。原论文可点击文末「阅读原文」下载。&lt;/span&gt;&lt;/em&gt;&lt;br/&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;iframe class="video_iframe" data-vidtype="1" style="   z-index:1; " height="375" width="500" frameborder="0" data-src="https://v.qq.com/iframe/preview.html?vid=b0343vh7eug&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0" allowfullscreen=""&gt;&lt;/iframe&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9RD7kdS9x2m8NcicfRrYTorwjjJeTsCUpuYZcGOZbIBbSX324tGOcoImJRQ8rBamLuRSquI3icEZNg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;摘要&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;唇读（lipreading）是指根据说话人的嘴唇运动解码出文本的任务。传统的方法是将该问题分成两步解决：设计或学习视觉特征、以及预测。最近的深度唇读方法是可以端到端训练的（Wand et al., 2016; Chung &amp;amp; Zisserman, 2016a）。但是，所有已经存在的方法都只能执行单个词的分类，而不是句子层面的序列预测。研究已经表明，人类在更长的话语上的唇读表现会更好（Easton &amp;amp; Basala, 1982），这说明了在不明确的通信信道中获取时间背景的特征的重要性。受到这一观察的激励，我们提出了 LipNet——一种可以将可变长度的视频序列映射成文本的模型，其使用了时空卷积、一个 LSTM 循环网络和联结主义的时间分类损失（connectionist temporal classification loss），该模型完全是以端到端的形式训练的。我们充分利用我们的知识，LipNet 是第一个句子层面的唇读模型，其使用了一个单端到端的独立于说话人的深度模型来同时地学习时空视觉特征（spatiotemporal visual features）和一个序列模型。在 GRID 语料库上，LipNet 实现了 93.4% 的准确度，超过了经验丰富的人类唇读者和之前的 79.6% 的最佳准确度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1 引言&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;唇读在人类的交流和语音理解中发挥了很关键的作用，这被称为「麦格克效应（McGurk effect）」（McGurk &amp;amp; MacDonald, 1976），说的是当一个音素在一个人的说话视频中的配音是某个人说的另一个不同的音素时，听话人会感知到第三个不同的音素。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;唇读对人类来说是一项众所周知的艰难任务。除了嘴唇和有时候的舌头和牙齿，大多数唇读信号都是隐晦的，难以在没有语境的情况下分辨（Fisher, 1968; Woodward &amp;amp; Barber, 1960）。比如说，Fisher (1968) 为 23 个初始辅音音素的列表给出了 5 类视觉音素（visual phoneme，被称为 viseme），它们常常会在人们观察说话人的嘴唇时被混淆在一起。许多这些混淆都是非对称的，人们所观察到的最终辅音音素是相似的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以说，人类的唇读表现是很差的。听觉受损的人在有 30 个单音节词的有限子集上的准确度仅有 17±12%，在 30 个复合词上也只有 21±11%（Easton &amp;amp; Basala, 1982）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因此，实现唇读的自动化是一个很重要的目标。机器读唇器（machine lipreaders）有很大的实用潜力，比如可以应用于改进助听器、公共空间的静音听写、秘密对话、嘈杂环境中的语音识别、生物特征识别和默片电影处理。机器唇读是很困难的，因为需要从视频中提取时空特征（因为位置（position）和运动（motion）都很重要）。最近的深度学习方法试图通过端到端的方式提取这些特征。但是，所有的已有工作都只是执行单个词的分类，而非句子层面的序列预测（sentence-level sequence prediction）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这篇论文中，我们提出了 LipNet。就我们所知，这是第一个句子层面的唇读模型。就像现代的基于深度学习的自动语音识别（ASR）一样，LipNet 是以端到端的方式训练的，从而可以做出独立于说话人的句子层面的预测。我们的模型在字符层面上运行，使用了时空卷积神经网络（STCNN）、LSTM 和联结主义时间分类损失（CTC）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们在仅有的一个公开的句子层面的数据集 GRID 语料库（Cooke et al., 2006）上的实验结果表明 LipNet 能达到 93.4% 的句子层面的词准确度。与此对应的，之前在这个任务上的独立于说话人的词分类版本的最佳结果是 79.6%（Wand et al., 2016）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们还将 LipNet 的表现和听觉受损的会读唇的人的表现进行了比较。平均来看，他们可以达到 52.3% 的准确度，LipNet 在相同句子上的表现是这个成绩的 1.78 倍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，通过应用显著性可视化技术（saliency visualisation techniques (Zeiler &amp;amp; Fergus, 2014; Simonyan et al., 2013)），我们解读了 LipNet 的学习行为，发现该模型会关注视频中在语音上重要的区域。此外，通过在音素层面上计算视觉音素（viseme）内和视觉音素间的混淆矩阵（confusion matrix），我们发现 LipNet 少量错误中的几乎所有都发生在视觉音素中，因为语境有时候不足以用于消除歧义。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2 相关工作&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本节介绍了其它在自动唇读研究上的工作，包含了自动唇读、使用深度学习进行分类、语音识别中的序列预测、唇读数据集四个方面。但由于篇幅限制，机器之心未对此节进行编译，详情请查看原论文。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9RD7kdS9x2m8NcicfRrYTorwWGEqaxNdxy4icC0DOfObvhRk3pmYpMuJcocNr7eltzHzW8Bj41eC4w/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;em style="color: rgb(136, 136, 136);"&gt;&lt;span&gt;表 1：现有的唇读数据集和对应数据集上已被报告出来的最佳准确度。Size 这一栏是指作者训练时所用的话语的数量。尽管 GRID 语料库包含了整个句子，但 Wand et al. (2016) 只考虑了更简单的预测单独的词的情况。LipNet 预测的是句子，因此可以利用时间语境来实现更高的准确度。短语层面的方法被当作简单的分类看待。&lt;/span&gt;&lt;/em&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3 LipNet&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;LipNet 是一种用于唇读的神经网络架构，其可以将不同长度的视频帧序列映射成文本序列，而且可以通过端到端的形式训练。在本节中，我们将描述 LipNet 的构建模块和架构。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3.1 时空卷积&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;卷积神经网络（CNN）包含了可在一张图像进行空间运算的堆叠的卷积（stacked convolutions），其可用于提升以图像为输入的目标识别等计算机视觉任务的表现（Krizhevsky et al., 2012）。一个从 C 信道到 C' 信道的基本 2D 卷积层（没有偏置（bias），以单位步长）的计算：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9RD7kdS9x2m8NcicfRrYTorYgIncWu9eiahbgK7HPDBgVuQojW450OlVOQqjE1QhBBdop92YQyy35w/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于输入 x 和权重：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9RD7kdS9x2m8NcicfRrYToraXolMA2J5CictGpN0prakcHdHXrlO5oyD1Qkg0zs2qMR11NplwRJkuw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其中我们定义当 i,j 在范围之外时，xcij=0.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;时空卷积神经网络（STCNN）可以通过在时间和空间维度上进行卷积运算来处理视频数据：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9RD7kdS9x2m8NcicfRrYTorvib5eaibsMlk0CQ6VmkoRKSjSJX9UCdpJyibjWmVvtgbW7H8IAPwmRhLw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3.2 长短期记忆&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;长短期记忆（LSTM）（Hochreiter &amp;amp; Schmidhuber, 1997）是一类在早期的循环神经网络（RNN）上改进的 RNN，其加入了单元（cell）和门（gate）以在更多的时间步骤上传播信息和学习控制这些信息流。我们使用了带有遗忘门（forget gates）的标准 LSTM 形式：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9RD7kdS9x2m8NcicfRrYTorTsialkTZaW7LKhomtfR37dGjy9u3Wmh8iaMrxRDccqf9KBV1tCvPPdsw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其中 z := {z1, . . . , zT } 是 LSTM 的输入序列，是指元素之间的乘法（element-wise multiplication）, sigm(r) = 1/(1 + exp(−r))。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们使用了 Graves &amp;amp; Schmidhuber (2005) 介绍的双向 LSTM（Bi-LSTM）：一个 LSTM 映射&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9RD7kdS9x2m8NcicfRrYTor3DvleogNmia67cic3SDEblejpdp7OzibhCyFURO6pFNZHdwksQC2BmDZA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;，另一个是&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9RD7kdS9x2m8NcicfRrYTore5pAnibTT6cY9YFq417X03Wfpicqy8xYzI175RDR1MQCNJcIQhHHk49Q/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;，然后&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9RD7kdS9x2m8NcicfRrYTorQQghC6grTIBpW9GMibSpiaicbUfpEHRGhiaia2O4YF0nxNrT5MFzAjemsfw/0?wx_fmt=png"/&gt;&lt;br/&gt;，该 Bi-LSTM 可确保 ht 在所有的 t' 上都依赖于 zt'。为了参数化一个在序列上的分布，在时间步骤 t，让 p(ut|z) = softmax(mlp(ht;Wmlp))，其中 mlp 是一个权重为 Wmlp 的前向网络。然后我们可以将长度 T 的序列上的分布定义为&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9RD7kdS9x2m8NcicfRrYTorT6Nbo7icWZDl8gxz299ugUS2m1bGhDuvuMg57I7ZiaGNzYLvyaRcJh5A/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;，其中 T 由该 LSTM 的输入 z 确定。在 LipNet 中，z 是该 STCNN 的输出。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3.3 联结主义的时间分类&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;联结主义的时间分类损失（onnectionist temporal classification (CTC) loss）（Graves et al., 2006）已经在现代的语音识别领域得到了广泛的应用，因为这让我们不再需要将训练数据中的输入和目标输出对齐（Amodei et al., 2015; Graves &amp;amp; Jaitly, 2014; Maas et al., 2015）。给定一个在 token 类（词汇）上输出一个离散分布序列的模型——该 token 类使用了一个特殊的「空白（blank）」token 进行增强，CTC 通过在所有定义为等价一个序列的序列上进行边缘化而计算该序列的概率。这可以移除对对齐（alignment）的需求，还同时能解决可变长度的序列。用 V 表示该模型在其输出（词汇）的单个时间步骤上进行分类的 token 集，而空白增强过的词汇&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9RD7kdS9x2m8NcicfRrYToriafUPNzMtz2bE0dXqm2JVT9VVRlgUibd6P5neSNM1PsxQwGBEk0wxHhw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其中空格符号表示 CTC 的空白。定义函数 B : V˜ ∗ → V ∗，给定 V˜ 上的一个字符串，删除相邻的重复字符并移除空白 token。对于一个标签序列 y ∈ V ∗，CTC 定义&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9RD7kdS9x2m8NcicfRrYTor5pq6uP2wWuXOWJDYLKL0E7xvS711B61WCgibXlkt0RB2IoVY8xLgFWg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其中 T 是该序列模型中时间步骤的数量。比如，如果 T=3，CTC 定义字符串「am」的概率为&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9RD7kdS9x2m8NcicfRrYTorcPynj8zWyJThbtEavQ1Y9PXMdpkS2KPS7dn5ZmgvA2Bw3PlmoiaiaS5w/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个和可以通过动态编程（dynamic programming）有效地计算出来，让我们可以执行最大似然（maximum likelihood）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9RD7kdS9x2m8NcicfRrYTor4kuAbicannF6IahRgicQRfJG3Htib8ZN8TpaZkf5Ks3cbwF8me2uF8OLg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;图 1：LipNet 架构。一个 T 帧的序列被用作输入，被一个 3 层的 STCNN 处理，其中每一层后面都有一个空间池化层（spatial max-pooling layer）。提取出的特征是时间上上采样（up-sample）的，并会被一个 Bi-LSTM 处理；LSTM 输出的每一个时间步骤会由一个 2 层前向网络和一个 softmax 处理。这个端到端的模型是用 CTC 训练的。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3.4 LipNet 架构&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图 1 给出了 LipNet 的架构，其始于 3×（时空卷积、信道上的 dropout、空间最大池化），后面跟随时间维度中的上采样。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因为人类每秒钟大约能发出 7 个音素，而且因为 LipNet 是在字符层面上工作的，所以我们总结得到：每秒输出 25 个 token（视频的平均帧率）对 CTC 来说太受限了。时间上采样（temporal up-sampling）允许在字符输出之间有更多的空格。当许多词有完全相同的连续字符时，这个问题会加剧，因为他们之间需要一个 CTC 空白。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;随后，该时间上采样后面跟随一个 Bi-LSTM。该 Bi-LSTM 对 STCNN 输出的有效进一步会聚是至关重要的。最后在每一个时间步骤上应用一个前向网络，后面跟随一个使用了 CTC 空白和 CTC 损失在词汇上增强了的 softmax。所有的层都是用了修正线性单元（ReLU）激活函数。超参数等更多细节可参阅附录 A 的表 3.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;4 唇读评估&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这一节，我们将在 GRID 上评估 LipNet。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;4.1 数据增强&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;预处理（Preprocessing）:GRID 语料库包含 34 个主题，每一个主题包含了 1000 个句子。说话人 21 的视频缺失，其它还有一些有所损坏或空白，最后剩下了 32839 个可用视频。我们使用了两个男性说话人（1 和 2）与两个女性说话人（20 和 22）进行评估（3986 个视频），剩下的都用于训练（28853 个视频）。所有的视频都长 3 秒，帧率为 25 fps. 这些视频使用 DLib 面部检测器和带有 68 个 landmark 的 iBug 面部形状预测器进行了处理。使用这些 landmark，我们应用了一个放射变换（affine transformation）来提取每帧中以嘴为中心的 100×50 像素大小的区域。我们将整个训练集上对 RGB 信道进行了标准化以具备零均值和单位方差。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;增强（Augmentation）：我们使用简单的变换来增强数据集以减少过拟合，得到了多 15.6 倍的训练数据。首先，我们在正常的和水平镜像的图像序列上进行训练。然后，因为该数据集提供了每个句子视频中的词开始和结束时间，所以我们使用单独的词的视频片段作为额外的训练实例增强了句子层面的训练数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;4.2 基线&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了评估 LipNet，我们将其表现和三位懂得读唇的听觉受损者以及两个由最近的最佳成果启发的 ablation model（Chung &amp;amp; Zisserman, 2016a; Wand et al., 2016）的表现进行了比较。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;听觉受损者：这个基线是由牛津学生残疾人社区（Oxford Students』 Disability Community）的三位成员得到的。在被介绍了 GRID 语料库的语法之后，他们从训练数据集中观察了 10 分钟带有注释的视频，然后再从评估数据集中注释了 300 个随机视频。当不确定时，他们可以选择觉得最有可能的答案。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Baseline-LSTM：使用句子层面的 LipNet 配置，我们复制了之前 GRID 语料库当时（Wand et al., 2016）的模型架构。参看附录 A 了解更多实现细节。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Baseline-2D：基于 LipNet 架构，我们使用仅空间的卷积替代了 STCNN，这类似于 Chung &amp;amp; Zisserman (2016a) 的那些。值得一提的是，和我们用 LipNet 观察到的结果相反，Chung &amp;amp; Zisserman (2016a) 报告他们的 STCNN 在他们的两个数据集上比他们的 2D 架构的性能差分别 14% 和 31%。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;4.3 性能评估&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;strong&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9RD7kdS9x2m8NcicfRrYTorruMykGBuc46KvG19LYnQ2bBEmWu9RFCu2ncml5v7RicMWnmL6xqjdJA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;表 2：LipNet 相比于基线的性能&lt;/span&gt;&lt;/em&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;表 2 总结了相比于基线的性能。根据文献，人类唇读者的准确率大约是 20%（Easton &amp;amp; Basala, 1982; Hilder et al., 2009）。如预料的一样，GRID 语料库中固定的句子结构和每个位置有限的词子集有助于对语境的使用，能提升表现。这三位听觉受损者的词错率（WER）分别为 57.3%、50.4% 和 35.5%，平均词错率为 47.7%。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;4.4 学到的表征&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这一节中，我们从语音学的角度分析了 LipNet 的学习到的表征。首先，我们创造了显著性可视化（saliency visualisations (Simonyan et al., 2013; Zeiler &amp;amp; Fergus, 2014)）来说明 LipNet 所学的重点区域。特别地，我们向该模型送入了一个输入，并贪婪地解码了一个输出序列，得出了一个 CTC 对齐&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9RD7kdS9x2m8NcicfRrYTorh1udLfCvsBtfWc414YL2ha4GoGgzYe5lVxSX1s6tq9PHC9YtK9ZrDA/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（遵循 3.2 和 3.3 节的符号）。然后，我们计算了&amp;nbsp;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9RD7kdS9x2m8NcicfRrYTorgnicY6NaBpDtIdtnbv5gbpd0icHMmNiclS5EyGk3jEiagILEU8a078KpVw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;的梯度，并考虑了输入视频帧序列，但和 Simonyan et al. (2013) 不一样，我们使用了有引导的反向传播（guided backpropagation (Springenberg et al., 2014)）。第二，我们训练 LipNet 预测的是 ARPAbet 音素，而不是字符，这样可以使用视觉音素（viseme）内和视觉音素间的混淆矩阵（confusion matrix）来分析视觉音素。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4.4.1 显著性地图（Saliency Maps）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们应用显著性可视化技术（saliency visualisation techniques）来解读 LipNet 学习到的行为，结果表明该模型会重点关注视频中在语音方面重要的区域。特别地，在图 2 中，我们基于 Ashby (2013) 为说话人 25 的词 please 和 lay 分析了两个显著性可视化。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9RD7kdS9x2m8NcicfRrYTorLtzJEwibDFpAEFpUfxPichI2PMyP8KlqCNQ998RC7Fx7jnalZtWS96icw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;图 2：词 (a) please 和 (b) lay 的显著性地图，由向输入的反向传播产生，展示了 LipNet 学会关注的地方。图中的转录由贪婪 CTC 解码（greedy CTC decoding）给出。CTC 空白由空格符号表示。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4.4.2 视觉音素（viseme）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;根据 DeLand（1931）和 Fisher（1968），Alexander Graham Bell 首次假设给定说话人的多音素可被视觉地识别。这在后来得到了证实，这也带来了视觉音素的概念，即一个音素的视觉对应（Woodward &amp;amp; Barber, 1960; Fisher, 1968）。为了我们的分析，我们使用了 Neti et al. (2000) 中音素到视觉音素的映射，将视觉音素聚类成了以下类别：Lip-rounding based vowels (V)、Alveolar-semivowels (A),、Alveolar-fricatives (B)、Alveolar (C)、Palato-alveolar (D)、Bilabial (E), Dental (F)、Labio-dental (G) 和 Velar (H)。完整映射可参看附录 A 中的表 4. GRID 包含了 ARPAbet 的 39 个音素中的 31 个。我们计算了音素之间的混淆矩阵（confusion matrix），然后按照 Neti et al. (2000) 将音素分组成了视觉音素聚类。图 3 表示了 3 个最容易混淆的视觉音素类别，以及视觉音素类别之间的混淆。完整的音素混淆矩阵参看附录 B 图 4.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9RD7kdS9x2m8NcicfRrYTorpjJIBvKYzpvoOESW6TeHjRxU4FUehdVEsVk79TGXPGaEqwzibSqLemw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;图 3：视觉音素内和视觉音素间的混淆矩阵，描绘了 3 个最容易混淆的类别，以及视觉音素聚类之间的混淆。颜色进行了行规范化（row-normalised）以强调误差。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;5. 结论&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们提出了 LipNet，它是第一个将深度学习应用于模型的端到端学习的模型，可以将说话者的嘴唇的图像帧序列映射到整个句子上。这个端到端的模型在预测句子前不再需要将视频拆分成词。LipNet 需要的既不是人工编入的时空视觉特征，也不是一个单独训练的序列模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们的实证评估表明了 时空特征提取和高效的时间聚集（temporal aggregation）的重要性，确认了 Easton 和 Basala 在 1982 年提出的假说（1982）。此外，LipNet 大大超越了人类的读唇水平的基线，比人类水平高出 7.2 倍，WER 达到了 6.6%，比现在 GRID 数据集中最好的词水平（Wand 等人，2016）还要低 3 倍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然 LipNet 在实证上取得了成功，Amodei 等人在 2015 年发表的深度语音识别论文显示，只有更多的数据才能让表现提升。在未来的研究中，我们希望通过将 LipNet 应用到更大的数据集中来证明这一点，如由 Chung 和 Zisserman 等人在 2016 年收集的这种数据集的句子水平变体（sentence-level variant）。像默写这样的应用只能使用视频数据。然而，为了扩展 LipNet 的潜在应用，我们能将这种方法应用到一种联合训练的视听语音识别模型上，其中视觉输入会在嘈杂的环境中提升鲁棒性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;致谢、参考文献及附录（略）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Sun, 06 Nov 2016 16:45:06 +0800</pubDate>
    </item>
    <item>
      <title>前沿 | Nature发布计算和理论神经科学特刊：剖析机器学习推动下的神经科学进展</title>
      <link>http://www.iwgc.cn/link/3388469</link>
      <description>&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Nature Neuroscience&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：蒋思源、杜夏德&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;Nature Neuroscience 近日推出了一个关注应用于神经科学的计算驱动的和理论驱动的方法（computation- and theory-driven approaches）的特刊，介绍了许多生物物理模型和机械式的模型。相关论文可点击「阅读原文」查看。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;神经科学研究的进展无法脱离数据收集，同时也需复杂的方法将这些数据组装和合成到更广泛的框架中。理论神经科学，加上必要的计算技术，能确保我们的努力不仅仅是大规模的收集工作。本期，&lt;em&gt;Nature Neuroscience&lt;/em&gt; 呈现了一批论文综述与观点讨论，包含了一系列当下该领域突出的思考，从神经回路和网络到认知评估和精神疾病。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;神经机制的深刻见解都是来源于基于理论的研究。描述动作电位传播的 Hodgkin-Huxley 模型，Hebbian-based 的可塑性规则，Barlow 的有效编码假说和 Marr 的三层分析模型都是强有力的证明。然而尽管取得了这些成就，但生物学仍然存在实验和理论之间的脱节，这些在物理学上简直无法想象。技术的进步使得生物学在现代神经科学理论与实验的分离更有先见之明。正是这种大量数据生成的能力需要敏锐的实验设计和聚焦问题以获得理解。由于在没有理论基础的条件下就对这一问题的概念化，实验神经科学不过就是多个观察的简单堆叠，就像宇宙建立在海龟背上那种传说中的模型毫无意义。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;自然神经科学出版了一期关于计算神经科学的特刊，之前已经出版过三期的特刊。第一期是关于这一领域几十年主流的历史评论中不被看好但非常重要的内容。接下来两个合刊分别介绍了一些综述与主要的研究论文。现在我们处在一个临界点，即该领域已经成熟到可以做一期新的特刊，由综述和观点还有一篇评论构成，强调了了计算和理论神经科学近期的一些进展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;实验创新几乎已经蔓延到神经科学的每一个分支，而每个问题上都有了更多的数据。在《理论神经科学的关键时刻，概念与技术的进步》（Conceptual and technical advances define a key moment for theoretical neuroscience）论文中，Churchland 和 Abbott 推荐一个称之为大帐篷政策（big tent approach）的方法，计算和理论进入了从原始数据分析到建立详细的机制和生物物理模型所有阶段。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这里有一个详细的生物物理建模的例子，围绕带有相等的兴奋性和抑制性输入的网络建模，实验性证据也支持这种突触平衡（synaptic balance）的存在。在《高效的代码与均衡网络》（Efficient codes and balanced networks）论文中，Denève 和 Machens 论述了平衡网络模型的最新进展，他们特别强调这种网络能够支持高效的编码。大多数网络模型的实例化是以连续时间系统为背景的，然而我们知道神经元主要是是通过离散的尖峰脉冲传递信息的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在《建立尖峰神经模型的功能网络》（Building functional networks of spiking model neurons）的论文中，Abbott, DePasquale 和 Memmesheimer 讨论了当前桥接模拟-数字鸿沟的方法。我们总希望能逆向运行而不是施加一个网络结构来匹配当前的尖峰输出。人口记录和成像现在已经很平常了，但有可能推断出这种生理机制和可变性的来源吗？在《神经相关的状态依从性机制》（The mechanics of state-dependent neural correlations）中，Doiron 和同事们论述了跟踪大脑状态中的神经关联变化如何能暗示潜在的因果要素。但考虑记忆理论的时候，不同的神经状态视图就变得很重要了，也就是我们该如何如何构建并且维持稳定的表征。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Chaudhuri 和 Fiete 在《记忆的计算法则》（Computational principles of memory）论文中关注记忆系统所必要的法则。他们论述了相关的网络构架，潜在的生物物理过程，噪音的鲁棒性（robustness to noise），信息能力和编码策略，并承认其可以和计算机科学相媲美。计算机科学，特别是用计算机视觉技术构建的目标识别系统，又兜回来告诉我们如何建立人类视觉感知的模型。在《利用目标驱动的深度学习模型来理解感觉皮层》（Using goal-driven deep learning models to understand sensory cortex）论文的观点中，Yamins 和 DiCarlo 介绍了目标驱动的深层神经网络在解释感官处理上成功的一些原因，并提出可以做出类似的进展来超越感知系统。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;神经系统层级上升后，我们就可以做出感知上（perceptual）或者形式更加公开的决定。在《信心与确定：不同目标的不同概率量》（Confidence and certainty: distinct probabilistic quantities for different goals）这篇论文中，Pouget，Drugowitsch 和 Kepecs 提出了决策确定性（decision certainty）与决策信心（decision confidence）之间的绝对区分。当大脑在嘈杂的环境下工作时（「当」指的是「在任何时候」），大脑必须计算出概率分布。作者认为，确定性应该是指所有概率决策变量的编码，而信心应被具体定义为一个决策正确的概率。也许只有时间才能决定是否应该对它们的建议有信心。有了更好的感知模型后，当系统出现故障时，行为和决策制定也能潜在地让我们诊断和修改对策。Huys，Maia 和 Frank 在 Computational psychiatry as a bridge from neuroscience to clinical applications 这篇论文中对计算精神病学的新兴领域做了一个综述，详细介绍了机器学习计算应用以及基于理论的机器模型这两种方式在疾病分类和治疗上综合运用的进展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本期杂志中涉及的话题涉及的范围很广，大多数重点的内容都是发表在其他期刊上的文章。事实上，我们期刊上神经计算文章的数量最近几年一直在稳步增长。从谷歌搜索的 Google Trends 上看，对计算神经科学的普遍兴趣得到了初步支持（也许是确认偏误（conformation bias）？）过去 5 年中「computational neuroscience」的搜索量稳步增长，其增长可以在同一时期「光遗传学」的搜索频率也有类似的增长中得到佐证。计算神经科学增长或许不会迎来拐点，因为对该领域主题特定的期刊（如计算神经科学期刊。Journal of Computational Neuroscience）以及博士课程的搜索也会将这个词汇的搜索频率推向在峰值。有趣的是，到目前为止，「认知神经科学」的搜索数量远远超过了计算神经科学，但是搜索频率也会有季节性波动，每年秋天大学新生入学时搜索频率会波动性增长。现在每所大学都应该让计算成为神经生物学课程的核心部分。好处是在这 5 年的时间里，我们不再需要通过证明计算与神经科学的相关性来吸引大家对神经计算研究的关注。最大的希望是能促使神经计算在生物学有更好的理解，以及实现更好疾病治疗。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Sun, 06 Nov 2016 16:45:06 +0800</pubDate>
    </item>
  </channel>
</rss>
