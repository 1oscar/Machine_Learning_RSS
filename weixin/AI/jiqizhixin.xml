<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>机器之心</title>
    <link>http://www.iwgc.cn/list/670</link>
    <description>人与科技的美好关系</description>
    <item>
      <title>干货 | 图解LSTM神经网络架构及其11种变体（附论文）</title>
      <link>http://www.iwgc.cn/link/2923335</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自FastML&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Zygmunt Z.&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：老红、李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;就像雨季后非洲大草原许多野生溪流分化成的湖泊和水洼，深度学习已经分化成了各种不同的专门架构。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;并且，每个架构都会有一个图解，这里将详细介绍它们。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;神经网络在概念上很简单，并且它们十分动人。在层级上，有着一堆同质化的元素和统一的单位，并且它们之间还存在在一系列的加权连接。这就是神经网络的所有，至少从理论上来说是这样。然而，时间证明的结果却有所不同。并非工程的特性，我们现在拥有的是建筑工程，而非工程的特性，正如 Stephen Merrity 描述的那样：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;深度学习的浪漫主义描述通常预示着手工制作工程特性的日子一去不复返了，这个模型的本身是足以先进到能够解决问题的。正如大多数广告一样，它同时具备真实性和误导性。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;虽然深度学习在很多情况下简化了工程特性，但它肯定还没有彻底地摆脱它。随着工程特性的减少，机器学习模型本身的结构变得越来越复杂。大多数时候，这些模型架构会特定于一个给定的任务，就像过去的工程特性那样。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;需要澄清一下的是，这仍然是很重要的一步。结构工程要比工程特性更具一般性，并且提供了许多新的机会。正如我们提到的，我们不能无视这样一个事实：我们离我们想要达到的还很远。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;LSTM 图解&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;怎样解释这些架构？自然地，我们可以通过图解，图解往往可以让阐述变得更清晰。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;让我们先来看看如今最流行的两种网络，CNN 和 LSTM：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW98I8H8hN4aJlSo9VbVJdVk5IrVwA2tz4iadefHcoGBkHqrenjs2hkBfhUBI5112ezrAucxywwwLnA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;很简单吧，我们再更仔细地研究下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW98I8H8hN4aJlSo9VbVJdVkHPUMgoeSApaOcNXrRMleDXdgb02X3yDjbnicMaSL0NY3yZYQaGGwUyw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;正如大家所言，你可能有很多不理解的数学问题，但你会慢慢习惯它们。幸运地是，我们有很多非常好的解释。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;仍觉得 LSTM 太复杂了？那让我们来试试简单的版本，GRU (Gated Recurrent Unit)，相当琐碎。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW98I8H8hN4aJlSo9VbVJdVkhSIdibcp93sW23lz35WIbeSIQgV7zgCj1iaicqRicwX4mricNE9scIqaOoQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尤其是这一个，被称为 minimal GRU：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW98I8H8hN4aJlSo9VbVJdVkc3N0EClfXeZ2nrXGHoPLks312eoclDOkeRuCVRMJkAjcy7V4ucpTlw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;更多图解&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;LSTM 个多各样的变体如今很常见。下面就是一个，我们称之为深度双向 LSTM：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW98I8H8hN4aJlSo9VbVJdVkxqqiaom9sZ5FNCMhrR7f8ib4rPS8J86ialY93yicbwjUbuzicdiaOA1KRs4Q/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;DB-LSTM（参见论文：End-to-end Learning of Semantic Role Labeling Using Recurrent Neural Networks ）&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW98I8H8hN4aJlSo9VbVJdVkCF36ricibt2fXK5WdYwXckCiaztKRGKXFE4Ezgx8YICJPG1AEnPTfVXPQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;剩下的也不需要加以过多说明。让我们从 CNN 和 LSTM 的结合开始说起：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW98I8H8hN4aJlSo9VbVJdVkn8VLCxrXKY4yCkSLicia7aPWGj3ibbVWOcb1s8mVIyQ4QXNURfo1xyxZA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;卷积残差记忆网络（参见论文：Convolutional Residual Memory Networks）&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW98I8H8hN4aJlSo9VbVJdVkYmTqApYMLLDdfLhTp2v59ibjGDGtPEXZzyVL5yxuSZ80VbJa6oiaW86w/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;动态 NTM（参见论文：Dynamic Neural Turing Machine with Soft and Hard Addressing Schemes）&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW98I8H8hN4aJlSo9VbVJdVk08GsE8h6Zla4Azb2ycgSYgctvL4MaDmZob3MhlgHF7FVibvOXM8WI2w/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;可发展神经图灵机（参见论文：Evolving Neural Turing Machines for Reward-based Learning）&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW98I8H8hN4aJlSo9VbVJdVk81HK99GYzhBExwb4pXKHyuall9XtBpqDCTVmBpw8yt2lOLcX3YjpvA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;视觉注意的循环模型（参见论文：Recurrent Models of Visual Attention）&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW98I8H8hN4aJlSo9VbVJdVkDDsDb88icXTrkocwaPCnwxRkQjwQk8puiceyS6KmdFklCTH7dw2RZzsQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;通过反向传播无监督域适应（参见论文：Unsupervised Domain Adaptation by Backpropagation）&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW98I8H8hN4aJlSo9VbVJdVkSPIScElIRv0DcQfSicdVgkCw5jetdNl49sWBrLSJlG9RXUhBRS3KL9g/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;进行图像超分辨率的深度递归 CNN（参见论文：Deeply-Recursive Convolutional Network for Image Super-Resolution）&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;带有合成梯度的多层感知器的图解在清晰度上得分很高：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW98I8H8hN4aJlSo9VbVJdVkgic0ibrCQZGcbCS9y9zjlUAj2Kyz25aXgRyTfflLiadO4XL2JZxbnibk6w/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;带有合成梯度的 MLP（参见论文：Decoupled Neural Interfaces using Synthetic Gradients）&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;每天都有新的成果出现，下面这个就是新鲜的，来自&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719470&amp;amp;idx=1&amp;amp;sn=3368dea980517ea7d7942967da2740dc&amp;amp;chksm=871b0090b06c89863620be4e75c757940d03d8a43cd3c1d9a8309b6594c1bccd769cab193177&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719470&amp;amp;idx=1&amp;amp;sn=3368dea980517ea7d7942967da2740dc&amp;amp;chksm=871b0090b06c89863620be4e75c757940d03d8a43cd3c1d9a8309b6594c1bccd769cab193177&amp;amp;scene=21#wechat_redirect"&gt;谷歌的神经机器翻译系统&lt;/a&gt;：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW98I8H8hN4aJlSo9VbVJdVkcOFxiaia3pYoP9SBcNaCibcKjIV7cvny2nibmcFUVJJu4fgd7koibZxlYng/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;一些完全不同的东西&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719170&amp;amp;idx=1&amp;amp;sn=68b6b7f87677f5287b6e5a306409653b&amp;amp;chksm=871b07bcb06c8eaa0a649d7d3fd7963423dd4ea51b6e7711bc63653a528fbf196566345ae064&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719170&amp;amp;idx=1&amp;amp;sn=68b6b7f87677f5287b6e5a306409653b&amp;amp;chksm=871b07bcb06c8eaa0a649d7d3fd7963423dd4ea51b6e7711bc63653a528fbf196566345ae064&amp;amp;scene=21#wechat_redirect"&gt;Neural Network ZOO&lt;/a&gt;（一篇描述神经网络架构的文章，机器之心同样进行了编译）&lt;/span&gt;&lt;span&gt; 的描绘非常简单，但很多都华而不实，例如：ESM, ESN 和 ELM。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW98I8H8hN4aJlSo9VbVJdVkMliayexKcHej85O4ylvacoBc52VeDoEXftbicjiblQMsZgRLuaTaeU7ag/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;它们看上去像没有完全连接的感知器，它们看上去像没有完全连接的感知器，但它们应该代表的是一种液体状态机、一个回声状态网络和一个极端学习机。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;LSM 和 ESN 有何不同？很简单，LSM 有着三角状绿色的神经元。而 ESN 和 ELM 又有什么不同呢？它们都有蓝色的神经元。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;讲真，虽然类似，,ESN 是一个递归网络而 ELM 则不是。而这种区别也可在架构图中见到。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Sun, 02 Oct 2016 13:54:55 +0800</pubDate>
    </item>
    <item>
      <title>Synced Talk | 从MIT-CHIEF 到YC : Robby无人车的最后一公里</title>
      <link>http://www.iwgc.cn/link/2923336</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心原创&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;采访：Rita Chen , Chain Zhang&lt;br/&gt;编辑：Mandy , Rita Chen&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;麻省理工中国创新与创业论坛（MIT-CHIEF）自 2011 年创办以来，已经走过了 6 个年头，其中的「PITCH TO CHINA」商业计划书大赛是全美高校中面向中国的最早的创业比赛之一。截止目前为止，已有来自包括中美在内的 30 多个国家和地区的 800 多个创业团队踊跃入驻 MIT-CHIEF 创业社区。6 年来，MIT-CHIEF 专注于搭建中美创新与创业的平台，以及服务早期创业团队，从 MIT-CHIEF 走出的团队已获得总额超过 10 亿元的资金支持，20 余支团队走进了如 Y Combinator，MassChallenge，Plug and Play，500 Startup 等国际知名孵化器。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这些团队中，有建立全球首个癌症病理学数据库的 HistoWiz, 有用大数据改变停车行业的 Smarking, 还有让不懂程序的人轻松 DIY 完美网址的 Strikingly. 近日，机器之心 有幸采访到了众多成功从 MIT-CHIEF 走入 YC 的团队中的一支, 专注于开发小型快递无人车的 Robby 团队。恰好，团队的联合创始人和 CEO 李瑞也是 MIT-CHIEF 的发起创办人和前主席。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW98I8H8hN4aJlSo9VbVJdVk3WVdRq7HvQbict9yqj8PpBdfEOl5O9nic6SGDuFlzqrja0iaE0uyTicaPA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Robby 是一家机器人科技公司，专注于小型快递无人车的开发，大幅度降低最后一公里的送货成本问题。创始团队包括从 MIT 获得博士学位的李瑞（CEO），和在 MIT 获得本硕博学位的 Dheera Venkatraman（CTO），还有两位全职员工及一位实习生。谈到无人车，我脑海里首先浮现的便是美国硅谷街上 Google 无人车来来往往的场景。机器之心也报道和采访过一些专门研发无人驾驶技术的团队和公司，而当李瑞具体向我们介绍 Robby 团队建立的初衷和产品应用时，我却不禁好奇起来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;民以食为天：小型送餐无人车的第一步&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;李瑞：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;在美国，送餐或果蔬配送费用往往占食物本身费用相当大的比例，少则 30-40%，多则 70-80%。虽然很多人都有这个需求，但是又觉得太贵了所以就不愿意叫外卖，尤其对于学生而言。我们在波士顿地区曾做过一个调查，现在每周叫外卖的人有 30%，但是如果成本降低 1 到 2 美金的话，订单量会从 30% 增长至 77%，这是一个非常大的上升空间。而降低费用的重要方法就是去除快递的人力成本，无人车是很自然的一个解决方案。因为我一直从事计算机视觉和机器人的研究，Dheera 则从事激光雷达的研究，而这些是无人车最核心的技术，如果将小型无人车技术用在最后一公里的快递，市场空间将非常巨大，必将改变整个快递行业。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Synced: 那这个想法初始最直观的会有哪些技术问题需要攻克？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;李瑞：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;从技术上来讲，无人车最需要解决的难题主要有三个方面：定位、导航和避障。我们的小车会行驶在人行道上，定位需要非常精准，至少要在厘米级别。传统的低成本 GPS 精度是几米的范围，远远不能达到要求，这就需要借助其他类型的传感器和感知技术，如计算机视觉或者激光雷达等，这恰恰是我们在 MIT 的博士研究领域。知道自己的精确位置后，无人车需要进行路径规划抵达终点，在这个过程中需要识别和应对各种障碍物，并进行有效的避障。这部分主要用到的是机器学习，比如最近几年火的发紫的深度学习。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当然，在采访的过程中，李瑞也谈及了很多现实的问题，就拿看似最基本的拿放物件来举例。拿放物件对于人类来说是一个极其自然的动作，但是对于机器却不简单。李瑞博士表示，尽管并不是所有谈到的技术都会用到 Robby 机器人的开发中，但是他愿意结合自身的一些研究经历 和我们分享一下这其中的技术难点。Sensor 是机器人接触和获取外界信息的重要手段，如何达到高品质的触觉传感器和如果让传感器很好地将视觉与行为相结合都是开发中需要考虑的问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW98I8H8hN4aJlSo9VbVJdVkl4wvX7uSMboAmjEUibVG4jl7XZDUMmKI0fsKzO7vObJlqFcmCYcapTA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;李瑞：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我在博士期间的研究方向是 Fingertip GelSight Sensor，是通过摄像头将触觉信息转化为图像信息并进行智能处理的一个传感器，所以本质上做的是计算机视觉和机器学习在机器人领域的应用。人类的手是软的，触觉可以帮助了解外界，但机器不是。我们就想着把机器人的手指传感器也做成软胶，碰触后的变形会被摄像头捕捉到。我们通过计算机视觉和机器学习的算法来得到胶层的变形程度 (比如物体表面的三维纹理）, 从而计算出力度的大小，这个对机器人是使用多大的力度来拿东西有很多帮助。我们的分辨率比市面上已有的触觉传感器要高成百上千倍，可以达到几微米到几十微米的精度，比如如果感触头发，可以分辨出哪个头发在上面哪个在下面。除了力度以外，第二个通过物体表面的 3D 纹理信息，通过机器学习可以得到材质的信息。我们有一篇论文是关于通过触觉传感器分辨不同的材料（参加Sensing and Recognizing Surface Textures Using a GelSight Sensor）。第三点是对细节信息的处理。通过传感器我们可以得到侧向力的信息，这样我们可以通过物体是否滑动，了解到现在使用的力度是否合适。要知道，不同大小不同重量不同硬度的物体，受到的摩擦力影响也是不一样的。现在很多的机器人可以运送大型货物，但是单靠机器人手指去拿叶子确是非常难的，而我做的触觉传感器可以很容易的自适应拿不同的物体，包括重物以及很轻很柔软的叶子。我们也是希望可以通过 自己的一套传感器设备，一套算法能适应各种情况的需要。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW98I8H8hN4aJlSo9VbVJdVkWC0HfqTh1j8sUlAcg4ILpJdWIFj0QJ7RxDPHSjUKZTqbPL5SxzlQfQ/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;李瑞表示，基于现有资源和技术，我们的小型无人车会先在校园和 Palo Alto 地区进行试点，然后逐步在美国推广。「因为美国大部分的住宿都是比较宽敞的公寓独栋，直接送餐到楼下门外即可。当然，就仅仅是我们的第一步。」李瑞说道。据了解，Robby 已经在斯坦福校园成功配送了 50 份午餐和奶茶，并已经开始了与相关公司的试点计划，其中包括做副食品快递平台的独角兽公司 Instacart。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;从配餐到包裹配送，让 Robby 成为 24 小时的快递小哥&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;无论是配餐还是快递，都是一个行业化的过程，从上游的配货到分发、运输，直至最后到达顾客的手里，这中间有太多的细节需要考虑。对于无人驾驶而言，目前主要的技术是激光雷达和计算机视觉。他们确保无人车具备人眼一样识别外界环境的功能，并做出快速分析与判断，从而控制车体运动。借助这次采访的机会，机器之心也和李瑞一起探讨了在配送行业内无人车和无人机的发展大趋势。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Synced:虽然无人驾驶的技术愈趋成熟，但这一两年也出现了好几例无人车交通事故。针对 Robby 的产品研发，你是否有安全方面的一些技术措施？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;李瑞：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;首先就概念而言，无人车（Self-driving Car）和无人机器人（Self-driving Robot）是很不一样的，面临的问题也很不一样。无人车如果要上路，安全级别和自动化程度必须达到 99.99999...%，因为一旦出问题，很可能是致命的。Self-driving robot 虽说也需要保证安全，但不需要达到那么高的自动化程度。对于机器人来说，如果遇到问题可以随时停在人行道上，等待远程的协助和指示。但无人车几乎无法做到这一点，因为它不能停在高速行驶的马路中间，由于网络延迟，远程控制也几乎不可能。在安全性能方面，Google self-driving car 其实很多年前就达到了 99%，但是这最后 1% 所需的资源和投入确是之前 99% 的千万倍。Google 最后的这几年一直都是在完善最后的 0.1%，甚至 0.000001%。就这一点而言，无人机器人实现安全上路会容易很多，可能明后年就可以看到很多机器人在街上送外卖了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Synced: 确实，感觉配送是一个相对分离的过程，只要按时到达，中间的过程顾客不会那么在意，推广起来也相对容易。说到无人机器人就让我想到无人机，像 Amazon (Amazon PrimAir), DHL(Parcelcopter 3.0), Google ( Project Wing) 都在 Drone-delivery 领域有很多的突破. 同样是做快递，你认为无人飞行器和无人陆行机，这两个大方向有哪些相同和不同？他们各自的优势及劣势又在哪里？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;李瑞：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;当时 Amazon 推出视频引爆了无人机快递的话题，但那只是一个概念视频，无人机还没有达到视频中展现的程度。我认为这其中有几个原因：第一，无人机的续航能力很短，像大疆等小型无人机一般的续航能力就是二十分钟，很少的达到一个小时。这些还是针对普通拍照的无人机；而送包裹的无人机考虑到包裹的重量和体积，自身的体积也会更大一些，那么对功耗的需求会变得更高；第二，安全性，现在全世界有很多无人机掉下来的事故。试想一下，从那么高的地方掉下来它就是一个小炸弹。如果在城市中送快递，要是掉在马路中间就会引发交通事故，如果掉在人身上就更严重了。这些都是运输过程中无法预测的。所以，反过来想，如果不是城市而是送东西到城郊，也许比较可行，路上障碍物比较少，飞行速度快，线路难度相对较低。第三就是着陆点的问题。在城市里如何确定无人机的着陆点，这对技术是一个很大的挑战。最后一点是法律法规的限制。目前在美国还没有法律法规批准。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW98I8H8hN4aJlSo9VbVJdVk6BOSx7FazuV3GliaVoHWj8XrTplJIpUF2ia8Wygz66TOfoia75P0XeGng/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Synced：我看到今年六月美国六月份公布了最新的小型无人机商业使用的管理条例（SMALL UNMANNED AIRCRAFT RULE by FFA), 里面出现了很多新的限制条件。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;李瑞：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;对，那个里面有些要求和规定。比如，无人机必须在可视范围之内。这意味着什么呢？你遥控无人机或用于拍摄是可以的，但超出视野的无人快递至少目前是不行的。当然我们希望有一天它可以有所改变，至少给大家多一些选择，但时间上很可能不是近期的事，可能需要三年五年到更长。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Synced : 好的，那么，结合你刚才自己谈到的四点，续航能力，安全性，法律法规这些，能不能和我们回头说说无人车或无人机器人在这方面的现状呢？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;李瑞：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;好的。首先是续航能力。机器人的续航能力取决于电池的容量和本身的重量等，笼统的来讲，陆地机器人要续航长的话加电池就可以了，要做到全天都没问题。但在空中增重的话会妨碍飞行。负重取决于设计。Robby 机器人目前可以承载一个成年人的重量，但一般运送快递也不会太重，大部分情况下不会超过一个人的重量。关于法规这方面，目前我知道的是在华盛顿 DC，只要满足特定条件，无人机器人就可以在人行道上行驶。例如，它们规定机器人重量不可以超过 50 磅，奔跑速度不可以超过 16 公里每小时（大概是人类行走速度的 3-4 倍）。华盛顿 DC 已经推出了这样的法规，我认为其他城市应该会很快跟上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Synced：中国快递业务现在非常火爆，像顺丰，圆通，申通等等有很多。Robby 目前是打算在美国做包裹配送，你觉得这样的配送在中国能实现吗？你如何看待中国的快递市场？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;李瑞：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;无人快递是个趋势。别管用什么样的工具，无人机，无人车亦或是无人机器人，它都是经济成本驱动的。在美国每年大概有 120 亿件包括食品和物资在内的快递单，这个需求和市场在中国肯定比美国大得多。「最后一公里」这个概念对快递公司来说是相通的。其实国内有些公司也在探索这个领域，比如京东和阿里。今年九月，我看到新闻报道，京东和阿里正在开发最后一公里的快递机器人。这对于我们来说是非常好的契机。我们算过一笔账，只要机器人做好之后，它主要是电力成本（非常低）。人送快递还需要耗油，机器人在最后一公里比车的成本低很多。我们不是简单地取代快递员的工作，而是人与机器人形成互补和互相协作，发挥各自所长。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW98I8H8hN4aJlSo9VbVJdVk2g4QYGiaxEnZ1xibtNf92znJLXPibMGfzbwmaWUmH7n2kE5DBk7HLrYXw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;从 MIT-CHIEF 到 YC：五年来我们一直在做自己相信的事&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;每次采访 MIT-CHIEF 社区走出来的优秀团队，我们总会谈及他们和 MIT-CHIEF 相识的契机和创业背后的故事。这次我们面对李瑞，他不仅是 Robby 的 CEO，还是 MIT-CHIEF 的创始人。同样的，Robby 团队的联合创始人及 CTO Dr. Dheera Venkatraman 也是 MIT-CHIEF 最早的核心成员之一。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Synced：当时创建 MIT-CHIEF 是什么契机？现在 MIT-CHIEF 的发展和当初自己设立的初衷有没有不同？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;李瑞：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;在 2011 年之前，中国和 MIT 有一些交流和合作，但都相对比较零碎，没有一个统一的平台。2011 年 3 月 5 日，在一个留学海归的讲座后我和 7 个 MIT 的朋友一起吃饭，聊到想为中国做一些事情。我当时的想法是做一个论坛，让其成为中国和美国在创新和创业方面的桥梁和平台，得到了大家的一致认同。我们考虑到 MIT 的一个优势是在科技和创新创业方面，初期我们主要集中在主题演讲、板块讨论和创业大赛这三个方面，这也是 MIT-CHIEF 的这个名字的由来，MIT-China Innovation and Entrepreneurship Forum。想到当年办第一届大会的时候遇到了很多的困难，如何去找项目、请嘉宾、拉赞助等等，MIT Sloan 的黄亚生教授和 MIT 人工智能实验室（CSAIL）的前负责人 Victor Zue 当时给我们了很大的帮助，他帮我们和几大学院的院长取得了联系。校外方面，2011 年 4 月份的时候，徐小平对我们的这个想法很感兴趣，给了我们第一笔校外赞助，并答应做我们的嘉宾。之后事情就慢慢有了起色，8 月 19 日是另一个转机，当时微软研究院的院长张亚勤确定来做演讲，同时给了我们一笔不小的赞助。他确定了之后，陆续我们就确定了更多的嘉宾和赞助。现在想想，MIT-CHIEF 的第一届阵容在当时看其实是非常豪华的，包括真格基金的徐小平、万科的王石、微软的张亚勤（现百度总裁）、IBM 中国区的负责人 Thomas Lee、IDG 的李骁军以及 MIT 的陈刚教授（MIT 机械系第一位华人系主任）等等。后面几届又陆陆续续有了更多的有影响力的企业家、学者、创业者等等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Synced : Dheera, 我听说你也是 MIT-CHIEF 当年成立的核心成员之一。你能不能和我们讲讲你的故事呢？你当时对于 MIT-CHIEF 的预期是怎样的？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Dheera：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我当时担任的是第一二届的技术主席和组织层成员。我认为，每年的挑战都不太一样。在第一年，还没有任何经验和证据的时候，当时最大的挑战就是把平台搭建起来，如何吸引参与者和邀请到嘉宾。第二年最大的挑战可能在于如何扩大活动并且保持质量。第一年的时候几乎就是一群靠谱的朋友在一起做靠谱的事情，这种情况下靠得是朋友之间的凝聚力。但第二年，团队逐渐扩大以后，如何在一个壮大的非盈利组织保持每个人之间的平衡，调动大家的热情这是我们经常思考的问题。相信许多在第二届团队中历练的成员们也培养了一些领导能力，这些之后都是各自创业很好的经验。另外，我想聊一下 MIT 的价值观，这也是我在提倡和推广活动的过程中感切到的。MIT 的价值观，不仅是科技发展层面的，还有很多学校文化上的细节，包括环保，鼓励原创和发明，还有信任社会，这些都是我认为非常好的价值观。我当时一直在寻找各种各样的方法在 MIT-CHIEF 的内核中传递 MIT 的这些精神。在大会的准备过程中，我们做了不少调整专门为了减少垃圾，在拍摄宣传片的时候我们集思广益用了不少创意的方法，包括很早就用到了气球和无人机来拍摄素材等等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Synced :MIT-CHIEF 自你们创办以来一直不断成长，活动和大赛的开展也越来越专业和国际化。前不久，MIT-CHIEF 的中国行活动也刚刚结束。现在 MIT-CHIEF 的发展符合你当时的创办预期吗？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;李瑞：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;这个问题非常好。从 MIT-CHIEF 的创办初衷是做中美科技创新的桥梁，不管是分会还是创业大赛都是围绕核心来的。总体来说，这些活动都是我们之前活动的延伸和升级。CHIEF 现在的很多活动影响力越来越大，很多参与过的团队都表示很有收获和很自豪。对于未来的五年十年甚至五十年，我希望 MIT-CHIEF 能够不忘初心，把使命更好地履行，在影响别人的同时影响自己。尽管我现在不参与 CHIEF 的具体活动，但我毕竟做了两年的主席，对 CHIEF 的感情非常深厚。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Dheera：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;当时主要希望 MIT-CHIEF 可以成为一个新的渠道，和 MIT 在世界上的影响力一样，也能通过自己的方式影响到国内和世界，同时让西方文化中的人更加了解亚洲文化和发展状况。当时我肯定没法想象五年后的 MIT-CHIEF 会发展到今天的情景，我希望现在的这样一批人能一直努力，继续带动这个梦想。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Synced：今年你们加入了 YC 大家族，可否与大家分享一下在 YC 的亲身经历和体验？YC 给予 Robby 最大的帮助是什么？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;李瑞：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;YC 是美国最早的创业加速器，之前一直有所耳闻。我们今年申请进 YC 之后得到很多帮助：首先是 Mentorship，YC 的合伙人是一些有丰富创业或投资经验的人，比如大名鼎鼎的 Justin Kan 是 Justin.tv 的创始人，Paul Buchheit 是 Gmail 的缔造者以及著名的创业者和投资人。第二是 YC 的 Network，包括我们听过的很多著名公司的讲座和分享，比如 Dropbox，Airbnb，Cruise Automation，DoorDash，Instacart 等等，这些公司都是从 YC 走出来的独角兽公司，我们可以随时通过内部邮件联系到他们。需要一些方面的合作或者资源的时候，YC 公司通常会非常乐意互相帮助。第三个是 Demo day。他们邀请了湾区及其周边具有影响力的投资人和媒体来 Demo day，对大家的融资和宣传都很有帮助。在这三个方面，YC 做得都非常好。那么，我们学到了什么？这可以总结为四个单词：Make something people want。这四个单词包涵了很多含义。首先，你做的事情是有人需要的, 你有正确的团队和正确的目标市场。具体到 Robby，我们偏技术，YC 教会我们一定要把产品放到真实的世界去做反馈，快速迭代，这也就是为什么短短的时间内我们可以把产品做到雏形就拿到斯坦福校园做测试。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW98I8H8hN4aJlSo9VbVJdVksrcwfcWLuHkNvaocia1rG8EgbLYM6gQBpH4F8IHAdOKGUeRfZbNsO9w/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Robby 团队联合创始人及 CEO 李瑞博士（图左），联合创始人及 CTO Dr.Dheera Venkatraman（图右）&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;Synced Talk 快问快答&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在采访的最后，我们按照 Synced Talk 的传统和两位嘉宾进行了快问快答。每一期我们都有固定的主题，这一期我们的主题是可穿戴与智能医疗。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Synced: 你们认为既智能手表之后，什么会成为下一代可穿戴成品的主要载体？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;李瑞：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我认为是 AR（增强现实）的设备。如果把 AR 眼镜做得和普通眼镜一样轻薄时，它的应用潜力将会非常大。同时它也可以作为一个计算平台，你不用带手机，它可以将所有的信息呈现出来。那时候你可以完成手机上的所有基本功能，同时能实现一些现在的设备实现不了的功能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Dheera：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;Google 推出安卓手表的时候，我当时参与了不少应用的开发，包括一个维基百科的手表客户端，一个自拍助手。但两年后的今天，安卓手表也没有达到普及的程度。为什么呢？我个人认为可穿戴设计跟桌面电脑有很大差别，因为是戴在身上，它会影响你出门的外表，所以像时尚艺术款式这些因素显得尤为重要。虽然现在 VR 和 AR 在技术圈子里很火，但是我个人认为跟手表一样可能需要一款方便，好看好用的硬件才能普及化。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Synced :第二个问题，作为了一个消费者或者是用户，每个设备都会给你检测一个数据，你是否信赖这些数据？你觉得这些数据会怎样被使用？你会担心数据透露你的隐私吗？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;李瑞：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我觉得这些数据的使用时取决于公司的。相信像苹果、Google 等公司会尽量遵循行业规范，可能以大数据的形式，把个人的具体信息隐掉，分析的过程中看不到每个用户个人的信息，但是可以通过整体的分析来对一群人的行为进行预测，来更好的服务大家。比如 Google 可以借此将搜索做的更准更个性化。如果是基于这一点的考虑，我觉得是没问题的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Dheera：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;是的，其实连手机都让我很担心。因为前几年大多数通讯协议和软件相对封闭，总不知道哪些公司在采集哪些数据。我希望将来可以更加开放和透明一些，这对于开发者本身也会比较好。同时就个人而言，我希望不要对新技术产生太大的依赖，比如我小时候生活在一个没有手机的时代，当时其实很多事情也比较简单，出门很自由，没有人知道我在哪，没人打扰我去玩，没有人打扰我工作，也没有人采集我的数据。所以现在我偶尔会坚持不带手机出门，训练我的方向感，在没有人打扰我的情况下好好思考该思考的事情。我希望 VR/AR 技术在方面我们未来生活的同时，最好不增加我们对其的依赖，希望用不用任何技术，下载和使用哪些服务，永远可以是一个用户的选择。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Synced :感谢两位的回答，也很感谢你们抽时间参加机器之心的采访。关于无人车和无人机器人，我相信还有很多细节技术可以谈。等到 Robby 机器人成功面试的那天，希望还有机会和两位聊聊从无人送餐到无人快递之间的迈进。感谢！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;——————————————————————&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;关注麻省理工中国创新与创业论坛（MIT-CHIEF）微信公众号了解更多美国科技创业圈资讯：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW98I8H8hN4aJlSo9VbVJdVk66IHYg41vG3SO1icynw3FWg1DDnwOZAeQJSuichxJickPBso7CCLLneYA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;MIT-CHIEF “PITCH TO CHINA”商业计划书大赛继续招募中! 报名截止10月7号晚11点59分，向MIT-CHIEF提交全英文的Pitch Deck 的同时附注「机器之心通道」信息。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;入围团队将在11月12号MIT-CHIEF年度会议上进行决赛，最高可获得3万美金奖金。关于创业大赛任何问题请邮件：contest@mitchief.org&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Sun, 02 Oct 2016 13:54:55 +0800</pubDate>
    </item>
    <item>
      <title>深度 | TensorFlow工程设计主任Rajat Monga问答：计算能力是深度学习发展的主要瓶颈</title>
      <link>http://www.iwgc.cn/link/2923337</link>
      <description>&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Quora&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：Rick、刘婷娜、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Rajat Monga 是谷歌 TensorFlow 的工程设计主任，同时也是一位深度学习技术研究者。近日，他在 Quora 上进行了一场专题问答，谈及了深度学习的瓶颈和 TensorFlow 社区的发展情况。下面是机器之心对 Rajat Monga 的问答内容的编译整理。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;1. 使深度学习更有效的主要瓶颈是什么（在 2016 年）？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;由于三个事物的共同进展，深度学习似乎在最近几年取得了成功：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;算法：这一领域已经有了一些改进，但早期的大多数成就来自于相当老旧的思想。现在深度学习也有所成就，我们正看到的一些良好进展。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;数据集：没有足够大的数据集很难训练大的网络。MNIST 只是向前推进了这一限制。类似 &lt;/span&gt;&lt;span&gt;ImageNet 的数据集确实有助于推动视觉方面的最先进的技术发展。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;计算：我相信这是近年来作用最大的一个方面。以我的专业背景来看我是有些偏见的，但计算在一些深度学习所取得的早期成就中发挥了一个很大的作用。Google Brain 2011 年的关于猫的论文和 Krizhevsky 等人在 2012 年在 ImageNet 上取得的成果将深度学习带到了计算机视觉领域的最前沿。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;也就是说要想使深度学习变得更有效，所有这些都还有很长的路要走。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;计算：即使我们已经有了定制化芯片，但我们依然还要面对持续需求更多的挑战。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;数据集：由于目前的算法在很大程度上是监督型的，因而还需要更大的数据集来继续推动新研究的进展。我们正在谷歌中积极致力于数据集的改进，并且最近已经发布了一个视频数据集（参考阅读《&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719494&amp;amp;idx=1&amp;amp;sn=5c796cf9da81e6532750cea04667467c&amp;amp;chksm=871b0178b06c886e12aa5bc32a1cd9d585d4a2d624aab1c660e63ea619fd4c3aa8430ae8da0c&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719494&amp;amp;idx=1&amp;amp;sn=5c796cf9da81e6532750cea04667467c&amp;amp;chksm=871b0178b06c886e12aa5bc32a1cd9d585d4a2d624aab1c660e63ea619fd4c3aa8430ae8da0c&amp;amp;scene=21#wechat_redirect"&gt;谷歌发布 YouTube-8M：单个 GPU 一天就能完成训练的最大视频数据集&lt;/a&gt;》）和两个用于机器人的数据集（参考阅读《&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718527&amp;amp;idx=3&amp;amp;sn=bbb26fade567fe63ba7cd1131fb66e05&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718527&amp;amp;idx=3&amp;amp;sn=bbb26fade567fe63ba7cd1131fb66e05&amp;amp;scene=21#wechat_redirect"&gt;谷歌公开两个机器人研究数据集：Grasping + Push&lt;/a&gt;》）。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;算法：不要轻视算法部分，比如 ReLU、 Dropout、Sequence to Sequence 和 GANs 这些思想就带来了巨大变革。回到计算这一点，我们不可能由于传统的、纯硬件方面的提高就在计算上实现 1000 倍的提升。这需要的是算法与计算的协同设计，例如我们能够用 1000 倍的参数而仅用 10 倍的计算来创建一个模型吗？我认为建立稀疏模型来解决这个问题会是一个能带来重大成果的方法。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;2.Google Brain 的主要招聘渠道是什么？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Google Brain 是一个非常多样化的团队。我们的许多研究人员拥有机器学习背景，并且是该领域的著名专家，比如 Geoffrey Hinton、Samy Bengio 和 Quoc Le。然而，我们也有一些项目会从非机器学习专业领域聘请研究人员和工程师。此类项目的信息来自于目前一些比较特殊的团队成员。我们还有其他一些招聘方式——全职、访问学者、实习生和 Brain Residency 项目。我们在 2016 年启动了 Brain Residency 项目以培养和支持下一代深度学习研究者。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;3. 有什么还未建立的对深度学习来说有价值的工具？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;作为一个程序员，我将构建深度学习的模型看作是编程和实验。所有应用于那些领域的工具都与这点息息相关。用于深度学习的 TensorFlow 就像一门编程语言。该生态系统中其余部分的建立还有大量工作要做。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;例如更好的调试工具将有助于研究人员了解为什么他们的模型没有在学习，更好的实验管理将使他们能够更容易地运行和分析更多的实验。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;4. 深度学习在系统方面最需要的突破是什么？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;正如我在深度学习的瓶颈那个问题中所回答的，我们不可能由于传统的、纯硬件方面的提高而在计算中得到一个 1000 倍的提升，或者甚至是使用更好的软件和通信技术来集成更多的芯片。这需要的是算法和计算的协同设计，例如我们能够用 1000 倍的参数而仅用 10 倍的计算来创建一个模型吗？我认为可以解决问题的稀疏模型以及能够利用这些限制的系统能发挥很大的作用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;按照 GPU 和定制 ASIC 目前的发展状态，这不是大多数团队需要优先考虑的问题，但是由于这各方向的改进开始放慢了步伐，所以我希望看到这方面有更多研究出现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;5. 面对人工智能研究领域出现的无数挑战，Google Brain 团队主要致力于哪些问题？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们相信我们所研究的问题将有助于打造出那些能帮助人们的生活的智能机器这个使命。我们目前的一些研究领域包括机器学习算法、机器人、医疗和自然语言理解。有关我们的所有研究领域和文献发表的更多信息可以参看网站 https://g.co/brain。我们通过从这每一领域中挑出那些困难的挑战来追求对机器智能更广泛的理解。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;6. 深度学习在视频方面有哪些潜在应用？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;视频在许多方面都很有趣。虽然我们已经运用 ImageNet 的成果在人类的水平上取得了视觉方面的巨大进展，但距离真正的人类视觉还很遥远。部分原因是：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;我们在图像中获得的单张快照只提供有限的可用信息。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;缺乏大的标记数据集。ImageNet 虽然又一次提供了很多帮助，但要想放大到人类可识别到的所有不同类别则很困难。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;视频有可能解决这两个问题，并帮助机器获得人类的视觉。通过每个相关联视频中的帧序列，它提供了一个看待现实世界更为丰富的视角，允许模型创建一个 3D 的世界视图，而无需立体视觉。此外，所有帧的连续性也允许无监督学习算法不通过标签来提取有价值的图像信息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;应用方面，Google Photos 是一个很好展现更优视觉应用可能的例子。人类在其中花费很多时间执行例行任务的所有领域都是商业游戏的所在之处，例如驾驶（自动驾驶汽车）在今天很受欢迎，但也有许多简单的家庭任务比如整理衣物，由于它过于依赖我们的视觉因而目前还不能实现自动化。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;7. 由于昂贵的计算成本需求，我们如何让更多人获得研究深度学习的机会？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在一个大数据集上从零开始训练一个模型很昂贵。然而大多数人并不需要从头开始。我们目前有一些训练于大数据集之上先进模型，比如人们可以从我们的图片和文本解析开始，然后基于他们自己的数据做出调整。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Pete Warden 有一篇很棒的博文（《TensorFlow for Poets》）展示可以如何实现一个图像模型。我希望在更多领域看到这样的例子，因为我们正在使我们自己的 GitHub 模型库（https://github.com/tensorflow/models）中的模型公开可用，也欢迎我们的用户带来他们的贡献。）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;比如来自 Google Cloud ML 中那些处理繁重工作的 API 也将允许很多人使用深度学习方面的成果去打造更智能的应用程序，而不需要训练自己的模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;8.TensorFlow 从 DistBelief 带走的最有价值的东西是什么？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现今的深度学习框架有三个关键性要求，我将通过探讨我们如何从 DistBelief 进化到 TensorFlow 来切入这个问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;可扩展性: DistBelief 通过使用大量的 CPU 来进行拓展。例如，我们的关于猫的论文采用了 16000 个处理器内核。这在 2011 年是很了不起的，但是随着硬件的发展以及 GPU 和 TPU 的出现，我们的数据中心能够支持其他平台也是十分重要的。我们就如何扩展到其他机器这个问题研究了很多，例如我们在异步 SGD（Asynchronous SGD）的工作和最近的同步 SGD（Synchronous SGD）的工作，两者都始于 DistBelief，且时至今日依然可应用这些技术。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;灵活性: DistBelief 允许我们扩展，但它是在我们做系统的这部分人对深度学习足够了解之前建立的。对于那些急需在大数据集上进行训练的实际产品，以及在更大的数据集上进行的研究，DistBelief 的作用十分显著，但它却难以适用于新的想法。前端层也随着时间不断更新演变，我们能够把从这一过程中学到的东西，运用到对 TensorFlow 的新的设计中。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;便携性：在过去的几年里，在手机以及其它设备中部署深度学习模型已成为一种潮流。再次强调，DistBelief 最初并不是为此设计的，这最终导致我们的用户通过实现他们自己的库以支持这些深度学习模型。在 TensorFlow 的设计开发过程中，我们不断从我们的用户那里学习，实际上一些这些开发者加入了我们，使得 TensorFlow 可以运行在手机以及嵌入式平台，其中包括安卓、iOS、树莓派以及其他的很多平台上。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;9. 如果计算能力能够增加十倍，这将对现今的人工智能研究有何影响？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;正如我在前面的一个回答中所提到的：计算能力将继续作为人工智能进步的瓶颈。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一个实验如果仅需一天而非一周，或者一小时而非一天，那会让我们能完成多少实验、尝试多少新想法啊。这仍然还在研究阶段，许多新想法在获得成功以及推动领域发展之前，仍然需要尝试和提升。拥有更加强大的计算能力可以使得研究者们进行更多同一类型的实验，或者在相同时间内训练更大的模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有趣的注释：训练一个模型通常需要一周——这似乎是研究者为了好结果而愿意等待的时间的上限。我相信我们可以利用甚至是 1000 倍的计算能力的提升给人工智能的发展带来重大影响。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;刚从斯坦福大学毕业的 OpenAI 研究科学家 Andrej Karpathy 也对该问题进行了回答，这里也随带附上他的答案：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是一个有趣的思维训练。我喜欢思考阻碍进步的四个因素。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;计算（最明显的因素：摩尔定律，GPU，ASIC）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;数据（有良好的格式，而不仅是网上一些随便的数据——例如 ImageNet）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;算法（研究和想法，例如：反向传播 (，CNN，LSTM）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;基础设施（底层软件-Linux, TCP/IP, Git, ROS, PR2, AWS, AMT, TensorFlow, 等）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你会注意到计算只是这 4 项中的 1 项。所以我认为如果给我十倍的计算能力，不会有什么重大改变。当我以十倍的速度得到实验结果时，我的迭代周期一定会提升，所以也许我可以提高第三点（开发算法）的速度。我也将可以拓展许多现有实验（但这还不清楚，因为我们的许多模型是受存储限制的），所以一些现有的模型可能会因此给出一些稍好的结果。但我不认为会立即有激动人心的结果发生。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我认为第四点目前是一个较大且较慢的限制因素，这也就是我认为在 OpenAI 工作很激动人心的原因，在这里我们真的可以向其投入资源，以及建立许多专门服务于人工智能的基础设施。最后，第三点是最重要的——即使我拥有所有的计算资源，所有的数据以及梦想中的基础设备，我依旧不知道在上面跑些什么才能得到一个可以思考、说话、学习、探索的人工智能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;10.TensorFlow 多大程度上受到了 Theano 的启发？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们从先前 DistBelief 的经验中学到了很多，并将其应用于 TensorFlow。但在重新开始的时候，我们考察了所有现存的深度学习框架，并且我们很多团队成员是那些框架的开发者，包括 Theano、Torch 和 Caffe。其中我们的设计在很多方面与 Theano 最接近：比如，我们如何支持自动微分（auto differentiation）、如何运用符号表达式、以及在基础数学和线性代数的基础上铺设专门的神经网络层。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;它们都是十分优秀的框架，我们很幸运能够有机会从其中学习以及推动领域向前发展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;11. 如何将 TensorFlow 运用于计算机视觉？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我推荐 Pete Warden 的博客 TensorFlow for Poets（https://petewarden.com/2016/02/28/tensorflow-for-poets）作为开始计算机视觉模型开发最好的起点。对于 TensorFlow 新手来说，这是一个绝佳的起点，它能帮助你从安装 TensorFlow 开始直到为一个小的图像数据集制作视觉模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;12.TensorFlow 用户最大的痛点是什么，以及你认为可以如何解决它们?&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;TensorFlow 用户要求了两点，一是模型实现的集合，二是用以构建模型的更高级的库。我们正在这两点上取得巨大进步。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;模型：在我们的社区的帮助下，我们在 GitHub 上有一个愈发壮大的模型集合。此外，TensorFlow 用户和一些研究论文的作者也用 TensorFlow 实现了大量由研究论文提出的模型。这些在 GitHub 上简单搜索一下都能被找到。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;库：我们的 tf.learn 正取得长足进步且被广泛使用。此外，Keras 是另一个 TensorFlow 用户经常使用的很好的库。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;13. 非美国公民学生可以申请谷歌的 Brain Residency 项目吗？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;可以，我们的现有项目里有许多非美国公民，我们鼓励全世界的申请者申请该项目。详情请参见 Brain Residency 网站：https://research.google.com/teams/brain/residency/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Sun, 02 Oct 2016 13:54:55 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 历史回顾：深度学习如何让计算机看得见（附李飞飞TED演讲）</title>
      <link>http://www.iwgc.cn/link/2923338</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自TechCrunch&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Claire Bretton&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;21 世纪的一大挑战是如何让计算机更类似于人类大脑。我们想要计算机能说会道，能理解并解决问题，还希望它们能看见并识别图像。在很长的一段时间内，智能电脑都是「瞎的」，现在它们能看了。这一变革因为深度学习成为可能。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;iframe class="video_iframe" data-vidtype="1" style="   z-index:1; " height="375" width="500" frameborder="0" data-src="https://v.qq.com/iframe/preview.html?vid=v0333il31b6&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0" allowfullscreen=""&gt;&lt;/iframe&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器学习：第一步&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;理解机器学习很简单。思路是在大型数据集上训练算法，使它们能够从新数据中预测结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这有一个简单的例子：我们想要根据直径预测一棵树的年龄。数据集只包含 3 类数据：输入（x，树的直径），输出（y，树的年龄），特征（a，b：树的类型，位置......）这些数据通过一个线性函数联系在一起：y=ax+b。通过在该数据集上训练，机器学习算法将能够理解 x 与 y 之间的关联，并定义特征的准确值。一旦训练阶段完成，计算机将能够从任何新的直径（x）中预测树的年龄（y）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以上只是非常简单的描述，在图像识别上却更加复杂。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对计算机而言，一张图像是数百万像素，这对算法而言是大量需要处理的数据，有太多的输入。研究人员需要找到一个捷径。第一个解决方案是定义中间的特征。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;比如，你想要计算机识别一只猫。首先，人类需要定义猫的所有主要特征：圆头、两只尖耳朵、口鼻等。一旦定义了主要特征，一个良好训练的神经网络算法将以足够的准确率分析这些特征，并测定图像中是否是只猫。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW98I8H8hN4aJlSo9VbVJdVkA5F8PXicuYDNvXfgjzDyoHUAgRQskfPstOGdxP2BnyPgTeFXlkGU3BA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果要识别更复杂的东西又会怎样？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;比如，你会如何向计算机描述服饰？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW98I8H8hN4aJlSo9VbVJdVkJ10vZibRL6K5q33jpQdlCiahStzbxDLJsttgVxEz42eDFyps5xIjO0zg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你得到了基础机器学习进行图像识别的首个限制：我们总是难以定义有 100%识别潜力的识别特征。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;深度学习：在无人干预情况下能看见并学习&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 21 世纪初，斯坦福人工智能实验室和视觉实验室的主任李菲菲有过很好的直觉：儿童如何学习物体名称？他们怎么识别猫或衣服的？父母并未通过向他们展示特征而教会他们，而是在儿童看到后告诉他们物体/动物的名称。他们通过视觉样本训练儿童。那为什么不可以通过同样方式训练计算机呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然而，存在两个问题：数据集可用性和计算能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先，我们如何得到足够大的数据集「教计算机如何去看？」为了解决该问题，李飞飞和其团队在 2007 年发布 ImageNet 项目。与来自 180 个国家的超过 5 万人合作，于 2009 年创建了世界上最大的图像数据集：1500 万被命名和分类的图像，覆盖 22000 类别。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;好了，在没有人类干预的情况下，计算机能够在大型图像数据集上训练自我从而识别关键特征了。像个 3 岁儿童一样，计算机看到百万张被命名的图像，并自己理解每个条目的主要特征。这些复杂的特征提取算法使用深度神经网络，需要千百万的节点计算。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW98I8H8hN4aJlSo9VbVJdVkrmaPP6pYHIwXVVRbczHlOae7zLQXEENdBicGsficlHjIGLUnFceCaI9w/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这只是深度学习的开端：我们成功做到了让计算机像 3 岁儿童那样看东西。但就像李菲菲在 TED 演讲中说的那样，「正在的挑战还在前方：如何帮助计算机从 3 岁成长到 13 岁甚至更大？」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Sun, 02 Oct 2016 13:54:55 +0800</pubDate>
    </item>
    <item>
      <title>深度 | 雅虎开源首个色情图像检测深度学习解决方案</title>
      <link>http://www.iwgc.cn/link/2914329</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Yahoo!&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Jay Mahadeokar、Gerry Pesavento&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：Rick、李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;雅虎开源了一个进行色情图像检测的深度学习解决方案。据文章介绍，这可能是首个识别 NSFW 图像的开源模型。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;开源地址：https://github.com/yahoo/open_nsfw&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;自动识别一张对工作做来说并不适合/不保险的图像（Not Suitable/Safe For Work - NSFW）——包括暴力图像和成人图像——是研究者们几十年来一直在试图解决的重要问题。由于当下图像与用户生成的内容主宰了互联网，过滤 NSFW 图像成为网页应用和移动应用的一个重要组成部分。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;随着计算机视觉、改进的训练数据和深度学习算法的发展，计算机现在能够以更高的精度来自动分类 NSFW 图像内容。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;NSFW 素材的定义是主观的，而识别这些图像的任务并非没有价值。此外，在某一语境下使人反感的东西却可以适合于另一语境。为此，我们下文所描述的模型只侧重于一种 NSFW 内容：色情图像。NSFW 简笔图、漫画、文字、写实暴力图像或其他不当内容的识别解决方案不适用于此模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;据我们目前所知，还没有用以识别 NSFW 图像的开源模型或算法。秉承合作精神并怀揣推进这一努力的希望，我们发布了自己的深度学习模型，它能让开发者使用一个 NSFW 检测分类器来进行实验，同时向我们提供反馈以改善分类器的性能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们的通用 Caffe 深度神经网络模型（general purpose Caffe deep neural network model）以图像作为输入并输出一个概率（即一个介于 0 和 1 之间的数字），可用于检测和过滤 NSFW 图像。开发者可以针对具体使用情况来用这个概率过滤掉 ROC 曲线上低于某个适当阈值的图像，或用在搜索结果中进行图像排名。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicCYYBeS6htTRphzMKNPJbRZcreC3YkXs36WEOib25Oq1ZicFg9ubZqWLSA0ria45CPNrTm3oQ5wYMWg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;卷积神经网络架构和权衡&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;近年来，卷积神经网络已经在图像分类问题中取得了巨大成功。自 2012 年以来，新的卷积神经网络架构一直在不断改进标准 ImageNet 分类挑战的精度。一些主要突破包括了 AlexNet（2012）、GoogLeNet、VGG（2013）和残差网络（Residual Networks）（2015）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些网络在运行时间、内存需求和准确性方面有不同的权衡。运行时间和内存需求的主要指标是：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Flops 或连接——一个神经网络中的连接数量决定了向前传播过程之中的计算操作数量，这与图像识别时的网络运行时间成比例。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;参数——一个神经网络中的参数数量决定了加载网络所需的内存量。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;理想情况下，我们希望一个网络拥有最少的 flops 和最少的参数，而达到最大精度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;训练用于 NSFW 识别的深度网络&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们使用一个包含正（即 NSFW）图像和负（即 SFW-suitable/safe for work）图像的数据集来训练模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;由于数据属性的问题，我们没有发布训练图像或其他细节，但我们开源了可用于开发者独立进行分类的输出模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们使用 Caffe 深度学习库（Caffe deep learning library）和 CaffeOnSpark；后者是一个用于分布式学习的强大开源框架，令你可以在 Hadoop 和 Spark 模型训练集群中使用 Caffe 深度学习。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在训练过程中，图像被重新调整到 256x256 像素，水平翻转进行数据增强，并被随机裁剪为 224x224 像素，然后送入网络。在训练残差网络时，我们使用了 ResNet 论文中所描述的规模增大（scale augmentation）来避免过度拟合。我们评估各种架构来找到运行时间和精度之间的权衡。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;MS_CTC——这种架构是由微软限制时间成本的那篇论文提出。它在卷积层和全连接层相结合的速度和精度方面秒杀了 AlexNet。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Squeezenet——这种架构提出了 fire 模块——包含层挤压，然后扩大输入数据团。这有助于节省参数数量，使 Imagenet 的精度与 AlexNet 的一样好，尽管内存需求仅为 6MB。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;VGG——这种架构有 13 层卷积层和 3 层 FC 层。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;GoogLeNet——GoogLeNet 提出了 Inception 模块并拥有 20 个卷积层阶段。它还在中间层中使用 hanging loss functions 来解决深度网络中的梯度递减问题。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;ResNet——ResNet 使用快捷连接来解决梯度递减问题。我们使用了作者所发布的 50 层的残差网络。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;ResNet-thin——该模型是使用我们的 pynetbuilder 工具生成，并复制了残差网络论文中的 50 层网络（每层过滤器的半数）。你可以在这里（https://github.com/jay-mahadeokar/pynetbuilder/tree/master/models/imagenet）找到更多有关如何生成和训练模型的细节。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWicCYYBeS6htTRphzMKNPJbRIfekY6SgaWP3blrD8LauxnzYHulHyMZx20wFS4EjNZ1HwWdf7s5mKg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;不同架构之间的权衡：精度 vs（网络中的）flops 数量 vs（网络中的）参数数量。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;深度模型首次在 ImageNet 1000 类数据集上进行预训练。我们将每个网络的最后一层（FC1000）更换为 2 节点的全连接层。然后我们精调 NSFW 数据集中的权重。注意我们让与最后的 FC 层相乘的学习率是精调后的其他层的 5 倍。我们还调整了超参数（hyper parameters）（步长、基本学习率）以优化性能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们观察到，NSFW 分类任务的模型性能与 ImageNet 分类任务中的预训练模型性能有关，所以如果我们有一个更好的预训练模型，它将有助于精调分类任务。下面的图表显示了我们所提出的 NSFW 评估集合的相对性能。请注意，图中的假正率（FPR）和一个固定的假负率（FNR）所针对的是我们的评估数据，在这里作说明用。要用该模型进行 NSFW 过滤的话，我们建议你们使用自己的数据来绘制 ROC 曲线并挑选一个合适的阈值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWicCYYBeS6htTRphzMKNPJbRSH4GUZa09JUIVWHUT2HNSeIIoL3a4vgE2ER1v4xWmyGA7Sa0WqRYMQ/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;在 Imagenet 上的模型与在 NSFW 数据集上精调的模型的性能比较&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们发布了 thin ResNet 50 模型，因为它在准确度方面做了很好的折中，并且该模型在运行时间（CPU 上运行时间 &amp;lt; 0.5 秒）和内存（~ 23 MB）方面体量轻巧。请参阅我们的 Git 库来查看我们的模型指令和用法。我们鼓励开发者尝试将此模型用于 NSFW 过滤的情况。如有任何关于模型性能的问题或反馈，我们都会支持并尽快回复。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;结果可以通过在你的数据集上精调模型来改进。如果你改善了性能或者训练了一个使用不同架构的 NSFW 模型，我们都鼓励那么为模型贡献出力或将链接分享到我们的描述页面。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Sat, 01 Oct 2016 12:28:58 +0800</pubDate>
    </item>
    <item>
      <title>活动 | 这个十月，机器之心将带你开启北美人工智能之旅</title>
      <link>http://www.iwgc.cn/link/2914330</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;机器之心北美系列技术分享暨中国人工智能公司北美巡回招聘会&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;10 月 2 日-15 日，「机器之心北美系列技术分享暨中国人工智能公司北美巡回招聘会」即将开启，我们将和十余家优秀的人工智能公司走向北美多个城市和顶尖高校。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWicCYYBeS6htTRphzMKNPJbRv9XJRVia8tBJCoicUgbicnJicQDFqWmxibeoI9lFWCnfnmoMBFHEeITD8MA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这期间，我们也将会及时呈现最新的技术分享和现场报道。如果对我们的活动感兴趣，可以通过扫描如下二维码，我们的活动助手将协助大家进入相应的站点群。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWicCYYBeS6htTRphzMKNPJbRexVQHpibcx8d8ZpZqtCNzbibanmwNnGSlsZJfOCVfibpP0FZNEamx0FYQ/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本系列活动对北美地区的参与者免费，但因场地限制我们会控制参会人数，请提前报名预约。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;首站波士顿报名开启&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;波士顿站活动将于当地时间 10 月 2 日举行，报名已经开启，请添加上方的「机器之心小助手」进行报名。&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;strong&gt;波士顿站&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;演讲嘉宾：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;blockquote&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;KITT.AI 创始人姚旭晨；联合创始人陈果果&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;搜狗语音团队负责人兼首席科学家 陈伟（视频）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;图普科技创始人兼 CEO 李明强（视频）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;时间：&lt;/strong&gt;&lt;span&gt;EST：18:30-21:00，10月2日；北京时间：6:30-9:00，10月3日&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;地址：&lt;/strong&gt;&lt;span&gt;2 Amherst St, Cambridge, MA 02142&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;联合主办：&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;NECINA，MIT CSSA&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;多伦多站的活动嘉宾和报名也即将开始，机器之心将第一时间公布，敬请关注。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;若有其他人工智能公司对参与此次活动感兴趣，请联系 zhaoyunfeng@almosthuman.cn&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Sat, 01 Oct 2016 12:28:58 +0800</pubDate>
    </item>
    <item>
      <title>MXNet专栏 | 陈天奇：NNVM打造模块化深度学习系统</title>
      <link>http://www.iwgc.cn/link/2914331</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心专栏&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：陈天奇&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;本文是机器之心 MXNet 系列专栏的第一篇，作者是 MXNet 的打造者之一陈天奇。MXNet 专栏是机器之心之后将发表的系列文章，包括 MXNet 打造者的人物专访、技术博客等，敬请期待！&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是一个深度学习的大航海时代，不仅算法和应用日新月异，深度学习硬件发展势头也很迅猛。虽然目前主流硬件是 Nvidia GPU，但 Intel 也试图通过下一代 Xeon Phi 摇头赶上。而在用于汽车自动驾驶和智能硬件的低功耗深度学习硬件上，多家公司在同时发力。深度学习计算框架也是百花怒放，既有成名已久的 Torch 和 Caffe，也有一年前开源就名声大噪的 TensorFlow 和刚刚公开的 PaddlePaddle。我们 DMLC 小伙伴也在上面耕耘了好几年，从早期的 CXXNet, Minerva 和 Purine 到现在用户稳步增长的 MXNet，深刻的感受到了技术的变革。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们也一直在琢磨，我们需要什么样的技术和系统来更好的服务未来几年深度学习的发展。为了弄清这个问题，我们先来大胆预测下未来深度学习需要什么样的编程和计算环境。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然大家都说深度学习能火归功于数据量大和计算能力的提升，但我们觉得它能够在众多领域上快速铺开，更主要得益于它的灵活性。反过来看传统机器学习，每个算法都是针对特定的应用，例如 SVM 主要是对分类，输入一个定长向量得到一个类别标量。大家的发挥余地基本是在特征的抽取上。而深度学习则可以是更多样的输入和输入，例如任意维度的张量，甚至大小都是可以变化。同时模型设计上也很灵活，更宽？更深？空间还是时间？更加精巧的内部连接？从这一点上，深度学习其实是一种语言，我们通过它来描述对问题的理解。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个灵活性必然导致了深度学习框架前端用户接口的多样化。而且这个趋势肯定是越来越剧烈。因为随着进入这个领域的人越来越多，大家关注的应用各不相同，熟悉的编程语言又各不一样，所以很难会有一个统一的前端语言来满足这些要求。所以我们觉得深度学习的前端很有可能像编程语言那样，风潮涌动。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一方面，深度学习应用需要大量的计算，目前没有，甚至未来几年内也不会有单一的硬件架构解决所有需求。所以必然是根据场景选择不同的硬件。例如 GPU 适合模型训练，CPU 由于大量存在也经常用作云端模型预测，但很多厂商也开始走 FPGA 路线。ARM 主要用在手机等低功耗的场景上，但很可能很快就会被定制的 FPGA/ASIC 取代。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不同硬件需要不同的优化。例如 GPU 计算单元多，需要算法并行度高，而 ARM 通常内存小而且结构复杂，需要重点优化。而定制化硬件则有更多的特殊打开方式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以在前端和后端都在快速发展的今天，要求每一个前端都对每个硬件做更好的支持明显是不能可持续发展的。所以我们要更好的解决方案。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;幸运的是历史总是在重复。如果我们往回看，会发现我们曾面临一样的问题。当年编程语言层出不穷，CPU 架构也不断翻新，于是大名鼎鼎的 LLVM 横空出世，通过很好的模块化分离前后端，为新语言和新硬件提供和非常好的支持。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于深度学习，我们需要类似的项目。学习 LLVM 的思想，我们将其取名 NNVM。他的工作原理如下所示：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9ibicGpNCBjqeDIoXuzlnTBl96xpsHMBZh8Tc2Jb5QzpNzkQZStK8tfKicgvOzXOQ8WAW0xhHUrwiadw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;示意图&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;前端把计算表达成一个中间形式，通常我们称之为计算图，NNVM 则统一的对图做必要的操作和优化，然后再生成后端硬件代码。简单地说, NNVM 是一个神经网络的比较高级的中间表示模块，它包含了图的表示以及执行无关的各种优化（例如内存分配，数据类型和形状的推导）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;设计这样一个模块最困难的地方并不是加入新的功能，而是可以在支持新的功能的情况下保持最小的接口，零依赖但是可以扩展未来可能可以想要的各种需求。我们总结了主流的深度学习框架 (TF, caffe2, MXNet) 的 operator 接口设计，设计了一个简洁但是扩展性极强的计算图结构和优化接口。利用这些模块，我们可以很容易地加入新的功能，或者删除我们不需要的功能来组合新的执行框架。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在第一阶段，我们通过把 MXNet 的符号执行模块转移到 NNVM，验证了接口的可靠性。未来我们会给 NNVM 加入更多的执行后端和优化。作为机器学习系统研究人员，我们也会基它来进行深度学习系统优化研究的探索。对于深度学习系统有兴趣的同学不妨一起来参与贡献代码。我们可以利用 NNVM 来很容易地为新的机器学习系统生成各种前端，并且复用通用的优化用以方便地实现各种后端。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前 NNVM 发布在 https://github.com/dmlc/nnvm。我们相信可以模块化各个部件，从而可以相互组装成满足各种需求的深度学习平台，使得更好的适应未来算法，应用，前端编程环境，后端硬件的高速发展。这是一个 开始，相信未来会有更多更加灵活，模块化和通用的组件出现，使得大家轻松打造深度学习平台不再是一个不可能的事情。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;不知道如何使用? 我们同时开放了一个两千行代码的样例项目，教你如何从头开始打造一个和 TensorFlow 一样 API 的深度学习系统 https://github.com/tqchen/tinyflow。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心经授权发布，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Sat, 01 Oct 2016 12:28:58 +0800</pubDate>
    </item>
    <item>
      <title>业界 | Google发布Open Images图像数据集，包含9百万标注图片</title>
      <link>http://www.iwgc.cn/link/2914332</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Google Research&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;最近，谷歌不断加大开源的力度。前天，&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719494&amp;amp;idx=1&amp;amp;sn=5c796cf9da81e6532750cea04667467c&amp;amp;chksm=871b0178b06c886e12aa5bc32a1cd9d585d4a2d624aab1c660e63ea619fd4c3aa8430ae8da0c&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719494&amp;amp;idx=1&amp;amp;sn=5c796cf9da81e6532750cea04667467c&amp;amp;chksm=871b0178b06c886e12aa5bc32a1cd9d585d4a2d624aab1c660e63ea619fd4c3aa8430ae8da0c&amp;amp;scene=21#wechat_redirect"&gt;谷歌发布YouTube-8M&lt;/a&gt;，这是单个GPU一天就能完成训练的一个最大视频数据集；昨天，&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719511&amp;amp;idx=3&amp;amp;sn=0674ef2a2e995d180ca081ed3a6ae1b9&amp;amp;chksm=871b0169b06c887feefc5604f1f53081e919eadec5c3d02c25d8da786de0bfa23141bd3f184e&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719511&amp;amp;idx=3&amp;amp;sn=0674ef2a2e995d180ca081ed3a6ae1b9&amp;amp;chksm=871b0169b06c887feefc5604f1f53081e919eadec5c3d02c25d8da786de0bfa23141bd3f184e&amp;amp;scene=21#wechat_redirect"&gt;谷歌开放了图像压缩模型&lt;/a&gt;，能高质量地将图像压缩得更小；今天，谷歌再次发布大规模图像数据集 Open Images。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;过去几年机器学习的发展使得计算机视觉有了快速的进步，系统能够自动描述图片，对共享的图片创造自然语言回应。其中大部分的进展都可归因于 ImageNet 、COCO（监督学习）以及 YFCC100M（无监督学习数据集） 这样的数据集的公开使用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今天，我们向公众介绍 Open Image，这是一个包含~900 万张图像 URL 的数据集，里面的图片通过标签注释被分为 6000 多类。我们试图让该数据集更为实用：该数据集中的标签要比 ImageNet（1000 类）包含更真实生活的实体存在，它足够让我们从头开始训练深度神经网络。&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;开源地址：https://github.com/openimages/dataset&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;使用谷歌云视觉 API 这样的视觉模型自动进行图像层次的注释已经变得很流行。在验证数据集上，我们有人类评定等级查证这些自动标签，并移除里面的假正例。平均而言，每个图像有大约 8 个标签。如以下示例：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicCYYBeS6htTRphzMKNPJbRelX2ovtCHict3zXUXWqH80icGnt0SsqSXibNGBmqt06LXoiaXia7Qg6XmJA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;来自 Open Images 数据集的带有注释的图片。左图：Kevin Krejci 的 Ghost Arches；右图：一些银器&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;仅基于 Open Images 注释，我们已经训练出了一个 Inception V3 模型，而且该模型被用于微调应用和其他事件时表现足够的好，比如用于 Deep Dream 或艺术风格迁移这样的需要较好层次结构的过滤器的任务。我们希望在接下来几个月能改进 Open Images 数据集中图像注释的质量，因此能改进训练的模型的质量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Sat, 01 Oct 2016 12:28:58 +0800</pubDate>
    </item>
    <item>
      <title>一周论文| 神经网络机器翻译下的字符级方法</title>
      <link>http://www.iwgc.cn/link/2914333</link>
      <description>&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;引&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;神经网络机器翻译(NMT)是seq2seq模型的典型应用，从2014年提出开始，其性能就接近于传统的基于词组的机器翻译方法，随后，研究人员不断改进seq2seq模型，包括引入注意力模型、使用外部记忆机制、使用半监督学习和修改训练准则等方法，在短短2年时间内使得NMT的性能超过了传统的基于词组的机器翻译方法。在27号谷歌宣布推出谷歌神经网络机器翻译系统，实现了NMT的首个商业化部署，使得NMT真正从高校实验室走向了实际应用。本期Paperweekly的主题是神经网络机器翻译下的字符级方法，主要用来解决NMT中的out-of-vocabulary词问题，分别是：&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1、A Character-Level Decoder without Explicit Segmentation for Neural Machine Translation，2016&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2、Achieving Open Vocabulary Neural Machine Translation with Hybrid Word-Character Models，2016&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3、Character-based Neural Machine Translation，Costa-Jussa, 2016&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4、Character-based Neural Machine Translation，Ling, 2016&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;5、Neural Machine Translation of Rare Words with Subword Units，2016&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;A Character-Level Decoder without Explicit Segmentation for Neural Machine Translation&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;1&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;作者&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Junyoung Chung, Kyunghyun Cho, Yoshua Bengio&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;单位&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Universite de Montreal&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;关键词&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Segmentation, Character-level, Bi-scale recurrent network&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;文章来源&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;ACL 2016&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;问题&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;能否在不需要分词的前提下直接在字符级进行神经机器翻译。&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;模型&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;在讲模型之前，本文花了大量篇幅论证为何需要在不分词的前提下进行字符级翻译，首先作者总结了词级翻译的缺点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;词级翻译的缺点包括：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1、任何一个语言都没有完美的分词算法，完美的分词算法应该能够将任意句子划分为lexemes和morphemes组成的序列&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2、导致的问题就是在词典中经常充斥着许多共享一个lexeme但有着不同morphology的词，比如run,runs,ran,running可能都存在于词典中，每个词都对应一个词向量，但是它们明显共享相同的lexeme——run&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3、存在unknown word问题和rare word问题，rare word问题是指某些词典中词在训练集中出现次数过少，导致无法训练得到很好的词向量；unknown word问题是指不在词典中的词被标记为UNK（OOV词）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;接着作者指出使用字符集翻译可以解决上述问题：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1、使用LSTM或GRU可以解决长时依赖问题&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2、使用字符级建模可以避免许多词态变形词出现在词典中&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然而上述字符级方法依然需要进行分词，然后对每个词的字符序列进行编码，因此引出了本文的motivation，即是否能直接在不分词的字符序列上进行翻译。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本文使用的模型同样是经典的seq2seq模型，其创新点主要在decoder端，引入了一种新的网络结构biscale RNN，来捕获字符和词两个timescale上的信息。具体来说，主要分为faster层和slower层，faster层的gated激活值取决于上一步的faster和slower层的激活值，faster层要想影响slower层，则必须要是faster层处理完当前数据，并且进行重置。换句话说，slower层无法接受faster层输入，直到faster层处理完其数据，因此比faster层要慢，而这样的层次结构也对应字符和词在timescale上的关系。下图为网络结构示意图。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a title="1-figure1" rel="gallery0" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnekfxYfFp7qEgOSnjdr3Wy2cw2RcyoK9Z5LnM9eJJw7oiabz4ViaNOU9PKVmz3XBesWsPtI9RFEoWw/640?wx_fmt=png"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在4种语言翻译任务上的实验显示完全可以在不分词的情况下进行字符级翻译，性能优于state-of-the-art的非神经翻译系统&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;相关工作&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Sennrich ACL2016提出使用BPE算法对subword建模。Kim AAAI2016中提出直接对字符进行encode，Costa-jussa ICLR2016中将该模型用在了NMT任务中。Ling ICLR2016的工作中使用Bi-RNN来编码字符序列。以上工作基于字符级展开，但它们都依赖于知道如何将字符分为词，即分词。本文研究能否在不分词的情况下进行字符级翻译。&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;简评&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;本文是Bengio组工作，Bi-scale RNN受启发于该组之前提出的GF-RNN，本文创新点主要是提出了一种新的RNN结构，可以在字符和词两个timescales上进行处理，输出字符序列不需要进行分词。不足是未考虑encoder端是否也可以直接使用未分词的字符序列，而是仅仅使用了分词后的BPE序列。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;span&gt;Achieving Open Vocabulary Neural Machine Translation with Hybrid Word-Character Models&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;2&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;作者&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Minh-Thang Luong and Christopher D. Manning&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;单位&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Stanford University&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;关键词&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;OOV, hybrid word-character models, NMT&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;文章来源&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;ACL 2016&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;问题&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;机器翻译里面的OOV问题, 如何处理UNK&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;模型&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;提出了一种混合word-character的NMT模型.在训练难度和复杂度不是很高的情况下,同时解决源语言和目标语言的OOV问题.&lt;br/&gt;&lt;/span&gt;&lt;a title="2-1" rel="gallery0" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnekfxYfFp7qEgOSnjdr3WyYET3Qko2GTpMpJBgLjt7WHriabA5vciaJydibZ05ictyLcYuzudU1Ec6zw/640?wx_fmt=png"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个图表达了模型的整体思路. 大多数情况下,模型在word-level进行translation. 当出现&amp;lt;unk&amp;gt;&lt;/span&gt;&lt;unk style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;的时候,则会启用character-level的模型. 对source&amp;nbsp;&amp;lt;unk&amp;gt;&lt;/span&gt;&lt;unk style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;, 由character-level模型来得到它的representation; 对target &amp;lt;unk&amp;gt;&amp;nbsp;&lt;/span&gt;&lt;unk style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;, 用character-level模型来产生word.&lt;/span&gt;&lt;/unk&gt;&lt;/unk&gt;&lt;/unk&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1、整体上采用他们组以前提出的基于global attention的encoder-decoder模型. RNN采用的是deep LSTM.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2、源语言端和目标语言端的character-level模型都是基于character的deep LSTM. 对源语言端来说, 它的character-level模型是context independent的. 隐层状态全部初始化为0, 因此在训练时可以预先计算mini-batch里的每一个rare word的representation. 而对于目标语言端来说, 它的character-level模型是context dependent的.它的第一层的hidden state要根据当前context来初始化, 其它部分都初始化为0.训练时, 在目标语言的decoder阶段, 首先用word-level的decoder产生句子, 这时句子里包含了一些&amp;lt;unk&amp;gt;&lt;/span&gt;&lt;span&gt;. 接着对这些&amp;lt;unk&amp;gt;&lt;/span&gt;&lt;unk style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;, 用character-level模型以batch mode来产生rare word.&lt;/span&gt;&lt;/unk&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3、对于目标语言端character-level模型的初始化问题, 作者提出了两种方法来表示当前的context. 一种叫做same-path, 用预测&amp;lt;unk&amp;gt;的softmax层之前的ht来表达. 但是因为ht是用来预测&amp;lt;unk&amp;gt;的, 所以所有ht的值都会比较相似,这样很难用来产生不同的目标rare word. 因此作者提出了第二种表达叫做separate-path, 用ht’来表达context. ht’不用预测&amp;lt;unk&amp;gt;, 是专门作为context在character-level的输入的. 它的计算方法和ht’相同,只是用了一个不一样的矩阵.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4、模型训练的目标函数是cross-entropy loss, 同时考虑了word level和character level的loss.&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;相关工作&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;NMT的模型分为word-level和character-level的. 对于word-level模型,要解决OOV问题, 之前的工作提出了unk replacement(Luong et al. 2015b), 使用大字典并在softmax时进行采样(Jean et al. 2015), 对unk进行Huffman编码(Chitnis et al. 2015)等方法. 而对于character-level的模型, 本身可以处理OOV词, 但是训练难度和复杂度会增加.&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;简评&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;本文的创新之处在于提出了混合word-character model的NMT模型. 这个混合模型结合了二者的优点, 在保证模型复杂度较低的同时,实现了很好的效果.因为加入了character, 特别适合单词有丰富变形的语言.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;span&gt;Character-based Neural Machine Translation&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;3&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;作者&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Marta R. Costa-jussa and Jose A. R. Fonollosa&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;单位&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;TALP Research Center, Universitat Politecnica de Catalunya, Barcelona&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;关键词&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;NMT，character-based word embeddings，CNN&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;文章来源&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;ICLR2016&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;问题&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;本文提出使用character-based word embeddings的NMT，可以在一定程度上克服机器翻译中OOV问题。&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;模型&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;a title="3-encoder_decode" rel="gallery0" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnekfxYfFp7qEgOSnjdr3WymIxIEiazRz0lib8ZIRcgS3zWuwL8ib8ZtfLwLJWn2x6MRortvtwtRhwCQ/640?wx_fmt=png"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如上图所示，这篇论文使用的基本模型架构是一个带attention机制的seq2seq的encoder-decoder的架构，使用的神经网络单元是GRU。encoder把源句子转化成一个向量（双向），使用attention的机制来捕获context信息，decoder把context解码成目标句子。网络的输入仍然使用word embedding，但是作者在获取word embedding的时候使用的方法不同。本文是基于词中的character来生成word embedding的，具体方法如下图所示。&lt;br/&gt;&lt;/span&gt;&lt;a title="3-embedding" rel="gallery0" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnekfxYfFp7qEgOSnjdr3WyQ86BuDUTpC3F6zJP51JIIYxUR9qLnIZq5rx4TibzcbQjKmgOA95NUtg/640?wx_fmt=png"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;上图中，最底层是一个character-based embedding组成的序列，对应的是每个词中的字母。然后这个序列被送入一个由不同长度的一维卷积过滤器组成的集合中进行处理，不同的长度对应单词中不同数量的字母（从1到7）。对于每个卷积过滤器，只取最大的值作为输出。然后把每个卷积过滤器输出的最大值连接起来组成一个向量。最后这个向量再通过两层Highway layer的处理作为最终的word embeddings。这个方法的详细信息可以参考Kim的论文&lt;/span&gt;&lt;a target="_blank" rel="external" style="text-decoration: underline; max-width: 100%; font-size: 14px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;Character-Aware Neural Language Models&lt;/span&gt;&lt;/a&gt;&lt;span&gt;(2016)。&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;资源&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;1、本文数据集[German-English WMT data] (&lt;/span&gt;&lt;a target="_blank" rel="external" style="text-decoration: underline; max-width: 100%; font-size: 14px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;http://www.statmt.org/wmt15/translation-task.html&lt;/span&gt;&lt;/a&gt;&lt;span&gt;)&amp;nbsp;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2、建立对比模型使用的软件包&lt;/span&gt;&lt;a target="_blank" rel="external" style="text-decoration: underline; max-width: 100%; font-size: 14px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;DL4MT&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;相关工作&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;1、2003年，基于短语的统计机器翻译模型。Statistical Phrase-Based Translation&amp;nbsp;&lt;br/&gt;2、2013年，基于神经网络的机器翻译模型。Recurrent continuous translation models&amp;nbsp;&lt;br/&gt;3、2014年，seq2seq的神经网络模型用于机器翻译。Sequence to sequence learning with neural networks&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;简评&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;本文作者将基于character来产生word embedding的方法应用于机器翻译，可以在一定程度上克服OOV的问题。同时，由于利用了单词内部的信息，这篇论文提出的方法对于词形变化丰富的语言的翻译也产生了更好的效果。但是，作者只是在source side使用了上述方法，对于target side，仍然面临词典大小的限制。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;span&gt;Character-based Neural Machine Translation&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;4&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;作者&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Wang Ling, Isabel Trancoso, Chris Dyer, Alan W Black&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;单位&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;1、LF Spoken Systems Lab,Instituto Superior Tecnico Lisbon, Portugal&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2、Language Technologies Institute, Carnegie Mellon University Pittsburga, PA 15213, USA&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;关键词&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;NMT, Character-Based&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;文章来源&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;ICLR 2016&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;问题&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;尝试在字符级别上应用神经机器学习方法&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;模型&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;在带注意力机制的神经机器学习模型的前后端增加字符到词（C2W)和词向量到字符（V2C）的模块。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a title="4-C2" rel="gallery0" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnekfxYfFp7qEgOSnjdr3Wyh8X9FicJK164GXVibA6sT2w5oZd4UZaNEZo03oTYlHWFtgQTTSaxe0Ng/640?wx_fmt=png"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图中，小矩形是一个双向LSTM，双向LSTM的前向和后向的最终状态以及bias之和为词的向量表示。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a title="4-V2" rel="gallery0" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnekfxYfFp7qEgOSnjdr3WyanesZGRKjDOObevUXzwdYdibCr4bEIEGkJjWPLLWV1TMDn8r1HiceI8w/640?wx_fmt=png"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个模块主要由三个步骤组成：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1、将字符转换为向量表示。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2、将字符向量和之前模型产生注意力向量的a和目标词在前向LSTM中产生的向量表示做拼接并输入到LSTM。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3、将得到的向量输入到softmax层得到结果。&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;相关工作&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;1、Neural machine translation by jointly learning to align and translate.&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;简评&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;这篇文章在基于注意力机制的机器翻译模型上增加了两个模块。由于是基于字符集别的模型，该模型自然可以学得一些语言中的前后缀在翻译中的关系。此外，基于字符级别的模型在翻译未知词时有灵活性。可是，文中也提到，该模型为能够准确的翻译未知词。并且该文也没有明确表明该模型和其他模型相比具有哪些明显的优势。从实际上来说，该模型在V2C部分的训练速度慢是一个很大的弱点，因此若仅根据文章的表述，该模型的实际应用价值应该有限。&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/h2&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;span&gt;Neural Machine Translation of Rare Words with Subword Units&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;5&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;作者&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Rico Sennrich and Barry Haddow and Alexandra Birch&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;单位&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;School of Informatics, University of Edinburgh&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;关键词&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;NMT, Rare Words, Subword Units, BPE&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;文章来源&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;ACL 2016&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;问题&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;NMT中的OOV（集外词）和罕见词（Rare Words）问题通常用back-off 词典的方式来解决，本文尝试用一种更简单有效的方式（Subword Units）来表示开放词表。&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;模型&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;本文从命名实体、同根词、外来语、组合词（罕见词有相当大比例是上述几种）的翻译策略中得到启发，认为把这些罕见词拆分为“子词单元”(subword units)的组合，可以有效的缓解NMT的OOV和罕见词翻译的问题。&lt;br/&gt;子词单元的拆分策略，则是借鉴了一种数据压缩算法：Byte Pair Encoding(BPE)(Gage,1994)算法。该算法的操作过程和示例如Figure1所示。&lt;br/&gt;&lt;/span&gt;&lt;a title="5-Fig1" rel="gallery0" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgnekfxYfFp7qEgOSnjdr3Wyn4xW7akEoHY7IO1icj2kD6JEFe3ybmOHezvOeWhZ88FeLnl4r2WTcibQ/640?wx_fmt=jpeg"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不同于(Chitnis and DeNero,2015)提出的霍夫曼编码，这里的压缩算法不是针对于词做变长编码，而是对于子词来操作。这样，即使是训练语料里未见过的新词，也可以通过子词的拼接来生成翻译。&lt;br/&gt;本文还探讨了BPE的两种编码方式：一种是源语言词汇和目标语言词汇分别编码，另一种是双语词汇联合编码。前者的优势是让词表和文本的表示更紧凑，后者则可以尽可能保证原文和译文的子词切分方式统一。从实验结果来看，在音译或简单复制较多的情形下（比如英德）翻译，联合编码的效果更佳。&lt;br/&gt;实验结果分别在WMT15英德和英俄的任务上得到1.1和1.3个BLEU值的提升。&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;资源&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;本文提出的子词拆分算法代码在&amp;nbsp;&lt;/span&gt;&lt;a target="_blank" rel="external" style="text-decoration: underline; max-width: 100%; font-size: 14px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;https://github.com/rsennrich/subword-nmt&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;span&gt;实验所用的NMT系统为Groundhog: github.com/sebastien-j/LV_groundhog&lt;br/&gt;实验数据来自WMT 2015&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;相关工作&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;OOV的处理一直是机器翻译研究的重点。&lt;br/&gt;基于字符的翻译在短语SMT模型中就已被提出，并在紧密相关的语种对上验证是成功的(Vilar et al., 2007; Tiedemann,2009; Neubig et al., 2012)。 此外还有各种形态素切分方法应用于短语模型，(Nießen and Ney,2000; Koehn and Knight, 2003; Virpioja et al.,2007; Stallard et al., 2012)。&lt;br/&gt;对于NMT，也有很多基于字符或形态素的方法用于生成定长连续词向量(Luong et al., 2013; Botha and Blunsom, 2014; Ling et al., 2015a; Kim et al., 2015)。与本文类似的一项工作 (Ling et al., 2015b)发现在基于词的方法上没有明显提升。其与本文的一个区别在于，attention机制仍然在词层级进行操作，而本文在子词层级上。&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;简评&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;这篇文章的创新点在于提出了一种介乎字符和单词之间，也不同于字符n-gram的文本表示单元，并借鉴BPE压缩算法，在词表大小和文本长度两个方面取得一个较为平衡的状态。应用在非同源/近源的语言对（如英汉）是否可以有类似的效果，尚待研究。在NMT模型的优化上，也还有探讨的空间。&lt;br/&gt;本文的实验评价方法值得学习，单看BLEU值并不觉得有惊艳之处，但加上CHR F3和(对所有词、罕见词和集外词分别统计的)unigram F1这两个评价指标，尤其是Figure2和3画出来的效果，还是让人比较信服的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;总结&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;OOV词对于翻译性能和实用性的影响非常巨大，如何处理OOV词并达到open vocabulary一直是NMT的主要研究方向。传统方法基于单词级别来处理该问题，比如使用UNK替换、扩大词典规模等方法，往往治标不治本。因此最近一些研究者提出基于字符的NMT模型，取得了不错的成绩，字符级方法的主要优势包括不受语言的形态变化、能预测出词典中未出现的单词并降低词典大小等。值得一提的是，基于字符的模型不仅局限于NMT上，任何生成模型都面临OOV词问题，因此是否能够将字符级方法用在其他NLP任务，比如阅读理解或文本摘要上，让我们拭目以待。&lt;/span&gt;&lt;span&gt;以上为本期Paperweekly的主要内容，感谢&lt;strong&gt;EdwardHux&lt;/strong&gt;、&lt;strong&gt;Mygod9&lt;/strong&gt;、&lt;strong&gt;Jaylee1992&lt;/strong&gt;、&lt;strong&gt;Susie&lt;/strong&gt;和&lt;strong&gt;AllenCai&lt;/strong&gt;五位同学的整理。&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;广告时间&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;PaperWeekly是一个分享知识和交流学问的民间组织，关注的领域是NLP的各个方向。如果你也经常读paper，也喜欢分享知识，也喜欢和大家一起讨论和学习的话，请速速来加入我们吧。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;微信公众号：&lt;strong&gt;PaperWeekly&lt;/strong&gt;&lt;/span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgkSMlEJFo90NY8rCXr3mJMBibduVHxMKSHzQtVkHz8kNwpjCKBiccGuqLE0WpPuAbdtEs6cTF5iabpAQ/640?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;微博账号：&lt;strong&gt;PaperWeekly&lt;/strong&gt;（&lt;/span&gt;&lt;a target="_blank" rel="external" style="color: rgb(64, 64, 64); text-decoration: underline; max-width: 100%; box-sizing: border-box; font-size: 14px; word-wrap: break-word !important;"&gt;http://weibo.com/u/2678093863&lt;/a&gt;&lt;span&gt;&amp;nbsp;）&lt;br/&gt;知乎专栏：&lt;strong&gt;PaperWeekly&lt;/strong&gt;（&lt;/span&gt;&lt;a target="_blank" rel="external" style="color: rgb(64, 64, 64); text-decoration: underline; max-width: 100%; box-sizing: border-box; font-size: 14px; word-wrap: break-word !important;"&gt;https://zhuanlan.zhihu.com/paperweekly&lt;/a&gt;&lt;span&gt;&amp;nbsp;）&lt;br/&gt;微信交流群：微信+ &lt;strong&gt;zhangjun168305&lt;/strong&gt;（请备注：加群 or 加入paperweekly）&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;</description>
      <pubDate>Sat, 01 Oct 2016 12:28:58 +0800</pubDate>
    </item>
    <item>
      <title>专访 | 谷歌神经网络翻译系统发布后，我们和Google Brain的工程师聊了聊</title>
      <link>http://www.iwgc.cn/link/2899977</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心原创&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;记者：老红&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt; 参与：吴攀、张俊、李亚洲、杜夏德&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;9 月 27 日，谷歌在 arXiv.org 上发表论文《Google`s Neural Machine Translation System: Bridging the Gap between Human and Machine Translation》介绍谷歌的神经网络翻译系统（GNMT）后，「机器之心」第一时间进行了详细的解读和报道，&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719470&amp;amp;idx=1&amp;amp;sn=3368dea980517ea7d7942967da2740dc&amp;amp;chksm=871b0090b06c89863620be4e75c757940d03d8a43cd3c1d9a8309b6594c1bccd769cab193177&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719470&amp;amp;idx=1&amp;amp;sn=3368dea980517ea7d7942967da2740dc&amp;amp;chksm=871b0090b06c89863620be4e75c757940d03d8a43cd3c1d9a8309b6594c1bccd769cab193177&amp;amp;scene=21#wechat_redirect"&gt;重磅 | 谷歌翻译整合神经网络：机器翻译实现颠覆性突破（附论文）&lt;/a&gt;。&lt;/span&gt;&lt;/em&gt;&lt;br/&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在最新报道发出后的第二天，「机器之心」受邀来到谷歌中国和来自 Google Brain 的软件工程师陈智峰聊了聊人机翻译、GNMT 和谷歌的技术创新等问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以下为采访对话，「机器之心」略有删改：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;机器之心：神经网络翻译系统（NMT）将整个输入的句子视作翻译的基本单元，相比于之前基于短语的翻译系统，除了所需的工程设计更少这个优点外，句子意思理解的精确度有多大的提升？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;陈智峰：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我们过去的方法有很多翻译出来给人看，会发现有很多错误。机器会给这些翻译结果打个分，而我们新的系统作出的翻译所得的分会很高。我们在翻译结果的正确率在一些分数上会提高大概 0.5 分到 1 分，这是非常巨大的进步。比如，刚才我的同事讨论在微信上最近有些人开始测试「小偷偷偷偷东西」这个句子，相比过去的模型，这个翻译会非常非常正确。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;机器之心：GNMT 有利用外部对准模型（External Alignment Model）对罕见词进行处理吗？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;陈智峰：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我们这个模型是没有 External Alignment Model 的，其他一些地方需要使用到外部对准模型来帮助神经网络模型来达到同样的效果，我们这个模型是不需要外面帮助的，整个训练和整个模型就是端对端的模型，它的迅速速度非常简单，你对照着中文句子，对照着英文句子就可以告诉我们，当中几乎没有任何其他的帮助就能够学习到这样的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;机器之心：那在罕见词的处理上是用了什么方法呢？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;陈智峰：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我们有两种方法，你可以把中文一个句子分成一个词一个词，比如说「我们今天见面」，你可以把它分成三个词，我们、今天、见面，你也可以把它分成六个字，传统的方法还有很多其他的类似系统里面大多数都是把它分成词来进行建模和训练的。英文也有同样的规律，比如说这个英文里是两个词，我们现在用的方法是把中文词全部打成字，然后把英文单词全部打成像词根一样的部分，比如说英文词语言、图像它的前缀都是一样的，所以说我们把这些前缀作为一个单元进行翻译，而不是像过去那样三个词分别翻译。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;机器之心：我们都知道人在阅读时有一种能力是可以忽略文字排序错乱的问题，机器面临这种情况如何像人类一样高效处理这些内容？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;陈智峰：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;不受顺序的影响我觉得是一个程度，比如说你随便打出一个中文的十个字的句子，你任意打乱的话很有可能是错误表达的，但如果你随机调整两个的话是可以跳过一些错误拼写出来的字。现在的模型也能做到，因为整个模型是统计模型，就是你看到前面几个字，然后猜下一个字是什么，有些字的可能性大一些，有些可能性低一点，也可能它会说下一个字就应该是一个空格，这样的话它就会跳过去。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们做过一些测试。中文里经常会有一些标点符号，比如前面是双引号，写了句子以后会发现最后忘了加引号，你可以很清楚地看到这个模型会意识到这个地方你是想写一个双引号的，但你没有写。这些现在都能在一定程度上避免这些错误。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;机器之心：你觉得 GNMT 在技术上的新突破以及未来的发展是否会完全取代人工翻译？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;陈智峰：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我觉得完全替换，或者说在任何情况下替换人的翻译还是有一定难度的。现在的机器翻译都是基于已经出现过的语言现象，但是整个人类不停地在发展，比如说网络上经常出现不同的新的语言现象，比如说有些短语、有些常用语，也是不停地在变化的。所以说机器是很难发明新的规则来表达你现在的意义，最终还是要靠人来创造出新的表达方式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;就是机器从人那边学习到怎么表达这个意思更加贴近时代，比如说同样一个英文词一百万，在英国和美国 20 年前是不一样的。还有对于同样的单词，如果是英国长大的人搬到美国，他会自己调整适应度。也就是说英语环境变化了，它的意思发生了微妙的变化，而你要让一个机器翻译的系统能够捕捉到这样细微的变化还是很难的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;机器之心：在结构化比较高的文章中，比如论文、科技文献上的处理是不是会更接近一些？可以取代一些？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;陈智峰：对，那些我觉得可能，比如说翻译一些医学的文章，就是这个领域非常非常固定的，有些很成文的规则表达的东西，我觉得将来会非常依赖于机器翻译来处理各个语言之间的信息交流，帮助会很大，而且精确度也会很快提高。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;机器之心：从你们一些产品的实验中，就是从更大的范围来看，您觉得有哪些领域是现在特别适合机器翻译来做，或者机器翻译的水平和人的水平最接近的？哪些领域是目前不太适合机器翻译来做的？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;陈智峰：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;比如说在时事新闻方面，因为很多时事新闻写作都是有套路的，比如说美国总统今天怎么样，中国国家主席怎么样，这些模式比较固定的情况机器翻译就能够做得比较好，而且读新闻的人不太注重时事新闻的写作文笔，更注重的是信息的传达，所以说在一些修辞方面或者情感的传达方面要求比较弱。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器翻译就能够很快地帮助你获得信息，这是主要机器翻译目前对人类的帮助。目前来讲我觉得在人与人之间的自然沟通上，机器翻译还是有很大的工作需要做，才能达到真正能够让你感觉到跟你说话的人是一个真的人，而不是一个机器，这还需要很多年的努力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;机器之心：在科幻小说《银河系漫游指南》里，有一个种叫「巴别鱼」的生物能实时翻译任何语言，你觉得 Google 实现这样的水平还需要多久？（也就是说在更高层次上与自然语言处理上，实现两种语言对话的实时翻译，预计这种情景能多久实现？中间有着什么样的技术难题？）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;陈智峰：很难预测，但我觉得从目前来看如果是要达到信息交互的过程还是很有可能的，但是要达到让你感觉是跟你家人说话的亲切感还是有很大的距离的，尤其是如果你要实时地和另一个人交互。我觉得现在要做到实时翻译还是有一些距离的，尤其是实时的语言翻译还是有一些距离的，但是三年五年可能会有一些突破。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;机器之心：除了在机器翻译上，你们现在在其他语言和产品（例如 Allo）上这项技术应用的进展如何？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;陈智峰：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;GNMT 是非常针对机器翻译这个产品做的，但是它的顶层研究，就是模型本身是非常广的，可以使用到很多领域里的，每一个产品都在这个基础模型上做一些开发的。举例来讲大家都有 iPhone，但是每个公司做的每个项目上的 APP 不一样。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;机器之心：现在 seq2seq+attention 的模型已经在 NMT 及其他众多 NLP 任务上取得了非常好的效果，本次发布的 paper 中提到用了更多层的网络得到了更好的效果，请问是否还可以不断地增加网络层数来提升效果？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;陈智峰：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;现在所谓你的层数增加，大家会普遍认为你的模型的能力就相对增强，但是在现有的技术条件下盲目地增加深度的话也有缺点。你的层次增加了，在应用时候的速度会变慢，因为它的计算量会增加，所以在现实当中都是有不同的考虑的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;机器之心：seq2seq+attention 的模型在效果方面是否达到了上限，从而需要更新的模型来解决问题？如果有的话，Google 最近在研究什么新的模型？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;陈智峰：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我觉得在机器翻译这个问题上，就是在基本的模型上还有很多扩展的余地，就是说你可以把这个模型变得更大，程序增加，它的模型架构是基本上一样的，但是在这方面你可以进一步推展。当然，这个领域变化很快，每年都会有不同的细分结构、模型结构出来，我们会不停地取长补短，就是有没有可能更快地提供更好的翻译服务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;机器之心：我有注意到现在移动版和网页版的 Google Translate 的汉英翻译已经在 100% 使用 GNMT 机器翻译了，为什么会率先在汉英 翻译上去应用呢？现在是有什么技术难点或者考虑吗？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;陈智峰：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;有两个基本考虑，第一个考虑是在所有的 Google Translate 领域中，中文翻英文和英文翻中文的确是很大的一部分。用户很多，这也是在很多翻译任务当中相对较难的一部分，因为这是两个非常不同的语言，所以从传统上来讲这是一个比较难的。另外一点，在整个项目开发过程中有很多中国同事参与，有很多能懂中文也能懂英文的人在第一个系统的时候可以帮助调试，这会有很大帮助，所以这是主要的考虑。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;机器之心：不同语言的语料规模差别很大，英文中的语料非常多，但中文语料就显得非常少。请问，能够将 NMT 的研究成果应用在不同语言语料构建上，从而提升其他语言 NLP 研究水平？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;陈智峰：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;其实中文语料也是很多的，在我们的数据库里中文语料是英文语料的一半，但是这两个语言的语料库中我们掌握的语料是非常非常巨大的，世界上有很多其他语言没有足够的数据，所以这也是一个研究难点，就是怎么通过其他的语言来帮助翻译一些小语种，也是我们正在努力的方向。因为 Google 不光是要服务英文、中文，它的目的是让世界上所有的国家、所有的人都能够获得同样的服务，所以说我们非常致力于全世界有 100 多种语言，我们希望这 100 多种语言我们都能够做到很快翻译。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;机器之心：刚才提到 Google Brain 和 Translate 这次的合作，我想知道在 GNMT 这次的技术研发包括产品的应用上，两个团队之间的分工是怎么样的？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;陈智峰：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我们主要是在初期建模的工作上做的工作比较多，在怎么使用最新的那些 GPU上，我们早期工作做的比较多。在 Google Translate 里面，他们负责很多怎么获得数据的工作，有些数据的有关情况需不需要调试，还有最后怎么把这个模型应用到产品里去，他们也做了巨大的工作，这是主要的工作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其实 Google 很多技术开发都是这个模式的，不同的团队之间都会有很强的合作，因为 Google Brain 更多的是一个注重于神经网络、人工智能方面研发的团队，而 Google Translate 主要负责的是翻译这个产品，当然他们也有研究团队。所以各个团队不同，他们花了很多的时间，那么多年，就是需要采集数据，比如说我们训练的时候可以完全用他们已有的训练数据，每个团队的目标不一样，但是合作非常流畅，没有任何问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;机器之心：你们的新论文描述了让 NMT 在非常大型的数据集上工作的许多挑战，你觉得当前最大的技术难点在哪里？在翻译速度和准确度的提高上你们又做了哪些创新？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;陈智峰：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;这个项目在三年前，也就是 2013、2014 年的时候 Google Brain 就想做了，当时从硬件和软件上都无法支持训练这个模型，在过去两三年中 Google Brain 开发了 TensorFlow，使得训练类似的模型可以充分利用分布式计算，利用很多很多不同的硬件类型。另外，如果你这两三年没有一些专门的硬件加速器的话也是很难在短时间内完成这个训练。而过去两三年 Google 在机器学习、在人工智能方面的巨大投入，使得类似的操作才变得可行。当然，我们也做了很多，对于具体的训练在我们现有的硬件资源上做了很多优化，这也是一方面的努力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;机器之心：您说这个短时间是短到什么程度？是多久训练一次？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;陈智峰：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;一般来说我们训练一个语言现在需要五天到六天的时间，差不多需要将近一百个 GPU 的加速器才能做完，差不多一星期才能处理一个方向的语言模型。但是 Google 有大概一万个语言的模型需要训练，当然我们有巨大的资源投入，也在不停地改进算法，所以说都在努力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;机器之心：这次我们这个系统昨天晚上的新闻发出来以后，很多人拿一些有趣的句子去测试，我想了解一下你们内部也有很多中国人，有这种有趣的句子测试它吗？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;陈智峰：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;上市之前我们每个同事都绞尽脑汁想出一些办法考考我们这个系统，大家都觉得不太容易考倒它，所以最后决定我们可以拿出来给用户用一下。当然，肯定不是一百分，但是我们还是相对满意的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因为 Google 以前有那么多年积累下来的难题，用户在使用Google翻译时，可能当时觉得翻译得不好，他们就会有记录，然后发给我们。我们会把那些东西放进新的系统看看这次做得好不好，比如说把中国的一些歌词拿出来放进去看看翻译出来的结果会不会比原来好，其实那种测试主要是防止它说出一些不太好的话。我们都做了很多测试，所以我们觉得还是有信心的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;机器之心：我昨天晚上做了一个测试，我输入中文「我要下班」，结果翻译成「I want to work」。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;陈智峰：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;哈哈，这个我们也有收到反馈并修复了这个问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心原创，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Fri, 30 Sep 2016 11:39:19 +0800</pubDate>
    </item>
  </channel>
</rss>
