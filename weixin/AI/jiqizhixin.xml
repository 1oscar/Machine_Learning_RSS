<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器之心</title>
    <link>http://www.iwgc.cn/list/670</link>
    <description>人与科技的美好关系</description>
    <item>
      <title>重磅｜斯坦福「人工智能百年研究」首份报告：2030年的人工智能与生活（附全文编译下载）</title>
      <link>http://www.iwgc.cn/link/2538752</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自 Stanford&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：机器之心编辑部&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;em style="color: rgb(136, 136, 136); line-height: 1.75em; text-align: justify;"&gt;&lt;span&gt;本文节选自斯坦福大学「人工智能百年研究」的首份报告：《2030 年的人工智能与生活》，这篇报告是计划持续至少 100 年的研究系列中的第一篇。该报告&lt;/span&gt;&lt;/em&gt;&lt;em style="color: rgb(136, 136, 136); line-height: 1.75em; text-align: justify;"&gt;&lt;span&gt;描述了目前人工智能相关技术、法律以及道德上的挑战，并对产业界、学界、政界三方人士提供了人工智能技术、应用、政策上的指导与建议。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em style="color: rgb(136, 136, 136); line-height: 1.75em; text-align: justify;"&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="color: rgb(136, 136, 136); line-height: 1.75em; text-align: justify;"&gt;&lt;span&gt;「机器之心」于第一时间对报告进行了全文编译，但因微信字数限制无法全部展现，请点击「阅读原文」下载完整版中文报告。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;strong&gt;&lt;em style="color: rgb(136, 136, 136); line-height: 1.75em; text-align: justify;"&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;strong&gt;&lt;em style="color: rgb(136, 136, 136); line-height: 1.75em; text-align: justify;"&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;strong&gt;&lt;em style="color: rgb(136, 136, 136); line-height: 1.75em; text-align: justify;"&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;全文目录:&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;序言&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;概述&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一部分：人工智能是什么？&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;定义人工智能&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;人工智能研究趋势&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;第二部分：人工智能应用领域&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;交通&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;家庭/服务机器人&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;医疗&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;教育&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;低资源社区&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;公共安全与防护&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;就业与劳资&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;娱乐&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;第三部分：人工智能公共政策的预期与建议&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如今与未来的人工智能政策&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;附录：人工智能历史简述&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;序言&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2014 年秋季，人工智能百年研究（OneHundred Year Study）项目启动，这是一项对人工智能领域及其对人类、社区、社会影响的长期学术研究。这项研究包含使用人工智能计算系统的科学、工程和应用实现。监督该「百年研究」的常务委员会（Standing Committee）组建了一个研究小组（Study Panel）来每五年评估一次人工智能所处的状态——这是本项目的核心活动。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本研究小组要回顾从上次报告到现在这段时间人工智能的进展，展望未来潜在的进展并且描述这些进展对于技术、社会的挑战与机遇，涉及的领域包括：道德伦理、经济以及与人类认知兼容的系统设计等等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「百年研究」定期进行专家回顾的首要目标是：提供一个随着人工智能领域发展的关于人工智能及其影响的收集性的和连通的集合。这些研究希望能在人工智能领域的研究、发展以及系统设计方面、以及在帮助确保那些系统能广泛地有益于个人和社会的项目与政策上提供专业推断上的方向指南及综合评估。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这篇报告是计划持续至少 100 年的研究系列中的第一篇。常务委员会在 2015 年的暑期成立了一个研究小组来负责组建现在这个初始的研究小组，并任命了得克萨斯大学奥斯汀分校的教授 Peter Stone 担任该小组的主席。这个包含了 17 名成员的研究小组由人工智能学术界、公司实验室以及产业界的专家与了解人工智能的法律、政治科学、政治以及经济方面的学者组成，并于 2015 年秋季中期启动。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;参与者代表着不同的专业、地区、性别以及职业阶段。常务委员会广泛讨论了 Study Panel 相应的责任，包括人工智能最近的发展与在工作、环境、运输、公共安全、医疗、社区参与以及政府的潜在社会影响。委员会考虑多种聚焦研究的方式，包括调查子领域及其状态、研究特定的技术（例如机器学习与自然语言处理）以及研究特定的应用领域（例如医疗与运输运输）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;委员会最终选择了「2030 年的人工智能与生活（AI and Life in 2030）」为主题以强调人工智能的各种用途与影响的发生不是独立于彼此，也不独立于其他许多社会和技术上的发展。意识到了城市在大多数人类生活中的核心作用之后，我们将专注重点缩小到大多数人居住的大都市。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWib6Sw6RA7ddKj6ODvvgQgvOMeLBsYNRjpqV6aVePdY8OTYqs0coBFsNiaYyUXSN7PM8Yia8icWjicp8fQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;第一部分：什么是人工智能？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;a name="_Toc460619586" style="font-size: 14px; text-decoration: underline;"&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本节介绍了研究人员和从业者如何定义「人工智能」以及目前正在蓬勃发展的人工智能研究和应用领域。它提出了人工智能是什么和不是什么的定义，并介绍了一些当前人工智能研究的「热点」领域。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本节为第二部分的内容奠定了基础，第二部分阐述了人工智能在八个领域和在第三部分中的影响与未来，第三部分介绍了涉及人工智能设计和公共政策的问题，并提出在保护民主价值的同时如何鼓励人工智能创新的建议。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;h2 style="text-align: justify; line-height: 1.75em;"&gt;&lt;span&gt;&lt;strong&gt;1.定义人工智能&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;/h2&gt;&lt;p&gt;&lt;a name="_Toc460619587" style="font-size: 14px; text-decoration: underline;"&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;奇怪的是，人工智能缺乏一个精确的、被普遍接受的定义，这或许有助于该领域的加速成长、繁荣以及前进。虽然人工智能的从业者、研究人员和开发人员由一种粗略的方向感和一个「与它相处」的命令所引导，人工智能的定义仍然很重要，而 Nils J. Nilsson 就提供了一个有用的定义：「人工智能就是致力于让机器变得智能的活动，而智能就是使实体在其环境中有远见地、适当地实现功能性的能力。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从这个角度来看，对人工智能的表征取决于个人愿意「适当地」并「有远见地」为功能性提供合成软件和硬件的信用。一个简单的电子计算器比人类大脑进行的计算要快得多，而且几乎从来不出错。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;电子计算器智能吗？像 Nilsson 一样，研究小组以一种宽泛的视角来看待此问题，认为智力取决于一个多维频谱。根据这一观点，算术计算器和人脑之间的区别不是某一类，而是规模、速度、自主性和通用性的区别。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;同样的因素可以用来评估智能的其他各例——智能语音识别软件、动物大脑、汽车巡航控制系统、围棋程序、自动调温器——并将它们放置在频谱中的适当位置。虽然我们的宽泛解释把计算器列在了智能频谱中，但是如此简单的设备与今天的人工智能相比几乎没有相似之处。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从这个角度看，对人工智能的表征取决于个人愿意「适当地」并「有远见地」为功能提供合成软件和硬件的信用。一个简单的电子计算器比人脑计算快得多而且几乎从不出错。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能的边界已经远远走在前面，而计算器可以实现的功能只是当下的智能手机的百万分之一。目前人工智能开发人员正在改进、推广和扩大从当下的智能手机中所建立起来的智能。事实上人工智能领域是一个不断努力推动机器智能向前发展的过程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;具有讽刺意味的是，人工智能正在遭受失去话语权的长期灾难，最终不可避免地会被拉到边界内，即一个被称为「人工智能效应（AI effect）」或「奇怪悖论（odd paradox）」的重复模式——人工智能将一种新技术带到了普通大众中去，人们习惯了这种技术，它便不再被认为是人工智能，然后更新的技术出现了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;同样的模式将在未来继续下去。人工智能并没有「交付」一个惊雷般改变生活的产品。相反人工智能技术以一个连续的、进步的方式正在继续更好的发展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2.人工智能研究趋势&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;直到本世纪初，人工智能的吸引点主要在于它所传递的承诺，但在过去的十五年里，大多这样的承诺已经得到兑现。人工智能技术已经充斥了我们的生活。当它们成为了社会的一股中心力量时，该领域正在从仅仅建立智能系统，转向了建立有人类意识的、值得信赖的智能系统。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;几个因素加速了人工智能革命。其中最重要的是机器学习的成熟，部分由云计算资源和广泛普及的、基于 Web 的数据收集所支持。机器学习已经被「深度学习（deep learning）」急剧地向前推进了，后者是一种利用被称作反向传播的方法所训练的适应性人工神经网络的一种形式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;信息处理算法的这种性能飞跃一直伴随着用于基本操作的硬件技术的显著进步，比如感觉、感知和目标识别。数据驱动型产品的新平台和新市场，以及发现新产品和新市场的经济激励机制，也都促进了人工智能驱动型技术的问世。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所有这些趋势都推动着下文中所描述的「热门」研究领域。这种编辑只是想要通过某个或另一个度量标准来反映目前比其他领域得到更大关注的领域。它们不一定比其他领域更重要或更有价值。事实上目前的一些「热门」领域在过去几年中并不怎么流行，而其他领域可能在未来会以类似的方式重新出现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;大规模机器学习&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;许多机器学习的基本问题（如监督和非监督学习）是很好理解的。目前努力的一个重点是将现有算法扩展到更庞大的数据集上。例如鉴于传统方法能够负担得起若干遍数据集的处理，现代方法是为单次处理所设计；某些情况只认同非线性方法（那些只关注一部分数据的方法）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;深度学习&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;成功训练卷积神经网络的能力非常有益于计算机视觉领域，比如目标识别、视频标签、行为识别和几个相关变体的应用。深度学习也在大举进军感知方面的其他领域，如音频、语音和自然语言处理。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;强化学习&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;鉴于传统机器学习主要关注于模式挖掘，强化学习将重点转移到决策中，这种技术将有助于促进人工智能在现实世界中更深入地进入相关研究和实践领域。作为一种经验驱动型的序贯决策框架，强化学习已经存在了几十年，但是这个方法在实践中没有取得很大成功，主要是由于表征和缩放的问题。然而深度学习的出现为强化学习提供了「一贴强心剂」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;由谷歌 DeepMind 开发的计算机程序 AlphaGo 在五次对抗比赛中击败了人类围棋冠军，它最近所取得的成功在很大程度上要归功于强化学习。AlphaGo 是通过使用一个人类专家数据库来初始化一个自动代理的方法被训练的，但随后提炼的方法是通过大量地自我对抗游戏以及应用强化学习。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器人&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;至少在静态环境中，机器人导航在很大程度上被解决了。目前的努力是在考虑如何训练机器人以泛型的、预测性的方式与周围世界进行交互。互动环境中产生的一个自然要求是操纵，这是当下所感兴趣的另一个话题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;深度学习革命只是刚开始影响机器人，这在很大程度上是因为要获得大的标记数据集还很困难，这些数据集已推动了其他基于学习的人工智能领域。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;免去了标记数据需求的强化学习可能会有助于弥合这一差距，但是它要求系统在没有错误地伤害自己或其他系统的情况下能够安全地探索出一个政策空间。在可信赖的机器感知方面的进步，包括计算机视觉、力和触觉感知，其中大部分将由机器学习驱动，它们将继续成为推进机器人能力的关键。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;计算机视觉&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;计算机视觉是目前最突出的机器感知形式。它是受深度学习的兴起影响最大的人工智能子领域。直到几年前，支持向量机还是大多视觉分类任务所选择的方法。但是特别是在 GPU 中的大规模计算的汇合，使得更大数据集的可获得性（尤其是通过互联网）以及神经网络算法的改进导致了基准任务中能的显著提高（比如 ImageNet 中的分类器）。计算机首次能够比人类更好地执行一些（狭义定义的）视觉分类任务。目前的研究多是关注于为图像和视频自动添加字幕。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;自然语言处理&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;自然语言处理是另一个通常与自动语音识别一同被当做非常活跃的机器感知领域。它很快成为一种拥有大数据集的主流语言商品。谷歌宣布目前其 20% 的手机查询都是通过语音进行的，并且最近的演示已经证明了实时翻译的可能性。现在研究正在转向发展精致而能干的系统，这些系统能够通过对话而不只是响应程式化的要求来与人互动。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;协同系统&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;协同系统方面进行的是对模型和算法的研究，用以帮助开发能够与其他系统和人类协同工作的自主系统。该研究依赖于开发正式的协作模型，并学习让系统成为有效合作伙伴所需的能力。能够利用人类和机器的互补优势的应用正吸引到越来越多的兴趣——对人类来说可以帮助人工智能系统克服其局限性，对代理来说可以扩大人类的能力和活动。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;众包和人类计算&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在完成许多任务方面由于人类的能力是优于自动化方法的，因而在众包和人类计算方面，通过利用人类智力来解决那些计算机无法单独解决好的问题，该领域研究调查了增强计算机系统的方法，这项研究的提出仅仅是在大约 15 年前，现在它已经在人工智能领域确立了自己的存在。最有名的众包例子是维基百科，它是一个由网络公民维护和更新的知识库，并且在规模上和深度上远远超越了传统编译的信息源，比如百科全书和词典。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;众包专注于设计出创新的方式来利用人类智力。Citizen 科学平台激发志愿者去解决科学问题，而诸如亚马逊的 Mechanical Turk 等有偿众包平台，则提供对所需要的人类智力的自动访问。通过短时间内收集大量标记训练数据和/或人机交互数据，该领域的工作促进了人工智能的其它分支学科的进步，包括计算机视觉和自然语言处理。基于人类和机器的不同能力和成本，目前的研究成果探索出了它们之间理想的任务分离。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;算法博弈理论与 (基于) 计算机 (统计技术的) 社会选择&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;包括激励结构、人工智能的经济和社会计算维度吸引到了新的关注。自 20 世纪 80 年代初以来，分布式人工智能和多代理（multi-agent）系统就已经被研究了，于 20 世纪 90 年代末开始有显著起色，并由互联网所加速。一个自然的要求是系统能够处理潜在的不恰当激励，包括自己所感兴趣的人类参加者或公司，以及自动化的、基于人工智能的、代表它们的代理。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;备受关注的主题包括计算机制设计（computational mechanism design）（一种激励设计的经济理论，它寻求激励兼容的系统，其中输入会被如实报告）、(基于) 计算机 (统计技术的) 社会选择（computational social choice）（一种有关如何为替代品排列顺序的理论）、激励对齐信息获取（incentive aligned information elicitation）（预测市场、评分规则、同行预测）和算法博弈理论（algorithmic game theory）（市场、网络游戏和室内游戏的平衡，比如poker——它在近几年通过抽象技术和无遗憾学习（no-regret learning）已经取得了显著的进步）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;物联网（IoT）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;越来越多的研究机构致力于这样一个想法：一系列设备可以相互连接以收集和分享它们的感官信息。这些设备可以包括家电、汽车、建筑、相机和其他东西。虽然这就是一个技术和无线网络连接设备的问题，人工智能可以为了智能的、有用的目的去处理和使用所产生的大量数据。目前这些设备使用的是令人眼花缭乱的各种不兼容的通信协议。人工智能可以帮助克服这个「巴别塔」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;神经形态计算&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;传统计算机执行计算的冯诺依曼模型，它分离了输入/输出、指令处理和存储器模块。随着深度神经网络在一系列任务中的成功，制造商正在积极追求计算的替代模型——特别是那些受到生物神经网络所启发的——为了提高硬件的效率和计算系统的稳定性的模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前这种「神经形态的（neuromorphic）」计算机尚未清楚地显示出巨大成功，而是刚开始有望实现商业化。但可能它们在不久的将来会变成寻常事物（即使仅作为冯诺依曼所增加的兄弟姐妹们）。深度神经网络在应用景观中已经激起了异常波动。当这些网络可以在专门的神经形态硬件上被训练和被执行，而不是像今天这样在标准的冯诺依曼结构中被模拟时，一个更大的波动可能会到来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;总体趋势以及人工智能研究的未来&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数据驱动型范式的巨大成功取代了传统的人工智能范式。诸如定理证明、基于逻辑的知识表征与推理，这些程序获得的关注度在降低，部分原因是与现实世界基础相连接的持续挑战。规划（Planning）在七十和八十年代是人工智能研究的一根支柱，也受到了后期较少的关注，部分原因是它强烈依赖于建模假设，难以在实际的应用中得到满足。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;基于模型的方法——比如视觉方面基于物理的方法和机器人技术中的传统控制与制图——已经有很大一部分让位于通过检测手边任务的动作结果来实现闭环的数据驱动型方法。即使最近非常受欢迎的贝叶斯推理和图形模式似乎也正在失宠，被数据和深度学习显著成果的洪流所淹没。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;研究小组预计在接下来的十五年中，会有更多关注集中在针对人类意识系统的开发上，这意味着它们是明确按照要与之互动的人类特点来进行建模与设计的。很多人的兴趣点在于试图找到新的、创造性的方法来开发互动和可扩展的方式来教机器人。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此外在考虑社会和经济维度的人工智能时，物联网型的系统——设备和云——正变得越来越受欢迎。在未来的几年中，对人类安全的、新的感知/目标识别能力和机器人平台将会增加，以及数据驱动型产品数量与其市场规模将会变大。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;研究小组还预计当从业者意识到纯粹的端到端深度学习方法的不可避免的局限性时，会重新出现一些人工智能的传统形式。我们不鼓励年轻的研究人员重新发明理论，而是在人工智能领域以及相关领域（比如控制理论、认知科学和心理学）的第一个五十年期间，保持对于该领域多方面显著进展的觉察。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;第二部分：人工智能在各领域的应用&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然人工智能的很多研究和应用会基于一些通用技术，比如说机器学习，但在不同的经济和社会部门还是会有所区别。我们称之为不同的领域（domain），接下来的这部分将介绍人工智能研究和应用的不同类型，以及影响和挑战，主要有八个方面：交通、家庭服务机器人、医疗健康、教育、低资源社区、公共安全、工作和就业、娱乐。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;基于这些分析，我们还预测了一个有代表性的北美城市在未来 15 年的趋势。与人工智能的流行文化中的典型叙述不同，我们寻求提供一个平衡的观点来分析，人工智能是如何开始影响我们日常生活的，以及从现在到 2030 年，这些影响将如何发展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1.交通&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;交通可能会成为首批几个特定应用领域之一，在这些领域，大众需要对人工智能系统在执行危险任务中的可靠性和安全性加以信任。自动化交通会很快司空见惯，大多数人在嵌入人工智能系统的实体交通工作的首次体验将强有力的影响公众对人工智能的感知。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;智能汽车&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;交通规划&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;即时交通&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;人机交互&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2.家庭&lt;/span&gt;&lt;span&gt;服务机器人&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;过去十五年中，机器人已经进入了人们的家庭。但应用种类的增长慢得让人失望，与此同时，日益复杂的人工智能也被部署到了已有的应用之中。人工智能的进步常常从机械的革新中获取灵感，而这反过来又带来了新的人工智能技术。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;未来十五年，在典型的北美城市里，机械和人工智能技术的共同进步将有望增加家用机器人的使用和应用的安全性和可靠性。特定用途的机器人将被用于快递、清洁办公室和强化安全，但在可预见的未来内，技术限制和可靠机械设备的高成本将继续限制狭窄领域内应用的商业机会。至于自动驾驶汽车和其它新型的交通机器，创造可靠的、成熟的硬件的难度不应该被低估。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;真空吸尘器&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;家庭机器人 2030&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;3.医疗&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;a name="_Toc460619593" style="font-size: 14px; text-decoration: underline;"&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对人工智能而言，医疗领域一直被视为一个很有前景的应用领域。基于人工智能的应用在接下来的几年能够为千百万人改进健康结果和生活质量，但这是在它们被医生、护士、病人所信任，政策、条例和商业障碍被移除的情况下。主要的应用包括临床决策支持、病人监控、辅导、在外科手术或者病人看护中的自动化设备、医疗系统的管理。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;近期的成功，比如挖掘社交媒体数据推断潜在的健康风险、机器学习预测风险中的病人、机器人支持外科手术，已经为人工智能在医疗领域的应用扩展出了极大的应用可能。与医学专家和病人的交互方法的改进将会是一大挑战。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;至于其他领域，数据是一个关键点。在从个人监护设备和手机 App 上、临床电子数据记录上收集有用的数据方面，我们已经取得了巨大的进展，从协助医疗流程和医院运行的机器人那里收集的数据可能较少一些。但使用这些数据帮助个体病人和群体病人进行更精细的针对和治疗已经被证明极其的困难。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;研究和部署人工智能应用已经被过时的条例和激励机制拉扯后腿。在这样大型的、复杂的系统中，贫乏的人机交互方法和固有的难题以及部署技术的风险也阻碍了人工智能在医疗的实现。减少或者移除这些障碍，结合目前的创新，有潜力在接下来几年为千百万人极大的改进健康结果和生活质量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;临床应用&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;医疗分析&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;医疗机器人&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;移动健康&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;老年看护&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;4.教育&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;a name="_Toc460619594" style="font-size: 14px; text-decoration: underline;"&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在过去的十五年间，教育界见证了为数众多的人工智能科技的进步。诸如 K-12 线上教育以及大学配套设备等等应用已经被教育家和学习者们广泛利用。尽管素质教育还是需要人类教师的活跃参与，但人工智能在所有层面上都带来了强化教育的希望，尤其是大规模定制化教育。如何找到通过人工智能技术来最优化整合人类互动与面对面学习将是一个关键性的挑战，这一点医疗行业也是如此。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器人早已经成为了广为欢迎的教育设备，最早可以追溯到 1980 年 MIT Media Lab 所研制出的 Lego Mindstorms。智能辅导系统（ITS）也成为了针对科学、数学、语言学以及其他学科相匹配的学生互动导师。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;自然语言处理，尤其是在与机器学习和众包结合以后，有力推进了线上学习，并让教师可以在扩大教室规模的同时还能做到解决个体学生的学习需求与风格。大型线上学习的系统所得的数据已经为学习分析产生了迅速增长的动力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是，学院与大学采用人工智能技术的步伐依然很缓慢，主要是由于资金的缺乏，以及其可以帮助学生达成学习目标的有力证据。一个典型美国北部城市的未来五十年，智能导师与其他人工智能技术帮助教师在课堂或家中工作的规模很有可能会显著扩大，因为意愿学习是基于虚拟现实的应用。但是计算机为基础的学习系统将无法完全替代学校里的教师们。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;教育机器人&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;智能辅导系统（ITS）与线上学习&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;学习分析&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;挑战和机遇&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;更广大的社会成果&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;自广大人民难以获得教育的国家，如果这些群体有可以获取在线教育的工具，那么在线资源将会产生重要的积极影响。在线教育资源的发展应该能让支持国际教育项目的基金会可以通过提供工具和相对简单的使用培训来更轻松地提供素质教育。比如说，针对 iPad 开发出了大量的、且大部分免费的教育应用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在消极的一面，现在学生已有把自己的社会接触限制在电子设备上的趋势了，他们在网络程序的互动上花费了大量时间，却没有进行社会接触。如果教育也越来越多地通过网络进行，那么在学生的社会发展阶段缺乏与同龄人有规律的面对面接触会带来怎样的影响呢？特定的技术已经表明这会产生在神经方面的影响。另一方面，自闭症儿童已经开始从与人工智能系统的互动中受益了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;5.低资源社区&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能存在许多机会去改善生活于一个典型北美城市的低资源社区中的人民生活状况——事实上在某些情况下已经有所改变。了解这些人工智能的直接贡献也可能会激发对于发展中国家最为贫穷的地区的潜在贡献。在人工智能的数据收集过程中并没有对这个人群的显著关注，而且传统上人工智能资助者在缺乏商业应用的研究中表现得投资乏力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有了有针对性的激励和资金优先次序，人工智能技术可以帮助解决低资源社区的需求。萌芽中的努力是有希望的。人工智能可能会有有助于对抗失业和其他社会问题带来的恐惧，它或许会提供缓解措施和解决方案，特别是通过受影响的社区以与其建立信任的方式来实现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;6.公共安全与防护&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;城市已经为公共安全和防护部署人工智能技术了。到 2030 年, 典型的北美城市将在很大程度上依赖它们。这些措施包括可以检测到指向一个潜在犯罪的异常现象的监控摄像机、无人机和预测警务应用。与大多数问题一样，好处与风险并存。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;获得公众信任是至关重要的。虽然会存在一些合理的担心，即与人工智能合作的警务可能会在某些情况下变得霸道或是无处不在，而相反的情况也是可能的。人工智能可能使警务变得更有针对性并只在需要时被使用。而且假设经过仔细的部署，人工智能也可能有助于消除一些人类决策中固有的偏见。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于人工智能分析学更成功的一个应用是检测白领犯罪，比如信用卡诈骗罪。网络安全（包括垃圾邮件）是一个被广泛关注的问题，而机器学习也对其有所影响。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能工具也可能被证明有助于警察管理犯罪现场或是搜索和救援活动，它可以帮助指挥官排列任务的优先次序以及分配资源，尽管这些工具还没有为这些活动的自动化做好准备。在一般的机器学习尤其是在转换学习中的改进——在新情境中基于与过去情况的相似性而加快学习——可能有利于这样的系统。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;7.就业与劳资&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;a name="_Toc460619596" style="font-size: 14px; text-decoration: underline;"&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尽管人工智能很有可能会对典型北美城市的就业和工作场所产生深远的影响，但对当前的影响我们目前还难以作出评估——是积极的还是消极的。在过去十五年，由于经济衰退和日益的全球化，尤其是中国参与到了世界经济中，就业状况已经发生了改变，非人工智能的数字技术也发生了很大的变化。自 1990 年代以来，美国经历了生产率和 GDP 的连续增长，但平均收入却停滞不前，就业人口比率也已经下降。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有一些数字技术有重大影响（好的影响或坏的影响）的行业的显著案例，而在一些其它的行业，自动化将很有可能能在不久的将来发生重大的改变。许多这些改变已经得到了「例行的」数字技术的推动，其中包括企业资源规划、网络化、信息处理和搜索。理解这些改变应该能为人工智能影响未来劳动力需求的方式（包括技能需求的改变）提供见解。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;到目前为止，数字技术已经给中等技能的工作（比如旅行代理）带来了更大的影响，而不是非常低技能或非常高技能的工作。另一方面，数字系统所能完成的任务的范围正随着人工智能的演进而提升，这很可能会逐渐增大所谓的「例行任务」的范围。人工智能也正向高端的领域蔓延，包括一些机器之前无法执行的专业服务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了获得成功，人工智能创新将需要克服可以理解的人们对被边缘化的恐惧。在短期内，人工智能很有可能会取代任务，而非工作，同时还将会创造新类型的工作。但新类型的工作比将可能失去的已有工作更难以想象。就业领域的变化通常是渐进的，不会出现剧烈的过渡。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;随着人工智能进入工作场所，这很有可能是一个持续的趋势。影响的范围也将扩大，从少量的替代或增强到完全的替代。比如说，尽管大部分律师的工作还没被自动化，但人工智能在法律信息提取和主题建模方面的应用已经自动化了一部分第一年工作的律师新人的工作。在不远的将来，包括放射科医生到卡车司机到园丁等许多类型的工作都可能会受到影响。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能也可能会影响工作场所的大小和位置。许多组织和机构很庞大的原因是他们所执行的功能只能通过增加人力来扩大规模，要么是「横向」扩展地理区域，要么是「纵向」增多管理层级。随着人工智能对许多功能的接管，扩展不再意味着会带来大型的组织。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;许多人已经指出一些知名的互联网公司只有很少数量的员工，但其它公司并不是这样。人类企业可能存在一个自然的规模大小，在这样的企业中，CEO 能够认识公司里的每一个人。通过将创造有效地外包给人工智能驱动的劳动力市场，企业会倾向于自然的大小。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能也将创造工作，特别是在某些行业中，通过使某些特定任务更重要，以及通过产生新的交互模型创造新类型的工作。复杂的信息系统可被用于创造新的市场，这往往会带来降低门槛和增加参与的影响——从应用商店到 AirBnB 再到 taskrabbit。人工智能界有一个活跃的研究社区在研究创造新市场和使已有市场更高效地运作的进一步的方式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尽管工作本身有内在的价值，但大部分人工作是为了购买他们看重的商品和服务。因为人工智能系统可以执行之前需要人力的工作，因此它们可以导致许多商品和服务的成本下降，实实在在地让每个人都更富有。当正如当前的政治辩论中所给出的例子一样，失业对人们的影响比对散布的经济效益的影响更显著——尤其是那些直接受其影响的人；而不幸的是，人工智能常常被视作是工作的威胁，而不是生活水平的提升。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人们甚至在某些方面存在恐惧——害怕人工智能会在短短一代人的时间内迅速取代所有的人类工作，包括那些需要认知和涉及到判断的工作。这种突变是不太可能发生的，但人工智能会逐渐侵入几乎所有就业领域，这需要在计算机可以接管的工作上替换掉人力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能对认知型人类工作的经济影响将类似于自动化和机器人在制造业工作上对人类的影响。许多中年工人失去了工厂里的高薪工作以及伴随这个工作的家庭和社会中的社会经济地位。长期来看，一个对劳动力的更大影响是失去高薪的「认知型」工作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;随着劳动力在生产部门的重要性的下降（与拥有知识资本相比），大多数市民可能会发现他们的工作的价值不足以为一种社会可以接受的生活标准买单。这些变化将需要政治上的，而非单纯经济上的响应——需要考虑应该配置怎样的社会安全网来保护人们免受经济的大规模结构性转变的影响。如果缺少了缓解政策，这些转变的一小群受益者将成为社会的上层。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;短期来看，教育、再训练和发明新的商品和服务可以减轻这些影响。更长期来看，目前的社会安全网可能需要进化成更好的服务于每个人的社会服务，例如医疗和教育或有保障的基本收入。事实上，瑞士和芬兰等国家已经在积极地考虑这些措施了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能可能会被认为是一种财富创造的完全不同的机制，每个人都应该从全世界人工智能所生产的财富中分得一部分。对于人工智能技术所创造的经济成果的分配方式，相信不久之后就会开始出现社会争议了。因为传统社会中由孩子支持他们年老的父母，也许我们的人工智能「孩子」也应该支持我们——它们的智能的「父母」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;8.娱乐&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;a name="_Toc460619597" style="font-size: 14px; text-decoration: underline;"&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;随着过去十五年互联网的爆发式增长，很少有人能想象没有它的生活。在人工智能的驱动下，互联网已经将用户生成的内容作为了信息和娱乐的一个可行的来源。Facebook 这样的社交网络现在几乎已经无处不在，而且它们也成为了社会互动和娱乐的个性化渠道——有时候会损害人际交往。WhatsApp 和 Snapchat 等应用可以让智能手机用户与同伴保持「接触」和分享娱乐和信息源。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在《第二人生》这样的在线社区和《魔兽世界》这样的角色扮演游戏中，人们想象在虚拟世界中有一个虚拟的存在。亚马逊 Kindle 这样的专用设备已经重新定义了打发时间的要领。现在只需手指点点划划几下，就可以浏览和获取书籍了；一个口袋大小的设备就可以存储成千上万本书，而阅读体验基本上可手持的纸质书差不多。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在我们有了共享和浏览博客、视频、照片和专题讨论的可信平台，此外还有各种各样用户生成的内容。为了在互联网的规模上运行，这些平台必须依赖现在正被积极开发的技术，其中包括自然语言处理、信息检索、图像处理、众包和机器学习。比如，现在已经开发出了协同过滤（collaborative filtering）这样的算法，它可以基于用户的人口统计学细节和浏览历史推荐相关的电影、歌曲或文章。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了跟上时代的步伐，传统的娱乐资源也已经开始拥抱人工智能。正如书和电影《点球成金》中给出的例子，职业运动现在已经转向了密集的量化分析。除了总体表现统计，赛场上的信号也可以使用先进的传感器和相机进行监控。用于谱曲和识别音轨的软件已经面世。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;来自计算机视觉和 NLP 的技术已被用于创建舞台表演。即使非专业用户也可以在 WordsEye 等平台上练习自己的创造力，这个应用可以根据自然语言文本自动生成 3D 场景。人工智能也已经被用于协助艺术品的历史搜索，并在文体学（stylometry）得到了广泛的应用，最近还被用在了绘画分析上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人类对人工智能所驱动的娱乐的热情是很令人惊讶的，但也有人担心这会导致人与人之间的人际交互减少。少数人预言说人们会因为在屏幕上花费了太多时间而不再与人互动。孩子们常常更愿意在家里快乐地玩他们的设备，而不愿意出去和他们的朋友玩耍。人工智能会使娱乐更加交互式，更加个性化和更有参与感。应该引导一些研究来理解如何利用这些性质为个人和社会利益服务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;h1 style="text-align: center; line-height: 1.75em;"&gt;&lt;strong&gt;第三部分：人工智能公共政策的前景与建议&lt;/strong&gt;&lt;/h1&gt;&lt;p&gt;&lt;a name="_Toc460619598" style="font-size: 14px; text-decoration: underline;"&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能应用的目标必须是对社会有价值。我们的政策建议也会遵循这个目标，而且即便这个报告主要关注的是 2030 年的北美城市，建议依然广泛适用于其他城市，同时不受时间限制。一些提升解读和人工智能系统能力并参与其使用的策略可以帮助建立信任，同时防止重大失败。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在增强和提升人类能力和互动时需要小心，还有避免对不同社会阶层的歧视。要强调多做鼓励这个方向以及沟通公共政策探讨的研究。鉴于美国目前的产业监管，需要新的或重组的法律和政策来应对人工智能可能带来的广泛影响。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;政策不需要更多也不要更严，而是应该鼓励有用的创新，生成并转化专业知识，并广泛促进企业与公民对解决这些技术带来的关键社会问题的责任感。长期来看，人工智能将会带来新财富，整个社会也要探讨如何分配人工智能技术带来的经济成果的分配问题。&lt;/span&gt;&lt;/p&gt;&lt;h2 style="text-align: justify; line-height: 1.75em;"&gt;&lt;a name="_Toc460619599" style="font-size: 14px; text-decoration: underline;"&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/a&gt;&lt;/h2&gt;&lt;h2 style="text-align: justify; line-height: 1.75em;"&gt;&lt;span&gt;&lt;strong&gt;如今以及未来的人工智能政策&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;/h2&gt;&lt;p&gt;&lt;a name="_Toc460619599" style="font-size: 14px; text-decoration: underline;"&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了帮助解决个人和社会对快速发展的人工智能技术产生的忧虑，该研究小组提供了三个一般性政策建议。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 在所有层级的政府内，制定一个积累人工智能技术专业知识的程序。有效的监管需要更多的能理解并能分析人工智能技术、程序目标以及整体社会价值之间互动的专家。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;缺少足够的安全或其他指标方面的专业技术知识，国家或地方政府官员或许或拒绝批准一个非常有前途的应用。或者缺少足够训练的政府官员可能只会简单采纳行业技术专家的说法，批准一个未经充分审查的敏感的应用进入市场。不理解人工智能系统如何与人工行为和社会价值互动，官员们会从错误的角度来评估人工智能对项目目标的影响。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 为研究人工智能的平等、安全、隐私和对社会的影响扫清感知到的和实际的障碍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在一些相关的联邦法律中，如计算机欺诈和滥用法案（Computer Fraud and Abuse Act）和数字千年版权法的反规避条款（theanti-circumvention provision of the Digital Millennium Copyright Act），涉及专有的人工智能系统可能被如何逆向向工程以及被学者、记者和其他研究人员评价的内容还很模糊。当人工智能系统带来了一些实质性后果需要被审查和追究责任时，这些法律的研究就非常重要了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3. 为人工智能社会影响的跨学科研究提供公共和私人资金支持。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从整个社会来看，我们对人工智能技术的社会影响的研究投入不足。资金要投给那些能够从多角度分析人工智能的跨学科团队，研究范围从智能的基础研究到评估安全、隐私和其他人工智能影响的方法。一下是具体问题：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当一辆自动驾驶汽车或智能医疗设备出现失误时，应该由谁来负责？如何防止人工智能应用产生非法歧视？谁来享有人工智能技术带来的效率提升的成果，以及对于那些技能被淘汰的人应该采取什么样的保护？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;随着人工智能被越来越广泛和深入地整合到工业和消费产品中，一些领域中需要调整现有的建立监管制度以适应人工智能创新，或者在某些情况下，根据广泛接受的目标和原则，从根本上重新配置监管制度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在美国，已经通过各种机构将监管具体到各个行业。在设备中使用人工智能实现医疗诊断和治疗由食品药品监督管理局（FDA）监管，包括定义产品类型和指定产生方法，还有软件工程的标准。无人机在管制空域中的使用由美国联邦航空局（FAA）监管。面向消费者的人工智能系统将由联邦贸易委员会（FTC）监管。金融市场使用的人工智能技术，如高频交易，由证券交易委员会（SEC）监管。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除了针对具体行业制定监管的方法外，「重要基础设施」中定义模糊和广泛的监管类别可能适用于人工智能应用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;鉴于目前美国行政法结构，短期内制定出全面的人工智能政策法规似乎不太可能。但是，可以根据人工智能在各种情境中可能出现的法律和政策问题，广泛列出多个类别。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;隐私&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;创新政策&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;责任（民事）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;责任（刑事）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;代理&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;认证&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;劳动力&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;税务&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;政治&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;未来的指导原则&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;面对人工智能技术将带来的深刻变化，要求「更多」和「更强硬」的监管的压力是不可避免的。对人工智能是什么和不是什么的误解（尤其在这个恐慌易于散布的背景下）可能引发对有益于所有人的技术的反对。那将会是一个悲剧性的错误。扼杀创新或将创新转移到它处的监管方法同样也只会适得其反。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;幸运的是，引导当前数字技术的成功监管原则可以给我们带来指导。比如，一项最近公布的多年研究对比了欧洲四个国家和美国的隐私监管，其结果却很反直觉。西班牙和法国这样的有严格的详细法规的国家在企业内部孕育出了一种「合规心态（compliance mentality）」，其影响是抑制创新和强大的隐私保护。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些公司并不将隐私保护看作是内部责任，也不会拿出专门的员工来促进其业务或制造流程中的隐私保护，也不会参与必需范围之外的隐私倡议或学术研究；这些公司只是将隐私看作是一项要满足规范的行为。他们关注的重点是避免罚款或惩罚，而非主动设计技术和采纳实际技术来保护隐私。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相对地，美国和德国的监管环境是模糊的目标和强硬的透明度要求和有意义的执法的结合，从而在促进公司将隐私看作是他们的责任上做得更加成功。广泛的法律授权鼓励企业发展执行隐私控制的专业人员和流程、参与到外部的利益相关者中并采用他们的做法以实现技术进步。对更大的透明度的要求使民间社会团队和媒体可以变成法庭上和法庭外的公共舆论中的可靠执法者，从而使得隐私问题在公司董事会上更加突出，这又能让他们进一步投资隐私保护。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在人工智能领域也是一样，监管者可以强化涉及内部和外部责任、透明度和专业化的良性循环，而不是定义狭窄的法规。随着人工智能与城市的整合，它将继续挑战对隐私和责任等价值的已有保护。和其它技术一样，人工智能也可以被用于好的或恶意的目的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这份报告试图同时强调这两方面的可能性。我们急切地需要一场重要的辩论：如何最好地引导人工智能以使之丰富我们的生活和社会，同时还能鼓励这一领域的创新。应该对政策进行评估，看其是否能促进人工智能所带来的益处的发展和平等共享，还是说会将力量和财富集中到少数权贵的手里。而因为我们并不能完美清晰地预测未来的人工智能技术及其所将带来的影响，所以相关政策一定要根据出现的社会难题和线索不断地重新评估。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;截至本报告发布时，重要的人工智能相关的进展已经在过去十五年内给北美的城市造成了影响，而未来十五年还将有更大幅度的发展发生。最近的进展很大程度是由于互联网所带来的大型数据集的增长和分析、传感技术的进步和最近的「深度学习」的应用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;未来几年，随着公众在交通和医疗等领域内与人工智能应用的遭遇，它们必须以一种能构建信任和理解的方式引入，同时还要尊重人权和公民权利。在鼓励创新的同时，政策和流程也应该解决得到、隐私和安全方面的影响，而且应该确保人工智能所带来的好处能得到广泛而公正的分配。如果人工智能研究及其应用将会给 2030 年及以后的北美城市生活带来积极的影响，那么这样做就是非常关键的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;点击「阅读原文」，下载完整版中文报告↓↓↓&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;</description>
      <pubDate>Fri, 02 Sep 2016 23:54:36 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 技术和产品二重奏：搜狗如何演绎「自然交互和知识计算」</title>
      <link>http://www.iwgc.cn/link/2538753</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心原创&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：赵云峰&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;苹果 Siri 的推出让大众开始对语音交互有了初步概念，而这几年深度学习的发展更是使语音识别准确率获得了质的提升。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1976 年，Reddy 在一篇关于当时语音识别最高水平的综述文章中大胆预测：未来 10 年内有望实现成本为 20,000 美元的联网语音系统。虽然超出了预计时间，但研究人员最终不仅达到了目标，而且建立系统的成本低得多并继续大幅下降。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今天，在很多智能手机里，业内提供了明显超出 Reddy 预测的免费语音识别服务。&amp;nbsp;从某种程度上来看，目前的语音识别技术已然成熟，我们已经习惯在家居、车载等某些场景下去使用语音，众多拥有语音识别技术的公司也开始把语音和人机自然对话当做下一代交互方式去豪赌未来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但就像语音识别在过去几十年的发展路径一样，技术和基础研究的进步是需要循序渐进的。&amp;nbsp;一方面，我们需要通过更多创新的方法来进行语音识别的基础研究，以尽可能提高准确率，如同IBM 曾将英语会话词错误率降低至 6.9% 。另一方面，前沿技术研究到实际应用需要一个很长的过程，我们也不可能等到语音识别的准确率达到 100% 之后再将其应用，而是在当前成熟技术的最高水平下，通过产品设计去让技术落地，解决用户需求问题。通过应用场景的设计和产品的创新去弥补技术的不足，在依靠技术的同时，应该更多的以产品为导向。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;纵观整个互联网行业，可以说搜狗作为一家技术型公司，在人工智能领域一直依靠实践来获取更多的经验，从而提升产品使用体验。&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;人工智能=自然交互+知识计算&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;关于人工智能，搜狗将其总结为两点，即「自然交互和知识计算」。在交互方面，&lt;span&gt;搜狗语音交互技术中心负责人&lt;/span&gt;王砚峰认为语音和图像已经具有一定的成熟度，除了向更加成熟的方向发展外，未来也会将更多的传感技术以及传感器加入到交互中，进一步推动交互技术的发展。同时，语义理解和对话也是交互方面的核心能力，因为不能只有「耳朵眼睛」没有「大脑」；在信息获取方面，王砚峰认为知识计算和逻辑推理会让当前的搜索形态发生变化，即从单纯文字的检索，到理解搜索需求并且从网页中抽取知识反馈用户。从而提升搜索体验，同时帮助用户更自然的获取信息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWib6Sw6RA7ddKj6ODvvgQgvO0JfRn3nSVR97x3SCrxqcHSoDgtxwF9apnUFuY753oPnL2faw8B2Tew/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「语音识别技术经过这几年的快速发展，准确率有了非常大的提升。但即使如此，当前语音识别准确率仍然做不到 100% ，而语音识别一旦出错，用户修改成本就会异常的高，从而反过来提高了用户使用语音的门槛，」王砚峰表示，「于是我们就去想，能不能结合用户使用语音的场景，通过产品创新进一步提升语音识别的效果，弥补技术发展的不足。」所以，搜狗推出了语音识别纠错功能，当语音识别发生错误时，可以让用户通过语音交互去修改错误，这样就大大提升了语音交互的体验和使用效率。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;支撑这个功能有两方面技术，一是需要语音识别本身的准确率，二是需要强大的语义理解能力，「就是能够听懂用户想改什么以及怎么改。&lt;/span&gt;&lt;span&gt;为了降低用户使用这个功能的学习成本，需要做的就是能够支持用户各种修改的表达，用户可以说『把第一个字删掉』，也可以说『将第一个字删掉』，『删除第一个字』等各种其他表达方法。我们追求的就是让用户在修改的时候，平时对人是怎么描述修改的，对机器就怎么描述。这才是用户最自然的交互方式。」王砚峰解释到。&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;用「最自然的交互方式」进行纠错还体现在用户可以去描述某个文字，比如机器能够听懂「立早章」和「女字旁的她」这样复杂的语言命令，而实现这个功能则是和搜狗在输入法的积累密不可分。「这方面搜狗输入法还是带给了我们先天的优势，」王砚峰说，「我们输入法具有基础的拆字库，知道一个字是如何拆开的，同时我们也有大量的用户表达数据，通过数据挖掘，是可以知道用户日常表达中如何描述一个字的。这两个知识串起来，就能够让我们知道，用户会用『立早章』来描述『章』这个字，于是就把这个知识加入到我们的知识库中。」&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;什么才是未来的内容获取方式？&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;拥有技术基础，再加上对应用场景理解的产品理念，那语音纠错这个功能显然就变成了解决刚需的通用工具，因为整个行业在语音识别准确率未能达到100%的情况下，只要处于语音输入的场景下，势必都需要这样的技术，不仅能够解放用户的双手，同时在一定程度上提高了用户的使用效率。「车内导航的时候，利用它去修改语音识别错误的导航目的地，真正的解放用户双手；在客厅中，比如电视遥控器和智能音箱这种没有屏幕的设备，甚至只能通过语音修改来进行错误的修正了。所以但凡语音有价值的场景，语音修改就同等的具有价值，」王砚峰说。&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;王砚峰认为，语音纠错这个功能只是人工智能技术和产品理念结合的一个案例，为了帮助用户更方便的进行信息的表达和获取，属于这条路径上的技术领域，都是搜狗需要重点发力的方向。&amp;nbsp;因此，除了语音和语义理解，搜狗在图像等方面也在进行布局。一方面致力于对未来主流技术的布局和追求，另一方面也使得现有核心产品向未来更智能的方向演进。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心原创，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;</description>
      <pubDate>Fri, 02 Sep 2016 23:54:36 +0800</pubDate>
    </item>
    <item>
      <title>一周论文|  ACL 2016 十篇论文：Logic Form、NMT、Summarization、QA、Chatbot等</title>
      <link>http://www.iwgc.cn/link/2538754</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;Paper Weekly&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;微信公众号：paperweekly&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;世界顶级语言学会议 ACL 2016 已经落下帷幕，机器之心发布了多篇关于此次会议的文章：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717202&amp;amp;idx=1&amp;amp;sn=56d10fceea3211e325d85a3aecb0a7e2&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717202&amp;amp;idx=1&amp;amp;sn=56d10fceea3211e325d85a3aecb0a7e2&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: underline;"&gt;&lt;span&gt;深度 | 自然语言处理顶级会议ACL2016即将召开，10大优秀论文先睹为快（附论文）&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718072&amp;amp;idx=2&amp;amp;sn=dc0f5e9ac4ca943afe91ea8d4e08f78c&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718072&amp;amp;idx=2&amp;amp;sn=dc0f5e9ac4ca943afe91ea8d4e08f78c&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: underline;"&gt;&lt;span&gt;重磅 | 自然语言顶级会议 ACL 2016 开幕，谷歌18篇参选论文概览（附论文）&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718160&amp;amp;idx=2&amp;amp;sn=9e3e0dd83103ce15ecabc0a9cae58d0a&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718160&amp;amp;idx=2&amp;amp;sn=9e3e0dd83103ce15ecabc0a9cae58d0a&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: underline;"&gt;&lt;span&gt;业界 | ACL 2016公布三项大奖：乔姆斯基学生Joan Bresnan获终身成就奖（附获奖论文）&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718106&amp;amp;idx=2&amp;amp;sn=93aceb9b6e4a0772bbaf9257a4def3d2&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718106&amp;amp;idx=2&amp;amp;sn=93aceb9b6e4a0772bbaf9257a4def3d2&amp;amp;scene=21#wechat_redirect"&gt;深度 | 微软NLP团队齐聚ACL 2016，自然语言技术逼近人类对话水平（附论文）&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此次带来的是 &lt;span&gt;Paper Weekly 的 ACL 论文解读。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本期分享的 topic 是ACL 2016，一共10篇文章，涉及的内容包括：Logic Form、NMT、Summarization、QA、Chatbot等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;h1&gt;&lt;span&gt;&lt;a target="_blank" rel="external" style="font-size: 14px; text-decoration: underline;"&gt;Sentence Rewriting for Semantic Parsing&lt;/a&gt;&lt;/span&gt;&lt;/h1&gt;&lt;h1&gt;&lt;br/&gt;&lt;/h1&gt;&lt;h2&gt;&lt;span&gt;关键词&lt;/span&gt;&lt;/h2&gt;&lt;h2&gt;&lt;span&gt;Semantic Parsing、Sentence Rewriting&lt;/span&gt;&lt;/h2&gt;&lt;h2&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/h2&gt;&lt;h2&gt;&lt;span&gt;来源&lt;/span&gt;&lt;/h2&gt;&lt;h2&gt;&lt;span&gt;ACL 2016&lt;/span&gt;&lt;/h2&gt;&lt;h2&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/h2&gt;&lt;h2&gt;&lt;span&gt;问题&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;语义分析的表现形式是将自然语言（natural language）转化成逻辑形式（logic form）。因语言表达多样性的问题导致两者间存在mismatch problem。&lt;/span&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/h2&gt;&lt;h2&gt;&lt;span&gt;文章思路&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;先给出一个语义分析的例子：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWib6Sw6RA7ddKj6ODvvgQgvOPnVuociaqn0m9byKcsP7HHESRFyDoicSAvV3dwoCcdfaqVxf5s6UY8JQ/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;给句子换个表达（How many people live in Berlin?），对应的逻辑形式就变得复杂很多(count(λx.person(x)∧live(x,Berlin)))。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;作者认为，原句子和逻辑形式之间存在的结构不匹配导致了语义分析的困难，而结构不匹配的核心是词汇的不匹配。作者率先提出先把句子重写再转成目标逻辑形式的语义分析方案，如下图：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWib6Sw6RA7ddKj6ODvvgQgvOPIfBUCoGddKl0y32BnTUosibSJvUQBGMrFibqt1zt64fGLFC5pHwibvPQ/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;针对词汇不匹配问题的两种情况分别给出基于字典和基于模板两种方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1）问题一：1-N mismatch&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;是指一个单词（word）对应一个复合的逻辑形式（compound formula）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;例如daughter对应 child ∩ female。但在开放域的知识体系下，制定这些规则十分困难。于是作者提出将句子中的常用名词替换为字典（Wiktionary）中的解释，比如先把刚才的daughter转换为female child，接着再转换为逻辑形式child ∩ female就十分自然了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2）问题二：N-1 mismatch&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;是指将复杂的自然语言表达对应为单个逻辑表达。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;例如将How many people live in Berlin?转化为λx.population(Berlin,x)的分析过程中，How many people live in被对应为逻辑式常量population。如同问题一，这样的规则实在过多，作者的思路是将复杂的表达式转化为简单的形式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;沿用之前的句子来了解算法流程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWib6Sw6RA7ddKj6ODvvgQgvOflm5hxpUghY2K0YJdxuI8aJoicDtbvwcwOriblMiaB8rmbGZaYibhLluDA/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Step 1 替换实体生成候选template，例如得到模板how many people live in #y。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;Step 2 检索template pairs来替换模板，例如找到(a：how many people live in #y, b：what is the population of #y)的模板对，于是将b作为新模板，&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;Step 3 把实体替换回去得到容易生成逻辑形式的what is the population of Berlin。&lt;/span&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/h2&gt;&lt;h2&gt;&lt;span&gt;相关工作&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWib6Sw6RA7ddKj6ODvvgQgvOYAibzvslErZm3Ow3VymJib9uFia9VB4WcsXZuW86VOcdyMnVNVKUJ0F8Q/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;简评&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如今深度学习在自然语言处理领域大红大紫，也给语义分析的方法带来更多的思考。比如ACL2016另外一篇文章Language to Logical Form with Neural Attention，就把语义分析转换为seq2seq问题，进而使用深度学习的方法来解决。如果我们把词向量这样的表示形式比喻为粗糙的连结主义，那么逻辑表达就好比精细的形式主义。两者各有优势，希望以后会有更多结合两种思想的工作出现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;h1&gt;&lt;a title="Language to Logical Form with Neural Attention"&gt;&lt;/a&gt;&lt;a target="_blank" rel="external" style="font-size: 14px; text-decoration: underline;"&gt;&lt;span&gt;Language to Logical Form with Neural Attention&lt;/span&gt;&lt;/a&gt;&lt;/h1&gt;&lt;h2&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/h2&gt;&lt;h2&gt;&lt;span&gt;关键词&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Logical Forms, Sequence to Sequence&lt;/span&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/h2&gt;&lt;h2&gt;&lt;span&gt;来源&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;ACL 2016&lt;/span&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/h2&gt;&lt;h2&gt;&lt;span&gt;问题&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;如何把自然语言转化成Structured Logical Forms？&lt;/span&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/h2&gt;&lt;h2&gt;&lt;span&gt;文章思路&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWib6Sw6RA7ddKj6ODvvgQgvOrgv0kwGzaE5QW7XZicz9Kn9nict4W3R2U5mibsrbUyZbAaZsszF5MfbjA/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;模型总体是一个encoder-decoder架构，input sequence首先通过LSTM encoder转化成一个vector，然后这个vector通过LSTM decoder被转化成Logical Forms。在decode过程中用到了一个attention layer去获取context信息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWib6Sw6RA7ddKj6ODvvgQgvOicS46sEJ3vicuib5BtgktPfBnpYSyzHN4gknDtJ3nJBr4CgM2mhTicfChQ/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;和encoder-decoder模型类似，作者提出了一种hierarchical decoder。与普通的decoder不同，首先，decode之后的sequence中存在一个特殊字符&lt;/span&gt;&lt;n&gt;&lt;span&gt;代表nonterminal。在nonterminal的基础上，decoder可以继续进行下一个layer的decoding。每一次decoding的输入不仅包含current hidden state,还包含这一个parent nonterminal的hidden state。&lt;/span&gt;&lt;/n&gt;&lt;/p&gt;&lt;p&gt;&lt;n&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/n&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWib6Sw6RA7ddKj6ODvvgQgvOgmrS5oIjeQy66EfBRXLdl8E0MVzgCyw53hCibdYg1DEsqf5xDFQuFpQ/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;作者还使用了一种attention机制，在构建current hidden state的时候将hidden state与所有encoder中的hidden state进行对比，给每一个encoder hidden state一个weight。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;资源：&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;代码：&lt;/span&gt;&lt;span&gt;&lt;a target="_blank" rel="external" style="font-size: 14px; text-decoration: underline;"&gt;https://github.com/donglixp/lang2logic&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;span&gt;Jobs和GEO数据集：&lt;/span&gt;&lt;a target="_blank" rel="external" style="font-size: 14px; text-decoration: underline;"&gt;&lt;span&gt;http://www.cs.columbia.edu/~mcollins/papers/uai05.pdf&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/h2&gt;&lt;h2&gt;&lt;span&gt;相关工作&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;之前的大部分工作都采用一些parsing models，string-to-tree transformation rules，文中没有提到之前有人采用seq2seq/deep learning的方法。本文中使用的seq2seq方法主要来自Kalchbrenner, Blunsom, Cho, Sutskever 在machine translation中提出的模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;简评&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本文解决的是一个非常有趣的问题，将自然语言转换成结构化的Logical Forms。试想如果此模型能够很好的解决这个问题，那么将来的各种query language甚至programming languages都可以由自然语言转换而成。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;h1&gt;&lt;a title="Neural Summarization by Extracting Sentences and Words"&gt;&lt;/a&gt;&lt;a target="_blank" rel="external" style="font-size: 14px; text-decoration: underline;"&gt;&lt;span&gt;Neural Summarization by Extracting Sentences and Words&lt;/span&gt;&lt;/a&gt;&lt;/h1&gt;&lt;h2&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/h2&gt;&lt;h2&gt;&lt;span&gt;关键词&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Summarization、Hierarchical Document Encoder、Attention-based Extractor&lt;/span&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/h2&gt;&lt;h2&gt;&lt;span&gt;来源&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;ACL 2016&lt;/span&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/h2&gt;&lt;h2&gt;&lt;span&gt;问题&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;如何使用数据驱动的方法来做提取式摘要？&lt;/span&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/h2&gt;&lt;h2&gt;&lt;span&gt;文章思路&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本文针对的任务分为sentence和word两个level的summarization。sentence level是一个序列标签问题，每个句子有0或1两个标签，为1表示需要提取该句作为总结。而word level则是一个限定词典规模下的生成问题，词典规模限定为原文档中所有出现的词。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;使用的模型也比较有特点，首先在encoder端将document分为word和sentence来encode，word使用CNN encode得到句子表示，接着将句子表示输入RNN得到encoder端隐藏层状态。从word到sentence的encode体现了本文的hierarchical document encoder的概念。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWib6Sw6RA7ddKj6ODvvgQgvOr8qDmibNXTQANgzknEF2VPCLJEZiaYtXHvuZ2qxmA03JPTRSIIcuFCtw/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在decoder端根据任务的不同使用不同网络结构，sentence任务就是一个简单的有监督下二分类问题，使用RNN网络结构更新decoder端隐藏层状态， decoder端隐藏层状态串联encoder端隐藏层状态后接入一个MLP层再接sigmoid激活函数得到句子是否被extract的概率。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;word任务则是使用传统的attention-based的方法来计算每个词的概率。但要注意本文的计算的attention不是word-level attention，而是encoder端sentence-level attention。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWib6Sw6RA7ddKj6ODvvgQgvOlJojE1ibdBbbrzdNonrmvgumSBbGog7aDxtpnnrdqSM0DQU13cicZW7g/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/h2&gt;&lt;h2&gt;&lt;span&gt;资源&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;数据集：&lt;/span&gt;&lt;a target="_blank" rel="external" style="font-size: 14px; text-decoration: underline;"&gt;http://homepages.inf.ed.ac.uk/s1537177/resources.html&lt;/a&gt;&lt;br/&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/h2&gt;&lt;h2&gt;&lt;span&gt;相关工作&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;之前大多数extractive methods都基于human-engineered特征来给句子建模，通常会对每个句子计算一个分数，然后再使用诸如binary classifiers，hidden Markov模型，graph-based算法或integer linear programming等方法来选择句子构成总结。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;简评&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;之前基于data-driven的seq2seq模型在abstractive summarization任务上大放异彩，本文提出了使用类似的模型来解决extractive summarization任务。不过针对的依旧是single-document summarization任务，未来需要将工作拓展至multi-document summarization任务上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;h1&gt;&lt;span&gt;&lt;a target="_blank" rel="external" style="font-size: 14px; text-decoration: underline;"&gt;Sequence-to-Sequence Generation for Spoken Dialogue via Deep Syntax Trees and Strings&lt;/a&gt;&lt;/span&gt;&lt;/h1&gt;&lt;h1&gt;&lt;br/&gt;&lt;/h1&gt;&lt;h2&gt;&lt;span&gt;关键词&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Sequence to Sequence、Natural Language Generation、Chatbot&lt;/span&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/h2&gt;&lt;h2&gt;&lt;span&gt;来源&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;ACL 2016&lt;/span&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/h2&gt;&lt;h2&gt;&lt;span&gt;问题&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;如何通过小规模、未对齐语料生成对话语句？&lt;/span&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/h2&gt;&lt;h2&gt;&lt;span&gt;文章思路&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;作者介绍了两个模型:&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1、通过DA(diglogue acts)生成句法依赖树，再利用external surface realizer，生成语句。（如下图）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWib6Sw6RA7ddKj6ODvvgQgvOkInoNJmSBWLyiaHpicoMnNRZ8C9gQs3OVC01803qk4pCtEWQ9uFDQt0w/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2、将两部分结合起来，直接生成语句。步骤如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Step 1 将DA(dialogue acts)中的每个slot(表示特定信息)表示成三元组(DA type,slot,value)并结合(下图左)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWib6Sw6RA7ddKj6ODvvgQgvOpVGVyZMXCOPSSaF8mqakyBZzdGWEuOTTCBiaFLvqLiadH5icHTov9UY6w/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Step 2 基于seq2seq generation technique生出语句或句法依赖树。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;Step 3 结合beam search和n-best列表重排序（list reranker）以减少输出中的不相关信息。&lt;/span&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/h2&gt;&lt;h2&gt;&lt;span&gt;资源&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;代码:&amp;nbsp;&lt;/span&gt;&lt;a target="_blank" rel="external" style="font-size: 14px; text-decoration: underline;"&gt;&lt;span&gt;https://github.com/UFAL-DSG/tgen&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/h2&gt;&lt;h2&gt;&lt;span&gt;相关工作&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWib6Sw6RA7ddKj6ODvvgQgvO4H9re8117p8WZ69Fcia7CQJtFBQ8VMF3F8kj7Z3gsGT52FkQSdhZjOA/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;简评&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该方法基于广泛使用的seq2seq模型，可以用未对齐的MR对(pair of meaning representation)和句子进行训练，且只要小规模的语料就可以有很好的效果。生成器可以从数据中学会slot的对齐和值，生成流利的domain style)语句，虽然语义错误还是很频繁，但还是取得了不错的成绩。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;h1&gt;&lt;a title="On-line Active Reward Learning for Policy Optimisation in Spoken Dialogue Systems"&gt;&lt;/a&gt;&lt;a target="_blank" rel="external" style="font-size: 14px; text-decoration: underline;"&gt;&lt;span&gt;On-line Active Reward Learning for Policy Optimisation in Spoken Dialogue Systems&lt;/span&gt;&lt;/a&gt;&lt;/h1&gt;&lt;h2&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/h2&gt;&lt;h2&gt;&lt;span&gt;关键词&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Dialogue System、Reinforcement Learning、Online Active Reward Learning&lt;/span&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/h2&gt;&lt;h2&gt;&lt;span&gt;来源&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;ACL 2016&lt;/span&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/h2&gt;&lt;h2&gt;&lt;span&gt;问题&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;文章提出一种在线学习框架，通过高斯过程分类模型进行主动学习，训练对话策略和奖励模型，减少数据标注的花费和用户反馈中的噪声。&lt;/span&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/h2&gt;&lt;h2&gt;&lt;span&gt;文章思路&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWib6Sw6RA7ddKj6ODvvgQgvOGiazUDNAvJ3pVrhWfURnVNnGnkW7972GBxjibvbW9AHPnXHk28nPcoiaA/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;框架分为三部分：对话策略、对话嵌入函数、用户反馈主动奖励模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;无监督学习输入为双向LSTM，通过Encoder-Decoder模型表征用户意图，将对话的成功与否看做高斯过程的一个二元分类问题，当模型对当前结果不能评判时，主动学习，通过reward模型决定是否询问用户反馈，当模型不确定时，生成增强信号来训练策略。&lt;/span&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/h2&gt;&lt;h2&gt;&lt;span&gt;资源&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;数据集：&lt;/span&gt;&lt;a target="_blank" rel="external" style="font-size: 14px; text-decoration: underline;"&gt;&lt;span&gt;http://camdial.org/~mh521/dstc/&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/h2&gt;&lt;h2&gt;&lt;span&gt;相关工作&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1、之前的工作有用任务完成度和对话持续情况做Reward，但任务完成度不好衡量&lt;br/&gt;2、用协同过滤表征用户偏好&lt;br/&gt;3、用逆强化学习从行为中推出reward&lt;/span&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/h2&gt;&lt;h2&gt;&lt;span&gt;简评&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;用lSTM Encoder-Decoder表征用户意图，无需大规模标注语料和构建用户模拟器来进行训练，在较小的训练语料中取得了不错的效果，率先实现了在真实场景中的应用。但Reward函数只关心对话任务是否成功，模型过于简单。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;h1&gt;&lt;a title="Achieving Open Vocabulary Neural Machine Translation with Hybrid Word-Character Models"&gt;&lt;/a&gt;&lt;a target="_blank" rel="external" style="font-size: 14px; text-decoration: underline;"&gt;&lt;span&gt;Achieving Open Vocabulary Neural Machine Translation with Hybrid Word-Character Models&lt;/span&gt;&lt;/a&gt;&lt;/h1&gt;&lt;h2&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/h2&gt;&lt;h2&gt;&lt;span&gt;关键词&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Neural Machine Translation、UNK Words&lt;/span&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/h2&gt;&lt;h2&gt;&lt;span&gt;来源&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;ACL 2016&lt;/span&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/h2&gt;&lt;h2&gt;&lt;span&gt;问题&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;如何解决机器翻译中的未登录词问题？&lt;/span&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/h2&gt;&lt;h2&gt;&lt;span&gt;文章思路&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;文章提出了一个混合（层次）模型。该模型由两部分组成，分别为：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;a. 传统的基于词（word level）的seq2seq模型；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;b. 基于字母级别（character level）的LSTM模型，由一个将字母encode成单词的encoder和一个根据状态生成低频词的decoder组成。其中a部分负责进行翻译，b部分负责处理低频词（unk）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWib6Sw6RA7ddKj6ODvvgQgvOMvdz3W1wEVPcDSBDdnY1eoicX4qg8umw7qeia0QqXrVkVv6mqpdacXcg/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;具体地，a部分的encoder遇到unk时，会使用character level对该低频词进行encode，并使用encode出的representation作为输入。而decoder遇到unk时，会利用attention机制将当前上下文和LSTM状态初始化character level decoder。此处的初始化采用的是文章提出的separate path模式，即利用一个MLP作为character level decoder的初始化网络。值得注意的是此处word level decoder仍会选择用&lt;/span&gt;&lt;unk&gt;&lt;span&gt;作为下一步的输入。&lt;/span&gt;&lt;/unk&gt;&lt;/p&gt;&lt;p&gt;&lt;unk&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/unk&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;相关工作&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Unk问题属于NMT中长期存在问题。目前多是采取后处理的方法。今年ACL有两篇paper，分别是李航老师实验室的copynet和Bengio实验室的pointing the unknown words，但对机器翻译任务参考意义有限。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;另外一种思路则是加大词典，比较知名工作有On Using Very Large Target Vocabulary for Neural Machine Translation。此外该工作还借鉴了Jiwei Li的hierarchical auto encoder。&lt;/span&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/h2&gt;&lt;h2&gt;&lt;span&gt;简评&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;文章思路新颖且简单明了。因为NMT中存在unk的问题，作者直接利用character level RNN来生成一个词替代unk。该工作对拼音文字有一定意义，对中日韩文的参考意义有限。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;h1&gt;&lt;a title="Pointing the Unknown Words"&gt;&lt;/a&gt;&lt;a target="_blank" rel="external" style="font-size: 14px; text-decoration: underline;"&gt;&lt;span&gt;Pointing the Unknown Words&lt;/span&gt;&lt;/a&gt;&lt;/h1&gt;&lt;h2&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/h2&gt;&lt;h2&gt;&lt;span&gt;关键词&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Neural Machine Translation、UNK Words&lt;/span&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/h2&gt;&lt;h2&gt;&lt;span&gt;来源&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;ACL 2016&lt;/span&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/h2&gt;&lt;h2&gt;&lt;span&gt;问题&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;如何解决机器翻译中的未登录词问题？&lt;/span&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/h2&gt;&lt;h2&gt;&lt;span&gt;文章思路&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;作者在有注意力的机器翻译模型上增加了一个开关来判断和是否复制原文。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1、Attention-based机器翻译模型&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWib6Sw6RA7ddKj6ODvvgQgvOsO8vFv03ibCqjPFEdI1WyWoax1EBPnMMds9ce1iaE2UTP89FFicFXoVrQ/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;span&gt;经典的attention model这里不再赘述。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2、Pointer Softmax模型&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWib6Sw6RA7ddKj6ODvvgQgvOeu0uSampia0uIVOibTLdicelPFELEh6xpyLDu80Qr0MQwR321GCMSfMLw/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;两个问题有待解决解决：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;a. 是否进行copy？&lt;br/&gt;b. copy的位置在哪？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;先说第二个问题，作者先引入shortlist softmax和location softmax。前者来确定要从shortlist中选取哪一个单词作为输出，后者确定在哪个位置要进行copy操作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;再看第一个问题，作者引入一个二值变量（可以想象为一个开关）来选择使用shortlist softmax还是location softmax。当值为1的时候不进行copy操作，使用shortlist softmax来从shortlist中选一个词作为输出。当值为0的时候进行copy操作，使用location softmax，将原文的词直接copy到指定位置。&lt;/span&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/h2&gt;&lt;h2&gt;&lt;span&gt;资源&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;代码：&lt;/span&gt;&lt;a target="_blank" rel="external" style="font-size: 14px; text-decoration: underline;"&gt;&lt;span&gt;https://github.com/caglar/pointer_softmax&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/h2&gt;&lt;h2&gt;&lt;span&gt;简评&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本文的想法很有趣，直接从原文照抄罕见词和未知词很符合日常生活中人类的处理方法。从文中实验结果来看，该模型有一定的提升效果。注意力模型的提出与对人类行为的观察密不可分，而copy机制也是从生活中提炼出来的一种有效模型，我们可以借鉴的是从人类解决问题的具体方式中进行总结和归纳不失为一种有效的解决方案。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;h1&gt;&lt;a title="Harnessing Deep Neural Networks with Logic Rules"&gt;&lt;/a&gt;&lt;a target="_blank" rel="external" style="font-size: 14px; text-decoration: underline;"&gt;&lt;span&gt;Harnessing Deep Neural Networks with Logic Rules&lt;/span&gt;&lt;/a&gt;&lt;/h1&gt;&lt;h2&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/h2&gt;&lt;h2&gt;&lt;span&gt;关键词&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;CNN、RNN、First-order Logic, Iterative Distillation Method&lt;/span&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/h2&gt;&lt;h2&gt;&lt;span&gt;来源&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;ACL 2016&lt;/span&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/h2&gt;&lt;h2&gt;&lt;span&gt;问题&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;如何将深度学习与逻辑规则结合使用？&lt;/span&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/h2&gt;&lt;h2&gt;&lt;span&gt;文章思路&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWib6Sw6RA7ddKj6ODvvgQgvOpACiaUgZm4tHyZyeiaTlRHEQPdSG0RqQ5CmBDusQHClib305HSibzibCd3A/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;系统在构建正常神经网络(student)的同时，构建了一个基于逻辑规则的训练网络(teacher)。整个网络的目标还是优化神经网络的参数变量 θ，因为新的目标损失函数结合了二者的损失，通过这种方式，教师网络的逻辑信息就能够被转移到神经网络的θ上，从而加强神经网络的性能。 在这种结构里逻辑规则是用于辅助的可选项，通过调整权重，系统可以偏向某个网络。这种模型可以将监督学习扩展到无监督学习，比如图示中，无标记的数据通过教师子网之后提取有用信息，也可以用来训练监督学习的神经网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1、训练过程&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;假设输入数据为x, y。student神经网络的参数变量是θ, 输出层是softmax，对输入xn，输出预测概率分布σ(xn)。对teacher网络，在第ｔ次迭代中基于逻辑规则的预测结果表示为sn(t)，那么新的优化目标变成了&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWib6Sw6RA7ddKj6ODvvgQgvOR8ViauicaO3hCVqEMzu6VFznBYKrwSM56c8PoAOMSsgtCNYCXicAumb5A/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;可以看出来自教师网络的反馈作为regularization加到了目标函数里，通过这种方式两个网络的信息就结合在了一起。注意教师网络在每次训练迭代中都要构建，因此整个过程被称之为iterative knowledge distillation.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2、教师网络&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;教师网络使用软逻辑(soft logic)来编码first-order logic的信息。soft logic在[0,1]之间的连续取值，而不是二元值{0, 1}。逻辑运算也用max, min, sum代替原来的与或非。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;神经网络数学模型为pθ(y|x) 教师网络数学模型假设为q(y|x)。我们实际上是用基于逻辑规则的教师网络来模拟神经网络输出，因此我们希望能找到一个最优的q，使得输入尽可能满足逻辑规则的要求，同时q要尽可能接近pθ。详细推导可以参见原文，最后的优化结果就是&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWib6Sw6RA7ddKj6ODvvgQgvOMNO3vKgFLS3pWoEDFFGrHJPWceKe6icWayaXicDcdS7pkiaia9cEc0aUHQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;λl 是每个规则的自信度(confidence)，而rl, gl 是某个规则应用于某一输入时的逻辑结果，介于0,1之间。可以看到自信度比较高的规则可以使输入更容易通过规则。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3、应用&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;a. 基于CNN的情感分析&lt;br/&gt;b. 基于BLSTM-CNN的NER任务&lt;/span&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/h2&gt;&lt;h2&gt;&lt;span&gt;相关工作&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1、Neural-symbolic systems (Garcez et al., 2012) 从给定的规则构建推理网络&lt;br/&gt;2、(Collobert 2011)， 利用领域知识domain knowledge提取额外特征，增强原始数据&lt;br/&gt;3、Knowledge distillation (Hinton et al., 2015) (Bucilu et al. 2006)&lt;br/&gt;4、Posterior regularization (PR) method (Ganchev et al., 2010)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;简评&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;创新点在于将逻辑规则与神经网络结合，可以利用人已知的知识去引导机器学习。当数据量不足的，或者对数据进行补充时，可以将人类的知识用逻辑语言表达出来，然后通过本文提出的框架进行增强训练。本文的两个例子中都提到只用了少量规则，优化的结果虽然显示要比当前其他模型好，但是没有大幅度的提高。需要进一步验证如果使用更多的规则，能不能大幅度提高准确率。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;h1&gt;&lt;a title="Easy Questions First? A Case Study on Curriculum Learning for Question Answering"&gt;&lt;/a&gt;&lt;a target="_blank" rel="external" style="font-size: 14px; text-decoration: underline;"&gt;&lt;span&gt;Easy Questions First? A Case Study on Curriculum Learning for Question Answering&lt;/span&gt;&lt;/a&gt;&lt;/h1&gt;&lt;h2&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/h2&gt;&lt;h2&gt;&lt;span&gt;关键词&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Curriculum Learning、Self-paced Learning、Question Answering&lt;/span&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/h2&gt;&lt;h2&gt;&lt;span&gt;来源&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;ACL2016&lt;/span&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/h2&gt;&lt;h2&gt;&lt;span&gt;问题&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;文章讨论了Curriculum Learning在NLP领域, 尤其是在QA task里应用的可行性。&lt;/span&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/h2&gt;&lt;h2&gt;&lt;span&gt;文章思路&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;文章首先对QA类型的task给出了比较general的定义: 我们可以把QA问题看做是一个经验风险最小化(ERM)问题, 我们需要最小化:&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWib6Sw6RA7ddKj6ODvvgQgvOW06Is8n1OYsv4kPcic92KkEw3deibuwxHLf7knr15jIRFc5YQvTFYcjw/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其中是a正确答案, f是给定背景知识以及问题, 模型选择出的最佳答案,Ω是regularizer.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;之后, 作者对于Curriculum Learning, 尤其是Self-paced Learning做了介绍, 并且将其引入QA task, 进而将之前的ERM问题变为:&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWib6Sw6RA7ddKj6ODvvgQgvOoeGfjWPVIsEprciarOLiayjAPlCPGqp3hhj0BkNbbq9xu8MPSoFrSYsQ/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其中v是对问题进行采样时候的权值, g是self-paced regularizer, 其中λ代表’age’, 或者说’pace’. 训练初期, 模型趋向于对简单的问题进行训练, 而随着’age’的增加, 模型越来越多地加入更复杂的问题一起训练。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;文章给出并分析了四种流行的self-paced regularizer如Table 1:&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWib6Sw6RA7ddKj6ODvvgQgvO1EK04ToTPoUTpkBhEoz2mEuFXvdlLTBkibDAovZ7ibKvvmlMv9XsV0Gg/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;之后提出了7种新的heuristics:&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1) Greedy Optimal (GO): 将已有的Q和一系列新的Q一起训练, 选回答正确并且loss最低的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;2) Change in Objective (CiO): 将已有的Q和一系列新的Q一起训练, 选择令loss改变最小的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;3) Mini-max (M2 ): 当某个新的Q与其loss最大的一个candidate answer配对时, loss最小的. (通俗地讲, 就是最差情况都没有那么糟糕的一个)。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;4) Expected Change in Objective (ECiO): 只拿新的Q训练, 和之前的loss改变最小的. (相比于第二种的将已有的Q和新Q一起训练)。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;5) Change in Objective-Expected Change in Objective (CiO - ECiO): 2)和4)的值最接近的, 按照作者的意思, 这个值反应了model见到某个新Q时surprise的程度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;6) Correctly Answered (CA): 将一系列新Q在当前model上测试, 选择用最小的loss正确回答的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;7) Farthest from Decision Boundary (FfDB): 只用在latent structural SVMs上, 选择答案与decision boundary最远的一个新Q。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;资源&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;MCTest:&amp;nbsp;&lt;/span&gt;&lt;a target="_blank" rel="external" style="font-size: 14px; text-decoration: underline;"&gt;&lt;span&gt;http://research.microsoft.com/en-us/um/redmond/projects/mctest/&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;span&gt;Science Textbook:&amp;nbsp;&lt;/span&gt;&lt;a target="_blank" rel="external" style="font-size: 14px; text-decoration: underline;"&gt;&lt;span&gt;http://http://www.ck12.org/&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;span&gt;Science question answering:&amp;nbsp;&lt;/span&gt;&lt;a target="_blank" rel="external" style="font-size: 14px; text-decoration: underline;"&gt;&lt;span&gt;http://aristo-public-data.s3.amazonaws.com/AI2-Elementary-NDMC-Feb2016.zip&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;span&gt;Simple English Wikipedia:&amp;nbsp;&lt;/span&gt;&lt;a target="_blank" rel="external" style="font-size: 14px; text-decoration: underline;"&gt;&lt;span&gt;https://dumps.wikimedia.org/simplewiki/20151102/&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;span&gt;QANTA:&amp;nbsp;&lt;/span&gt;&lt;a target="_blank" rel="external" style="font-size: 14px; text-decoration: underline;"&gt;&lt;span&gt;https://cs.umd.edu/~miyyer/qblearn/&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/h2&gt;&lt;h2&gt;&lt;span&gt;相关工作&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1、Curriculum Learning:&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;早在1958年[1], 就有认知科学的相关学者意识到, 对于人类学习过程, 相对于提供随机的知识,由浅及深的地给予有计划的训练样本, 可以得到更好的效果. 之后这一Curriculum Learning的想法也被引入到机器学习中[2], 其中Self-paced learning (SPL)[3][4][5]是比较常用的方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2、QA:&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Jurafsky和Martin[6]对于QA系列问题有一个非常好的叙述, 而这篇文章突出讨论Curriculum Learning在non-convex的QA模型上的应用, 着重介绍了基于配对的模型[7][8][9]和基于深度学习的模型[10][11].&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;基于配对的模型将每一个问题和问题附带的多个备选答案组成若干个QA对, 我们称之为假设, 然后在给定相关文章的情况下, 寻找有最可能是正确的一个假设作为答案. 基于深度学习的模型可以使用依赖关系树结构的递归神经网络, 对句子level的QA模型的结果取平均[10]; 也可以用RNN构建”长期”存储器, 通过学习对存储器进行读/写操作, 模拟一个动态的知识构建过程[11]。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;简评&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在QA task中引入Curriculum Learning旨在在训练过程中, 启发式地对于提供给模型的数据出现的顺序进行一些调整, 从而让模型从简单的, 易于学习的样本开始, 随着模型对数据的表述愈加成熟, 逐渐加入更复杂的样本. 理想状况下这会指导模型从得到一个普通的local minima, 变成得到一个”更”好的local minima, 进而利用全部数据得到一个”更更”好的local minima。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通常来说, 我们给予模型的heuristic并不一定能够真正帮助模型, 因为通常我们都在猜测数据以及模型的latent representation是什么, 但是这篇文章通过了一系列的实验验证, 本文阐述的heuristic确实可以帮助QA model获得更好的准确率. 这证明了引导模型由浅及深的这种思路是可行的, 我们也许可以思考一些更复杂的heuristic, 或者将其应用到其他的一些NLP tasks。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然而本文给出的大部分heuristic在新问题的选择上都需要比较大的时间复杂度, 对于类似MCTest这种总共只有660个文章的小型数据集来说还算比较现实, 但是对于更大更长的数据集(比如CNN数据集, 38万个文章, 很多文章都超过了一千五百个单词, 而且备选答案数量也远超MCTest的四个)时, 就显得不那么轻松了. 最简单的Attention Sum Reader[1] 在CNN数据集上, 每个epoch都需要10个多小时, 就更别说其他基于AS Reader的模型了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;总体来说, 相对于实用性, 这篇文章更多在于提供了一种新的思路, 也就是把Curriculum Learning相关的概念应用到QA乃至于其他NLP task中, 非常值得思考, 因此是一篇非常值得阅读的文章。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;h1&gt;&lt;a title="The LAMBADA dataset:Word prediction requiring a broad discourse context"&gt;&lt;/a&gt;&lt;a target="_blank" rel="external" style="font-size: 14px; text-decoration: underline;"&gt;&lt;span&gt;The LAMBADA dataset:Word prediction requiring a broad discourse context&lt;/span&gt;&lt;/a&gt;&lt;/h1&gt;&lt;h2&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/h2&gt;&lt;h2&gt;&lt;span&gt;关键词&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Machine Reading Comprehension、Dataset&lt;/span&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/h2&gt;&lt;h2&gt;&lt;span&gt;来源&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;ACL 2016&lt;/span&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/h2&gt;&lt;h2&gt;&lt;span&gt;问题&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;构建了一个难度更大的机器阅读理解数据集。&lt;/span&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/h2&gt;&lt;h2&gt;&lt;span&gt;构建思路&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以Book Corpus的小说作为数据源，构建了10222个passages，每个passage包括平均4.6句话的context和相邻着的一句target，定义的任务是通过理解context来预测target中最后一个词，平均每个passage包括约75个tokens。其中，超过80%的passage context中包括了target中需要预测的词，48%的target words是专有名词（proper nouns），37%的词是一般名词（common nouns），约7.7%的是动词。这里，专有名词和一般名词是最难猜出来的，动词有一定的概率可以不需要context，而直接从target sentence利用语言模型猜出来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在处理原始数据时，作者做了一层过滤，将容易从target sentence中直接猜出target word的passages统统丢掉，将剩下的部分放在众包网站上进行人工筛选，筛选的过程比较长，目的是让留在数据集中的数据有下面的效果：通过分析passage的context可以给出正确的target word，而如果只是给定target sentence的话，是猜不出正确的target word。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;资源&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本文数据集Lambada dataset:&amp;nbsp;&lt;/span&gt;&lt;a target="_blank" rel="external" style="font-size: 14px; text-decoration: underline;"&gt;&lt;span&gt;http://clic.cimec.unitn.it/lambada/&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;span&gt;众包网站Crowdflower:&amp;nbsp;&lt;/span&gt;&lt;a target="_blank" rel="external" style="font-size: 14px; text-decoration: underline;"&gt;&lt;span&gt;http://www.crowdflower.com/&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;span&gt;原始数据集Book Corpus:&amp;nbsp;&lt;/span&gt;&lt;a target="_blank" rel="external" style="font-size: 14px; text-decoration: underline;"&gt;&lt;span&gt;http://www.cs.toronto.edu/~mbweb/&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;span&gt;CNN/Daily Mail dataset:&amp;nbsp;&lt;/span&gt;&lt;a target="_blank" rel="external" style="font-size: 14px; text-decoration: underline;"&gt;&lt;span&gt;https://github.com/deepmind/rc-data&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;span&gt;CBT dataset:&amp;nbsp;&lt;/span&gt;&lt;a target="_blank" rel="external" style="font-size: 14px; text-decoration: underline;"&gt;&lt;span&gt;http://fb.ai/babi/&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;span&gt;MSRCC dataset:&amp;nbsp;&lt;/span&gt;&lt;a target="_blank" rel="external" style="font-size: 14px; text-decoration: underline;"&gt;&lt;span&gt;https://www.microsoft.com/en-us/research/publication/the-microsoft-research-sentence-completion-challenge/&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/h2&gt;&lt;h2&gt;&lt;span&gt;相关数据集&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWib6Sw6RA7ddKj6ODvvgQgvOcTpQoLKpK6t32DTeSGfIbx8NmxzsbuxVkNljnrw2icR7UsyEPsicymXg/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/h2&gt;&lt;h2&gt;&lt;span&gt;简评&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;大型数据集是深度学习技术发展的重要基础，数据集的质量和难度也直接关系着模型的质量和实用性。机器阅读理解的数据集有很多，包括中文和英文的数据集，每一个的构建都会带来模型的创新，随着难度不断增加，对模型也提出了更高的要求。本文在构建数据集过程中为了保证任务的难度所采取的方法是值得借鉴的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;h1&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/h1&gt;&lt;h1&gt;&lt;strong&gt;&lt;span&gt;致谢&lt;/span&gt;&lt;/strong&gt;&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;本期的10篇文章由以下同学完成：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;苏辉、Xiaoyu、胡小明、赵越、周青宇、韩晓伟、Eric Yuan、Zewei Chu、tonya、张俊。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;感谢大家地辛勤付出。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;PaperWeekly是一个分享知识和交流学问的民间组织，关注的领域是NLP的各个方向。如果你也经常读paper，也喜欢分享知识，也喜欢和大家一起讨论和学习的话，请速速来加入我们吧。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWib6Sw6RA7ddKj6ODvvgQgvOqQRBn3u9vwibdJz3FwdX0kKHNZBPf2sKgUhpMBByltT0t9NRH3zianGg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;微博账号：PaperWeekly（http://weibo.com/u/2678093863 ）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;知乎专栏：PaperWeekly（https://zhuanlan.zhihu.com/paperweekly ）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;微信交流群：微信+ zhangjun168305（请备注：加群 or 加入paperweekly）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;</description>
      <pubDate>Fri, 02 Sep 2016 23:54:36 +0800</pubDate>
    </item>
    <item>
      <title>重磅 | 深度揭秘谷歌「量子霸权」计划：有望明年底突破经典计算极限</title>
      <link>http://www.iwgc.cn/link/2514055</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自 New Scientist&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：&amp;nbsp;Jacob Aron&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀、李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;昨日，New Scientist 发表文章解密谷歌量子计算机的进展。文章中写到，量子计算领域正在快速重组，谷歌的工程师已经悄悄拿出了计划要成为该领域的霸主！&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWichcWU2hkia3ZnF1OnoykPjiciauj4GYo1qDf3hIJLH99VSibLSUhmUrVLa5BlliaXYkpZReOtL6eMljkA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;上图是超导量子位，来自 UCSB&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在加利福尼亚州的某个地方，谷歌正在打造某种能将计算技术带进一个新时代的设备——量子计算机（quantum computer）。谷歌正在打造的这台量子计算机是有史以来最大的，其目的是为了一劳永逸地证明这种使用了奇异的物理学的机器能够超越当下顶级的超级计算机的性能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而 New Scientist 也了解到这一目标的实现可能将会比所有人的预期更早——甚至可能就在明年年底之前！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;量子计算革命已经等待了很长的时间了。20 世纪 80 年代时，理论学家认识到基于量子力学的计算机有望在特定的任务上远超普通或经典计算机的性能。但说起来简单做起来难，直到最近，可以击败经典计算机的量子计算机才有望从实验室研究变成现实真正可用的东西，而谷歌想造出第一台。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这家公司的规划目前还是机密，谷歌也拒绝就这篇文章发表评论。但 New Scientist 接触过的一些科学家都相信现在它们已经处在了实现重大突破的边缘，紧接着就将有大会和私人会议上的演示出现了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「他们现在肯定是世界上最领先的，这是毫无疑问的，」日本新兴物质科学中心（RIKEN Center for Emergent Matter Science）Simon Devitt 说，「谷歌稳操胜券。如果谷歌最后没有成功，那一定是什么地方出了问题。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们简单了解了谷歌的意图。上个月，谷歌的工程师悄悄发布了一篇描述了他们的计划细节的论文《Characterizing Quantum Supremacy in Near-Term Devices（在短期的设备内表征量子霸权）》。他们的目标被大胆地命名成了「Quantum Supremacy（量子霸权）」，其目标是打造世界上第一个可以执行经典计算机无法执行的任务的量子计算机。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「这是他们未来几年规划的蓝图，」得克萨斯大学奥斯汀分校 Scott Aaronson 说，他曾和谷歌的这个团队讨论过这个规划。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以他们会怎么做？量子计算将信息作为量子位（qubit）进行处理。和经典的位（bit/比特）不一样，由于量子叠加原理，量子位可以同时存储 0 和 1 的混合状态。正是这样的潜力让量子计算机在一些特定的任务上具备了优势，比如大数因子分解。但普通的计算机在这些任务上也能取得很好的表现。要证明量子计算更好，会需要用到数千个量子位，而这远远超出了我们现有的技术能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而谷歌想要实现 50 个量子位的成果。这仍然是一个很有雄心的目标——就目前公开的消息来看，他们只公布了一个 9 量子位的计算机——但这是一个可以实现的目标。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;谷歌稳操胜券。如果谷歌最后没有成功，那一定是什么地方出了问题。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了成功实现这一目标，谷歌已经开始了量子核心问题的攻关。他们正在专注解决对普通计算机来说极度困难，而对量子计算机来说可以自然地解决的问题：模拟量子电路（quantum circuits）随机排布的行为。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些量子电路中输入的任何微小变化都可能带来非常不同的输出，所以对经典计算机来说，是很难通过逼近以简化该问题的方法来作弊式地解决这个问题的。「他们正在打造一个量子版本的混沌（chaos），」Devitt 说，「其输出本质上是随机的，所以你必须计算所有东西。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了找到经典计算的极限，谷歌寻求了 Edison 的帮助。Edison 是世界上最先进的超级计算机之一，安置在美国国家能源研究科学计算中心（ US National Energy Research Scientific Computing Center）。谷歌用其模拟了越来越大的量子位网格（grids of qubits）的量子电路的行为，发现最多能模拟 6×7 网格的 42 个量子位。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这种计算非常困难。因为随着网络大小的增长，存储所有数据所需的内存就会快速暴增。一个 6×4 的网格仅需要 268 MB，比一般的智能手机的内存还小。而一个 6×7 的网格则需要 70 TB，差不多是高端个人计算机的 10,000 倍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谷歌没再继续增大网格，因为再增大一点对现在的技术来说就已经是不可能的了：一个 48 量子位的网格需要 2.252 PB 的内存，这差不多相当于现在世界上最强大的超级计算机的两倍。如果谷歌可以解决 50 个量子位的量子计算机的问题，那么它就将超越世界上任何已经存在的计算机。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;矢志不移&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过设置这个明确的测试，谷歌希望能够避免那些困扰过之前的宣称量子计算机超越普通计算机的断言的问题——其中包括谷歌宣称的一些。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;去年，该公司曾宣布通过使用一台 D-Wave 量子计算机（一款饱受争议的已经商业化的设备），该公司以超过经典计算机 1 亿倍的速度解决了一些特定的问题。相关专家立即反驳了这一结果，他们说这并不是一次公平的比较。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谷歌在 2013 年购买了一台 D-Wave 计算机，想要搞清楚它是否可以被用于改善搜索结果和人工智能。后一年，该公司聘请了加州大学圣塔芭芭拉分校的 John Martinis 来设计自己的超导量子位（superconducting qubit）。Aaronson 说，「他的量子位的质量要高得多。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在正是 Martinis 及其同事想要尝试实现 50 量子位的 quantum supremacy（量子霸权），而且许多人相信他们很快将取得成功了。「我认为这将在两到三年内实现，」瑞士苏黎世兰邦理工学院的 Matthias Troyer &amp;nbsp;说，「他们已经让人们看到了他们将怎么做的具体步骤。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Martinis 及其同事已经就实现这一里程碑的时间表做过很多讨论了，Devitt 说。最早的估计是今年年底，但看起来不太可能。「我比较乐观，我觉得可能会是在明年年底。」他说，「就算他们在接下来的五年之内才完成，那也将会是一个巨大的飞跃。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一个成功的量子争霸实验并不能直接给我们带来可以执行任何可以想象的任务的计算机——基于目前的理论，这种计算机将会非常庞大。但有一个可以工作的小型计算机可以推动创新或者增强现有的计算机，从而使之成为一个新时代的开始。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Aaronson 将其比作是第一个自持核反应（self-sustaining nuclear reaction）——1942 年由曼哈顿计划在芝加哥实现。他说：「这可能会让人们说：如果我想要一台完全可扩展的量子计算机，就让我们谈谈数字：要花多少亿美元？」解决构建 50 量子位设备的难题之后，谷歌就为更大的目标做好了准备。「这是构建完全可扩展的机器之路上的绝对重大进展，」牛津大学 Ian Walmsley 说。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了量子计算机能在长远上真正有用，我们还需要稳健的量子纠错（quantum error correction）技术——一种用来减轻量子态脆弱性的技术。Martinis 等人已经在研究这方面的问题了，但这将要花费比实现 quantum supremacy（量子霸权）更长的时间。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不过，霸权的实现不会被取消。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「一旦一个系统达到了量子霸权，并且表现出了明显的规模化行为，那么它就将成为私有企业天空上耀眼的火炬。」Devitt 说，「就为走出实验室做好了准备。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「这个领域的发展速度比原来预想的快得多，」Troyer 说，「现在是时候将量子计算从科学变成工程并真正打造设备了。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;论文：在短期的设备内表征量子霸权（Characterizing Quantum Supremacy in Near-Term Devices）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWichcWU2hkia3ZnF1OnoykPjicunShQ2rE9GqryiauSHDuhejmwAgH2U5E4zpAbzoB80fraxUW0f9ZUCQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于近未来的量子计算领域，一个关键的问题是：没有纠错（error correction）的量子设备能否执行定义良好的计算任务，并在这些任务上超越当前最好的经典计算机的能力，从而实现所谓的量子霸权（quantum supremacy）。我们研究了从（伪）随机量子电路的输出分布中进行采样的任务——这是一个用来评测量子计算机的自然任务。重要的是，对这样的分布进行采样需要该电路的直接数值模拟（direct numerical simulation），同时计算成本会随量子位的数量指数式地增长。这是混沌系统（chaotic systems）的典型要求。我们在计算复杂度上延展了之前的结果，以更正式地说明这种采样任务会在经典计算机上消耗指数级更多的时间。我们研究了混沌状态（chaotic regime）的收敛（convergence），该研究使用了应用广泛的超级计算机模拟建模了多达 42 个量子位的电路——这是目前在实现量子霸权的任务上最大的量子电路。我们认为尽管混沌状态对错误非常敏感，但量子霸权可以通过大约 50 个超导量子位在短期内实现。我们引入了交叉熵（cross entropy）作为量子电路的评测基准，这近似于电路保真度（circuit fidelity）。我们证明这种交叉熵可在电路模拟可用时测定。除了传统上可测量的状态，该交叉熵还可通过电路保真度的理论估算进行比较来进行推断，从而可以定义出一种实用的量子霸权测试方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;点击「阅读原文」，下载此论文↓↓↓&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 01 Sep 2016 12:51:51 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 谷歌开放Inception-ResNet-v2：一种新的图像分类卷积神经网络模型</title>
      <link>http://www.iwgc.cn/link/2514056</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自 Google Research&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：&amp;nbsp;Alex Alemi&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;昨天，&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718786&amp;amp;idx=4&amp;amp;sn=274bbf2332427a274123f6b9e009487e&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718786&amp;amp;idx=4&amp;amp;sn=274bbf2332427a274123f6b9e009487e&amp;amp;scene=21#wechat_redirect"&gt;谷歌宣布开放 TF-Slim&lt;/a&gt;，这是一个在 TensorFlow 中定义、训练、和评估模型的轻量软件包，同时它还能对图像分类领域中的数个有竞争力的网络进行检验与模型定义。今天，谷歌再次宣布开放 Inception-ResNet-v2，一个在 ILSVRC 图像分类基准上取得顶尖准确率的卷积神经网络。文中提到的论文可点击「阅读原文」进行下载。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了在该领域取得更多进展，今天我们非常高兴的宣布开放 Inception-ResNet-v2，这是一个在 ILSVRC 图像分类基准上取得顶尖准确率的卷积神经网络。Inception-ResNet-v2 是早期发布的 Inception V3 模型的变体，该模型借鉴了微软 ResNet 论文中的思路。具体内容可在我们的论文：Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning 中看到。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;残差连接（Residual connections ）允许模型中进行 shortcut，也使得研究员能成功的训练更深的神经网络从而产生更好的性能。这也使得 Inception 块的极度简单化成为可能。下图对比了这两个模型架构：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWichcWU2hkia3ZnF1OnoykPjichFlv1fnX95Nx8y9PcYQQH2ibJKiaemaIdEjWB1ltqkPM0GBrX9L8tdFg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Inception V3 图解&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWichcWU2hkia3ZnF1OnoykPjicZ4F2Hsx4qrOA9ibPlTdAdIH63dGnOejppiabrAKHDTibydwuwFdbe3LYA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Inception-ResNet-v2 的图解&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在第二张图解的顶端，你可以看到全部的网络拓展，可以注意到该网络比之前的 Inception V3 要深得多。主图的下面是更简单阅读同一网络版本的方式，里面重复的残差块是被压缩了。注意，里面的 Inception 块被简化的，比先前的 Inception V3 包含更少的并行塔 （parallel towers）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Inception-ResNet-v2 架构比之前的前沿模型更加准确。下表报告了在基于单类图像的 ILSVRC 2012 图像分类基准上的 Top-1 和 Top-5 的准确度检验结果。此外，该新模型相比于 Inception V3 大约只需要两倍的存储和计算能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWichcWU2hkia3ZnF1OnoykPjicfLibjPtmia7JBzZ17QXFWJyGKHZuuBQJo0Hic75cxJgVB5wZNo5V2zXhQ/0?wx_fmt=png"/&gt;&lt;br/&gt;结果援引于 ResNet 论文&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;举个例子，Inception V3 和 Inception-ResNet-v2 模型在识别犬种上都很擅长，但新模型做的更好。例如，旧模型错误报告右图中的狗是阿拉斯加雪橇犬，而新的 Inception-ResNet-v2 模型准确识别了两张图片中的狗的种类。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWichcWU2hkia3ZnF1OnoykPjicnpLbvzB7Xkw42kWBeuqhrTubTg5zPrltNLdNvu6iaxlAoe0ibHv35gIg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;阿拉斯加雪橇犬（左），西伯利亚爱斯基摩狗（右）&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了让人们能立即进行试验，我们也发布了 Inception-ResNet-v2 模型的一个预训练案例作为 TF-Slim 图像模型库的一部分。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果想进行试验，这是如何训练、评估或微调网络的指导：https://github.com/tensorflow/models/blob/master/slim/README.md&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 01 Sep 2016 12:51:51 +0800</pubDate>
    </item>
    <item>
      <title>学界 | FAIR实验室与微软研究院合著论文：通过虚拟问答衡量机器智能</title>
      <link>http://www.iwgc.cn/link/2514057</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自 arXiv.org&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;作者：C. Lawrence Zitnick、Aishwarya Agrawal、Stanislaw Antol、 Margaret Mitchell、Dhruv Batra、Devi Parikh&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：孙宇辰、李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWichcWU2hkia3ZnF1OnoykPjicpJmzzqfzO3LnWwZj6Hw7dkXFeNN4tRABdx6u26HwFtysniamy7kGg7w/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;摘要&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;随着机器逐渐变得更加智能，社区内对衡量机器智能程度的方法再次产生了兴趣。一种常用的方法是使用人类可以处理的、但机器做起来困难的任务。然而，这样的一个理想任务应该容易进行评估，同时不那么容易蒙出来。我们从最近图片描述（image captioning）以及其局限性作为一个衡量机器智能的任务开始探索。另一个更有前途的任务就是虚拟问答，测试机器语言与视觉上思考的能力。我们为了这项任务搭建了前所未有的数据集，包含 76 万人们对图片内容生成的问题。使用一千万左右人类产生的回答，机器可能很容易被评估。&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;点击「阅读原文」，下载此论文↓↓↓&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 01 Sep 2016 12:51:51 +0800</pubDate>
    </item>
    <item>
      <title>深度 | 从硬件到软件：OpenAI 解读自家的深度学习基础架构</title>
      <link>http://www.iwgc.cn/link/2499489</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自 OpenAI&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：VICKI CHEUNG, JONAS SCHNEIDER, &lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;ILYA SUTSKEVER, AND GREG BROCKMAN&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：孙宇辰、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;em style="line-height: 1.75em; color: rgb(136, 136, 136);"&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;em style="line-height: 1.75em; color: rgb(136, 136, 136);"&gt;&lt;span&gt;深度学习是一门经验科学，群组基础架构的质量不断地改善。幸运的是，如今的开源生态环境让任何人都可以搭建很出色的深度学习基础架构。&lt;/span&gt;&lt;/em&gt;&lt;br/&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这篇文章中，我们将要分享深度学习的研究通常是如何进行的，我们如何选择适当的架构辅助研究以及一个为 Kubernetes 的批优化过的扩展管理器（ batch-optimized scaling manager）开源项目「kubernetes-ec2-autoscaler」。我们希望这篇文章能对你在搭建你自己深度学习基础架构时有所帮助。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;用例&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一个典型的深度学习进展通常从有一个想法，在小问题上进行测试开始。在这个阶段，你想非常快地运行许多 ad-hoc 实验。理想情况是，你通过 SSH 接入机器，在屏幕上运行一个脚本，然后在不到一小时的时间内得到一个结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;想让一个模型确实可以工作，通常需要观察它在各种可以想象到的方式失败，然后找到某种方式修复这些限制。（这和你搭建一个新的软件系统类似，你需要运行你的代码很多次才能建立对其工作方式的直觉。）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;iframe class="video_iframe" data-vidtype="1" style="   z-index:1; " height="375" width="500" frameborder="0" data-src="https://v.qq.com/iframe/preview.html?vid=g032571v3vh&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0" allowfullscreen=""&gt;&lt;/iframe&gt;&lt;br/&gt;&lt;/span&gt;&lt;em style="color: rgb(136, 136, 136); line-height: 1.75em; text-align: center;"&gt;&lt;span&gt;你需要从许多角度检查你的模型，从而对它们实际所学习的内容有一种直觉上的认识。Dario Amodei 运用强化学习的代理（agent）（控制右侧的球拍）在 Pong 这个游戏上获得很高的分数，但是当你看它玩的时候，你会认为它就坐在某个地方进行游戏。所以深度学习的基础架构必须允许使用者灵活地检视模型，仅仅显示汇总统计是不够的。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当模型表现出足够的成效时，你就可以将其扩展到更大的数据集以及更多的 GPU 上。这是一个很耗时的工作，需要用掉许多计算周期并且持续很多天。你需要注意你的实验管理工作，并且对你选择的超参数范围进行认真思考。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;早期的研究工作是非结构化的、急促的，而现在是有条理的，还伴随着些许痛苦，但是为了得到一个良好的结果这绝对是必须的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;一个例子&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;论文《Improved Techniques for Training GANs（改进过的训练 GAN 的技术）》开始于 Tim Salimans 构想出的一些用于改进生成对抗网络（Generative Adversarial Network）训练的想法。我们将描述这些想法中最简单的一些（这也碰巧是其中能生成最好看的样本的那些，尽管并不是最好的半监督学习）。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;GAN 由一个生成器（generator）网络和一个鉴别器（discriminator）网络构成。其中生成器会尽力欺骗鉴别器，而鉴别器则会尽力分辨出生成的数据和真实数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;直觉上看，一个能够欺骗每一个鉴别器的生成器是相当好的。但总是存在一个难以修复的故障模式：生成器可以通过一直输出完全一样（很可能非常逼真！）的样本使网络「崩溃」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibCficthDQHbyjskJ3ia44KfnlCia7yqquZ96icjm3VWPJKJM8IDXibuibeFdMwnzfEdDsSXstZVvEnEnQw/0?wx_fmt=png"/&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;我们的模型学习生成 ImageNet 图像&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有了更大的模型和数据集，Ian 还需要将该模型并行化到多个 GPU 上。即使每一项工作都让多台机器上的 CPU 和 GPU 的使用率达到了 90%，但即便如此，该模型的训练还是花费了许多天的时间。在这种情况下，每一次实验都变得非常宝贵，他也会一丝不苟地记录每一次的实验结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，尽管结果很不错，但仍然没有我们希望的那么好。为了找到原因，我们已经测试了很多假设，但仍然还没有解决它。这就是科学的本质。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;基础架构&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;软件&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibCficthDQHbyjskJ3ia44KfnynDzmYmad4NQ7Tw1foM6NUoPMpUAOsfMzZObOb0fm6h3C8HuQtHeGQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;我们的 TensorFlow 代码中的一节&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们的研究的绝大多数代码都是用 Python 写的，可参见我们的开源项目：https://github.com/openai/imitation 、https://github.com/openai/improved-gan 、 https://github.com/openai/iaf 、https://github.com/openai/vime 。在 GPU 计算上，我们大部分使用的是 TensorFlow（一些特殊案例使用了 Theano）；在 CPU 上我们也使用了这些或 Numpy。研究者有时候还在 TensorFlow 之上使用了 Keras 这样的更上层的框架。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;和大部分深度学习社区一样，我们使用的是 Python 2.7。我们通常使用 Anaconda，它有一些方便的软件包；其它情况我们还使用了一些困难的软件包，比如 OpenCV 和针对一些科研方面的库的性能优化：https://docs.continuum.io/anaconda/#high-performance&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;硬件&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于一个完美的 batch 工作，让你的集群中的节点的数量加倍可以让运行时间减半。不幸的是，在深度学习中，人们常常会看到一些来自许多 GPU 的非常次线性（sublinear）的加速。因此顶级的性能需要顶级的 GPU。我们也在模拟器、强化学习环境或小型模型（在 GPU 上运行不会更快）上使用了相当多的 CPU。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibCficthDQHbyjskJ3ia44KfnlyDSxDoScEL5bmTVrmp0iaMoo309LKHHf4sibhnN6DQP6C1StvXEibpWQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;nvidia-smi 查看完全负载的 Titan X&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;AWS 慷慨地同意向我们捐赠大量的计算。我们现在已在使用它们计算 CPU 实例和水平扩展 GPU 的工作。我们也运行着我们自己的物理服务器——基本上是运行在 Titan X GPU 上。我们预计会有一个用于长期作战的混合云：在不同的 GPU、互连（interconnect）和其它可能会在深度学习的未来变得重要的技术上进行实验是很有价值的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibCficthDQHbyjskJ3ia44KfndJuF16nfkEs09tl415a00CIVfLgMOqvJzfMKz84X8dChibmhZPIVPgg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;同样物理基础的 htop（http://hisham.hm/htop/）表现出了大量空余的 CPU。我们通常将我们 CPU 密集型负载和 GPU 密集型负载分开运行。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;配置&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们的基础架构方法就和许多公司对待产品一样：它必须有一个简单的界面，而且易用性和功能一样重要。我们使用一套统一的工具来管理我们所有的服务器，并将它们尽可能配置得完全一样。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibCficthDQHbyjskJ3ia44KfncQgPQ6sQOFenxZ64kwCianWgAnBDgE4rwgNFU3V7H1Srm62D7moU0ow/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;我们用来管理 Auto Scaling 组的 Terraform 配置的一个片段。Terraform 可以创造、修改或破坏你的运行云资源以匹配你的配置文件。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们使用 Terraform 来设置我们的 AWS 云资源（如，网络路由、DNS 记录等）。我们的云和物理节点使用的是 Ubuntu，并配置了 Chef。为了更快的 spinup times，我们使用 Packer 预焙（pre-bake）了我们的集群 AMI。我们所有的集群都使用了互不重叠的 IP 地址范围，并且通过用户笔记本电脑上的 OpenVPN 和物理节点上的 strongSwan（作用类似 AWS Customer Gateways）与公共互联网进行了互连。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们将人们的主目录、数据集和结果存储在 NFS（物理硬件）和 EFS/S3（AWS）上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;编排&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;可扩展的基础设施往往最后会使简单的情况变得更困难。我们在用于小型和大型工作中的基础设施上投入了同等的努力，而且我们正在积极地充实我们的用于将分布式用例变得本地可访问的工具包。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们提供了一个用于 ad-hoc 实验的 SSH 节点集群，并使用了 Kubernetes 作为我们的物理和 AWS 节点的集群调度器。我们的集群横跨 3 个 AWS 区域（regions）——我们的工作是很有突发性的，我们将在某个时候达到单个区域的能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Kubernetes 要求每项工作都是一个 Docker 容器（container），这给我们带来了依赖隔离（dependency isolation）和代码快照（code snapshotting）。但是，构建一个新的 Docker 容器会给研究者宝贵的迭代周期增加额外的几秒钟时间，所以我们也提供了可以帮助研究者将笔记本中的代码透明地转换成标准图像的工具。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibCficthDQHbyjskJ3ia44KfnB6ibgm3oYsZga0THYxFECMDP23o0zlN3Mhch1xXIHF2woHrnEa0C4mA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;TensorBoard 中的模型学习曲线&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们直接向研究者的笔记本电脑公开了 Kubernetes 的 flannel network，让研究者可以无缝网络接入他们的运行中的工作。这对于获取 TensorBoard 这样的监控服务尤其有用。（我们最初的方法——从严格的隔离角度来看更清洁——需要人们为每个他们想要公开的端口创建 Kubernetes Service，但我们发现这会带来太多的麻烦。）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;kubernetes-ec2-autoscaler&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们的工作具有突发性与不可预测性：研究的线路可能很快地从单机实验到需要 1000 个核。例如在几周内，我们的一个实验就从处于在一台 Titan X 上运作的阶段，到了在 60 台Titan X、需要 1600 块 AWS GPU 上进行实验的阶段。因此我们的云架构需要动态提供 Kubernetes 的节点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在一个 Auto Scaling 组中运行Kubernetes节点是很容易的，但是很难正确管理这些组的大小。在提交一个批任务之后，所在集群（cluster）知道自己需要什么资源，应该直接分配这些资源。（相反的，AWS 的 Scaling Policies（扩展策略）则需要多次迭代，一点点释放新的节点，直到资源不再紧张。）此外，在终止它们以避免丢失正在运行的任务之前，集群还需要消耗节点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;仅使用 raw EC2 来完成大批量的任务是具有吸引力的，这也是我们开始的地方。然而，Kubernetes生态环境增加了很多内容：低摩擦工具（low-friction tooling）、记录日志、监控、独立于运行实例管理物理节点的能力等等。让 Kubernetes 正确地自动扩展要比在 raw EC2 上重建这个生态系统更加简单。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们正在发布 kubernetes-ec2-autoscaler （https://github.com/openai/kubernetes-ec2-autoscaler），这是一个 Kubernetes 的批优化过的扩展管理器（batch-optimized scaling manager ）。它作为一个普通的 Pod 运行在 Kubernetes 上，仅仅需要的是你的节点在 &amp;nbsp;Auto Scaling 组中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibCficthDQHbyjskJ3ia44KfnB0ibLRk5qQIAPibB55ngn7odVQ9sQv7M1NmKgHiaolSEvnubBmjbZMWLg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;em style="color: rgb(136, 136, 136); line-height: 1.75em; text-align: center;"&gt;&lt;span&gt;Kubernetes 集群的启动配置&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;自动扩展器（autoscaler）是通过对 Kubernetes master 的状态进行查询的方式工作的，其中包括计算集群资源的询问与容量所需的一切。如果超出容量限制，它将耗尽相应的节点，最终停止它们。如果需要更多的资源，它会计算哪些服务器要被创建，并适当地增加你的 Auto Scaling 组的大小（或就简单地使用 uncordons drained 节点，这可以避免新的 spinup time）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;kubernetes-ec2-autoscaler 可以处理多种 Auto Scaling 组、CPU 之外的资源（内存和GPU）以及在 AWS 区域以及实例的大小等细节上约束你的任务 。另外，突发的工作负载可以导致 Auto Scaling 组超时、出错，这是因为即使 AWS 也没有无限的容量。在这些情况下，kubernetes-ec2-autoscaler 会检测错误，并将超出部分转移到下一级的 AWS 区域。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 31 Aug 2016 15:40:57 +0800</pubDate>
    </item>
    <item>
      <title>深度 | 机器人为什么能写稿，以及它们能拿普利策奖吗？</title>
      <link>http://www.iwgc.cn/link/2499490</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心原创&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：赵云峰&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;里约奥运会期间，写稿机器人「Xiaomingbot」通过对接奥组委的数据库信息，可以进行实时撰写新闻稿件，在 16 天内发布了 456 篇资讯报道，平均新闻生成到发布时间为 2 秒钟，几乎达到电视直播的传播速度。Xiaomingbot 是今日头条实验室研发的AI机器人，可以通过两种文本生成技术产出新闻：一是针对数据库中表格数据和知识库生成自然语言的比赛结果报道，即简讯；二是利用体育比赛文字直播精炼合成比赛过程的总结报道，即资讯。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibCficthDQHbyjskJ3ia44KfnfUPF9p3Jq7zkdsLBcEz0Z9icA0jBAliczUnyWA0OmpRzLeuWc1DGqbiaQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;随着自然语言处理、知识库等人工智能技术的发展，许多媒体已经开始了机器人报道的探索。《纽约时报》数字部门开发了机器人编辑 Blossomblot ，每天推送 300 篇文章，每篇文章的平均阅读量是普通文章的38倍。此外，《纽约时报》还会在财报季、运动比赛报道的时候使用机器人来写稿；美联社在过去一年多时间里使用 Wordsmith 系统编发企业财报；在华尔街引起巨大反响的 Kensho 可以通过接入美国劳工部等数据源来自行创造投资分析报告；电讯社也计划使用雅虎在报导梦幻橄榄球联赛时用到的技术，用来发布一些美式橄榄球回顾；Automated Insights 的写作软件去年写了 150 亿篇文章，宣称自己是世界上最大的内容生产者；路透社也在发表机器撰写的文章，该系统的负责人认为「在一次盲测中，机器的作品表现得比人类作品更具可读性。」；此外，还有专门提供「标题党」服务的 Click-o-Tron 公司。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;媒体领域出现这种趋势的原因在于相关技术已经达到了一定的成熟度，而且这种成熟度是和新闻媒体的要求很好的匹配在了一起。在卡斯韦尔的「结构化故事」系统中，所谓的「故事」完全不是个故事，而是一个信息网，我们可以像对待文案、信息图表或者其它表达形式一样去组装它，阅读它，就像我们摆弄音乐音符一样。任何一类信息——从法院报道到天气预报——都能够最终能放入到这个数据库中。这样的系统的潜力是巨大的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「大多数自然语言系统都是在简单地描述一个事件。但是大多数新闻都是描绘性的，甚至是事件驱动的」来自密苏里大学 Donald W Reynolds 新闻机构的大卫·卡斯韦尔说。「事件们在不同的地点发生，这些事件之间的因果关系是这些事件的核心叙述结构。」需要把它们放到古老的新闻术语中：谁，发生了什么，在哪里，什么时候。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;根据 Donald W Reynolds 的说法，人工智能系统在进行新闻创作时需要解决非常多的技术难题，包括自然语言处理中的自动摘要、文本分类等，还有知识库和知识发现（KDD）等相关技术，比如实体定义、关系抽取、问答系统等。简单来说，就是机器首先需要理解自然语言，然后通过知识管理弄明白新闻中各个要素（各类知识）之间的关系。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;自然处理技术所有信息密集型处理过程的核心，也是今年以来谷歌、Facebook 和微软等科技巨头都最为重视的研究方向，在刚刚结束的语言学顶级会议 ACL 上，他们也都发表了众多重磅论文。谷歌开源了SyntaxNet，将神经网络和搜索技术结合起来，在解决歧义问题上取得显著进展——能像训练有素的语言学家一样分析简单句法；Facebook 推出了文本理解引擎 DeepText ，每秒能理解几千篇博文内容，语言种类多达 20 多种，准确度近似人类水平。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其中，阅读和理解人类语言对机器来说是一项极具挑战性的任务，这需要对自然语言的理解以及根据多种线索推理的能力。阅读理解是现实世界中的一个普通问题，其目的是阅读和理解给定的文章或语境，并基于此回答问题。在多种类型的阅读理解问题中，完形填空式的查询是基础的一类，并且也已经变成了解决机器理解问题的起点。与普通的阅读理解问题类似，完形填空式的查询（Taylor, 1953）是基于文档的本质提出的，尽管其答案是文档内部的单个词。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了教会机器完成完形填空式的阅读理解，需要学习给定文档和查询之间的关系，因此必须要大规模的训练数据集。通过采用基于注意（attention）的神经网络方法（Bahdanau et al.,2014），机器可以学习大规模训练数据中的这些模式。为了创造大规模训练数据，Hermann et al. (2015) 发布了用于完形填空式的阅读理解的 CNN/Daily Mail 新闻语料库，其中的内容由新闻文章及其摘要构成。之后 Hill et al.（2015）发布了 Children’s Book Test （CBT：儿童图书测试）数据集，其中的训练样本是通过自动化的方式生成的。此外，Cui et al.（2016）也发布了用于未来研究的汉语阅读理解数据集。正如我们所见，自动生成用于神经网络的大规模训练数据对阅读理解来说是至关重要的。此外，语境的推理和总结等更复杂的问题需要远远更多的数据才能学会更高水平的交互。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今年六月份，人工智能创业公司 Maluuba 公司发表了一篇关于机器理解的论文，提出了目前最先进的机器阅读理解系统 EpiReader ，该模型在 CNN 和童书测试（CBT）两个数据集上的成绩都超过了谷歌 DeepMind 、Facebook 和 IBM 。EpiReader 采取两个步骤来确定问题答案。第一步(Extractor), 我们使用了一个双向 GPU 逐字阅读故事和问题，接着采用一种类似 Pointer Network 中的 Attention 机制在故事中挑选出可能作为答案备选的单词。第二步( Reasoner )，这些备选答案被插入「完型填空」式的问题中，构成一些「假设」，接着卷积神经网络会将每个假设与故事中的每个句子加以比较，寻找文本蕴涵( Textual Entailment )关系。简单来说, 蕴涵是指，两个陈述具有很强的相关性。因此，最近似故事假设的蕴涵得分最高。最后，将蕴涵得分与第一步得到的分数相结合，给出每一个备选答案正确的概率。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;国内的哈工大讯飞实验室也提出了一种用于完形填空式阅读理解任务的全新模型，这被称为 attention-over-attention（注意之上的注意）阅读器。我们模型的目标是在文档级的注意之上放置另一种注意机制（attention mechanism），并诱导出「attended attention（集中注意）」以用于最后的预测。和之前的成果不同的是：我们的神经网络模型只需要更少预定义的超参数，并且可以使用一种简洁的架构进行建模。实验结果表明我们提出的 attention-over-attention 模型在大量公共数据集中都显著优于当前许多最佳的系统，例如 CNN 和「（Children’s Book Test）儿童图书测试」数据集。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;CMU 的 Mrinmaya Sachan 和邢波在 ACL 2016 上发表论文《用丰富的语义表征来实现机器理解》，通过用如指代和修辞结构这种跨句现象来合并组成句子的 AMR，从而为给出的文本和每个问答对建构意义表征图（meaning representation graph）。然后将机器理解降格成为了一个图包含问题（graph containment problem）。假定问答含义表征图（question-answer meaning representation graph ）和文本含义表征图（text meaning representation graph ）之间存在一个隐含的映射，该映射能够解释该答案。他们提出了一个统一的最大边缘框架，它能学习发现这个映射（给定一个文本语料库和问答对），并使用它学到的来回答关于新文本的问题。他们发现这个方法是目前完成这类任务的最好方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在知识库方面，谷歌自然语言处理技术专家 Enrique Alfonseca 认为，挑战包括知识库的实体解析和一致性问题。两年前，谷歌的一些员工发布了一个实体解析注释的超大文集，这个大的网络文集包括对 Freebase 主题的110亿次引用，它是由世界上研究信息提取的研究人员开发的。知识集指的是真实世界（或者虚拟世界）的结构化信息，在许多其他应用中，人们能够对文字进行语言分析。这些一般包括主题（概念和实体）、属性、关系、类型层次、推理规则、知识表征和人工、自动知识获取的研究进行了许多年，但是这些都是远未解决的难题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;CMU 的 Sujay Kumar Jauhar 认为，问答需要一个知识库来检查事实和推理信息。自然语言文本形式的知识学习起来比较简单，但是自动推理很难。高度结构化的知识库能让推理变得容易一些，但是学习起来又难了。他们在近期 ACL 上发表论文，探讨了半结构形式主义（semi-structured formalism ）的表来平衡这两种情况。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而上文提到的Xiaomingbot的主人今日头条实验室近期也在这方面取得进展——通过深度学习和知识库的结合来解决知识类问答问题。今日头条实验室科学家李磊博士表示，知识在知识库里表达成三元组形式的结构化信息，系统要做的事情是问了这个自然语言问题后，从知识库里找出这样的答案。这个问题的难度在于：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1）知识库非常大，从海量数据中找出答案是非常困难的；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2）自然语言问题本身比较复杂，因为有多种问法和表达方式；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3）训练数据非常有限。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而今日头条实验室提出的深度学习加上知识库的CFO方法是，首先观察到需要把自然语言问题表达成结构化 query ，把这个结构化 query 里的条件信息从问题里找出来。和传统方法不同，CFO 通过神经网络用了一个 Stacked Bidirectional GRU ，它是一个上下叠加起来的多层双向循环神经网络，通过这个模型去计算出问题中的实体以及实体之间的关系，之后就是构建结构化的查询语句以及从知识库里寻找答案。在测试结果上，准确率超过了微软和 Facebook。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些在自然语言处理、知识库方面最新的研究进展将会传导到人工智能在新闻领域的应用，就像今日头条此前所做的智能推荐一样，通过每天观察数千万用户的刷新，点击，搜索，收藏，评论的行为，不断加强对用户兴趣偏好的理解，从而能够不断提高推荐的准确性，成为在资讯推荐领域的人工智能。希望靠算法连接内容创作者和消费者。而现在，技术的进步将使这个边界获得再次延伸。就像今日头条创始人兼 CEO 张一鸣预言的那样，未来人工智能演化的第一阶段首先是在各个垂直领域诞生若干超级智能，比如资讯推荐领域的今日头条，健康和知识问答领域的沃森，围棋领域的 AlphaGo 。这些垂直超级智能可以在特定领域内展现出远超人类的能力，但是在擅长领域之外没有任何作为。不过，他们将为诞生在所有领域内都具备超人能力的终极智能打下基础。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而越来越多的机器人创作将成为媒体领域超级智能的开始，目前 Xiaomingbot 的资讯生成部分即实时文本生成研究是今日头条同北大计算机所万小军教授团队合作，用于问答系统的 CFO 也将应用在今日头条的其他媒体产品中。李磊表示，今日头条有个产品叫「头条问答」，我们希望对于一些简单的问题和事实类的问题可以通过自动回答的方式去解决，这样就可以节省专家人力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Xiaomingbot、CFO 只是头条实验室众多研究布局中的阶段性成果，后者旨在推动人工智能技术研究，让算法更好地理解文字、图片、视频、环境场景和用户兴趣，从而促进人类信息与知识交流的效率和深度。今日头条不仅仅是新闻客户端，是一款基于机器学习的个性化资讯推荐引擎，是所有信息、内容分享创作的平台。人工智能和机器学习的算法起到了重要作用，能够帮助高效精准地把用户感兴趣的内容推荐出去。今日头条的内容平台对应着双边用户：一边是内容的创作者，另一边是内容的消费者。所以为了把最好的内容推荐给最需要的读者，就需要机器学习的技术。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今日头条等媒体巨头对人工智能技术在研发和应用上的加码，让我们看到了人工智能在未来对媒体业造成的巨大影响。《浅薄》中提到，互联网作为一种智力工具，在给我们带来便利的同时也在重塑着我们的思维方式。随之而来的问题是，互联网这种媒介传递的信息越多，我们想找到优质或者自己所需信息的难度也就越大。而这正是人工智能的优势所在，它可以让大数据从负担变成便利，会重塑媒体的内容生产和分发。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在采用 Wordsmith 之前，美联社需撰写约 300 家公司的财报文章，可想而知这并不是个轻松的工作量。在使用机器人 Wordsmith 之后，美联社每季度可以出 3000 家公司财报，虽然其中仍有 120 篇需要人力更新或添加独立的后续报道，但显然它替人类编辑承担了绝大部分的工作量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在哥伦比亚大学庆祝普利策奖诞生一百年之际，智能机器人也将在财经报道、体育实况报道、骗点击的标题党新闻（clickbait）以及其它原本只有受过训练的记者才能报导的领域开始一展身手。「总有一天，机器人会赢得普利策奖」，来自 Narrative Science 的 Kris Hammond 如此预测。这家公司专注于「自然语言生成」。「我们能讲述隐藏在数据中的故事。」最近的进步味着，人工智能现在能够撰写出具有可读性的流畅文字，并且还能比亢奋的写手更快地大量炮制模板型文章。「有了自动化，我们现在能为 4,000 家公司追踪、 撰写季度收益报告，」来自世界第一个也是迄今为止唯一个使用自动化编辑的通讯社——美通社的贾斯汀· 迈尔斯说，「以前我们只能做到 400 家。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而对于机器人能否拿普利策新闻奖这个问题，迈尔斯也「绝对相信」——因为机器人已经做到了。Bill Dedman 因一篇抵押贷款中存在种族主义问题的调查报道，而获得了普利策奖。这篇报道虽然发表于 1988 年，却是由电脑协助写作成的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;自动化新闻不仅仅具有数量优势，还有助于定位客户需求——通过用户画像、情感分析等技术为用户提供个性化内容，或者对于智能对话系统与用户进行交互。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;随着人工智能技术在新闻领域的参与程度越来越高，对于人工智能技术是否造成失业问题的争论也愈演愈烈。牛津大学此前发布了一篇报告称，目前 47% 的工作岗位将最终被自动化。但对此的批评意见认为，工作被取代，并不意味着劳动者将失去工作，正如曾经汽车的出现取代了许许多多的马车夫和马童，但同时创造了更多修建高速公路和服务加油站的工作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于媒体领域来说同样如此，机器人负责这项单调而又乏味的工作就能把记者们解放出来，让他们追求一些需深度思考的报道，同时机器人也可以将消费者从海量信息中解放出来，提高他们获取信息和知识的效果和效率，而这就是人工智能对媒体的最重要影响。不久的未来，我们将看到人工智能作为工具在新闻产业产出发挥重要的作用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心原创，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 31 Aug 2016 15:40:57 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 自动驾驶汽车怎么和人类交流？创业公司Drive.ai正在解决这个问题</title>
      <link>http://www.iwgc.cn/link/2499491</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自 IEEE Spectrum&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：&amp;nbsp;Evan Ackerman&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：Rick. R、吴攀、杜夏德&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;em style="color: rgb(136, 136, 136); line-height: 1.75em;"&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em style="color: rgb(136, 136, 136); line-height: 1.75em;"&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;em style="color: rgb(136, 136, 136); line-height: 1.75em;"&gt;&lt;span&gt;在自动驾驶研发领域都在专注于在自动驾驶的机制上开发时，创业公司 Drive.ai 另辟蹊径选择了与自动驾驶汽车与周围环境（主要是人类）进行通信的发展方向。今天，这家神秘的创业公司走出了隐身模式，发布了一款帮助将现有的汽车改装成自动驾驶汽车的套件。另外，本文还包含了 IEEE Spectrum 对 Drive.ai 联合创始人兼总裁 Carol Reiley 博士的专访。&lt;/span&gt;&lt;/em&gt;&lt;br/&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;大多数自动驾驶方面的研究者们都非常专注于使汽车免于碰撞之类的事情，这可以理解。而在一般情况下，这恰恰是自动驾驶汽车已经非常擅长做的事情——特别是在公路上以及其他一些区域中，驾驶员不必担心周围会出现突如其来的行人，从而不必进行更复杂和更困难的思考。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Drive.ai 是一小部分正在推动自主驾驶技术快速商业化的创业公司之一。这家公司于今年四月走出了隐身状态，IEEE Spectrum 也曾写了有关其自上而下的深度学习（top-to-bottom deep learning）解决方法。如今，Drive.ai 是「正式出山」了，而我们已经了解到了有关该公司的更多内容。Drive.ai 正在兜售一种改装套件——一组为商业车提供的可以使现存车辆变身成为完全自动驾驶的工具。但与众不同的是，它含有一个 HRI（人机交互）组件，即一个能使汽车直接与人进行交流的超大显示器。乍一看这似乎是个全新的东西，但它却是自动驾驶汽车迫切需要的一个功能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;理解自动驾驶汽车被赋予这种交流能力的原因是非常重要的，试想一下当你试图走过一条无法被控制的人行横道的情况。一辆迎面而来的汽车可能会因为你而减速，但通常情况下，在你穿过道路之前会与司机进行眼神交流，确保他们已经看到你了并且会停止前进。现在想象同一情形下的一辆无人驾驶汽车。在无人控制的情况下，你如何知道汽车是否已经：1）完全检测到你；2）明白你想做什么；3）决定是否会为你停下？&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;无论是在行人、骑自行车或其他驾驶员之间，这样的交流发生得比你可能会意识到的更加频繁。它也可能没有实际上应该发生的那么频繁（我认为自己是一个这方面的专家，因为我上周末从纽约开车到了华盛顿。）。实际上自动驾驶汽车不仅会使用其转向信号，也会传达更复杂的概念，它们甚至可以礼貌地要求并道，提供诸如「减速防止前方事故」这样的有用信息，或者甚至是在超车占道时向你道歉，当然它们可能不会那么做。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在第一代商业化的自动驾驶汽车中聚焦 HRI 的基本必要性源自这样一个事实：大部分人类驾驶员与大部分自动驾驶汽车之间将有一个重要的过渡期。一旦道路上行驶的都是自动驾驶汽车，而且车辆之间可以进行无线通信，那么这就不是个大问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有时能感觉到自动驾驶汽车公司高度关注于那个终极目标。而由于过渡期将是混乱不堪的，常见的解决方案就是要么忽略它（「我们以后会处理它」），要么试图规避这个问题。回到人行横道的例子，与确实帮助人们安全过马路相反，区别在于能否确保你的自动驾驶汽车不会在人行横道上撞到别人。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibCficthDQHbyjskJ3ia44KfnYGaOC9cLZfE94v1dzlZibVk2okS69bJhWHLONczcM15LRpEBZ8uicaDg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了得到更多无人驾驶汽车应用 HRI 的细节，以及更多有关 Drive.ai 自动驾驶的全栈深度学习（full stack deep learning）方法，我们采访了 Drive.ai 的联合创始人兼总裁 Carol Reiley 博士：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;IEEE Spectrum：Drive.ai 的自动驾驶技术有什么特别的地方？&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Reiley：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我把自动驾驶汽车看作大多数人将与之互动的第一个社会机器人。它不是人形的，而是一个通过人工智能实现的智能机器。（我们不得不问自己），一旦你解决了从 A 点到 B 点的问题，这些自动驾驶汽车如何与道路上的所有其他玩家互动？这种关系是什么样的？以及发生在人行横道上、路口或当你试图并道时的非语言之舞是什么？当你替代了方向盘后的人类时，这辆车会如何反应？它如何进行沟通才能让每个人都感到安全并信任它呢？我们觉得这是一个人们还没有太多谈论的话题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;Spectrum：在你谈到通过人工智能来实现一个更智能的机器人时，它是如何在自动驾驶背景下进行的？在 2007 DARPA Grand Challenge 中运用的人工智能与目前自动驾驶汽车所使用的有何不同？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Reiley：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;这个问题有很多不同层面。我们正在从头运用深度学习来创建公司；在美国国防部高级研究计划局（DARPA）的那段时间进行的是前期的深度学习。 Sebastian（即 Thrun (http://robots.stanford.edu/)，他在谷歌开发自动驾驶汽车之前，带领的是斯坦福大学的 DARPA Grand Challenge团队）曾说：「计算机视觉行不通，我支持高清地图和激光雷达。」而谷歌的自动驾驶汽车计划就是这样被建立的：在计算机视觉行不通的设想之上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2012 年，Google Brain 彻底改变了计算机视觉与感知方面的人工智能，而现在这个行业都是由深度学习支撑的。在这一点上，谷歌已经在非深度学习方法上投资了数年，而他们正在一个模块一个模块地进行切换，但很难从根本上改变这个方法。这是我们创业的优势之一：我们是在从头创办一家深度学习自动驾驶汽车公司。而且我们不仅用它来进行感知，也将它用于决策。这是一个更加闭环的方法。这是我自从 DARPA Grand Challenge 时期以来对人工智能所发生的变化的一个看法。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Spectrum：你们的汽车用的是什么传感器？你觉得摄像头和激光雷达相比如何？&lt;/span&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Reiley：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;这正是我们的深度学习流程所面临着的问题：什么样的传感器适合你的车，我到底要收集多少数据，以及到底需要驾驶多少英里才够。在深度学习方面，我们目前是希望把传感器的成本降得比以往任何时候都更低。摄像头是非常便宜的传感器，而且有了深度学习后，就可以对图像置于语境中处理。对于冗余的部分，我们有其他的传感器，但是比起其他团队，我们真的在推动摄像头要努力得多，而机器学习帮我们做到了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;某些团队把激光雷达安放在车的前面和中心位置，否则他们就会认为没有高清地图，你就不能解决这个问题。即便没有地图人也能在熟悉的附近开得很好，他们基本上有一个相当于（立体）相机的东西。我们的团队欢迎任何低成本的传感器；如果 Quanergy 能拿到 100 美元的传感器，那就太棒了，我们一定会用它的。我们并不是在炫耀我们能用摄像头做高难度的事情；我们只是尝试建立安全且人们能真正使用并能负担得起的系统。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;Spectrum：为什么HRI 对于自动驾驶汽车来说如此重要？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Reiley：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;一个人开车时，他会观察周围环境中的所有相关线索。例如，你看见前面有辆车，如果它的车轮向右转，你就可以推测它下一个动作：它可能要右转。真实世界中有很多这种微妙的线索可以用来帮助我们导航，而且使[我们的汽车]看起来具有更多社会智能，因为你能在它们做出动作之前就能预测到会发生什么。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们正在推动自动驾驶汽车在社会互动方面的技术。人类与人类的非语言交流有时可能会很让人困惑。当你把人移开，这些车就得智能到可以自己导航，而且能被这条道路上的所有人接受，同时要保证非常安全。所以，在一个四岔路口，路人与车之间会发生什么呢？我们正在探寻车该如何表达自己，我们用 LED 灯，像 R2-D2 这样的声音来传递信息，或者通过不同的移动方式来显示车的意图。我们正在考虑如何让我们的汽车与其他人沟通。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;驾驶的一个有趣之处是它是动态的，涉及到很多人类，而人类是不可预测的。对于一辆必须进行实时决策的自动驾驶汽车而言，它需要在切换模式时保持非常透明，所以它不只是显得不稳定。我们如何向外部世界说明这辆汽车是自动的呢，以及我们如何表示我们的意图是什么呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;Spectrum：这种对 HRI 的重视是否意味着汽车自动化的实际驾驶部分已经（几乎）得到解决了呢？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Reiley：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我觉得这个行业的大部分都在关注驾驶的机制。这不是说 HRI 与那是完全不同的；我将其看作是高度的耦合，是应该并行发展的东西，而不是一样一样地做。这不只是某种实验室里面的机器人。存在许多与人类相关的问题需要考虑。我认为汽车行业在很多事情上采用了模块化的方法，但自动驾驶汽车并不是模块化的问题：它们是一种基于软件的、整体性的东西，你必须退后一步了解其整体面貌。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;Spectrum：Drive.ai 在这方面有什么计划？&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Reiley：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我们不造汽车；我们的业务是创造改装套件。所以需要选择有兴趣交付货物或交付人的合作伙伴。已有的汽车进入 Drive.ai &amp;nbsp;的工厂，然后我们为其添加带有传感器和 HRI 组件和软件的车顶架，而且我们也在与这些合作伙伴合作做固定路线的驾驶。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们将这看作是自动驾驶汽车的安全的、逻辑上的第一步。我认为自动驾驶汽车的全球部署将会带来大规模的混乱。我认为人们目前还没有将人类看作是其中的一环。即使我们解决了自动驾驶汽车的问题，更大的问题实际上是人类。人类会搞砸一切，而且你必须为人类使用自动驾驶汽车的情况进行设计，还有他们会怎样理解他们周围的事物。我们想要快速推出这项技术，我们将这种与我们合作伙伴的固定路线的策略看作是第一步。而且我们肯定有兴趣做一种 4 级的（完全自动）方法，因为 3 级的（其中人类还控制着一些事情）也是很混乱的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibCficthDQHbyjskJ3ia44KfnmkKtzBWGuyuumlMw71jkhG9k89TbjrIWqIgxjZSrlTu4VbdKJUYHUw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Drive.ai 有其自己的车队，它们将在加州山景城附近进行测试。该公司的愿景涉及到汽车「能够与我们透明地沟通，即使没有人类司机」。最后 Drive.ai 的业务将会扩展到公共和私人货运领域。有媒体报道称他们目前已经和一些重要的 OEM 和汽车供应商建立了合作关系。再加上他们已经获得了 1200 万美元的融资，也许一两年之内，我们就能在加州的道路上看到带有友好的大屏幕的汽车了吧。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 31 Aug 2016 15:40:57 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 谷歌开放TF-Slim：在TensorFlow中定义复杂模型的高层库（附论文）</title>
      <link>http://www.iwgc.cn/link/2499492</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自 Google Research Blog&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：&amp;nbsp;Nathan Silberman 、 Sergio Guadarrama&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：杜夏德、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今年早些时候，我们发布了一款在 TensorFlow 上的最先进的图像分类模型实现——Inception -V3。这些代码允许用户使用一个单一的本地机器或机器集群在 Image Net 分类数据集上通过同步梯度下降（synchronized gradient descent）的方式训练模型。该 Inception-V3模型建立在 TenorFlow 的 TF- Slim 实验库上，它是一个用于在 TensorFlow 中定义、训练和评估模型的轻量软件包。这个TF-Slim 库提供了常见的抽象，可以使用户简要快速地定义模型，同时还能维持模型架构透明和其超参数的明确性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;自发布以后，TF-Slim 增长迅速，添加了多种类型的层、损失函数和评估指标，用于训练和评估模型的方便的例程（routine）也越来越多，。这些例程考虑到了扩展工作时你需要担心的所有细节，比如并行读取数据、在多台机器上部署模型等等。此外，我们已经利用标准数据集创建了 TF-Slim 图像模型库（TF-Slim Image Models library），可以为许多广泛使用的图像分类模型提供定义和训练脚本。TF-Slim 和它的组件已经在谷歌内部得到了广泛使用，而很多改进已经被集成到 tf.contrib.slim 中。（https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/slim）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今天，我们很高兴与 TF 社区共享最新的 TF-Slim 版本。以下几点需要强调：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;许多新种类的层（如 Atrous Convolution 和 Deconvolution）丰富了神经网络架构的大家庭。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;支持更多的损失函数和评估指标（例如，mAP，IoU）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;一个部署库，可以使得用多个 GPU / CPU在同一台机器或多台机器上执行同步或异步训练变得更简单：https://github.com/tensorflow/models/blob/master/slim/deployment/model_deploy.py&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;用于定义和训练许多使用广泛的图形分类模型的代码（例如，Inception[1][2][3]，VGG[4]，AlexNet[5]，ResNet[6]）：https://github.com/tensorflow/models/tree/master/slim/nets&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;用于上述图像分类模型的预训练模型权重。这些模型已经在 ImageNet 分类数据集上训练过了，但是也能用来执行很多其他的计算机视觉任务。举个简单的例子，我们提供了可以微调这些分类器以适应一个新的输出标签集合的代码。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;容易处理标准图像数据集的工具，如 ImageNet，CIFAR 10 和 MNIST。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;想尝试一下 TF-Slim 吗？这条链接（https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/slim）可以帮到你。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你想试试图像分类模型可以看下这条介绍（https://github.com/tensorflow/models/blob/master/slim/README.md）或者 Jupyter notebook（https://github.com/tensorflow/models/blob/master/slim/slim_walkthough.ipynb）&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;参考文献：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;em style="color: rgb(136, 136, 136); line-height: 1.6;"&gt;&lt;span&gt;[1] Going deeper with convolutions, *Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, Andrew Rabinovich, CVPR 2015*&lt;/span&gt;&lt;/em&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[2] Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift，*Sergey Ioffe, Christian Szegedy, ICML 2015*&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[3] Rethinking the Inception Architecture for Computer Vision , *Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens, Zbigniew Wojna, arXiv technical report 2015*&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[4] Very Deep Convolutional Networks for Large-Scale Image Recognition, *Karen Simonyan, Andrew Zisserman, ICLR 2015*&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[5] ImageNet Classification with Deep Convolutional Neural Networks , *Alex Krizhevsky, Ilya Sutskever, Geoffrey E. Hinton, NIPS 2012*&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[6] Deep Residual Learning for Image Recognition, *Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun, CVPR 2016*&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;点击「阅读原文」，下载论文↓↓↓&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 31 Aug 2016 15:40:57 +0800</pubDate>
    </item>
  </channel>
</rss>
