<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>机器之心</title>
    <link>http://www.iwgc.cn/list/670</link>
    <description>人与科技的美好关系</description>
    <item>
      <title>深度 | 谷歌发布YouTube-8M：单个GPU一天就能完成训练的最大视频数据集（附论文）</title>
      <link>http://www.iwgc.cn/link/2884651</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Google Research&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Sudheendra Vijayanarasimhan、Paul Natsev&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器学习和机器感知领域近来的许多突破都可归功于大型有标注数据集的可用性，例如 ImageNet，其包含了分成了数千个类别的数百万张有标签的图像。它们的可用性显著加速了图像理解领域的研究，例如检测和分类静态图像中的物体&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;视频分析能为检测和识别物体、理解人类行为和与世界的交互提供更多的信息。改善视频理解能带来更好的视频搜索和发现，这类似于图像理解帮助重新想象照片中的经历的方式。但是，这一领域进一步发展的一个关键瓶颈是缺乏与图像数据集同等规模和多样性的真实世界视频数据集。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今天，我们很高兴宣布发布 YouTube-8M——该数据集包含了 800 万个 YouTube 视频 URL（代表着 500,000 小时的视频）以及它们的视频层面的标签（video-level labels），这些标签来自一个多样化的包含 4800 个知识图谱实体（Knowledge Graph entity）的集合。相比于之前已有的视频数据集，这个数据集的规模和多样性都实现了显著的增长。比如说，我们所知的之前最大的视频数据集 Sports-1M 包含了大约 100 万段 YouTube 视频和 500 个体育领域的分类——YouTube-8M 在视频数量和分类数量上都差不多比它高一个数量级。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicQUibx1s2Llj1oosE69QCicOxjcCG3FssrxrxmrcfQEXmOtgfPhs58iarib1HIVUGCVBrAmu81ibsq5Fw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了构建一个这样大规模的有标签视频数据集，我们需要解决两个关键难题：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="list-style-type: decimal;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;用人工标注的话，视频标注比图像标注所需的时间远远更多；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;视频的处理和存储的计算成本非常高。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了克服难题 1，我们使用了 YouTube 及其视频标注系统（video annotation system）。该系统可为所有公开的 YouTube 视频确定相关的知识图谱主题。尽管这些标注是机器生成的，但它们整合了来自数百万用户的强大的用户参与信号（user engagement signals）以及视频元数据和内容分析。由此，这些标注的质量是足够高的，可用于视频理解研究和制定标准的目的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了确保该有标注视频数据集的稳定性和质量，我们仅使用了包含超过 1000 条评论的公开视频，而且我们创建了一个多样化的实体词汇集（vocabulary of entities）——这些实体都是视觉上可见的，而且出现的频率也足够高。该词汇集的创建结合了频率分析、自动过滤、人类评估者验证该实体是视觉上可见的、以及分组成 24 个顶层的垂直类别（更多详情参见我们的技术报告）。下图描述了其数据浏览器（dataset browser：https://research.google.com/youtube8m/explore.html）和在顶层垂直类别的视频分布，同时也说明了该数据集的规模和多样性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicQUibx1s2Llj1oosE69QCicOibn9vIZV3wDPqvld1KaAkiciaRBulnsicLAfErxylSbZEBy2bglUmUaejw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;数据浏览器允许浏览和搜索整个知识图谱实体词汇集，它们被分成了包含了对应视频的 24 个顶层的垂直类别。这张截图描述了一个标注了实体「Guitar」的数据集视频的子集。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicQUibx1s2Llj1oosE69QCicOMdLwD3lJQR76NN9OBvbImHpyd7FU3ibdibUAVlv0qooZiaiaqXW8wKLMhA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;该顶层垂直类别的视频分布说明了该数据集的规模和多样性，同时也反映了流行的 YouTube 视频的自然分布。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了解决难题 2，我们必须克服研究者处理这些视频时所面临的存储和计算资源的瓶颈。在 YouTube-8M 的规模上进行视频理解通常应该需要 PB 级存储以及相当于 CPU 工作几十年的处理能力，为了让计算资源有限的研究者和学生也能用上这个数据集，我们对视频进行了预处理并使用了在 ImageNet 上训练的公开可用的 Inception-V3 图像标注模型（一种目前最佳的深度学习模型）提取出了帧层面的特征（frame-level features）。这些特征是按每秒 1 帧的时间分辨率从 19 亿个视频帧中提取的，然后它们还被进一步压缩到了可装入单个商品级硬盘的大小（少于 1.5 TB）。这使得我们可以在单个 GPU 上只用低于一天的时间就能全规模地下载该数据集并完成基准的 TensorFlow 模型的训练。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们相信该数据集能极大地加速在视频理解上的研究，因为它能让研究者和学生无需使用大数据和大机器就能进行之前前所未有的规模的研究。我们希望这个数据集将能激励在视频建模架构和表征学习上的激动人心的新研究，尤其是能有效处理噪声或不完整标签的方法、迁移学习（transfer learning）和领域适应（domain adaptation）方面的研究。事实上，我们的实验表明：在该数据集上对模型进行预训练并在其它外部数据集上进行应用/微调，可以在这些外部数据集（如 ActivityNet、Sports-1M）上实现当前最佳的表现。关于我们使用该数据集进行的所有实验以及我们构建它的更多细节，请参阅我们的技术报告论文。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面是对该技术报告论文的摘要翻译。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;论文：YouTube-8M：一个大型视频分类基准（YouTube-8M: A Large-Scale Video Classification Benchmark）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicQUibx1s2Llj1oosE69QCicOzhWdgf03HVRONpHovvVekY5ibibvuUVwibDorjLfHCgPNsduvJ1u2sJSg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：&lt;/span&gt;&lt;span&gt;计算机视觉领域近来的许多进步都可归功于大型数据集。机器学习的开源软件包和不再昂贵的商品级硬件大幅降低了探索新方法的进入壁垒。我们可以在几天时间内就在数百万个样本上完成模型的训练。但是大型数据集（如 ImageNet）都是为图像理解存在的，还没有规模能与之媲美的视频分类数据集。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这篇论文中，我们介绍 YouTube-8M——这是目前最大的多标签视频分类数据集，包含了约 800 万段视频（约 50 万小时），这些视频用一个包含了 4800 个视觉实体（visual entity）的词汇集进行了标注。为了获取这些视频和它们的（多）标签，我们使用了一个 YouTube 视频标注系统（video annotation system），该系统可以给其中的视频标注上主要的主题。尽管这些标签是机器生成的，但它们的准确度非常高并且是衍生自各种基于人类的信号，其中包括元数据（metadata）、查询点击信号，所以可以说它们是基于内容的标注方法的一个非常好的目标。我们使用了自动和人工兼用的调制（curation）策略对视频标签（知识图谱实体）进行了过滤，其中包括询问人类评估者标签是否可以通过视觉识别。然后我们以每秒一帧的速度对每个视频进行了解码，然后使用了一个在 ImageNet 上预训练过的 Deep CNN 来提取刚好在分类层之前的隐藏表征（hidden representation）。最后，我们对帧特征（frame features）进行了压缩，使帧层面和视频层面的标签都可供下载。该数据集包含了超过 19 亿个视频帧和 800 万段视频的帧层面的特征，所以它是最大的公开的多标签视频数据集。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们在该数据集上训练了多种（中等的）分类模型，并使用了流行的评估标准对它们进行了评估，然后将它们报告作为了基准。尽管这个数据集很大，但我们的一些使用了公开公用的 TensorFlow 框架的模型在单台机器上只用不到一天的时间就训练到了收敛（convergence）的程度。我们计划发布用于训练基本 TensorFlow 模型和用于计算标准的代码。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们的实验表明：在大型数据集上的预训练可以泛化到其它数据集上，比如 Sports-1M 和 ActivityNet。我们在 ActivityNet 上实现了当前最佳的表现，将 mAP 从 53.8% 提升到了 77.6%。我们希望 YouTube-8M 的前所未有的规模和多样性可以带来在视频理解和表征学习上的进步。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 29 Sep 2016 11:19:43 +0800</pubDate>
    </item>
    <item>
      <title>深度 | 机器之心代表读者对话Yoshua Bengio：没有可与深度学习竞争的人工智能技术（附演讲）</title>
      <link>http://www.iwgc.cn/link/2884653</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心整理&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;演讲：Yoshua Bengio&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;特别感谢：石涛 （帮忙法语转英语的朋友）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;现场报道：王双栋、&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;Chain Zhang&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;报道准备：赵巍、玉喜、李勇、Yanchen&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;编译：杜雪、吴攀&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;在 2016 年 9 月 21 日，蒙特利尔举办的 cdlm 2016 大会上，Yoshua Bengio、Yann LeCun、Joëlle Pineau 三人发表了经常的主题演讲。机器之心在北美的小伙伴对该会议进行了跟踪报道，并有机会对 Yoshua Bengio 和 Yann LeCun 进行问题采访。此篇文章是 Yoshua Bengio 演讲以及机器之心对其采访问题的整理。因大会全程法文（PPT 也是），所以对 PPT 就不做过多展示。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;mpvoice frameborder="0" class="res_iframe js_editor_audio audio_iframe" src="/cgi-bin/readtemplate?t=tmpl/audio_tmpl&amp;amp;name=%E6%9C%BA%E5%99%A8%E4%B9%8B%E5%BF%83%E9%87%87%E8%AE%BF%20YoshuaBengio&amp;amp;play_length=03:23" name="%E6%9C%BA%E5%99%A8%E4%B9%8B%E5%BF%83%E9%87%87%E8%AE%BF%20YoshuaBengio" play_length="203000" voice_encode_fileid="MzA3MzI4MjgzM18yNjUwNzE5NDkz"&gt;&lt;/mpvoice&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;采访内容：&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;机器之心：有什么未来可以与深度学习竞争的人工智能技术吗？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Yoshua Bengio&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：没有。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;机器之心：你强调了神经科学所带来的灵感，你认为新的深度学习研究者应该接受一些怎样的神经科学训练？反向传播真的是一种近似生物学习的过程吗？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Yoshua Bengio：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我写了一些关于反向传播和神经科学的论文，我认为弥合对神经科学的理解与机器学习比如反向传播之间的差距非常重要，因为大脑必须使用一些非常强大的东西。我们现在还有很多无法回答的问题。这是非常有趣的探索，也是非常基础的科学研究。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;机器之心：你有什么深度学习方面的书推荐吗？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Yoshua Bengio&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：他们需要大量阅读论文和专业书籍，比如我和Ian Goodfellow合作的那本。他们还需要练习，真正的投入进入，可以使用现有的packages，做一些试验，用数据来训练自己的网络，调整相应的参数，并熟悉算法的使用过程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;机器之心：数据科学比赛有什么作用？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Yoshua Bengio&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：参加比赛是很好的学习方式，可以挑战自我。你可以阅读论文，论文中会提到很多数据集，你可以拿来与自己的比较，这是一个好方法，重复论文中的试验也是一个好方法，虽然很难。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Yoshua Bengio 大会演讲内容：&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWicQUibx1s2Llj1oosE69QCicOQyp9HSzGF5ibubhKf3USUPzJF8AdQroZia9z0vxE9RZzZlsCJiaNKARdQ/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我将在这里谈一谈发生在人工智能领域的这场革命。它是什么？然后我们会谈一谈深度学习。我会从便于理解的内容入手，也就是自动驾驶汽车，它还未实现，但得益于视觉研究的深入，它已有相当可观的进展。这种视觉理解之所以成为可能，乃是得益于深度学习和认知网络的发展，我们稍后会谈到它们... 也许你们中的一些人已经开始与你的手机聊天了？随着我们将与这种变形了的计算机进行交互，这种事会开始占据我们越来越多的空间。过去几个月里，也许你听到过一项引起了人们广泛讨论的突破成果：一台使用了深度学习和强化学习的计算机击败了世界围棋（一种复杂的中国棋盘游戏）冠军，在这之前人们普遍认为计算机要想成功击败世界冠军可能需要几年甚至几十年，而它现在就做到了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWicQUibx1s2Llj1oosE69QCicO19ibOwRziaNvIOXTsfFwuq8lw9nkR9ZgNFRz0H9dbnghG3g2V2SCpX8g/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;那么到底发生了什么？的确人工智能是循序渐进的耐心工作的成果，而且它总是站在巨人的肩膀上，并且这些进步在某种程度上促成了转折点——我们可以在新服务中利用这些成果来生产新东西，进行经济转型以及改变社会。正如人们所写的那样，我们正在经历另一场工业革命，它并不是简单地增加人类的机械力；计算机将增加人类的认知能力和智力。我谈到了深度学习，因为这些变化和突破在很大程度上正是由于深度学习的进步。所以它是什么呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;它始于十年前，这得感谢加拿大高级网络研究所（Canadian Institute of Advanced Network Research/ICRA），它资助了这项在那段时间被认为过时而不受欢迎的研究，几个傻瓜仍然相信这些受大脑概念所启发的想法，它们想做更进一步的研究。经过了数十年的人工神经网络研究之后，这项研究进入到了深度神经网络领域，这是过去几年所发生的事情的一点点起源。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以在你们讲人工智能之前，我会告诉你们我真正感兴趣的是去理解我们所能实现和理解的数学原理和信息技术，这能帮助我们解释「智能（intelligence）」。这是广义上的智能，它可以是人类和动物，当然它可以用来构建智能机器。这也多亏了这个事实：我们可以使用能够一步一步发展的机器进行实验。那么智能是什么？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这不是我们在社区中达成的几件共识，但我们足以一致同意的是：智能与智能行为相联系并为一个系统/代理人采取好的决策和行为，我们需要知识。自 50 年代初开始的那个有关基本智能的基本问题是：计算机如何能够获得使它们行动起来更加智能的知识？上文所描述的研究已经运用符号的经典基本智能方法进行了几十年，这个著名的专家系统并没有真正地解决问题，因为它试图将我们所了解的知识直接提供给计算机；但遗憾的是我们知道但我们无法向机器解释，我们不能为一台计算机设计一个程序来做这样的事，因为有许多知识是凭直觉获知的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;真正效果惊人的解决方法是去教计算机我们自己获取知识的方式，通过观察、案例分析、模仿人类、结合数据，最终我们拥有越多的数据，计算机就可以使用越多的信息来了解世界的某一方面——世界可以用数据进行阐释。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因此这门探讨生物系统或计算机如何能够从样本中学习的科学是一门有关学习的科学，尤其是机器学习。所以近几十年中所孕育的这个突破却主要在过去的 3、4 年间才显露出来，深度学习是一种特殊的机器学习方法，它显然滋养于机器学习领域所取得的大量研究成果，而且其中有着更多的重要思想。也就是说，比我所坚持的两个思想多多了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其中一个是表征（representation）的思想。这是说计算机不仅要去学习一个任务，而且要学习如何表现那些表征了声音、词、句子的信息。第二个思想是我们不仅要学习表征，还要学习多个层次的表征，而且我们必须要将这些表征的不同层次理解为抽象的层次。为什么这很有趣呢，因为一个人能够让计算机建立越多的抽象层次，它就能更好地了解世界，从而更好地生成情景，而这才是关键。然后计算机就会在编辑和理解单词、机器翻译、自然语言理解、机器人方面出现巨大改进，我今天也会给出一些例子。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最近我们开始结合表征学习的思想，它使得计算机能将来自不同资源的表征放在一起，比如图像和短语的表征。所以这里我们看到一个例子是说计算机完全做到了图像中的对象识别，计算机可以识别出图像中出现了哪些物体及其位置。左边是一个计算机要处理的简单例子，阅读它并回答一个相关背景的问题。而底部则说明了我们不久前在实验室所做的一些事情，我们在这个实验室将这些能力结合了起来，在那里计算机会看到一张图片（例如左侧一张公园中的女人的图片）后将会生成一句法语「一个女人开始在公园里掷飞盘」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWicQUibx1s2Llj1oosE69QCicOltk0MlYZ4AtuxKMpFiaL1GEpZclnxCj7BoiafGZ7dUVicWoyf85fZtKDQ/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因此计算机不仅能解释图像，还用自然语言生成单词序列，这里用的是英文。就在几年前，人们还认为这种事还太过遥远，而现在它并不像我们想象中的那么困难。我们仍然还远远不能解决这个问题，但你将会看到这个方向上的迅速进步。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我将回到表征的概念上，我们做了一些事情来试着了解计算机在这些表征中所发现的东西，试着去表达单个单词。我们可以将每个单词联想成一个所谓的「向量（vector）」，它可以看做二维的一系列实数，也是一个有关计算机学习过的单词的近似，这里看不到它们，它们太小了。但我们可以放大，然后我们可以看到那些有着相似含义的单词将在表征空间中彼此靠近。不仅如此，我们还有绝对吸引人的发现：我们可以用这种表征来做类比推理。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWicQUibx1s2Llj1oosE69QCicOXDy7B6ZWZ5qt4msetTZcbRyiaINicEcMCHbksegEyc00rUkJGORw7Vrw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以如果我们有了包含一系列数字的向量，空间中对应于一个单词「巴黎」的点和对应于「法国」的向量表征，然后我们将两者之间的差别当做另一个向量，这个向量会告诉我们从「巴黎」到「法国」的方向。同样的方向可以应用于表征罗马到意大利。同样如果是单词「国王」和「王后」之间的表征差异，我们会得到了一些非常接近于「男人」和「女人」之间差异的东西。最后计算机能够看到对词「男人」来说词「女人」所意味的就是对于单词「王后」来说单词「国王」所意味着的东西。这是我们没有教但是计算机在无监督的情况下自己发现的一些事情。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然后我会以人们可以理解的一个例子来尝试去解释这种表征思想。如果我们看一张图片，一张数字化文字页面上的图片，在这张图片中有某些层次的表征，例如作为第一个非常粗糙的层次来说是像素，然后我们会在这张图片中识别到稍高的一个层次是边缘，它定义了物体的边缘。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicQUibx1s2Llj1oosE69QCicODsxoWxUFXlHtxGicOiaBpjrk7RJiasic2ZibdlicnsUibO7jicSrARKfMToKAw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然后你可以想象一个更高的表征层次，其中计算机可以识别到线条所匹配的部分，例如字符，而再高一层次就是线条能够结合在一起形成整体特征，然后这些特征会结合成为单词，而这就到了我们还未能掌握的地方，即一个更高层次的抽象——单词的含义。所以像我们之前所展示的那样，你看到了一个尝试去捕捉词含义的词表征，而毕竟它还不足以完成一些有趣的任务，比如你想让它捕捉到隐藏单词的含义（潜在意思），或者短语、文档背后隐藏的想法，甚至是消息的核心内容。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以我向你展示所有这些内容，是因为在这种情况下会有若干层次的表征，词层面的表征比像素层面更为抽象，而如果我们必须作出决策并要求计算机回答一个有关该文件的问题，如果它工作在词层面的话会更容易，同样的单词可以用许许多多可能的图像来说明。我们能够以非常不同的方式来选择字符，并且我们想让计算机分离出有关字符如何被书写的细节，比如这里的「S」是什么，让它了解单词的含义等等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因此这种表征和抽象的思想是非常重要的。我这里举的例子包括了我们所理解的表征，从而我们能够迫使计算机去遵循这些表征，但事实上在我们的研究领域，我们感兴趣的是让计算机自己去发现不同层次的表征，从第一个层次到词的含义这个层次，这些表征对我们来说很自然，但我们并不需要让计算机真的以我们的方式去学习，即使这些层次之间的关系并不明显，而机器学习被用于识别字母，当你达到更高的抽象层次时，事实上我们并不知道怎样去表征语义，而这就是为什么要拥有一个完全自动化的方法来发现这些抽象层次会变得如此重要。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以我将以两个不那么偏技术性但会得到更多共鸣的想法作为结束：我们当下在人工智能领域所目睹的围绕这些进展的社会问题。首先，正如许多强大的科学和技术，我们对它们放任自流的风险是什么？为了不让一些人利用这一权力从而使得财富集中在少数人手中，我认为许多研究人员会希望让这些进步首先去造福尽可能多的人。我们如何安排来让事情如此进展呢？这里有一个特殊情况，即这些技术在未来几年很有潜力，例如自动驾驶汽车对就业市场有着显着的影响，这意味着一些人可能会失去工作并被机器取代。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWicQUibx1s2Llj1oosE69QCicORlicDbsN4ZxFQwic1n7MGribKGbicqP8AlsvYPaEozsKSceW1nsNWAEIaA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们如何确保它从人道角度出发并造福于每个人，而不让部分群众悬而待决。然后更一般地说，还有许多普通人尤其是公民应该思考的道德问题。例如数据的隐私问题，还有一些问题不仅仅……比如我想要保留我的数据并且保证无人可以访问它，但是如果我们将自己的数据分享到健康领域呢，比如它可以造福于每一个人。这有点像是疫苗，如果每个人都接种疫苗，它将能够造福于每一个人。所以我们要如何管理这其中的个人和集体的利益？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，正如 Valerie 所说，我所谈论的是试图将研究方向引向推动人工智能的社会型积极应用上来。显然健康、环境、教育、创造性服务将服务于世界上的大部分群体，不一定是为了即时的商业利润。有一些人提出关于人工智能长期风险的道德问题。我是那些不太害怕它的人之一。我也认为考虑这种可能性很重要，不能不经过思考就行动。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;由于所有这些原因，拥有某种对话是很重要的，我希望今天可以实现它。人们可以从中参与讨论、了解问题，代表集体意志的政治家们也是对话的一部分。所以我邀请你们学习更多东西，以任何方式参与进来，无论是贡献于技术的发展，我希望公司可以遵循这些，或者是简单地作为一个公民。现在，目前在蒙特利尔有一个机会，我们有一个人工智能领域的批判性团体，特别是我领导的小组和 McGill 大学的机器学习小组。我们在该领域一共有 150 位研究人员，在任何情况下这都是世界上一个非常独特的大学水准的集结。我们刚刚收到的一项拨款，它会帮助我们发展这一科学，而且会有政府委员会来确保技术的可转化性，使它在蒙特利尔创造财富，所以这是一个挑战，如果我们能够在蒙特利尔创造一个硅谷，我们如何将一个批判性团体转型成私人企业，创建一个围绕所有这些的生态系统呢？我认为最重要的因素是吸引和留住世界上最好的人才，无论他们是来自大学还是私人领域。谢谢。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心整理，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 29 Sep 2016 11:19:43 +0800</pubDate>
    </item>
    <item>
      <title>学界 | DeepMind最新论文：在线 Segment to Segment 神经传导</title>
      <link>http://www.iwgc.cn/link/2884654</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自ArXiv&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Lei Yu, Jan Buys, Phil Blunsom&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicQUibx1s2Llj1oosE69QCicOEfNQoJhMgMYO8qTgOaHPY7U3kHIYfv3yrA8VFOakpInPp2YVHic7V5A/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;摘要&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们在这里介绍一种在线神经序列到序列模型（online neural sequence to sequence model），其可以从其读取到的输入的编码和解码片段（segment）中交替地学习。通过独立地追踪编码和解码的表征，我们的算法可以在训练过程中实现潜在分割（latent segmentation）的准确的多项式边缘化（polynomial marginalization），而在解码过程中，我们使用了波束搜索（beam search）来寻找最好的对准路径（alignment path）以及预测出的输出序列。我们的模型解决了 vanilla 编码器-解码器的瓶颈，其在产生任何输出前必须在其固定长度的隐藏状态中读取和记忆整个输入序列。这不同于之前的注意模型（attentive model）：我们的模型并不将注意权重（attention weights）看作是一个确定函数的输出，而是将注意权重分配给一个序列隐变量（sequential latent variable），其可以被边缘化而且允许在线生成。在抽象句子总结和形态曲折（morphological inflection）上的实验表明我们的模型在基准编码器-解码器（baseline encoder-decoders）之上实现了显著的性能提升。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;点击阅读原文，下载论文↓↓↓&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 29 Sep 2016 11:19:43 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 谷歌、微软等五大巨头历史性走到一起，建立合作组织应对人工智能的社会挑战</title>
      <link>http://www.iwgc.cn/link/2884655</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Venture Beat&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：杜夏德&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;span&gt;亚马逊、DeepMind/谷歌、 Facebook、IBM 和微软今天宣布成立一家非营利组织，致力于推进公众对人工智能技术的理解，针对当前该领域的挑战和机遇执行可行方案。学界、非营利组织以及政策和伦理专家也将被邀请进入该组织委员会，比如艾伦人工智能研究所。该人工智能合作关系的目标是处理人工智能技术的挑战和机遇，惠及社会和人类。&lt;/span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicQUibx1s2Llj1oosE69QCicOQyc7CytQlR1x0ufw1l0EolaMslqPxJ0kkIYTL6dAb912hMBOrouWhg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能这一科技概念总能让人想到计算机成为世界霸主并营造出科技反面乌托邦的画面，或者机器人要全面接管人类工作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是人工智能一直都在那：是它驱动了你的利用语音激活的数码个人助手和搜索引擎，引导你汽车上的自动功能，帮你翻译外文文本，它能从你上传到社交媒体上的照片中找出你朋友的照片，并过滤掉垃圾邮件。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是最近几年人工智能在实际中的应用缺少了一个关键的元素：一个行业伦理标准，或者这一领域成长的最佳实践指导。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在，该行业的巨头公司们开始合作来填补这个空白，联合成立了 Partnership on Artificial Intelligence to Benefit People and Society，一项为了造福人类和社会的 人工智能合作伙伴关系，囊括了亚马逊、Facebook、谷歌、微软和 IBM，目前苹果也在商讨加入进来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「关于这个问题，我们已经讨论多年了，大多都是非正式的，」IBM 的认知计算副总裁 Guruduth Banavar 说道。「最终们终于有机会正式讨论了这个问题（谈话）。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个团队的目标是创建业界领先的第一个财团，同时将学界和非营利组织的研究者拉进来，主导相关工作，从本质上确保人工智能的可信性：将研究推向与伦理相关的、安全可靠的技术上，这些技术可以带来更多的帮助而不是伤害，也会帮助减少人们对人工智能的恐惧和误解。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我计划展开讨论，计划推广，也计划潜在地赞助一些深入具体问题的研究项目，」Banavar 说，「但是首先，这是一个跨行业的开放讨论的平台」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在某种程度上，人工智能在过去几年中发展太快，已经在不知不觉中潜进很多人的生活中。人工智能科学家长期一来一直都在预测人工智能浪潮，但是时机是一个处于移动中的目标。现在，机器在翻译和讯息发送上击败了人类。各家语音激活助手的竞争不断激烈：苹果的 Siri、亚马逊的 Alex、微软的 Cortana。IBM 的 Watson 超级计算机正在开出医疗处方，帮助医生治疗癌症。谷歌的 DeepMind 在复杂的围棋游戏中击败了人类。各类算法不断走向顶尖。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「各家公司不得不在已有的情况下，从基本上做出自己的最佳实践。」亚利桑那州立大学计算机科学教授，人工智能发展协会（Association for the Advancement of Artificial Intelligence）主席 Subbarao Kambhampati 说。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些研究者们在一起讨论，咨询和协商；做人工智能的各家公司已经形成了伦理管理会和委员会。但是行业协调还没有退出。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「这段时间，人工智能技术已经进入我们生活中的很多决策中，并且还在深入。」Kambhampati 说。「大多数情况下，事情进展顺利，但是有时也不会那么顺利。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;就像那次微软做了一个 Twitter 聊天机器人，它学习了对话，但很脱离了原有轨道，变得具有攻击性。还有那次特斯拉的自动驾驶汽车没有在明亮的天空下识别出一辆白色的拖拉机，导致了驾驶员的死亡。还有谷歌的广告算法要面对各种种族歧视和性别歧视的指控。这类事故还是会出现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「当你在一堆数据上训练一个学算法时，它会在这些数据中发现一个模式。显然，人工智能领域中的每个人都已经知道并理解这个事情，」Kambhampati 说。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「但事实是，这件事的影响会在无意在形成刻板印象和歧视，这已经成为一个日益凸显的问题，」因为这些技术确实正在日常生活中做出非常重要的决策。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Kambhampati，他领导的科学社会 AAAI 也会参与到这个人工智能的伙伴关系中，他希望这个新建的团队能够重点专注于当前和短期的实际问题，而不是伦理学家经常探讨的遥远的世界末日场景。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;IBM 的 Banavar 说大家对这个团队的期望是它能长期坚持下去，但它的目标确都是短期的。他期望这个人工智能伙伴关系能创建一个教育论坛，有线上也有线下，能为人工智能聚集各方资源。该团队有一个具体的计划，有望在未来几周内推广开来，随后还有一个事件来启动该项合作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当然，他承认该团队的工作无法停止任何对人工智能的滥用，它的实际目的是产生影响。但是 Banavar 希望这个团队的工作能在世界范围内办起教育课程，激发新一代的人工智能研究者。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 29 Sep 2016 11:19:43 +0800</pubDate>
    </item>
    <item>
      <title>重磅 | 谷歌翻译整合神经网络：机器翻译实现颠覆性突破（附论文）</title>
      <link>http://www.iwgc.cn/link/2869136</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Google Research&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;作者：Quoc V. Le、Mike Schuster&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;昨日，谷歌在 ArXiv.org 上发表论文《Google`s Neural Machine Translation System: Bridging the Gap between Human and Machine Translation》介绍谷歌的神经机器翻译系统（GNMT），当日机器之心就对该论文进行了摘要翻译并推荐到网站（www.jiqizhixin.com）上。今日，谷歌 Research Blog 发布文章对该研究进行了介绍，还宣布将 GNMT 投入到了非常困难的汉语-英语语言对的翻译生产中，引起了业内的极大的关注。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;十年前，我们发布了 Google Translate（谷歌翻译），这项服务背后的核心算法是基于短语的机器翻译（PBMT:Phrase-Based Machine Translation）。自那时起，机器智能的快速发展已经给我们的语音识别和图像识别能力带来了巨大的提升，但改进机器翻译仍然是一个高难度的目标。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今天，我们宣布发布谷歌神经机器翻译（GNMT：Google Neural Machine Translation）系统，该系统使用了当前最先进的训练技术，能够实现到目前为止机器翻译质量的最大提升。我们的全部研究结果详情请参阅我们的论文《Google`s Neural Machine Translation System: Bridging the Gap between Human and Machine Translation》（见文末）[1]。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;几年之前，我们开始使用循环神经网络（RNN：Recurrent Neural Networks）来直接学习一个输入序列（如一种语言的一个句子）到一个输出序列（另一种语言的同一个句子）的映射 [2]。其中基于短语的机器学习（PBMT）将输入句子分解成词和短语，然后很大程度上对它们进行独立地翻译，而神经机器翻译（NMT）则将整个输入句子视作翻译的基本单元。这种方法的优点是：相比于之前的基于短语的翻译系统，这种方法所需的工程设计更少。当其首次被提出时，NMT 在中等规模的公共基准数据集上就达到了可与基于短语的翻译系统媲美的准确度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;自那以后，研究者已经提出了很多改进 NMT 的技术，其中包括模拟外部对准模型（external alignment model）来处理罕见词 [3]，使用注意（attention）来对准输入词和输出词 [4] 以及将词分解成更小的单元以应对罕见词 [5,6]。尽管有这些进步，但 NMT 的速度和准确度还没能达到成为 Google Translate 这样的生产系统的要求。我们的新论文 [1] 描述了我们怎样克服了让 NMT 在非常大型的数据集上工作的许多挑战，以及我们如何打造了一个在速度和准确度上都已经足够能为谷歌的用户和服务带来更好的翻译的系统。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWic8AYNx1rVQyUcIs8bbyDhYYnia3jZRmI5bMIIluWHibScueHom3bXNCS0rORlZiaEoRuzsvkGVYc2TA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;来自对比评估的数据，其中人类评估者对给定源句子的翻译质量进行比较评分。得分范围是 0 到 6，其中 0 表示「完全没有意义的翻译」，6 表示「完美的翻译」。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面的可视化图展示了 GNMT 将一个汉语句子翻译成英语句子的过程。首先，该网络将该汉语句子的词编码成一个向量列表，其中每个向量都表征了到目前为止所有被读取到的词的含义（「编码器（Encoder）」）。一旦读取完整个句子，解码器就开始工作——一次生成英语句子的一个词（「解码器（Decoder）」。为了在每一步都生成翻译正确的词，解码器重点注意了与生成英语词最相关的编码的汉语向量的权重分布（「注意（Attention）」，蓝色链接的透明度表示解码器对一个被编码的词的注意程度）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_gif/KmXPKA19gWic8AYNx1rVQyUcIs8bbyDhYKGC1GMI9FibcKU7hc2dia5qJzKVUg9B1FULZKcIs3wvxjCOsk7o57QfQ/0?wx_fmt=gif"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;使用人类评估的并排比较作为一项标准，GNMT 系统得出的翻译相比于之前的基于短语的生产系统实现了极大的提升。在双语人类评估者的帮助下，我们在来自维基百科和新闻网站的样本句子上测定发现：GNMT 在多个主要语言对的翻译中将翻译误差降低了 55%-85% 以上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWic8AYNx1rVQyUcIs8bbyDhYoD35dMSt4n4vib0HZUT5k5xxh1ohicNClItTUycqMiaW7lahOJFBYzVMQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;我们的系统产出一个翻译案例，其输入句子采样自一个新闻网站。这个地址（https://drive.google.com/file/d/0B4-Ig7UAZe3BSUYweVo3eVhNY3c/view?usp=sharing）可以看到更多随机采样自新闻网站和书籍的输入句子翻译样本。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今天除了发布这份研究论文之外，我们还宣布将 GNMT 投入到了一个非常困难的语言对（汉语-英语）的翻译的生产中。现在，移动版和网页版的 Google Translate 的汉英翻译已经在 100% 使用 GNMT 机器翻译了——每天大约 1800 万条翻译。GNMT 的生产部署是使用我们公开开放的机器学习工具套件 TensorFlow 和我们的张量处理单元（TPU：Tensor Processing Units），它们为部署这些强大的 GNMT 模型提供了足够的计算算力，同时也满足了 Google Translate 产品的严格的延迟要求。汉语到英语的翻译是 Google Translate 所支持的超过 10000 种语言对中的一种，在未来几个月，我们还将继续将我们的 GNMT 扩展到远远更多的语言对上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器翻译还远未得到完全解决。GNMT 仍然会做出一些人类翻译者永远不出做出的重大错误，例如漏词和错误翻译专有名词或罕见术语，以及将句子单独进行翻译而不考虑其段落或页面的上下文。为了给我们的用户带来更好的服务，我们还有更多的工作要做。但是，GNMT 代表着一个重大的里程碑。我们希望与过去几年在这个研究方向上有所贡献的许多研究者和工程师一起庆祝它——不管是来自谷歌还是更广泛的社区。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Google Brain 团队和 Google Translate 团队都参与了该项目。Nikhil Thorat 和 Big Picture 也帮助了该项目的可视化工作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;论文：Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWic8AYNx1rVQyUcIs8bbyDhYT2r1HkDqWO8ianIib4y3rsKrCDj3oq8IicQMlqe2AkxEibuSfNp4D582gA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：神经机器翻译（NMT: Neural Machine Translation）是一种用于自动翻译的端到端的学习方法，该方法有望克服传统的基于短语的翻译系统的缺点。不幸的是，众所周知 NMT 系统的训练和翻译推理的计算成本非常高。另外，大多数 NMT 系统都难以应对罕见词。这些问题阻碍了 NMT 在实际部署和服务中的应用，因为在实际应用中，准确度和速度都很关键。我们在本成果中提出了 GNMT——谷歌的神经机器翻译（Google's Neural Machine Translation）系统来试图解决许多这些问题。我们的模型由带有 8 个编码器和 8 个解码器的深度 LSTM 网络组成，其使用了注意（attention）和残差连接（residual connections）。为了提升并行性从而降低训练时间，我们的注意机制将解码器的底层连接到了编码器的顶层。为了加速最终的翻译速度，我们在推理计算过程中使用了低精度运算。为了改善对罕见词的处理，我们将词分成常见子词（sub-word）单元（词的组件）的一个有限集合，该集合既是输入也是输出。这种方法能提供「字符（character）」-delimited models 的灵活性和「词（word）」-delimited models 的有效性之间的平衡、能自然地处理罕见词的翻译、并能最终提升系统的整体准确度。我们的波束搜索技术（beam search technique）使用了一个长度规范化（length-normalization）过程，并使用了一个覆盖度惩罚（coverage penalty），其可以激励很可能能覆盖源句子中所有的词的输出句子的生成。在 WMT' 14 英语-法语和英语-德语基准上，GNMT 实现了可与当前最佳结果媲美的结果。通过在一个单独的简单句子集合的人类对比评估中，它相比于谷歌已经投入生产的基于短语的系统的翻译误差平均降低了 60%。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;参考文献：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[1] Google’s Neural Machine Translation System: Bridging the Gap between Human and Machine Translation, Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V. Le, Mohammad Norouzi, Wolfgang Macherey, Maxim Krikun, Yuan Cao, Qin Gao, Klaus Macherey, Jeff Klingner, Apurva Shah, Melvin Johnson, Xiaobing Liu, Łukasz Kaiser, Stephan Gouws, Yoshikiyo Kato, Taku Kudo, Hideto Kazawa, Keith Stevens, George Kurian, Nishant Patil, Wei Wang, Cliff Young, Jason Smith, Jason Riesa, Alex Rudnick, Oriol Vinyals, Greg Corrado, Macduff Hughes, Jeffrey Dean. Technical Report, 2016.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[2] Sequence to Sequence Learning with Neural Networks, Ilya Sutskever, Oriol Vinyals, Quoc V. Le. Advances in Neural Information Processing Systems, 2014.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[3] Addressing the rare word problem in neural machine translation, Minh-Thang Luong, Ilya Sutskever, Quoc V. Le, Oriol Vinyals, and Wojciech Zaremba. Proceedings of the 53th Annual Meeting of the Association for Computational Linguistics, 2015.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[4] Neural Machine Translation by Jointly Learning to Align and Translate, Dzmitry Bahdanau, Kyunghyun Cho, Yoshua Bengio. International Conference on Learning Representations, 2015.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[5] Japanese and Korean voice search, Mike Schuster, and Kaisuke Nakajima. IEEE International Conference on Acoustics, Speech and Signal Processing, 2012.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[6] Neural Machine Translation of Rare Words with Subword Units, Rico Sennrich, Barry Haddow, Alexandra Birch. Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, 2016.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 28 Sep 2016 11:01:38 +0800</pubDate>
    </item>
    <item>
      <title>前沿 | 日本科学家开发精密控制量子纠缠态的新技术，成功率提高60倍（附论文）</title>
      <link>http://www.iwgc.cn/link/2869137</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自phys.org&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：杜夏德、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;30 年前人们对量子计算机的想象是，它有潜力能快速精确地完成一些对人类和传统计算机来说不可能的事情。但是一个很大的问题是：微尺度量子效应很容易崩溃，以至于可靠供应能量的计算机一直无法真的实现。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在，日本的一组科学家或许已经克服了这个障碍。他们用激光开发出一个精确持续的控制技术，其持续维持「量子比特」生命周期的成功率要比之前的技术高上 60 倍，而量子比特是量子计算机编码的基本单元。尤其是这些研究者已经展示出他们能持续创造一个纠缠状态的量子行为——纠缠超过一百万个不同的物理系统。在他们数据存储的调查范围内，这是一个世界记录。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这一成果非常重要，因为纠缠的量子粒子，比如原子、电子和光子，都是量子信息处理的来源，而这些是由微小尺寸下的量子行为创造出来的。利用它们开创了一个崭新的信息技术时代。在叠加和纠缠这些行为中，量子粒子能同时处理巨量的计算任务。他们的研究报告发表在本周的 APL Photonics 期刊上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「在量子信息处理中，量子比特的生命周期有一个问题。我们已经解决了这个问题，而且我们能在我们想要的任何时间段内持续进行量子信息处理，」东京大学工程学院应用物理系的 Akira Furusawa 解释道，他是该项研究的领导人。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「这一成果最困难的地方是被压缩（squeezed）的光束之间的连续相位锁定，但是我们已经解决了这个问题。」基于集成电路和硅芯片的计算机是当下主导的信息处理技术，而量子计算机被认为继它们之后的下一代计算。目前计算机使用一长串的 0 和 1，也被称为 bit，来处理信息。相比之下，量子计算机通过利用量子力学的强大力量，能编码在量子状态下被称为量子比特的 0 和 1。量子比特有两种不寻常的配置方式：「叠加」和「纠缠」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;量子系统可以同时以好几种状态存在，比如衰变和未衰变两种状态的叠加。粒子也表现出纠缠的量子行为，这是量子之间的亲密性质，能将它们完美地结合在一个共同的存在中，即使它们之间的距离非常远。用爱因斯坦的话说，就是鬼魅。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;接下来在迈向量子计算粒子的道路上，Furusawa 设想要创建二维和三维的晶格状的纠缠状态。「这将会使我们实现拓扑量子计算，一种非常强大的量子计算，」他说。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;论文：Invited Article: Generation of one-million-mode continuous-variable cluster state by unlimited time-domain multiplexing&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWic8AYNx1rVQyUcIs8bbyDhYYZZwCNamicKgSnia4hicD38tDOZVFkiapzLcW9wk2txFcbA0DNYWicPKPCg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：在最近的量子光学的连续可变实验中，完全不可分的光模式的数量通过引入一个复用方案（不管是时域还是频域）而实现了急剧的增长。其中，Yokoyama et al.[Nat. Photonics 7, 982 (2013)] 报告了在时域复用进行修改的实验的成果，我们的研究表明其可以连续生成超过一百万种模式的完全不可分的光模式（fully inseparable light modes）。我们所得到的多模式状态可用作双轨连续可变集群状态（dual-rail continuous variable cluster state）。我们通过光学系统的连续反馈控制规避了之前的光学相位漂移（optical phase drifts）问题，这个问题将完全不可分光模式的数量限制在了大约一万。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 28 Sep 2016 11:01:38 +0800</pubDate>
    </item>
    <item>
      <title>招聘｜图普科技第二季谜题招聘活动正式启动</title>
      <link>http://www.iwgc.cn/link/2869138</link>
      <description>&lt;blockquote style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p&gt;&lt;span&gt;今年6月份的时候，&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716316&amp;amp;idx=4&amp;amp;sn=3c38c2d65d2f3d58f4e267528ab10092&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716316&amp;amp;idx=4&amp;amp;sn=3c38c2d65d2f3d58f4e267528ab10092&amp;amp;scene=21#wechat_redirect"&gt;机器之心发布了一期图普科技以Mario为主题的深度学习谜题招聘活动&lt;/a&gt;，在DL爱好者圈内引发了不少讨论。现在，图普科技第二期谜题招聘活动已经开启，本次我们准备了彩蛋更多的DL招聘海报，同时，Node.js方向的谜题也加入了本期招聘。&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;深度学习招聘&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8UiaacpTJM0C6dlzmbWH7t2V9TFXKwdEurJ1nj7RibZ3xVrZxXpQkt1errOZtbVVXaNkVj0nMh8b0A/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你想要成为谁&lt;span&gt;，你想要去到哪，还剩&lt;/span&gt;多少勇气？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一张门的背后&lt;span&gt;，&lt;/span&gt;一条路的尽头&lt;span&gt;，&lt;/span&gt;还有多少可能？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「每个梦都像任意门&lt;span&gt;，&lt;/span&gt;往不同世界&lt;span&gt;，&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; &lt;/span&gt;而你的故事&lt;span&gt;，&lt;/span&gt;现在正是起点。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;Node.js招聘&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8UiaacpTJM0C6dlzmbWH7t2uPkajTibgM0iaGM5q2ZjsHYltqbfdiciaIQRFQabJmojFazBGiakHicp6S0Q/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;每棵参天的大树，都萌芽于一颗不安分的种子；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;每个梦想的实现，都始于一颗不忘勇气的初心。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「&lt;/span&gt;&lt;span&gt;小小的天 留过的泪和汗&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;总有一天我有属于我的天&lt;span&gt;」&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;活动说明&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;＊前10名完成谜题的挑战者，直通技术终面。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;＊前60名完成谜题的挑战者，优先获得面试。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;＊全职/实习皆可，&lt;span&gt;欢迎应届生/非应届生前来挑战。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;＊点击阅读原文开始答题，推荐使用Chrome浏览器。&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;－END－&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 28 Sep 2016 11:01:38 +0800</pubDate>
    </item>
    <item>
      <title>专栏 | 基于行为事件的客户画像理论基础之哈耶克统一意识表达框架</title>
      <link>http://www.iwgc.cn/link/2869139</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心专栏&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：袁峻峰&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;本文是文章《我们为什么要这样联想|用哲学论证客户画像体系的复杂性》中 &amp;nbsp;[4] 提出基于行为事件的客户画像的理论探讨。客户历史行为事件构建客户画像可以认为是「哈耶克将『自我』理解为能够统一表达全部意识事件的时空框架」[3] 的一种应用。了解更多内容可浏览文章《&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718634&amp;amp;idx=5&amp;amp;sn=1fe554973deb996d761ce3af40b37edd&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718634&amp;amp;idx=5&amp;amp;sn=1fe554973deb996d761ce3af40b37edd&amp;amp;scene=21#wechat_redirect" style="font-size: 12px; text-decoration: underline; color: rgb(136, 136, 136);"&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;专栏 | 基于客户行为事件的跨领域统一推荐模型探讨&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;》。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在前文 [4] 中，基于行为事件的客户画像的想法源自「每个插曲，每一个决心，每一种不合时宜的行动，都象征着唐吉坷德」[2]. 仅凭福柯大师的一句话，似乎还是缺乏理论基础。虽然我们常常以特定行为去标记他人「原来你是这样的人！」；虽然孔夫子也说过「观其言而察其行」；但这些都不是系统的理论基础。在寻找模型的理论基础过程中，读到了汪丁丁教授「哈耶克《感觉的秩序》导读」[3], 终于找到基于行为事件的客户画像的理论基础, 那就是哈耶克的基于事件的统一意识表达框架！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;一、哈耶克基于事件的统一意识表达框架&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然业界的客户画像基本上都是基于标签体系。特别是前些日子的百度世界大会上大力的推荐其客户画像能力。给用户打了 60 多万个标签，做到千人千面，在不同领域取得的很棒的应用效果。和福柯认为特征体系是存在随意性，特征的确认是困难的相一致。哈耶克也认为，意识是难以定义的，与之类似的问题，感知的特征也是难以确认的。所以我们不应纠结于意识是什么而更应关心意识做了什么「Not asking what consciousness 『is』but by merely inquiring what consciousness does」[1]。哈耶克认为这是可以通过有意识过程行为以及无意识过程行为观察的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些过程行为是指发生在我们身上用于描述自我与其他人不同的有意识以及无意识行为事件。在此基础上，哈耶克构建了「统一表达全部意识事件的时空框架」[3]( Common Spatio-Temporal Framework)，其认为所有可重复的、想象的、过去的、可能的事件都关联到连续的「自我」意识表达。借此框架可以解决以下问题：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="list-style-type: decimal;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;通过行为事件标记一个人，他是什么，做过什么。「Be able to 『give an account』 of what he is or has been doing」.[1]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;「借助于意识事件的统一表达框架，行为主体得以『想象』和『预期』未来事件的样式及后果」[3].&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;并且哈耶克认为事件是通过注意力被感知的，这符合行为经济学的有限理性假设，即只有被感知的事件特征会被用于预期。而不论是主体注意力对事件的特征属性提取，还是预期过程都是基于主体历史的意识经验。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;正如汪丁丁教授总结的「在哈耶克看来，对人类这样具有『有限理性』的动物而言，没有』客观』知识，只有』主体间客观』（Intersubjective）的知识过程。其次，』知识』不是静态的一堆观念，它们是』过程』。」[3] 所以我们可以认为，以过程的视角，通过个人历史行为事件数据去构建客户画像是与哈耶克基于事件的统一意识表达框架的相一致的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;二、场景中的事件&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;如何将哈耶克所描述的有意识无意识个体行为事件与当下大数据中个体行为事件相结合呢？我们知道在行为经济学以及心理学中，情景记忆（Episodic Memory）是构成自我意识至关重要的一种长期记忆。而互联网中场景化，特别是互联网金融的目标之一是将金融服务融入各个场景中。自然，数据也是有场景化特征的。如果我们不再特意区分线上场景事件、线下场景事件、有意识行为事件、无意识行为事件，那么在哈耶克意识事件统一表达框架下的行为主体未来事件后果预测，也可以应用为在基于行为事件的客户画像体系下场景事件的预测。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;三、结论&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本文简单的介绍了哈耶克的统一意识事件框架，并将其视为基于行为事件的客户画像体系下跨领域统一推荐模型理论基础。并结合行为经济学以及实践中数据特性，将意识事件进一步理解应用为基于场景事件，为之后具体应用提供可能性。欢迎各位同业讨论相关应用案例可行性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;参考文献：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;[1] 哈耶克．The Sensory Order: Inquiry into the Foundations of Theoretical Psychology[M]．1952.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;[2] 米歇尔•福柯, 莫伟民 译．词与物 [M]．上海三联书店. 2002.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;[3] 汪丁丁. 哈耶克《感觉的秩序》导读 [OL].&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;[4] 袁峻峰. 我们为什么要这样联想|用哲学论证客户画像体系的复杂性 [OL]. 大数据文摘 (公众号). 2016-09-14.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;作者介绍&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：袁峻峰，花名观妙，蚂蚁金服人工智能部，复旦金融学硕士，FRM 金融风险管理师。10 年以上从事金融IT相关领域工作经验：国内银行间市场金融产品（包括衍生产品）的量化分析、市场风险管理以及相关系统实现。目前从事并关注于金融领域机器学习相关主题与应用，欢迎探讨, 邮箱yuanjunfeng_fr@163.com &amp;nbsp;。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;本文版权属于袁峻峰，仅代表个人观点。如需转载请联系作者（微信号 jake-80 ）&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 28 Sep 2016 11:01:38 +0800</pubDate>
    </item>
    <item>
      <title>重磅 | Facebook 开源人工智能环境CommAI-env，目标是实现人机之间的语言交流（附论文）</title>
      <link>http://www.iwgc.cn/link/2854955</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Facebook Research&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：杜夏德、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Facebook 今天开源重磅项目 CommAI-env，这是一个开发基于通信的人工智能系统的平台，本文整合了该项目的 README.md 文件和相关论文的摘要。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8UiaacpTJM0C6dlzmbWH7t2oJ45SVbGgYCqUTQpUoDc0UUe4qpQYkmBjNKZKWC2oWHhyf51kM3Qhw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;开源地址：https://github.com/facebookresearch/CommAI-env&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;CommAI-env（基于通信的人工智能环境（Environment for Communication-based AI））是一个用于训练和评估人工智能的平台，该平台已经在论文《A Roadmap towards Machine Intelligence》中进行过了描述。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8UiaacpTJM0C6dlzmbWH7t2UveKaNObbFpNSI1IxW7HVCydHwZn1YQNhHoCyib9ZgWmnuyHdxm68pQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;介绍&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;CommAI-env 是一个用于训练和测试人工智能系统（Learner（学习器，可以系统开发者所选择的任意语言编程））的平台，其使用了一个基于通信（communication）的设置，其中它可以通过一个 bit 层面的接口与 Environment（环境）进行交互。该 Environment 会要求 Learner 去解决一些基于通信的 Task（任务），并为其已经成功完成的每一个任务实例分配一个 Reward（奖励）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该 Learner 会以随机的顺序处理所有任务中的多个实例，而且其必须尽可能多地解决它们以获得最大的奖励。目前可以实现的任务包括计数问题、Learner 必须学习记忆项的列表并回答有关问题的任务、或通过基于文本的引导方案按引导指令执行任务（任务的详情描述请参阅该文档：https://github.com/facebookresearch/CommAI-env/blob/master/TASKS.md）。其任务范围现已开放：我们正在扩展任务范围，我们也邀请其他人能够参与进来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;CommAI-env 的最终目标是提供一个可用于从头开始训练 Learner 的环境，从而使其能够实现通过语言的与人类的真正交互。尽管这样的任务可能看起来微不足道（但你可以试试在我们所支持的混杂的模式中解决它们——你的英语知识根本没用！），但我们认为其中大部分任务都超出了现有的基于学习的算法的能力；而要让一个 Learner 能够解决所有这些任务，就必须要在与人类交互所需的通信智能（communicative intelligence）上取得重大的进展，并且还要能从人类老师那里获得进一步的学习。注：我们并不是说 CommAI-env 中的任务覆盖了一个智能通信代理所应该处理的所有技能。我们是说：为了解决 CommAI-env，智能代理必须要有非常宽泛的学习能力，这样它应该才可以通过与人类交互和其它方式获得它快速所需的所有进一步的任务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以下是 CommAI-env 有别于其它目前用于训练和测试人工智能系统的环境和数据集（比如，OpenAI Gym、Allen AI Science Challenge、MazeBase 或 bAbI）的一些基本特征，这些特征被设计出来的目的是为了鼓励开发者开发快速的、通用的、基于通信的 Learner。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;CommAI-env 的关注重点完全是基于通信的任务，其中所有的通信都是通过 Learner 和 Environment 之间的一个共同的 bit 层面的接口实现的。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;在单个 CommAI-env 会话（session）中，Learner 会被暴露在许多种任务中，所以它必须学会识别不同的任务，并将不同的技能合适地应用到这些任务上。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;许多任务都是渐进的，在这个意义上，解决其中一个或多个任务应该能让其它任务的解决更简单，只要 Learner 有对数据和算法的长期记忆（例如，一旦一个 Learner 解决了基本的计数任务以及如何将物体和属性关联起来，那么计数一个物体的属性就会更容易）。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;训练和测试阶段并没有明显的区分：&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: circle;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;一方面，Learner 应该不只是记忆一个固定任务集合的解决方案，而且还要学习如何将其泛化到其所遇到的新任务上。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;另一方面，就和人类一样，Learner 应该只需要少数几次遭遇后就能解决基本的问题：因此，学习的速度应该被考虑在评估之中。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;我们计划当该平台足够成熟时开展一个基于 CommAI-env 的比赛。为此，CommAI-env 的评估配置的任务集合将不同于开发版本中所包含的任务。这些任务不同的方面可能包括：它们可能基于不同的（自然和人工）语言、它们可以需要学习 Learner 周围的新物体和新位置、它们可能需要重新组合在开发过程中所学到的技能、等等。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;运行该环境有以下两步:&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;# Creating a configuration file (for instance, by copying the full training set)&lt;br/&gt;cp task_config.sample.json tasks_config.json&lt;br/&gt;# Running the environment, in the simplest case, just providing the configuration file as an argument&lt;br/&gt;python run.py tasks_config.json&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;默认情况下，该环境会在人类模式下运行（见下方）。如果你想用一个给定的算法来运行该环境，请见下方相应的部分。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;配置&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先，你应&lt;/span&gt;&lt;span&gt;该创建一个配置文件标明要投给 Learner 的任务和命令。你可以从复制对应全部训练集的文件开始，如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;cp tasks_config.sample.json tasks_config.json&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;人类模式&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了在控制台接口上运行这个系统，在这个系统中你可以冒充该&lt;span&gt; Learner &lt;/span&gt;，运行如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;python run.py tasks_config.json&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这会为你提供一个基于控制台的用户界面，与一下运作的环境互动。每次当该环境看上去静了下来并期待&lt;span&gt; Learner &lt;/span&gt;回答时，控制就转换到能输入字符串返回环境的用户手中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这两者之间的沟通，当下的时间和积累的奖励都会显示在屏幕上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了更好地理解该学习算法面对的问题的种类，你可以使用该 scrambled flag 运行该环境，它会用随机的伪词（pseudo-word）替换所观察到的词汇中的每一个词。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;警示：注意人类模式关于输入有两个来自教授者的假设。第一个假设是关于字符编码。虽然输入事实上达到了位（bit）级别，但是对于人类用户来说，阅读一长串 bit，还是会不舒服，所以我们在将它们投放到屏幕上之前将它转换成了字符串。第二个假设是话轮转换机制（turn-taking convention），在这个假设下，当环境已经产生了两个连续的空间后，我们将控制交给人类。学习算法不能安全地假设这些机制（convention），因为它们可以在后续的任务迭代中被修改。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;指定学习算法&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;用一个给定的学习算法来运行该环境，你可以使用学习器 class 的完全限定名称 -l 或 --learner flag。例如，你可以使用任何一个样本学习器：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;code&gt;&lt;span&gt;learners.sample_learners.SampleRepeatingLearner&lt;/span&gt;&lt;/code&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;code&gt;&lt;span&gt;learners.sample_learners.SampleMemorizingLearner&lt;/span&gt;&lt;/code&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;限定一个学习算法需要定义两个功能：next 和 reward.next 从该环境中接收一个 bit，并且应该回到&lt;span&gt; Learner &lt;/span&gt;说出的下一个 bit。reward 告知&lt;span&gt; Learner &lt;/span&gt;一个给定的接收奖励。在 Python 中，你可以从下面的代码片断开始创建一个&lt;span&gt; Learner &lt;/span&gt;：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;from learners.base import BaseLearner&lt;br/&gt;class MySmartLearner(BaseLearner):&lt;br/&gt; &amp;nbsp; &amp;nbsp;def reward(self, reward):&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;# record receiving a rewarddef next(self, input_bit):&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;# figure out what should be# the next bit to be spikenreturn next_bit&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;用编程语言 X 定义一个&lt;span&gt; Learner &lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;也可以用其他任何一种编程语言俩定义学习算法。为此，我们要包含一个learner.base.Remotelearner，它在一个任意的&lt;span&gt; Learner &lt;/span&gt;二进制与该环境之间建立一个 zeromq socket 接口。该环境作为一个服务器。为了方便，该用户能指定命令来发布这个学习者，所以它是在同一个过程中与环境一起发布的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当该 Session 创建后，该环境和学习器就被初始化了：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;该学习器通过向环境发送一个招呼「hello」来开始。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;循环：接受奖励，接受环境 bit，发送回复 bit&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;例子：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;#include &amp;lt;string.h&amp;gt;&lt;br/&gt;#include "zmq.h"int main()&lt;br/&gt;{&lt;br/&gt; &amp;nbsp; // This is an example of a silly learner that always replies with '.'char reply[1];&lt;br/&gt; &amp;nbsp; int n = 0;&lt;br/&gt; &amp;nbsp; const char* response = "00101110"; &amp;nbsp;// '.' utf-8 code// connectvoid *context = zmq_ctx_new();&lt;br/&gt; &amp;nbsp; void *to_env = zmq_socket(context, ZMQ_PAIR);&lt;br/&gt; &amp;nbsp; int rc = zmq_connect(to_env, "tcp://localhost:5556");&lt;br/&gt;&lt;br/&gt; &amp;nbsp; // handshakezmq_send(to_env, "hello", 5, 0);&lt;br/&gt;&lt;br/&gt; &amp;nbsp; // talkwhile (true)&lt;br/&gt; &amp;nbsp; {&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp;// receive rewardzmq_recv(to_env, reply, 1, 0);&lt;br/&gt;&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp;// receive teacher/env bitzmq_recv(to_env, reply, 1, 0);&lt;br/&gt;&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp;// reply&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp;reply[0] = response[n % strlen(response)];&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp;zmq_send(to_env, reply, 1, 0);&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp;n += 1;&lt;br/&gt; &amp;nbsp; }&lt;br/&gt;&lt;br/&gt; &amp;nbsp; zmq_close(to_env);&lt;br/&gt; &amp;nbsp; zmq_ctx_destroy(context);&lt;br/&gt;&lt;br/&gt; &amp;nbsp; return 0;&lt;br/&gt;}&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;用 Learner Binary Run Session：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;python run.py tasks_config.json -l learners.base.RemoteLearner \&lt;br/&gt;--learner-cmd "/my/learner/binary"&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;控制台视角&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;鉴于人类模式，默认视角展示了一个控制台界面，你能观察正在进行的两部分之间的通信，当运行一个自动学习算法时，该视角默认为一个更简单的存在，从而让算法更快的运行。然而，仍然有可能通过参数 -v ConsoleView，或等效的 --view ConsoleView 来返回到控制台视角。例如：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;python run.py -l learners.sample_learners.SampleRepeatingLearner -v ConsoleView tasks_config.json&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;要求：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Python 2.6+&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;zeromq (for remote learners)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;论文标题：通向机器智能的路线图&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8UiaacpTJM0C6dlzmbWH7t2gFia8vkeaOMlN5Nk0Gn1OtibjwPicOfJMEPqKiaDgKvsD5zDzvZEwAVYQQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：&lt;/span&gt;&lt;span&gt;智能机器的发展是计算机科学领域中面临的最大挑战之一。在这篇论文中，我们提出了这些机器应该有的一些基本性质，尤其是沟通和学习上。我们探讨了一个用于逐步教一台机器学习基于自然语言的交流的环境，将它作为与人类用户实现更加复杂的互动前提。我们也提出一些猜想，是关于该机器应该支持的算法，以便于能便捷地从该环境中学习。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 27 Sep 2016 11:54:34 +0800</pubDate>
    </item>
    <item>
      <title>重磅 | PaddlePaddle之后，百度开源深度学习硬件基准DeepBench</title>
      <link>http://www.iwgc.cn/link/2854957</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Baidu Research&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李亚洲、老红、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;谷歌、微软、Facebook 等传统的人工智能技术巨头之外，百度近来也加入到了技术开源的浪潮之中，继 PaddlePaddle 之后，百度又宣布开源了一项深度学习基准 DeepBench。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;开源地址：&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;https://github.com/baidu-research/DeepBench&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;1.DeepBench&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;DeepBench 是一个开源的基准工具，用来测量深度神经网络训练中的基础操作的表现。使用神经网络库，这些操作在不同的硬件平台被执行。如今测试基准工具 DeepBench 在 github 上已经开源。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;DeepBench 的主要目标是 benchmark 对深度学习在不同硬件平台上而言很重要的运算。尽管深度学习背后的基础计算已经被很好的理解了，但在实践中它们被使用的方式惊人的不同。例如，矩阵相乘运算基于被相乘矩阵的大小和 Kernel 实现，可能是 compute-bound，也可能是 bandwidth-bound, 或者 occupancy-bound。因为每个深度学习模型带着不同的参数使用这些运算，面向深度学习硬件和软件的优化空间还是很大的，也是不足的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;DeepBench 试图解决这个问题，「在被用于训练深度神经网络时，在基础运算上哪种硬件提供最好的表现？」我们在低层次上详细说明了这些运算，建立深度学习处理器的团队很适合在硬件模拟中使用 DeepBench。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1.1 DeepBench 适合用在哪里？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;深度学习生态系统包含不同的模块。我们想要强调 DeepBench 适合用于该生态系统的哪部分。在下面的图表中，描述了关于深度学习的软件和硬件组件。在最顶端是百度的 PaddlePaddle、Theano、TensorFlow、Torch 等这样的深度学习框架，这些框架使得我们能够建立深度学习模型。它们包含层（layer）这样的基础建筑模块，可通过不同的方式连接从而创造模型。为了训练这些模型，框架使用英伟达的 cuDNN 和英特尔的 MKL 这样的基础神经网络库。这些库执行矩阵相乘这样的用来训练深度学习模型的运算。最后，在英伟达 GPU 或英特尔 Xeon Phi 处理器这样的硬件上训练这些模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8UiaacpTJM0C6dlzmbWH7t2e9M6RfMFXubcjvko6xfibLiccfnxQO07Ncfc327Gc0ibXiby4UQlJwn8Ww/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;DeepBench 使用神经网络库 benchmark 基础运算在不同硬件上的表现。它对建立应用的深度学习框架或深度学习模型没用。我们不能测量使用 DeepBench 训练整个模型所需要的时间。为不同应用建立的模型的表现特性彼此间差别很大。因此，我们要 benchmark 涉及到深度学习模型训练中的潜在运算。benchmark 这些运算有助于提高硬件供应商的 意识，也有助于软件开发者了解深度学习训练的瓶颈。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1.2 方法论&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;DeepBench 包括一系列的基础操作（稠密矩阵相乘、卷积和通信）以及一些循环层类型。在开源的代码中有一个 Excel 表格描述了所有的大小。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;前向和后向的运算都会被测试。该基准的第一代版本将注重在 32 位浮点算法中的训练表现。未来的版本可能扩展到注重推理工作负载（inference workloads）和更低精度的算法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;即使存在更快的独立库或公开了更快的结果，我们也将使用供应商提供的库。大部分用户将默认使用供应商提供的库，而且这种库更代表用户的体验。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1.3. Entry&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们正在释放在 4 个硬件平台上的结果：英伟达的 TitanX、M40、TitanX Pacal 和英特尔的 Knights Landing。硬件供应商或独立用户可运行大致的基准，并将结果输入到表格中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;2. 运算的类型&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2.1 稠密矩阵相乘&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;稠密矩阵相乘存在于大部分深度神经网络中。它们被用于执行全连接层和 vanilla RNN，以及为其他类型的循环层建立基石。有时它们也被用作快速执行新类层（在这里面自定义的代码不存在）的方式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当执行 GEMM 运算 A * B = C 时，A 和 B 中的一个或两个都能被随意的换位。描述一个矩阵问题的常用术语是 triple（M,N,K）, 该术语描述了矩阵的大小。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8UiaacpTJM0C6dlzmbWH7t2uGysicfIFOj1QHCpoMFePBv7fDkO4wMDufEMGsbs5j5XQlYITrr05EQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2.2 卷积&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;卷积构成了网络中在图像和视频操作上的绝大多数的浮点计算，也构成了语音和自然语言模型网络中的主要部分，从模型表现角度来看，它可能也是唯一最重要的层。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;卷积有 4 或 5 维的输入和输出，为这些维提供了大量可能的排序。在改基准的第一代版本，我们只考虑了在 NCHW format 中的表现，即数据是在图像、特征映射、行和列中展示的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有很多计算卷积的技术对不同大小的过滤器和图像来说都是很好的选择，包括：direct approaches、基于矩阵相乘的方法、基于 FFT 的方法以及基于 Winograd 的方法。在该基准的第一代版本，我们没考虑不同方法的准确率，因为普遍共识是 32 位浮点计算对它们每个方法而言都是足够准确的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2.3 循环层（recurrent layers）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;循环层总是由之前的运算与一元（unary）或二元（binary）运算这样的简单计算结合而成的——这些简单运算不是计算密集型的，通常只需占据总体运算时间的一小部分。然而，在循环层中，GEMM 和卷积运算相对较小，所以这些更小运算的成本变得有极大影响。如果开始计算就有一个很高的固定成本，那上述内容就尤其准确。也可以为循环矩阵使用额外的存储格式，因为转换成一个新的存储格式的成本可被分摊到循环计算的许多步骤上。如果能做到这一点，那么从一个自定格式转换或转换成一个自定义格式的时间应该被包含在整体时间之内。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在一个时间步骤内和跨序列的时间步骤上，这些因素会导致很多优化的可能性，因此测定运算的原始性能并不一定能够代表整个循环层的的性能。在这样的基准上，我们仅关注一个循环层，即使还存在其它更多的优化机会（如果考虑它们的层叠（stack））。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;输入的计算不应该被包含在用于循环层计算的时间内，因为其可以作为一个大的乘法计算，然后被实际的循环运算所消化。所以在 h_t = g(Wx_t + Uh_t-1) 中，Wx_t 对于所有 t 的计算时间不应被包含在循环层的时间内。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;反向计算应该在考虑权重而非输入的基础上计算更新（update）。所有的循环工作完成以计算权重更新，所以同时考虑输入来计算更新会掩盖我们想要测定的内容。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;vanilla RNN 的非线性应该是一个 ReLU。LSTM 的内在非线性应该是标准运算——门（gate）是 S 型函数，激活（activation）是双曲正切函数。LSTM 不应该有窥视孔连接（peephole connections）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2.4. All-Reduce&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在的神经网络通常在多 GPU 或多系统与 GPU 并行的情况下训练，这主要有两个技术分类：同步和异步。同步技术依赖于保持参数和所有模型实例的同步，它通常要保证在优化步骤执行前，所有模型实例有一些梯度的备份。最简单运行这些计算结果的 Message Passing Interface (MPI) 被称为 All-Reduce。有很多可以执行 All-Reduce 的方法，我们可以依靠数字的排列、数据的大小和网络的拓扑结构来执行。这种基准测试的方式在执行时是没有限制的，所以它的结果是不确定的。异步的方法则非常的不同，在这个版本的基准测试中我们不会测试这些方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了评估 All-Reduce，我们使用了下面的库和基准：NVIDIA's NCCL Ohio State University (OSU) Benchmarks&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;NCCL 库包括一组标准的通信程序。这个库支持在单个节点任意数量的 GPU 运行，并且它能在单个或多个进程中运行，但 NCC 程序不支持多节点下的 All-Reduce。为了能够在多节点下评估 All-Reduce，我们使用了 OSU 下的 benchmark。我们在三个执行过程中 (NCCL single process, NCCL MPI, OpenMPI) 报告了最短的延迟。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Nvidia 8 GPU 系统的拓扑结构&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;每个节点都有两个 GPU 插槽，而每个插槽都有一个 PCIe root complex。&lt;/span&gt;&lt;span&gt;每个节点都有两个 GPU 插槽，而每个插槽都有一个 PCIe root complex。每一套插槽都有两个 PLX 开关，它们通过 16 个 PCIe v3 的 lanes 各自连接到 CPU 插槽中。每个 PLX 插槽有两个 GPU，所有的 GPU 通过 16 个 PCIe v3 的 lanes 进行同时通信。这两个 CPU 插槽通过 Intel 的 QPI 连接，而跨界点的互联则是通过 InfiniBand FDR。下图显示了一个原理图的节点，在图中，所有的设备均由同一个虚线框内的 PCL root 连接。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8UiaacpTJM0C6dlzmbWH7t22b2ic5ZGyos6e4fGLUWBR3jtbX331VTibN2TNGVnXsvuibRdK35b6ibuyg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;英特尔 Xeon Phi 和 Omni-Path 系统的拓扑结构&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;MPI_AllReduce 时间是在英特尔 Xeon Phi 7250 处理器上测定的——在英特尔内部的带有 fat-tree 拓扑的 Intel® Omni-Path Architecture (Intel® OPA) series 100 fabric 结构的 Endeavor 集群上，使用了 Intel MPI 5.1.3.181。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3. 结果&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这部分，我们记录了一些运算的表现。下面这些结果是随机挑选的，它们只是为了演示几个应用的运算表现。下面的结果仅包括了特定操作和参数下最快的处理器的时间和浮点运算速度。完整的结果可以在库里查看。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些软件库（例如 cuDNN 和 OpenMPI）和一些硬件系统的细节同样在 github 的库里适用。如有问题，请随时和我们联系。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一旦更多硬件平台的结果被发现可以适用，它们都会被加到库里面来。我们也欢迎所有硬件厂商为此贡献结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3.1. GEMM Results&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8UiaacpTJM0C6dlzmbWH7t26OqvhvvTQEVm395lDtHE2VCYX0NH2gbKHxGic592ibxnQHjSlW7Cu3Lg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3.2. Convolution Results&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8UiaacpTJM0C6dlzmbWH7t25oxl1fFBhibRCwSNRSETMqSwicHaY78Igxqx4GP3cRKMuqSUZCFFUibwQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3.3. Recurrent Ops Results&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;周期性的操作内核仅能在 NVIDIA 的硬件上运行，而周期性的标准检查程序也将很快可以在 Intel 的硬件上运行。在今年十月份我们将会得到这些结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8UiaacpTJM0C6dlzmbWH7t2FXbgGkpzRLSdNEVqfauH5psbhGLsHQ6Aplm11gQNMv8B5A0l3AWCDA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3.4. All-Reduce Results&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因为我们仅仅只有一个 Pascal GPU，所有我们不能在 NVIDIA's TitanX Pascal GPU 运行 All-Reduce benchmark。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8UiaacpTJM0C6dlzmbWH7t2jUqWWxibH4n3dffVFS4Y9gu7uAGMxLjvxIJ4SqLL8ibaqZzicjR1jOaTQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们欢迎来自各界的贡献，具体体现在如下两个方面：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 深度学习研究者/工程师：如果你是一个正在从事新的深度学习应用的研究者或者工程师，你可能会在训练你的模型的时候有不同的运算结果和工作量。而我们对于那些能够逆向影响你模型表现（速度）的底层运算结果非常感兴趣。请将这些运算结果和工作量反馈给我们。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 硬件供应商：我们也非常愿意接受来自其他硬件硬件供应商的贡献。我们对 benchmark results 的接受态度十分开放，无论你是大公司还是基于深度学习训练的小型创业公司，都请将你们的 benchmark results 反馈给我们！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 27 Sep 2016 11:54:34 +0800</pubDate>
    </item>
  </channel>
</rss>
