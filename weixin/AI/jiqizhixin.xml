<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>机器之心</title>
    <link>http://www.iwgc.cn/list/670</link>
    <description>人与科技的美好关系</description>
    <item>
      <title>深度 | 专访Facebook人工智能实验室负责人Yann LeCun：错过DeepMind也不算一件坏事</title>
      <link>http://www.iwgc.cn/link/3362551</link>
      <description>&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Business Insider&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Sam Shead&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：蒋思源、李泽南&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Yann LeCun是人工智能界的著名学者，现任Facebook人工智能研究部门的主管。就在上周，LeCun作为神经网络的先驱获得了Lovie终身成就奖，Business Insider专访了这位来自巴黎的学者。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Yann LeCun 教授是人工智能三巨头之一（另两位是 Hinton 与 Bengio），在 20 余年的研究历程中，他已累积发表了超过 180 篇论文，现在 LeCun 是 Facebook 人工智能研究机构的主管。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他最广为人知的研究在 1988 年，LeCun 参与开发了著名的「卷积神经网络」，可以识别手写数字。随着数据训练的不断持续，这种革命性的系统开始从图片像素中识别视觉特征，这就像为计算机打开了双眼，让它们可以从数据中自我学习。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们在上周 LeCun 刚刚获得 Lovie 终身成就奖之后见到了这位来自巴黎的学者，并专访了他。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：谈谈你的部门在 Facebook 中的角色吧。&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：我领导的部门：FAIR（Facebook Artificial Intelligence Research）的任务——我们总称自己为「FAIRies」——是推进人工智能的科学与技术；并通过实验发展这一技术在各个领域中的应用，如计算机视觉，对话系统，虚拟助手，语音识别，自然语言识别等等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能的背后存在很多基础科学，它们也许并不面向应用，你的研究可能也只是通向对智能和人工智能的理解。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们也同 Facebook 的另一个小组合作研究，应用机器学习团队（AML），他们的人数是我们的一半。是它们将科学转化为可见的技术，通过为公司构建应用平台，他们正将人工智能服务变为产品团队可以使用的东西。所以我得说 Facebook 里有很多人都在做着 AI 相关的工作，不仅仅是 FAIRies。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：你能说说有多少人在你的实验室里工作吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：当然，有大约 75 个人正在 FAIR 工作，就像我说的，AML 的两倍，公司中还有很多其他人处理 AI 应用方面的事务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：FAIR 的员工仅在加利福尼亚，还是遍布全球？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：有一些员工在纽约工作，我也在那里。此外，Menlo Park（Facebook 总部所在地，位于加利福尼亚州）和巴黎也有一些成员，还有一个小团队在西雅图。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWicKYha6n6vemibmx6zUztu84WAoBNicztvyb6csXhGHRTG5oOicsXdsRlB1uCsEaMgialMewh19h2e8icg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Facebook 在 Menlo Park 的总部&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：你认为 Facebook 的哪个部分可以用人工智能加以改善？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：Facebook 面临的最大问题，时刻需要解决的问题，就是我们需要将最好的内容向每个人呈现。所以你必须理解内容，理解每个人，然后把内容和对它们感兴趣的人相匹配。这是非常重要的一个方面。只有做到这一点，人们才会选择 Facebook Feed。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而在这之上，我们的远期目标，是建立一个真正的智能机器，让你可以与它直接对话，它需要能回答任何问题，并对你的生活提供帮助。这件事对于当今的人工智能而言非常具有挑战性。对话系统，自然语言识别，所有这些的基础在于让机器学会人类的常识。我们现在还不知道到底应该怎么做，但我们对此有很多想法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：所以，比如我是一个 Facebook 的用户，我厌倦了 News Feed 里面晒娃的消息，我能用自然语言告诉 Facebook 让它屏蔽这类推送吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;答：这是一种方式，但其实是一种非常不方便的方式，让人告诉 Facebook 怎么做。如果我们拥有了对话系统，你可以对它说：「请不要再推送婴儿照片了。」但是现在已有的方式是 Facebook 通过学习用户习惯知道了你不看这些图片。你或许会很快地浏览这些图片，或者点击它们但没有评论之类。所以我们已经可以通过你的习惯了解你的兴趣所在了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：你觉得目前的人工智能军备竞赛谁是赢家？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;答：没有谁跑在前面。有许多公司正在做着大量的人工智能研发，对于人才的竞争也很激烈，但现在并没有谁发明了远远领先于其他公司的新技术，我是说需要别人花费三个月以上才能赶上的新技术。我认为有三四家公司现在处于第一集团，Facebook，谷歌——特别是其中的 DeepMind，其实我的意思是 Alphabet，它已经不是谷歌的一部分了——还有微软，人工智能是他们的传统优势项目，IBM 也进步了很多。然后才是其他很多公司。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：你提到了谷歌和 DeepMind。DeepMind（以创纪录的 40 亿英镑价格被谷歌收购）开发了 AlphaGo，击败了围棋的世界冠军，我听说 Facebook 也在这一领域有所研究，当 DeepMind 超过你们的时候你是否很失望？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;不不，我们没有失望，因为这是整个人工智能领域的伟大胜利。我的一些学生和博士后参与了 DeepMind 项目。分析围棋棋盘并决定落子位置的系统实际上是卷积神经网络，这是我的发明。所以说这一成就建立在所有人的努力之上。我们 Facebook 对围棋的研究不多，基本上只有两个人在做。我们的围棋研究主要作为计划和勘探研究的载体。我们做这个，我们的系统工作得不错，然后我们把它开源了，这跟 DeepMind 的系统相比体量相差很多。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：在人才方面，你们如何保证 Facebook 可以招揽人工智能最好的人才？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：你知道，这需要和大学实验室保持良好关系，这些机构输出各类人才，进行各种可能的研究，同时项目和成果也是公开的。事实上，对于 FAIR 而言，公开性不止于可能，而是需求。假设你是一名研究者，你肯定总是想公开发表你的研究成果，对于科学家来说这很重要，因为你的地位在于学术影响。而要有影响，你不能简单地告诉人们「我正在为 FAIR 工作，但我不能告诉你们我在研究什么」，这样你的职业生涯就毁了。这很重要，我觉得在这一点上我们领先于其他公司，同时在 Facebook 你可以和世界上最棒的同事们交流。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们还在做很多事，都有关和学术界保持良好关系。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：进去工作的薪水是多少？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：哦，这是很重要的，特别是现在我们还在和微软，谷歌及其子公司竞争的情况下。但是其他的基本待遇也要给到，如果条件不够好，那么都没人愿意过来了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：你能大概告诉我们顶级 AI 从业人大概的薪水吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：不，我不能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：你的聊天机器人 M 现在怎么样了？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：最初 M 只是一个研究人们是怎样使用类人虚拟助手的试验，不过 M 的大多数工作实际上是由人类完成的。也就是说你不能把它扩展到数以百万计的用户，这也就是为什么我们把用户数量限制在很小的范围内。随着研究的进展，我们学到了很多人类会问的问题，开始让机器执行一些人类的工作，并为特定领域开发了一些相对专业的机器人，这就是它的现状。所以相对专业的机器人都是在电影，餐厅或别的什么地方。而能回答任何问题的机器人的基础研究还在网页里，比如在维基百科上，这还处于研究阶段。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：你们正在倡导与 AI 伙伴关系，Facebook 如何确保人工智能发展的伦理和安全？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：对于人工智能，现在还有一些真实存在或想象下的危险。如像终结者那样的危险情况，或者是 Nick Bostrom 书中的超级智慧（Superintelligence），你知道他说人们本来想要开发一个高效制造回形针的人工智能，最后整个银河系都会塞满回形针。这不是我们需要但有的，因为我们的技术水平还差得很远。而且现在已有各种会议，研讨会，论文等正在讨论更远未来超级智能机器的伦理问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们现在努力解决的 AI 伙伴关系问题在于如何让人工智能系统不出现偏见，比如，数据中可能会有偏见。举个例子，我们并没有驾驶自动驾驶汽车，但是如果你是在建立一个机器学习系统让它自己驾驶汽车，你就想彻底地测试它，不过由于最佳的实践方案还不完全清楚，所以我们还有很多工作要做。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：有传言说 Facebook 一度考虑收购 DeepMind，Facebook 收购 DeepMind 是一个好的选择吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;你也知道事情已经过去了，现在 DeepMind 还有很多优秀的人。我认为如果不是谷歌收购了 DeepMind，那么 DeepMind 的现状还要有很多不同的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我认为 DeepMind 的挑战就是在地理上和加州的总部所隔开了，这使得他很难将技术转化为产品。所以这也在一定程度上让 DeepMind 需要靠自己生存下去。也许它会发展一些应用，例如将 AI 运用到医疗。他们十分强调公共关系，因为这对于整个团队是很重要的。特别是他们很难自己生产应用级产品，这将对他们是个巨大的挑战。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这样一个几家公司同时为一个目标而努力的时代实在是很棒的体验，因为我们能在彼此的基础上思考问题。每当我们有个好想法，DeepMind 都会在我们想法上更进一步提升，反之亦然。有时候我们会一起工作在一个团队几天或几个月，他们基本上雇佣了我一半的学生。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：DeepMind 基本处于 Sergey Brin 和 Eric Schmidt 的掌控中，这意味着谷歌高管们强烈支持 DeepMind，这肯定能帮助 DeepMind 把技术转化为产品，对吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：研究这种先进的技术，你必须获得管理层的支持，因为基础研究的影响在比较长时间后才能体现出来。你不能幻想种下一颗种子，然后技术就自然而然地有了，突然冒出了实体产品线，商业形式发生了彻底改变。你需要来自高层的支持，因为这是一种长期投资。这不是那种我投资进去，半年后就能收回成本的事情。它需要的是有远见的人，这样的人谷歌有，Facebook 也有。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Fri, 04 Nov 2016 14:24:33 +0800</pubDate>
    </item>
    <item>
      <title>专访｜百度语音识别技术负责人李先刚：如何利用Deep CNN大幅提升识别准确率？</title>
      <link>http://www.iwgc.cn/link/3362552</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心原创&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：赵云峰&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;技术顾问：赵巍、Yuxi Li&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;近日，百度将 Deep CNN 应用于语音识别研究，使用了 VGGNet ，以及包含 Residual 连接的深层 CNN 等结构，并将 LSTM 和 CTC 的端对端语音识别技术相结合，使得识别错误率相对下降了 10% （原错误率的 90%）以上。 &lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;iframe class="video_iframe" data-vidtype="1" style="   z-index:1; " height="375" width="500" frameborder="0" data-src="https://v.qq.com/iframe/preview.html?vid=a0342d35pi3&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0" allowfullscreen=""&gt;&lt;/iframe&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器之心对百度语音技术部识别技术负责人，同时也是 &lt;/span&gt;&lt;strong&gt;Deep Speech 中文研发负责人李先刚博士&lt;/strong&gt;&lt;span&gt;进行了独家专访，李先刚博士详细解读了 Deep CNN 中的各项技术以及研究思路，并表示此次语音识别技术的提升将在接下来用于语音搜索产品。而百度正在努力推进 Deep Speech 3 ，这项研究不排除将会是 Deep Speech 3 的核心组成部分。以下是采访内容：&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：能先大体介绍一下 Deep CNN 吗？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;李先刚&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：百度这次利用深层卷积神经网络技术（Deep CNN）应用于语音识别声学建模中，将其与基于长短时记忆单元（LSTM）和连接时序分类（CTC）的端对端语音识别技术相结合，大幅度提升语音识别产品性能。该技术相较于工业界现有的 CLDNN 结构（CNN+5LSTM+DNN）的语音识别产品技术，错误率相对降低 10% 。该技术借鉴了图像识别在近些年的成果，以及语音与图像在利用 CNN 模型训练的共通性，是在端对端语音识别技术的革新之后取得的新的技术突破。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其实最早 CNN 在语音领域是有应用的，这两年语音研究专注的主要是 RNN ，而图像领域专注的 CNN 。在语音领域的研究者把 LSTM 和 RNN 做的很好之后，发现 CNN 的发展在语音领域是可以借鉴和有所帮助的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;比如从 ImageNet 竞赛中就可以看出深层卷积神经网络方面的进展。这些网络结构有一个明显的发展趋势，就是越来越深的卷积神经网络层级（CNN）：从最初的 8 层网络，到 19 层，22 层，乃至 152 层的网络结构。ImageNet竞赛的错误率也从 12 年的 16.4% 逐步降到了 3.57% 。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8E4TjIhibUIREOamYfQmmEwvVYr1IKP7et4lNAB3G09srQWvwRuJEAibr6lGTp7t8DHE6WCFHVz1tg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这个背景下，深层 CNN 成为今年语音领域前沿研究中最火的东西，很多公司都在做这方面研究。而我们这次做 CNN 有个很好的点是有个 baseline ，这是基于 Deep Speech 2 端对端基础上，进一步通过引入 CNN 来实现更好效果，这是我们的研究背景。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这个情况下，我们做了一些非常有意思的实验和希望得到最好性能的工作。为什么说最好性能呢？因为我们做的工作都是大数据，调参时有上万小时，做产品时甚至有 10 万小时。我们希望通过这些来验证，Deep CNN 是真的可以发挥作用，因为你会发现，现在很多基于数据集做的算法在大数据时可能就没用了，但我们发现它是有用的，在端到端框架下也是有用的，这可能算是我们的一个突破点和贡献。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;机器之心：微软最近也公布了一项语音识别的突破，能对比一下这两项研究吗？&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;李先刚&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：微软这次研究更加学术，是在一些标准数据库上做的，是一个口语数据库，叫做 switchboard ，数据库只有 2,000 小时。这个工作是微软研究院做的，他们的关注点是基于这样一个数据库最终能做到什么样的性能。而我们的关注点是我们的语音技术能够深入到大家的日常应用中，去把语音识别服务做到更好，我们的数据是数万小时。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;机器之心：这项研究涉及的过程和具体技术工作有哪些？&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;李先刚&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：在 ImageNet 竞赛得到广泛关注的 DeepCNN 结构，包括 VGGNet ，GoogleNet 和 ResNet 等。其中 ResNet ，可以通过 Residual 连接，训练得到一百多层的 CNN 网络，这样的网络虽然能够显著提升性能，由于其无法实现实时计算，使得其难以在产品模型得到应用。但是我们可以借鉴 Residual 连接的思想，训练一个数 10 层的包含 Residual 连接的 DeepCNN ，以用于工业产品中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8E4TjIhibUIREOamYfQmmEwRmvNJUuPTicCNV3NZ25Ccd1icZdOqj0w2kqVdvHviaVTt8OZxhXFic7JYA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8E4TjIhibUIREOamYfQmmEw8etWC0zYQxQyYCIicicj08mnpYgYzlv2d4GFkMia25mkd6RicrZc2ecavA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8E4TjIhibUIREOamYfQmmEwG70wwCLLwaaNzZvTa3zE7PsBt4U1XjxgDcZECeWxy7NK19jWnia1hfA/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;从上至下为 VGGNet 、GoogleNet 和 ResNet&lt;/span&gt;&lt;/em&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因此，百度做了以下的对比试验：1）HMM 框架中基于 VGGNet 结构的声学模型；2）在 HMM 框架中包含 Residual 连接的 CNN 网络结构的声学模型；3）在 CTC 框架中使用纯 VGGNet 实现端对端建模；4）在 CTC 框架中，在 CLDNN（CNN+5LSTM+DNN）结构中的 CNN 借鉴图像领域的研究成果，尝试 VGGNet ，包含 Residual 连接的深层 CNN 等结构。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们发现，深层 CNN 结构，不仅能够显著提升 HMM 语音识别系统的性能，也能提升 CTC 语音识别系统的性能。仅用深层 CNN 实现端对端建模，其性能相对较差，因此将如 LSTM 或 GRU的 循环隐层与 CNN 结合是一个相对较好的选择。可以通过采用 VGG 结构中的 3*3 这种小 kernel ，也可以采用 Residual 连接等方式来提升其性能，而卷积神经网络的层数、滤波器个数等都会显著影响整个模型的建模能力，在不同规模的语音训练数据库上，百度需要采用不同规模的 DeepCNN 模型配置才能使得最终达到最优的性能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因此，我们认为：1）在模型结构中，DeepCNN 帮助模型具有很好的在时频域上的平移不变性，从而使得模型更加鲁棒（抗噪性）；2）在此基础上，DeepLSTM 则与 CTC 一起专注于序列的分类，通过 LSTM 的循环连接结构来整合长时的信息。3）在 DeepCNN 研究中，其卷积结构的时间轴上的感受野，以及滤波器的个数，针对不同规模的数据库训练的语音识别模型的性能起到了非常重要的作用。4）为了在数万小时的语音数据库上训练一个最优的模型，则需要大量的模型超参的调优工作，依托多机多 GPU 的高性能计算平台，才得以完成工作。5）基于 DeepCNN 的端对端语音识别引擎，也在一定程度上增加了模型的计算复杂度，通过百度自研的硬件，也使得这样的模型能够为广大语音识别用户服务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：CNN 适用于语音识别的原理是什么，是如何带来效果的大幅提升的？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;李先刚&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：语音识别建模是需要对语音信号和文字内容间的关系建模。通常情况下，语音识别都是基于时频分析后的语音谱完成的，而其中语音时频谱是具有结构特点的。要想提高语音识别率，就是需要克服语音信号所面临各种各样的多样性，包括说话人的多样性（说话人自身、以及说话人间），环境的多样性等。卷积神经网络，由于其局部连接和权重共享的特点，使得其具有很好的平移不变性。将卷积神经网络的思想应用到语音识别的声学建模中，则可以利用卷积的不变性来客服语音信号本身的多样性。从这个角度来看，则可以认为是将整个语音信号分析得到的时频谱当作一张图像一样来处理，采用图像中广泛应用的深层卷积网络对其进行识别。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8E4TjIhibUIREOamYfQmmEwNp3MrvxXYSR2eXFdMfUyTrJSVGc1fHcJwn4SQciaszWouOdr07HCicjw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Deep CNN语音识别的建模过程&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2013 年过后，语音领域开始做 RNN ，图像领域做 CNN 。卷积操作是一种相较于全连接更加通用的计算形式，在 2013 年之后有很多进展，从 ImageNet 就可以看出来，首先发现 VGG 模型很有用，这种结构使用的是 3*3 这种小 kernel ； 此外 GoogleNet 结构，里面设计了一个 Inception 模块，也是基于 CNN 来实现的；比较有趣的是，微软 2015 年做的残差网络直接把十几层一下拉到 152 层，但 100 多层在工业上肯定没法用，因为算不过来。但这告诉大家，通过这种方式可以非常简单直接的提升性能，也就是提出了 residual 连接。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从这几个方面来看，CNN 在语音领域都没得到充分的研究，但大家能意识到这是我们可以探索的一个方向。有了这个出发点之后，我们就有好几个点可以做，比如说 VGGNet 里的 3*3 的 kernel 在语音领域应该怎么做；residual 连接怎么融合进来。我们在语音识别最早用的 CLDNN 结构是一层卷积，我把其做到 10 层，变成 VGG 结构，再加上一些残差连接，通过做一些大量实验模型的结构调整，最终得到性能提升。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8E4TjIhibUIREOamYfQmmEw8YBghpiaFhiaPhDskIZSLicDP5JV9us5S7rgxHM9wd9yHweLiadlLL1aJw/0?wx_fmt=png"/&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;语谱图&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从另外一个角度来看，如果你把语音当成一个图像，把语音视频信号分析过后就是一张图像，所以图像和语音是可以相互借鉴的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：能否介绍一下 CTC 端对端学习？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;李先刚&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：在深度学习兴起以前，机器感知算法（如语音识别，说话人识别，图像识别，等）通常都会包含以下几个部分：特征提取及学习，模式分类等。研究者们发现，在这样的级联系统里面，特征学习起到了非常关键的作用。在深度学习中，特征学习和模式分类两个模块则通常联合起来优化，从而使得通常意义下，深度学习的模型至少有两层。从而也带来了一个新的研究趋势：减少流水线中的模块，使用一个单独的学习算法来完成从任务的输入端到输出端的所有过程，也就是所谓的端对端学习的兴起。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;端对端学习使用一个算法将输入和输出联系了起来，通常采用的是一个深层的神经网络。端对端学习推崇更少的人工特征设计，更少的中间单元。端对端学习的系统包括：基于 CTC 的语音识别，基于注意机制的机器翻译，都已经在工业界得到了应用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：Warp-CTC 、Stanford CTC 和 TensorFlow 等在使用上有什么明显区别么？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;李先刚&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：我对 Stanford CTC 了解不多，但不管是哪种，我相信都是对 CTC 这种算法的功能实现，都是加速的问题。TensorFlow 不太一样，它是深度学习框架，不是针对 CTC 来做，客观来说，它的好处是方便研究者做实验预研。但坏处是速度慢。你可以在实验室里很快的尝试一个新的网络结构，做个 100 小时的实验，但如果规模上去了，TensorFlow 是不够的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：语言模型采用 n-gram models 的主要好处是什么？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;李先刚&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：n 元文法技术相对较老，但它可以很好的把规模弄上去，百度是一个文本大数据公司，在这样的背景下，你会发现基于大数据做一个很好的 n 元文法是很容易的，而且性能很好。通过这样一个大模型，通过海量数据，加上工程师做解码器的特别优化，使得系统在很好的实时性下的情况去达到很好的识别率。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;说到语言模型，还有一个研究比较多的是神经网络语言模型。对于神经网络语言模型，我们也希望能做到 first-pass decoding ，神经网络语言模型还有一些工程上的东西需要突破，我们都是把它放在第二遍 second-pass rescoring 上。总之，两者相比的话，神经网络语言模型的计算量特别大，优势是性能好。这个需要做很多工程方面的工作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：训练数据里的「模拟语音数据」和 10 万小时的精准标注语音数据对最后性能提升的贡献各有什么样的价值？如何获取「精准标注」数据？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;李先刚&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：训练模型的根本还是精确标注的数据，这是决定整个性能的基础。一般来说可以有这样的结论：数据增加十倍，性能提升10%，这是针对精准人工标注的数据。一般情况下，在获取什么样的精确标注数据的问题上，我们也会结合主动学习的思想，去收集那些对识别率影响更加直接的数据拿来人工精标。那为什么还要用模拟数据呢？所谓的模拟数据就是在精准标注的基础上做些信号变化，加一点背景噪声、混响的冲击响应，加上这些数据以后，会使模型能够见过更加多样的数据，这样对于模型的推广性和性能有一定程度的帮助，这算是一个保证模型具有更强能力的方法。所以，从根本上来说还是那 10 万小时。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：百度自主研发的硬件技术对计算效率有多少贡献？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;李先刚&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：百度开源了 Warp-CTC ，CTC 算法本质是一个前向后向算法在里面，要实现它的并行化还是比较难的，Warp-CTC 在这方面做的比较好。我们在做实验时发现，有了 Warp-CTC 这样一个高速的算法，还有我们自己内部有一个非常高效的多机训练的平台。使得我们整个模型训练的规模性比较好，当我们从一台机器扩展到十台机器，我们训练速度上的提升基本可以接近线性。有了这样的平台，才能使我们的近十万小时的模型才能做实验。否则连实验也做不了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此外，基于百度自主研发的硬件，才使得这样的计算复杂度更好的 Deep CNN 技术得以成为线上的服务。只有这些硬件技术的不断升级，才给了我们声学建模研究更大的空间。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：CNN 是目前语音领域的最新研究进展，你能介绍一下深度学习以来语音领域出现过的其他突破性研究吗？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;李先刚&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：大约是在 2011、2012 年开始将深度学习用于语音研究，最早是用最简单的前馈 DNN 模型，发现比 GMM 有 30% 的提升，大家就意思到这是一个划时代的突破。2013 年，研究者开始尝试做一些激活函数（例如ReLU，Maxout），其中的 Maxout 发现对 low-resource 的任务有帮助，对真实的大数据库不一定有显著帮助；2013-2014 年，大家开始做 CNN ，而非深层的；2014 年开始做 RNN ，尤其是 LSTM 。2014 年底 2015 年初，Hinton 的博士后 Alex Graves ，把以前做手写体识别的 LSTM 加 CTC 的系统应用在了语音识别领域，在 TIMIT 上做了结果。紧接着谷歌认为这个很有前途，就开始把这些技术推广在大数据上面。LSTM 和 CTC 引入进来之后，相较于之前的 DNN ，LSTM 能够更好的帮助模型来捕捉输入中的重要的点，CTC 打破了隐马尔科夫的假设，把整个模型从静态分类变成了序列分类，这是很重要的。百度在 2015 年中期开始做，年底 LSTM 和 CTC 上线。现在的 Deep CNN 是在我们整个研究框架中把 CNN 的潜力挖掘的更彻底。其实 CNN 和 LSTM 有相通也有不一样的地方，如果 CNN 在时间上做卷积的话，和 LSTM 有很多相似之处。而不同在于 LSTM 擅长做整个时间域信息的整合，而 CNN 要想达到同样效果做的配置就要更加复杂。但 CNN 有很强的平移的不变性，对于整个语音识别任务来说，要获得更好的鲁棒性，CNN 比 LSTM 做的好。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：这次 Deep CNN 带来的提升会应用在哪些产品中？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;李先刚&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：这项技术会在搜索产品，如手机百度的语音搜索先使用，然后再推广到其他产品。近一年来，手机百度上的语音识别的准确率提升了 20% 以上，效果感觉完全不一样。这次会带来效果的再次提升。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：你提到，现在做的技术研究都是要和产品相结合。对于整个语音识别行业来说，识别率一直在提升，但目前语音识别产品还没有被大范围使用，这里的原因是识别准确度还没有达到一个临界点？还是说产品层面的原因？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;李先刚&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：有各方面的问题，首先，识别率如果从现在的 97% 达到 99% ，那肯定会不一样。其次，产品上也有很多问题，你要做好一个输入法，或者语音搜索，是要把很多方面结合在一起的。像我们的语音搜索很早也具备了语音纠错功能，语音纠错对整个语音输入和搜索非常关键，仅仅做好一个识别率还不错，怎么样让你的产品体验更好，还有很多事情要做。因此，一方面是从研究的角度提高准确度，另一个是从产品角度提升用户体验。还有一个是用户习惯的养成，我们发现小孩对语音输入的接受程度很高。此外，之前百度硅谷人工智能实验室和斯坦福合作过一篇论文，在实验中，相比于在手机屏幕上打字，人类能够语音识别能更快、更准确的组织文本消息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：能否介绍一下百度目前整体的语音技术研究，这次 Deep CNN 对百度语音研究有着怎样的意义？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;李先刚&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：此前，百度语音每年的模型算法都在不断更新，从 DNN ，到区分度模型，到 CTC 模型，再到如今的 Deep CNN 。基于 LSTM-CTC 的声学模型也于 2015 年底已经在所有语音相关产品中得到了上线。比较重点的进展如下：1）2013 年，基于美尔子带的 CNN 模型；2）2014年，Sequence Discriminative Training（区分度模型）；3）2015 年初，基于 LSTM-HMM 的语音识别 ；4）2015 年底，基于 LSTM-CTC 的端对端语音识别；5）2016 年，Deep CNN 模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicKYha6n6vemibmx6zUztu84bo6Kb7z8B5oHUoSyyyN3jvgibHt1gU9haic71hHRXxqksXZNotkdtceQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;百度语音识别技术每年迭代算法模型&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在识别精度提升方面，通常在海量数据库上稳定提升 10% 以上就可以称作显著进步（significant improvement），这次我们就达到了这样一个效果。举个例子，我们语音技术部最开始用 CTC 提升了 15% ，这次用 Deep CNN 又提升了 10% 。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们正在努力推进 Deep Speech 3 ，这项研究不排除将会是 Deep Speech 3 的核心组成部分。而在工程领域，我们一直在做一些语音识别应用，手机百度和输入法要提升性能。我们希望在未来的几年内，将语音识别的准确率在某些任务上做到 99% ，从现在来看是有希望的。同时还有一些周边技术也在研究，包括说话人切分、远场语音识别应用等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心原创，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Fri, 04 Nov 2016 14:24:33 +0800</pubDate>
    </item>
    <item>
      <title>前沿 | 量子计算新进展，MIT联手哈佛用激光束实现单个中性原子的囚禁</title>
      <link>http://www.iwgc.cn/link/3362553</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自MIT&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Jennifer Chu&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：杜夏德&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;近日MIT哈佛的量子研究团队发明了一项新技术，用激光束将原子从原子云中一个一个孤立出来，而且不带电荷。&lt;span&gt;目前他们已将创造出了由 50 个原子构成的原子阵列，其中的每个原子都能单独控制。&lt;span&gt;科学家们会用照相机拍下这些被囚禁的原子及其位置的图像，然后基于这些图像，操作激光束的角度，来移动单个原子形成任意数量的不同组态（configurations）。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;原子、光子和其他量子粒子天生顽固；很少处于停顿状态，同一种量子粒子间常常产生碰撞。如果能把大量量子一个个单独用量子围栏拦起来控制住，就可以将它们作为量子比特——一种极小的信息单元，其状态和方向可用来进行计算，速度要比当下基于半导体的计算机芯片快上很多。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最近几年，科学家想了很多方法来把每个量子单独囚禁起来控制住。但是这类技术很难能扩展，因为缺少操控大量原子的可靠方法，这是实现量子计算的重大障碍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在，来自哈佛和 MIT 的科学家发现了一种有望解决这一问题的方法。相关论文发表在近日的 Science 杂志上，论文中提到他们发现一种新的方法，使用激光器或「光钳」（optical「tweezers」）来将原子一个一个从原子云中挑出来囚禁在某个地方。当原子被「囚禁」时，科学家们会用照相机拍下这些原子及其位置的图像。然后基于这些原子的图像，操作激光光束的角度，来移动单个原子形成任意数量的不同组态（configurations）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该研究团队目前已将创造出了由 50 个原子构成的原子阵列，并操控它们进入各种无缺陷的形状（pattern），其中的每个原子都能单独控制。论文作者之一，MIT 物理系的 Lester Wolfe 教授 Vladan Vuletic，将这一过程比喻为「从底部向上建立一个原子的小晶体。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们已经展示了一个可重复组态的（reconfigurable）单个原子的陷阱阵列，在这里面我们能确切地在分开的陷阱中将 50 个原子单独囚禁，用于未来的量子信息处理、量子模拟或者精确度测量，」Vuletic 说，他也是 MIT 电子研究实验室的成员。「就好像把原子当乐高积木来玩，你可以决定每块积木的位置。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicKYha6n6vemibmx6zUztu84n2mchsVsicibkFia9d9BL8gL0VSWB05nF5U4m9PKvglyx1T8icjWvHibCTA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;保持中性&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该研究团队设计的操纵中性原子的技术是不带电荷的。其他大多数量子实验中的原子总会带上电荷，或者离子，因为带上电荷的原子比较容易被囚禁。科学家还发现特定条件下的离子可被作为量子门——两个量子比特之间的逻辑运算，类似于经典的电路中的逻辑门。然而由于天生带电荷，离子间相互排斥，很难组成密集的阵列。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;与离子不同，中性原子之间在紧密性上没有问题。使用中性原子作为量子比特的主要障碍是，它们受到的外力非常微弱，很难被控制在一个地方。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;设陷阱&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了囚禁单个的中性原子，研究者们首次使用了一个激光器来将一团铷原子云冷却成超冷原子，其温度接近绝对 0 度，让原子从正常的高速轨道上慢下来。之后他们让第二个激光光束通过仪器分成很多小的光束，其数量和角度可以通过导流板（deflector）上的无线电频率来控制。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;研究者将这些小光束聚焦通过超冷原子云，并发现每一个光束的聚焦点——光束强度最高的点，都吸引了一个单个原子，将它们从云中完全孤立出来控制在某个地方。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「这就好像在某种毛织物上摩擦梳子带电，然后 用它来捡起一小片纸，」Vuletic 说。「这个过程类似于被吸引到光场（light field）中高强度区域的原子。」科学家使用电荷耦合器件相机捕获的原子虽然被囚禁住了，但它们还能发光。通过查看它们的图像，研究者可以辨别出哪些激光束或者「光钳」控制住了原子，哪些没有。然后，他们可以改变每个激光束的无线电频率来「关掉」无原子的光束，重新排列那些带有原子的光束，该研究小组最终创建了 50 个原子的阵列，这些原子被囚禁在某个地方的时间长达几秒。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「现在的问题依然是这次你能执行多少次量子运算？」Vuletic 说。「通常中性原子的时间刻度（timescale）大约是 10 微妙，所以你可以在一秒内做 10 万次运算，我认为这是一个很好的结果了。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在，该研究团队仍在他们是否能够促使中性原子作为量子门——两个量子比特之间的最基本的信息处理。虽然有其他研究者在量子中性原子之间展示了这一过程，但他们还无法在大量原子的系统中保留量子门。如果 Vuletic 和他的同事能成功地在他们的 50 个原子的系统中诱导出量子门，他们就会在实现量子计算的道路上迈出意义重大的一步。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「对于除量子计算外的其他实验，比如用具有预定数量的原子模拟凝聚态物理。用我们的技术就可以实现，」Vuletic 说这让他非常兴奋。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Fri, 04 Nov 2016 14:24:33 +0800</pubDate>
    </item>
    <item>
      <title>开源| 汉字风格迁移项目Rewrite：利用神经网络学习设计汉字新字体</title>
      <link>http://www.iwgc.cn/link/3362554</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心经授权编译&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：&lt;span&gt;Yuchen Tian&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀、李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;日前，Flipboard 软件工程师 Yuchen Tian 在 GitHub 上发布了用于汉字字体的神经风格迁移的项目，该项目介绍了如何通过神经网络学习设计汉字新字体的方法。机器之心授权编译发布。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;项目地址：https://github.com/kaonashi-tyc/Rewrite&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;项目目的&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;创建字体是一件难事，创建汉字字体更是艰难。要做一个兼容 GBK（中国政府设定的字符集标准）的字体，设计师需要为超过 26000 个不同的汉字字符设计外观，这是一项艰巨的工作，可能需要数年时间才能完成。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;可不可以让设计师仅设计其中一部分字符的字体，然后让计算机来确定剩下的字符应该是什么模样呢？毕竟，汉字是由一些被称为「偏旁部首」的基本元素构成的；在不同的汉字上，相同的偏旁部首看起来也都相当雷同。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个项目是使用深度学习的一个探索性的应用。具体而言，整个字体设计流程可被表示成一个风格迁移问题（style transfer problem）——将标准样式字体（比如 SIMSUN 体）转换为目标风格的字体。本项目通过向一个神经网络提供配对样本的子集来训练该神经网络近似学会两种字体设计之间的转换。一旦学习完成，该神经网络就可被用来推理其它字符的外形。下面的框图大概说明了这个思想：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicKYha6n6vemibmx6zUztu84Th3GjdWmRMPA7AeQLsotfrEuGZia0RbRBNI2RA0GbPIOeicHL3vmr2dw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个项目的灵感很大程度上来自于 Erik Bernhardsson 的博客《Analyzing 50k fonts using deep neural networks》和 Shumeet Baluja 的好论文《Learning Typographic Style》。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;网络结构&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在尝试过了各种不同的架构（包括具有残差（residuals）和去卷积（deconvolution）的更复杂的架构）之后，我最终选择了一种更为传统的自上而下的 CNN 架构，如下所示。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicKYha6n6vemibmx6zUztu84nGfVqUymuxs2DBhaEkuNmfCR5VGrIfMSnynnSib7N1lZM4gEMSF5rXA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;注意事项：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;每一个卷积层之后都有一个批规范化（Batch Normalization）层，然后是一个 ReLU 层，然后一直向下零填充（zero padding）。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;该网络基于预测输出和 ground truth 之间的像素级的平均绝对误差（MAE）进行最小化，而没有使用 Erik 的博客中提到的更常用的均方误差（MSE）。MAE 往往能产出更锐利和更清晰的图像，而 MSE 则会得到更模糊和灰蒙蒙的结果。另外为了图像的平滑度，还使用了总变差损失（total variation loss）。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;层数 n 是可配置的，更大的 n 往往会生成更详细和更清晰的输出，但也需要更长的训练时间，通常的选择是在 [2, 4] 之间。大于 4 的时候似乎会达到收益递减的点，即虽然运行时间增加了，但在损失或输出上不会有明显的提升。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;大卷积能带来更好的细节。在我的实验过程中，我开始使用的是堆叠的平直的 3×3 卷积，但它最后表现并不好或无法在更困难和更奇异的字体上收敛。所以最后我选择了这种涓滴形状的架构（trickling down shape architecture），其不同的层有不同大小的卷积，每一个都具有差不多相同数量的参数，所以该网络可以获取不同层面的细节。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;dropout 是收敛（convergence）的基础。没有它，该网络就只能放弃或受困于毫无价值的解决方案，比如全白或全黑图像。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;在 Erik 和 Shumeet 的工作中使用的全连接层（fully-Connected layers）对汉字字符的效果不是非常好，会生成噪声更多和不稳定的输出。我猜想是汉字字符的结构比字母的结构要远远复杂得多，而且从本质上来说更接近于图像，所以一个基于 CNN 的方法在这种情况下更为合理。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;和真实世界图像不一样的是，我们可以生成任意分辨率的字符图像。我们可以对这个事实加以利用：用高分辨率的源图像来逼近低分辨率的目标，从而可以保留更多的细节以及避免模糊和噪声。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;可视化&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;训练中的进展&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;上图展示了模型在多种字体上的训练过程中的验证集上所取得的进展。它们全都在 2000 个样本上进行了训练，层数设置为 3。看该模型如何从随机噪声收敛是很有意思的：首先获取一个字符的可识别的形状，然后获取更为细微的细节。下面是训练过程中某种字体的进展过程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicKYha6n6vemibmx6zUztu84T9hhLmicDj02BqPaK9NkAdsGLcVhq8icFOiabicTbXexzTC4NibT6ADzGZw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;与 ground truth 比较&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面的图像给出了对比 ground truth 的预测结果。对于每一种字体，我们都选取了最常用的 2000 个字作为训练集，运行 3000 次迭代。另外还有一个包含 100 个字的测试集用于推理。对于所有的字体，源字体都是 SIMSUN。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicKYha6n6vemibmx6zUztu84BgXzjofH5bALY2o9dthzSsmCdJ12JcyUJSWh1JaVc4R1ghQRSv3f8w/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于其中大部分字体，该网络都能成功做出合理的猜测。实际上其中一些还跟 ground truth 非常接近。另外值得一提的是，该网络还保留了微小的但可辨认的细节，比如偏旁部首的弯曲的端部。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但正如许多其它的神经网络所驱动的应用一样，当该网络出错时，就会错得非常离谱。对于一些字体（尤其是笔画粗的字体），它只会得到一些模糊的字迹斑点。另一方面，对于这些笔画粗的字体，它会失去让该字符可被辨认的关键的空白处细节，而只会获取到整体的轮廓。即使是在成功的案例中，偏旁部首的损失问题似乎也很常见。此外，网络似乎在宋体上可以做的更好，但在楷体上表现并不好，这主要是因为 SIMSUN 字体本身也是一种宋体。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因为空间的限制，对于每一种字体，我们从测试集中仅随机取样了一个字符。如果你想看到在更大的字符测试集上的结果，请查阅：https://github.com/kaonashi-tyc/Rewrite/blob/master/images/bigger_test.png&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;需要多少字符？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2000 字也许只有 GBK 集的 10%，但也仍然很多了。这个数字是我靠直觉选择的，而且看起来这个选择在很多字体上都表现不错。但必需这么多吗？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了搞清这一点，我选择了一种字体（在每种字体上都进行这个实验会太耗时间）进行了不同数量的训练样本的实验，数量的范围是从 500 到 2000，然后让该模型在一个常用的测试集上对字符进行渲染，下面是得到的结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicKYha6n6vemibmx6zUztu84x1rBw1bO99xgkKCrYLoH661swZWiacjjvickgict3ATTrrJDo78jxYLLA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从上到下，上图分别给出了训练集大小从 500 到 2000 增长时的不同结果。当训练集大小在 1500 到 2000 之间，表现的提升会变得更小，这表明 sweet point 就在这之间的某个地方。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;使用方法&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;要求&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;要使用这个软件包，需要安装 TensorFlow（已在 0.10.0 上测试过）。其它的 Python 要求列在 requirements.txt 文件里。另外强烈推荐使用 GPU——如果你想在合理的时间内看到结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我的所有实验都运行在一个 Nvidia GTX 1080 上。以 16 的 batch 大小进行了 3000 次迭代，这需要小型模型计算 20 分钟、中规模模型计算 80 分钟、大模型则需要 2 小时。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;样例&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在训练之前，你需要运行预处理脚本为源字体和目标字体生成字符位图（character bitmap）：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicKYha6n6vemibmx6zUztu84nerWn2WTgicU6AGn7tbUpz4DwNet52Icw549FWiaAOJXOSPdLV3L7Mow/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该预处理脚本支持 TrueType 和 OpenType 字体，它会获取一个字符列表（一些常见的字符集内置于本 repo 的 charsets 目录中，比如 3000 个最常用的简体汉字字符），然后将这些字符的位图保存为 .npy 格式。对于源字体，每个字体会被默认保存为字体大小为 128 的 160×160 的尺寸，而目标字体则是字体大小为 64 的 80×80 的尺寸。这里并不需要特别的对齐，只要确保字符不被截断即可。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在预处理步骤之后，你就能得到源字体和目标字体的位图，分别是 src.npy 和 tgt.npy，然后运行以下命令开始实际的训练：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicKYha6n6vemibmx6zUztu847BTMMLzicr4VT4wtfoOgzIpSbpAshZoR9uoib2KS0rOWu5icJLYVdiaQtQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这里给出了一些解释：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;mode：可以是 train 或 infer，前者不言而喻，后者我们将在后面讨论&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;model：表示模型的大小。它有三个可用选择：small、medium 或 big，分别对应的层数为 2、3、4&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;tv：总变差损失（total variation loss）的权重，默认 0.0001。如果输出看起来是损坏的或有波动，你可以选择增大权重迫使模型生成更平滑的输出。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;keep_prob：表示训练过程中一个值通过 dropout 层的概率。这实际上是一个非常重要的参数——这个概率越高，图像越锐利，但输出可能会损坏。如果结果不好，你可以尝试减小这个值，这会得到噪声更多但更圆润的形状。通常的选择是 0.5 或 0.9&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;ckpt_dir：用于保存模型的 checkpoint 的目录，用于后续的推理步骤&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;summary_dir：如果你想使用 TensorBoard 来可视化一些指标（比如迭代中的损失），这就是保存所有总结的地方。默认在 /tmp/summary。你可以检查训练 batch 的损失，以及验证集上的损失及其 breakdown&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;frame_dir：保存在验证集上获取的输出的目录。用于选出用于推理的最好模型。在训练之后，你也可以找到一个名为 transition.gif 的文件，可以看到该模型在训练过程中的进展动画，同样也在验证集上。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于其它选择，你可以使用 -h 查看确切的使用案例。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;假设我们最后完成了训练（终于完成了！），我们就可以使用前面所提到的 infer 模式了，看模型在之前从未见过的字符上表现如何。你可以在 frame_dir 中参考获取的帧来帮助你选择你最满意的模型（说明一下：通常不是误差最小的那个）。运行以下命令：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicKYha6n6vemibmx6zUztu84OHdVibs11KTnx6tXDDSBW7iaPDl2ccmhj3A1QuOX6oUIYpzhAZLfIpaA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;注意这里的 source_font 可以不同于训练中所使用的那个。事实上，它甚至可以是任何其它字体。但最好选择相同或相似的字体进行推理，以得到最佳的结果。在推理之后，你将能找到所有输出字符的图像序列以及一个包含了这些推理出的字符位图的 npy 文件。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;讨论&amp;amp;未来工作&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该项目只是一个个人项目，来帮助我学习和理解 TensorFlow，但也顺利发展成了一件更为有趣的事，所以我认为值得与更多的人分享。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前，该网络一次只能学习一种风格，如何将它扩展到一次性掌握多种风格会是一件有趣的事。2000 个字符比完整 GBK 数据集的 10% 还少，但它还是比较多的，少于 100 字符的情况下有可能学习到字体的风格吗？我的猜测是 GAN 可能会对此有所帮助。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在网络的设计上，该架构被证明在不同的字体上是有效的，但每个卷积层的数量的优化还需要搞清楚，或者一些卷积层是否有必要？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我想要探索的另一个有趣的方向是创造混合多种风格的字体。在损失函数上简单结合两种字体的表现并不好。可能我们应该为字体单独训练一个 VGG 网络，然后劫持（hijacking）特征映射？或者在网络设计上使用潜在更多的新变化，从而解决这个问题？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，该项目证明了更专门化的应用深度学习的可能性，CNN 帮助加速了汉字字体的设计流程。研究的结果很是振奋人心，但并非从无到有的创造新字体，这也不是该项目的内容。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;感谢&amp;amp;有用的资料&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;谷歌的 TensorFlow 教程：https://www.tensorflow.org/versions/r0.11/tutorials/mnist/pros/index.html&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;来自 Justin Johnson 的在快速神经风格迁移网络上的补充材料：http://cs.stanford.edu/people/jcjohns/papers/eccv16/JohnsonECCV16Supplementary.pdf 和 https://github.com/jcjohnson&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;来自 Ian Goodfellow 的视频：https://www.youtube.com/watch?v=NKiwFF_zBu4 。非常好的东西，非常实用，说明了很多如何使用深度学习解决问题的要点；看完之后，我就觉得没必要自己再写一份笔记了。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;感谢我的朋友 Guy 帮助我在合理的预算内搭建了一台 PC&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;证书&lt;/strong&gt;&lt;br/&gt;&lt;br/&gt;GPLv3&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心经授权编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Fri, 04 Nov 2016 14:24:33 +0800</pubDate>
    </item>
    <item>
      <title>学界 | Vicarious在ICLR 2017提交无监督学习论文，提出层级组合特征学习</title>
      <link>http://www.iwgc.cn/link/3362555</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Open Review&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李亚洲、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;人工智能领域的明星创业公司 Vicarious 一直受到了业内的极大关注，亚马逊 CEO 贝佐斯，Facebook CEO 扎克伯格，Salesforce CEO Marc Benioff 和 Box CEO Aaron Levie 等都是其投资人。近日，Vicarious 发表了他们的一篇有关无监督学习的新论文，该论文已提交 ICLR 2017。点击阅读原文可下载此论文。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicKYha6n6vemibmx6zUztu84QgNQhVDXwJW3dnz80gY2Cj51qlobiajxmicOvZbpsyxh4vha2jCicr9Bw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;摘要&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们介绍了一种层级组合网络（hierarchical compositional network，HCN），它是一种定向的生成式模型（directed generative model），能够在无监督的情况下发现并解开二值图像（binary images）集合的构建模块。这些构建模块是被层级式地定义为网络后层中一些特征（以某种特别的形式排布）的组合的二值特征。从高层面来说，HCN 类似于带有池化的 S 型信念网络（sigmoid belief network）。HCN 中的推断和学习非常具有挑战性，而且现有的变分近似法的效果不太令人满意。该研究的一个主要贡献是发现：使用经过特别安排的（不需要 EM）max-product message passing（MPMP），刚才提到的两个问题都能解决。而且，使用 MPMP 作为 HCN 推断引擎使得新任务更为简单：加入监督信息、分类图像或执行图像修复——全部都对应于将模型的一些变量固定于模型的已知值，然后在剩余部分上运行 MPMP。当被用于分类时，HCN 的快速推断几乎与带有线性激活函数和二值权重的卷积神经网络有同样的函数形式。然而，HCN 的特征在质量上却有很大的不同。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;关键词：无监督学习&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Fri, 04 Nov 2016 14:24:33 +0800</pubDate>
    </item>
    <item>
      <title>深度 | 自然语言处理顶级会议EMNLP 2016干货：从原理到代码全面剖析可用于NLP的神经网络（附获奖论文）</title>
      <link>http://www.iwgc.cn/link/3347055</link>
      <description>&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自EMNLP&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编辑整理&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：杜夏德、李泽南、李亚洲、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;今年的自然语言处理实证方法会议（EMNLP 2016）正在（11 月 1 日-5 日）美国德克萨斯奥斯汀市举行。作为自然语言处理领域的顶级大会，EMNLP 一直以来都在为自然语言处理的发展提供强大的助力。在此文中，机器之心整理了大会的最佳论文、荣誉论文、最佳短篇论文和最佳资源论文。此外，还把 Chris Dyer 等三人在大会上做的一个 tutorial 演讲《Practical Neural Networks for NLP》作为资源分享给大家，该 tutorial 较为全面地覆盖了用于自然语言处理的神经网络的基础，是自然语言处理入门的必备良品。机器之心还整理了相关论文和幻灯片，读者也可点击文末「阅读原文」下载。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;第一部分：获奖论文&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本届 EMNLP 一共选出了 6 篇获奖论文，包括 2 篇最佳论文、2 篇荣誉论文、1 篇最佳短篇论文和 1 篇最佳资源论文。下面是对这 6 篇论文的摘要介绍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;最佳论文&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1.Improving Information Extraction by Acquiring External Evidence with Reinforcement Learning&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8E4TjIhibUIREOamYfQmmEwcvDW8ia8RicI6WKnKKichTicKaQ9RqFNfKsxJkbIQaNb91FgekYOwYcYZA/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：大部分成功的信息提取系统运行时都接入一个大型的文件集。在这个研究中，我们探索了获取并结合外部证据的任务，以在训练数据量稀缺的领域中提高提取的精确度，这个过程需要重复发布搜索查询，从新的来源中提取以及使提取值一致，直到收集到足够的证据。我们使用强化学习框架来解决这个问题，在此框架中，我们的模型可以学习基于上下文来选择最优行动。我们应用了一个深度 Q-network，训练它来优化能反应提取精度同时还能惩罚多余工作的奖励函数。我们的试验用到了两个数据库——枪击事件数据和食品掺假情况数据——证明了我们的系统明显优于传统的提取器和一个元分类基准。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2.Global Neural CCG Parsing with Optimality Guarantees&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8E4TjIhibUIREOamYfQmmEwu7crLh2H8pv6S8ibrEH141fBWgX3AJBzOiamKMY8WbHgCxGOp6iaM6B6A/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：我们介绍了第一种全局递归神经解析模型，它是实时解码的最佳保证。为了支持全局特性，我们放弃了动态程序，用直接在所有可能子树中搜索的方式代替。尽管这样会导致句长指数性地增长，我们展示了达到学习效率 A 解析器的可能性。我们增大了已知解析模型，它存在外界评分的信息界限，通过一个宽松界限并只需非局性现象建模的全局模型。全局模型因此在新的目标下进行训练，这可以鼓励解析器更精确有效地进行搜索。这种方式适用于 CCG 解析，通过 0.4F1 获得了可观的精确性提升。解析器可为 99.9% 的停止句（held-out sentence）找到最佳解析，仅需搜索平均 190 个子树。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;最佳论文荣誉提名：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1.Span-Based Constituency Parsing with a Structure-Label System and Provably Optimal Dynamic Oracles&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8E4TjIhibUIREOamYfQmmEwT7AsCDUPibnZ9Y42mdPjPJZOBcZF0PIMVBRs42baEWt6Lv1JK7NH1HQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：由于神经网络的出现，使用有效的转换系统的解析精确度已得到巨大提升。尽管依存关系语法分析的结果惊人，神经模型还没有超过 constituency 分析中的最佳方法。为了弥补这个缺陷，我们引进了一个新的位移减少系统，该系统的堆栈只包含了句子跨度，通过最低限度的长短期记忆网络特征来表征。我们还为 constituency 分析方法设计出首个可查验的最优的 dynamic oracle，相比于进行依存分析的 O(n3)oracles，它在 amortized O(1)time 内运行。在此 Oracle 上训练，我们在英语和法语中任何不适用 reranking 和外部数据的解析器上，都取得了最好的 F1 得分。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2.Sequence-to-Sequence Learning as Beam-Search Optimization&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8E4TjIhibUIREOamYfQmmEwuwMlewDUX6I0icl5oRrBRGg8ZicHZqGaEepAibSfSSgPOwOjjsJNzicmOA/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：Sequence-to-Sequence（seq2seq）建模已经成为了一种重要的多用途自然语言处理工具，它已被证明在很多文本生成和排序任务中被证明有效。Seq2seq 建立在深度神经语言建模之上，并在局部的下一个词分布的估计中延续了其良好的精确度。在本研究中，我们介绍了一种模型和训练方式，基于 Daum'e III 和 Marcu（2005）的成果，同时扩展了 seq2seq 方式，使它可以学习全局序列分数。这种结构方式在证明了已有 seq2seq 模型架构能够进行有效训练的情况下，避免了传统方式上局部训练（local training）的常见偏差，同时通过测试使用时间使训练损失一致。我们发现与高度优化的基于注意的 seq2seq 系统以及其他系统相比，在三种不同的 sequence to sequence 任务中（词序，解析和机器翻译），我们的系统存在明显优势。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;最佳短篇论文：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Learning a Lexicon and Translation Model from Phoneme Lattices&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8E4TjIhibUIREOamYfQmmEwicLdV0Lmwxr7Vib010FFgqLkBT7ZcAelziazb7Bzad5PBUTt7qMl2xdZA/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：语言文件始于对语音的收集。在词上的手动或自动转录几乎不可能实现，因为缺乏正字法（orthography）或先前词汇，而且尽管手动音素转录是可能的，却相当的慢。此外，将小语种转译为主要语言更容易掌握。我们提出一种方法能掌握这样的翻译技能，从而改进自动音素识别。该方法假设没有先前词汇或翻译模型，而是从音素网格和被转录的语音翻译中进行学习。实验表明在两个基线上对音素错误率有了极大改进，也改进了该模型学习有用双语词汇入构项的能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;最佳资源论文：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;SQuAD: 100,000+ Questions for Machine Comprehension of Text&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8E4TjIhibUIREOamYfQmmEw2Hn3qa2hjJ3KSgR3C6SaLmT2Lfq5uibW9Qofuzfvh8XWUl3WZKHdrzQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：我们展现了斯坦福问答数据集（SQuAD），这是一个新的包含 10 万条问题的阅读理解数据集，由众包工作人员在一系列 Wikipedia 文章上提出，面向每个问题的答案是相应阅读文章的分割文本。我们分析了该数据集来理解回答这些问题所需的推理类型，及其依赖 dependency 和 constituency 树。我们建立了一个逻辑回归模型，取得了 51% 的 F1 得分，这是对基线成果（20%）的极大改进。然而，人类水平却更高（86.8%），表明该数据集展示了未来研究的一大挑战。数据集免费开放地址：&lt;/span&gt;&lt;a style="font-size: 14px; text-decoration: none;"&gt;&lt;span&gt;https://stanford-qa.com/。&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;第二部分：自然语言处理实际应用的神经网络&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;语言是离散的和结构化的，可以用序列、树、图来表示。神经网络以连续的向量表示，天生缺乏结构性。所以神经网络进行自然语言识别的最大的挑战是：如何在语言和神经网络不同结构间进行合理的转换。Chris Dyer、Yoav Goldberg 和 Graham Neubig 三位研究者在本届 EMNLP 上做一个题为《Practical Neural Networks for NLP》的 tutorial 演讲，其概括解释了在不抛弃普通算法的情况下如何使用神经网络进行自然语言识别的方法。同时，三人还展示了使用 DyNet 工具包在神经网络训练中的优势。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;该 tutorial 的幻灯片及相关代码地址：https://github.com/clab/dynet_tutorial_examples&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以下是对该 tutorial 的幻灯片内容框架的整理：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一部分大纲：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;计算图结构&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;DyNet 中的神经网络&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;循环神经网络&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Minibatching&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;加入新函数&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第二部分大纲&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;DyNet 的优势——动态结构网络&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;其他架构不擅长的领域。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8E4TjIhibUIREOamYfQmmEw9oHGhXIKjgZRyhiby8uUsDUQiclSmd8ZEMNJAJshibrscatJ2TtZ9icibYQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;神经网络与语言&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;语言是离散的和结构化的，可以用序列、树、图来表示&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;神经网络以连续的向量表示，天生缺乏结构性。所以神经网络进行自然语言识别的最大的挑战是如何在语言和神经网络不同结构间进行合理的转换。这篇讲义概括解释了在不抛弃普通算法的情况下如何使用神经网络进行自然语言识别。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8E4TjIhibUIREOamYfQmmEwkPUqicKhqYAas4zwic1YLy3FPXic38HdLwicGNdtveUrVu6juib7j77xOicg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8E4TjIhibUIREOamYfQmmEw3FtJMSgTZibSTB2ejsG2s4ymzWAamb4tu4s3Pt24b4K8Pxa8uyicmTww/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8E4TjIhibUIREOamYfQmmEwo6DD8PBT0ZwQLNWNn2RvCHVsGrDIpgiaZibicDoImH5QTZlhaia3tLdncA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;算法&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;图结构&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;前向传播&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以拓扑次序在节点中正向遍历，计算节点中的输入值，通过输入给出预测（或者计算出「错误」提出一个「输出目标」）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;反向传播&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;反拓扑次序在节点中逆向遍历，以找到最终目标节点并从该位置开始，计算最终目标节点的分支节点，并逐渐扩展至尾节点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8E4TjIhibUIREOamYfQmmEwa3dNI7oYAnT3GsYvzTHfXNo8EqHjYjLCEibicD4NicJxpEdv2nj2aB1Cw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;两种软件模型&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;静态声明：第一步定义架构（可以是基本流控制，如循环和条件）；第二步输入大量数据进行模型训练，给出预测&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;动态声明：在计算的进行过程中隐性定义图谱（如使用操作符重载）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8E4TjIhibUIREOamYfQmmEwQeEpOOXvqqcMHuZ594QwnNcic6IWJuRkvdXSgg1AOibW1edic87OpG8Mg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;DyNet 是一种通用自动微分（autodiff）库与深度学习工具的结合，兼具 AD 库的灵活性与深度学习的简洁。DyNet 的 C++后端基于 Eigen（TensorFlow 也基于 Eigen），提供自定义内存管理，在 Python 中有轻量的 C++API。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 03 Nov 2016 13:56:55 +0800</pubDate>
    </item>
    <item>
      <title>前沿 | 谷歌新型量子控制技术：向实用量子计算再进一步</title>
      <link>http://www.iwgc.cn/link/3347056</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自UCSB&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Sonia Fernandez&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：武竞、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你正在开发一台计算能力远远超越目前传统技术的量子计算机，那么你在做一项非常艰苦的工作。就是这么个情况：深入研究与全新复杂系统和尖端技术的基础工作相关的新问题和新情况。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这就是加州大学圣塔芭芭拉分校和谷歌联合的量子计算研究团队 Martinis Group 的科学家在探索令人兴奋的、但也有些违反直觉的量子计算世界时的生活。在他们发表于 Nature Physics 的一篇论文中，他们和位于新奥尔良的杜兰大学的同事展示了一个完整的相对简单的量子处理平台，这个平台可以同时控制 3 个超导量子比特（superconducting qubit）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8E4TjIhibUIREOamYfQmmEw8YvAYb7KRMPlIUjtzCIMkrNibXy9DEun3csPkgvJtzkZMheQJR56ODw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我们在探索我们能力的极限，」这篇论文的主要作者 Pedram Roushan 说。他解释说，对构建单个量子处理器，目前已经有相当多的研究，但是这个项目特别之处是把这些量子处理器集中在一个基本构建块（building block）中，这个基本构建块可以被完全控制并可能扩展到功能性量子计算机中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然而，在一台完全实用的量子计算机——兼具广泛、快速和同时计算的潜力——可以被制造出来之前，会出现各种以及有时是不可预测的和自发的情况，研究人员为了追求更精确的控制和设计更复杂的系统，这些情况必须被研究理解。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「你在处理粒子——在这里是量子比特——它们会发生相互作用，而且它们也会与外部场（external fields）互相作用，」Roushan 说，「这些都需要非常复杂的物理知识。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了解决这个特殊的多体问题（many-body problem），他解释说，他们的完全可控的量子处理系统必须从单个量子比特建立，以便让研究人员更好地了解可能发生的状态、行为和相互作用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过设计用于操纵其系统中光子自旋的脉冲序列，研究人员创建了一个人造磁场（artificial magnetic field），来影响由 3 个量子比特构成的闭环，使光子不仅能够与其它光子，而且能够与人造磁场间有强烈的相互作用。这是不小的进步。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「天然的，大多数能够比较精准控制的系统是光子系统，」合作者 Charles Neill 说。与电子不同，无电荷的光子通常不会彼此相互作用，也不会与外部磁场相互作用，他解释说。「在这篇论文中，我们展示了我们可以让光子之间有非常强烈的相互作用，并且也与磁场有非常强烈的相互作用——为了对光子进行有趣的物理操作，这两种作用是必需的。」Neill 说。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该合成凝聚态系统（synthetic condensed-matter system）的另一个优点是能够将其激发到其最低能量状态——称为基态——以探测其性质。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是控制越多，退相干（decoherence）的可能也越大。随着研究人员努力提高量子比特的可编程性以及对量子比特的干预和读取能力，他们的系统越开放就越可能导致错误和信息丢失。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我们对量子系统的控制越多，那我们能够运行的复杂算法也越多，」合作者 Anthony Megrant 说。「然而，每当我们添加一条控制线（control line），我们也同时引入了一个新的退相干来源。」在单个量子比特的水平上，我们可以容忍微小的误差，研究人员解释说，但是，一旦量子比特的数量增加，即使只增加相对很小的数量，误差也可能呈指数性增长。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「针对这些问题有一些校正方法，这些校正本质上是量子力学，它们会影响我们得到的精度水平，」Neill 说。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了在提高其控制水平的同时降低可能的错误，团队必须考虑该装置的电路结构和其中使用的材料。与传统的单层平面布局（single-level，planar layout）不同，这些研究人员重新设计的电路允许控制线通过自支撑的金属「桥（bridge）」「跨越（cross over）」其它控制线。因为发现介质——控制导线之间的绝缘材料——是错误的一个主要来源。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我们了解的所有沉积的电介质层（deposited dielectrics）都是非常容易损耗的，」Megrant 说，因此我们引入构造更精确且缺陷较少的介电衬底（substrate）以使退相干的可能性最小化。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;根据研究人员的说法，在探索量子系统可能性的道路上，他们的工作正在取得一点一点坚实的进步。加上它们被精心控制的速度，这对于他们真正想实现的可以操作的量子计算机来说是至关重要的。慢的速度可以降低控制误差，但会使系统更易受到材料所施加的相干限制（coherence limits）和缺陷的影响。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;快的速度可以避免材料中缺陷的影响，但也会降低操作者对系统的可控程度，他们说。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Roushan 说：「如果我们可以非常精确地控制这些系统——也许在大概 30 个量子比特的水平上——那么我们就可以进行传统计算机无法做到的计算了。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;论文：合成磁场中相互作用的光子的手性基态流（Chiral ground-state currents of interacting photons in a synthetic magnetic field）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8E4TjIhibUIREOamYfQmmEwtSE64CEeJUlrEMUgK2hTFfRib95lPgWjZ25Oqfia19p7Azq2ibgJMYZaA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：&lt;/span&gt;&lt;span&gt;令人着迷的量子物质的多体相（many-body phases）来自于粒子相互作用、空间对称性和外部场的相互作用。在一个工程系统中生成这些相可以提供对它们的本质的更深刻的见解。使用超导量子比特（superconducting qubit），我们可以在实现合成磁场（synthetic magnetic field）的同时实现强粒子相互作用（strong particle interactions），这是研究量子磁性（quantum magnetism）和分数量子霍尔效应（fractional quantum Hall phenomena）的基本要素之一。该人工磁场是通过正弦调制量子比特耦合（qubit couplings）来合成的。在一个由 3 个量子比特构成了闭环中，我们观察到了光子的定向循环（directional circulation），这标志着破碎的时间反演对称性（broken time-reversal symmetry）。我们的研究证明了通过按相反方向循环的光子空位（photon vacancies，或叫做「洞（hole）」）可以创造强烈的相互作用。这些关键元素的组合可以得到手性基态流（chiral ground-state currents）。这篇论文介绍了一种用于设计强相互作用光子的量子相的实验性平台。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;论文地址：&lt;/span&gt;&lt;span&gt;http://www.nature.com/nphys/journal/vaop/ncurrent/full/nphys3930.html&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 03 Nov 2016 13:56:55 +0800</pubDate>
    </item>
    <item>
      <title>学界 | OpenAI最新论文：神经GPU的扩展和限制</title>
      <link>http://www.iwgc.cn/link/3347057</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自arXiv.org&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote style="max-width: 100%; color: rgb(62, 62, 62); font-size: 16px; line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8E4TjIhibUIREOamYfQmmEwoGD32GibBU0M1NAwibgXuzVjMfG6KhhRVgTfg6Z3SVf2wC7NTMyN1oFg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;摘要&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;神经 GPU（Neural GPU）是最近一种用来学习多位二进制加法和二进制乘法等算法的模型，其可以泛化到任意长度的输入。我们的研究表明存在两种提升神经 GPU 的表现的简单方法：通过谨慎地设计 curriculum 和增加模型的大小。后一种方法需要需要细致的内存管理，因为神经 GPU 的 naive implementation 有密集的内存需求。我们发现这些用来增加算法问题集的技术可以通过神经 GPU 解决：我们可以在参数被以十进制的形式给出（让人惊讶的是，这在以前还不可能办到）时学习执行所有的算术运算（以及泛化到任意长的数字）。我们也可以训练该神经 GPU 来评估带有多个操作数的长算术表达式，这些操作数遵守操作数的优先顺序，尽管这些操作数在它们的仅二进制表示下取得过成功，但并没有达到 100% 的精度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除此之外，我们尝试通过理解其出错模式来获取关于神经 GPU 的深入见解。我们发现可以正确泛化到任意长数字的神经 GPU 仍然无法在高对称的、非典型的输入上计算出正确答案。比如说，一个神经 GPU 可以在长达 100 位的数字的十进制乘法上实现近乎完美的泛化，但它仍然无法计算 000000…002×000000…002（尽管它可以计算 2×2）。这些出错模式使人想起了对抗性样本（adversarial examples）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8E4TjIhibUIREOamYfQmmEwe4jJiagHKAjaKL36s9PbsZaRex94ctlEUZ8Bmva3zAWAnC1l4CJ109A/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 1：神经 GPU。红色表示共享的卷积过滤器（shared convolutional filters），绿色表示共享的卷积过滤器的不同集合。卷积被应用于可变长度的输入，而每一层的权重都被共享。这个架构对于可变长度的输入有固定数量的参数，并且能在其长度上执行二次计算（quadratic computation）。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;论文下载：https://arxiv.org/pdf/1611.00736v1.pdf&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 03 Nov 2016 13:56:55 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 彭博发布2016机器智能图谱：竞争进入白热化</title>
      <link>http://www.iwgc.cn/link/3347059</link>
      <description>&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自哈佛商业评论&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Shivon Zilis、James Cham&amp;nbsp;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;参与：杜夏德、李泽南&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;当地时间 10 月 27 日，Creative Destruction Lab 在多伦多举办了 2016 机器学习与智能市场（2016 Machine Learning and the Market for Intelligence）会议。会议云集了人工智能投资及科研界众多世界级明星。在机器之心报道（&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720220&amp;amp;idx=1&amp;amp;sn=8d0ad29c191f69c490af038ce760690d&amp;amp;chksm=871b03a2b06c8ab426b41e55b4e2d5d90a6312ea6c7cca3f477ddecdb17abb212d96944ce1b2&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720220&amp;amp;idx=1&amp;amp;sn=8d0ad29c191f69c490af038ce760690d&amp;amp;chksm=871b03a2b06c8ab426b41e55b4e2d5d90a6312ea6c7cca3f477ddecdb17abb212d96944ce1b2&amp;amp;scene=21#wechat_redirect"&gt;《独家 | Hinton、Bengio、Sutton 等巨头聚首多伦多：通过不同路径实现人工智能的下一个目标》&lt;/a&gt;）中，我们介绍了科研领域的大会内容。作为投资领域的代表，彭博社旗下基金 Bloomberg Beta 的合伙人 Shivon Zilis 和 James Cham 也在大会上宣布将发布机器智能报告的 3.0 版本（2.0 版本参见：&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=401467209&amp;amp;idx=3&amp;amp;sn=1dcdfb22e5f038f176cb87c6e2404e36&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=401467209&amp;amp;idx=3&amp;amp;sn=1dcdfb22e5f038f176cb87c6e2404e36&amp;amp;scene=21#wechat_redirect"&gt;业界 | 彭博社风投合伙人：2016 年机器智能 2.0 的新面貌&lt;/a&gt;）。这篇文章是 Shivon Zilis 和 James Cham 在哈佛商业评论发表的一篇文章，介绍了机器智能 3.0。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;三年前，我们的风险投资公司开始研究人工智能初创企业。科幻小说对人工智能的描述误导了大众对这项技术的看法。最近两年，我们一直在尝试寻找最重要的创业公司，汇集成一张概览图。（比起人工智能，我们更倾向于一个中性的词汇「机器智能」来描述这项技术。）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;过去几年中，我们总是从创业公司创始人和学界中关注这一领域较早的人那里听闻技术行业中的大趋势。但是今年不同，很多关于机器智能的话题都是出自《财富》世界 500 强公司高层之口。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些管理人员在不断自我反思：自己要做什么。在过去的一年中，机器智能爆发了，风险投资总额达到 50 亿美元，几宗大收购，数十万人阅读了我们早期的研究。上世纪九十年代的互联网，管理人员正在意识到这项新技术有可能改变一切，但是没人知道怎么改变以及何时改变。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8E4TjIhibUIREOamYfQmmEw8XGWE7lEPwAvhS37XlnbhH5UEkib3fLNyghxkYict8s4snOBdB1YdriaQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;高清PDF下载链接：https://hbr.org/resources/pdfs/hbr-articles/2016/11/the_state_of_machine_intelligence.pdf&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今年的这张的创业公司竞争概览图展示了机器智能眼下的影响力。从农业到交通运输，智能几乎触及到了所有领域。每一个员工都能通过现有的工具用上机器智能，提升工作效率。各大公司也第一次开始在他们的业务中配套配入机器智能技术。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;与互联网不同，即便是最早进入市场的大佬公司也常常被机器智能技术打的束手无策，只有那些能迅速引入机器智能技术的公司持续占有优势。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;世界 500 强和其他公司该从哪里找到切入点呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;让人才更有生产力&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一种能迅速获得机器智能价值的方法是为你的人才配备机器智能工具。使用该技术的最早的赢家们一直在根据知识工作的特定领域不断调试这些机器智能生产力工具。在我们的概览图中我们称之为「企业功能（Enterprise Functions）」。有了这些工具，每一名员工都能之前只有 CEO 们才有能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8E4TjIhibUIREOamYfQmmEw4Advs9A8HFOOzaFAQSuX6hElJJwG89FOOysiaibgEzxI1NzH7l1qZk1A/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些工具能够帮助监控和预测（比如，像Clari这样的公司一个一个地预测客户销售来帮助优化交易）也有助于指导和训练（Textio的预测文本编辑平台帮助员工提高写文档的效率）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;发现全新的数据来源&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下一步是使用机器智能实现新数据源的价值，也就是我们在概览图的「企业功能」部分强调的内容。机器智能软件能够快速查看海量的数据，因此也开辟了一些原来无法获取的数据资源。人工太贵，想象一下你能负担得起让某人听销售人员的每一条销售记录并据此预测他们的销售表现，或者让一个团队检查所有的卫星图像，决定需要收集哪个宏观经济指标的数据吗。而这些数据也许你的公司就有（例如，客户服务对话记录、传感器数据预测中断需要维护），或者这些数据可以从外部新的数据源中获取。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8E4TjIhibUIREOamYfQmmEwRvQobkdRyjVAYw0ibKrQ81EwCu0gUfwNKDSGLWyltkqkiba82EEzOdDA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;重新思考如何开发软件&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你已经尝试了一些新的生产力工具并开始挖掘新的数据源寻找洞见。实现机器智能价值的下一步是在新软件的基础上建立起持续的竞争优势。但是机器智能是一门管理者需要学习的新学科分支，需要一组新的软件人才和新的组织结构。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;大多数 IT 集团公司想到的都是应用和数据方面的人才。而新的机器智能 IT 公司会考虑应用、数据和模型，把软件看成是代码、数据和模型的结合。这里的「模型」指的是业务规则，就像批准贷款和调试数据中心功耗的规则一样。对于传统的软件，程序员需要手动开发这些规则。今天机器智能可以用数据和新的算法生成一个人类程序员无法做到的非常复杂的模型，&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;传统软件中的模型只能通过程序员手写代码来做出改变。有了机器智能后，公司就能开发出自己定期进化的模型，模型拥有了学习能力，公司的竞争力也就能维持下去。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;把这些传统的模型想成那些拥有海量记忆但不善社交的员工——白痴专家。他们可以预测如何让业务获得最佳增长，让客户更加满意，或者削减成本。但如果你试图将它们应用到新的东西，往往会失败，甚至更差。当你的业务和数据改变时，这些传统软件就更不上了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所有这些都意味着开发机器智能软件完全不同于传统的软件，因此公司需要进行相应的员工结构调整。幸运的是，虽然找到适合的人才很难，开发这些软件的工具已经有了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 03 Nov 2016 13:56:55 +0800</pubDate>
    </item>
    <item>
      <title>Quora问答 |《Python机器学习》作者Sebastian Raschka：从Python的学习经验到计算生物学的最前沿</title>
      <link>http://www.iwgc.cn/link/3331426</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Quora&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：杜夏德、李泽南、蒋思源、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;昨日机器之心编译的一篇文章（参见：&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720220&amp;amp;idx=3&amp;amp;sn=c3b8b65ec118d6fdef3f55e5f29e89ff&amp;amp;chksm=871b03a2b06c8ab4b0a0c87a3b3647372578b129ad5f420fddc5a1a84138a7db51911e143980&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720220&amp;amp;idx=3&amp;amp;sn=c3b8b65ec118d6fdef3f55e5f29e89ff&amp;amp;chksm=871b03a2b06c8ab4b0a0c87a3b3647372578b129ad5f420fddc5a1a84138a7db51911e143980&amp;amp;scene=21#wechat_redirect"&gt;业界 | 超越R，Python成为最受欢迎的机器学习语言&lt;/a&gt;）显示Python已经逐渐成为最受欢迎的机器学习语言。在今日的 Quora 专题上， 《Python机器学习》一书的作者 Sebastian Raschka 回答了有关 Python、机器学习、计算生物学方面的许多问题。让我们通过这个专题看看这个机器学习界的明星（他被列为Github中最有影响力的数据科学家之一）是如何完成从生物到计算机的传奇跨界经历的。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;1. 你用过什么让你工作效率提升的工具？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从较高的层面来说，我把「计算编程语言和算法」视为最重要的生产工具，它能处理所有类型的问题。然而，从软件应用层面来说，我喜欢 Atom Editor（我仍在使用 VIM 进行远程工作）。每天我都需要编写很多不同类型的文件：Python 脚本、.cpp 文件、HTML 文件、Markdown、.tex 、纯文本文件、蛋白质结构文件等等。Atom Editor 支持跨平台（macOS 和 Linux）并带有丰富的插件系统。自从有了 VIM 后，我逐渐习惯使用这个小工具了。当然，我的大部分数据分析工作都在 Jupyter Notebook 上做。我不会用 Jupyter 来「开发」代码，但是对我来说，它为我提供一个记录研究轨迹的环境，就像一本「笔记本」，把所有的事情都集中在一处：执行代码，不同的 notation 和 comment，inline plots，以及 LaTeX 等式，不仅节约了时间，在我回顾某个项目写报告赶 deadline 时，它还是我的救命武器，哈哈。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对了，差点忘了「git」（和 GitHub）和一个强大的笔记类应用程序 Quiver（只能在 Mac 上用）。笔记类应用太多了，但我只喜欢 Quiver，它能输出所有格式的数据，有了它你永远不会觉得你会陷入某个特定的程序或格式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;2. 对一个刚入行的、有点手忙脚乱的机器学习/数据科学家，你有什么建议？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我认为手上握有太多的可用资源既有好处又有坏处。好的是我们有很多可选的工具和信息资源，但是为了利用好时间充分使用它们，做好「选择」和保持「关注」才是真正重要的事情。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我不想说很多资源都是「冗余的」，因为「冗余」这个词用在这里有点负面。然而，市面上有很多看似不同的书、工具、教程，内容实际上都差不多，可能在范围和风格上有些差别。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以，不要想贪多，我们总是被长长的阅读清单拖后腿，更重要的是先想清楚个人的目标（「我需要学习那些技能来解决 X 问题？」「我真的要学这个流行的 X 工具而不是 Y 工具吗？」）。资料和工具太多了，我们需要更加精心地挑选。当然有时候我们会感觉是不是错过了什么，但是我觉得习惯这种感觉会帮你把注意力集中在某一件事情上，取得稳定的进步。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;例如，我认为「机器学习简介」的书一本就足够了，没必要每本都读，除非你真的感觉到内容不完整需要补充。就像 Cathy O'Neil 和 Rachel Schutt 解释的那样，没有「完美」的数据科学家，因为没有时间去学每样东西。每个人掌握属于自己的一套技能，擅长某一领域就可以了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我认为不知道所有的事情不一定是件坏事。因为（如下图所示）我们能通过团队合作来弥补各自的缺陷。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibNsuVzdAtufgY2lKIlMXzHTpnKodp1RkiaPtwibCfaCyYNLxrnSsSZHKkUUSCNNyI79nkuJ4jfySKw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;3.2016 年机器学习领域发生的哪件事让你最兴奋？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我对如何将解决特定问题的技术比如卷积神经网络和循环神经网络应用到除图像识别和神经语言处理外的其他问题上极度感兴趣。我认为现在这些技术应用上的一个关键挑战是找到合适的「表征」（除了有足够的 数据外）。这里有个例子（比较旧），&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Lusci, Alessandro, Gianluca Pollastri, 和 Pierre Baldi。「化学信息学中的深度架构和深度学习：药物类分子的水溶性预测」Journal of chemical information and modeling 53.7（2013）：1563-1575.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;研究者们用有向非循环图呈现分子（通常来说，结构是无向循环图）作为递归神经网络的输入，来预测这些分子的水溶性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最近的一个例子是：&lt;/span&gt;&lt;span&gt;Gómez-Bombarelli, Rafael 等人「使用数据驱动的连续分子表达进行自动化学设计（Automatic chemical design using a data-driven continuous representation of molecules）」arXiv：https://arxiv.org/abs/1610.02415&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;简而言之，研究者们训练了一个自动解码器来生成现实的、合成分子。这里，他们的神经网络将 SMILES 串转换成潜在的表达（经过压缩后仅包含统计上的显著信息的向量）并以最小的（或者没有）误差回到 SMILE 串。SMILE 串是一个分子的一维表达；例如，阿司匹林的 SMILES 串是 CC(=O)OC1=CC=CC=C1C(=O)O 对应的是下面的二维结构：&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibNsuVzdAtufgY2lKIlMXzHicf8UwpHYkOCOZHDdplwzh0RODU6HySH0m654XBPc6M7H9IRUwicRo0A/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;阿司匹林（2 -（乙酰氧基）苯甲酸）&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，这些年出现了很多非常棒的工具，从 scikit-learn 到 Theano、 TensorFlow 和 Keras，使得进入机器学习的门槛降低，这也让我很兴奋。这些工具带来的便利让我们不用太担心技术上的部署问题，还让我们集中关注我们想解决的实际问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;4. 你是如何在紧张的工作中挤出时间做那些小项目的？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个问题问的好，说实话，我没有什么秘密可以分享。我觉得这个问题就像是：人们总是说要控制体重，但最终问题还是会归结于每日的热量摄入与消耗。而且，每天只有 24 小时，没人可以延长这个数字。我认为挤出时间的秘诀是你需要对这些小项目感兴趣，这样我就会自然地减少其他业余活动的时间，如看比赛，读小说等等。当然，你的关注点也是很重要的。我觉得对大多数有趣的东西说「不」是其中的关键。我没有说我们必须全天无休止地工作，我想表达的是：如果你有一个绝妙的想法，你通常会挤出时间来实现它。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;5. 解决机器学习问题时最适用的数学是什么？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;统计、概率论、线性代数 和微积分。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;统计和概率论，因为首要任务之一通常是在区别生成模型之间选择一个，来定义性能指标，并评估结果。线性代数是机器学习部署中主要支柱之一，因为它让我们能持续高效地记录和部署。我想说微积分在纯机器学习应用中显得不太重要，但是如果你想理解我们使用或部署的算法，多元微积分和优化理论就显得非常重要，如果你想研究机器学习，那就更不必说了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;6. 我是一位生物物理学专业的学生，对 Python 在自然科学中的应用很感兴趣。对于初学者，你能推荐一本学习 Python 的最好的书吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不幸的是，在学习 Python 上，我个人没有什么推荐的书，因为我是通过 Codecademy 以及后面参加的一个大学课程（CS Programming I）学会 Python 的；与此同时，我还大概在 2011 年 12 月份学习了 Udacity 的「计算机科学入门」课程。所以我倒是愿意推荐 Codecadamy 和 Udacity 的计算机科学入门课程，它们都是很好的资源（而且就我所知它们是免费的）。推荐书的话，我觉得最受欢迎的两本书是《Hitchhiker's Guide to Python》和《Learn Python the Hard Way》。但是我个人从来没有读过这两本书，也就不能为它们做担保了——但这不是说它们并不够好 :)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外，我认为这还要看你在其它编程语言上的经验如何。如果你之前曾经使用过另一种动态语言（例如 Ruby 或甚至 R），那么我觉得你只需要读一下 Python Pocket Guide（甚至只需要网页文档）就可以很快掌握 Python 了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尽管我相信上面列出的所有资源都对入门很有帮助，但你应该通过应用这门语言来解决你领域内的问题的方式来自动地学习这门语言。或者换句话说，一旦你通过入门的门槛，你就可以快速地在网上找到相关的或更特定的概念实现（比如通过 StackOverflow）。另外，写代码的时候进行合作也是有帮助的，因为你可以通过阅读其他人的代码获得很多有用的想法，而且其他人也能为你的实现提供有用的指点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;参考：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;计算机科学入门：https://www.udacity.com/course/intro-to-computer-science--cs101&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Hitchhiker's Guide to Python：http://docs.python-guide.org/en/latest/&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Learn Python the Hard Way：https://learnpythonthehardway.org/&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;7. 在生物学和机器学习的尖端，最激动人心的问题是什么？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在计算生物学领域（computational biology），我们常常有丰富的无标签的数据（有标签的数据有时候可能会有些棘手，这要看具体的项目）。我认为主要的难题之一实际上是我们应该如何呈现数据以使之能够被机器学习算法处理（即：特征表征（feature representation））。现在我看到了很多有潜力的想法和方法；碰巧的是，我刚刚在上面还回答了这个问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;8. 我喜欢你的《Python Machine Learning》这本书，你有计划再写一本吗？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我很高兴听到你喜欢我的《Python Machine Learning》。是的，我正计划写另一本书！在 2015 年我上一本书之后，我在学术界度过了非常忙碌的一年，我在教书、写论文、参加会议……上花掉了大量的时间，而且在写作新书之前我还需要休息一下 :)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但长话短说：我正计划写一本关于模型评估（model evaluation）的书。我收到过关于这个主题的很多问题，而且其往往只在介绍性的书里面有一些简短的介绍。因此，我今年开始写作关于「机器学习中模型评估、模型选择和算法选择的博客」（http://sebastianraschka.com/blog/2016/model-evaluation-selection-part1.html），但关于它的更多内容我想在一本书（Model Evaluation and Selection in Machine Learning：https://leanpub.com/meval）中扩展——通过使用 Python/scikit-learn/Tensorflow 的说明性的和实用的代码例子来增强这些概念。（另外，我相当确定未来某天我还会写一本关于深度学习的书。）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;9. 我可以如何在 10 天之内学会机器学习？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;10 天？嗯，这绝对很有难度 :)。但是，我也认为 10 天是一个你需要用来很好地整体了解机器学习领域的时间框架，也许还能开始将一些技术应用到你的问题上了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在阅读了机器学习三个不同的子领域（监督学习、无监督学习和强化学习）的介绍之后。我可能会花时间了解一下这些领域内代表性的简单（但有用的）算法（可能要把强化学习放到后面一点）。比如：用于回归分析的简单线性回归和 Ridge 回归、用于分类的 logistic 回归和 k-最近邻、以及用于聚类任务的 k-均值聚类和分层聚类。一旦你了解了每种算法的目标和它们解决特定问题的方式，你就能轻松地为你的知识库增加更多算法和方法。但是除了算法之外，你还要清楚如何准备你的数据（特征选择、变换和压缩）以及如何评估你的模型。也许，作为初学者，你可以查看我们在 SciPy 2016 上的 scikit-learn 机器学习教程。它大概有 6 小时长，并总结了大部分基础，还介绍了 scikit-learn 库，这些库可被用于实现和进一步的学习。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;教程地址：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;https://www.youtube.com/watch?v=OB1reY6IX-o&amp;amp;feature=youtu.be&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;https://www.youtube.com/watch?v=Cte8FYCpylk&amp;amp;feature=youtu.be&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;10. 人工智能会颠覆设计行业吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当然，我肯定这么想。人工智能或机器学习已经在很多设计相关的领域得到了应用。从提升图像质量到 Stitch Fix 的个人造型（https://www.stitchfix.com/）和自动驾驶汽车。另一个将自动算法整合到设计里面的例子是 NASA 用在太空船上面的「进化天线（evolved antenna）」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibNsuVzdAtufgY2lKIlMXzHzhLbGTSMfxiad5S7xCW14plbibuIwLJWvZia07ic0WwDPwTFNzD9IR1KHA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能和机器学习可能并不会完全取代设计师，但我认为它将成为设计师的工作流程中「机械性的（mechanical）」部分中不可缺少的部分。或者换句话说，我认为这是一种增强而非完全的替代。但我预计「设计（design）」将随时间变得越来越好，因为特定的人工智能驱动的流程将能帮助缺乏人力或资源的公司或行业实现「好」的设计。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;11. 你如何鉴定机器学习是否对一个项目有用？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一步需要考虑这个项目的主要目的以及完成目标的需要那些步骤。一旦我确定了某个问题可以用一个预测模型（一个分类器或回归器）来处理，或一个聚类算法（clustering algorithm），我会问自己这些数据是否适用于这个任务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果这是一个监督学习任务，我能访问这些标签/目标变量吗？如果不能，我能不能从别的地方获取？是否有足够的可用样本？在一个机器学习算法中，我能不能以某种适当的格式（也许是表格）表达这些输入数据？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;还有，如果我有一个可以轻易可视化或手绘的简单的一维或二维数据，用机器学习处理可能会有点过。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;例如，我或许不会为预测分子重量拟合一个回归模型，因为它是输入的结构。举个例子，给定一个乙酰水杨酸分子，它的分子结构是：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibNsuVzdAtufgY2lKIlMXzHicf8UwpHYkOCOZHDdplwzh0RODU6HySH0m654XBPc6M7H9IRUwicRo0A/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们得到了包含 9 个碳原子、8 个氢原子和 4 个氧原子的化合物；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;C ~ 12 g/mol&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;H ~ 1 g/mol&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;O ~ 16 g/mol&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以我们可以轻松计算出它的重量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;思考一些我们想要解决的问题十分重要，无论我们是否能轻松手动推倒出规则或者，无是够需要机器学习。大体上说，机器学习就是把手动推倒规则和假设或逼近函数的工程自动化。另一个例子是 Joel Grus 写的： Fizz Buzz in Tensorflow（http://joelgrus.com/2016/05/23/fizz-buzz-in-tensorflow/）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;12. 从分子生物学学士到 Python 机器学习，你转行进入数据科学领域的想法是因何而起？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我得承认，在本科学分子生物的时候，我确实对其中的统计和数据分析最感兴趣，而不是那些「实际」的实验室工作，仅仅为了一篇老式的，无名的论文就花了我本科学习的大部分时间。顺便说一句，我在这篇论文中，用实验数据画结论中的图表用了一两天时间，做实验却用了一个多月。所以我不是那么地不喜欢分子生物学，但我很快发现潮湿的实验室不是我的归宿：我视它为：「必要的邪恶」——项目中繁琐的数据收集部分。希望我说完以后，实验室的同僚们不要对我发火，我很感谢他们的辛勤工作（笑）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然我的博士学位是纯计算机领域的，我觉得我对数据科学和机器学习的热情来源于我在研究生学习期间的统计识别课程。学习这些技术非常有意思，而且效果立竿见影，我很快就能在生物学问题上用到它们。那段时间，我得说我对于算法和技术有点过于感兴趣了，而生物学被放在了第二位。今天，我对通用领域解决问题的过程最感兴趣，而生物学恰好是一个有很多数据的学科，恰好有很多问题需要解决。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;13. 你认为机器学习和数据科学会对医疗领域产生什么样的影响？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我的工作并不涉及医疗领域，但是我遇到了几个在机器学习和医疗交叉领域工作的人。例如在我们学院的 Mias 实验室（G.Mias Lab）就专注于收集来自于各种在线数据库和数据源的基本数据，用以预测患上特定疾病的风险。《Why》的作者 Samantha Kleinberg 正在做着非凡的研究，她应用和开发了各种用于医疗行业的统计学建模技术。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;看看那些生物医学的文献，我觉得描述特定蛋白质或基因的功能的经典方法是孤立地看待它们，然后分类至特定的表型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这种自下而上的方法当然也是医疗领域中的关键。然而，基因或蛋白质其实只是更大，更复杂系统中的一小部分。我相信汇集实验和设备的信息能对我们理解这个复杂系统提供有用的信息，并且能使医疗进步。特别是，我希望监测随着时间推移不同风险因素的变化。&lt;/span&gt;&lt;span&gt;如果这能够被高效地完成，那么我相信医疗界将会因此受益。我想说的是我们的目标是尽早获知健康隐患，最好是在这些隐患成为真正的问题之前。比如在一个人真正地患了糖尿病之前跟踪那些有患糖尿病风险的因素。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;发展更好的糖尿病治疗方法是很重要的，但是如果我们更好地理解哪种外界环境的组合会提高患糖尿病的风险，我们就能帮助许多人避免患上这种疾病。我认为不需要在这方面做任何研究，只需要整合如家庭历史、基因表达水平、年龄、购物行为、锻炼等信息就能帮助我们尽早发现患病的风险。我们收集越来越多的数据在一定程度上可以是以匿名形式研究的，因为这样才可以更容易地把它加入到机器学习算法中来建立一个预测模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然而，主要的挑战就是这些数据是高度异质，原始的，并且结合不同的数据库也是也是一个瓶颈，当然，出于隐私方面的担忧——数据是匿名的，这种方式很难链接不同的数据集。然而，苹果等公司正在研究如智能手机这类电子设备上的匿名追踪数据的解决方案。现如今，我认为找到一个将个人资料通过匿名方式提供给研究者的可行方法是建立一个更好的健康问题检测系统的第一步。我相信一旦解决这个问题，我们就为个人预警系统铺平了道路，这个系统是结合数据, 如购物行为, 日常锻炼和饮食信息, 也许个人基因组和偶尔的血液测试。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;14. 你在计算生物学中参与过哪些有趣的项目？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我的大多数其他项目都专注于虚拟筛选的应用：我们一直与实验生物学的实验室合作，开发和使用各种方式，在不存在或存在蛋白质晶体结构的情况下预测单独抑制的（或活性的，取决于哪个项目）候选分子。最有趣的地方是预测与反馈之间的关系：我需要预测（在某些时候），得到实验结果，然后再看看我的尝试对不对，分析我的方式为什么比其他方式更好。这些项目的另外一个挑战在于研究者需要让所有算法在计算上可行——如果你有 1500 万个分子，想在其中选取 100 个候选分子有点像在大海捞针。通常在这种情况下我们会预先进行「过滤」步骤让计算变得简单一些，因为研究总是有时间限制的。我的项目需要所有人充分发挥自己的创造力和技术，但最终，我们的研究成果也需要对合作方产生价值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除了虚拟筛选的应用（其中的一些已经完成了，我现在正在撰写论文，同时准备发布工具包），我同时正在参与蛋白质——配体相互作用等一般概念的研究，我们最近发现了一个蛋白质——配体相互作用的有趣现象，我们正在寻找数据点以确认它不是一个特例。今年夏天刚刚结束的一个项目则有关计算蛋白质——配体结合袋的局部刚性，用以预测近天然蛋白质——配体的结合模式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我觉得这是一个有趣的想法，因为近天然捆绑模式通常需要通过不同的能量项求和来进行预测。使用刚性理论，计算结构中的自由度更多是关于相互作用的协同性，而不是它们的相加和。换句话说，如果特定的非共价相互作用不从复合体中去除额外的自由度（如果复合体已经是刚性的），则其不被「计数」到相互作用分数。在实践中，使用局部刚性蛋白质——配体符合体似乎比其他方式或基于知识的评分方式一样好。而且，除了除了作为「独立」评分函数之外，我认为它是一个有趣的新的「信号」或「特征」，可以用于整体评分。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;15. 使用 Octave 作为机器学习语言到底有多高效？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我认为 Octave 是一种原型设计的高效环境，同时它也是（和 MATLAB 一起）计算机科学（学术领域）中的流行语言。我在很多地方必须使用它，而且我得说它确实是在机器学习上的好选择。但是，看起来现实世界中不趋向于使用 Octave/MATLAB，我得说像 Python 这样的语言也很容易学习——而且功能更多一点（但请注意这是我的个人喜好）。简而言之：如果你的研究需要大量使用，或者你的实验室/团队已经再用了，Octave 是一个不错的选择，否则我会考虑 Python 和 R 语言。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你有兴趣，可以看我去年写的一篇关于「语言战争」的文章：http://sebastianraschka.com/blog/2015/why-python.html&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;16. 对于有一些机器学习知识的程序员来说，学习计算生物学有什么好的方法？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是一个好问题！计算生物学是一个广阔的领域，有很多不同的子领域和方向可以研究：蛋白质折叠，同源性蛋白质建模，蛋白质配体对接和评分、分子动力学模拟、序列比对、基因组装配、微生物组研究、进化生物学和系统发育等等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;生物学的入门可以从分子生物学和基因开始，首先了解「大局」，然后再开始进入你所感兴趣的分区。关于生物计算方面的学习，我主要通过阅读论文——这一领域的变化很快，一本十年前的教科书可能已经过时了。我听说 Edx 和 Coursera 这样的网站已经在提供计算生物学和生物信息学的专门课程了，我没有接触过这些课程，但我觉得这也是不错的入门方式。有一个内容我想要特别分享一下，Greg Caporaso 的「应用生物信息学概论（Introduction to Applied Bioinformatics：http://readiab.org/）」，一本免费的在线图书。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;17. 你对数据科学的初学者有什么好建议？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我的建议是选择你个人感兴趣的问题或项目，而不是从复制一个问题的解决方案入手。如果你对一个问题感兴趣，自然会急于去解决它，并在此过程中开发新的工具和技术。首先，你需要以你能够熟练使用的技术和工具入手，看看能做到什么程度。如果使用现有的工具包不能够解决问题，我会尝试在线搜索类似问题的解决方案，或者问问别人。举个例子，如果你对某种预测感兴趣，在一开始你会将键值对储存在 Python 字典中。随着你的数据集不断增长，你可能会开始需要其他的存储方式，如 SQLite，然后你会开始学习 SQLite。同样的，假如你会使用 NumPy 数组处理很多问题，在收集异构数据时，你可能会转而寻求 Pandas 来处理；如果你的系统内存有限，你会尝试使用其他工具，例如 Blaze。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我建议的方法是你需要学习使用你认为可以解决问题的工具，假如合适就使用它们。第二步是看看你目前工具的潜在替代者，看看它们有什么额外的功能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我发现为了学习工具而学习工具很快就会变得无聊，所以我的方式是在实践中学习工具。如果方向正确，你自然会花时间来学习新的工具。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;18. 您怎么找到时间来掌握机器学习，获得另一个博士学位，并且还对这个学科出了本书的？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我认为计算生物学和机器学习在解决问题的时候是有很大的相似之处的。在计算生物学中，我们通常通过各种数据挖掘来解决计算问题，机器学习中，数据挖掘也占大头。我一直很喜欢统计学，在研究生的阶段我就上过一门「类统计模式识别」，我真的认为这门课点燃了我对预测建模还有机器学习的热情。最开始的时候，我感到「哇，这真是太不可思议了，它帮我解决了计算生物学各种各样的问题」，后来，我真是感觉到「哇，机器学习是那么重要，他几乎能帮我解决所有问题，我要学到更多。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在课程中，我发展出了对机器学习真正的热情，这使我有动力在晚上花一些额外的时间去努力钻研。说实话，有很多机器学习的方面我都没有深入研究，还有很多文件资料我都没有来得及读。然而当我被要求写本书的时候，我发现先前的研究正好与此有关。虽然我在每个周末晚上花上几个小时来写书，我的社交生活在这几个月里也遭受些磨难，但是这也是我激情的来源：我十分高兴能够分享那些使我兴奋的的知识，这也使整个写书的过程变得充满了乐趣。所以，我认为抓紧所有时间在已经足够疯狂的博士期间写一本书是一个很棒的体验（因为他直接有助于解决计算生物学的问题），所以我也愿意花费一些我的「空闲」时间。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;19. 我能在哪找到可以用来学习的 Python 机器学习项目？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我的建议是关注一些数据科学的博客，因为有很多人的博客都在分享他们所爱好的 Python 机器学习方面的东西。现在这边有一个较为全面的数据科学家博客列表，不过这并不是全都关于机器学习的，所以你得做一些手动搜索：rushter/data-science-blogs 你也可以看看 Kaggle（https://www.kaggle.com/）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;例如：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;「通过 100 万条酒店评论发现一些有趣的见解」：https://blog.monkeylearn.com/machine-learning-1m-hotel-reviews-finds-interesting-insights/&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;在 Python 中的机器学习训练，第一部分：http://www.johnwittenauer.net/machine-learning-exercises-in-python-part-1/&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不幸的是，他的博客似乎不常更新了（或者有了个新的站点），但还是可以看看通过了 Kaggle 比赛的解决方案（http://www.chioka.in/kaggle-competition-solutions/）。同样的，我也认为 Kaggle 比赛和论坛是学习的良好平台。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 02 Nov 2016 14:58:26 +0800</pubDate>
    </item>
  </channel>
</rss>
