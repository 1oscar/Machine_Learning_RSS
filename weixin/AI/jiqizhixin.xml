<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>机器之心</title>
    <link>http://www.iwgc.cn/list/670</link>
    <description>人与科技的美好关系</description>
    <item>
      <title>深度 | 自然语言处理顶级会议EMNLP 2016干货：从原理到代码全面剖析可用于NLP的神经网络（附获奖论文）</title>
      <link>http://www.iwgc.cn/link/3347055</link>
      <description>&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自EMNLP&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编辑整理&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：杜夏德、李泽南、李亚洲、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;今年的自然语言处理实证方法会议（EMNLP 2016）正在（11 月 1 日-5 日）美国德克萨斯奥斯汀市举行。作为自然语言处理领域的顶级大会，EMNLP 一直以来都在为自然语言处理的发展提供强大的助力。在此文中，机器之心整理了大会的最佳论文、荣誉论文、最佳短篇论文和最佳资源论文。此外，还把 Chris Dyer 等三人在大会上做的一个 tutorial 演讲《Practical Neural Networks for NLP》作为资源分享给大家，该 tutorial 较为全面地覆盖了用于自然语言处理的神经网络的基础，是自然语言处理入门的必备良品。机器之心还整理了相关论文和幻灯片，读者也可点击文末「阅读原文」下载。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;第一部分：获奖论文&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本届 EMNLP 一共选出了 6 篇获奖论文，包括 2 篇最佳论文、2 篇荣誉论文、1 篇最佳短篇论文和 1 篇最佳资源论文。下面是对这 6 篇论文的摘要介绍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;最佳论文&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1.Improving Information Extraction by Acquiring External Evidence with Reinforcement Learning&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8E4TjIhibUIREOamYfQmmEwcvDW8ia8RicI6WKnKKichTicKaQ9RqFNfKsxJkbIQaNb91FgekYOwYcYZA/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：大部分成功的信息提取系统运行时都接入一个大型的文件集。在这个研究中，我们探索了获取并结合外部证据的任务，以在训练数据量稀缺的领域中提高提取的精确度，这个过程需要重复发布搜索查询，从新的来源中提取以及使提取值一致，直到收集到足够的证据。我们使用强化学习框架来解决这个问题，在此框架中，我们的模型可以学习基于上下文来选择最优行动。我们应用了一个深度 Q-network，训练它来优化能反应提取精度同时还能惩罚多余工作的奖励函数。我们的试验用到了两个数据库——枪击事件数据和食品掺假情况数据——证明了我们的系统明显优于传统的提取器和一个元分类基准。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2.Global Neural CCG Parsing with Optimality Guarantees&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8E4TjIhibUIREOamYfQmmEwu7crLh2H8pv6S8ibrEH141fBWgX3AJBzOiamKMY8WbHgCxGOp6iaM6B6A/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：我们介绍了第一种全局递归神经解析模型，它是实时解码的最佳保证。为了支持全局特性，我们放弃了动态程序，用直接在所有可能子树中搜索的方式代替。尽管这样会导致句长指数性地增长，我们展示了达到学习效率 A 解析器的可能性。我们增大了已知解析模型，它存在外界评分的信息界限，通过一个宽松界限并只需非局性现象建模的全局模型。全局模型因此在新的目标下进行训练，这可以鼓励解析器更精确有效地进行搜索。这种方式适用于 CCG 解析，通过 0.4F1 获得了可观的精确性提升。解析器可为 99.9% 的停止句（held-out sentence）找到最佳解析，仅需搜索平均 190 个子树。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;最佳论文荣誉提名：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1.Span-Based Constituency Parsing with a Structure-Label System and Provably Optimal Dynamic Oracles&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8E4TjIhibUIREOamYfQmmEwT7AsCDUPibnZ9Y42mdPjPJZOBcZF0PIMVBRs42baEWt6Lv1JK7NH1HQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：由于神经网络的出现，使用有效的转换系统的解析精确度已得到巨大提升。尽管依存关系语法分析的结果惊人，神经模型还没有超过 constituency 分析中的最佳方法。为了弥补这个缺陷，我们引进了一个新的位移减少系统，该系统的堆栈只包含了句子跨度，通过最低限度的长短期记忆网络特征来表征。我们还为 constituency 分析方法设计出首个可查验的最优的 dynamic oracle，相比于进行依存分析的 O(n3)oracles，它在 amortized O(1)time 内运行。在此 Oracle 上训练，我们在英语和法语中任何不适用 reranking 和外部数据的解析器上，都取得了最好的 F1 得分。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2.Sequence-to-Sequence Learning as Beam-Search Optimization&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8E4TjIhibUIREOamYfQmmEwuwMlewDUX6I0icl5oRrBRGg8ZicHZqGaEepAibSfSSgPOwOjjsJNzicmOA/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：Sequence-to-Sequence（seq2seq）建模已经成为了一种重要的多用途自然语言处理工具，它已被证明在很多文本生成和排序任务中被证明有效。Seq2seq 建立在深度神经语言建模之上，并在局部的下一个词分布的估计中延续了其良好的精确度。在本研究中，我们介绍了一种模型和训练方式，基于 Daum'e III 和 Marcu（2005）的成果，同时扩展了 seq2seq 方式，使它可以学习全局序列分数。这种结构方式在证明了已有 seq2seq 模型架构能够进行有效训练的情况下，避免了传统方式上局部训练（local training）的常见偏差，同时通过测试使用时间使训练损失一致。我们发现与高度优化的基于注意的 seq2seq 系统以及其他系统相比，在三种不同的 sequence to sequence 任务中（词序，解析和机器翻译），我们的系统存在明显优势。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;最佳短篇论文：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Learning a Lexicon and Translation Model from Phoneme Lattices&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8E4TjIhibUIREOamYfQmmEwicLdV0Lmwxr7Vib010FFgqLkBT7ZcAelziazb7Bzad5PBUTt7qMl2xdZA/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：语言文件始于对语音的收集。在词上的手动或自动转录几乎不可能实现，因为缺乏正字法（orthography）或先前词汇，而且尽管手动音素转录是可能的，却相当的慢。此外，将小语种转译为主要语言更容易掌握。我们提出一种方法能掌握这样的翻译技能，从而改进自动音素识别。该方法假设没有先前词汇或翻译模型，而是从音素网格和被转录的语音翻译中进行学习。实验表明在两个基线上对音素错误率有了极大改进，也改进了该模型学习有用双语词汇入构项的能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;最佳资源论文：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;SQuAD: 100,000+ Questions for Machine Comprehension of Text&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8E4TjIhibUIREOamYfQmmEw2Hn3qa2hjJ3KSgR3C6SaLmT2Lfq5uibW9Qofuzfvh8XWUl3WZKHdrzQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：我们展现了斯坦福问答数据集（SQuAD），这是一个新的包含 10 万条问题的阅读理解数据集，由众包工作人员在一系列 Wikipedia 文章上提出，面向每个问题的答案是相应阅读文章的分割文本。我们分析了该数据集来理解回答这些问题所需的推理类型，及其依赖 dependency 和 constituency 树。我们建立了一个逻辑回归模型，取得了 51% 的 F1 得分，这是对基线成果（20%）的极大改进。然而，人类水平却更高（86.8%），表明该数据集展示了未来研究的一大挑战。数据集免费开放地址：&lt;/span&gt;&lt;a style="font-size: 14px; text-decoration: none;"&gt;&lt;span&gt;https://stanford-qa.com/。&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;第二部分：自然语言处理实际应用的神经网络&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;语言是离散的和结构化的，可以用序列、树、图来表示。神经网络以连续的向量表示，天生缺乏结构性。所以神经网络进行自然语言识别的最大的挑战是：如何在语言和神经网络不同结构间进行合理的转换。Chris Dyer、Yoav Goldberg 和 Graham Neubig 三位研究者在本届 EMNLP 上做一个题为《Practical Neural Networks for NLP》的 tutorial 演讲，其概括解释了在不抛弃普通算法的情况下如何使用神经网络进行自然语言识别的方法。同时，三人还展示了使用 DyNet 工具包在神经网络训练中的优势。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;该 tutorial 的幻灯片及相关代码地址：https://github.com/clab/dynet_tutorial_examples&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以下是对该 tutorial 的幻灯片内容框架的整理：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一部分大纲：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;计算图结构&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;DyNet 中的神经网络&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;循环神经网络&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Minibatching&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;加入新函数&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第二部分大纲&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;DyNet 的优势——动态结构网络&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;其他架构不擅长的领域。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8E4TjIhibUIREOamYfQmmEw9oHGhXIKjgZRyhiby8uUsDUQiclSmd8ZEMNJAJshibrscatJ2TtZ9icibYQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;神经网络与语言&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;语言是离散的和结构化的，可以用序列、树、图来表示&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;神经网络以连续的向量表示，天生缺乏结构性。所以神经网络进行自然语言识别的最大的挑战是如何在语言和神经网络不同结构间进行合理的转换。这篇讲义概括解释了在不抛弃普通算法的情况下如何使用神经网络进行自然语言识别。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8E4TjIhibUIREOamYfQmmEwkPUqicKhqYAas4zwic1YLy3FPXic38HdLwicGNdtveUrVu6juib7j77xOicg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8E4TjIhibUIREOamYfQmmEw3FtJMSgTZibSTB2ejsG2s4ymzWAamb4tu4s3Pt24b4K8Pxa8uyicmTww/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8E4TjIhibUIREOamYfQmmEwo6DD8PBT0ZwQLNWNn2RvCHVsGrDIpgiaZibicDoImH5QTZlhaia3tLdncA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;算法&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;图结构&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;前向传播&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以拓扑次序在节点中正向遍历，计算节点中的输入值，通过输入给出预测（或者计算出「错误」提出一个「输出目标」）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;反向传播&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;反拓扑次序在节点中逆向遍历，以找到最终目标节点并从该位置开始，计算最终目标节点的分支节点，并逐渐扩展至尾节点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8E4TjIhibUIREOamYfQmmEwa3dNI7oYAnT3GsYvzTHfXNo8EqHjYjLCEibicD4NicJxpEdv2nj2aB1Cw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;两种软件模型&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;静态声明：第一步定义架构（可以是基本流控制，如循环和条件）；第二步输入大量数据进行模型训练，给出预测&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;动态声明：在计算的进行过程中隐性定义图谱（如使用操作符重载）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8E4TjIhibUIREOamYfQmmEwQeEpOOXvqqcMHuZ594QwnNcic6IWJuRkvdXSgg1AOibW1edic87OpG8Mg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;DyNet 是一种通用自动微分（autodiff）库与深度学习工具的结合，兼具 AD 库的灵活性与深度学习的简洁。DyNet 的 C++后端基于 Eigen（TensorFlow 也基于 Eigen），提供自定义内存管理，在 Python 中有轻量的 C++API。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 03 Nov 2016 13:56:55 +0800</pubDate>
    </item>
    <item>
      <title>前沿 | 谷歌新型量子控制技术：向实用量子计算再进一步</title>
      <link>http://www.iwgc.cn/link/3347056</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自UCSB&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Sonia Fernandez&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：武竞、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你正在开发一台计算能力远远超越目前传统技术的量子计算机，那么你在做一项非常艰苦的工作。就是这么个情况：深入研究与全新复杂系统和尖端技术的基础工作相关的新问题和新情况。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这就是加州大学圣塔芭芭拉分校和谷歌联合的量子计算研究团队 Martinis Group 的科学家在探索令人兴奋的、但也有些违反直觉的量子计算世界时的生活。在他们发表于 Nature Physics 的一篇论文中，他们和位于新奥尔良的杜兰大学的同事展示了一个完整的相对简单的量子处理平台，这个平台可以同时控制 3 个超导量子比特（superconducting qubit）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8E4TjIhibUIREOamYfQmmEw8YvAYb7KRMPlIUjtzCIMkrNibXy9DEun3csPkgvJtzkZMheQJR56ODw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我们在探索我们能力的极限，」这篇论文的主要作者 Pedram Roushan 说。他解释说，对构建单个量子处理器，目前已经有相当多的研究，但是这个项目特别之处是把这些量子处理器集中在一个基本构建块（building block）中，这个基本构建块可以被完全控制并可能扩展到功能性量子计算机中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然而，在一台完全实用的量子计算机——兼具广泛、快速和同时计算的潜力——可以被制造出来之前，会出现各种以及有时是不可预测的和自发的情况，研究人员为了追求更精确的控制和设计更复杂的系统，这些情况必须被研究理解。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「你在处理粒子——在这里是量子比特——它们会发生相互作用，而且它们也会与外部场（external fields）互相作用，」Roushan 说，「这些都需要非常复杂的物理知识。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了解决这个特殊的多体问题（many-body problem），他解释说，他们的完全可控的量子处理系统必须从单个量子比特建立，以便让研究人员更好地了解可能发生的状态、行为和相互作用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过设计用于操纵其系统中光子自旋的脉冲序列，研究人员创建了一个人造磁场（artificial magnetic field），来影响由 3 个量子比特构成的闭环，使光子不仅能够与其它光子，而且能够与人造磁场间有强烈的相互作用。这是不小的进步。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「天然的，大多数能够比较精准控制的系统是光子系统，」合作者 Charles Neill 说。与电子不同，无电荷的光子通常不会彼此相互作用，也不会与外部磁场相互作用，他解释说。「在这篇论文中，我们展示了我们可以让光子之间有非常强烈的相互作用，并且也与磁场有非常强烈的相互作用——为了对光子进行有趣的物理操作，这两种作用是必需的。」Neill 说。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该合成凝聚态系统（synthetic condensed-matter system）的另一个优点是能够将其激发到其最低能量状态——称为基态——以探测其性质。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是控制越多，退相干（decoherence）的可能也越大。随着研究人员努力提高量子比特的可编程性以及对量子比特的干预和读取能力，他们的系统越开放就越可能导致错误和信息丢失。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我们对量子系统的控制越多，那我们能够运行的复杂算法也越多，」合作者 Anthony Megrant 说。「然而，每当我们添加一条控制线（control line），我们也同时引入了一个新的退相干来源。」在单个量子比特的水平上，我们可以容忍微小的误差，研究人员解释说，但是，一旦量子比特的数量增加，即使只增加相对很小的数量，误差也可能呈指数性增长。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「针对这些问题有一些校正方法，这些校正本质上是量子力学，它们会影响我们得到的精度水平，」Neill 说。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了在提高其控制水平的同时降低可能的错误，团队必须考虑该装置的电路结构和其中使用的材料。与传统的单层平面布局（single-level，planar layout）不同，这些研究人员重新设计的电路允许控制线通过自支撑的金属「桥（bridge）」「跨越（cross over）」其它控制线。因为发现介质——控制导线之间的绝缘材料——是错误的一个主要来源。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我们了解的所有沉积的电介质层（deposited dielectrics）都是非常容易损耗的，」Megrant 说，因此我们引入构造更精确且缺陷较少的介电衬底（substrate）以使退相干的可能性最小化。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;根据研究人员的说法，在探索量子系统可能性的道路上，他们的工作正在取得一点一点坚实的进步。加上它们被精心控制的速度，这对于他们真正想实现的可以操作的量子计算机来说是至关重要的。慢的速度可以降低控制误差，但会使系统更易受到材料所施加的相干限制（coherence limits）和缺陷的影响。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;快的速度可以避免材料中缺陷的影响，但也会降低操作者对系统的可控程度，他们说。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Roushan 说：「如果我们可以非常精确地控制这些系统——也许在大概 30 个量子比特的水平上——那么我们就可以进行传统计算机无法做到的计算了。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;论文：合成磁场中相互作用的光子的手性基态流（Chiral ground-state currents of interacting photons in a synthetic magnetic field）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8E4TjIhibUIREOamYfQmmEwtSE64CEeJUlrEMUgK2hTFfRib95lPgWjZ25Oqfia19p7Azq2ibgJMYZaA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：&lt;/span&gt;&lt;span&gt;令人着迷的量子物质的多体相（many-body phases）来自于粒子相互作用、空间对称性和外部场的相互作用。在一个工程系统中生成这些相可以提供对它们的本质的更深刻的见解。使用超导量子比特（superconducting qubit），我们可以在实现合成磁场（synthetic magnetic field）的同时实现强粒子相互作用（strong particle interactions），这是研究量子磁性（quantum magnetism）和分数量子霍尔效应（fractional quantum Hall phenomena）的基本要素之一。该人工磁场是通过正弦调制量子比特耦合（qubit couplings）来合成的。在一个由 3 个量子比特构成了闭环中，我们观察到了光子的定向循环（directional circulation），这标志着破碎的时间反演对称性（broken time-reversal symmetry）。我们的研究证明了通过按相反方向循环的光子空位（photon vacancies，或叫做「洞（hole）」）可以创造强烈的相互作用。这些关键元素的组合可以得到手性基态流（chiral ground-state currents）。这篇论文介绍了一种用于设计强相互作用光子的量子相的实验性平台。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;论文地址：&lt;/span&gt;&lt;span&gt;http://www.nature.com/nphys/journal/vaop/ncurrent/full/nphys3930.html&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 03 Nov 2016 13:56:55 +0800</pubDate>
    </item>
    <item>
      <title>学界 | OpenAI最新论文：神经GPU的扩展和限制</title>
      <link>http://www.iwgc.cn/link/3347057</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自arXiv.org&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote style="max-width: 100%; color: rgb(62, 62, 62); font-size: 16px; line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8E4TjIhibUIREOamYfQmmEwoGD32GibBU0M1NAwibgXuzVjMfG6KhhRVgTfg6Z3SVf2wC7NTMyN1oFg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;摘要&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;神经 GPU（Neural GPU）是最近一种用来学习多位二进制加法和二进制乘法等算法的模型，其可以泛化到任意长度的输入。我们的研究表明存在两种提升神经 GPU 的表现的简单方法：通过谨慎地设计 curriculum 和增加模型的大小。后一种方法需要需要细致的内存管理，因为神经 GPU 的 naive implementation 有密集的内存需求。我们发现这些用来增加算法问题集的技术可以通过神经 GPU 解决：我们可以在参数被以十进制的形式给出（让人惊讶的是，这在以前还不可能办到）时学习执行所有的算术运算（以及泛化到任意长的数字）。我们也可以训练该神经 GPU 来评估带有多个操作数的长算术表达式，这些操作数遵守操作数的优先顺序，尽管这些操作数在它们的仅二进制表示下取得过成功，但并没有达到 100% 的精度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除此之外，我们尝试通过理解其出错模式来获取关于神经 GPU 的深入见解。我们发现可以正确泛化到任意长数字的神经 GPU 仍然无法在高对称的、非典型的输入上计算出正确答案。比如说，一个神经 GPU 可以在长达 100 位的数字的十进制乘法上实现近乎完美的泛化，但它仍然无法计算 000000…002×000000…002（尽管它可以计算 2×2）。这些出错模式使人想起了对抗性样本（adversarial examples）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8E4TjIhibUIREOamYfQmmEwe4jJiagHKAjaKL36s9PbsZaRex94ctlEUZ8Bmva3zAWAnC1l4CJ109A/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 1：神经 GPU。红色表示共享的卷积过滤器（shared convolutional filters），绿色表示共享的卷积过滤器的不同集合。卷积被应用于可变长度的输入，而每一层的权重都被共享。这个架构对于可变长度的输入有固定数量的参数，并且能在其长度上执行二次计算（quadratic computation）。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;论文下载：https://arxiv.org/pdf/1611.00736v1.pdf&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 03 Nov 2016 13:56:55 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 彭博发布2016机器智能图谱：竞争进入白热化</title>
      <link>http://www.iwgc.cn/link/3347059</link>
      <description>&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自哈佛商业评论&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Shivon Zilis、James Cham&amp;nbsp;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;参与：杜夏德、李泽南&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;当地时间 10 月 27 日，Creative Destruction Lab 在多伦多举办了 2016 机器学习与智能市场（2016 Machine Learning and the Market for Intelligence）会议。会议云集了人工智能投资及科研界众多世界级明星。在机器之心报道（&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720220&amp;amp;idx=1&amp;amp;sn=8d0ad29c191f69c490af038ce760690d&amp;amp;chksm=871b03a2b06c8ab426b41e55b4e2d5d90a6312ea6c7cca3f477ddecdb17abb212d96944ce1b2&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720220&amp;amp;idx=1&amp;amp;sn=8d0ad29c191f69c490af038ce760690d&amp;amp;chksm=871b03a2b06c8ab426b41e55b4e2d5d90a6312ea6c7cca3f477ddecdb17abb212d96944ce1b2&amp;amp;scene=21#wechat_redirect"&gt;《独家 | Hinton、Bengio、Sutton 等巨头聚首多伦多：通过不同路径实现人工智能的下一个目标》&lt;/a&gt;）中，我们介绍了科研领域的大会内容。作为投资领域的代表，彭博社旗下基金 Bloomberg Beta 的合伙人 Shivon Zilis 和 James Cham 也在大会上宣布将发布机器智能报告的 3.0 版本（2.0 版本参见：&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=401467209&amp;amp;idx=3&amp;amp;sn=1dcdfb22e5f038f176cb87c6e2404e36&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=401467209&amp;amp;idx=3&amp;amp;sn=1dcdfb22e5f038f176cb87c6e2404e36&amp;amp;scene=21#wechat_redirect"&gt;业界 | 彭博社风投合伙人：2016 年机器智能 2.0 的新面貌&lt;/a&gt;）。这篇文章是 Shivon Zilis 和 James Cham 在哈佛商业评论发表的一篇文章，介绍了机器智能 3.0。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;三年前，我们的风险投资公司开始研究人工智能初创企业。科幻小说对人工智能的描述误导了大众对这项技术的看法。最近两年，我们一直在尝试寻找最重要的创业公司，汇集成一张概览图。（比起人工智能，我们更倾向于一个中性的词汇「机器智能」来描述这项技术。）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;过去几年中，我们总是从创业公司创始人和学界中关注这一领域较早的人那里听闻技术行业中的大趋势。但是今年不同，很多关于机器智能的话题都是出自《财富》世界 500 强公司高层之口。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些管理人员在不断自我反思：自己要做什么。在过去的一年中，机器智能爆发了，风险投资总额达到 50 亿美元，几宗大收购，数十万人阅读了我们早期的研究。上世纪九十年代的互联网，管理人员正在意识到这项新技术有可能改变一切，但是没人知道怎么改变以及何时改变。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8E4TjIhibUIREOamYfQmmEw8XGWE7lEPwAvhS37XlnbhH5UEkib3fLNyghxkYict8s4snOBdB1YdriaQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;高清PDF下载链接：https://hbr.org/resources/pdfs/hbr-articles/2016/11/the_state_of_machine_intelligence.pdf&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今年的这张的创业公司竞争概览图展示了机器智能眼下的影响力。从农业到交通运输，智能几乎触及到了所有领域。每一个员工都能通过现有的工具用上机器智能，提升工作效率。各大公司也第一次开始在他们的业务中配套配入机器智能技术。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;与互联网不同，即便是最早进入市场的大佬公司也常常被机器智能技术打的束手无策，只有那些能迅速引入机器智能技术的公司持续占有优势。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;世界 500 强和其他公司该从哪里找到切入点呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;让人才更有生产力&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一种能迅速获得机器智能价值的方法是为你的人才配备机器智能工具。使用该技术的最早的赢家们一直在根据知识工作的特定领域不断调试这些机器智能生产力工具。在我们的概览图中我们称之为「企业功能（Enterprise Functions）」。有了这些工具，每一名员工都能之前只有 CEO 们才有能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8E4TjIhibUIREOamYfQmmEw4Advs9A8HFOOzaFAQSuX6hElJJwG89FOOysiaibgEzxI1NzH7l1qZk1A/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些工具能够帮助监控和预测（比如，像Clari这样的公司一个一个地预测客户销售来帮助优化交易）也有助于指导和训练（Textio的预测文本编辑平台帮助员工提高写文档的效率）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;发现全新的数据来源&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下一步是使用机器智能实现新数据源的价值，也就是我们在概览图的「企业功能」部分强调的内容。机器智能软件能够快速查看海量的数据，因此也开辟了一些原来无法获取的数据资源。人工太贵，想象一下你能负担得起让某人听销售人员的每一条销售记录并据此预测他们的销售表现，或者让一个团队检查所有的卫星图像，决定需要收集哪个宏观经济指标的数据吗。而这些数据也许你的公司就有（例如，客户服务对话记录、传感器数据预测中断需要维护），或者这些数据可以从外部新的数据源中获取。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8E4TjIhibUIREOamYfQmmEwRvQobkdRyjVAYw0ibKrQ81EwCu0gUfwNKDSGLWyltkqkiba82EEzOdDA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;重新思考如何开发软件&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你已经尝试了一些新的生产力工具并开始挖掘新的数据源寻找洞见。实现机器智能价值的下一步是在新软件的基础上建立起持续的竞争优势。但是机器智能是一门管理者需要学习的新学科分支，需要一组新的软件人才和新的组织结构。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;大多数 IT 集团公司想到的都是应用和数据方面的人才。而新的机器智能 IT 公司会考虑应用、数据和模型，把软件看成是代码、数据和模型的结合。这里的「模型」指的是业务规则，就像批准贷款和调试数据中心功耗的规则一样。对于传统的软件，程序员需要手动开发这些规则。今天机器智能可以用数据和新的算法生成一个人类程序员无法做到的非常复杂的模型，&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;传统软件中的模型只能通过程序员手写代码来做出改变。有了机器智能后，公司就能开发出自己定期进化的模型，模型拥有了学习能力，公司的竞争力也就能维持下去。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;把这些传统的模型想成那些拥有海量记忆但不善社交的员工——白痴专家。他们可以预测如何让业务获得最佳增长，让客户更加满意，或者削减成本。但如果你试图将它们应用到新的东西，往往会失败，甚至更差。当你的业务和数据改变时，这些传统软件就更不上了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所有这些都意味着开发机器智能软件完全不同于传统的软件，因此公司需要进行相应的员工结构调整。幸运的是，虽然找到适合的人才很难，开发这些软件的工具已经有了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 03 Nov 2016 13:56:55 +0800</pubDate>
    </item>
    <item>
      <title>Quora问答 |《Python机器学习》作者Sebastian Raschka：从Python的学习经验到计算生物学的最前沿</title>
      <link>http://www.iwgc.cn/link/3331426</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Quora&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：杜夏德、李泽南、蒋思源、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;昨日机器之心编译的一篇文章（参见：&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720220&amp;amp;idx=3&amp;amp;sn=c3b8b65ec118d6fdef3f55e5f29e89ff&amp;amp;chksm=871b03a2b06c8ab4b0a0c87a3b3647372578b129ad5f420fddc5a1a84138a7db51911e143980&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720220&amp;amp;idx=3&amp;amp;sn=c3b8b65ec118d6fdef3f55e5f29e89ff&amp;amp;chksm=871b03a2b06c8ab4b0a0c87a3b3647372578b129ad5f420fddc5a1a84138a7db51911e143980&amp;amp;scene=21#wechat_redirect"&gt;业界 | 超越R，Python成为最受欢迎的机器学习语言&lt;/a&gt;）显示Python已经逐渐成为最受欢迎的机器学习语言。在今日的 Quora 专题上， 《Python机器学习》一书的作者 Sebastian Raschka 回答了有关 Python、机器学习、计算生物学方面的许多问题。让我们通过这个专题看看这个机器学习界的明星（他被列为Github中最有影响力的数据科学家之一）是如何完成从生物到计算机的传奇跨界经历的。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;1. 你用过什么让你工作效率提升的工具？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从较高的层面来说，我把「计算编程语言和算法」视为最重要的生产工具，它能处理所有类型的问题。然而，从软件应用层面来说，我喜欢 Atom Editor（我仍在使用 VIM 进行远程工作）。每天我都需要编写很多不同类型的文件：Python 脚本、.cpp 文件、HTML 文件、Markdown、.tex 、纯文本文件、蛋白质结构文件等等。Atom Editor 支持跨平台（macOS 和 Linux）并带有丰富的插件系统。自从有了 VIM 后，我逐渐习惯使用这个小工具了。当然，我的大部分数据分析工作都在 Jupyter Notebook 上做。我不会用 Jupyter 来「开发」代码，但是对我来说，它为我提供一个记录研究轨迹的环境，就像一本「笔记本」，把所有的事情都集中在一处：执行代码，不同的 notation 和 comment，inline plots，以及 LaTeX 等式，不仅节约了时间，在我回顾某个项目写报告赶 deadline 时，它还是我的救命武器，哈哈。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对了，差点忘了「git」（和 GitHub）和一个强大的笔记类应用程序 Quiver（只能在 Mac 上用）。笔记类应用太多了，但我只喜欢 Quiver，它能输出所有格式的数据，有了它你永远不会觉得你会陷入某个特定的程序或格式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;2. 对一个刚入行的、有点手忙脚乱的机器学习/数据科学家，你有什么建议？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我认为手上握有太多的可用资源既有好处又有坏处。好的是我们有很多可选的工具和信息资源，但是为了利用好时间充分使用它们，做好「选择」和保持「关注」才是真正重要的事情。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我不想说很多资源都是「冗余的」，因为「冗余」这个词用在这里有点负面。然而，市面上有很多看似不同的书、工具、教程，内容实际上都差不多，可能在范围和风格上有些差别。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以，不要想贪多，我们总是被长长的阅读清单拖后腿，更重要的是先想清楚个人的目标（「我需要学习那些技能来解决 X 问题？」「我真的要学这个流行的 X 工具而不是 Y 工具吗？」）。资料和工具太多了，我们需要更加精心地挑选。当然有时候我们会感觉是不是错过了什么，但是我觉得习惯这种感觉会帮你把注意力集中在某一件事情上，取得稳定的进步。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;例如，我认为「机器学习简介」的书一本就足够了，没必要每本都读，除非你真的感觉到内容不完整需要补充。就像 Cathy O'Neil 和 Rachel Schutt 解释的那样，没有「完美」的数据科学家，因为没有时间去学每样东西。每个人掌握属于自己的一套技能，擅长某一领域就可以了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我认为不知道所有的事情不一定是件坏事。因为（如下图所示）我们能通过团队合作来弥补各自的缺陷。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibNsuVzdAtufgY2lKIlMXzHTpnKodp1RkiaPtwibCfaCyYNLxrnSsSZHKkUUSCNNyI79nkuJ4jfySKw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;3.2016 年机器学习领域发生的哪件事让你最兴奋？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我对如何将解决特定问题的技术比如卷积神经网络和循环神经网络应用到除图像识别和神经语言处理外的其他问题上极度感兴趣。我认为现在这些技术应用上的一个关键挑战是找到合适的「表征」（除了有足够的 数据外）。这里有个例子（比较旧），&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Lusci, Alessandro, Gianluca Pollastri, 和 Pierre Baldi。「化学信息学中的深度架构和深度学习：药物类分子的水溶性预测」Journal of chemical information and modeling 53.7（2013）：1563-1575.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;研究者们用有向非循环图呈现分子（通常来说，结构是无向循环图）作为递归神经网络的输入，来预测这些分子的水溶性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最近的一个例子是：&lt;/span&gt;&lt;span&gt;Gómez-Bombarelli, Rafael 等人「使用数据驱动的连续分子表达进行自动化学设计（Automatic chemical design using a data-driven continuous representation of molecules）」arXiv：https://arxiv.org/abs/1610.02415&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;简而言之，研究者们训练了一个自动解码器来生成现实的、合成分子。这里，他们的神经网络将 SMILES 串转换成潜在的表达（经过压缩后仅包含统计上的显著信息的向量）并以最小的（或者没有）误差回到 SMILE 串。SMILE 串是一个分子的一维表达；例如，阿司匹林的 SMILES 串是 CC(=O)OC1=CC=CC=C1C(=O)O 对应的是下面的二维结构：&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibNsuVzdAtufgY2lKIlMXzHicf8UwpHYkOCOZHDdplwzh0RODU6HySH0m654XBPc6M7H9IRUwicRo0A/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;阿司匹林（2 -（乙酰氧基）苯甲酸）&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，这些年出现了很多非常棒的工具，从 scikit-learn 到 Theano、 TensorFlow 和 Keras，使得进入机器学习的门槛降低，这也让我很兴奋。这些工具带来的便利让我们不用太担心技术上的部署问题，还让我们集中关注我们想解决的实际问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;4. 你是如何在紧张的工作中挤出时间做那些小项目的？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个问题问的好，说实话，我没有什么秘密可以分享。我觉得这个问题就像是：人们总是说要控制体重，但最终问题还是会归结于每日的热量摄入与消耗。而且，每天只有 24 小时，没人可以延长这个数字。我认为挤出时间的秘诀是你需要对这些小项目感兴趣，这样我就会自然地减少其他业余活动的时间，如看比赛，读小说等等。当然，你的关注点也是很重要的。我觉得对大多数有趣的东西说「不」是其中的关键。我没有说我们必须全天无休止地工作，我想表达的是：如果你有一个绝妙的想法，你通常会挤出时间来实现它。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;5. 解决机器学习问题时最适用的数学是什么？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;统计、概率论、线性代数 和微积分。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;统计和概率论，因为首要任务之一通常是在区别生成模型之间选择一个，来定义性能指标，并评估结果。线性代数是机器学习部署中主要支柱之一，因为它让我们能持续高效地记录和部署。我想说微积分在纯机器学习应用中显得不太重要，但是如果你想理解我们使用或部署的算法，多元微积分和优化理论就显得非常重要，如果你想研究机器学习，那就更不必说了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;6. 我是一位生物物理学专业的学生，对 Python 在自然科学中的应用很感兴趣。对于初学者，你能推荐一本学习 Python 的最好的书吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不幸的是，在学习 Python 上，我个人没有什么推荐的书，因为我是通过 Codecademy 以及后面参加的一个大学课程（CS Programming I）学会 Python 的；与此同时，我还大概在 2011 年 12 月份学习了 Udacity 的「计算机科学入门」课程。所以我倒是愿意推荐 Codecadamy 和 Udacity 的计算机科学入门课程，它们都是很好的资源（而且就我所知它们是免费的）。推荐书的话，我觉得最受欢迎的两本书是《Hitchhiker's Guide to Python》和《Learn Python the Hard Way》。但是我个人从来没有读过这两本书，也就不能为它们做担保了——但这不是说它们并不够好 :)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外，我认为这还要看你在其它编程语言上的经验如何。如果你之前曾经使用过另一种动态语言（例如 Ruby 或甚至 R），那么我觉得你只需要读一下 Python Pocket Guide（甚至只需要网页文档）就可以很快掌握 Python 了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尽管我相信上面列出的所有资源都对入门很有帮助，但你应该通过应用这门语言来解决你领域内的问题的方式来自动地学习这门语言。或者换句话说，一旦你通过入门的门槛，你就可以快速地在网上找到相关的或更特定的概念实现（比如通过 StackOverflow）。另外，写代码的时候进行合作也是有帮助的，因为你可以通过阅读其他人的代码获得很多有用的想法，而且其他人也能为你的实现提供有用的指点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;参考：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;计算机科学入门：https://www.udacity.com/course/intro-to-computer-science--cs101&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Hitchhiker's Guide to Python：http://docs.python-guide.org/en/latest/&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Learn Python the Hard Way：https://learnpythonthehardway.org/&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;7. 在生物学和机器学习的尖端，最激动人心的问题是什么？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在计算生物学领域（computational biology），我们常常有丰富的无标签的数据（有标签的数据有时候可能会有些棘手，这要看具体的项目）。我认为主要的难题之一实际上是我们应该如何呈现数据以使之能够被机器学习算法处理（即：特征表征（feature representation））。现在我看到了很多有潜力的想法和方法；碰巧的是，我刚刚在上面还回答了这个问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;8. 我喜欢你的《Python Machine Learning》这本书，你有计划再写一本吗？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我很高兴听到你喜欢我的《Python Machine Learning》。是的，我正计划写另一本书！在 2015 年我上一本书之后，我在学术界度过了非常忙碌的一年，我在教书、写论文、参加会议……上花掉了大量的时间，而且在写作新书之前我还需要休息一下 :)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但长话短说：我正计划写一本关于模型评估（model evaluation）的书。我收到过关于这个主题的很多问题，而且其往往只在介绍性的书里面有一些简短的介绍。因此，我今年开始写作关于「机器学习中模型评估、模型选择和算法选择的博客」（http://sebastianraschka.com/blog/2016/model-evaluation-selection-part1.html），但关于它的更多内容我想在一本书（Model Evaluation and Selection in Machine Learning：https://leanpub.com/meval）中扩展——通过使用 Python/scikit-learn/Tensorflow 的说明性的和实用的代码例子来增强这些概念。（另外，我相当确定未来某天我还会写一本关于深度学习的书。）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;9. 我可以如何在 10 天之内学会机器学习？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;10 天？嗯，这绝对很有难度 :)。但是，我也认为 10 天是一个你需要用来很好地整体了解机器学习领域的时间框架，也许还能开始将一些技术应用到你的问题上了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在阅读了机器学习三个不同的子领域（监督学习、无监督学习和强化学习）的介绍之后。我可能会花时间了解一下这些领域内代表性的简单（但有用的）算法（可能要把强化学习放到后面一点）。比如：用于回归分析的简单线性回归和 Ridge 回归、用于分类的 logistic 回归和 k-最近邻、以及用于聚类任务的 k-均值聚类和分层聚类。一旦你了解了每种算法的目标和它们解决特定问题的方式，你就能轻松地为你的知识库增加更多算法和方法。但是除了算法之外，你还要清楚如何准备你的数据（特征选择、变换和压缩）以及如何评估你的模型。也许，作为初学者，你可以查看我们在 SciPy 2016 上的 scikit-learn 机器学习教程。它大概有 6 小时长，并总结了大部分基础，还介绍了 scikit-learn 库，这些库可被用于实现和进一步的学习。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;教程地址：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;https://www.youtube.com/watch?v=OB1reY6IX-o&amp;amp;feature=youtu.be&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;https://www.youtube.com/watch?v=Cte8FYCpylk&amp;amp;feature=youtu.be&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;10. 人工智能会颠覆设计行业吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当然，我肯定这么想。人工智能或机器学习已经在很多设计相关的领域得到了应用。从提升图像质量到 Stitch Fix 的个人造型（https://www.stitchfix.com/）和自动驾驶汽车。另一个将自动算法整合到设计里面的例子是 NASA 用在太空船上面的「进化天线（evolved antenna）」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibNsuVzdAtufgY2lKIlMXzHzhLbGTSMfxiad5S7xCW14plbibuIwLJWvZia07ic0WwDPwTFNzD9IR1KHA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能和机器学习可能并不会完全取代设计师，但我认为它将成为设计师的工作流程中「机械性的（mechanical）」部分中不可缺少的部分。或者换句话说，我认为这是一种增强而非完全的替代。但我预计「设计（design）」将随时间变得越来越好，因为特定的人工智能驱动的流程将能帮助缺乏人力或资源的公司或行业实现「好」的设计。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;11. 你如何鉴定机器学习是否对一个项目有用？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一步需要考虑这个项目的主要目的以及完成目标的需要那些步骤。一旦我确定了某个问题可以用一个预测模型（一个分类器或回归器）来处理，或一个聚类算法（clustering algorithm），我会问自己这些数据是否适用于这个任务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果这是一个监督学习任务，我能访问这些标签/目标变量吗？如果不能，我能不能从别的地方获取？是否有足够的可用样本？在一个机器学习算法中，我能不能以某种适当的格式（也许是表格）表达这些输入数据？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;还有，如果我有一个可以轻易可视化或手绘的简单的一维或二维数据，用机器学习处理可能会有点过。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;例如，我或许不会为预测分子重量拟合一个回归模型，因为它是输入的结构。举个例子，给定一个乙酰水杨酸分子，它的分子结构是：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibNsuVzdAtufgY2lKIlMXzHicf8UwpHYkOCOZHDdplwzh0RODU6HySH0m654XBPc6M7H9IRUwicRo0A/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们得到了包含 9 个碳原子、8 个氢原子和 4 个氧原子的化合物；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;C ~ 12 g/mol&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;H ~ 1 g/mol&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;O ~ 16 g/mol&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以我们可以轻松计算出它的重量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;思考一些我们想要解决的问题十分重要，无论我们是否能轻松手动推倒出规则或者，无是够需要机器学习。大体上说，机器学习就是把手动推倒规则和假设或逼近函数的工程自动化。另一个例子是 Joel Grus 写的： Fizz Buzz in Tensorflow（http://joelgrus.com/2016/05/23/fizz-buzz-in-tensorflow/）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;12. 从分子生物学学士到 Python 机器学习，你转行进入数据科学领域的想法是因何而起？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我得承认，在本科学分子生物的时候，我确实对其中的统计和数据分析最感兴趣，而不是那些「实际」的实验室工作，仅仅为了一篇老式的，无名的论文就花了我本科学习的大部分时间。顺便说一句，我在这篇论文中，用实验数据画结论中的图表用了一两天时间，做实验却用了一个多月。所以我不是那么地不喜欢分子生物学，但我很快发现潮湿的实验室不是我的归宿：我视它为：「必要的邪恶」——项目中繁琐的数据收集部分。希望我说完以后，实验室的同僚们不要对我发火，我很感谢他们的辛勤工作（笑）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然我的博士学位是纯计算机领域的，我觉得我对数据科学和机器学习的热情来源于我在研究生学习期间的统计识别课程。学习这些技术非常有意思，而且效果立竿见影，我很快就能在生物学问题上用到它们。那段时间，我得说我对于算法和技术有点过于感兴趣了，而生物学被放在了第二位。今天，我对通用领域解决问题的过程最感兴趣，而生物学恰好是一个有很多数据的学科，恰好有很多问题需要解决。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;13. 你认为机器学习和数据科学会对医疗领域产生什么样的影响？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我的工作并不涉及医疗领域，但是我遇到了几个在机器学习和医疗交叉领域工作的人。例如在我们学院的 Mias 实验室（G.Mias Lab）就专注于收集来自于各种在线数据库和数据源的基本数据，用以预测患上特定疾病的风险。《Why》的作者 Samantha Kleinberg 正在做着非凡的研究，她应用和开发了各种用于医疗行业的统计学建模技术。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;看看那些生物医学的文献，我觉得描述特定蛋白质或基因的功能的经典方法是孤立地看待它们，然后分类至特定的表型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这种自下而上的方法当然也是医疗领域中的关键。然而，基因或蛋白质其实只是更大，更复杂系统中的一小部分。我相信汇集实验和设备的信息能对我们理解这个复杂系统提供有用的信息，并且能使医疗进步。特别是，我希望监测随着时间推移不同风险因素的变化。&lt;/span&gt;&lt;span&gt;如果这能够被高效地完成，那么我相信医疗界将会因此受益。我想说的是我们的目标是尽早获知健康隐患，最好是在这些隐患成为真正的问题之前。比如在一个人真正地患了糖尿病之前跟踪那些有患糖尿病风险的因素。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;发展更好的糖尿病治疗方法是很重要的，但是如果我们更好地理解哪种外界环境的组合会提高患糖尿病的风险，我们就能帮助许多人避免患上这种疾病。我认为不需要在这方面做任何研究，只需要整合如家庭历史、基因表达水平、年龄、购物行为、锻炼等信息就能帮助我们尽早发现患病的风险。我们收集越来越多的数据在一定程度上可以是以匿名形式研究的，因为这样才可以更容易地把它加入到机器学习算法中来建立一个预测模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然而，主要的挑战就是这些数据是高度异质，原始的，并且结合不同的数据库也是也是一个瓶颈，当然，出于隐私方面的担忧——数据是匿名的，这种方式很难链接不同的数据集。然而，苹果等公司正在研究如智能手机这类电子设备上的匿名追踪数据的解决方案。现如今，我认为找到一个将个人资料通过匿名方式提供给研究者的可行方法是建立一个更好的健康问题检测系统的第一步。我相信一旦解决这个问题，我们就为个人预警系统铺平了道路，这个系统是结合数据, 如购物行为, 日常锻炼和饮食信息, 也许个人基因组和偶尔的血液测试。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;14. 你在计算生物学中参与过哪些有趣的项目？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我的大多数其他项目都专注于虚拟筛选的应用：我们一直与实验生物学的实验室合作，开发和使用各种方式，在不存在或存在蛋白质晶体结构的情况下预测单独抑制的（或活性的，取决于哪个项目）候选分子。最有趣的地方是预测与反馈之间的关系：我需要预测（在某些时候），得到实验结果，然后再看看我的尝试对不对，分析我的方式为什么比其他方式更好。这些项目的另外一个挑战在于研究者需要让所有算法在计算上可行——如果你有 1500 万个分子，想在其中选取 100 个候选分子有点像在大海捞针。通常在这种情况下我们会预先进行「过滤」步骤让计算变得简单一些，因为研究总是有时间限制的。我的项目需要所有人充分发挥自己的创造力和技术，但最终，我们的研究成果也需要对合作方产生价值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除了虚拟筛选的应用（其中的一些已经完成了，我现在正在撰写论文，同时准备发布工具包），我同时正在参与蛋白质——配体相互作用等一般概念的研究，我们最近发现了一个蛋白质——配体相互作用的有趣现象，我们正在寻找数据点以确认它不是一个特例。今年夏天刚刚结束的一个项目则有关计算蛋白质——配体结合袋的局部刚性，用以预测近天然蛋白质——配体的结合模式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我觉得这是一个有趣的想法，因为近天然捆绑模式通常需要通过不同的能量项求和来进行预测。使用刚性理论，计算结构中的自由度更多是关于相互作用的协同性，而不是它们的相加和。换句话说，如果特定的非共价相互作用不从复合体中去除额外的自由度（如果复合体已经是刚性的），则其不被「计数」到相互作用分数。在实践中，使用局部刚性蛋白质——配体符合体似乎比其他方式或基于知识的评分方式一样好。而且，除了除了作为「独立」评分函数之外，我认为它是一个有趣的新的「信号」或「特征」，可以用于整体评分。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;15. 使用 Octave 作为机器学习语言到底有多高效？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我认为 Octave 是一种原型设计的高效环境，同时它也是（和 MATLAB 一起）计算机科学（学术领域）中的流行语言。我在很多地方必须使用它，而且我得说它确实是在机器学习上的好选择。但是，看起来现实世界中不趋向于使用 Octave/MATLAB，我得说像 Python 这样的语言也很容易学习——而且功能更多一点（但请注意这是我的个人喜好）。简而言之：如果你的研究需要大量使用，或者你的实验室/团队已经再用了，Octave 是一个不错的选择，否则我会考虑 Python 和 R 语言。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你有兴趣，可以看我去年写的一篇关于「语言战争」的文章：http://sebastianraschka.com/blog/2015/why-python.html&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;16. 对于有一些机器学习知识的程序员来说，学习计算生物学有什么好的方法？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是一个好问题！计算生物学是一个广阔的领域，有很多不同的子领域和方向可以研究：蛋白质折叠，同源性蛋白质建模，蛋白质配体对接和评分、分子动力学模拟、序列比对、基因组装配、微生物组研究、进化生物学和系统发育等等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;生物学的入门可以从分子生物学和基因开始，首先了解「大局」，然后再开始进入你所感兴趣的分区。关于生物计算方面的学习，我主要通过阅读论文——这一领域的变化很快，一本十年前的教科书可能已经过时了。我听说 Edx 和 Coursera 这样的网站已经在提供计算生物学和生物信息学的专门课程了，我没有接触过这些课程，但我觉得这也是不错的入门方式。有一个内容我想要特别分享一下，Greg Caporaso 的「应用生物信息学概论（Introduction to Applied Bioinformatics：http://readiab.org/）」，一本免费的在线图书。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;17. 你对数据科学的初学者有什么好建议？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我的建议是选择你个人感兴趣的问题或项目，而不是从复制一个问题的解决方案入手。如果你对一个问题感兴趣，自然会急于去解决它，并在此过程中开发新的工具和技术。首先，你需要以你能够熟练使用的技术和工具入手，看看能做到什么程度。如果使用现有的工具包不能够解决问题，我会尝试在线搜索类似问题的解决方案，或者问问别人。举个例子，如果你对某种预测感兴趣，在一开始你会将键值对储存在 Python 字典中。随着你的数据集不断增长，你可能会开始需要其他的存储方式，如 SQLite，然后你会开始学习 SQLite。同样的，假如你会使用 NumPy 数组处理很多问题，在收集异构数据时，你可能会转而寻求 Pandas 来处理；如果你的系统内存有限，你会尝试使用其他工具，例如 Blaze。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我建议的方法是你需要学习使用你认为可以解决问题的工具，假如合适就使用它们。第二步是看看你目前工具的潜在替代者，看看它们有什么额外的功能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我发现为了学习工具而学习工具很快就会变得无聊，所以我的方式是在实践中学习工具。如果方向正确，你自然会花时间来学习新的工具。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;18. 您怎么找到时间来掌握机器学习，获得另一个博士学位，并且还对这个学科出了本书的？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我认为计算生物学和机器学习在解决问题的时候是有很大的相似之处的。在计算生物学中，我们通常通过各种数据挖掘来解决计算问题，机器学习中，数据挖掘也占大头。我一直很喜欢统计学，在研究生的阶段我就上过一门「类统计模式识别」，我真的认为这门课点燃了我对预测建模还有机器学习的热情。最开始的时候，我感到「哇，这真是太不可思议了，它帮我解决了计算生物学各种各样的问题」，后来，我真是感觉到「哇，机器学习是那么重要，他几乎能帮我解决所有问题，我要学到更多。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在课程中，我发展出了对机器学习真正的热情，这使我有动力在晚上花一些额外的时间去努力钻研。说实话，有很多机器学习的方面我都没有深入研究，还有很多文件资料我都没有来得及读。然而当我被要求写本书的时候，我发现先前的研究正好与此有关。虽然我在每个周末晚上花上几个小时来写书，我的社交生活在这几个月里也遭受些磨难，但是这也是我激情的来源：我十分高兴能够分享那些使我兴奋的的知识，这也使整个写书的过程变得充满了乐趣。所以，我认为抓紧所有时间在已经足够疯狂的博士期间写一本书是一个很棒的体验（因为他直接有助于解决计算生物学的问题），所以我也愿意花费一些我的「空闲」时间。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;19. 我能在哪找到可以用来学习的 Python 机器学习项目？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我的建议是关注一些数据科学的博客，因为有很多人的博客都在分享他们所爱好的 Python 机器学习方面的东西。现在这边有一个较为全面的数据科学家博客列表，不过这并不是全都关于机器学习的，所以你得做一些手动搜索：rushter/data-science-blogs 你也可以看看 Kaggle（https://www.kaggle.com/）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;例如：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;「通过 100 万条酒店评论发现一些有趣的见解」：https://blog.monkeylearn.com/machine-learning-1m-hotel-reviews-finds-interesting-insights/&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;在 Python 中的机器学习训练，第一部分：http://www.johnwittenauer.net/machine-learning-exercises-in-python-part-1/&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不幸的是，他的博客似乎不常更新了（或者有了个新的站点），但还是可以看看通过了 Kaggle 比赛的解决方案（http://www.chioka.in/kaggle-competition-solutions/）。同样的，我也认为 Kaggle 比赛和论坛是学习的良好平台。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 02 Nov 2016 14:58:26 +0800</pubDate>
    </item>
    <item>
      <title>深度 | 专访《西部世界》科学顾问：机器人可能会进化为有意识的物种</title>
      <link>http://www.iwgc.cn/link/3331427</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;选自Flick&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：曹瑞、李泽南&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;HBO 雄心勃勃的新剧《西部世界》——描述了一个十九世纪牛仔风格的未来主题公园，其中遍布人工智能的角色「接待员」，自开播以来已经播出了五集，每周一更新。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在前几集中，我们已经看到了制片人乔纳森·诺兰和 Lisa Joy（他们是一对夫妻）如何在每个星期一用剧情戏弄观众的感受。通过五集的刻画，未来人工智能的行为方式跃然呈现在现代人的眼前。在第一季剧情进入高潮之前，Flick网站对本剧的科学顾问，奥克兰理工大学人工智能教授 Wai Kiang（Albert）Yeap 进行了一次有关人工智能的专访。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibNsuVzdAtufgY2lKIlMXzHNRiclDniafUveCJ6pnagTwLakUHia5odMZ67ava0C9DEFqKibGDZbEjcSA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;正如我们所见，《西部世界》展示了小诺兰的深厚功力，那么它是如何写成的？让我们看看 Yeap 是怎么说的&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：看到目前的剧情，我们不知道「西部世界」是如何创作的，你觉得科学对剧情的设计有什么样的影响？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：我得说从科学的角度来说，这是很有趣的。《西部世界》对于一个不研究人工智能的高学历人士而言——比如物理学家和化学家——是很有趣的。对于研究智能的人们来说，一些明显的 bug 会让他们有点出戏，我想。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：那当然啦。作为一名专业人士，你可以评价一下接待员在「西部世界」里的设定符合你心中人工智能的未来吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：他们干得不错（笑），接待员也很不错。一切都是人类的错（笑）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：我觉得我们未来会看到更多这种类型的剧作，顺着这个思路。你觉得《西部世界》中的人工智能是什么级别的存在？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：对于《西部世界》中的人工智能，表现力是核心——这就是说必须通过图灵测试。我认为对于大多数人而言最重要的是需要让你觉得它就是真实的人类，这样的接待员才能让来客们满意。当然，我们不知道剧中客人是如何分清谁是机器人，谁是其他客人的，我漏掉了一点剧情。但剧中的接待员举止得体，而且它们遵从阿西莫夫的经典定律「机器人不能伤害人类」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：如果你是这部剧中的人物，你会发现什么能区分出人类和机器人的东西？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：我觉得如果我在其中，或者任何其他人，在《西部世界》中如果没有被事先告知，那我们是看不出来的。所以我说机器人的表现很好嘛，它们让人真假难辨。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：你看到剧中对机器人的能力，功能和权限的设定了吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：是的，所以我说它们的表现很好，但对于一个故事而言，人类部分的描写就显得有些薄弱了。我认为目前剧中人物正在试图通过与接待员对话来控制他们。如果他们可以控制机器人，剧情就变得有点过头了。你不能用这种方法检查和分析性能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：这是因为通过图灵测试的机器人具有欺骗性吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：不，只是因为这太复杂了。剧中机器人的程序非常复杂，你不可以简单地询问公园中的角色「你为什么要这么做？」然后期待它们可以给你一个可以理解的答案。其中的原因会非常复杂，它们不会遵循简单的逻辑。想象一下一些程序可以为这些机器人加入一点阴险的特征，让它们变得更加危险，同时也变得更加像人类（甚至最终变成人类）。这样，就变成了有一个超人正在创造和控制这些机器人。一旦你创造了西部世界，你就难以分析其中的人造角色了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：当你在设计一个和《西部世界》中的人物一样复杂的物体，你认为创造者会在其中加入一些人类的特质吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：你能说的就是在程序当中可能会出现一些出乎意料的行为。如果你允许它们学习新的信息，学习怎样在不同的情境下表现的话，确实是这样。这也就是危险的所在。机器人可以在人类没有意识到的情况下进行学习，并且表现出很多不同的行为。它们很快就可以有能力做到这样的事情，它们选择怎样表现也就变得无法预料。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：如果在《西部世界》中，一个进化程序被故意设定开始运行，这会让你感到不不安吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：在回答这个问题之前，弄清楚设定「一个程序的进化过程」（an evolutionary process in motion）是什么意思非常重要。简单地说就是允许这些机器人自己接受（无限制的）信息，并且选择它们认为合适方式来改变自己的行为。这样一来，进化的就是它们的行为。潜在的过程基本上是一样的。机器人所进行的就是我们所说的符号到符号的处理（symbol to symbol manipulations）。如果是这样的话，我会觉得非常不安。如果它们来控制我们，想一想我们居然被机器统治。这部电视剧中对这一过程的描述从科学的角度来讲是非常薄弱的。在电视剧中，这些机器人慢慢发现了自己是谁，并且认识到人类正在尝试修复它们。而我认为，这不可能发生。如果机器真的这样做，它们可能会立刻展现出一些「疯狂的」行为，一个个被「消灭」。那个用石头砸自己头的流浪机器人可能就是感到迷惑的一个，我喜欢那一幕。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：似乎在这部电视剧当中，不只有一位人类科学家想要赋予这些机器人高级的意识。如果人类这样做的话，我们应该感到担忧吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：再次说明，当你说到他们正在尝试要去做什么的时候，事实上他们并没有那样去做。剧中科学家们正在做的事情是让它们可以「进化」，产生一些更加有趣和让人意想不到的行为。正如我之前说到的，如果这些科学家真的按照你说的方式去做，他们能够控制这些人工智能的时间也就不会太久了。这种行为很危险，也不是什么好事儿。也就会成为像我之前说到的一样，被机器所统治。可是尽管它们能够展现出复杂的行为，它们仍然还是机器。可惜的是，大多数电影描绘的都是人工智能的这一方面，让人工智能看上去很邪恶。另外一种可能，也是更加复杂的一种可能就是让机器加速人类的进化过程。这样，我们就会跨越物种，从生物进化为机器。但是我们首先需要要去认清我们是谁，我们是怎样从原始物种进化到现在的状态的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：考虑到这一点，你有没有猜想过，或者说你有没有一些想法认为哪些故事情节可能会在这里上演？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：最有可能的是，机器人会开始学习成为一种「有意识」的物种，之后他们有可能会取得控制权，或者是在人类和机器人之间创造出一种复杂的相互作用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;问：你认为人工智能拥有一定程度的能力已经是一种必然了，是这样吗？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：是的，但是就像我之前所说，虽然它们的行为和人类一样复杂，但它们也仍然只是机器。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：那么对我们来说，对待人工智能最好的方式是怎样的呢？从一方面来讲，我们是不是不应该让它们的能力超出某一限度？或者还是说我们应该继续追求那些只能在实验室环境下研究的高度受限的人工智能？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：对于我来说，最好的方式就是使用人工智能科技来帮助我们将心智神秘的面纱一层一层地揭开。如果我们继续使用人工智能科技创造拥有复杂行为的机器，那么它们就会像霍金教授所预言的那样摧毁我们。像《西部世界》这样的游戏太危险了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：如果要和一个自己拥有人工智能的机器人或是一个被远程人工智能控制的机器人互动，你认为在这种情境之下，人类的生命会面临危险吗？你会怎样去尝试控制这些风险？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：同样，这取决于你对机器人的警惕放松到了多大程度。如果你控制了他们的学习能力，那就不会出现什么问题。问题的源头就在于它们是否拥有自我学习的能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：在这部电视剧当中，有一个编程策略是让每一台机器都可以在一个狭窄的框架之中在白天完全自主，控制自己。这样让它们自己运行，但是又给它们设定了一些限制的方式，你怎么看？从一个非专业人员的角度来看的话，这让我感到有点不安。&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：如果说你为它们设定了一系列的行为，让他们从中选择的话也是可以的。如果我们对此进行限制的话，你会很安全，但是就没有那么有趣了。确实在现实世界当中，一些公司出于盈利的目的，会放松对人工智能的限制，让它们可以展现出更多有趣的行为。可这样的话，我们可能就会面临大麻烦了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：我在看电视剧的时候，想到其中一件最危险的事情就是人类用对待同类的方式来对待机器人。所以说，如果你可以谋杀或是强奸机器人，这会改变我们人类互相之间的关系吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：是的，当然。因为它们太过于真实，这会影响我们与机器人的关系以及对它们的感觉。我们会越来越觉得它们像人类——因为就像我所说的，从机器人层面来说，我们无法对它们进行区分。另外，你问到人与人之间的关系，我只能说我不太了解。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;问：如果你有反社会的冲动或是行为，在人工智能方面付诸实践是不是一个好主意？这样的行为应该受到鼓励吗？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：我认为我可能还没有资格来回答这个问题，但是如果你让我做一个猜想的话，我的回答应该是否定的！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：那我们换种方式来说吧。假设你是一个机器人研制方面的工程师，看到它们被对待的方式，你会喜欢吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：我认为这取决于你创造机器人的用途是什么。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：对于这个节目，你还有什么特别想要讨论的东西吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：是的。我一直在想这些接待员是怎么具备原始意图/意识的。在《西部世界》当中展示的是这些接待员是怎么突然有了「知觉」，但是否确实有一些「特别瞬间」让我们意识到它们是谁。这和处理其他情况或是产生一些反应有什么不同呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：对于说这样的改变会最终成为现实的说法，你怎么看？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：很困难，对于人工智能来说明白它是怎么来的是关键，就像圣杯一样。我们是怎样具备原初意向性（original intentionality），或者是一些宗教人士所说的人类灵魂。像我之前所说的，我相信使用人工智能科技能够揭开思维运作的秘密。或许之后我们就能够了解真相。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：如果看到这样的科技被用到了游乐园而不是一些科学领域，你会感到惊讶吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：不会，一点儿都不惊讶。事实上，我也有一个问题想要问你，我想问一下《西部世界》的地址。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：我们都想尽快去那儿，是吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：你也想去吗？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：当然了。你不会感觉不舒服吧？你确定是 100% 安全的吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：是的，当然。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：你在追求知识的过程中也花了很大功夫，是吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：肯定，那是当然。我一直在进行观察，尽力想要找到这个迷宫。「笑声」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 02 Nov 2016 14:58:26 +0800</pubDate>
    </item>
    <item>
      <title>学界 | 谷歌新论文提出神经符号机：使用弱监督在Freebase上学习语义解析器</title>
      <link>http://www.iwgc.cn/link/3331429</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;选自arXiv.org&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibNsuVzdAtufgY2lKIlMXzHFxvXVaGgOfLKibbsluO2raHFCtjiaI8HaQ4Ka8gP7WBlYib1grjkvlDrw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;摘要&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;将深度神经网络的成功扩展到自然语言理解和符号推理上需要复杂的运算和外部的记忆。最近的神经程序诱导方法（neural program induction approaches）已经在尝试解决这个问题了，但这种方法通常受限于可微分的记忆（differentiable memory），因此只能执行一些小型的合成任务，不能进一步扩展。在这项成果中，我们提出了 Manager-Programmer-Computer（管理器-编程器-计算机）框架，其整合了神经网络和不可微分记忆（non-differentiable memory）以支持通过一个友好的神经计算机接口执行抽象的、可扩展的和精准的运算。具体来说，我们引入了一种神经符号机（NSM：Neural Symbolic Machine），其包含了一个序列到序列（seq2seq）神经「编程器（programmer）」和一个不可微分的「计算机（computer）」——该计算机是一个带有代码协助（code assist）的 Lisp 解释器。为了成功将 REINFORCE 用于训练，我们通过使用一个迭代式的最大似然训练过程（iterative maximum likelihood training process）所找到的近似黄金程序（approximate gold programs）来增强它。NSM 可以通过弱监督（weak supervision）的方式在大型知识库上训练语义解析器（semantic parser）。其通过弱监督的方式在很有挑战性的语义解析数据集 WebQuestionsSP 上实现了新的当前最佳的表现。和之前的方法相比，NSM 是端到端的（end-to-end），因此无需依赖特征工程或特定领域的知识。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibNsuVzdAtufgY2lKIlMXzHzm1qH1jqh5PciaD1fkzHISL63tbVnkaK2wO4W3gpRh8vWxbP4jGS5Ig/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 3：使用 NSM 的语义解析。其密钥-变量记忆（key-variable memory）的密钥嵌入（key embedding）是该序列模型在特定编码或解码步骤的输出。为了说明，我们也在括号中显示了这些变量的值，但该序列模型永远不会看到这些值，而且只能通过变量名（如 R1）引用它们。特殊的 token「GO」表示解码的开始，而「RETURN」则表示解码的结束。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibNsuVzdAtufgY2lKIlMXzH60RQt9KicvhJyobNB4zeX5WO5RNpbnfR2rEYRT3bSMzIttcpZiaU57pg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 4：系统架构。100 个解码器、50 个 KG 服务器（KG server）和 1 个训练器（trainer）。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;论文下载地址：https://arxiv.org/pdf/1611.00020v1.pdf&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 02 Nov 2016 14:58:26 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 企业应用机器学习的主要障碍有哪些？</title>
      <link>http://www.iwgc.cn/link/3331430</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自The Next Platform&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李亚洲、杜夏德&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;如今机器学习的应用虽然越来越普遍，但如同其他新兴应用领域一样，一定会有一些障碍。对于企业来说，官僚化的批准流程、隐私保护、部门壁垒、价值周期长是其在部署机器学习时的主要障碍。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;即使在分析工作复杂的组织中，机器学习也存在「专业孤立性」问题。例如，银行中的反金融犯罪部门可能使用先进的技术进行反洗钱；而信用风险团队使用完全不同的、不兼容的工具来预测贷款违约，并基于风险设定价位；而财政部门却又使用另一工具预测现金流。同时，消费服务和分行运作根本就不用机器学习，因为缺乏专业知识和软件。这些部门经常不彼此合作，使得难以为成员、流程和技术建立标准。这种软件的拼接集合提高了全公司应用机器学习的总体拥有成本（TCO）。从外，团队的孤立也使得高层难以开始机器学习。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了支持数字化转型，机器学习必须要做三件事：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;彻底的转换企业商业流程：市场、销售、财务、人力资源、供应链等等；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;在全企业支持数据、用户和负载；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;融合企业技术堆栈；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Carolina Healthcare System、Cisco 和 PayPal 的例子说明了机器学习转换业务流程的潜力。在许多企业中，这种转换仍处于早期阶段。从平台架构的角度来看，机器学习需要与支撑业务流程的软件平台融合，支持不同背景的众多用户，以及支持不同的项目。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;扩展到企业级数据意味着许多不同的事。对支持全公司分析的数据仓库的看法迷惑着大部分公司。从实际来看，机器学习软件必须要能与不同的数据平台对接；消化不同格式的数据：有结构的、半结构的和无结构的；它必须能利用「高」（众多记录）和「宽」（许多列）的数据，并且能使用流数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，机器学习软件必须要与公司优选的技术堆栈融合。这意味着遵守安全协议；在优选的数据平台上的可操作性；符合操作系统的标准；虚拟化技术等等其他技术。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;数据科学家的短缺&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有一个普遍的认知就是企业缺乏数据科学家。麦肯锡的一份报告指出这种缺乏将会持续到 2018 年；Venture Beat、华尔街日报等多家媒体都曾报道过数据科学家的缺乏；哈佛商业评论表示要么不找要么降低对数据科学家的标准，因为真正的数据科学家都是独角兽。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;招聘难的问题不只是简单的供应与需求的问题。麦肯锡几年前的报告预测缺乏理解大数据的管理层，只不过比数据科学家缺失的差额小而已。学位课程和 MOOC 公开课每年产出数千新鲜的数据科学家。公司可以将机器学习项目推送到中国和印度等国家，因为在其他国家中，咨询公司就掌握了大量的有先进水平的分析师团队。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;缺乏专业标准和专业证书造成最大的招聘挑战。如今正在为数据科学家建立专业标准，却没有被普遍接受的标准。每个人都可以自称数据科学家。在 O'Reilly Media 发布的 2016 数据科学薪资调查报告中，29% 的调查对象自称数据科学家，但却说他们花费较少或不花费时间做机器学习项目，也不使用标准的机器学习工具。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对数据科学家合适的角色也不确定。在招聘经理找到带有机器学习技术和经验的人后，实际的工作可能完全不同。在许多公司中，带有数据科学家 title 的人的实际角色是信息检索：使用查询工具保证数据平台的数据安全，从而让用户能在 Tableau 或 Excel 上浏览（O'Reilly 的调查显示 SQL 是最流行的工具）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这样的误解损害了团队的积极性和激励机制。Stack Overflow 最近的一项调查显示创新和「建立有极大意义的东西」是机器学习专业人士的关键动力，要比其他条例更有激励性。因为一个机器学习人员知道如何使用 SQL 就把他放到「data broker」的角色，这是一种人力资源的误用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;价值的体现需要长久时间&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;根据 Gartner 的调查，负责高级分析的管理层说建立一个预测模型大约花费 52 天。（Gartner 对高级分析的定义包括统计、描述、预测数据挖掘、模拟和优化。）报告时间线从几天到几月各有不同。管理层都把「开发模型的速度」作为选择高级分析平台的顶级标准，仅次于使用方便度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;管理层想知道：为什么建立且部署预测模型需要这么久的时间？其实有许多原因：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: square;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;数据难以获得；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;数据污染；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;传统的机器学习工具不能扩展到大数据；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;管理部门批准部署模型的速度太慢，充满官僚主义；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;公司对模型部署缺乏明确的流程或技术标准；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;大部分数据科学家花费较少的时间训练机器学习模型。在 2014 年，纽约时报报道根据采访和专业评测，数据科学家花费 50-80% 的时间收集并准备数据。今年早些时候，Gil Press 在 Forbes 上发表的文章称 CrowdFlower 的一份数据科学家的报告称调查对象花费 80% 的时间收集、清理和组织数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;考虑到在企业数据仓库的投资，数据科学家需要花费如此多宝贵的时间来清洁数据是一件很惊人的事。有两个主要原因，首先，企业数据仓库注重对商业智能和性能管理使用案例的支持。这些使用案例是最容易获取的成果；他们有稳定的数据需求和大量的目标用户。然而，机器学习项目却要频繁处理企业数据库不支持的源数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第二，数据对机器学习项目的成果非常重要——「垃圾进入/垃圾清除」。有偏见或无效的数据产生有偏见或错误的预测。数据科学家的工作职责是高质量的输出，不能不理会数据问题说是「其他人的问题」。随着社会对算法中偏见的忧虑越来越多，我们期待对数据采集分析过程的可见性会成为普遍采用机器学习的重要因素。这种对责任的需求说明了数据科学家想要掌控数据的流程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器学习极其依赖计算基础设施，尤其是大数据。模型开发需要迭代测试和重复测试。2010 年之前，大部分基于机器学习软件的服务器都是单线程的，少有产品支持单机多核并行处理。（例如，SAS/STAT 中有超过 300 个程序，其中只有 22 个支持多线程处理。）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所有的这些顶级数据仓库提供商都在他们的分布式数据集中囊括机器学习引擎。Teradata 在 1989 年就引入了这一能力，IBM 在 1992 年做到这一点，微软 2000 年，Oracle 2003 年，Netezza 在 2006 年加入了机器学习。Greenplum 如今的品牌是 Apache MaDlib。2007 年独立的软件供应商 Fuzzy Logix 在多数据库平台上引入了机器学习库。嵌入 MPP 数据集中的机器学习引擎提供一些潜在的收益，包括减少数据移动，简化部署和一个 MPP 平台的性能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然而，在实际中，少有数据科学家使用数据库内的机器学习工具。主要有几个原因：第一，减少数据移动意味着一个机器学习项目所需的所有数据就只能是数据库里面的，这很少出现；第二，如果该分析数据集支持消费者喜好的应用我们只能加快部署；MPP 数据仓库中的机器学习库也缺少可用特征，要么强制用户妥协，要么依赖自定义代码。最后，机器学习工作量会分散数据库管理员的注意力，因为它是一些粗笨的、难以预测的工作。许多公司降低数据库内机器学习的部署或者严格的将使用缩减到商业智能的精调上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然关于公司审查模型的时间和通过流程的数据较少，但有证据显示机器学习很重要。负责的管理层要求将影响他们业务的机器学习透明化；没有银行会在不理解模型行为、测试并验证模型的情况下，冒险使用信用风险模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在受到监管的产业中，比如银行、保险、医疗中，法律审查是批准流程的一部分。例如在银行中，法律团队会评估信用风险模型从而保证模型没有显性或隐性的歧视效果，当然还有其他的合规问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器学习经验较少的公司可能缺乏模型部署的明确流程。没有明确流程的情况下，每个项目就是一个自定义项目，所以每个 contributor 必须从头开始完成每个人物，缺少最佳实践和标准模块提供的指导。这会花费很长的时间，在一些公司中，不是一个预测模型可能要花费 6 个月或更长的时间。在如今快速前进的商业环境中，这是很长的一段时间。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;企业机器学习的挑战&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;打破机器学习的各种「专业孤立性」是企业机器学习的关键目标。部门之间孤立行事会提高成本，阻碍投资，阻碍数字改革。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;技术人员的短缺是管理者们普遍关心的首要问题，因为这阻碍了更广泛的机器学习部署。技术差距部分归因于对于数据科学家，缺少一个专业的标准，机器学习项目 contributor 的角色不清晰。这个技术差距在组织中产生了一个恶循环，因为招聘经理在之前成功案例的情况下可能会无法判断某个人是否胜任机器学习的工作。管理人员的报告中提到，机器学习项目的周期太长是一个关键问题。机器学习项目需要花很长的时间才能产生价值，因为数据中有很多杂乱的东西，而且很难获取；因为传统的机器学习工具无法升级；因为部署模型的批准过程可能很复杂很官僚化；还因为很多组织缺少确定的模型部署程序和标准。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，机器之心系今日头条签约作者，本文首发于头条号，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 02 Nov 2016 14:58:26 +0800</pubDate>
    </item>
    <item>
      <title>独家 | Hinton、Bengio、Sutton等巨头聚首多伦多：通过不同路径实现人工智能的下一个目标</title>
      <link>http://www.iwgc.cn/link/3316956</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心原创&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：机器之心编辑部&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;技术顾问：Yuxi Li&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote style="max-width: 100%; color: rgb(62, 62, 62); font-size: 16px; white-space: normal; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p&gt;&lt;em style="color: rgb(136, 136, 136); font-size: 12px;"&gt;当地时间 10 月 27 日，Creative Destruction Lab 在多伦多举办了 2016 机器学习与智能市场（2016 Machine Learning and the Market for Intelligence）会议。会议云集了人工智能投资及科研界众多世界级明星。在下午的科研分论坛上 Yoshua Bengio、Geoffrey Hinton、Richard Sutton 和 Ruslan Salakhutdinov 等机器学习领域的巨星人物聚首于此，以接下来 1-5 年的人工智能方面的前沿科研方向为主题进行了公开探讨，并分享了很多有价值的知识和经验。机器之心现场观摩了这些大师级人物对机器学习技术、应用和未来的探讨。未来一段时间，机器之心将陆续发布对本次会议内容的独家整理报道。&lt;/em&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;整理内容如有疏漏之处，请不吝指正：留言或发送邮件到 editors@jiqizhixin.com。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以下为机器之心的分论坛现场整理。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Yoshua Bengio、Geoffrey Hinton、Richard Sutton 和 Ruslan Salakhutdinov 同台共同探讨人工智能这一研究领域的接下来 1-5 年的人工智能方面的前沿科研方向。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个明星小组论坛的主持人是科技领域的明星风投公司 DJF（Draper Fisher Juvetson）的合伙人 Steve Jurvetson。Steve 曾经投资过 Hotmail、Tradex、SpaceX、Nervana、D-Wave 和特斯拉等众多明星科技创业公司，他还拥有世界上第一辆 Tesla model S 和第二辆 Tesla model X（第一辆在 Elon Musk 手里）。但是，即使是 Steve，主持这场大师云集的小组论坛还是很有压力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibQiblzyVh1Iicfga2kY36K3YGI5wKK58sSznVpJlW9BSP1b8Qv3sHbzNwdxaryxwL3p7y49xo85ia6g/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本次小组论坛的主题是「What's Next?The Research Frontier（接下来是什么？研究前沿）」。论坛开始，Steve 先请每位小组成员分别讨论自己对人工智能领域，其是机器学习领域下一阶段的科研方向的看法。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;下一步，去向何方？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在未来的一年里 Bengio、Hinton、Sutton 和 Salakhutdinov 教授认为都有哪些问题需要解决？我们会在哪些方向取得进展？&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Yoshua Bengio&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Yoshua Bengio 教授与 Hinton 教授和 LeCun 教授是深度学习崛起背后的领军人物。从 20 世纪 80 年代到 90 年代再到 21 世纪前几年，在那段很少有其他人看到深度学习的发展潜力的时间里，他们三位一直在培养和孕育深度学习。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibQiblzyVh1Iicfga2kY36K3YZcg4d1Oa4VW6b7dxFyo1aFe7cZjLXgu5Edl6C8ZCrlG91zmLYhiagqg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Bengio 教授列出了两个方向：&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1. 解释性的无监督学习（Explanatory Unsupervised Learning）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&amp;nbsp;&lt;strong&gt;&amp;nbsp;&amp;nbsp;1）当前的模型通过提取表面的规律来解决表面的问题。&lt;/strong&gt;Bengio 教授给出了一个图像识别系统的例子。该系统可以被各种各样的色调愚弄，比如背景绿化仍会增加物体被识别成野生动物的可能性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;strong&gt;2）机器无法做到人类非常擅长的无监督学习。&lt;/strong&gt;即使两岁孩童也能理解直观的物理过程，比如丢出的物体会下落。人类并不需要有意识地知道任何物理学就能预测这些物理过程。但机器做不到这一点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;strong&gt;&amp;nbsp;3）处理罕见的危险状态所需要的带有隐变量（latent variable）的预测 (（predictive）,，因果（causal）和解释性（explanatory）模型&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;a. 研究和开发带有隐变量的模型非常重要&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;b. 为什么带有隐变量的模型很重要？因为在可观察到的事物与观察不到的事物之间存在因果关系&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;c. 除了要有更好的模型，处理无标签数据也很重要。无标签意味着没有进行人类解读。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;d. Bengio 教授给出了一个关于开发安全的自动汽车的例子：自动汽车应该要能搞清楚其在训练过程中从未见过的危险状况。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;strong&gt;4）基于模型的强化学习、域适应（domain adaptation）、半监督学习、多任务学习等的应用&lt;/strong&gt;。Steve 问 Bengio 教授因果模型（causal model）是否能以一种无监督的方式衍生出来。Bengio 教授认为无监督将会是一个关键的组成元素，但我们必须使用所有的信息源。我们既应该使用有标签数据，也需要无标签数据。事实上，我们遇到的数据大多是无标签的，也就是说没有提供人类的注解。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibQiblzyVh1Iicfga2kY36K3YKGS6libsLlia8DNVgnXCibf4laibF6jJT5Ma1LiahUx6I9c9nLPOV2ic5ibPg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2. 记忆（Memory）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Bengio 教授还提到未来几年记忆（memory）将成为一个热门的研究领域。为什么记忆会在这个领域如此重要呢？因为记忆与推理存在紧密的联系。从本质上讲，推理就是各种信息的组合过程。为了能够得出能够准确预测未来的结果，你需要有合理的预测步骤。这个过程会在很大程度涉及到记忆。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;Geoffrey Hinton&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Hinton 教授是第一批使用反向传播算法来训练多层神经网络的研究者之一，他也是深度学习社区的一位重要大师。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibQiblzyVh1Iicfga2kY36K3YnSibD2Aj8VIWKpANov2HibqjicV41h70gsMMavFJqX5hgtWWXXm2mvYjg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Hinton 教授用一个他常开的玩笑开场。他对医学院学生说不要去当放射科医生，因为这个工作在未来 5 年内就会被深度学习应用取代。Hinton 教授指出，通常而言，如果你有大量数据和高速的计算芯片，并且需要解决预测问题，深度学习基本上都能派上用场。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibQiblzyVh1Iicfga2kY36K3YiaJfxgJCGIpoibTF0lIW14aUcSJmuQZBG1dwuxoAxUOwQiavG4ByPDbOQ/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Hinton 教授认为未来可能会实现的两件事：&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1. 发现比 ReLU 效果更好的「神经元（neurons）」模型&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;发现比我们的标准 logistic 单元或修正线性单元（ReLU）效果更好的「神经元（neurons）」模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了解释这个问题，Hinton 教授首先简要谈论了自 50 年代以来人工神经元（artificial neuron）的定义的发展史。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;50 年代的时候，人们认为神经元是逻辑门，是确定性的和二进制形式的。然后人们发现它实际上是随机的二进制（stochastic binary）。然后到了 80 年代，Hinton 教授那一代人对神经元的理解从确定性的逻辑门转变成了 S 型的 logistic 单元（sigmoid logistic units）。此后 30 年来，人们一直在使用 logistic 单元；直到 2011 年，修正线性单元随 AlexNet 被引入，进而带来了革命性的影响。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2. 在相对较小的数据集上训练带有大量参数的神经网络。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相较于探索无监督学习，Hinton 教授相信监督学习领域仍然还有一些工作要做。计算能力将越来越便宜，数据集将越来越大，这是如今的趋势。Hinton 教授认为计算能力降价的速度将会超过数据集增长的速度。也就是说，更多的参数可能将不再是噩梦。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数周前，在 Hinton 教授为多伦多大学研究生做的一次讲演中，他表达了自己关于如何做出好成果的观点，他认为可以在网络中利用我们拥有的计算能力并注入尽可能多的参数来获取数据的规律（包括可靠的与不可靠的），并结合所有这些意见来做出预测。这个观点已经在许多任务的完成中得到了成功的证明。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了解释更多的参数能打造更好的模型，他举了一个关于人类的例子：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们每个人都有 100,000,000,000,000 个突触。一个人在一生中大概要进行 1000 万次注视（fixation）。以每 5 秒一次计算，就是 200 万秒。如果我们将每次注视都看作是一个数据点，那么参数的数量和数据的数量之间就存在大约 10,000 倍的差异。如果你一次处理一个数据，那么当你有更多的参数时，你所得到的模型的效果就越好。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于这个例子，Hinton 教授继续指出人脑处理的数据比注视过程中接收的数据多 10,000 倍，但仍然可以处理。而我们的计算机能力不足的原因很可能是因为我们还没有提出一种用于 dropout 的规范化的方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Steve 提出对是否可以使用机器学习来优化参数，同时是什么让 Hinton 相信参数是解决问题的关键的疑问。对于 Steve 的这个问题，Hinton 表示赞同可以将其转变成一个机器学习问题，而且这能给科学研究带来很大的裨益。但同时，Hinton 也并未过多深入探讨参数的问题，反而指出人们实际上仍然不知道神经元实际的工作方式，但在研究上我们甚至有避免将我们在生物神经元上观察到的基本性质应用到人工神经元上的趋势。当前的人工神经元仍然还存在诸多限制，还只能计算一些非常简单的问题。为了解决更复杂的问题，我们还需要继续改变基本的神经元。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Richard Sutton&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Richard Sutton 教授被认为是现代计算强化学习之父，他在该领域有几个重要贡献，包括时间差分学习（temporal difference learning）、策略梯度方法（policy gradient methods）和 Dyna 架构。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibQiblzyVh1Iicfga2kY36K3YWdITSrnub5KicXYC7gZ8L4k2raOpRA3DStQ4HAykc6u7qNa2dgbChqg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Sutton 教授的兴趣点在于智能本身，以及学习的本质。Sutton 教授并没有探讨接下来一年什么会帮助公司企业获得利益，而是探讨了接下来一年里，他认为机器学习最重要的进展。主要有以下三个方面：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1. 从普通经历中规模化学习的能力&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2. 将机器学习扩展到下一阶段&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3. 使用深度强化学习进行长期预测，（可能）进行无监督学习&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibQiblzyVh1Iicfga2kY36K3YZzU0XqFWcupibw1ZJoicCUZiaK6iaIQ6ic1W07aicukXnQ7XILKVXxDRkiajw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在的机器学习过程和人类学习的方式并不相同。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Sutton 教授提到了经验学习法，比如人类和动物会通过生活经验来学习知识。在最近的深度学习方法种借鉴了这种经验法，我们用经验构建起巨大的训练集。能像人类那样学习是件非常重要的事情。不过在机器学习中，这种经验学习的方法还关涉到训练集的可扩展性和限制。这就是为什么现在的系统只能「被动学习（learned）」无法「主动学习（learning）」的原因。一个被动学习的系统建立在训练数据之上，而在主动学习系统中，系统能随时能通过新的经验不断提高。对于未来一年机器学习领域的发展，Sutton 总结道：了解世界的运行规律、可扩展的深度学习方法、用于长期预测的深度强化学习以及无监督学习。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 Sutton 教授看来，学习应该源自与世界交互的过程，而不需要使用有标签的数据集进行训练。它应该是一种更加自然的方式，就像人类小孩与动物的方式一样。它应该有关世界的运行规律和因果规律。Sutton 教授认为他和 Bengio 是在用不同的术语和方法讨论同一个问题。他在用强化学习的方法，而 Bengio 则用的是无监督学习。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他最后说，人工智能目前还有很长一段路要走，我们还仅仅出于旅程的起点，我们将会找到一个稳定的方式赶上甚至超越摩尔定律。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当 Steve 问到这和人类与大脑连接的类比时，Sutton 只是微笑着把问题让给了 Bengio 教授。Bengio 提到 logistic 单位模型受神经元科学假说的影响很大。我们还需要探索更多，才能消除神经科学与机器学习之间的差距。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Ruslan Salakhutdinov&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Ruslan Salakhutdinov 教授是卡耐基梅隆大学计算机科学院机器学习系的副教授，之前是多伦多大学的教授，也是 Hinton 的博士生。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibQiblzyVh1Iicfga2kY36K3YRaWHNxOSaXNkiadR7t9rAibAJ3BaT93DNYy49OQG5L9fmXHclJat0pKQ/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibQiblzyVh1Iicfga2kY36K3Yx0Oh4zL3HibwsP72vKKSnCbswewAvzicd7iaSVN7XShhvib5UPg3fMXZHg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719828&amp;amp;idx=3&amp;amp;sn=5f72f8b9bbd0078d483ad233e578081a&amp;amp;chksm=871b022ab06c8b3ce2ef881c941e1ea532e3f465bbc1109c74e0aa0a72b283a8408dca7b353f&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719828&amp;amp;idx=3&amp;amp;sn=5f72f8b9bbd0078d483ad233e578081a&amp;amp;chksm=871b022ab06c8b3ce2ef881c941e1ea532e3f465bbc1109c74e0aa0a72b283a8408dca7b353f&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;Salakhutdinov 教授最近作为机器学习研究的负责人加入了苹果&lt;/span&gt;&lt;/a&gt;&lt;span&gt;。他说他们正在组建一个顶级科学家团队。有很多棘手的项目和研究要做。他的工作是确保他们能开发出新的优秀算法。因为机器学习正在被应用到苹果内部的每个角落。他很高兴能够兼顾到所有的地方。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Salakhutdinov 教授说，人工智能与机器学习在未来一到三年内存在四大挑战：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1. 无监督学习/一次性学习（One-Shot Learning）/迁移学习&lt;/span&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Salakhutdinov 教授表示他在卡内基梅隆大学的实验室里已经利用数据进行了大量研究，已经可以使用监督学习从数据中提取结构，这是一个新进展，但计算机距离无监督学习还很远。他还提到了一次性学习，Bengio 和 Hinton 也提到过这种方法。只是目前的机器还不能像人类一样从少数例子中学到新的知识与概念。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2. 推理、注意和记忆&lt;/span&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Salakhutdinov 教授没有深入探讨这一部分，但他提出了一个问题：如何让系统具有内建记忆，帮助我们进行决策。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3. 自然语言理解/对话与提问/自动应答系统&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;即使我们在自然语言的推理中取得了很大的进展，但我们距离人机自然交互仍然有很长的一段距离。Salakhutdinov 在被问及建立嵌入记忆是否是让自然语言理解语境和长对话的关键时回答说：需要有正式的记忆网络，能在神经网络中进行读取和存储。建立和设计新的神经网络架构是我们要探索的问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Steve 还问到了人机交互自然对话界面建立的时间表，Salakhutdinov 则说，我们仍需在有限的环境中做很多工作，而不是在通用人工智能上。Bengio 则开了个玩笑：「严肃的科学家从不给出时间表。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;4. 深度增强学习&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Salakhutdinov 推荐对这一话题感兴趣的人们阅读 Sutton 的著作。他认为认真总结上个世纪 80 到 90 年代增强学习的成就之后，人们将会取得更伟大的进步。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;讨论花絮&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除了讨论这一个领域未来的展望，教授们还探讨了很多有趣的想法，互相开了开玩笑，与 Steve 进行问答，下面是从讨论中摘录的部分有意思的花絮。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Hinton 教授的灵感之源：「它（大脑）是如何工作的？」&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;待四位教授说完自己对未来科研风向的观点后，Steve 问了一个问题，是什么让教授们坚信，并且在不知道什么时间才会出成果的情况下，全身心将事业投入于此？（在会议中 Bengio 教授曾笑言：「（对科研态度）严肃的教授是不会给你（出成果的）时间线的。」）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;Hinton 教授谈到自己的坚持是希望探索出大脑是如何工作的。Steve 追问，「这个强烈的兴趣就在于我们对大脑真实工作情况理解的越多，模拟就能做的越好。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Hinton 教授：「不，我不关心这个。我只关心大脑如何工作。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibQiblzyVh1Iicfga2kY36K3YJVV8ic5ORMlBmpxskjpkq0dIuI1Ip72uC3SV0LtYTPL1bzcgic8Pfu4A/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;关于智能，存在一个简单的解释吗？&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在讨论到自由意志这个主题时，Bengio 教授还聊了聊自己正在思考怎样才能简单的解释智能。他提到 Pedro Domingos 教授在书中写过，很多机器学习（和深度学习）都有基础假设。有一些可以理解的简单原理能解释我们的智能以及我们大脑理解世界的能力。如果这个方法复杂到我们无法理解，那就不好玩了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Geoffrey Hinton 最近的工作&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;讨论中，Hinton 教授提到谷歌正全力支持他探索新型人工神经元及其工作原理，谷歌对他基础研究的支持非常有效，有了些突破性进展。他开玩笑说实际上谷歌是比 NSERC（加拿大自然科学与工程技术研究理事会）更好的资金来源。但由于这些讨论的内容本身很难，再加上 Hinton 浓重的英国口音就更加晦涩难懂。Bengio 教授则建议大家可以阅读他们最近发表的论文（论文点击「&lt;span&gt;阅读原文&lt;/span&gt;」下载，这是 Geoffrey Hinton之前的论文：&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719971&amp;amp;idx=3&amp;amp;sn=c23aa4b6172bd4ccea042d139ffa5daf&amp;amp;chksm=871b029db06c8b8b939ba2e0eb256db1d5fdd5ce2b229139cb31e7e54e5bdd2772761ce01c19&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719971&amp;amp;idx=3&amp;amp;sn=c23aa4b6172bd4ccea042d139ffa5daf&amp;amp;chksm=871b029db06c8b8b939ba2e0eb256db1d5fdd5ce2b229139cb31e7e54e5bdd2772761ce01c19&amp;amp;scene=21#wechat_redirect"&gt;&lt;em&gt;使用快速权重处理最近的过去&lt;/em&gt;&lt;/a&gt;的修订版）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Yoshua Bengio 教授 :「自由意志是一种错觉！」&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当 Steve 问 Bengio 教授他如何看待自由意志和计算决定论时，Bengio 教授并没有正面回答，而是给出了一个引人深思观点：「自由意志是一种错觉！」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;深度增强学习渐热&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Sutton 教授和 Salakhutdinov 教授都在强调深度强化学习。这种方法会催生通用人工智能吗？我们还不知道。但我们明白目前还有很多工作要做，而在这条路上我们将会有很多收获。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibQiblzyVh1Iicfga2kY36K3YGzHjcXzUmkcfc4r7QdVrzbZ3kNiajoCA2hHibodlkT6QUzA81f9RRcEw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;我们需要知道大脑的运作机制&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在会议和讨论中，Hinton 教授不断地讲述他关于神经、突触、脉搏、电流和其他工作的进展。他同时提到了图灵对神经网络的观点，并多次强调我们其实还是不明白它（人工神经网络以及大脑）的具体机制。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Bengio 教授与 Hinton 分享了类似的观点，他认为将大脑运作机制研究清楚是非常重要的——「如果我们不这么做一定是疯了」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Hinton：「我们不知道它的工作机制。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Bengio：「或者说，我们不知道我们大脑的工作机制！」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibQiblzyVh1Iicfga2kY36K3YCuQ3PeSXu78IpCFINp4jAf44LQcKoBIcbjRJl4PtT9aX7UfIf0zIyg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;本文是机器之心对 2016 机器学习和人工智能市场会议的第一篇小组论坛要点报道。该会议由多伦多 Creative Destruction Lab 于 2016 年 10 月 27 日在多伦多举办。我们希望本篇总结可以让大家从这些研究者的观点中受益。随后的一段时间里，机器之心将会陆续发出该会议的其他精彩小组论坛总结报道。请锁定机器之心，第一时间获得感兴趣的小组论坛总结报道。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心原创，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 01 Nov 2016 16:26:34 +0800</pubDate>
    </item>
    <item>
      <title>学界 | 微软重磅论文提出LightRNN：高效利用内存和计算的循环神经网络</title>
      <link>http://www.iwgc.cn/link/3316957</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;选自arXiv.org&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李泽南、吴攀、蒋思源&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQiblzyVh1Iicfga2kY36K3YNNKLJ7BbGrq6rTRLpKjpnHsdFPhHZxtVsxDKojEMntPibyc9IdUD9ibQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;摘要&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;循环神经网络（RNN）已经在许多自然语言处理任务上取得了最出色的表现，比如语言建模和机器翻译。然而当词汇量很大时，RNN 模型会变得很大（可能超过 GPU 最大的内存能力），这样训练将变得很低效。在这项工作中，我们提出一种全新的方法来解决这一挑战。其中的关键思想是使用二分量（2-Component(2C)）共享的词表征的嵌入（embedding for word representations）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们将词汇表中的每一个词都分配到一个表格中，其中每一行都关联了一个向量，每一列则关联了另一个向量。根据一个词在表中的位置，该词可由行向量和列向量两个维度联合表示。因为该表中同一行具有相同的行向量，同一列具有相同的列向量，所以我们仅仅需要 2p|V|个向量来表示带有|V|个词的词汇表，这远远少于现有的方法所需要的向量数|V|。基于二分量（2-Component）共享嵌入的方法，我们设计了一种新的 RNN 算法，并且使用几个基准数据集上的语言建模任务对其进行了评估。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;结果表明，我们的算法可以显著地减少模型的大小，并且能在不牺牲精度的情况下加快训练速度（它实现了与当前最佳的语言模型相近或更好的困惑度（perplexity））。值得注意的是，在 One-Billion-Word 基准数据集上，我们的算法实现了和以前语言模型差不多的困惑度，同时却将模型的大小减小了 40 到 100 倍、训练过程也加快了 2 倍。我们将我们提出来的算法命名为 LightRNN, 这主要是反应它在模型大小上的精简和很快的训练速度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQiblzyVh1Iicfga2kY36K3Ykw75jfcsfYRZu7VArMce4A8zh3TUFoicA8cEfDx45EibK8hZyXJttjBQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;训练 ACLW-French 时的困惑度对比&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;引言&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最近，循环神经网络（RNN）已被用于处理多种自然语言处理（NLP）任务，例如语言建模、机器翻译、情绪分析和问答。有一种流行的 RNN 架构是长短期记忆网络（LSTM），其可以通过记忆单元（memory cell）和门函数（gating function）建模长期依赖性和解决梯度消失问题。因为这些元素，LSTM 循环神经网络在当前许多自然语言处理任务中都实现了最佳的表现，尽管它的方式几乎是从头开始学习。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然 RNN 越来越受欢迎，但它也存在一个局限性：当应用于大词汇的文本语料库时，模型的体量将变得非常大。比如说，当使用 RNN 进行语言建模时，词首先需要通过输入嵌入矩阵（input-embedding matrix）从 one-hot 向量（其维度与词汇尺寸相同）映射到嵌入向量。然后为了预测下一词的概率，通过输出嵌入矩阵（output-embedding matrix）将顶部隐藏层投射成词汇表中所有词的概率分布。当该词汇库包含数千万个不同的词时（这在 Web 语料库中很常见），这两个嵌入矩阵就会包含数百亿个不同的元素，这会使得 RNN 模型变得过大，从而无法装进 GPU 设备的内存。以 ClueWeb 数据集为例，其词汇集包含超过 1000 万词。如果嵌入向量具有 1024 个维度并且每个维度由 32 位浮点表示，则输入嵌入矩阵的大小将为大约 40GB。进一步考虑输出嵌入矩阵和隐藏层之间的权重，RNN 模型将大于 80GB，这一数字远远超出了市面上最好的 GPU 的能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;即使 GPU 的内存可以扩容，用于训练这样体量模型的计算复杂度也将高到难以承受。在 RNN 语言模型中，最耗时的运算是计算词汇表中所有词的概率分布，这需要叠乘序列每个位置处的输出嵌入矩阵和隐藏状态。简单计算一下就可以知道，需要使用目前最好的单 GPU 设备计算数十年才能完成 ClueWeb 数据集语言模型的训练。此外，除了训练阶段的难题，即使我们最终训练出了这样的模型，我们也几乎不可能将其装进移动设备让它进入应用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了应对这些挑战，在本研究中我们提出了将二分量（2-Component）共享的嵌入用于循环神经网络中词表征的方法。我们将词汇表中的所有词放入一个表中，每一行都与一个向量关联，每一列都与另一个向量关联。这样我们就能够通过两个组件来表示一个词：对应的行向量和列向量。因为该表中同一行具有相同的行向量，同一列具有相同的列向量，所以我们仅仅需要 2p|V|个向量来表示带有|V|个词的词汇表，这样可以大幅度减少模型体积（相比而言，vanilla 方法需要|V|个不同的向量）。同时，由于模型尺寸的减小，RNN 模型的训练速度将会显著加快。因此，我们将这一新算法称为 LightRNN，以表示模型的小尺寸和极高的训练速度。这种方法的最大技术难题是如何将词合适地分配到表中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmsns.qpic.cn/mmsns/KmXPKA19gWibQiblzyVh1Iicfga2kY36K3YfrIj0081O9ruFYI5JuZibEQ/0"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;LightRNN（左）对比常规 RNN（右）&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了这个目的，我们提出一个引导框架：（1）首先随机初始化词分配（word allocation），并训练 LightRNN 模型。（2）解决训练了的嵌入向量（对应为表格中的行和列向量），然后细化分配来最小化训练损失（training loss），这是图论（graph theory）最小权重完美匹配问题，我们能够有效地解决。（3）重复第二步，直到满足确切的终止标准。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们使用在多个基准数据集进行语言建模任务来评价 LightRNN。实验表明，在困惑度（perplexity）上面，LightRNN 实现了可与最先进的语言模型媲美或更好的准确度。同时还减少了模型大小高达百倍，加快了训练过程两倍。请注意，对于高度紧凑的模型来说这个可预见的（没有准确性下降）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先，这使得将 RNN 模型运用到 GPU 甚至是移动设备成为了可能。其次，如果训练数据很大，需要执行分布式数据平行训练时，聚合本地工作器（worker）的模型所需要的交流成本会很低。通过这种方式，我们的方法使先前昂贵的 RNN 算法变得非常经济且规模化了。因此，它将会对用于人工自然语言处理（NLP）任务的深度学习有深远的影响。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;结论和未来的方向&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在本研究中，我们提出了一个全新的算法 LightRNN，该算法可用于自然语言处理任务。通过用于词表征的二分量共享的嵌入（2-Component shared embedding for word representations），LightRNN 在模型尺寸和运行时间上都取得了高效的表现，特别是在具有大词汇量的语料库中。在未来，这种算法有很多方向可以进一步研究。首先，我们计划将 LightRNN 应用于更大的语料库中，如 ClueWeb 数据集——传统的 RNN 模型还不能将其装进一个现代的 GPU 中。第二，我们会将 LightRNN 应用于机器翻译和问答等其它自然语言处理任务中。第三，我们会探索 k-分量分享嵌入（k&amp;gt;2）并研究 k 在权衡效率和有效性之间的作用。最后，我们将会整理我们的代码，以便在近期通过 CNTK 将其发布出来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;论文下载：https://arxiv.org/pdf/1610.09893v1.pdf&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 01 Nov 2016 16:26:34 +0800</pubDate>
    </item>
  </channel>
</rss>
