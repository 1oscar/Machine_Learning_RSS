<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>机器之心</title>
    <link>http://www.iwgc.cn/list/670</link>
    <description>人与科技的美好关系</description>
    <item>
      <title>重磅论文 | 如何通过机器学习解读唇语？DeepMind要通过LipNet帮助机器「看」懂别人说的话</title>
      <link>http://www.iwgc.cn/link/3388468</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自oxml.co.uk&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;em style="color: rgb(136, 136, 136);"&gt;&lt;span&gt;还记得经典科幻电影《2001 太空漫游》中的飞船主控计算机 Hall 吗？它具有依靠阅读说话人的嘴唇运动理解其所表达的内容的能力，这种能力也在推动那个幻想故事的情节发展中起到了至关重要的作用。近日，牛津大学、Google DeepMind 和加拿大高等研究院（CIFAR）联合发布了一篇同样具有重要价值的论文，介绍了利用机器学习实现的句子层面的自动唇读技术 LipNet。该技术将自动唇读技术的前沿水平推进到了前所未有的高度。原论文可点击文末「阅读原文」下载。&lt;/span&gt;&lt;/em&gt;&lt;br/&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;iframe class="video_iframe" data-vidtype="1" style="   z-index:1; " height="375" width="500" frameborder="0" data-src="https://v.qq.com/iframe/preview.html?vid=b0343vh7eug&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0" allowfullscreen=""&gt;&lt;/iframe&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9RD7kdS9x2m8NcicfRrYTorwjjJeTsCUpuYZcGOZbIBbSX324tGOcoImJRQ8rBamLuRSquI3icEZNg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;摘要&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;唇读（lipreading）是指根据说话人的嘴唇运动解码出文本的任务。传统的方法是将该问题分成两步解决：设计或学习视觉特征、以及预测。最近的深度唇读方法是可以端到端训练的（Wand et al., 2016; Chung &amp;amp; Zisserman, 2016a）。但是，所有已经存在的方法都只能执行单个词的分类，而不是句子层面的序列预测。研究已经表明，人类在更长的话语上的唇读表现会更好（Easton &amp;amp; Basala, 1982），这说明了在不明确的通信信道中获取时间背景的特征的重要性。受到这一观察的激励，我们提出了 LipNet——一种可以将可变长度的视频序列映射成文本的模型，其使用了时空卷积、一个 LSTM 循环网络和联结主义的时间分类损失（connectionist temporal classification loss），该模型完全是以端到端的形式训练的。我们充分利用我们的知识，LipNet 是第一个句子层面的唇读模型，其使用了一个单端到端的独立于说话人的深度模型来同时地学习时空视觉特征（spatiotemporal visual features）和一个序列模型。在 GRID 语料库上，LipNet 实现了 93.4% 的准确度，超过了经验丰富的人类唇读者和之前的 79.6% 的最佳准确度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1 引言&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;唇读在人类的交流和语音理解中发挥了很关键的作用，这被称为「麦格克效应（McGurk effect）」（McGurk &amp;amp; MacDonald, 1976），说的是当一个音素在一个人的说话视频中的配音是某个人说的另一个不同的音素时，听话人会感知到第三个不同的音素。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;唇读对人类来说是一项众所周知的艰难任务。除了嘴唇和有时候的舌头和牙齿，大多数唇读信号都是隐晦的，难以在没有语境的情况下分辨（Fisher, 1968; Woodward &amp;amp; Barber, 1960）。比如说，Fisher (1968) 为 23 个初始辅音音素的列表给出了 5 类视觉音素（visual phoneme，被称为 viseme），它们常常会在人们观察说话人的嘴唇时被混淆在一起。许多这些混淆都是非对称的，人们所观察到的最终辅音音素是相似的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以说，人类的唇读表现是很差的。听觉受损的人在有 30 个单音节词的有限子集上的准确度仅有 17±12%，在 30 个复合词上也只有 21±11%（Easton &amp;amp; Basala, 1982）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因此，实现唇读的自动化是一个很重要的目标。机器读唇器（machine lipreaders）有很大的实用潜力，比如可以应用于改进助听器、公共空间的静音听写、秘密对话、嘈杂环境中的语音识别、生物特征识别和默片电影处理。机器唇读是很困难的，因为需要从视频中提取时空特征（因为位置（position）和运动（motion）都很重要）。最近的深度学习方法试图通过端到端的方式提取这些特征。但是，所有的已有工作都只是执行单个词的分类，而非句子层面的序列预测（sentence-level sequence prediction）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这篇论文中，我们提出了 LipNet。就我们所知，这是第一个句子层面的唇读模型。就像现代的基于深度学习的自动语音识别（ASR）一样，LipNet 是以端到端的方式训练的，从而可以做出独立于说话人的句子层面的预测。我们的模型在字符层面上运行，使用了时空卷积神经网络（STCNN）、LSTM 和联结主义时间分类损失（CTC）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们在仅有的一个公开的句子层面的数据集 GRID 语料库（Cooke et al., 2006）上的实验结果表明 LipNet 能达到 93.4% 的句子层面的词准确度。与此对应的，之前在这个任务上的独立于说话人的词分类版本的最佳结果是 79.6%（Wand et al., 2016）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们还将 LipNet 的表现和听觉受损的会读唇的人的表现进行了比较。平均来看，他们可以达到 52.3% 的准确度，LipNet 在相同句子上的表现是这个成绩的 1.78 倍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，通过应用显著性可视化技术（saliency visualisation techniques (Zeiler &amp;amp; Fergus, 2014; Simonyan et al., 2013)），我们解读了 LipNet 的学习行为，发现该模型会关注视频中在语音上重要的区域。此外，通过在音素层面上计算视觉音素（viseme）内和视觉音素间的混淆矩阵（confusion matrix），我们发现 LipNet 少量错误中的几乎所有都发生在视觉音素中，因为语境有时候不足以用于消除歧义。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2 相关工作&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本节介绍了其它在自动唇读研究上的工作，包含了自动唇读、使用深度学习进行分类、语音识别中的序列预测、唇读数据集四个方面。但由于篇幅限制，机器之心未对此节进行编译，详情请查看原论文。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9RD7kdS9x2m8NcicfRrYTorwWGEqaxNdxy4icC0DOfObvhRk3pmYpMuJcocNr7eltzHzW8Bj41eC4w/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;em style="color: rgb(136, 136, 136);"&gt;&lt;span&gt;表 1：现有的唇读数据集和对应数据集上已被报告出来的最佳准确度。Size 这一栏是指作者训练时所用的话语的数量。尽管 GRID 语料库包含了整个句子，但 Wand et al. (2016) 只考虑了更简单的预测单独的词的情况。LipNet 预测的是句子，因此可以利用时间语境来实现更高的准确度。短语层面的方法被当作简单的分类看待。&lt;/span&gt;&lt;/em&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3 LipNet&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;LipNet 是一种用于唇读的神经网络架构，其可以将不同长度的视频帧序列映射成文本序列，而且可以通过端到端的形式训练。在本节中，我们将描述 LipNet 的构建模块和架构。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3.1 时空卷积&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;卷积神经网络（CNN）包含了可在一张图像进行空间运算的堆叠的卷积（stacked convolutions），其可用于提升以图像为输入的目标识别等计算机视觉任务的表现（Krizhevsky et al., 2012）。一个从 C 信道到 C' 信道的基本 2D 卷积层（没有偏置（bias），以单位步长）的计算：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9RD7kdS9x2m8NcicfRrYTorYgIncWu9eiahbgK7HPDBgVuQojW450OlVOQqjE1QhBBdop92YQyy35w/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于输入 x 和权重：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9RD7kdS9x2m8NcicfRrYToraXolMA2J5CictGpN0prakcHdHXrlO5oyD1Qkg0zs2qMR11NplwRJkuw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其中我们定义当 i,j 在范围之外时，xcij=0.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;时空卷积神经网络（STCNN）可以通过在时间和空间维度上进行卷积运算来处理视频数据：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9RD7kdS9x2m8NcicfRrYTorvib5eaibsMlk0CQ6VmkoRKSjSJX9UCdpJyibjWmVvtgbW7H8IAPwmRhLw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3.2 长短期记忆&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;长短期记忆（LSTM）（Hochreiter &amp;amp; Schmidhuber, 1997）是一类在早期的循环神经网络（RNN）上改进的 RNN，其加入了单元（cell）和门（gate）以在更多的时间步骤上传播信息和学习控制这些信息流。我们使用了带有遗忘门（forget gates）的标准 LSTM 形式：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9RD7kdS9x2m8NcicfRrYTorTsialkTZaW7LKhomtfR37dGjy9u3Wmh8iaMrxRDccqf9KBV1tCvPPdsw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其中 z := {z1, . . . , zT } 是 LSTM 的输入序列，是指元素之间的乘法（element-wise multiplication）, sigm(r) = 1/(1 + exp(−r))。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们使用了 Graves &amp;amp; Schmidhuber (2005) 介绍的双向 LSTM（Bi-LSTM）：一个 LSTM 映射&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9RD7kdS9x2m8NcicfRrYTor3DvleogNmia67cic3SDEblejpdp7OzibhCyFURO6pFNZHdwksQC2BmDZA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;，另一个是&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9RD7kdS9x2m8NcicfRrYTore5pAnibTT6cY9YFq417X03Wfpicqy8xYzI175RDR1MQCNJcIQhHHk49Q/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;，然后&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9RD7kdS9x2m8NcicfRrYTorQQghC6grTIBpW9GMibSpiaicbUfpEHRGhiaia2O4YF0nxNrT5MFzAjemsfw/0?wx_fmt=png"/&gt;&lt;br/&gt;，该 Bi-LSTM 可确保 ht 在所有的 t' 上都依赖于 zt'。为了参数化一个在序列上的分布，在时间步骤 t，让 p(ut|z) = softmax(mlp(ht;Wmlp))，其中 mlp 是一个权重为 Wmlp 的前向网络。然后我们可以将长度 T 的序列上的分布定义为&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9RD7kdS9x2m8NcicfRrYTorT6Nbo7icWZDl8gxz299ugUS2m1bGhDuvuMg57I7ZiaGNzYLvyaRcJh5A/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;，其中 T 由该 LSTM 的输入 z 确定。在 LipNet 中，z 是该 STCNN 的输出。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3.3 联结主义的时间分类&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;联结主义的时间分类损失（onnectionist temporal classification (CTC) loss）（Graves et al., 2006）已经在现代的语音识别领域得到了广泛的应用，因为这让我们不再需要将训练数据中的输入和目标输出对齐（Amodei et al., 2015; Graves &amp;amp; Jaitly, 2014; Maas et al., 2015）。给定一个在 token 类（词汇）上输出一个离散分布序列的模型——该 token 类使用了一个特殊的「空白（blank）」token 进行增强，CTC 通过在所有定义为等价一个序列的序列上进行边缘化而计算该序列的概率。这可以移除对对齐（alignment）的需求，还同时能解决可变长度的序列。用 V 表示该模型在其输出（词汇）的单个时间步骤上进行分类的 token 集，而空白增强过的词汇&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9RD7kdS9x2m8NcicfRrYToriafUPNzMtz2bE0dXqm2JVT9VVRlgUibd6P5neSNM1PsxQwGBEk0wxHhw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其中空格符号表示 CTC 的空白。定义函数 B : V˜ ∗ → V ∗，给定 V˜ 上的一个字符串，删除相邻的重复字符并移除空白 token。对于一个标签序列 y ∈ V ∗，CTC 定义&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9RD7kdS9x2m8NcicfRrYTor5pq6uP2wWuXOWJDYLKL0E7xvS711B61WCgibXlkt0RB2IoVY8xLgFWg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其中 T 是该序列模型中时间步骤的数量。比如，如果 T=3，CTC 定义字符串「am」的概率为&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9RD7kdS9x2m8NcicfRrYTorcPynj8zWyJThbtEavQ1Y9PXMdpkS2KPS7dn5ZmgvA2Bw3PlmoiaiaS5w/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个和可以通过动态编程（dynamic programming）有效地计算出来，让我们可以执行最大似然（maximum likelihood）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9RD7kdS9x2m8NcicfRrYTor4kuAbicannF6IahRgicQRfJG3Htib8ZN8TpaZkf5Ks3cbwF8me2uF8OLg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;图 1：LipNet 架构。一个 T 帧的序列被用作输入，被一个 3 层的 STCNN 处理，其中每一层后面都有一个空间池化层（spatial max-pooling layer）。提取出的特征是时间上上采样（up-sample）的，并会被一个 Bi-LSTM 处理；LSTM 输出的每一个时间步骤会由一个 2 层前向网络和一个 softmax 处理。这个端到端的模型是用 CTC 训练的。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3.4 LipNet 架构&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图 1 给出了 LipNet 的架构，其始于 3×（时空卷积、信道上的 dropout、空间最大池化），后面跟随时间维度中的上采样。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因为人类每秒钟大约能发出 7 个音素，而且因为 LipNet 是在字符层面上工作的，所以我们总结得到：每秒输出 25 个 token（视频的平均帧率）对 CTC 来说太受限了。时间上采样（temporal up-sampling）允许在字符输出之间有更多的空格。当许多词有完全相同的连续字符时，这个问题会加剧，因为他们之间需要一个 CTC 空白。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;随后，该时间上采样后面跟随一个 Bi-LSTM。该 Bi-LSTM 对 STCNN 输出的有效进一步会聚是至关重要的。最后在每一个时间步骤上应用一个前向网络，后面跟随一个使用了 CTC 空白和 CTC 损失在词汇上增强了的 softmax。所有的层都是用了修正线性单元（ReLU）激活函数。超参数等更多细节可参阅附录 A 的表 3.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;4 唇读评估&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这一节，我们将在 GRID 上评估 LipNet。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;4.1 数据增强&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;预处理（Preprocessing）:GRID 语料库包含 34 个主题，每一个主题包含了 1000 个句子。说话人 21 的视频缺失，其它还有一些有所损坏或空白，最后剩下了 32839 个可用视频。我们使用了两个男性说话人（1 和 2）与两个女性说话人（20 和 22）进行评估（3986 个视频），剩下的都用于训练（28853 个视频）。所有的视频都长 3 秒，帧率为 25 fps. 这些视频使用 DLib 面部检测器和带有 68 个 landmark 的 iBug 面部形状预测器进行了处理。使用这些 landmark，我们应用了一个放射变换（affine transformation）来提取每帧中以嘴为中心的 100×50 像素大小的区域。我们将整个训练集上对 RGB 信道进行了标准化以具备零均值和单位方差。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;增强（Augmentation）：我们使用简单的变换来增强数据集以减少过拟合，得到了多 15.6 倍的训练数据。首先，我们在正常的和水平镜像的图像序列上进行训练。然后，因为该数据集提供了每个句子视频中的词开始和结束时间，所以我们使用单独的词的视频片段作为额外的训练实例增强了句子层面的训练数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;4.2 基线&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了评估 LipNet，我们将其表现和三位懂得读唇的听觉受损者以及两个由最近的最佳成果启发的 ablation model（Chung &amp;amp; Zisserman, 2016a; Wand et al., 2016）的表现进行了比较。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;听觉受损者：这个基线是由牛津学生残疾人社区（Oxford Students』 Disability Community）的三位成员得到的。在被介绍了 GRID 语料库的语法之后，他们从训练数据集中观察了 10 分钟带有注释的视频，然后再从评估数据集中注释了 300 个随机视频。当不确定时，他们可以选择觉得最有可能的答案。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Baseline-LSTM：使用句子层面的 LipNet 配置，我们复制了之前 GRID 语料库当时（Wand et al., 2016）的模型架构。参看附录 A 了解更多实现细节。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Baseline-2D：基于 LipNet 架构，我们使用仅空间的卷积替代了 STCNN，这类似于 Chung &amp;amp; Zisserman (2016a) 的那些。值得一提的是，和我们用 LipNet 观察到的结果相反，Chung &amp;amp; Zisserman (2016a) 报告他们的 STCNN 在他们的两个数据集上比他们的 2D 架构的性能差分别 14% 和 31%。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;4.3 性能评估&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;strong&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9RD7kdS9x2m8NcicfRrYTorruMykGBuc46KvG19LYnQ2bBEmWu9RFCu2ncml5v7RicMWnmL6xqjdJA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;表 2：LipNet 相比于基线的性能&lt;/span&gt;&lt;/em&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;表 2 总结了相比于基线的性能。根据文献，人类唇读者的准确率大约是 20%（Easton &amp;amp; Basala, 1982; Hilder et al., 2009）。如预料的一样，GRID 语料库中固定的句子结构和每个位置有限的词子集有助于对语境的使用，能提升表现。这三位听觉受损者的词错率（WER）分别为 57.3%、50.4% 和 35.5%，平均词错率为 47.7%。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;4.4 学到的表征&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这一节中，我们从语音学的角度分析了 LipNet 的学习到的表征。首先，我们创造了显著性可视化（saliency visualisations (Simonyan et al., 2013; Zeiler &amp;amp; Fergus, 2014)）来说明 LipNet 所学的重点区域。特别地，我们向该模型送入了一个输入，并贪婪地解码了一个输出序列，得出了一个 CTC 对齐&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9RD7kdS9x2m8NcicfRrYTorh1udLfCvsBtfWc414YL2ha4GoGgzYe5lVxSX1s6tq9PHC9YtK9ZrDA/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（遵循 3.2 和 3.3 节的符号）。然后，我们计算了&amp;nbsp;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9RD7kdS9x2m8NcicfRrYTorgnicY6NaBpDtIdtnbv5gbpd0icHMmNiclS5EyGk3jEiagILEU8a078KpVw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;的梯度，并考虑了输入视频帧序列，但和 Simonyan et al. (2013) 不一样，我们使用了有引导的反向传播（guided backpropagation (Springenberg et al., 2014)）。第二，我们训练 LipNet 预测的是 ARPAbet 音素，而不是字符，这样可以使用视觉音素（viseme）内和视觉音素间的混淆矩阵（confusion matrix）来分析视觉音素。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4.4.1 显著性地图（Saliency Maps）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们应用显著性可视化技术（saliency visualisation techniques）来解读 LipNet 学习到的行为，结果表明该模型会重点关注视频中在语音方面重要的区域。特别地，在图 2 中，我们基于 Ashby (2013) 为说话人 25 的词 please 和 lay 分析了两个显著性可视化。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9RD7kdS9x2m8NcicfRrYTorLtzJEwibDFpAEFpUfxPichI2PMyP8KlqCNQ998RC7Fx7jnalZtWS96icw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;图 2：词 (a) please 和 (b) lay 的显著性地图，由向输入的反向传播产生，展示了 LipNet 学会关注的地方。图中的转录由贪婪 CTC 解码（greedy CTC decoding）给出。CTC 空白由空格符号表示。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4.4.2 视觉音素（viseme）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;根据 DeLand（1931）和 Fisher（1968），Alexander Graham Bell 首次假设给定说话人的多音素可被视觉地识别。这在后来得到了证实，这也带来了视觉音素的概念，即一个音素的视觉对应（Woodward &amp;amp; Barber, 1960; Fisher, 1968）。为了我们的分析，我们使用了 Neti et al. (2000) 中音素到视觉音素的映射，将视觉音素聚类成了以下类别：Lip-rounding based vowels (V)、Alveolar-semivowels (A),、Alveolar-fricatives (B)、Alveolar (C)、Palato-alveolar (D)、Bilabial (E), Dental (F)、Labio-dental (G) 和 Velar (H)。完整映射可参看附录 A 中的表 4. GRID 包含了 ARPAbet 的 39 个音素中的 31 个。我们计算了音素之间的混淆矩阵（confusion matrix），然后按照 Neti et al. (2000) 将音素分组成了视觉音素聚类。图 3 表示了 3 个最容易混淆的视觉音素类别，以及视觉音素类别之间的混淆。完整的音素混淆矩阵参看附录 B 图 4.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9RD7kdS9x2m8NcicfRrYTorpjJIBvKYzpvoOESW6TeHjRxU4FUehdVEsVk79TGXPGaEqwzibSqLemw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;图 3：视觉音素内和视觉音素间的混淆矩阵，描绘了 3 个最容易混淆的类别，以及视觉音素聚类之间的混淆。颜色进行了行规范化（row-normalised）以强调误差。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;5. 结论&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们提出了 LipNet，它是第一个将深度学习应用于模型的端到端学习的模型，可以将说话者的嘴唇的图像帧序列映射到整个句子上。这个端到端的模型在预测句子前不再需要将视频拆分成词。LipNet 需要的既不是人工编入的时空视觉特征，也不是一个单独训练的序列模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们的实证评估表明了 时空特征提取和高效的时间聚集（temporal aggregation）的重要性，确认了 Easton 和 Basala 在 1982 年提出的假说（1982）。此外，LipNet 大大超越了人类的读唇水平的基线，比人类水平高出 7.2 倍，WER 达到了 6.6%，比现在 GRID 数据集中最好的词水平（Wand 等人，2016）还要低 3 倍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然 LipNet 在实证上取得了成功，Amodei 等人在 2015 年发表的深度语音识别论文显示，只有更多的数据才能让表现提升。在未来的研究中，我们希望通过将 LipNet 应用到更大的数据集中来证明这一点，如由 Chung 和 Zisserman 等人在 2016 年收集的这种数据集的句子水平变体（sentence-level variant）。像默写这样的应用只能使用视频数据。然而，为了扩展 LipNet 的潜在应用，我们能将这种方法应用到一种联合训练的视听语音识别模型上，其中视觉输入会在嘈杂的环境中提升鲁棒性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;致谢、参考文献及附录（略）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Sun, 06 Nov 2016 16:45:06 +0800</pubDate>
    </item>
    <item>
      <title>前沿 | Nature发布计算和理论神经科学特刊：剖析机器学习推动下的神经科学进展</title>
      <link>http://www.iwgc.cn/link/3388469</link>
      <description>&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Nature Neuroscience&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：蒋思源、杜夏德&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;Nature Neuroscience 近日推出了一个关注应用于神经科学的计算驱动的和理论驱动的方法（computation- and theory-driven approaches）的特刊，介绍了许多生物物理模型和机械式的模型。相关论文可点击「阅读原文」查看。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;神经科学研究的进展无法脱离数据收集，同时也需复杂的方法将这些数据组装和合成到更广泛的框架中。理论神经科学，加上必要的计算技术，能确保我们的努力不仅仅是大规模的收集工作。本期，&lt;em&gt;Nature Neuroscience&lt;/em&gt; 呈现了一批论文综述与观点讨论，包含了一系列当下该领域突出的思考，从神经回路和网络到认知评估和精神疾病。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;神经机制的深刻见解都是来源于基于理论的研究。描述动作电位传播的 Hodgkin-Huxley 模型，Hebbian-based 的可塑性规则，Barlow 的有效编码假说和 Marr 的三层分析模型都是强有力的证明。然而尽管取得了这些成就，但生物学仍然存在实验和理论之间的脱节，这些在物理学上简直无法想象。技术的进步使得生物学在现代神经科学理论与实验的分离更有先见之明。正是这种大量数据生成的能力需要敏锐的实验设计和聚焦问题以获得理解。由于在没有理论基础的条件下就对这一问题的概念化，实验神经科学不过就是多个观察的简单堆叠，就像宇宙建立在海龟背上那种传说中的模型毫无意义。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;自然神经科学出版了一期关于计算神经科学的特刊，之前已经出版过三期的特刊。第一期是关于这一领域几十年主流的历史评论中不被看好但非常重要的内容。接下来两个合刊分别介绍了一些综述与主要的研究论文。现在我们处在一个临界点，即该领域已经成熟到可以做一期新的特刊，由综述和观点还有一篇评论构成，强调了了计算和理论神经科学近期的一些进展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;实验创新几乎已经蔓延到神经科学的每一个分支，而每个问题上都有了更多的数据。在《理论神经科学的关键时刻，概念与技术的进步》（Conceptual and technical advances define a key moment for theoretical neuroscience）论文中，Churchland 和 Abbott 推荐一个称之为大帐篷政策（big tent approach）的方法，计算和理论进入了从原始数据分析到建立详细的机制和生物物理模型所有阶段。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这里有一个详细的生物物理建模的例子，围绕带有相等的兴奋性和抑制性输入的网络建模，实验性证据也支持这种突触平衡（synaptic balance）的存在。在《高效的代码与均衡网络》（Efficient codes and balanced networks）论文中，Denève 和 Machens 论述了平衡网络模型的最新进展，他们特别强调这种网络能够支持高效的编码。大多数网络模型的实例化是以连续时间系统为背景的，然而我们知道神经元主要是是通过离散的尖峰脉冲传递信息的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在《建立尖峰神经模型的功能网络》（Building functional networks of spiking model neurons）的论文中，Abbott, DePasquale 和 Memmesheimer 讨论了当前桥接模拟-数字鸿沟的方法。我们总希望能逆向运行而不是施加一个网络结构来匹配当前的尖峰输出。人口记录和成像现在已经很平常了，但有可能推断出这种生理机制和可变性的来源吗？在《神经相关的状态依从性机制》（The mechanics of state-dependent neural correlations）中，Doiron 和同事们论述了跟踪大脑状态中的神经关联变化如何能暗示潜在的因果要素。但考虑记忆理论的时候，不同的神经状态视图就变得很重要了，也就是我们该如何如何构建并且维持稳定的表征。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Chaudhuri 和 Fiete 在《记忆的计算法则》（Computational principles of memory）论文中关注记忆系统所必要的法则。他们论述了相关的网络构架，潜在的生物物理过程，噪音的鲁棒性（robustness to noise），信息能力和编码策略，并承认其可以和计算机科学相媲美。计算机科学，特别是用计算机视觉技术构建的目标识别系统，又兜回来告诉我们如何建立人类视觉感知的模型。在《利用目标驱动的深度学习模型来理解感觉皮层》（Using goal-driven deep learning models to understand sensory cortex）论文的观点中，Yamins 和 DiCarlo 介绍了目标驱动的深层神经网络在解释感官处理上成功的一些原因，并提出可以做出类似的进展来超越感知系统。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;神经系统层级上升后，我们就可以做出感知上（perceptual）或者形式更加公开的决定。在《信心与确定：不同目标的不同概率量》（Confidence and certainty: distinct probabilistic quantities for different goals）这篇论文中，Pouget，Drugowitsch 和 Kepecs 提出了决策确定性（decision certainty）与决策信心（decision confidence）之间的绝对区分。当大脑在嘈杂的环境下工作时（「当」指的是「在任何时候」），大脑必须计算出概率分布。作者认为，确定性应该是指所有概率决策变量的编码，而信心应被具体定义为一个决策正确的概率。也许只有时间才能决定是否应该对它们的建议有信心。有了更好的感知模型后，当系统出现故障时，行为和决策制定也能潜在地让我们诊断和修改对策。Huys，Maia 和 Frank 在 Computational psychiatry as a bridge from neuroscience to clinical applications 这篇论文中对计算精神病学的新兴领域做了一个综述，详细介绍了机器学习计算应用以及基于理论的机器模型这两种方式在疾病分类和治疗上综合运用的进展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本期杂志中涉及的话题涉及的范围很广，大多数重点的内容都是发表在其他期刊上的文章。事实上，我们期刊上神经计算文章的数量最近几年一直在稳步增长。从谷歌搜索的 Google Trends 上看，对计算神经科学的普遍兴趣得到了初步支持（也许是确认偏误（conformation bias）？）过去 5 年中「computational neuroscience」的搜索量稳步增长，其增长可以在同一时期「光遗传学」的搜索频率也有类似的增长中得到佐证。计算神经科学增长或许不会迎来拐点，因为对该领域主题特定的期刊（如计算神经科学期刊。Journal of Computational Neuroscience）以及博士课程的搜索也会将这个词汇的搜索频率推向在峰值。有趣的是，到目前为止，「认知神经科学」的搜索数量远远超过了计算神经科学，但是搜索频率也会有季节性波动，每年秋天大学新生入学时搜索频率会波动性增长。现在每所大学都应该让计算成为神经生物学课程的核心部分。好处是在这 5 年的时间里，我们不再需要通过证明计算与神经科学的相关性来吸引大家对神经计算研究的关注。最大的希望是能促使神经计算在生物学有更好的理解，以及实现更好疾病治疗。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Sun, 06 Nov 2016 16:45:06 +0800</pubDate>
    </item>
    <item>
      <title>入门 |  智能时代每个人都应该了解：什么是深度学习？</title>
      <link>http://www.iwgc.cn/link/3388470</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自algorithmia&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：武竞&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;本文通过介绍人工智能、深度学习和机器学习三者之间的关系来阐明深度学习及其重要性。传统的机器学习智能处理一定量数据，而对于深度学习来说，数据越多，深度学习的技术表现越好。此外该文还介绍了深度学习的几大框架以及优秀在线课程和书籍。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;要理解深度学习是什么，我们首先需要了解深度学习与机器学习、神经网络和人工智能之间的关系。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;表示这种关系的最好方法是将它们用同心圆可视化：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9RD7kdS9x2m8NcicfRrYToryEzTxr2aibJ55JnZFImXwlBXDEZw7t4ia6jCEgIz0Rs8VpCxCicaZIHwg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在最外面的环是人工智能（使用计算机推理）。里面的一层是机器学习。人工神经网络和深度学习在最中心。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;广义地说，深度学习是人工神经网络的一个更平易近人的名称。深度学习的「深」是指网络的深度。而一个人工神经网络也可以非常浅。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;神经网络的灵感来自大脑皮层的结构。最基本的层次是感知器（perceptron），用数学表示的神经元。与大脑皮层中的结构一样，神经网络可以有几层相互连接的感知器。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一层是输入层。该层中的每个节点传入一个输入，然后将节点的输出作为输入传递给下一层中的每个节点。在同一层中的节点之间通常没有连接，最后一层输出处理后的结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们称中间部分为隐藏层。这些神经元没有与外部的连接（如：输入和输出），并且只由上一层的节点激活。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9RD7kdS9x2m8NcicfRrYTorWiaWOcicwucWH7DjmG1HicaIwfWsQjdmlUNLq5AzoQr5FnUQvfa5iabaOg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;来源：Michael A. Nielsen,「Neural Networks and Deep Learning」&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人们认为，深层学习是通过学习神经网络，并利用多层抽象来解决模式识别问题的技术。在 20 世纪 80 年代，由于计算成本和数据量的限制，大多数神经网络只有一层。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器学习被认为是人工智能的一个分支，而深度学习是一种特殊的机器学习。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器学习包含了计算机智能，它事先并不知道答案。相反，程序通过运行训练数据来验证其尝试，并根据是否成功相应地修改其方法。机器学习涉及多个学科，从软件工程和计算机科学到统计方法和线性代数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有两大类机器学习方法：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;有监督学习&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;无监督学习&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在有监督学习中，机器学习算法使用有标签的数据集来训练规则。这需要大量的数据和时间，因为数据需要手工标记。有监督学习是分类和回归问题的绝佳选择。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;例如，假设我们在运营一家公司，并希望了解奖金对员工留存率的影响。如果我们有历史数据——即员工奖金金额和任期——我们可以使用有监督机器学习。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;无监督学习没有任何预定义或相应的答案。无监督学习的目标是找出数据中隐含的模式。它通常用于聚类和关联的任务，如按行为将客户分组。亚马逊的「购买此商品的客户也买了...」建议是一类关联任务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然有监督学习可能是有用的，但我们经常不得不诉诸无监督学习。深度学习已被证明是一种有效的无监督学习技术。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;为什么深度学习很重要？&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9RD7kdS9x2m8NcicfRrYTor2vHiaPEzf8qu82zENY6eMuNvYOkDt23K3qfiaH1ZPptNpCV2zmOicafCQ/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;长期以来，计算机就有识别图像中特征的技术。但结果并不总是好的。机器视觉一直是深度学习的主要受益者。使用深度学习的机器视觉在许多图像识别的任务上可以与人类媲美。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Facebook 通过使用深度学习在照片面部识别领域取得了巨大的成功。这不仅仅是一个微小的改进，而是一个转折：「当被问及两个不熟悉的面部照片是否显示同一个人时，人类有 97.53％的正确率。由 Facebook 研究人员开发的新软件可以在相同的挑战下有 97.25％ 的正确率，无论照明的变化或者图片中的人是否直接面对相机。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;语音识别是另一个受深度学习影响的领域。口头表达极其丰富并且语义模棱两可。百度——中国领先的搜索引擎之一——已经开发了一种语音识别系统，能比人类更快更准确地在手机上生成文本，不管是英语还是普通话。特别令人着迷的是，概括这两种语言不需要额外的设计工作：「过去，人们将中文和英文看作两种截然不同的语言，因此需要设计非常不同的特征，」百度首席科学家 Andrew Ng 说，「现在的学习算法普适性强，你仅仅需要让计算机学习就行。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谷歌现在正使用深度学习来优化公司数据中心的能源消耗。他们将冷却能源需求降低了 40％。这意味着公司的电能使用效率提高了 15％，节省了数亿美元。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;深度学习微服务（Deep Learning Microservices）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面是一些使用深入学习的微服务的例子。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图片标签（Illustration Tagger）。这是应用 Illustr2Vec 的一个例子，这个微服务可以为图片打上安全性、存疑性、评分、版权以及一般类别的标签，以了解图像中的内容。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;DeepFilter 是一种将图像应用于艺术滤镜的图片风格转换服务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;年龄分类器使用面部检测来确定照片中的人的年龄。Places 365 分类器使用预训练的 CNN 并基于 Places 图像数据集（B. Zhou, et al., 2016）来识别图像中特定的位置，例如庭院、药店、酒店房间、冰川、山脉等。最后是 InceptionNet，可以使用谷歌的 TensorFlow 直接应用。它输入一个图像（如一辆汽车），并返回前 5 个与图像相关的预测类别。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;开源深度学习框架&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9RD7kdS9x2m8NcicfRrYToryGdCianliclVfbhYWibG3W9NpTZSZcqy1OXpo3atrt5fcF9NNGVA0K35A/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;深度学习可以通过一些开源项目来实现。一些最流行的技术包括（但不限于）：Deeplearning4j（DL4j），Theano，Torch，TensorFlow 和 Caffe。决定使用哪个框架的因素有：他们的技术目标，还有是否为低级别、是否作为学术研究或是否以应用程序为导向。以下是每个的概述：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;DL4J:&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;基于 JVM&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;分布式&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;与 Hadoop 和 Spark 集成&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Theano:&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在学术界很受欢迎&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相对的入门级&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有 Python 和 Numpy 接口&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Torch:&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;基于 Lua&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Facebook 和 Twitter 使用的内部版本&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;包含预训练模型&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;TensorFlow:&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谷歌撰写的 Theano 继承版本&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有 Python 和 Numpy 接口&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;高度多线程&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于某些问题集可能运行速度稍慢&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Caffe:&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;非通用。专注于机器视觉问题&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 C++中实现，速度非常快&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不容易扩展&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有 Python 接口&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;深度学习在线课程&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谷歌和 Udacity 合作开发了免费在线深度学习课程（https://cn.udacity.com/course/machine-learning-engineer-nanodegree--nd009），这也是 Udacity 机器学习工程师 Nano 学位的构成部分。该课程面向经验丰富的软件开发人员，针对希望在机器学习或其子专业有所专长的人员。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一个选择是非常受欢迎的 Andrew Ng 关于机器学习课程（https://www.coursera.org/learn/machine-learning），由 Coursera 和 Stanford 主办。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;深度学习相关书籍&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然许多深度学习课程对学习者的教育背景要求相当高，但 Grokking 深度学习（Grokking Deep Learning）这本书并非如此。用他们的话说：「如果你高中数学及格，并能熟练使用 Python，我就可以教你深度学习。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一本流行的书是 Deep Learning Book，内容正如其名。这是一本自下而上内容丰富的书，因为它涵盖了深度学习所需的所有数学知识。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;深度学习简要（Deep Learning Simplified）是一个很棒的 YouTube 视频系列，将深度学习分解成日常的词语和概念。下面是该系列第一个视频：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;iframe class="video_iframe" data-vidtype="1" style="   z-index:1; " height="375" width="500" frameborder="0" data-src="https://v.qq.com/iframe/preview.html?vid=b0343ceu60x&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0" allowfullscreen=""&gt;&lt;/iframe&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Sun, 06 Nov 2016 16:45:06 +0800</pubDate>
    </item>
    <item>
      <title>开源| 华为开源streamDM：用于Spark Streaming的数据挖掘软件</title>
      <link>http://www.iwgc.cn/link/3388471</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自huawei-noah.github.io&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：杜夏德&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;em style="color: rgb(136, 136, 136); font-size: 12px; text-align: justify; white-space: pre-wrap;"&gt;华为诺亚方舟实验室开源 &lt;/em&gt;stream DM ，是一种使用 Spark Streaming 挖掘大数据的开源软件。Stream DM 是 Apache Software License v2.0 许可下的开源软件。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;大数据流学习&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;大数据流学习（Big Data stream learning）比批量或离线学习更富有挑战性，因为数据在流动的过程中不太可能保持同一种分布。而且，数据流中的每一个样本只能被处理一次，否则它们就需要占用内存进行总结，同时该学习算法也必须非常高效。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Spark Streaming&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Spark Streaming（https://spark.apache.org/streaming/） 是核心 Spark API 的一个扩展，它能让多个源的数据流处理成为可能。Spark 是一个可扩展可编程的框架，用于大规模分布式数据集（也称为弹性分布式数据集（RDD））处理。Spark Streaming 接收输入的数据流后将数据分批，再由 Spark 引擎处理，生成结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Spark Streaming 数据被编成一个 DStreams 序列，内在地表示成一个 RDD 序列。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;包含以下方法：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在第一次开放的 StreamDM 中，我们部署了：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;SGD Learner (http://huawei-noah.github.io/streamDM/docs/SGD.html) 和 Perceptron (http://huawei-noah.github.io/streamDM/docs/SGD.html#perceptron)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Naive Bayes (http://huawei-noah.github.io/streamDM/docs/NB.html)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;CluStream (http://huawei-noah.github.io/streamDM/docs/CluStream.html)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Hoeffding Decision Trees (http://huawei-noah.github.io/streamDM/docs/HDT.html)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Bagging (http://huawei-noah.github.io/streamDM/docs/Bagging.html)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Stream KM++ (http://huawei-noah.github.io/streamDM/docs/StreamKM.html)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们部署了以下数据生成器&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（http://huawei-noah.github.io/streamDM/docs/generators.html）：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;HyperplaneGenerator&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;RandomTreeGenerator&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;RandomRBFGenerator&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;RandomRBFEventsGenerator&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们部署了 SampleDataWriter：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（http://huawei-noah.github.io/streamDM/docs/SampleDataWriter.html），它可以调取数据生成器创建样本数据用于模拟和测试。&lt;/span&gt;&lt;span&gt;后面我们将计划开放：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;分类：随机森林&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;回归：Hoeffding 回归树，Bagging，随机森林&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;聚类：Clustree, DenStream&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Frequent Itemset Miner：IncMine, IncSecMine&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;下一步&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了快速介绍一下 StreamDM 的运行，请打开 Getting Started （http://huawei-noah.github.io/streamDM/docs/GettingStarted.html）文件。StreamDM Programming Guide (http://huawei-noah.github.io/streamDM/docs/Programming.html) 展示了 StreamDM 的细节。完整的 API 文档，可以参考这里：http://huawei-noah.github.io/streamDM/api/index.html。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;</description>
      <pubDate>Sun, 06 Nov 2016 16:45:06 +0800</pubDate>
    </item>
    <item>
      <title>重磅论文 | 解析深度卷积神经网络的14种设计模式（附下载）</title>
      <link>http://www.iwgc.cn/link/3377505</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自arXiv.org&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀、武竞、李泽南、蒋思源、李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;这篇论文的作者是来自美国海军研究实验室的 Leslie N. Smith 和来自美国马里兰大学的 Nicholay Topin，他们在本论文中总结了深度卷积神经网络的 14 种设计模式；其中包括：1. 架构结构遵循应用；2. 扩增路径；3. 努力实现简洁；4. 增加对称性；5. 金字塔形状；6. 用训练数据覆盖问题空间；7. 过训练；8. 增量特征构造；9. 规范层输入；10. 可用资源决定网络深度；11. 转换输入；12. 求和连接；13. 下采样过渡；14. 用于竞争的 MaxOut。该论文已被提交到了 ICLR 2017。论文原文可点击文末「阅读原文」下载。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;摘要&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;深度学习领域近来的研究已经产出了大量的新架构。与此同时，也有越来越多的团队在将深度学习应用到新的应用和问题上。这些团队中的许多都可能是由没有经验的深度学习实践者构成的，他们可能会对让人眼花缭乱的架构选择感到困惑，因此会选择去使用一个更古老的架构，如 AlexNet。在这里，我们尝试挖掘近来深度学习研究中包含的集体知识（collective knowledge）以发现设计神经网络架构的基本原理，从而帮助弥合这一差距。此外，我们还描述了几种架构创新，其中包括 Fractal of FractalNet、Stagewise Boosting Networks 和 Taylor Series Networks（我们的 Caffe 代码和 prototxt 文件将会在被 ICLR 接受后公开）。我们希望这项初步的工作能够激励进一步的研究。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1.引言&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最近，关于新型神经网络架构的文章已经出现了很多，特别是关于残差网络（Residual Network）的，比如 He et al. (2015; 2016); Larsson et al. (2016); Zhang et al. (2016); Huang et al. (2016b)。这促使我们在一个更高的层面上来看待这些架构——将这些架构看作是普遍设计原理的潜在来源。这是相当重要的，因为现在有许多没有经验的实践者在想办法将深度学习应用到不同的新应用上。缺乏指导会导致深度学习实践新手忽视最新的研究而选择 AlexNet（或一些类似的标准架构），不管其是否合适他们的应用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这种研究的极大丰富也是一个机会：可以确认能为特定背景的应用带来好处的元素。我们提出了一些基本的问题：深度网络设计的普遍原理是否存在？这些原理可以从深度学习的集体知识（collective knowledge）中挖掘出来吗？哪些架构选择在哪些特定的背景（context）中效果最好？哪些架构或部分架构看起来很简洁优美？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;设计模式（design pattern）的概念最早由 Christopher Alexander (Alexander (1979)) 引入到建筑物和城镇的结构设计上。Alexander 写道：一种永恒的架构可以一直存在，这种质量可以通过基于普遍原理进行设计而实现。这种设计模式的基础是它们能在给定的背景中解决力量的冲突，并实现类似于自然生态平衡那样的均衡。设计模式既是高度特定的（使得它们可以很清楚地遵循），也是灵活的（让它们可被适配到不同的环境和情景中）。受 Alexander 的工作的启发，「gang of four」（Gamma et al. (1995)）将设计模式的概念应用到了面向对象的软件的架构设计上。这本经典的计算机科学书籍描述了 23 种可以用来解决软件设计中普遍存在的问题的模式，例如「需求总是在改变」。我们受到了之前这些在架构上的工作的启发，决定阐释神经网络架构的可能设计模式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;设计模式可以提供普遍性的指导原则，在这里我们首先要定义用于神经网络架构的设计模式。整体而言，要为所有的神经网络和所有的应用定义设计原理是一项巨大的任务，所以我们将这篇论文的范围限制在了卷积神经网络（CNN）及其基本的图像分类应用上。但是，我们认识到架构必须依赖于具备我们的第一设计模式的应用——设计模式 1：架构结构遵循应用；但相关的细节留待未来解决。此外，这些原理让我们可以发现已有研究中的一些缺陷和阐释全新的架构特征，比如 freeze-drop-path（参见 4.1 节）。这里阐述的经验法则可能对有经验的和新手的实践者都有价值。另外，我们真心希望这项初步的研究能够成为其它研究的垫脚石，能帮助其他人发现和分享其它深度学习设计模式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2.相关工作&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本节介绍和总结了其它一些神经网络架构上的相关研究工作，但由于篇幅限制，机器之心未对此节进行编译，详情请查看原论文。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3.设计模式&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;就我们所知，提供合适架构选择的指导与理解的文献资料很少。《Neural Networks: Tricks of the Trade》(Orr &amp;amp; Muller, ¨ 2003) 这本书包含了网络模型推荐，但没有参考过去几年的大量研究。与这项工作最接近的可能是 Szegedy et al. (2015b)，作者在其中描述了几种基于他们自己的经验的设计原理。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们仔细审阅了文献以提取出它们的共性并将它们的设计归结成了基本的元素——这些元素也许可被认为是设计模式。在审阅文献的过程中，我们似乎很清楚一些设计似乎是简洁优雅的，而另一些则没那么简洁优雅。在这里，我们将首先描述一些高层面的设计模式，然后再提出一些更为详细的设计模式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3.1 高层面的架构设计&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一些研究者已经指出 ImageNet 挑战赛 (Russakovsky et al., 2015) 的获胜者在不断使用越来越深度的网络（参见：Krizhevsky et al. (2012), Szegedy et al. (2015a), Simonyan &amp;amp; Zisserman (2014), He et al. (2015)）。另外在 ImageNet 挑战赛上很明显的一点是：将通过网络的路径的数量倍增是最近的一个趋势；如果看一看 AlexNet 到 Inception 到 ResNets 的演变，就能明显看到这个趋势。比如说，Veit et al. (2016) 表明 ResNets 可被看作是带有不同长度的网络的指数集合（exponential ensemble）。这引出了设计模式 2：扩增路径。开发者可以通过将多个分支包含在架构中来实现。最近的例子包括 FractalNet (Larsson et al. 2016)、Xception (Chollet 2016) 和决策森林卷积网络（Decision Forest Convolutional Networks (Ioannou et al. 2016)）。我们甚至可以更进一步预测今年的 ImageNet 获胜者也还会增加他们的架构中的分支数量，而不是继续增加深度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;科学家们已经拥抱简洁性/简约性（simplicity/parsimony）几个世纪了。简洁性的例子可参考论文「Striving for Simplicity」(Springenberg et al. 2014)，其使用更少类型的单元实现了当时最佳的结果。我们将其加为设计模式 3：努力实现简洁——使用更少类型的层以保持网络尽可能简单。我们还在 FractalNet (Larsson et al. 2016) 设计中注意到了一种特定程度的简洁性，我们将其归功于其结构的对称性。架构的对称性（architectural symmetry）通常被看作是美丽和质量的标志，所以我们在这里得到了设计模式 4：增加对称性。除了对称性以外，FractalNets 还遵循了「扩增路径」设计模式，所以它是我们第 4 节的实验的基础。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了理解相关的力量，考察权衡是设计模式的关键元素。一种基本的权衡是最大化表征的力量 vs 冗余的和非区分的信息的压缩。这普遍存在于所有卷积神经网络中，从数据到最后的卷积层，激活（activation）被下采样（downsample）并且信道数量增加。一个例子是深度金字塔残差网络（Deep Pyramidal Residual Networks (Han et al. (2016))）。这让我们得到了设计模式 5：金字塔形状，其中在整个架构中应该有一次整体的平滑的下采样，而且该下采样应该与信道数量的增长结合起来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;深度学习中另一个重要的权衡是：训练精度 vs 网络泛化到其从未见过的案例的能力。泛化的能力是深度神经网络的一个很重要的性质。一种提升泛化的方法是设计模式 6：用训练数据覆盖问题空间（Ratner et al. 2016, Hu et al. 2016, Wong et al. 2016, Johnson-Roberson et al. 2016）。这让训练精度可以直接提升测试精度。此外，正则化（regularization）常被用于提升泛化。正则化包括 dropout (Srivastava et al. 2014a) 和 drop-path (Huang et al. 2016b) 等方法。正如 Srivastava et al. 2014b 指出的那样，dropout 可通过向架构中注入噪声来提升泛化能力。我们将在训练过程使用正则化技术和谨慎的噪声注入可以提升泛化（Srivastava et al. 2014b, Gulcehre et al. 2016）的结论归结为设计模式 7：过训练（over-training）。过训练包含网络在一个更艰难的问题上训练的任何训练方法——该问题的难度超过了必要，因此在更容易的推理情况中的表现可以得到提升。除了正则化方法，设计模式 7 还包括有噪声的数据的使用（Rasmus et al. 2015, Krause et al. 2015, Pezeshki et al. 2015）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3.2 细节上的架构设计&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;很多更成功的架构的一个共同点是使每个层更容易完成任务。使用极深层网络（very deep network）就是这样的例子，因为任何单个层只需要递增地修改输入。这部分解释了残差网络（residual network）的成功，因为在极深层网络中，每层的输出可能与输入相似，因此将输入代替层的输出能使层更容易完成任务。这也是扩增路径设计模式背后的一部分动机，但是使每个层简化任务的想法超越了这一概念。设计模式 8 ：增量特征构造（Incremental Feature Construction）的一个例子是在 ResNets 中使用短距离跳跃（skip）。最近的一篇论文（Alain &amp;amp; Bengio (2016)）证明在深度 128 的网络中使用长度为 64 跳越会导致网络的第一部分不训练，并且导致不变化的权重，这是需要避免的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;设计模式 9：规范层输入（Normalize layer inputs）是另一个简化层任务的方法：使层输入标准化。已经显示，层输入的标准化能改善训练结果和提高准确性，但是潜在机理并不清楚（Ioffe &amp;amp; Szegedy 2015, Ba et al. 2016, Salimans &amp;amp; Kingma 2016）。Batch 标准化的论文（Ioffe &amp;amp; Szegedy 2015）将提高归因于解决内部协变量偏移问题，而流标准化（streaming normalization）的作者（Liao et al. 2016）认为这也许是其它原因造成的。我们认为标准化使所有输入样本更加平等，就好像它们通过单位转换进行缩放一样，这使得反向传播（back-propagation）训练更有效。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一些研究，如 Wide ResNets（Zagoruyko &amp;amp; Komodakis 2016），显示增加信道（channel）的数量提高了性能，但是多余的信道会产生额外的代价。许多基准数据集的输入数据有 3 个通道（即颜色 RGB）。几乎是普遍现象，CNN 的第一层的输出增加了信道的数量。设计模式 11：转换输入。增加信道的几个例子 / ImageNet 的第一层输出的数量分别为 AlexNet (96)，Inception (32)，VGG (224)，以及 ResNets (64)。直观上讲，第一层中信道数量从 3 增加是合理的，因为它允许以多种方式检查输入数据，但是不清楚使用多少个过滤器。另一个是成本与精确度的权衡。成本包括网络中的参数的数量，这直接反映在训练的计算量和存储成本中。增加信道数量会增加成本，这导致设计模式 10：可用资源决定网络深度。除了在下采样（down-sampling）时使输出数量加倍（见设计模式 13），根据内存、计算资源和期望的精确度来选择第一层的深度。深度学习的计算开销很高，每个从业者必须平衡这些成本与其应用程序的性能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3.2.1 分支连接：串联、求和/平均与 Maxout&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当存在多个分支时，有三种方法来合并输出：串联、求和（或平均）与 Maxout。目前看来研究人员对它们的看法各不相同，没有哪一种方式更具优势。在本节中，我们提出一些简单的规则来决定如何合并分支。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;求和是合并输出的最常见方法之一：求和/平均将分支间的近似工作分割，最终形成设计模式 12：求和连接（Summation Joining）。求和是残差网络的最佳连接机制。因为它允许网络计算校正项（即残差）而无需整个信号。sum 和 fractal-join（平均）之间的差异最好通过 drop-path 来理解（Huang et al.，2016）。在输入跳跃连接总是存在的残差网络中，求和能使卷积层学习残差（与输入的差）。另一方面，在具有若干分支的网络中，如 FactalNet（Larsson et al.，2016），使用均值是最佳方式，因为随着分支被随机丢弃，它可以保证输出平顺。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一些研究者似乎更喜欢串联（concatenation，例如 Szegedy et al，2015）我们相信串联对于增加池化时的输出数量是最有用的，这让我们得到了设计模式 13：下采样过渡（Down-sampling Transition）。这就是说，当池化或使用步幅（stride）超过 1 的下采样时，组合分支的最好方法是串联输出信道，它可以平滑地实现通常以下采样方式实现的信道连接和信道数量增加。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Maxout 已经被用于竞争，如本地竞争网络（Srivastava 等人，2014）和多尺度竞争网络（Liao 与 Carneiro，2015）Maxout 只选择一种激活，形成设计模式 14：MaxOut for Competition。它与求和或平均「合作」的激活方式相反，其中存在「竞争」关系，只有一个「赢家」。例如，当分支由不同大小的核（kernel）组成时，Maxout 可用于尺度的不变性，这类似于最大池化（max pooling）的平移不变性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们认为所有这些连接机制可以同时加入单独网络，不同于典型情况。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9H8eXM2kHRdtPPzmmGVKfMoZKibvyjic6RNFKY4Pqst8zLTUcMAdvyLva0m0R2oKanPbPYhX4nZfCw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 1：这是 FractalNet 模块（a）和 FoF 架构（b）。曾表示如下：卷积层粉红色，连接层（如均值）是绿色，池层是黄色，预测层是蓝色。（b）中的灰色模块表示（a）中的 FractalNet 实例。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;4 实验&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;4.1 架构创新&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本论文的重点是阐明基本设计原则，这样做的原因就是帮助我们发现一些架构上的创新，在本节中，这些创新将进一步被描绘出来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先，我们建议将求和/平均、串联和 maxout 连接机制与单一架构中的不同角色结合起来。接下来，通过增加分支的设计模式 2 来让我们能够大规模修饰 FractalNet 架构的顺序。最后按照我们称之为 Fractal of FractalNet (FoF) 网络，也就是 1b 中展示的分形模式调整模块，而不是按照最大深度来调整。该架构可将深度替换成更大数量的路径。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;4.1.1 Freeze-Drop-Path 和 Stagewise Boosting Networks（SBN）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Drop-path 是被 Huang 等引进的（2016b）. 它通过迭代训练随机移除分支路径，就好像这条路径在整个网络中是不存在的。出于对对称性的考虑，我们使用了一个叫 freeze-path 的相反的方法。我们冻结权重来达到零的学习率（learning rate），而不是在训练期间直接移除网络中的分支路径。循环神经网络领域也已经有一种类似的想法被提了出来 (Krueger et al. 2016)。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们称结合了 drop-path 和 freeze-path 效用的模型为 freeze-drop-path，这个可以在非随机情况下得到很好的解释。图 1 显示了一个 FractalNet 分形结构。我们从最左侧路径开始训练，并将 drop-path 应用到其他分支上面。这个分支的训练速度会很快，因为相对于整个网络只需要训练少量的参数。随后冻结那条分支路径的权重并激活在原来右边的一条分支路径。最左边的分支也就可以提供一个很好的近似函数，并且下一条分支也能在矫正的基础上运行了。因为下一个分支路径相比前一个包含了更多的层，所以和原来的相比更容易逼近矫正项的近似值，因此这样的分支允许网络获得更大的准确性。这样也就可以继续从左至右来训练整个网络。freeze-drop-path 将最后加入 FoF 架构（图片 1b），这个称之为梯度递增网络（Stagewise Boosting Networks (SBN)），因为它就是类似于梯度递增的（Friedman et al. 2001）。递增神经网络 (boosting neural network；Schwenk &amp;amp; Bengio 2000) 并不是个新概念，但是这个构架就是新的。在 B 部分我们将讨论测试的实施。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;4.1.2 泰勒级数网络（Taylor Series Netwroks，TSN）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;泰勒级数是一个经典的、众所周知的函数逼近方法。泰勒级数的扩展是：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;由于神经网络也是函数近似，将网络的分支（branch）看成一个泰勒级数展开的项，它可以作为 SBN 的延伸。这意味着，在求和连接单元（summation joining unit）之前使第二分支的结果平方，类似于泰勒展开中的二阶项。类似地，使第三分支立方。我们将它称作「泰勒级数网络」（TSN），并且存在多项式网络的优先级（Livni et al. 2014）和网络中的乘式项（例如 Lin et al. 2015 年的论文）。TSN 与 SBN 类比的实现细节详见附录讨论。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;4.2 结果&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该章节内的实验主要是验证上面提到的架构创新的验证，但并非完全进行测试。未来会有更完整的评估。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9H8eXM2kHRdtPPzmmGVKfMXZnhzEGhib28CCoMjV0icy0CichWxZFiaNWHSsWwz7qRNMz4B3ibGFQNRYg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;表 1：在 CIFAR-10 和 CIFAR-100 上各种架构的测试准确率对比。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9H8eXM2kHRdtPPzmmGVKfMbQeIqKibKIgUdQx91GCQEhhDgicHjlqdoFPv8bzQgjB1UbEytm6FQP2w/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 2：对比原 FractalNet 与用 Concatenation 或 Maxout 替代了一些 fractal-joins 的 FractalNet。同样展示的还有当用平均池化替代了最大池化时的测试准确度。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9H8eXM2kHRdtPPzmmGVKfM0yS5vLEpsH4qpFrOo7nanbukINFzwNe51Cy9oFHmaN7aSiaKpu5Rs0Q/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 3：对比原 FractalNet 与用 Concatenation 或 Maxout 替代了一些 fractal-joins 的 FractalNet。同样展示的还有当用平均池化替代了最大池化时的测试准确度。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;表一和图 3 接下来对比 4.1 章节中描述的架构创新的最终测试准确率的结果。最终的结果显示要比 FractalNet 基线差一点，但从 3a 和 3b 图中可以明显看到新架构训练起来要比 FractalNet 更快。FoF 架构最终测试准确率类似于 FractalNet，但 SBN 和 TSN 架构（使用 freeze-drop-path）在学习率下降的时候准确率会落后。这在 CIFAR-100 上要比 CIFAR-10 更加明显，表明这些架构可能更适合带有大量分类的应用。但是，我们也遗留下了对更多合适应用的探索，以后再做。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;5. 结论&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在此论文中，我们描述了通过研究近期深度学习论文中的新架构而发现的卷积神经网络架构的设计模式。我们希望这些设计模式对希望推进前沿结果的有经验的实践者和寻求深度学习新应用的新手都有所帮助。接下来也有许多的潜在工作可以做，一些工作我们也在此论文中有所指明。我们的努力主要限定在进行分类的残差神经网络，但希望这一初步工作能启发其他人进行循环神经网络、深度强化学习架构等等其它网络的架构设计模式的研究。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Sat, 05 Nov 2016 14:40:38 +0800</pubDate>
    </item>
    <item>
      <title>产品 | 机缘巧合诞生的讯飞语音输入法，如何累积了 4 亿用户？</title>
      <link>http://www.iwgc.cn/link/3377506</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心原创&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：虞喵喵&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 10 月 18 日的锤子发布会上，除焦点 M1L 之外，语音输入部分惊艳了不少观众。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;台上的老罗对着手机说出「今天上午，我们一行人从火车站来到了洲际酒店」，被迅速识别转换成文字出现在手机屏幕上。接着，老罗开始「长时间的胡说八道」，讲了一段自己没吃晚饭不舒服、吃药、喝冰水、来不及去医院、直接上发布会的过程。16 秒不间断的高语速大段口语内容，不到 1 秒便准确呈现在屏幕上，现场雷鸣般的掌声和欢呼声久久不能平息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9H8eXM2kHRdtPPzmmGVKfMxbh2TeZWg3qUm2RA8jy7sR6ZInPM1SjicVGU2HaWibdQ3xtUkMkUOCyw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;老罗现场「胡说八道」的内容&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;老罗的现场演示展示出语音输入的便捷、可靠与高效。支持这一切的，正是讯飞输入法的语音输入功能。自 2010 年发布以来，讯飞输入法已累积超 4 亿用户，活跃用户超 1.1 亿。据称，随着深度学习技术的不断突破和应用，其语音识别准确率高于 97%，1 分钟可识别 400 字。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 11 月 2 日的讯飞输入法沟通会上，讯飞输入法产品总监翟吉博分享了讯飞输入法背后的故事，包括这是一个最初仅 4 人的「小项目」、涟漪效应为这款输入法带来的提升、以及他们对输入法这一产品的思考。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;三个月，四个人&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2010 年 6 月 8 日，苹果发布了拥有「100 多项创新设计」的经典产品 iPhone 4，引发全球排队购机热潮。据称，iPhone4 的全球销量虽次于诺基亚「神机」1100，但总销售量也超过 1 亿大关。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不过 iPhone 4 屏幕仅为 3.5 英寸。虽说在当时已经算「大屏」，但现在看来也不过是 iPhone7plus 屏幕的二分之一，用全键盘打字时仍有不少困难。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;既然用手指输入文字体验不好，可不可以用语音输入？当时做语音相关工作的翟吉博「基于纯技术的思维，将手写输入、语音识别和拼音放在一起，做出了输入法的 Demo」。虽然自己不以为意，但当时的上司看到成果，认为这个产品应该让更多人使用。于是技术出身的翟吉博，开始了学习了解市场、分析用户需求，成为了一名「产品经理」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9H8eXM2kHRdtPPzmmGVKfMSaDlEs69wEmkljRNLicP2twtyVyPsUxoKLKKnn5tWzgpso2gxLrjhMw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;通过讯飞听见，嘉宾分享的内容可以实时呈现在屏幕上&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2010 年 10 月，在 iPhone4 发售 4 个月后，讯飞输入法正式上线。6 年积累，曾经由 4 人小团队封闭 3 个月打造的产品，已经牢牢占据各大应用商店输入法类下载量第二。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为什么是讯飞？回想这款输入法出现的时机，虽然 PC 上已有搜狗输入法、百度输入法等相关产品，但移动端市场还处在前期，针对手机端优化的输入法还是空白。「我们认为手机端的输入方式会发生变化，语音交互的比重会越来越大。而且语音输入已经达到可使用的基本门槛，加上对涟漪效应的理解，我们认为通过几年的时间，讯飞输入法可以成熟。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如今的讯飞输入法团队成员，最开始多是热心用户。曾在论坛里吐槽功能不好用、给产品经理提建议的粉丝成为了讯飞输入法的运营经理，机锋论坛里做 ROM 的「大神」正在负责起渠道推广。曾在电脑城卖过光盘、做过网站，因设计输入法皮肤获奖的用户，也成为了讯飞输入法的专职皮肤设计师。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;如何获取更多用户？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;满足了使用的基本需求后，如何让更多人使用这款产品？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;经过细致的思考和调研，翟吉博团队发现用户在使用语音输入时有四种需求需要被满足：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先是网络，当时的讯飞输入法需要调用云端极度依赖网络，但移动互联网并不稳定，用户对流量也很敏感；其次是方言，不同方言区的用户的特殊词难以被识别；再其次是个性化语言，不同的人有不同的语言习惯、说话方式和自己的惯用词汇；最后是跨语言交流，让不同语言的人可以通过文字互相了解，方便沟通。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过推出离线版、方言版、学习个人习惯和中英文实时翻译等版本和功能，讯飞输入法不断满足着这些需求。目前讯飞输入法支持包括粤语、东北话、河南话、四川话能在内近 20 种方言，「秃噜皮儿」、「辣子」等名词都能被迅速识别；选择中英文翻译功能，对准话筒说中文，屏幕上会自动翻译为英文。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9H8eXM2kHRdtPPzmmGVKfMm1TsaHFtia5CN7SEicPnGWEibhYNFjEWu7Ux9Q0ksAKukNCceQDBukj7w/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;产品总监翟吉博现场展示方言版效果，「巴适」、「马路牙子」都能识别出来&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除此之外，为满足明星粉丝用户的需求，推出了明星皮肤和图片；为满足二次元用户，可以用讯飞输入法上轻松打出颜文字，甚至还有斗图功能……&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这大概是对用户最友好的输入法了。作为高依赖度的工具类产品，获得 4 亿累计用户，1.1 亿活跃用户似乎也就不足为奇。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;为什么识别得快又准？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;世界上最早的语音识别系统是由 AT&amp;amp;T 贝尔实验室开发的 Audrey，可以识别 10 个英文数字。到了 1960 年代，人工神经网络被引入语音识别，两大突破是线性预测编码（Linear Predictive Coding，LPC) 与动态时间弯折（Dynamic Time Warp），不过大都是基于单词、孤立词或是特例人的研究。上世纪 80 年代末，李开复实现了基于隐马尔科夫模型的大词汇量语音识别系统 Sphinx，才完成了语音识别向随机内容、非特例人的句子识别的转变。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;直到 2010 年，深度神经网络技术开始应用于语音识别，识别的效果和速度才得到了跨越式的提升。通过海量训练语料基础上的高精度声学模型和语言模型训练，结合解码引擎工程技术，人工智能技术的加入给语音识别带来全新的发展前景。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9H8eXM2kHRdtPPzmmGVKfMd3tajJ4gmMOGlKMjiacYEoQ0mVyUDjDyyO7YPXvMW0SQY0WJtrs1W9Q/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;主流语音识别系统框架&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不过仅有核心技术的提升是不够的，对于深度神经网络来说，真实的数据就是养料和智慧。科大讯飞轮值总裁胡郁曾用「涟漪效应」解释过数据和技术应用的关系：当某一项核心技术刚刚被大众所使用时，就像一滴水滴入水面，水波纹的起伏就是核心技术与用户期望之间的误差。水波纹逐步传播，就像核心技术正在逐步被更多的用户所使用，虽然这时效果还不太好，接触到的用户也不多，但这些用户不知不觉中贡献的经验和数据已经被系统自动学习和更新。当水波纹向外扩散，接下来接触到核心技术的人已经在使用更新过的系统。随着使用的人群越来越多，水波纹扩散的越来越广，大家会发现其实水波的振幅也越来越小，系统的性能也大幅提高。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;正是 6 年间用户不断的贡献真实数据，才让讯飞输入法达到了「语音输入通用识别率为 97%，正常的语音输入文字已经不再有很大障碍」的程度，用户体验也在这一过程中逐步提升。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除了语音识别，讯飞输入法的手写识别部分也用到了神经网络和图像识别技术，还可以支持连续书写的文字识别。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这样一个「低头时代」，又会有多少人选择语音输入？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;答案可能远比想象的多。讯飞输入法后台数据显示，虽不是主要输入手段，语音输入的用户比例一直在提升，已经接近手写输入的比例。在这个追逐效率的时代，选择语音输入的用户大概会越来越多。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以及，如果真的很忙来不及发文字，可以考虑试一试语音输入。毕竟在微信上收五条 60 秒语音的经历，有过一次就不想再有一次啦。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心原创，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Sat, 05 Nov 2016 14:40:38 +0800</pubDate>
    </item>
    <item>
      <title>业界 | DeepMind牵手暴雪：要让人工智能征服星际争霸</title>
      <link>http://www.iwgc.cn/link/3377507</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Bloomberg&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Jeremy Kahn&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李泽南、蒋思源&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;谷歌的 DeepMind 团队在今年 3 月刚刚使用 AlphaGo 击败了围棋世界冠军李世乭，现在他们终于把注意力转向了经典即时战略游戏《星际争霸 2》。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;DeepMind 刚刚在一年一度的 Blizzcon 上宣布他们与著名游戏公司暴雪达成了协议，在《星际争霸》系列游戏中进行合作，这家隶属谷歌的公司将在游戏平台中引入机器学习方法，进行人工智能研究。DeepMind 总部位于伦敦，在 2014 年被谷歌以 4 亿英镑巨资收购。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前，DeepMind 还没有宣称自己的程序已经能够玩《星际争霸》了。「要打败人类职业选手，我们还有很长的路要走。」DeepMind 科学家 Oriol Vinyals 说道（此人曾是西班牙顶尖的星际争霸玩家），但公司在活动上的声明表示现在他们正像对待围棋一样认真对待《星际争霸》，并决心以此作为机器智能研究的突破点。&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;《星际争霸》一直被人工智能研究者视为下一个目标，因为它相比国际象棋与围棋更接近「复杂的现实世界」，Vinyal 表示：「能玩《星际争霸》的人工智能必须能够有效利用记忆，能够进行长期战略规划，同时还得根据不断出现的新情况做出反应调整。以这种标准开发的机器学习系统，最终完全可以应用到现实世界中的任务中去」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;双方的合作目前仍在开始阶段，暴雪《星际争霸 2》首席制作人 Chris Sigaty 说道：「目前我们正在进行一系列讨论。」他同时表示目前《星际争霸 2》的电脑玩家与 DeepMind 想要实现的人工智能系统有很大区别：「它们的设计难度不在一个级别上，游戏中的电脑玩家其实有一点「作弊」，因为它可以得知人类玩家无法知道的信息，例如电脑可以在同一时间向所有单位发出指令，即使对于你来说有些单位「不在屏幕中」。暴雪制作电脑玩家的目的是创造一个比人类更强的 AI 玩家，同时保证它受到游戏规则的约束。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;虚拟扩张&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在《星际争霸》里，游戏实时在线进行，玩家需要从三个种族之中选择一个进行游戏，每个种族都有不同的优缺点。玩家在游戏中必须掌控生产，探索地图，开采水晶和气矿，然后开拓新的矿点。富有经验的玩家会记住地图中的大量信息以获得优势，即使地图还未被探索。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;玩家的视角下，对手的信息是有限的——这与围棋这样的棋盘游戏不同。而且，不像棋类游戏的回合制玩法，机器学习系统在即时战略游戏中需要不断适应变化的环境。《星际争霸》需要玩家能够同时具有长期战略规划与应变对手的快速决策能力——设计能够同时处理这两种类型任务的系统对于研究人员来说是一个巨大的挑战。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Facebook 和微软的行动&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Facebook 和微软的人工智能研究者们都已发表过人工智能在《星际争霸》一代中进行游戏的研究。一些玩《星际争霸》的机器人已经被开发出来，但目前这样的程序距离击败人类职业玩家还相去甚远。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;微软 CEO 萨提亚·纳德拉对谷歌在人工智能研究中注重游戏的路线进行过抨击，他曾在 9 月份亚特兰大的一次活动中告诉观众「微软不会把钱花在让人工智能在游戏中击败人类」，微软希望把人工智能「用在解决急迫的社会与经济问题上去」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;电子游戏一直是人工智能研究和测试的重要组成部分。在二十世纪九十年代中期，IBM 的超级计算机「深蓝」数次击败了国际象棋世界冠军卡斯帕罗夫。后来到了 2011 年，IBM 的沃森人工智能在游戏《危险边缘》就击败了最优秀的人类玩家，并展示了 IBM 在自然语言处理的进展。早在 2015 年，DeepMind 就开始使用机器学习来训练人工智能玩一些复古的雅达利游戏（Atari games），并使其至少能做得和人类一样好。后来在 2016 年的三月份，DeepMind 通过另一种方法训练了 Alpha Go，并击败了围棋世界冠军李世乭。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;《星际争霸》自从 1998 年发行以来，已经积累了大量的忠实粉丝。在第一个十年里就售出了 950 多万册的原版游戏，其中超过一半的销售量出现在韩国，它在那里实在是太受欢迎了。2011 年发行的《星际争霸 2》以 48 小时内售出 150 万册打破了即时战略游戏的销售记录。让两个玩家实时互相对垒，这种方式使《星际争霸》成为首屈一指的专业视频竞赛游戏。尽管它的地位目前已被其他游戏取代，但仍然是一个重要的世界级电竞游戏。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9H8eXM2kHRdtPPzmmGVKfMrWRibw2pDuP2B29ytmnR9wyKXYYvDaIkNYewdP6DiacDc5GaBfEz4rfg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;em style="text-align: center;"&gt;&lt;span&gt;DeepMind这次的对手也许不是韩国人，在WCS2016中，美国选手Neeb获得了世界冠军&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;暴雪和 DeepMind 计划在明年第一季度发布一个新环境，对所有人工智能研究人员开放。在新界面里，《星际争霸 2》的图形将被简化以便于机器学习系统进行识别，同时他们也将开放 API，允许系统读取游戏中的数据，实现原先电脑玩家的部分功能。暴雪将在未来发布游戏 replay 文件数据集以供机器学习。DeepMind 的最终目标是让人工智能系统和人类玩家一样，通过处理视觉信息理解游戏。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;那么什么时候人工智能可以击败世界冠军呢？暴雪和 DeepMind 都对此持谨慎态度，两者都没有给出一个确切的日期，虽然 AlphaGo 的胜利比大多数人预测的要早。「我认为人工智能的支持者们会很兴奋，以至于曲解我们的话。」Sigaty 说道，所有人都十分期待这一刻。无论这需要多久时间，现在基础已经打下，《星际争霸 2》的舞台上，又一段传奇即将上演。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Sat, 05 Nov 2016 14:40:38 +0800</pubDate>
    </item>
    <item>
      <title>资源 | TensorFlow 生态系统：与多种开源框架的融合</title>
      <link>http://www.iwgc.cn/link/3377508</link>
      <description>&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Github&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;该 repository 包含 TensorFlow 与其他开源框架融合的样例。这些样例是有限的，但可以作为模板使用。用户也可以根据自己的使用情况特制这些模板。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;项目地址：https://github.com/tensorflow/ecosystem&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;内容：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;docker-Docker 配置用来在 cluster managers 上运行 TensorFlow&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;kubernetes-用来在 kubernetes 上运行分布式 TensorFlow 的模板&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;marathon-使用 Marathon 用来运行分布式 TensorFlow 的模板，在 Mesos 上部署&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;hadoop-为 Hadoop MapReduce 和 Spark 备录 InputFormat/OutputFormat 的 TFRecord 文件&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;分布式训练的常见设置&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;每个分布式训练项目都有一些常见设置。首先，定义 flags，以便于该 worker 知道其他 works 在分布式训练中扮演的角色：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;# Flags for configuring the task&lt;br/&gt;flags.DEFINE_integer("task_index", None,&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; "Worker task index, should be &amp;gt;= 0. task_index=0 is "&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; "the master worker task the performs the variable "&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; "initialization.")&lt;br/&gt;flags.DEFINE_string("ps_hosts", None,&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"Comma-separated list of hostname:port pairs")&lt;br/&gt;flags.DEFINE_string("worker_hosts", None,&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"Comma-separated list of hostname:port pairs")&lt;br/&gt;flags.DEFINE_string("job_name", None, "job name: worker or ps")&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然后，开始自己的 server。因为 worker 和 parameter servers（ps jobs）通常共享常见的程序，parameter servers 应该在此停顿，所以他们和该 server 可以结合。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;# Construct the cluster and start the server&lt;br/&gt;ps_spec = FLAGS.ps_hosts.split(",")&lt;br/&gt;worker_spec = FLAGS.worker_hosts.split(",")&lt;br/&gt;&lt;br/&gt;cluster = tf.train.ClusterSpec({&lt;br/&gt; &amp;nbsp; &amp;nbsp;"ps": ps_spec,&lt;br/&gt; &amp;nbsp; &amp;nbsp;"worker": worker_spec})&lt;br/&gt;&lt;br/&gt;server = tf.train.Server(&lt;br/&gt; &amp;nbsp; &amp;nbsp;cluster, job_name=FLAGS.job_name, task_index=FLAGS.task_index)&lt;br/&gt;if FLAGS.job_name == "ps":&lt;br/&gt; &amp;nbsp;server.join()&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;之后，代码的不同由你打算做的分布式训练的形式所决定。最常见的形式是图间复制（between-graph replication）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Between-graph Replication&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在此模式中，每个 worker 独立构建同一图。然后每个 worker 独立运行该图，只和 parameter servers 共享梯度。该设置可又下图进行解释，注意每个虚线框表示一个任务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9H8eXM2kHRdtPPzmmGVKfMU9icFb5ttxdcfsOaIgtQ29e1xdWtAH9b6t3QnhySJwhEhI1sG7CJe2g/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在为该训练模式构建图之前，你必须明令设置此设备。下面的代码显示了该设置：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;with tf.device(tf.train.replica_device_setter(&lt;br/&gt; &amp;nbsp; &amp;nbsp;worker_device="/job:worker/task:%d" % FLAGS.task_index,&lt;br/&gt; &amp;nbsp; &amp;nbsp;cluster=cluster)):&lt;br/&gt; &amp;nbsp;# Construct the TensorFlow graph.# Run the TensorFlow graph.&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;运行这些样例的需求&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了运行这些样例，Jinja 模板必须被安装：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;# On Ubuntu&lt;br/&gt;sudo apt-get install python-jinja2&lt;br/&gt;# On most other platforms&lt;br/&gt;sudo pip install Jinja2&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Jinja 是用作模板的扩展。还有其他的特定框架需求，请阅读 README 文件查看每个框架的需求。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Sat, 05 Nov 2016 14:40:38 +0800</pubDate>
    </item>
    <item>
      <title>一周论文| 文本摘要</title>
      <link>http://www.iwgc.cn/link/3377509</link>
      <description>&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;span&gt;&lt;strong&gt;引&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;文本摘要是自然语言处理的一大经典任务，研究的历史比较长。随着目前互联网生产出的文本数据越来越多，文本信息过载问题越来越严重，对各类文本进行一个“降维”处理显得非常必要，文本摘要便是其中一个重要的手段。传统的文本摘要方法，不管是句子级别、单文档还是多文档摘要，都严重依赖特征工程，随着深度学习的流行尤其是seq2seq+attention模型在机器翻译领域中的突破，文本摘要任务也迎来了一种全新的思路。本期PaperWeekly将会分享4篇在这方面做得非常出色的paper：&lt;/p&gt;&lt;p&gt;1、A Neural Attention Model for Abstractive Sentence Summarization, 2015&lt;br/&gt;2、Abstractive Text Summarization using Sequence-to-sequence RNNs and Beyond, 2016&lt;br/&gt;3、Neural Summarization by Extracting Sentences and Words, 2016&lt;br/&gt;4、AttSum: Joint Learning of Focusing and Summarization with Neural Attention, 2016&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;span&gt;&lt;strong&gt;1、A Neural Attention Model for Abstractive Sentence Summarization&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="作者" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;作者&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Rush, A. M., Chopra, S., &amp;amp; Weston, J.&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="单位" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;单位&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Facebook AI Research / Harvard SEAS&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="关键词" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;关键词&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Neural Attention, Abstractive Sentence Summarization&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="文章来源" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;文章来源&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;EMNLP 2015&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="问题" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;问题&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;这篇来自Facebook的paper的主题是基于attention based NN的生成式句子摘要/压缩。&lt;/p&gt;&lt;p&gt;&lt;a title="1" class="" rel="gallery0" style="color: rgb(37, 143, 184); max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgnYVBY4h2lIdnkAFQHjjYTsM6P0uRGicib5XMWHQl2WDqsJnMOB89YGWHroJsbzaEicB0r20iaerUNyWA/640?wx_fmt=jpeg"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="模型" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;模型&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;该工作使用提出了一种encoder-decoder框架下的句子摘要模型。&lt;/p&gt;&lt;p&gt;&lt;a title="encoder" rel="gallery0" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgnYVBY4h2lIdnkAFQHjjYTsx8La2MOcmlq0xqh13k3PlbcqriciaynHD5rMYNUe7nDXV4xibqhicAyNRQ/640?wx_fmt=jpeg"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;作者在文章中介绍了三种不同的encoding方法，分别为：&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="list-style-type: lower-alpha;"&gt;&lt;li&gt;&lt;p&gt;Bag-of-Words Encoder。词袋模型即将输入句子中词的词向量进行平均。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;CNN encoder&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Attention-Based Encoder。该encoder使用CNN对已生成的最近c（c为窗口大小）个词进行编码,再用编码出来的context向量对输入句子做attention，从而实现对输入的加权平均。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;模型中的decoder为修改过的NNLM，具体地：&lt;/p&gt;&lt;p&gt;&lt;a title="1" rel="gallery0" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgnYVBY4h2lIdnkAFQHjjYTs8blhWgkdoyBibRWTQTu0rR917ycUbUm2nTqxAleXmXFGt1SoQBJJKiag/0?"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;式中y_c为已生成的词中大小为c的窗口，与encoder中的Attention-Based Encoder同义。&lt;/p&gt;&lt;p&gt;与目前主流的基于seq2seq的模型不同，该模型中encoder并未采用流行的RNN。&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="数据" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;数据&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;该文章使用了English Gigaword作为语料，选择新闻中的首句作为输入，新闻标题作为输出，以此构建平行语料。具体的数据构建方法参见文章。此外，该文章还使用了DUC2004作为测试集。&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="简评" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;简评&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;在调研范围内，该文章是使用attention机制进行摘要的第一篇。且作者提出了利用Gigaword构建大量平行句对的方法，使得利用神经网络训练成为可能，之后多篇工作都使用了该方法构建训练数据。&lt;/p&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;br/&gt;&lt;/h1&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;span&gt;&lt;strong&gt;2、Abstractive Text Summarization using Sequence-to-sequence RNNs and Beyond&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="作者" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;作者&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Nallapati, Ramesh, et al.&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="单位" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;单位&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;IBM Watson&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="关键词" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;关键词&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;seq2seq, Summarization&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="文章来源" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;文章来源&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;In CoNLL 2016&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="问题" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;问题&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;该工作主要研究了基于seq2seq模型的生成式文本摘要。&lt;br/&gt;该文章不仅包括了句子压缩方面的工作，还给出了一个新的文档到多句子的数据集。&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="模型" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;模型&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;a title="" rel="gallery0" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgnYVBY4h2lIdnkAFQHjjYTsgtn4GR8WU5SskYLJKL7l3ct7bONsUIFebXfYEclemKRswaPr4YOHlA/640?wx_fmt=jpeg"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;该文章使用了常用的seq2seq作为基本模型，并在其基础上添加了很多feature：&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="list-style-type: lower-alpha;"&gt;&lt;li&gt;&lt;p&gt;Large Vocabulary Trick。&lt;br/&gt;参见Sébastien Jean, Kyunghyun Cho, Roland Memisevic, and Yoshua Bengio. 2014. On using very large target vocabulary for neural machine translation. CoRR, abs/1412.2007.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;添加feature。例如POS tag， TF、IDF， NER tag等。这些feature会被embed之后与输入句子的词向量拼接起来作为encoder的输入。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;pointing / copy 机制。使用一个gate来判断是否要从输入句子中拷贝词或者使用decoder生成词。参见ACL 2016的两篇相关paper。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Hierarchical Attention。这是用于文章摘要中多句子的attention，思路借鉴了Jiwei Li的一篇auto encoder的工作。大致思路为使用句子级别的weight对句子中的词进行re-scale。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="数据" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;数据&lt;/strong&gt;&lt;/h2&gt;&lt;ol class=" list-paddingleft-2" style="list-style-type: lower-roman;"&gt;&lt;li&gt;&lt;p&gt;English Gigaword&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;DUC 2004&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;提出了CNN/Daily Mail Corpus&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="简评" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;简评&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;该工作为在第一篇文章基础上的改进工作，做了大量的实验，非常扎实。文章提出的feature-rich encoder对其他工作也有参考意义，即将传统方法中的特征显式地作为神经网络的输入，提高了效果。&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;span&gt;&lt;strong&gt;3、Neural Summarization by Extracting Sentences and Words&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="作者" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;作者&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Cheng, Jianpeng, and Mirella Lapata.&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="单位" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;单位&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;University of Edinburgh&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="关键词" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;关键词&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Extractive Summarization, Neural Attention&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="文章来源" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;文章来源&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;ACL 2016&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="问题" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;问题&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;使用神经网络进行抽取式摘要，分别为句子抽取和单词抽取。&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="模型" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;模型&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;a title="" class="" rel="gallery0" style="color: rgb(37, 143, 184); max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgnYVBY4h2lIdnkAFQHjjYTsRw8Z6DNxGnR8PiaepwSNPEiaDT3ZbibCicenGHU7nU0pSOSy1HXSEV3qlA/640?wx_fmt=jpeg"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;h3 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="句子抽取" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;句子抽取&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;由于该工作为文档的摘要，故其使用了两层encoder，分别为：&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="list-style-type: lower-alpha;"&gt;&lt;li&gt;&lt;p&gt;词级别的encoder，基于CNN。即对句子做卷积再做max pooling从而获得句子的表示。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;句子级别的encoder，基于RNN。将句子的表示作为输入，即获得文档的表示。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;由于是抽取式摘要，其使用了一个RNN decoder，但其作用并非生成，而是用作sequence labeling，对输入的句子判断是否进行抽取，类似于pointer network。&lt;/p&gt;&lt;h3 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="词的抽取" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;词的抽取&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;对于词的抽取，该模型同样适用了hierarchical attention。与句子抽取不同，词的抽取更类似于生成，只是将输入文档的单词作为decoder的词表。&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="数据" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;数据&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;从DailyMail news中根据其highlight构建抽取式摘要数据集。&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="简评" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;简评&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;该工作的特别之处在于对attention机制的使用。该paper之前的许多工作中的attention机制都与Bahdanau的工作相同，即用attention对某些向量求weighted sum。而该工作则直接使用attention的分数进行对文档中句子进行选择，实际上与pointer networks意思相近。&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="AttSum: Joint Learning of Focusing and Summarization with Neural Attention" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;span&gt;&lt;strong&gt;4、AttSum: Joint Learning of Focusing and Summarization with Neural Attention&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="作者" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;作者&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Cao, Ziqiang, et al.&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="单位" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;单位&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;The Hong Kong Polytechnic University, Peking University, Microsoft Research&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="关键词" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;关键词&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Query-focused Summarization&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="文章来源" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;文章来源&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;COLING 2016&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="问题" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;问题&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Query-focused多文档抽取式摘要&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="模型" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;模型&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;a title="" rel="gallery0" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgnYVBY4h2lIdnkAFQHjjYTsybLdicPicmaSyrDzJVyMiaE7DuoRCqgWicrFCVSeG7znwicV3iaDu2Ins6rw/640?wx_fmt=jpeg"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;由于该任务为针对某个query抽取出可以回答该query的摘要，模型使用了attention机制对句子进行加权，加权的依据为文档句子对query的相关性（基于attention），从而对句子ranking，进而抽取出摘要。具体地：&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="list-style-type: lower-alpha;"&gt;&lt;li&gt;&lt;p&gt;使用CNN对句子进行encoding&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;利用query，对句子表示进行weighted sum pooling。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;使用cosine similarity对句子排序。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="数据" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;数据&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;DUC 2005 ∼ 2007 query-focused summarization benchmark datasets&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="简评" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;简评&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;该文章的亮点之处在于使用attention机制对文档中句子进行weighted-sum pooling，以此完成query-focused的句子表示和ranking。&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="总结" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;span&gt;&lt;strong&gt;总结&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;本次主要介绍了四篇文本摘要的工作，前两篇为生成式（abstractive）摘要，后两篇为抽取式（extractive）摘要。对于生成式摘要，目前主要是基于encoder-decoder模式的生成，但这种方法受限于语料的获得，而Rush等提出了利用English Gigaword（即新闻数据）构建平行句对语料库的方法。IBM在Facebook工作启发下，直接使用了seq2seq with attention模型进行摘要的生成，获得了更好的效果。对于抽取式摘要，神经网络模型的作用多用来学习句子表示进而用于后续的句子ranking。&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;广告时间&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;PaperWeekly是一个分享知识和交流学问的学术组织，关注的领域是NLP的各个方向。如果你也经常读paper，也喜欢分享知识，也喜欢和大家一起讨论和学习的话，请速速来加入我们吧。&lt;/p&gt;&lt;p&gt;微信公众号：PaperWeekly&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgkSMlEJFo90NY8rCXr3mJMBibduVHxMKSHzQtVkHz8kNwpjCKBiccGuqLE0WpPuAbdtEs6cTF5iabpAQ/640?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;微博账号：PaperWeekly（&lt;a target="_blank" rel="external" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;http://weibo.com/u/2678093863&lt;/a&gt;&amp;nbsp;）&lt;br/&gt;微信交流群：微信+ zhangjun168305（请备注：加群 or 加入paperweekly）&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Sat, 05 Nov 2016 14:40:38 +0800</pubDate>
    </item>
    <item>
      <title>深度 | 专访Facebook人工智能实验室负责人Yann LeCun：错过DeepMind也不算一件坏事</title>
      <link>http://www.iwgc.cn/link/3362551</link>
      <description>&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Business Insider&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Sam Shead&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：蒋思源、李泽南&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Yann LeCun是人工智能界的著名学者，现任Facebook人工智能研究部门的主管。就在上周，LeCun作为神经网络的先驱获得了Lovie终身成就奖，Business Insider专访了这位来自巴黎的学者。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Yann LeCun 教授是人工智能三巨头之一（另两位是 Hinton 与 Bengio），在 20 余年的研究历程中，他已累积发表了超过 180 篇论文，现在 LeCun 是 Facebook 人工智能研究机构的主管。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他最广为人知的研究在 1988 年，LeCun 参与开发了著名的「卷积神经网络」，可以识别手写数字。随着数据训练的不断持续，这种革命性的系统开始从图片像素中识别视觉特征，这就像为计算机打开了双眼，让它们可以从数据中自我学习。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们在上周 LeCun 刚刚获得 Lovie 终身成就奖之后见到了这位来自巴黎的学者，并专访了他。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：谈谈你的部门在 Facebook 中的角色吧。&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：我领导的部门：FAIR（Facebook Artificial Intelligence Research）的任务——我们总称自己为「FAIRies」——是推进人工智能的科学与技术；并通过实验发展这一技术在各个领域中的应用，如计算机视觉，对话系统，虚拟助手，语音识别，自然语言识别等等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能的背后存在很多基础科学，它们也许并不面向应用，你的研究可能也只是通向对智能和人工智能的理解。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们也同 Facebook 的另一个小组合作研究，应用机器学习团队（AML），他们的人数是我们的一半。是它们将科学转化为可见的技术，通过为公司构建应用平台，他们正将人工智能服务变为产品团队可以使用的东西。所以我得说 Facebook 里有很多人都在做着 AI 相关的工作，不仅仅是 FAIRies。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：你能说说有多少人在你的实验室里工作吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：当然，有大约 75 个人正在 FAIR 工作，就像我说的，AML 的两倍，公司中还有很多其他人处理 AI 应用方面的事务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：FAIR 的员工仅在加利福尼亚，还是遍布全球？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：有一些员工在纽约工作，我也在那里。此外，Menlo Park（Facebook 总部所在地，位于加利福尼亚州）和巴黎也有一些成员，还有一个小团队在西雅图。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWicKYha6n6vemibmx6zUztu84WAoBNicztvyb6csXhGHRTG5oOicsXdsRlB1uCsEaMgialMewh19h2e8icg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Facebook 在 Menlo Park 的总部&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：你认为 Facebook 的哪个部分可以用人工智能加以改善？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：Facebook 面临的最大问题，时刻需要解决的问题，就是我们需要将最好的内容向每个人呈现。所以你必须理解内容，理解每个人，然后把内容和对它们感兴趣的人相匹配。这是非常重要的一个方面。只有做到这一点，人们才会选择 Facebook Feed。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而在这之上，我们的远期目标，是建立一个真正的智能机器，让你可以与它直接对话，它需要能回答任何问题，并对你的生活提供帮助。这件事对于当今的人工智能而言非常具有挑战性。对话系统，自然语言识别，所有这些的基础在于让机器学会人类的常识。我们现在还不知道到底应该怎么做，但我们对此有很多想法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：所以，比如我是一个 Facebook 的用户，我厌倦了 News Feed 里面晒娃的消息，我能用自然语言告诉 Facebook 让它屏蔽这类推送吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;答：这是一种方式，但其实是一种非常不方便的方式，让人告诉 Facebook 怎么做。如果我们拥有了对话系统，你可以对它说：「请不要再推送婴儿照片了。」但是现在已有的方式是 Facebook 通过学习用户习惯知道了你不看这些图片。你或许会很快地浏览这些图片，或者点击它们但没有评论之类。所以我们已经可以通过你的习惯了解你的兴趣所在了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：你觉得目前的人工智能军备竞赛谁是赢家？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;答：没有谁跑在前面。有许多公司正在做着大量的人工智能研发，对于人才的竞争也很激烈，但现在并没有谁发明了远远领先于其他公司的新技术，我是说需要别人花费三个月以上才能赶上的新技术。我认为有三四家公司现在处于第一集团，Facebook，谷歌——特别是其中的 DeepMind，其实我的意思是 Alphabet，它已经不是谷歌的一部分了——还有微软，人工智能是他们的传统优势项目，IBM 也进步了很多。然后才是其他很多公司。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：你提到了谷歌和 DeepMind。DeepMind（以创纪录的 40 亿英镑价格被谷歌收购）开发了 AlphaGo，击败了围棋的世界冠军，我听说 Facebook 也在这一领域有所研究，当 DeepMind 超过你们的时候你是否很失望？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;不不，我们没有失望，因为这是整个人工智能领域的伟大胜利。我的一些学生和博士后参与了 DeepMind 项目。分析围棋棋盘并决定落子位置的系统实际上是卷积神经网络，这是我的发明。所以说这一成就建立在所有人的努力之上。我们 Facebook 对围棋的研究不多，基本上只有两个人在做。我们的围棋研究主要作为计划和勘探研究的载体。我们做这个，我们的系统工作得不错，然后我们把它开源了，这跟 DeepMind 的系统相比体量相差很多。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：在人才方面，你们如何保证 Facebook 可以招揽人工智能最好的人才？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：你知道，这需要和大学实验室保持良好关系，这些机构输出各类人才，进行各种可能的研究，同时项目和成果也是公开的。事实上，对于 FAIR 而言，公开性不止于可能，而是需求。假设你是一名研究者，你肯定总是想公开发表你的研究成果，对于科学家来说这很重要，因为你的地位在于学术影响。而要有影响，你不能简单地告诉人们「我正在为 FAIR 工作，但我不能告诉你们我在研究什么」，这样你的职业生涯就毁了。这很重要，我觉得在这一点上我们领先于其他公司，同时在 Facebook 你可以和世界上最棒的同事们交流。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们还在做很多事，都有关和学术界保持良好关系。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：进去工作的薪水是多少？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：哦，这是很重要的，特别是现在我们还在和微软，谷歌及其子公司竞争的情况下。但是其他的基本待遇也要给到，如果条件不够好，那么都没人愿意过来了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：你能大概告诉我们顶级 AI 从业人大概的薪水吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：不，我不能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：你的聊天机器人 M 现在怎么样了？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：最初 M 只是一个研究人们是怎样使用类人虚拟助手的试验，不过 M 的大多数工作实际上是由人类完成的。也就是说你不能把它扩展到数以百万计的用户，这也就是为什么我们把用户数量限制在很小的范围内。随着研究的进展，我们学到了很多人类会问的问题，开始让机器执行一些人类的工作，并为特定领域开发了一些相对专业的机器人，这就是它的现状。所以相对专业的机器人都是在电影，餐厅或别的什么地方。而能回答任何问题的机器人的基础研究还在网页里，比如在维基百科上，这还处于研究阶段。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：你们正在倡导与 AI 伙伴关系，Facebook 如何确保人工智能发展的伦理和安全？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：对于人工智能，现在还有一些真实存在或想象下的危险。如像终结者那样的危险情况，或者是 Nick Bostrom 书中的超级智慧（Superintelligence），你知道他说人们本来想要开发一个高效制造回形针的人工智能，最后整个银河系都会塞满回形针。这不是我们需要但有的，因为我们的技术水平还差得很远。而且现在已有各种会议，研讨会，论文等正在讨论更远未来超级智能机器的伦理问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们现在努力解决的 AI 伙伴关系问题在于如何让人工智能系统不出现偏见，比如，数据中可能会有偏见。举个例子，我们并没有驾驶自动驾驶汽车，但是如果你是在建立一个机器学习系统让它自己驾驶汽车，你就想彻底地测试它，不过由于最佳的实践方案还不完全清楚，所以我们还有很多工作要做。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：有传言说 Facebook 一度考虑收购 DeepMind，Facebook 收购 DeepMind 是一个好的选择吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;你也知道事情已经过去了，现在 DeepMind 还有很多优秀的人。我认为如果不是谷歌收购了 DeepMind，那么 DeepMind 的现状还要有很多不同的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我认为 DeepMind 的挑战就是在地理上和加州的总部所隔开了，这使得他很难将技术转化为产品。所以这也在一定程度上让 DeepMind 需要靠自己生存下去。也许它会发展一些应用，例如将 AI 运用到医疗。他们十分强调公共关系，因为这对于整个团队是很重要的。特别是他们很难自己生产应用级产品，这将对他们是个巨大的挑战。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这样一个几家公司同时为一个目标而努力的时代实在是很棒的体验，因为我们能在彼此的基础上思考问题。每当我们有个好想法，DeepMind 都会在我们想法上更进一步提升，反之亦然。有时候我们会一起工作在一个团队几天或几个月，他们基本上雇佣了我一半的学生。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：DeepMind 基本处于 Sergey Brin 和 Eric Schmidt 的掌控中，这意味着谷歌高管们强烈支持 DeepMind，这肯定能帮助 DeepMind 把技术转化为产品，对吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：研究这种先进的技术，你必须获得管理层的支持，因为基础研究的影响在比较长时间后才能体现出来。你不能幻想种下一颗种子，然后技术就自然而然地有了，突然冒出了实体产品线，商业形式发生了彻底改变。你需要来自高层的支持，因为这是一种长期投资。这不是那种我投资进去，半年后就能收回成本的事情。它需要的是有远见的人，这样的人谷歌有，Facebook 也有。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Fri, 04 Nov 2016 14:24:33 +0800</pubDate>
    </item>
  </channel>
</rss>
