<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>机器之心</title>
    <link>http://www.iwgc.cn/list/670</link>
    <description>人与科技的美好关系</description>
    <item>
      <title>开源| 哈佛大学九大自然语言处理开源项目（附论文）</title>
      <link>http://www.iwgc.cn/link/3149389</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Github&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：杜夏德、李泽南、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;在这篇文章中，我们盘点了哈佛大学开源的 9 大有关自然语言处理的项目。虽然里面的代码是研究代码（通常还有一些使用的注意事项），但也已经得到了哈佛研究团队之外的产业组织的应用，其相关项目的证书请参阅对应的 repo。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1.Sequence-to-Sequence Learning with Attentional Neural Networks（使用注意神经网络的序列到序列学习）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;项目地址：https://github.com/harvardnlp/seq2seq-attn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在带有（可选）注意（attention）的标准seq2seq模型的Torch实现中，其编码器-解码器（encoder-decoder）模型是LSTM。编码器可以是一个双向LSTM。此外还能在字符嵌入（character embeddings）上运行一个卷积神经网络然后再运行一个 highway network，从而将字符（而不是输入的词嵌入）作为输入来使用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该注意模型来源于发表于EMNLP 2015大会上的论文《Effective Approaches to Attention-based Neural Machine Translation》。我们使用该论文中的带有输入-反馈方式的全局通用注意力模型（ global-general-attention model with the input-feeding approach）。输入-反馈作为可选项，也可去掉。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其中的字符模型来源于AAAI 2016上的论文《Character-Aware Neural Language Models》。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2.Visual Analysis for State Changes in RNNs（用于 RNN 中状态变化的视觉分析）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;项目地址：https://github.com/HendrikStrobelt/lstmvis&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;循环神经网络（RNN），尤其是LSTM，是学习一个隐藏其序列输入表征的密集黑箱测试的序列处理的有效工具。对这些模型有更好理解的研究者已经研究了隐藏状态表征中随时间发生的变化，并注意到有些可以解释但噪声明显的模式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们提出的LSTMV是用在RNN中的一款视觉分析工具，其关注的重点是理解这些隐藏的状态动态。这个工具允许用户选择一个关于局部状态变化的假设输入范围，以将这些状态变化匹配到一个大数据库中类似的模式上，并将这些结果与它们的域（domain）的结构注释（structural annotations）进行比对。我们为这个工具提供了数据来分析数据集上特定的隐藏状态属性，包括嵌套、短语结构、和弦进程（chord progressions）并展示如何使用这个工具为进一步的统计分析来隔离模式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3.CNN for Text Classification（用于文本分类的CNN）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;项目地址：：https://github.com/harvardnlp/sent-conv-torch&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个代码用GPU在Torch中实现了Kim（2014）的句子卷积代码。它复制了现有数据库中的结果，并允许在任意其它的文本数据库上训练模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;4.Im2Markup&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;项目地址：https://github.com/harvardnlp/im2markup&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在最近图像字幕生成和光学字符识别（OCR）研究进展的基础上，我们提出了一个通用的基于深度学习的系统来将图像反编译成标识性置标语言（presentational markup）。虽然这个任务在OCR中已经得到了充分研究，但是我们用的是完全不同的数据驱动的方法。我们的模型不需要任何潜在的标记语言知识，仅在真实世界的样本数据中进行端到端（end-to-end）的训练即可。这个模型实现了一个卷积网络，该网络将文本和布局识别（text and layout recognition）与一个基于注意的神经机器翻译系统串联起来。为了训练和评估这个模型，我们引入了一个与 LaTeX标记语言配对的经过了真实世界渲染的数学表达式的新数据库，以及一个与HTML代码片段配对的网页的合成数据库。试验结果显示该系统在两个数据集的精确标记生成上非常有效。而一个标准特定域的LaTeX OCR系统的精确度能达到25%，我们的模型准确再现了样本中75%的渲染的图像。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;5.ABS: Abstractive Summarization&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;项目地址：https://github.com/harvardnlp/NAMAS&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该项目包含了来自以下论文的 Abs.神经抽象摘要系统（neural abstractive summarization system）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这里发布的代码可以：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;提取摘要数据集&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;训练神经摘要模型&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;用ROUGE构建评估集&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;调试提取的特征&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;6.LSTM Character-Aware Language Model&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;项目地址：https://github.com/yoonkim/lstm-char-cnn&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;代码来自 AAAI 2016 论文《Character-Aware Neural Language Models》。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是一个仅建立在字符输入上的一个神经语言模型（NLM）。预测还是在词水平上进行。当输入一个LSTM循环神经网络语言模型（RNN-LM）时，该模型在字符上启用了一个卷积神经网络（CNN）。也可选择让该CNN的输出通过一个 Highway Network，这能提升表现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;多数基础代码来源于Andrej Karpathy的字符RNN实现：https://github.com/karpathy/char-rnn。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;7.Neural Coreference Resolution （神经指代消解）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;项目地址：https://github.com/swiseman/nn_coref&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;神经指代模型（Neural Coref Models），在论文 Learning Global Features for Coreference Resolution（Sam Wiseman, Alexander M. Rush, and Stuart M. Shieber, NAACL 2015）和Learning Anaphoricity and Antecedent Ranking Features for Coreference Resolution（Sam Wiseman, Alexander M. Rush, Stuart M. Shieber, and Jason Weston. ACL 2015）中有所描述。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;8.PAD: Phrase-structure After Dependencies&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;项目地址：https://github.com/ikekonglp/PAD&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;PAD是一款免费软件；你可以遵照由 Free Software Foundation公布的GNU宽通用公共许可来修改/重发它；也可以二版的许可，或者后面其他版本的许可（看你自己的选择）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;发布PAD是希望它能变得有用，但是我们并不担保；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你应该会收到一份连同这个程序的GNU通用公共许可证；如果没有，写信给 Free Software Foundation，地址是59 Temple Place, Suite 330, Boston, MA 02111-1307 USA。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目标：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;依存分析器（dependency parsers）快速、精确，并可以产生易于解释的结果，短语结构分析虽然很便捷但在很多语言处理任务中需要输入。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;该PAD分析器能产生依存分析后的词组（phrases-after-dependencies）。给它依存分析的输出，它将会产生优化的约束短语结构分析。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;9.安卓系统中的神经机器翻译&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;项目地址：https://github.com/harvardnlp/nmt-android&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;基于Sequence-to-Sequence Learning with Attentional Neural Networks项目： http://github.com/harvardnlp/seq2seq-attn。&lt;/span&gt;&lt;span&gt;和一篇文献：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;http://www.people.fas.harvard.edu/~yoonkim/data/emnlp_2016.pdf&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;神经机器翻译（NMT）在翻译中提供了统计方式之外的另一种方式，同时也更加简便。然而，如果想要达到有竞争力的表现，神经机器翻译模型会变得非常巨大。本论文中我们考虑了将知识提炼（knowledge distillation）方式（Bucila 等人，2006；Hinton等人，2015）加入机器神经翻译中，以解决其体量问题，这种方式已在其他领域中被证明能够成功减小神经模型的尺寸。我们证明了适用于词级预测的标准知识提炼方式在神经机器翻译中是有效的，同时也介绍了两种新的序列级知识提炼方式，它们可以进一步提升性能。令人有些惊讶的是，这些方式可以消除对定向搜索（beam search）的需求（即使应用在原始教师模型（teacher model）上）。我们最好的学生模型（student model）在性能稍有损失的情况下运行速度比最好的教师模型速度快10倍。它同时大大优于没有知识提炼的基准模型，在贪婪解码（greedy decoding）/定向搜索中达到4.2/1.7的 BLEU。当学生模型应用了权重修剪（weight pruning）的知识提炼结果时，其参数相比教师模型小13倍，同时 BLEU 减少0.4。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;教程&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你是Torch新手，我们准备了NLP机器学习研究生班CS287的一套教材。这些笔记是由Sam Wiseman和Saketh Rama准备的，你可以由此获得对Torch核心方面的基本了解，接着快速转向一些高级的话题，比如内存使用、神经网络模块的细节和循环神经网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 20 Oct 2016 12:17:17 +0800</pubDate>
    </item>
    <item>
      <title>重磅 | Tesla 推出「完全自动驾驶」功能，这是彻底解放人类还是又一次「大跃进」？</title>
      <link>http://www.iwgc.cn/link/3149390</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心经授权转载&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;作者：龟途慢慢&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;极客公园微信号：geekpark &lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt; 特斯拉&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz/8cu01Kavc5a9ft1yVws5VFcwBwlR9uWFXXFT2kv3bwoPC9UZwVLRuYKw8iao6Ppo2mHEJJEIdJB8Bq1YJtzicib3A/640?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;如果说埃隆•马斯克（Elon Musk）有什么特点，除了遮掩不住的野心和在发布会上演讲时的经常性卡壳，喜欢跳票也是一个。他自己所制定的时间点基本没有能按时搞定的，差不多都得往后再推移一段时间。&lt;/p&gt;&lt;p&gt;上周的时候，马斯克在 Twitter 上宣布，Tesla 将会在本周一发布一款「大多数人都意想不到（unexpected by most）的新产品」。结果就在既定时间马上要到的时候，他又突然宣布「我们还没搞定」，大家周三再见吧！&lt;/p&gt;&lt;p&gt;于是，我们终于在几个小时之前见到了这个「新产品」——完全自动驾驶硬件（Full Self-Driving Hardware）。&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/8cu01Kavc5YgoBWPic3akaficlusXJgGQ0oCQULOuD6h9uKGyX9kxtYMrup8a0HN9I1CA53FZkUlT7SpxyyNEt9w/640?wx_fmt=png"/&gt;&lt;/p&gt;&lt;h2 style="margin: 0.6em 16px; padding-left: 0.5em; font-weight: bold; font-size: 21px; max-width: 100%; box-sizing: border-box; white-space: normal; line-height: 1.4em; border-left: 8px solid rgb(29, 172, 245); word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;多项升级给&amp;nbsp;Tesla&amp;nbsp;「完全自动驾驶」的信心&lt;/h2&gt;&lt;p&gt;考虑到这半年来有关自动驾驶技术的巨大争议性，Tesla 在此时推出这个所谓的「完全自动驾驶硬件」产品不可谓不大胆，甚至可以说是「逆天下之大不韪」。&lt;/p&gt;&lt;p&gt;Tesla 在其官方博客中给出了具体的产品细节和相关的技术组成，让我们一起先来看看 Tesla 凭什么会有这样的信心：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;·&lt;/span&gt;&lt;/strong&gt; 8 个环绕摄像机可以提供最远达 250 米的 360°可视视角；&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;·&lt;/span&gt;&lt;/strong&gt;&lt;span&gt; &lt;/span&gt;12 个升级版的超声波传感器，监测距离可达上一代系统的两倍；&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;·&lt;/span&gt;&lt;/strong&gt;&lt;span&gt; &lt;/span&gt;具有增强功能的前视雷达，能够在雾霾、下雨天等恶劣环境中提供帮助；&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;·&lt;/span&gt;&lt;/strong&gt;&lt;span&gt; &lt;/span&gt;更强大的车载计算系统，由 NVidia 提供 GPU 芯片，其计算能力达到了上一代版本的 40 倍，运行的是 Tesla 自己开发的神经网络；&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/8cu01Kavc5YgoBWPic3akaficlusXJgGQ0RNZN5qBWSat9STfcYuItdVWUCGvtjvoDnATK8djQoIbmmuRKIB1ziaw/640?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;根据其自己的说法，配备这种新硬件的 Model S 和 Model X 已经在生产中了，如果想要，你现在就可以下单购买。不过，由于这个新硬件系统的成本会贵 8000 美元，所以可能会在产品的售价上也有所提升。&lt;/p&gt;&lt;p&gt;当然，这个新的功能不会立刻就能使用，即使你现在买到了一辆新的 Model X，你暂时还不能完全使用自动驾驶模式，Tesla 表示自己还需要「通过在真实世界行驶数百万英里的距离来校准这个新系统」。&lt;/p&gt;&lt;h2 style="margin: 0.6em 16px; padding-left: 0.5em; font-weight: bold; font-size: 21px; max-width: 100%; box-sizing: border-box; white-space: normal; line-height: 1.4em; border-left: 8px solid rgb(29, 172, 245); word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;自动驾驶水准达最高标准，这是一个伟大成就还是在「放卫星」？&lt;/h2&gt;&lt;p&gt;马斯克自己表示，这套硬件已经具备了「第 5 级自动驾驶的能力」，如果成真，这会是一个巨大的进步。&lt;/p&gt;&lt;p&gt;自动驾驶技术在国际上有一个分级标准，美国交通部选择的是美国汽车工程师学会（Society of Automotive Engineers）的标准，其主要内容为：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;·&lt;/span&gt;&lt;/strong&gt;&lt;span&gt; &lt;/span&gt;0 级：无自动驾驶，由人类驾驶员全权操控汽车，可以得到警告或干预系统的辅助；&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;·&lt;/span&gt;&lt;/strong&gt;&lt;span&gt; &lt;/span&gt;1 级：驾驶支援，通过驾驶环境对方向盘和加减速中的一项操作提供驾驶支持，其他的驾驶动作都由人类驾驶员进行操作；&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;·&lt;/span&gt;&lt;/strong&gt;&lt;span&gt; &lt;/span&gt;2 级：部分自动化，通过驾驶环境对方向盘和加减速中的多项操作提供驾驶支持，其他的驾驶动作都由人类驾驶员进行操作。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;·&lt;/span&gt;&lt;/strong&gt;&lt;span&gt; &lt;/span&gt;3 级：有条件自动化，由自动驾驶系统完成所有的驾驶操作。根据系统要求，人类驾驶者需要在适当的时候提供应答。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;·&lt;/span&gt;&lt;/strong&gt;&lt;span&gt; &lt;/span&gt;4 级：高度自动化，由自动驾驶系统完成所有的驾驶操作。根据系统要求，人类驾驶者不一定需要对所有的系统请求做出应答，限定道路和环境条件等。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;·&lt;/span&gt;&lt;/strong&gt;&lt;span&gt; &lt;/span&gt;5 级：完全自动化，在所有人类驾驶者可以应付的道路和环境条件下，均可以由自动驾驶系统自主完成所有的驾驶操作。&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/8cu01Kavc5YgoBWPic3akaficlusXJgGQ0Vpqaia1ib2rbfTZwV0yg2z5cNAuCssKFOHl7eggVzNbYECUJUGj0sw7Q/640?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;而在此之前，现有的汽车及互联网厂商在自动驾驶技术方面大都集中在第 2 或第 3 级。比如前几个月刚刚除了车祸的 Tesla 上一代系统虽然允许驾驶员的双手短暂离开方向盘，但也需要你随时放回去拿回操控权。因此，马斯克这次宣称直接从第 3 级跳到了第 5 级，无疑还是令人有些担忧：这是不是又在「放卫星」？&lt;/p&gt;&lt;p&gt;但由于现在缺乏更多实际的数据和材料，因此究竟能否达到所谓的「第 5 级」的水准，恐怕还需要届时的实测才能知道了。但在此之前，相信我们绝大多数普通人恐怕对此还是持一个谨慎观望的态度。&lt;/p&gt;&lt;h2 style="margin: 0.6em 16px; padding-left: 0.5em; font-weight: bold; font-size: 21px; max-width: 100%; box-sizing: border-box; white-space: normal; line-height: 1.4em; border-left: 8px solid rgb(29, 172, 245); word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;安全性是人类驾驶的两倍，但出了事故我们不负责&lt;/h2&gt;&lt;p&gt;除此之外，马斯克自己还在之后的问答环节表达了一些自己对相关问题的看法，其中颇有一些看点。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1. 如果 Tesla 的自动驾驶汽车出现事故了，Tesla 会负法律责任吗？或者会提供「赔偿计划」吗？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;答：&lt;/strong&gt;不会，除非能证明是软件本身出现了错误。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2. 这个新的自动驾驶技术究竟有多安全？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;答：&lt;/strong&gt;根据目前的测试，它的安全性至少是人类驾驶的两倍。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3. 如何评价上一次的事故？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;答：媒体在事故上把太多的注意力放到了不恰当的地方，每年死于人类交通事故的人有 120 万，自动驾驶技术已经非常安全了。事实上，所有阻止我们采取自动驾驶汽车的行为都是在「杀人」。&lt;/p&gt;&lt;p&gt;当然，从这些问答中，我们一如既往地发现了马斯克满满的信心，他对自己的产品始终毫无挑剔。不过，这其中当然还存在一些模糊的地方，比方说法律责任。虽然马斯克自己强调要根据完全的调查结果来判定事故责任，但究竟怎样才能判断是驾驶者自己的判断出了问题还是驾驶系统的判断有误呢？这一切还需要政府部门和这些车厂更多的研究与合作。&lt;/p&gt;&lt;p&gt;不过，像以往一样，马斯克在最后又做出了一个时间上的承诺：&lt;strong&gt;他将会在明年年底之前在洛杉矶到纽约的路程上用完全自动驾驶汽车做一个展示。&lt;/strong&gt;到时候也许我们就能判断自己敢不敢买他的产品了。&lt;/p&gt;&lt;p&gt;所以，估计我们在 2017 年是见不到他的这个演示了，还是往 2018 年等等吧。&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心经授权转载，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系原公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 20 Oct 2016 12:17:17 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 英美四家顶级大学成立人工智能危机研究中心，霍金出席</title>
      <link>http://www.iwgc.cn/link/3149391</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自卫报&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李泽南&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicGV4U9vYdqa1Ve0U2v5UbwstXxib4qricQ5SKqubrznSicqpToWSOicmBib8MKTTFib1VG18qRSXs3kE6A/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;探索人工智能的影响──史蒂芬·霍金在 Leverhume Centre for the Future of Intelligence 周三的开幕仪式上。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;史蒂芬·霍金教授曾经警告世人，强人工智能的出现是「人类历史上发生的要么是最好的，要么是最坏的事情」，同时建议创立一个致力于研究未来人工智能的学术机构，并认为「这对人类的文明和生存的未来至关重要」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;霍金出席了本周三剑桥大学未来智能研究中心 Leverhulme Centre for the Future of Intelligence（LCFI）的开幕仪式，它是一个多学科的研究机构，&lt;span&gt;联合了牛津大学，剑桥大学，帝国理工和加州大学伯克利分校的力量，&lt;/span&gt;研究方向是为了探寻目前快速发展的人工智能中的一些开放性问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicGV4U9vYdqa1Ve0U2v5UbwVXKMiaTpxCjVV66UuR89biabYSIDtegxT5Rzy5QcpicvKMRBItpPxp5Dg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Huw Price ，研究中心的教务主任 &amp;nbsp;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;霍金，这位举世闻名的物理学家曾提醒人们要小心人工智能，他担心人类制造出具有自我意识的超级人工智能可能会毁灭自身，但很快他又强调了人工智能研究更可能为人类造福。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「人工智能的出现很可能会让人类受益，」他说。「当人类的思想被人工智能放大之后，很难想象我们将实现什么样的新成就。人工智能也许就是下一次技术革命的基石，我们将会消除上一次革命──工业革命对自然造成的破坏，同时一定会向着最终消灭疾病和贫穷的道路上前进。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我们生活的方方面面都将被改变。简而言之，人工智能的出现将是人类文明历史上最重要的事件。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Huw Price 成为了这家新学院的教务主任，他同时也是剑桥大学的 Bertrand Russell 哲学教授，霍金同样位列其中。Huw Price 说，这家新机构的成立部分原因在于剑桥大学的存在风险中心（Centre for Existential Risk）。那是一家经常被小报渲染成「末日研究所」的研究机构，探究过人类可能面临的种种危机。与之不同的是，LCFI 的研究方向仅限于人工智能领域。「我们正在做的是消灭『终结者』出现的风险」Price 说道，「但正如学院名字所指的，我们还会做很多其他的事。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;苏塞克斯大学认知科学教授，人工智能先驱 Margaret Boden，对这些努力的成果表示支持，她成为了 LCFI 的顾问。在 2009 年她曾表示，关于人工智能危险的担忧并没有被认真对待，甚至对于人工智能的研究者而言也是如此。在开幕式中，她说道，「人工智能的前景令人兴奋，但这种技术有其限制，如果随意使用可能酿成大祸。」在学术界，对于人工智能潜在风险的警告声不绝于耳。很多科技界的先驱，如其中最有名的埃隆·马斯克，也曾经表达过对于人工智能的担心，他认为超级人工智能可能会危害人类。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;LCFI 的研究范围覆盖人工智能的所有应用领域，从智能手机，外科手术机器人到「终结者」式的军用机器人。这家研究机构获得了来自 Leverhulme 信托的 1000 万英镑资助，研究中心致力于保证人工智能对人类有益。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 20 Oct 2016 12:17:17 +0800</pubDate>
    </item>
    <item>
      <title>演讲 | 今日头条机器人——对话、问答、新闻创作，人工智能已无所不能了吗？</title>
      <link>http://www.iwgc.cn/link/3149392</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心发布&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;演讲者：李磊&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;李磊博士，今日头条科学家、头条实验室总监，原百度美国深度学习实验室少帅科学家。上海交通大学计算机系本科，卡耐基梅隆大学计算机系博士，毕业论文获美国计算机学会 SIGKDD 最佳博士论文之一。曾于微软研究院、Google、IBM TJ Watson、加州大学伯克利分校工作。在机器学习和自然语言理解方面于国际顶级学术会议发表论文 30 余篇，拥有三项美国技术发明专利。机器之心不久前曾对李磊博士进行过专访，&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718173&amp;amp;idx=2&amp;amp;sn=7afb370ac67b7879f165bda12e4357d9&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718173&amp;amp;idx=2&amp;amp;sn=7afb370ac67b7879f165bda12e4357d9&amp;amp;scene=21#wechat_redirect"&gt;专访 | 头条实验室科学家李磊：准确率更高的问答系统和概率程序语言&lt;/a&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWicGV4U9vYdqa1Ve0U2v5UbwKkeGSC4PWzVgZ80qZ89H33ekTNMfqeoSTTE8x1uxGffaRuALyMax6w/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以下是关于机器理解语言演讲全文：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;大家下午好！很荣幸有机会在这里和各位专家学者以及同行朋友们交流人工智能在自然语言理解方面可以做到的一些成果。今天我会介绍一下用机器学习怎样来做自然语言的理解，怎样跟人对话、问答以及怎样自动创作新闻；做到这些事情，我们需要哪些机器学习的工具，和哪些基础的算法模块；然后介绍三个方面，分别是对话机器人、问答机器人、自动创作新闻的机器人，具体是通过何种技术来实现的；最后介绍我们如何来实现通用的人工智能，或者说目前的人工智能技术还有哪些挑战以及我的一些思考。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicGV4U9vYdqa1Ve0U2v5Ubw8faO1DghB7Muy9mvq8GJ1KZoqV3UmKpeW9dy7Dc50vCuzEDwqHC7sw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今年年初 GOOGLE 的 DeepMind 通过他们的围棋机器人 AlphaGO 让全世界几乎所有的人都知道，机器学习可以在某些任务上达到甚至超过人类的智力水平。那围棋的机器学习是怎样来实现的？用了两部分的算法，一部分深度学习，另一部分强化学习或者蒙特卡洛树搜索。我后面介绍的内容与深度学习有关。从过去 20 年或者 30 年神经网络以及深度学习发展的成功经验里都可以看到，深度学习解决一类问题是非常非常有效的，这一类问题是有监督学习。什么叫有监督学习？就是你给一组数据 X，希望对这组数据做一点预测，它是 Y，你希望通过机器学习的方法找到从 X 到 Y 的映射函数 f。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicGV4U9vYdqa1Ve0U2v5UbwgZx8Dn9DDib8aH0JcXGc1QPSAXicqrRF02Okj7VDEY3ic688zvItWwakw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;例如我们的输入是一张图片，我们的输出是这张图片的标记，它到底属于哪个类别，是猫还是狗，这是图像分类问题。如果我们的输入是一句中文的语音，输出是一句英文，那从中文到英文同样是一个有监督的学习或者叫机器翻译。第三个例子，我们给一个图片，我们希望生成一段文字来描述这个图片。大家知道我们小的时候会做看图说话，是不是机器也可以做看图说话？同样，这就可以把它建模成一个有监督学习的问题。第四，输入是一段语音，输出是这段语音对应的文字，这个叫语音识别，同样是有监督学习的问题。当然可以把这个问题反过来，输入是一段文字，输出是一段语音，这就是语音合成，同样是一个有监督学习。深度学习在解决这样一类有监督学习的问题时，只要数据充分、模型合适，可以做到非常好。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;那么深度学习究竟是如何来做的？深度学习或者人工神经网络最早是从人脑的工作方式得到启发。人脑由非常非常多的神经元组成，每个神经原元都只可以做非常简单的事情，但把这些神经元连接起来就可以做一些比较复杂的事情。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicGV4U9vYdqa1Ve0U2v5Ubwu854Nqgxu6wFvLNoRvQjIHBbLGHJicwia7pfyv1UPYAcjhFf0SdVvKmw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从这里得到启发，我们的人工智能先驱创作了人工神经元。人工神经元同样有一些输入，这个输入经过非常简单的方式加权求和，通过非线性的函数输出一些结果，把很多个这样的神经元组合起来，就可以做一些复杂的事情。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicGV4U9vYdqa1Ve0U2v5Ubwrzr8aeVJLlJeRibYSamibLxu18W8xNbKwV1fbPABX1JHfMZ9icX4XMESw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;比如说输入是一张图片，要识别这个图片里面带有的数字。这里展示一个单隐层的神经网络。当然也可以增加这个隐层的数量，可以把网络的识别能力不断提升。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicGV4U9vYdqa1Ve0U2v5UbwLOhVKCLTY3mu9CA92h6bU95o7TfDCOsU1VNEfdYSib7Tvzb0BmTeUfA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些深度学习跟今日头条有什么关系？今日头条是一家为用户提供信息资讯的分享阅读平台。整个环节当中有三部分非常重要，包括高质量的内容怎么创作出来，这些内容怎样分发给感兴趣的用户、读者读了这些文章、看了这些视频之后怎样去鼓励他们围绕这些内容进行讨论和交流。这三方面的核心技术都需要人工智能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicGV4U9vYdqa1Ve0U2v5UbwDl5cYkS26MBGLoW94e0qahFyfQ9ibSAJnDiaewGEicVQia1lPUiaAtTPCOQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我今天会介绍这三个方面中的两方面，包括内容创作以及内容讨论——我们怎样做机器人来跟人去讨论以及做机器人自动创作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们要处理的问题主要是语言问题，和之前讲的图象问题有很大的区别，图象的输入是固定大小的，而语言的问题就比较复杂，一句话可长可短。这样带来一个问题，怎样处理变长的输入。我们创作的深度学习模型最基础的就是要能够处理可变长的输入，最基本的想法就是增加记忆单元。在这个模型里面有一些单元专门负责记录历史信息，它能够记住较长时间内的信息，对未来做预测。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;span&gt;&lt;em&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicGV4U9vYdqa1Ve0U2v5Ubw0sjWlGSiciblO7SmrmVnyLWmCrNKSvnWibLlF3jqHrwRVYxAqfWTwiaJJw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;em style="color: rgb(136, 136, 136); line-height: 1.75em; text-align: center;"&gt;&lt;span&gt;循环神经网络（Recurrent Neural Networks）&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;比如说这里有一个非常简单的循环神经网络模型，它的输入是 X1、X2、X3、X4，每个输入都是一个向量，和传统卷积神经网络不同的地方就是它的输出部分或者影像量的那部分，h 在这里，每个 h 不仅跟当前的位置输入有关，还跟前面一个输入有关，这样可以把历史信息结合进来，这是最简单的形式。还有稍微复杂的一个形式叫 Gated Recurrent Unit(GRU)，像人脑学习加入了一些开关，可以选择性对信息做记忆和遗忘。比如加入了一个开关叫 Reset Gate，对信息做选择性记忆，另外还有一个开关控制输出，可以控制哪些部分是之前一个时刻之前一个位置留下来的信息，哪些信息需要保留到下一个位置。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicGV4U9vYdqa1Ve0U2v5UbwSOHQRiaA1IP7Hg5LZkKO7qsNDSoaTjricmiaQBt0PJG2XTfRkx3UzrKqg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过这些带有记忆单元的神经网络，就可以构建出自动对话的机器人。比如说这里我展示了一部分我们的机器人可以做的对话。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicGV4U9vYdqa1Ve0U2v5UbwhiaFxTIiaWiaDCT0F4Jw0TQoyIGq0B7Tr12INrLTrvxBohyaneOFKNzEg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们的机器人不仅可以跟人闲聊，还可以对用户说的一些新闻做出带有感情色彩的评判，甚至我们的机器人对于很长很长的输入，也可以做出比较准确的回应。这里有一段很有名的电影台词，机器也可以很好的回应。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicGV4U9vYdqa1Ve0U2v5Ubw8Hpt6UFiamFM2Q22O6o7zvkLS5libvZT5K0jeVd0tctbiciadAzz4DR0WA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;到底怎么生成这些对话中的回应？这里有一个简单的演示：从循环神经网络出发，给它一个初始状态，黄色的部分是它的初始状态，从这个初始状态出发生成下一个状态，从当前隐含的信息出发可以去预测出当前这个位置需要输出哪个文字。有了文字之后，我们再把这个文字信息作为下一个字需要输入的需要信息输入进去，综合起来从第一个字生成第二个字生成第三个字生成第四个字，直到生成句子结束为止。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicGV4U9vYdqa1Ve0U2v5Ubwp4Na1mdFgk3RmVMic4ukqiaicdMv0ZWaC5eqd1XUAmE5TuQJOcotrKuSA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;刚才说的是对话，如果没有上句的输入比较简单，如果有上句的输入，怎么生成合理回应？同样用循环神经网络，会对前一句来建模，把上句输入的每个字变成一个向量，把这个向量综合起来处理，最后整句话变成一个向量表示，这个向量就作为我们下句生成回应的循环神经网络的输入，再用前一页讲到的方法来生成第一个字第二个字第三个字，通过这样的方式来生成。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicGV4U9vYdqa1Ve0U2v5UbwoicnCm2HnL5RCr5XRb9ETSPiag5Owueo5IONRhQicicXicvQo76bicLsmibyQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我之前还提到，我们的机器人不仅能够生成这样的对话，它还能够带有感情色彩，那感情色彩是怎样出现的？我们对这个模型加入了额外的激励，这个额外的激励就是情感激励。我们希望这个对话是高兴的、开心的或者愤怒的或者悲伤的，我们可以给它加上额外的激励，这个额外激励加上去之后，它生成的内容就会带有特定的感情色彩。刚才提到的还只是会闲聊的机器人，但他也不能够回答一些带有知识性的问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第二个我要讲的是怎么样来做一个模型，让它能够回答一些知识类的问题。知识如何表示才能让计算机理解，我们需要表示成结构化的方式。例如围绕贝克汉姆这个人物，把知识表示成图，图里面每个结点是一个实体，实体之间、结点之间有一些边相连，这些边代表了关系。比如说贝克汉姆的出生地是 Leytonstone，我们把这些知识表达成三元组的形式，有它的主体、关系以及客体构成。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicGV4U9vYdqa1Ve0U2v5UbwDmuFa3LIFBwCh8UTef8iaBEJvbUeYJEym46kBkrKNTVPWWT0Un0HmEg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器怎样自动回答问题？要问贝克汉姆是在哪里出生的，为了回答这个问题，我们就要从知识库里面找到相应的三元组知识，这条知识是&amp;lt;DavidBeckham, PlaceOfBirth, Leytonstone&amp;gt;，从而找出答案 Leytonston。为什么让电脑回答这样的问题非常非常难？首先我们的语言是非常复杂的，同样一个意思可以有多种问法。比如我们可以问奥巴马总统在哪里出生的？也可以问奥巴马总统出生地是哪里。同样的意思但有不同的问法，这是语言的多样性和复杂性。第二个难点是歧义，同样的名字在我们的知识库里面会有很多个实体很有同样的名字，比如我们问迈克尔乔丹是谁，可能大家首先想到的是打篮球的迈克尔乔丹，但问机器学习领域的人会想到机器学习的大神迈克尔乔丹。这是指代的歧义性带来的挑战。第三个难点是由我们的数据稀疏性所带来。我们的知识海量，即使经过我们的三元组筛选之后也有 2200 万，这是在 GOOGLE 的 FreeBase 上得到的数据。我们一共有十万标注好的问答对，但要通过十万的标注数据回答 2200 万里面的问题，这是一个非常难的问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最近我们做了一个 CFO 系统，是一个基于深度学习的系统，它可以回答一些比较难的问题。比如说问 Harry Potter 在哪里上的学？大家知道 Hogwarts 魔法学校，还有上魔法学校之前的一个小学不是很多人知道，但是机器可以回答出来。通过我们的评测，在由 Facebook 做的公开数据集上，我们的系统准确率达到了 75.7%，相对之前由 Facebook 做的最好系统最好的结果是 62.9%，也就是说我们已经比之前最好的系统要高了十几个百分点。这是怎么实现的？如何来做问答机器人？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicGV4U9vYdqa1Ve0U2v5Ubwy7Js5CxjN4s8pzyialktuibgodxdOSgf99bwdx50zUnqL5qOp8VckUNA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;举个例子，拿到一个问题，Who created the character Harry Potter。首先要识别这个问题里面的关键实体是哪个。Harry Potter。第二步，识别这个问题问的究竟是什么样的关系，Character_Created_By，找到了这两个才能从知识库里面找到相应的答案。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicGV4U9vYdqa1Ve0U2v5Ubw9tkMyLBFmHaibazbStrMTjnCyul2sWnSNciapCQWlIfjfcwXn8Zp2ibIA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们通过序列标注的深度学习模型来对各种可能的实体打分，通过我们的模型就会发现 David beckham 问到的实体概率最大。我们通过另外一个类似的模型，这个模型里面有双向的循环神经网络，通过叠加多层的双向循环神经网络对我们的输入问题建模，最后对这个向量来预测到底实体库里面哪个实体跟这个问句是对应的，哪个关系跟这个问句是对应的。最后会发现这个问题问的实体是 Harry Potter，这样把实体找出来，把答案也找出来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicGV4U9vYdqa1Ve0U2v5UbwZSSiapVXBbhmZ5sktpvSqOTnUwsKibbLqejxLnjCX7iazv9OJQ29hjJWQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;刚才讲的是问答的机器人，最后要讲的是可以自动写新闻的机器人，名叫 XiaomingBot。在奥运会之前开发的机器人，16 天的时间写了 450 篇新闻，围绕乒乓球、羽毛球、足球、网球四个类别写。在短短 16 天内，读者总计一百万。后面通过数据分析发现，在同一时间由专业体育记者所写的体育新闻阅读率和 XiaomingBot 写出的新闻阅读率差不多，甚至 XiaomingBot 新闻阅读率会更高一些。XiaomingBot 既可以成比较短讯，也可以生成比较长的文章。比如女足的新闻比较长，描述的比赛过程比较详细。相对之前研究的新闻机器人来对比，我们的 XiaomingBot 有一些不同的特点：比如说我们非常快，XiaomingBot 在比赛结束的两秒钟之内就可以从生成到发布到读者读到，整个过程时间非常短，从创作到分发到自动推荐整个流程全都是机器来完成的，这也是我们今日头条这个平台的优势。第二个特点是短长结合，既可以生成短内容，也可以形成长报道。另外 XiaomingBot 可以图文结合，实时加上一些比赛的图片，而且我们对比赛的描述符合比赛的时间线，尤其对于足球比赛的描述。我们的生成结合了文法生成技术以及机器学习，内容读起来更像是专业记者所写。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicGV4U9vYdqa1Ve0U2v5UbwBYiciaDLDspic90anJsy2cBqaSicHvTGWhR4Nb9AVicfGmutkD031xRgpDw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对话、问答、新闻生成的机器人，是不是我们的机器人已经无所不能？不是。那现在机器人还有哪些不足，还有哪些做不到？通过对话机器人非常容易发现，我们说一些话会让机器人前言不搭后语；而我们的问答机器人虽然可以在知识类的问题上达到 75.7% 的准确率，但是它还不能处理更通用的问题，比如除了知识类以外，我们还有问原理性的、问步骤性的、以及问深度解释类的问题。如果你问他人生的意义是什么，很难回答你。我们对体育类的新闻生成是比较好的，但是如果把它推广到所有品类做成非常通用的文本生成机器人还是有很长的路要走。为什么机器人会有这些局限？首先一开始提到深度学习或者机器学习在解决有监督学习的问题是非常非常有效的，但是同时它的有效也带来局限。它的有效是因为现在有大量的数据有复杂的模型，但恰恰是因为需要大量的数据，这对目前深度学习方法造成了一个很大局限，就是需要非常大的标注好的数据，而通常标注这些数据所需要的代价是非常非常大的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其次，局限还在于通用性或者可扩展性。我们的问答机器人可以回答知识类问题，但很难再去回答其它的问题，这就是通用性和可扩展性的局限。怎么实现通用的人工智能或者说实现通用人工智能我们还有哪些问题哪些大的挑战需要去解决？这里分享三个需要我们人工智能学者、机器学习专家去研究的技术问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一个问题，机器学习模型的可解释性，深度学习模型在很多问题上做得非常好，可是有时候我们会发现模型做得好，但其实并不知道它为什么做得好。或者我们的模型犯错了，但我们并不知道它为什么犯错，这就是可解释性的问题。我们的机器学习还需要更多地去研究一些模型一些方法，让它能够对自己的行为做一些预测和分析、解释，当它做得不好的时候，它知道自己为什么做得不好，就像人一样，能够分析自己的错误。这是第一点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第二个问题，推理能力。应该能够更多的跟周围环境当中的物体去交互去推理，我们的机器学习目前做的离推理稍微有点远，还只能做非常简单的判别，比如说判别一个类别。但更复杂的推理实际上还是比较难的，所以我们还需要在这方面做更多的突破。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;第三个问题，是我们之前可能忽略的。目前的研究更多的在关注模型、性能和准确率，但是我们并没有注意这些超过人类的智能，达到比人水平还要高的围棋机器人，实际需要非常非常多的计算资源，几千台机器，需要消耗非常多的能源。我们未来更好的算法是不是能够在最少的能耗情况下去达到更高的智能。以上就是我的分享。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谢谢大家！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心发布&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 20 Oct 2016 12:17:17 +0800</pubDate>
    </item>
    <item>
      <title>思想 | 将黑暗森林理论应用到机器学习，提升模型的稳健性（附论文）</title>
      <link>http://www.iwgc.cn/link/3149393</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Github&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Leo K. Tam&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李亚洲、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;本文编译自英伟达深度学习社区经理（Deep Learning Community Manager）Leo K. Tam 的 GitHub 博客文章。他的 GitHub 页面：https://github.com/leotam。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWicGV4U9vYdqa1Ve0U2v5UbwzSdHKbCOtMUpTBdtMYcAeSRd6zCkBB2xw97v6M12Pwp9LIjPoEz9xA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在刘慈欣的小说《黑暗森林》中，他基于外星文明接触的三个基本公理引入了一个对费米悖论的解决方案。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="list-style-type: decimal;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;宇宙是一片有许多文明栖居的黑暗森林，彼此不知道对方的存在位置；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;每个有能力进行星际旅行的文明都经历过（指数式的）技术爆发；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;一旦发现另一文明，该文明必须消灭所发现的种群，因为害怕该法则（2），也害怕自己被超越而被摧毁；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;只需要最小的调整，就可以将法则应用于对抗机器学习，就是：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="list-style-type: decimal;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;当机器学习模型暴露时，要受对抗探索（adversarial probing）的支配，参考论文：Intriguing properties of neural networks。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;当机器学习模型服从对抗探索时，有可能会改进该模型的稳健性，参考论文：Explaining and Harnessing Adversarial Examples。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;通过探索，可能增加类似模型的稳健性，参考论文：Explaining and Harnessing Adversarial Examples &amp;nbsp;或 Generative Adversarial Nets。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这让我们得到了一种机器学习的黑暗森林均衡（Dark Forest equilibrium）。 要了解对抗博弈论（adversarial game theory）的基本知识，请参阅约翰·纳什的理论。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器学习世界也服从黑暗森林的情景。被超大规模网页公司（谷歌、百度、雅虎、腾讯等）所使用的网页爬虫成为网络空间中搜寻机器学习模型的捕猎者。在发现机器学习模型时，它们合理的处理方式是从该模型对抗性地挖掘信息，从而增强自己模型的稳健性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在黑暗森林情景中生存有两种解决方案。第一个明显的解决方案就是孤立（isolation），也就是每个公司部署一个内部机器学习模型。第二种解决方案是旅行者（traveler）模型，也就是通过对网络的积极学习（重复训练）不断调整参数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;注意，Ian Goodfellow 提到过这个并非完美的，因为不是每个模型都会有冲突。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 20 Oct 2016 12:17:17 +0800</pubDate>
    </item>
    <item>
      <title>重磅 | 微软语音识别实现历史性突破：语音转录达到专业速录员水平（附论文）</title>
      <link>http://www.iwgc.cn/link/3134917</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Microsoft Blog&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Allison Linn&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀、杜夏德&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;微软的语音识别有了重大突破，这一技术在对话中的词的识别水平上已经达到了人类水平。今天推送的第二条文章，机器之心对微软首席语音科学家黄学东进行了专访，深入了解微软语音技术背后的「秘密武器」。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8m80kN5ahgeeDRCwa7t5aZ1ezPoCASBFUicz4SkQ03iaTrFnQsHQf4MvQa8pUkEcAxSyiacP3HgIVdA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;后排左起：Wayne Xiong, Geoffrey Zweig, Frank Seide；前排左起：黄学东, Dong Yu, Mike Seltzer, Jasha Droppo，Andreas Stolcke；摄影：Dan DeLong&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在周一的发表的一篇论文《Achieving Human Parity in Conversational Speech Recognition》中，微软人工智能与研究部门的一个研究者和工程师团队报告出他们的语音识别系统实现了和专业速录员相当甚至更低的词错率（WER），达到了 5.9%，而上个月这一数字还是 6.3%（参见机器之心文章《&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719135&amp;amp;idx=1&amp;amp;sn=012d179f83a6c3b38c6e58b4ac9ba82f&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719135&amp;amp;idx=1&amp;amp;sn=012d179f83a6c3b38c6e58b4ac9ba82f&amp;amp;scene=21#wechat_redirect"&gt;语音识别新里程碑：微软新系统词错率低至 6.3% &lt;/a&gt;》）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;5.9% 的词错率已经等同于人速记同样一段对话的水平，而且这是目前行业标准 Switchboard 语音识别任务中的最低记录。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我们已经达到了人类水平，」微软首席语音工程师黄学东说。「这是一项历史性的成就。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个里程碑意味着，一台计算机在识别对话中的词上第一次能和人类做得一样好。而这个团队也达到了他们一年前设下的目标，而且结果大大超过了每个人的预期。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「即便在五年前，我都没想过我们有一天能达到这个水平，连可能性都没有想过，」微软人工智能与研究团队的执行副总裁沈向洋说。微软的语音识别研究起源于上世纪七十年代的 DARPA（一个为国家安全从事技术研发的美国政府机构），这一里程碑是几十年研究的成果。过去几十年里，最主要的技术公司和研究机构都参与了进来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「这一成果是我们这二十年努力的顶峰，」管理语音和对话研究组的 Geoffrey Zweig &amp;nbsp;说。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这一里程碑将为能用语音识别来增强的消费和企业产品带来广泛的影响，其中包括像 Xbox 这样的消费娱乐设备、像即时语音-文本速录这样的辅助工具和像 Cortana 这样的个人数字助理。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「这个技术会让 Cortana 变得更加强大，变成一位真正的智能助理，」沈向洋说。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;比肩人类，但并不完美&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个研究里程碑并不意味着计算机就能完美地识别每一个词了。事实上，人类也不能做到这一点。相反，这意味着计算机的词错率——即计算机将「have」误听为「is」、将「a」误听为「the」这样的错误率——和你从同样的对话中出现误听的错误率是一样的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Zweig 将这项成就归功于在这个系统的各个方面中对最新的神经网络技术的系统性的使用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;使这些研究者登顶的推动力是对神经语言模型（neural language models）的使用。在这种模型中，词被表征为了空间中的连续向量，比如「fast」和「quick」这样意思相近的词在空间中也相隔较近。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「这让这些模型可以很好地将一个词泛化到另一个词，」Zweig 说。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;梦想成真&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;深度神经网络需要使用大量数据（被称为训练集）来教计算机系统识别图像和声音这样的输入中的模式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了达到人类水平的里程碑，该团队使用了微软的计算神经网络工具包（Computational Network Toolkit：https://www.cntk.ai/），这是一个用于深度学习的微软自家开发的系统，该团队已经通过一个开源证书将其发布到了 GitHub：https://github.com/Microsoft/CNTK。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;黄学东表示 CNTK 在跨多台运行 GPU 专用芯片的计算机上快速处理深度学习算法的能力已经得到了极大的提升，正是这样的速度提升让他们的研究成为了可能并最终达到了人类的水平。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;回报来得很快，但一旦这个团队意识到了他们将会有所成果，他们就很难停止手头的工作。黄学东说这一里程碑是在大概凌晨 3:30 左右达到的；几个小时后他醒来的时候发现了这一结果，并且在私人的社交网络上看到了一张宣示胜利的帖子。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「对我来说，那就像是梦想成真了。」黄学东说，他已经在语音识别问题上工作了 30 多年。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这同一周，微软的另一个专注于计算机视觉的研究团队也实现了一个他们自己的里程碑：这个团队在 COCO 图像分割挑战赛（COCO image segmentation challenge）上获得了第一名，这个比赛是评判一项技术可以在确定图像中特定物体的位置上达到怎样的水平。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;微软亚洲研究院副院长郭百宁说分割（segmentation）是极其困难的，因为这项技术必须精确地描述出图像中物体的边界。他说：「这是图片中最难找出的部分。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该团队的技术构建于微软的计算机视觉专家去年设计的一种获过奖的非常深度的神经网络系统之上，其结果优于第二名 11%，并且也已经在微软去年第一名的成绩上实现了显著的提升。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我们将继续作为图像识别领域的一个领导者，」郭百宁说。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;参考阅读：《&lt;/span&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716628&amp;amp;idx=1&amp;amp;sn=f50792bee8674963ab55720606f28678&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716628&amp;amp;idx=1&amp;amp;sn=f50792bee8674963ab55720606f28678&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; line-height: 28px; text-align: justify; white-space: pre-wrap;"&gt;微软亚洲研究院常务副院长郭百宁：计算机视觉的最新研究与应用&lt;/a&gt;&lt;span&gt;》&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;从识别到真正理解&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尽管视觉和语音识别在近些年来都取得了巨大的进步，但这些研究者仍然提醒说仍然还有很多的工作要做。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;展望未来，Zweig 说研究者正在努力工作以确保语音识别能在更为真实生活的环境中良好地工作。这些环境包括具有很多背景噪声的地方，比如聚会场所或在高速路上驾驶的时候。他们也将关注如何更好地在多人交谈环境中将不同的说话人区分开，并且确保其能够在各种各样的声音上发挥效用，而不管说话人的年龄、口音或说话能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从更长远来看，研究者将会关注如何教计算机不只是转录来自人类嘴巴的声音信号，而且还要理解他们所说的话。这样就能让这项技术可以根据自己被告知的内容回答问题或采取行动。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「下一个前沿是从识别走向理解，」Zweig 说。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;沈向洋指出我们正在从一个人类必须理解计算机的世界迈向一个计算机必须理解我们的世界。不过他也提醒说：真正的人工智能仍然还在遥远的地平线上。「在计算机能理解其所听到或看到的事物的真正含义之前，还需要很长时间的工作，很长的路要走。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;论文：Achieving Human Parity in Conversational Speech Recognition&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8m80kN5ahgeeDRCwa7t5aZteUiaynxbd02Cnxc9I1fdSPoHHTtjSJp3ibXclZsZrSWziaCfJGoxrJFQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：&lt;/span&gt;&lt;span&gt;自 1990 年代 DARPA Switchboard 语料库发布以来，对话语音识别（conversational speech recognition）就一直是语音识别领域的一项旗舰任务。在这篇论文中，我们在广泛使用的 NIST 2000 测试集上测量了人类的误差率，并且发现我们最新的自动系统已经达到了与人类相当的水平。对于 Switchboard 部分的数据（其中新近纳入的是对话人谈论一个指定的主题），专业速记员的误差率是 5.9%；而对于 CallHome 部分数据（其中朋友和家人进行开放式的对话），专业速记员的误差率是 11.3%。我们的自动系统在这两个案例中都建立了一个新的、当前最佳的和最前沿的超越人类水平的基准。这标志着这是有史以来第一次在对话语音上达到人类水平的报告。我们的系统达到如此表现的关键是系统性地结合使用了卷积和 LSTM 神经网络与全新的空间平滑方法（spatial smoothing method）和 lattice-free MMI 声学训练。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，机器之心系今日头条签约作者，本文首发于头条号，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 19 Oct 2016 12:02:22 +0800</pubDate>
    </item>
    <item>
      <title>独家 | 专访微软首席语音科学家黄学东：CNTK 是词错率仅5.9% 背后的「秘密武器」</title>
      <link>http://www.iwgc.cn/link/3134918</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心原创&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：虞喵喵&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;9 月 14 日，微软的对话语音识别技术在产业标准 Switchboard 语音识别基准测试中实现了词错率（word error rate, 简称 WER）低至 6.3% 的突破，为当时业界最低。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一个月后的 10 月 18 日，微软进一步将词错率降低至 5.9%。在 Switchboard 语音识别任务测试中，人类对照组（由专业速记员组成）将对话语音转录成文字的最低词错率为 5.9%，这就意味着微软的语音识别系统的语音识别能力已经与人类专业高手持平。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;带领团队取得这一成果的正是微软首席语音科学家黄学东。日前，机器之心有幸专访黄学东博士，共同探讨了词错率降低背后的秘密、这一成就的意义，以及他对语音识别的思考。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;早在 1993 年，黄学东就已组建了微软语音识别部门，并一直进行语音、语义等方向的研究。不仅是这一成就，微软在语音方面取得的种种成果中都能找到他的身影。可以进行实时语音翻译的 Skype Translator、微软的智能个人助理微软小娜（Cortana）等，都有黄学东的努力。现在，他的目标是向全世界开放这些产品背后的技术。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;去年，微软发布了微软认知服务（原「牛津计划 Project Oxford」，现更名为「微软认知服务」），服务集合了多种智能 API，包括视觉、语音、语言、知识和搜索五大类共二十一项。「借助微软认知服务，开发者们就算没有人工智能的知识背景也能轻松开发出属于自己的智能应用。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不仅如此，今年年初微软更是开源了机器深度学习工具 CNTK（Computational Network Toolkit）。不仅使深度神经网络（DNN）、卷积神经网络（CNN）、循环神经网络（RNN）和长短时记忆单元（LSTM）的实现变得非常容易，还支持多个 GPU 组合、服务器自动分化和并行的随机梯度下降（SGD）学习。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;CNTK 正是在此次微软在 Switchboard 测试中取得突破的重要因素。目前微软的诸多产品，包括 Cortana、Bing、HoloLens AI 的训练（training）等都是在 CNTK 上实现的。黄学东笑称「CNTK 是我们的『秘密武器』」，如今这款「武器」人人都可使用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8m80kN5ahgeeDRCwa7t5aZ0NO0hY2WYuEokiaAYuYT6ke2uBMUVCzbkrnmC91MxBxyibFyjPeJH0wA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;以下是专访内容：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：前段时间您参与研发的语音识别系统的识别词错率实现了突破，单系统的词错率低至 6.9%，多系统达到了 6.3%。能否请您解读一下这项突破背后的技术，以及这一成就的意义？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;黄学东&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：关于这个问题，可以先回顾语音识别过去几十年的进步。微软 在过去 25 年一直在做非常基本的、应用的语音识别的研究。不仅仅是微软，整个语音识别的研究，包括学校、公司、政府，很多人做了很多工作。90 年代初，美国国防部还推动了包括华尔街语音识别听写系统等好几个大计划。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因为有这些大力推动，错误率每过三四年就能从 20% 左右降低 5-6% 左右，如果做到 5%-6%，大家觉得这个东西可以用了，然后就能不断地放松限制。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最早的语音识别需要针对特定的人，或者比较小的词汇表。到 90 年代中期，大家觉得既然语音识别每过三四年就有那么大进步，干脆看看能不能识别所有开放的语音，比如两个人在打电话，能不能把电话通话内容识别出来，并且不要任何限制、完全开放，这是非常有名的「电话识别系统」（Switchboard）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这可是一个难任务。在 90 年代中期，微软刚建语音团队的时候，我们用当时最好的技术来识别这样的系统，错误率大概在 80% 左右。很多人付出很多努力，在 20 年前，大概这个系统可以做到 60% - 50% 左右的错误率。今天从 80% 到 6%，是过去几十 年经过了很多人的辛苦努力达到这样的成就。我觉得这不仅是微软的骄傲，也是整个在语音识别、人工智能领域辛勤工作的科研人员的一个很大骄傲，很具有历史意义。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因为语言是人和动物最大的区别。人类发展到今天，因为有语言、能沟通，可以团结团队，一起征服很大的困难。今天机器能识别到这样的水平，不仅仅是微软的研发人员，也是 IBM、Google、百度和很多人一起努力，才推动了这个技术的进步。从历史角度来看，从 20 年前 60%，十年前 50%，以至今天的 6.3%，这是一个非常令人骄傲，也是令我自豪的成就。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今天做这到这个水平，所采用的技术是相当丰富的，核心技术是深度学习。神经网络有很多不同的模型，我们现在这个系统中将多种组合，最后结果达到 6.3%。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们最主要的贡献是：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一，这个系统里面没有 bug，因为要在标准数据上做到这样的水平，实际上体现了工程的完美；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第二，这个系统完全是用微软的 CNTK 开源工具做出来的。微软能做到今天的水平，全世界所有做语音识别的人用 CNTK 这样的工具也能达到这样的水平，这完全是没有问题的。当然但具体参数用多少，我们有很多经验。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第三，其中最核心的技术是把 ResNet 用到语音识别。此前微软亚洲研究院做 ImageNet 用到了突破性的 ResNet（残差网络，Residual Networks），我们第一次把 ResNet 用到语音识别发现效果也非常不错，这也是令我们非常骄傲的事情。去年 ImageNet 上微软亚洲研究院凭借 ResNet 拿了冠军，今年能在语音上取得新的突破，它的贡献功不可没。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：刚才也说到十年前，识别错误率是 50%，今天到达了 6.3%。这十年来您觉得这个速度是快还是慢，语音识别最终可能会达到人类水平，在这之后技术未来的发展方向是什么？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;黄学东&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：这个速度还是相当惊人的。过去 20 年，基本上每年错误率都会较上一年下降 15% 左右，按照这样的速度推下去，语音识别达到人的水平指日可待。但是人的鲁棒性比机器好很多，比如我们可以隔很远说话，人听起来没有问题；或者在鸡尾酒会大家都在谈话，人的耳朵可以很灵敏，要想听什么东西，他可以听什么东西。但是机器这个能力相对比较差，在高噪音、有口音、小孩儿说话或出现不熟悉的内容的情况下，机器 6% 的水平可能会变成 20%、30%。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是人和机器的最大区别，人的鲁棒性非常好，一个新的课题过来，他可以通过会话的方式跟你沟通，也能得到很好的结果。而机器对噪音的抗噪性不够强，对新的课题会话沟通能力比较差。最重要的一点是，语音识别并没有理解你的语义。理解语义是人工智能下一个需要攻克的难题，这也是我们团队花很多时间和精力正在做的事情。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;要做好语音识别需要更好的语义理解，这是相辅相成的。因为你没有知识，你就听不懂别人讲的话。比如我讲一个很高深学问的问题，如果听的一方没有对我说的话题有足够的知识，基本上是对牛弹琴。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：从最早的 HMM 模型到最近几年 RNN、LSTM 和注意力模型，它们促进了语音识别技术的飞跃。那具体在语音识别技术上的突破还需要哪方面的支持，还有哪些前沿研究可以介绍给我们吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;黄学东&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：我们现在用 LSTM 模型取得的进步就很好，将图象识别的最新技术用到语音识别效果也不错，然后通过 LSTM 和 ResNet 这样的组合使微软的系统得到了新的突破。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;再往前走，大数据，大的模型更加精细的深度学习算法，当然还有很多东西可以做。怎么样提高自由组合，然后通过语义理解来帮助语音识别，这都是亟待需要做的事情。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一个就是抗噪。在高噪音的情况下，人能做的很好。但是机器现在抗噪相当困难。我们这个系统实际有三个好东西：一是 LSTM；一是 CNN 的改进版 LACE，是我们团队自己研发的；第三个是用了 ResNet。这三个模型和一般的深度学习模型都不太一样，我们通过这三个模型的大组合，取得了突破性的进步。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在语音都是在云上，三个模型同时在做计算，然后再组合起来，这对 Cloudbase 的语音识别没有任何技术问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：您在之前的采访中也提到微软建立语音识别研究团队的时候是得到比尔盖茨的全力支持。你对现任的 CEO 纳德拉有什么评价？现在微软在语音识别技术上的投入大概是怎样的情况？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;黄学东&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：9 月 30 日，微软刚刚宣布，由沈向洋领导五千人团队负责人工智能。微软对人工智能的投入是相当重视的，在纳德拉的领导下，我们对人工智能的重视是前所未有。现在微软研究院和人工智能产品都在沈向洋领导之下，这改变了微软研究院没有产品任务的过去，对人工智能的重视提到了公司前所未有的战略高度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其次，微软研究院在建立的时候就有这样的口号，要让计算机能看、能听、能说、能想、能学习。实际上在 25 年前微软研究院建立的时候，人工智能就已经是我们的战略目标了。所以微软的严谨和我们的执行是一脉相承的。微软研究院建立的时候，语音识别、计算机视觉、自然语言处理等是最早几个核心团队。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我当时负责语音识别技术团队创建，今天的全球执行副总裁沈向洋当时加盟了微软研究院计算机视觉的团队。现在微软亚洲研究院的院长洪小文，当时也是在语音识别团队。所以不管是比尔盖茨，还是今天的纳德拉，微软对人工智能一直是非常重视的。我们当然可以说云为先、移动为先。从我个人来看，现在正在转向为智能为先。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：我们知道微软对人工智能非常重视，那语音识别方面在整个布局中大概是什么样的位置呢？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;黄学东&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：因为 Cortana 小娜是个人助理，不仅仅通过文本（Text），也可以通过语音来交互，所以语音识别是非常重要的第一步。语音是人和人交流最自然的工具，让人和机器交流更加自然、更加迅速、快捷、友好非常重要，我们对它的投入从来没有减弱。微软研究院在建立之初，最开始的团队之一就是语音识别。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：您从 1993 年加入微软，到现在差不多 20 年了，这期间语音研究思路上有哪些变化？微软在语音产品的思路上又有哪些变化？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;黄学东&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：变化非常大。微软 1995 年第一次在 Windows 上推出了语音识别的 API（Speech API，简称 SAPI），非常具有历史意义。SAPI 是工业界第一个完全基于 PC 的 API，也正是由我的团队推出来。过了二十年，「微软认知服务」（原「牛津计划」）再次推出，是以云为先的语音 API。很凑巧从 1995 年到 2015 年，20 年完成了从 PC 端到云端的变化。现在「微软认知服务」包括 21 个不同的 API，其中语音识别、语言处理等部分都由我现在的团队负责。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以我很感慨，20 年的风风雨雨，微软从 PC 电脑为中心完全转型为以云为中心，其中没有变的就是人工智能。不管当时 PC 为中心还是今天云为中心，人工智能都是中心的中心。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;微软再往前走，云中心之后应该是以智能云为中心。人工智能没有大数据、没有强大的计算能力，就不会有很大的智能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今天的人工智能为什么能够脱离过去几十年人工智能的寒冬。最主要的原因是两个，一是现在的数据量变大了，一是计算机运算能力提高了。有足够的计算能力，计算机「死记硬背」也会显得好像很聪明。其实深度学习、神经网络这些东西早就有了，但那时计算能力不够，数据量也不够大，所以没有太多用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在看来深度学习能把以前不能做的事情做到了，我们每个人都在说深度学习怎么怎么牛，怎么怎么样。但最主要的不要忘记了，因为现在有计算能力，有大的数据，才达到了以前我们没有达到的水平。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;微软开源深度学习的工具 CNTK，Cortana、Bing、HoloLens AI 的训练（training）等都是在 CNTK 上实现的，不仅仅这个 6.3% 的语音识别技术是在 CNTK 上跑的，我们的 Cortana 的识别、产品系统都是在这上面跑。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;CNTK 和其他的开源软件最大的不一样，是它能做大规模、分布式深度学习，性能体验也非常好。一般开源软件只能在一台 4 个 GPU 的电脑上运行。但 CNTK 在 64 台机器上运行都没问题，是真正的大规模、分布式的深度学习开源软件。我们今天能刷新语音识别纪录，真是归功于 CNTK 这个开源工具。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;CNTK 是我们的「秘密武器」。我们把秘密武器开源了，但是里面装什么样的子弹、弹药，你自己决定。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;事实上微软是开源最大的贡献者，可以称为「无名英雄」。我们将时间和精力全部投入在创新最优秀的技术，服务于我们的客户。Switchboard（词错率 6.3%）这个东西不是谁都可以做出来的，这体现了微软在人工智能技术、深度学习技术上二三十年的积累。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：现在有多少团队或者人在采用 CNTK？它的应用怎么样？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;黄学东&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：CNTK 这个技术是我的团队开发的，服务于整个微软公司内部所有的产品、所有的需求。既然能够满足微软公司内部所有产品的人工智能的需求，也可以开源为社会服务。因为这样的理念，CNTK 选择了开源，当时也并没有去炒作，我们更关注的是性能。跑大规模的人工智能实验，通常需要一到两个月的时间，把训练速度提上去才是重中之重。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8m80kN5ahgeeDRCwa7t5aZjXN4fJoEZiaAx7sMiauRX5laD7FzAHHPAS3J5G4iaKloNYkd9glDV4iciaQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;8 月，香港浸会大学发布论文《Benchmarking State-of-the-Art Deep Learning Software Tools》&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718688&amp;amp;idx=4&amp;amp;sn=17b45f18ccb1e29e80fdca1645a71e5c&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718688&amp;amp;idx=4&amp;amp;sn=17b45f18ccb1e29e80fdca1645a71e5c&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;香港浸会大学最近对单机单卡性能做了比较，这根本不是 CNTK 的长处&lt;/span&gt;&lt;/a&gt;&lt;span&gt;，它更擅长分布式系统做大规模的计算。这个研究在单机单卡环境建立了四个系统：标准的全连接神经网络（FCN）、计算机视觉的 AlexNet、微软亚洲研究院研发的 ResNet 和 LSTM。他们比较了 CNTK、Caffe、Torch、TensorFlow，在单机单卡 CNTK 表现不是优秀的情况下，仍在全连接神经网络和 LSTM 两项中拿了冠军。如果在多机多卡的情况下，差别就更大了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8m80kN5ahgeeDRCwa7t5aZ4hocS1ZWkVR9pslTQfLG1XeJC82SyQBn25rmFhwy0qEeiaFCx164Wicw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：您个人的工作轨迹是怎样的？似乎其间有在 Bing 等其他部门工作，是否给您的语音识别工作您带来启发或影响？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;黄学东&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：在加入微软之前，我在卡耐基梅隆大学工作，后来领导微软语音识别和语音产品研发超过了十多年。之后决定不做语音，去做其他事情。我做了一些新产品的研发，后来又去 Bing 搜索和广告部门工作了六年。两年前我才重新负责公司语音的研究。通过过去两年的努力，我们再次又拿到了这个创新的技术。所以我非常感慨，技术日新月异，需要大家一起努力。我们也是站在前人的肩膀上，才能走到这一天。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;微软语音识别技术的研究一直没有停止过，从前我们的重心放在开发 Cortana 这个语音识别系统身上，Cortana 语音识别的水平也是相当优秀的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当然不同的工作之间都是相通的。语音识别需要语义理解才能做的更好。Bing 是搜索，是大数据、大计算、理解语言相结合的工作。搜索以前都是以文本为标准，这都是与语音识别等相通的。我在产品部门做的事情，并没有通过发表文章的形式呈现在各位面前，大家能看到只是微软 Bing 这款产品。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;同时语音团队还一直往前在走。所以两年前我回到研究院重新领导语音团队，并不是从零开始做起，已经有一支非常优秀的团队。现在这支优秀团队重新设定目标，攻克难关。再加上我们使用了很多 GPU，把 CNTK 这个工具做得更完善。有了武器、有了弹药，再加上一支本来很优秀的团队，当然是攻无不克。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;机器之心：最后问一个比较大的问题，在整个人工智能布局上，您认为语音识别的定位是怎样的？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;黄学东&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：就像我们在跟人讲话的时候把他的嘴去掉，或者把他耳朵去掉，语音识别对与人工智能是非常重要的。当然脑子最重要，人工智能就像孟子讲「劳心者治人，劳力者治于人。」有脑子、能推理，能理解周围的环境，能了解人心，有 EQ、有 IQ，这才是最强大的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能最重要的是要有知识，能理解语言、能帮助人沟通、能推理、能分析大数据，能得出最优秀的结论。最后能做梦，那才了不起。语音识别是把音频转换成文字的过程，这个过程相当复杂，体现了人工智能今天最优秀的技术能达到的水平。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图象识别也是类似都是从 A 到 B 转换的学习。到了理解语言、理解语义、深刻地领会意思，就不再是简单的 A 到 B 的映射过程。因为语意没有音义，我讲了一句话具体是什么意思？你要把它翻译成文字定义是非常清楚的，但意义每个人都有不同的理解。这才是人工智能最核心的关键。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过语音识别做机器翻译，或是通过计算机视觉技术描述图像，只是做到了 Perception（感知）。人工智能不仅仅要有感知，还要有认知（Cognition），这才到了高级阶段。除了认知还要有情感（Emotional Intelligence），这是更高级的，是「劳心者」了。我觉得人工智能最高级阶段是要「劳心」，不仅仅要感知，要有认知，还要「心知」。「知心」最难，人都不一定能达到这个水平。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在人工智能最优秀的进步是在感知阶段，包括语音识别，视觉图像识别等等。目前机器翻译还是从 A 到 B 的转换，对语意的理解非常肤浅。认知现在还没有大的突破，「心知」就更没有戏了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不知道这是不是太悲观，但我们还在感知和认知的过渡阶段。感知这个门槛基本上会进步非常快。今后两年，语音识别的水平基本上是没有问题。然后下一步大的任务是认知，自然语音的理解、语意的理解和知识的积累。别小看这个东西，如果能理解语言，人工智能会很强大，它可以读世界上所有的教科书、所有的文章。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在没有一个机器人能把世界所有海量的知识，各个语言、各个国家、新闻、报纸、教科书所有东西都积累起来。当然，现在通过搜索引擎要查什么就可以查什么，但它并没有理解，只是把文字摘下来。有了什么都能理解的人工智能，它就像爱因斯坦一样聪明，上知天文、下知地理，从海洋到物理到数学，什么都知道。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但这个路途还相当遥远，即使要做好了，无非是 IQ 很高了，可是离 EQ 还很远。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心原创，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 19 Oct 2016 12:02:22 +0800</pubDate>
    </item>
    <item>
      <title>业界 | Gartner发布2017年10大战略性技术趋势，智能将无处不在</title>
      <link>http://www.iwgc.cn/link/3134919</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自 Gartner&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李泽南、杜夏德、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;美国咨询公司 Gartner 今天发布了 2017 年至关重要的十大战略性科技趋势。分析师在 Gartner 学术/科技展会中将其公布，这次活动将持续到本周四。Gartner 将战略性技术趋势定义为具有巨大颠覆性潜力的技术，它们已在部分地区有广泛影响；或这种技术存在高速增长的可能性，并将在未来五年内到达临界点。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「Gartner 的 2017 年十大战略性科技趋势已为智能数字网（Intelligent Digital Mesh）做好准备，」Gartner 副主席和合伙人 David Cearley 说道，「前三个围绕『智能无处不在』这个主题，是数据科学技术的突破和新方法，其中包含机器学习和人工智能，它们都是能够自我学习和适应的智能硬件和软件系统。接下来三个趋势聚焦数字世界，有关真实世界和数字世界怎样融合。最后四个趋势有关网络平台和智能物流数字网络服务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2017 年的十大战略性技术趋势是：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;人工智能和先进机器学习&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能（AI）和先进机器学习包含多种技术（例如深度学习，神经网络，自然语言处理（NLP）），是超越传统规则算法使系统获得理解、学习、预测、适应能力的先进技术，并可能在未来使系统获得自主运行能力。这些技术使智能机器出现「智力」。「应用级人工智能和先进机器学习领域已经出现了不同类型的智能应用，包括硬件设备（机器人、自动驾驶汽车、消费级电子产品）和应用与服务（虚拟个人助理（VPA），智能顾问），」Cearley 说道。「这些实现将发展出智能应用，同时也会在各种网络设备与目前软硬件设备中的嵌入式智能中出现。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;智能应用&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;智能应用，如虚拟个人助理就像人类助理一样可以让人们的生活变得更加简单（例如可以按重要性排列电子邮件顺序），它们的使用者工作更有效率（如优先进行重要的活动和交流）。其他智能应用如虚拟客服（VCA）的任务则更加专注于单一方面，如销售和客户服务。同样的，这些智能应用有可能会改变我们的工作方式和工作环境。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;智能物品&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;智能物品指那些超过简单编程模型，应用了人工智能和机器学习的硬件，它们可以对周遭环境和人们做出更加自然的交互与反应。智能物品，例如无人机，自动驾驶汽车和智能家电，已逐渐渗透进了我们的生活，Gartner 预测未来的发展趋势将是单机智能物品向多智能物品协同模型的转变。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;虚拟现实和增强现实&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虚拟现实（VR）和增强现实（AR）这样的沉浸式技术将会变革了人与人、人与软件互动的方式。「在 2021 年之前，这种现场感消费者和商业内容与应用将会快速发展，」Cearley 先生说。「VR 和 AR 的功能将会与数字网融合成一种更加无缝的设备系统，作为一款能够组织用户的信息流的超个性化的相关应用程序和服务。多种移动终端、可穿戴设备、物联网和传感丰富的环境的整合能将这种沉浸式设备的应用拓展到单个人的体验之外。房间和空间与事物都会变得活跃起来，它们通过网格的连接会出现并与沉浸式虚拟世界结合产生作用。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Digital Twin&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;digital twin 是一种依赖于传感数据来理解其状态的并反馈变化提升运作和增加价值的物理事物或系统的动态软件模型。digital twin 包括元数据（例如，分类、构成和结构）、条件或状态（例如，位置和温度）、事件数据（例如，样本、时间序列）和分析（例如，算法和规则）的结合。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在三到五年内，数亿个事物将由 digital twin 代表。各种组织会使用 digital twin 来主动为设备服务做维护和规划、设计制造程序、运维工厂、预测设备故障或提升运行效率，还会增强产品开发。如此一来，digital twin 最终将会代替技术人员和传统监控设备（例如，压力表，压力阀）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;区块链和分布式账本&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;区块链是分布式账本的一种类型，其价值交换贸易（以比特币或其他形式）被按顺序分成块。每一个块都与前一个块链接并使用密码信任和保证机制通过一个对等网络记录下来。区块链和分布式账本的概念增加了交易因为它们具有变革产业运作模式的前景。虽然目前的炒作是围绕金融服务产业，但是还有很多领域可以用上这个技术，包括音乐发行、身份验证、权利登记（title registry）和供应链。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Cearley 先生说，「分布式账本有望能带来变革，但是大多数倡议仍然是在早期的 alpha 或 beta 测试阶段。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;会话系统&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前的会话接口主要是聊天机器人和带有麦克风的设备（如智能手机、平板电脑、个人电脑和汽车）。在未来，智能网络会包含更多类型的终端，人们可以接入应用，获得信息，或和他人进行交流，进行社交活动，获取来自商业和政府的信息。网络设备将从传统的桌面计算机和其他设备进化到人能接触到的所有种类的终端。当所有设备接入网络，新的连接模型将会扩张，不同设备间更多的协同和交互将成为可能，这种发展会为新的数字生活方式提供基础。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;网格式的应用和服务架构&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在网格式的应用和服务架构（MASA：Mesh App and Service Architecture）中，移动应用、网页应用、桌面应用和物联网应用连接了广泛的后端服务网络，从而创造出用户称之为「应用（application）」的服务。这种架构能在多层次和跨组织上压缩服务和公开 API，并利用服务的组合和复用平衡对服务的灵活性与延展性的需求。MASA 能让用户在数字化网格网络（即，桌面、智能手机、汽车）中有面向目标端点的优化解决方案，以及在它们转换不同信道时有持续性的体验。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;数字技术平台&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数字技术平台为数字业务提供了基本的构建模块，是数字业务的关键推动。Gartner 指出了实现数字业务的新技术和商业模式五个关键点：信息系统、消费者体验、分析和智能、物联网和业务生态系统。每一个组织都会有一些集合了这个五项数字技术的平台。这些平台为数字业务提供了基础的构建块，是数字业务的关键推动因素。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;适应性安全架构&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;智能数字网络和数字技术平台以及应用架构将会创造一个前所未有的复杂世界安全形势。「安全技术必须成为物联网平台的基础，」Cearley 说道。「监视用户和实体的行为对安全而言是一种重要的补充，在物联网中是必须的。但是物联网对于信息技术安全行业的人们而言仍然是一个新领域，其应用可能会存在各种缺陷，经常会需要新的修复工具和流程，而这些问题需要在物联网平台中获得解决。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 19 Oct 2016 12:02:22 +0800</pubDate>
    </item>
    <item>
      <title>学界 | DeepMind最新论文：调控运动控制器的学习和迁移（附下载）</title>
      <link>http://www.iwgc.cn/link/3134920</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自 Arxiv.org&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：武竞&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8m80kN5ahgeeDRCwa7t5aZL3uFuSAZiaqWHnmcnUrZ6ExPYHAibOndOicFIbNFlhuUe6T776Ryrf5Qg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;摘要：&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;针对运动型任务，我们研究了一种新型的架构和训练过程。这是一种具有本体感应的高频传感器和低级「脊椎（spinal）」结构的网络，它通过对简单任务的训练来学习感觉运动的原理（primitives）。它有固定的预训练模块，并连接到一个低频、高级的「大脑皮层」网络，这个网络连接了所有的传感器，通过调控传输到「脊柱」网络的信息来控制行为。在单个端到端的架构完全失败的场景下，我们使用预先训练的「脊柱」模块能在多个高级任务中取得成功，并且使得在稀疏奖励空间（sparse reward）中能够进行有效探索。我们在 3 个模拟物体上进行了测试：游泳的 16 维的蛇，20 维的四脚生物，以及 54 维的人。最后，我们将结果展示成视频显示在此网址 https://youtu.be/sboPYvhpraQ 中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;iframe class="video_iframe" data-vidtype="1" style="   z-index:1; " height="375" width="500" frameborder="0" data-src="https://v.qq.com/iframe/preview.html?vid=g0338ykvegd&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0" allowfullscreen=""&gt;&lt;/iframe&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 19 Oct 2016 12:02:22 +0800</pubDate>
    </item>
    <item>
      <title>活动 | 2016 ByteCup国际机器学习竞赛，为5.8亿头条用户寻找问答答案贡献者</title>
      <link>http://www.iwgc.cn/link/3134921</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibaHjUHeQwH5yt6awMwBaOkQTUPhyUkHNBUeMp1ZwibMjA5BS9viaUuaROUZOMzumzTlqDno83t0kew/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2016ByteCup 国际机器学习竞赛正在火热进行中！本次比赛由中国人工智能学会主办，今日头条、电气电子工程师学会（IEEE）中国代表处协办，面向所有对数据分析感兴趣的专业人士和学生。优胜者将获得由今日头条提供的 1 万美元现金及 IEEE 计算机协会或中国人工智能学会的会员资格奖励。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;中国人工智能学会（微信公众号：CAAI-1981）成立于 1981 年，是经国家民政部正式注册的我国智能科学技术领域唯一的国家级学会。今日头条是一款基于数据挖掘技术的个性化推荐引擎，截至 9 月底，头条的累计下载用户数已逾 5.8 亿，日活跃用户数超过 6300 万，每个用户日均使用时长超过 76 分钟。而 IEEE 是全球最大的专业技术组织，它每年在中国举办 100 多场国际专业技术会议，拥有超过 12000 名中国会员，其大多数会员任职于顶尖高校和科研机构。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此次三方强强联合，举办这场数据分析竞赛的主题是：如何在社交问答系统中精准地匹配专家和问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;众所周知，社交问答平台是 Web3.0 时代的一项重要创新。它的产生充分发挥了互联网在人与信息连接上的作用。每个人都可能是专业领域或特定领域的「专家」，其认知盈余可以满足其他人的知识获取需求。这样的系统致力于为每个问题找到合适回答的「专家用户」，并将问题推送给他们，实现「让所有人问所有人，所有人答所有人」的理想目标。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不过，如何将问题精准地推送给合适的专家是一个困难的问题。如果问题推送策略准确度不高，为了保证问题有足够的高质量回答数，只能尽量扩大推送覆盖面，这将有可能给部分不适合回答问题的用户带来打扰。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「2016Byte Cup 国际机器学习竞赛」举办的目的，正在于解决这一问题。本次比赛的数据全部来源于今日头条的产品「头条问答」。头条问答是一个新兴的移动社交问答平台，自 2016 年 4 月上线以来，依托于今日头条 5.8 亿累计下载用户和 30 万头条号自媒体作者，头条问答已有涵盖社会热点、体育娱乐、历史文化、科技财经等领域问题数万个，每天有数万用户参与回答。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;值得一提的是，本次竞赛所使用的数据，源自今日头条自建广告监测系统的真实数据。在比赛期间，所有参赛者都可以自由下载数据、组队、分析建模，并把得出的结果上传到竞赛平台。比赛平台将实时比对提交的答案和真实数据，返回比赛分数并对当前所有参赛者进行排序。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;比赛将在 11 月下旬结束。获奖选手除了将分享 1 万美元的奖金外，还可获得 IEEE 计算机协会和中国计算机学会 2017 年的会员资格，以及一些技术图书奖品。此外，获奖选手还将获得额外的经费，以资助他们参加北京的颁奖仪式并发布自己的方法和结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;特别支持：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;IEEE 中国（IEEE_China）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;机器之心（almosthuman2014）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;环球科学杂志社（huanqiukexue）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;深科技（mit-tr）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;华章图书（微信：hzbook_jsj，微博：华章图书）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;168 大数据（微信:BIhome）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;AMiner 学术（微信：SciTouTiao）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;点击&lt;/span&gt;&lt;span&gt;“&lt;/span&gt;&lt;span&gt;原文链接&lt;/span&gt;&lt;span&gt;”&lt;/span&gt;&lt;span&gt;或进入Lab.toutiao.com浏览比赛详情。&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 19 Oct 2016 12:02:22 +0800</pubDate>
    </item>
  </channel>
</rss>
