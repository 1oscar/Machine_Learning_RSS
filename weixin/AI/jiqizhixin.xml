<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>机器之心</title>
    <link>http://www.iwgc.cn/list/670</link>
    <description>人与科技的美好关系</description>
    <item>
      <title>突破 | DeepMind为强化学习引入无监督辅助任务，人工智能的Atari游戏水平达到人类的9倍</title>
      <link>http://www.iwgc.cn/link/3552550</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自DeepMind Blog&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Max Jaderberg、Volodymyr Mnih、Wojciech Marian Czarnecki&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李泽南、吴攀、杜夏德&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;几个小时前，DeepMind 在其官方博客发表文章介绍他们在强化学习上的最新研究进展。他们通过为代理在训练过程中增加两项额外的任务来增强标准的深度强化学习方法，结果显示代理实现了更好的表现。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;DeepMind 的主要任务是开拓人工智能的新疆界，开发可以自主解决任何复杂问题的新系统。我们的强化学习代理已在 Atari 2600 游戏和围棋中实现了突破。但这些系统需要大量数据进行长时间训练，我们一直致力于提高我们的通用学习算法，改变这一情况。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们在最近的论文《使用无监督辅助任务的强化学习》中提出了一种可以大大提高人工智能代理学习速度和系统性能的方法。通过为代理在训练过程中增加两项额外的任务来增强标准的深度强化学习方法，我们的代理实现了更好的表现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面是我们的代理在 Labyrinth 迷宫任务中的可视化展示：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_gif/KmXPKA19gWibtpcdWV11ysdQEicbIfwqaiavib0ic2ia7icRDZOoYutYx1XPmcm6TiaxjfAzbyMdQgyp6OVJ5urEdmmG6Q/0?wx_fmt=gif"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一个任务包括让代理学习如何控制屏幕中的像素，这需要代理学习它的行为会如何影响它将要看到的事物，而不仅仅是预测。计算机学习的过程类似于人类婴儿通过移动和观察手的运动来学习如何控制手。通过学习如何改变屏幕的不同部分，我们的代理学习了视觉输入的特性，从而学会如何在游戏中打出高分。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在第二个任务中，代理通过训练从近期战况中预测出动作的即刻得分。为了得到更好的结果，我们将有得分和无得分的历史数据等比例地输入系统。通过更多地学习有得分的数据，代理可以更快地学会预测回报的视觉特征。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;结合这些辅助任务，以及我们之前发表的 A3C 论文《Human-level control through deep reinforcement learning》中的成果，我们提出了 UNREAL（无监督强化和辅助学习/UNsupervised REinforcement and Auxiliary Learning）代理。我们在一套 57 个 Atari 游戏合集和拥有 13 个级别的 3D 迷宫游戏 Labyrinth 中测试了这一新系统。在所有游戏中 UNREAL 代理被用同样的方式训练，系统只接收屏幕图像的信息，试图在游戏中获得最多的得分和奖励。在不同游戏中，得分的方式各不相同，从玩 3D 迷宫到《Space Invaders》——同样的 UNREAL 算法学会了所有这些游戏，得分几乎与人类玩家持平，有些甚至超过了人类。下面的视频中可以看到我们的部分结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;iframe class="video_iframe" data-vidtype="1" style="   z-index:1; " height="375" width="500" frameborder="0" data-src="https://v.qq.com/iframe/preview.html?width=500&amp;amp;height=375&amp;amp;auto=0&amp;amp;vid=s03471hfjfw" allowfullscreen=""&gt;&lt;/iframe&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;UNREAL 代理玩 Labyrinth&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 Labyrinth 中，通过使用辅助任务的结果——控制屏幕中的像素点预测何时奖励会出现——意味着 UNREAL 的速度比我们过去最好的 A3C 代理快超过十倍，而且得分好很多。我们的新系统在这些 Labyrinth 关卡中有 87% 的关卡可以达到专业人类玩家的表现，其中一些关卡的表现更是超过人类。在 Atari 游戏中，代理目前的游戏水平已是人类玩家的 9 倍。我们希望这些成果在不久的将来可以让人工智能系统应用到更加复杂的环境中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;论文：使用无监督辅助任务的强化学习（Reinforcement Learning with Unsupervised Auxiliary Tasks）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibtpcdWV11ysdQEicbIfwqaiaKxmbtkZbrsHQUiaHQAYHcp8C1X5kRPUcbmWvPGwlmdiajI2wBGicDicuCg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;深度强化学习代理已经通过直接最大化累积奖励而实现了当前最佳的表现。但是，环境包含了远远更多类型的可能的训练信号。在这篇论文中，我们介绍一种通过强化学习也能同时最大化许多其它伪奖励函数（pseudo-reward functions）的代理。所有这些任务都共享了一个共同的表征，就像无监督学习一样，这种表征可以继续在有外部奖励（extrinsic rewards）存在的情况下发展。我们还引入了一种全新的机制以将这种表征的重心放到外部奖励上，从而让学习可以快速适应该实际任务中最相关的方面。在 Atari 游戏上，我们的代理的表现显著超越了之前的最佳表现，平均达到了人类专家表现的 880%；并且在一个有挑战性的第一人称三维 Labyrinth 任务合集中实现了平均 10 倍的学习加速和平均 87% 的人类专家在 Labyrinth 上的表现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译文章，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Fri, 18 Nov 2016 09:34:47 +0800</pubDate>
    </item>
    <item>
      <title>开源| 让老司机告别快进，Miles Deep使用CNN截取色情视频的关键部分</title>
      <link>http://www.iwgc.cn/link/3552551</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Github&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote style="line-height: 25.6px; white-space: normal;"&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;在「非法」查看色情视频时，你是否也为其「漫长」的铺垫和前奏感到懊恼呢？前几天，GitHub 用户 ryanjay0 开源了一个可以用来识别色情视频中特定类型的场景的人工智能项目 Miles Deep。该算法可以将你想看的类型的片段从完整视频中截取出来并生成一个集合了这些片段的新视频，让你可以不再为那些多余的片段烦恼。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Miles Deep 使用了一个带有残差连接（residual connections）的深度卷积神经网络（DCNN），可以基于性行为（sexual act）将一段色情视频的每一秒分类成 6 种类别，其准确度高达 95%。然后它可以使用这种分类来自动编辑该视频。它可以移除所有不包含性接触的场景，或者编辑去掉一种特定的性行为。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Miles Deep 和雅虎最近发布的 NSFW 模型（见机器之心报道《&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719529&amp;amp;idx=1&amp;amp;sn=e99d95427ce67c32323be5310b767b7c&amp;amp;chksm=871b0157b06c88412d9b933805f5ca3a30df745a8ac147f35204e545c250f42e68c57312cbec&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719529&amp;amp;idx=1&amp;amp;sn=e99d95427ce67c32323be5310b767b7c&amp;amp;chksm=871b0157b06c88412d9b933805f5ca3a30df745a8ac147f35204e545c250f42e68c57312cbec&amp;amp;scene=21#wechat_redirect"&gt;雅虎开源首个色情图像检测深度学习解决方案&lt;/a&gt;》）使用了类似的架构，但不一样的是 Miles Deep 还能够区分裸体和多种特定的性行为之间的不同。就我所知，这是第一个公开的色情视频分类或编辑工具。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个程序可以说是使用 Caffe 模型进行视频分类的一种通用框架，其使用了 C++ 的 batching 和 threading。通过替换权重、模型定义和 mean file，它可以立即被用于编辑其它类型的视频，而不需要重新编译。下面会介绍一个例子。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="width: 528.188px; line-height: 25.6px; white-space: normal;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Miles Deep 项目地址：https://github.com/ryanjay0/miles-deep&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;雅虎 NSFW 模型地址：https://github.com/yahoo/open_nsfw&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;安装&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Ubuntu 安装（16.04）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;依赖包（Dependencies）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote style="line-height: 25.6px; white-space: normal;"&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;sudo apt install ffmpeg libopenblas-base libhdf5-serial-dev libgoogle-glog-dev&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;额外的 14.04 依赖包&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote style="line-height: 25.6px; white-space: normal;"&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;sudo apt install libgflags-dev&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;CUDA（推荐）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果要使用 GPU，你需要 Nvidia GPU 和 CUDA 8.0 驱动。强烈推荐；可提速 10 倍以上。这可以通过软件包安装或直接从 NVIDIA 下载：https://developer.nvidia.com/cuda-downloads&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;CUDNN（可选）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是来自 NVIDIA 的额外的驱动，可以让 CUDA GPU 支持更快。在这里下载（需要注册）：https://developer.nvidia.com/cudnn&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下载 Miles Deep&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="width: 528.188px; line-height: 25.6px; white-space: normal;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;miles-deep (GPU + CuDNN) &lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;miles-deep (GPU) &lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;miles-deep (CPU)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;也要下载这个模型。将 miles-deep 与该模型的文件夹放在同一个位置（而不是在模型文件里面）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8DLuIlocGmG4BCQ8jCHJbeFgm8ZC5626KHhWRaalMBphDURMKOgRuNGKQxahrWZ60GibHXBmYsLdg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;注：是在一个 GTX 960 4GB 上测试了一段 24.5 分钟长的视频&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Windows 和 OSX&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我目前还在开发用于 Windows 的版本。但我没有 Mac，不过应该只需要做一些小修改就可以在 OSX 上运行。编译指令如下。https://github.com/ryanjay0/miles-deep#compiling&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;使用方法&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;例子：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote style="line-height: 25.6px; white-space: normal;"&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;miles-deep -t sex_back,sex_front movie.mp4&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这能找到后向和前向的性爱（sex from the back or front）场景，并输出结果到 movie.cut.avi&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;例子：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote style="line-height: 25.6px; white-space: normal;"&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;miles-deep -x movie.avi&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这能编辑去除 movie.avi 中所有的非性爱场景，并将结果输出到 movie.cut.avi。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;例子：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote style="line-height: 25.6px; white-space: normal;"&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;miles-deep -b 16 -t cunnilingus -o /cut_movies movie.mkv&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这能将批大小（batch size）减小到 16（默认为 32）。筛选出舔阴（cunnilingus）的场景，结果输出到 /cut_movies/movie.cut.mkv&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;注：如果你的内存不够，可以减小批大小&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在多种批大小情况下的 GPU VRAM 用量和运行时间：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8DLuIlocGmG4BCQ8jCHJbe42ymc2LdlOUT8mbU6Odo26vU4s9AEMNLC1NHxMAIJrFDjAPr2LrG0g/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该结果是在带有 4GB VRAM 的 Nvidia GTX 960 上测试得到的，样本是一段 24.5 分钟的视频文件。当 batch_size = 32 时，处理 1 分钟的输入视频大约需要 0.6 秒，也就是说每小时大约 36 秒。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除了 batching 之外，Miles Deep 还使用了 threading，这让其可以在分类的过程中截取和处理截图（screenshot）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;预测权重&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这里是一个预测一段视频中每一秒的例子：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8DLuIlocGmG4BCQ8jCHJbeCpKmKP4O1G5q9JYjGxy60Zzm6LaNKagU1lxbUOe2dkITZsVyRSrPyQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;通过你自己的 Caffe 模型使用 Miles Deep&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;找猫&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面这个例子是如果通过你自己的模型（或一个预训练的模型）使用这个程序：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote style="line-height: 25.6px; white-space: normal;"&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;MODEL_PATH=/models/bvlc_reference_caffenet/&amp;nbsp;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;miles-deep -t n02123045 \&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;-p caffe/${MODEL_PATH}/deploy.prototxt \&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;-m caffe/data/ilsvrc12/imagenet_mean.binaryproto \&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;-w caffe/${MODEL_PATH/bvlc_reference_caffenet.caffemodel \ -l caffe/data/ilsvrc12/synsets.txt \ movie.mp4&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这能找到在 movie.mp4 中的所有带有虎斑猫（tabby cat）的场景，并返回仅带有这些部分的结果 movie.cut.mp4。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;代码中的 n02123045 是虎斑猫的类别。你可以在 caffe/data/ilsvrc12/synset_words.txt 查找这些类别的代码。你也可以使用一个来自 model zoo 的预训练的模型：https://github.com/BVLC/caffe/wiki/Model-Zoo&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;注：这个例子只是展示了其中的句法。但不知怎的，在我的经历中它的表现很差，很可能是因为分类有 1000 个。这个程序也能完美适合带有一个「other」类别的分类数量更小的模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;模型&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该模型是一个用 pynetbuilder 创建的带有残差连接（residual connections）的卷积神经网络（CNN）。这些模型都是 ImageNet 上预训练的。然后其最终层经过调整以适应新的分类数量和微调（fine-tuned）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;正如 Karpathy et al 的论文《Large-scale Video Classification with Convolutional Neural Networks》建议的那样，我训练了最上面 3 层的权重而不只是最顶层的，这稍微提升了一些准确度：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8DLuIlocGmG4BCQ8jCHJbeiaKWjQdkMO8ufOwseLklShz53SslfsgoJbVLibianx0obr3OkibrsS1CMw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面使用不同的模型微调最上面 3 层所得到的结果，该结果是在 2500 张训练图像上测试得到的，这些图像来自与训练集不同的视频。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8DLuIlocGmG4BCQ8jCHJbeL79M854Ad4AX6U6k99JAcw623Usl3a8bibh8R2pic3mI8apuTl78Rpiaw/0?wx_fmt=png"/&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;训练损失和测试精度：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8DLuIlocGmG4BCQ8jCHJbeQNQPsjelicr3ibjrvU7n4YKDgQLiaicSv5gV5NFeUOEN0mQycLrgRL7ZPA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在所有测试的模型中，resnet50_1by2 在运行时间、内存和准确度上表现出了最佳的平衡。我认为全 resnet50 的低精度是因为过拟合（overfitting）的关系，因为它有更多的参数，也许其训练可以按不同的方式完成。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;上面的结果是通过 mirroring 而非 cropping 得到的。使用 cropping 能够将在 resnet50_1by2 上的结果稍微提升至 95.2%，因此它被用作了最终的模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;使用 TensorFlow 微调（fine-tuning）Inception V3 也能实现 80% 的准确度。但是，这是使用 299x299 的图像大小，而不是 224x224 的大小，也没有 mirroring 或 cropping，所以它们的结果不能直接进行比较。这个模型可能也会有过拟合的问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;编辑电影&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;给定对于每一秒的帧的预测，它会获取这些预测的 argmax（最大值参数）并创建这段影片的截断块（cut blocks），其中的 argmax 等于目标（target），而其分数（score）也比一些阈值要大。其中的差距大小、匹配每个模块中目标的帧的最小比例（minimum fraction）和分数阈值（score threshold）都是可以调整的。FFmpeg 支持很多编解码器（codecs），包括 mp4、avi、flv、mkv、wmv 等等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;单帧 vs 多帧&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个模型并不使用任何时间信息，因为它分别处理每一张图像。Karpathy et al 的论文表明其它使用多帧（multiple frames）的模型的表现并不会好很多。它们难以应对相机的移动。将它们的慢融合模型（slow fusion model）与这里的结果进行比较仍然是很有趣的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;数据&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其训练数据库包含了 36,000（和 2500 测试图像）张图像，分成了 6 个类别：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="width: 528.188px; line-height: 25.6px; white-space: normal;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;blowjob_handjob&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;cunnilingus&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;other&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;sex_back&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;sex_front&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;titfuck&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些图像的大小都调整为了 256x256，并且带有水平镜像（horizontal mirroring），并且为了数据增强（data augmentation）还随机剪切（cropping）成了 224×224 的大小。有很多实验没有剪切，但这能稍微提升 resnet50_1by2 的结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前来说，这个数据集还受限于两个异性恋表演者。但鉴于这种方法的成功，我计划扩大分类的数量。因为这些训练很敏感，我个人并不会放出这些数据库；而只会提供训练出来的模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;前向和后向性爱&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这里的前向和后向性爱（sex front and back）是由相机的位置决定的，而非表演者的方向。如果女性表演者的身体面向相机，那么性器官的前面就展示了出来，这就是前向性爱（sex front）。如果女性的后面被展示了出来，就是后向性爱（sex back）。这创造了两种在视觉上不同的分类。其中在性交和肛交之间不做区分；前向性爱和后向性爱可能两者都包含。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;编译&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="width: 528.188px; line-height: 25.6px; white-space: normal;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;克隆包含 Caffe 作为外部依赖包的 git repository&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;按步骤指令（http://caffe.berkeleyvision.org/installation.html）安装 Caffe 依赖包以用于你的平台。Ubuntu 指令（http://caffe.berkeleyvision.org/install_apt.html）。默认的是 OpenBlas。不要担心编辑 Makefile.config 或使用 Caffe 的问题。在 Ubuntu 16.04 上尝试这个，并在其上附加依赖包：&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote style="line-height: 25.6px; white-space: normal;"&gt;&lt;p&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;sudo apt install libprotobuf-dev libleveldb-dev libsnappy-dev libopencv-dev libhdf5-serial-dev protobuf-compiler&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;sudo apt install --no-install-recommends libboost-all-dev&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;sudo apt install libopenblas-dev python-numpy&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;#Add symbolic links for hdf5 library#(not necessary on LinuxMint 18)cd /usr/lib/x86_64-linux-gnu&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;sudo ln -s libhdf5_serial.so libhdf5.so&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;sudo ln -s libhdf5_serial_hl.so libhdf5_hl.so&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="width: 528.188px; line-height: 25.6px; white-space: normal;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;默认的是不带 CuDNN 的 GPU。如果你想用其它的工具，请编辑 Makefile 和 Makefile.caffe。注释掉和取消注释这两个文件中对应的行即可。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;make&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;证书&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;代码（包括训练好的模型）按 GPLv3 授权。Caffe 使用的是 BSD 2 授权。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Fri, 18 Nov 2016 09:34:47 +0800</pubDate>
    </item>
    <item>
      <title>干货 | 深度学习硬件架构简述</title>
      <link>http://www.iwgc.cn/link/3552552</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Fossbytes&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：周文璐、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;深度学习具有极高的计算需求， 要对深度学习应用进行开发并商业化，就需要找到合适的硬件配置。目前，在开发用于深度学习应用的高效硬件平台这一领域，竞争十分激烈。本文将介绍具体的硬件要求，并讨论未来对深度学习硬件的展望。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;深度学习在这十年，甚至是未来几十年内都有可能是最热门的话题。虽然深度学习已是广为人知了，但它并不仅仅包含数学、建模、学习和优化。算法必须在优化后的硬件上运行，因为学习成千上万的数据可能需要长达几周的时间。因此，深度学习网络亟需更快、更高效的硬件。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;众所周知，并非所有进程都能在CPU上高效运行。游戏和视频处理需要专门的硬件——图形处理器（GPU），信号处理则需要像数字信号处理器（DSP）等其它独立的架构。人们一直在设计用于学习（learning）的专用硬件，例如，2016年3月与李世石对阵的AlphaGo计算机使用了由1920个CPU和280个GPU组成的分布式计算模块。而随着英伟达发布新一代的Pascal GPU，人们也开始对深度学习的软件和硬件有了同等的关注。接下来，让我们重点来看深度学习的硬件架构。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;对深度学习硬件平台的要求&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;要想明白我们需要怎样的硬件，必须了解深度学习的工作原理。首先在表层上，我们有一个巨大的数据集，并选定了一种深度学习模型。每个模型都有一些内部参数需要调整，以便学习数据。而这种参数调整实际上可以归结为优化问题，在调整这些参数时，就相当于在优化特定的约束条件。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWic45jgIOq2OCuFlIgqdSFLkN1LtQ73WJvUWYHZMsqTUpJFr0nz4Y91GHDibJCADvSbXKaNMBqy3SFA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图片：英伟达&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719456&amp;amp;idx=2&amp;amp;sn=8c6695450f107e3932ea7c15acc536a1&amp;amp;chksm=871b009eb06c8988f3462bd352566ad5fcda05766bf09a8dda2e1ca36b6f1fabde685e9e0830&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719456&amp;amp;idx=2&amp;amp;sn=8c6695450f107e3932ea7c15acc536a1&amp;amp;chksm=871b009eb06c8988f3462bd352566ad5fcda05766bf09a8dda2e1ca36b6f1fabde685e9e0830&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;百度的硅谷人工智能实验室（SVAIL）已经为深度学习硬件提出了DeepBench基准&lt;/span&gt;&lt;/a&gt;&lt;span&gt;，这一基准着重衡量的是基本计算的硬件性能，而不是学习模型的表现。这种方法旨在找到使计算变慢或低效的瓶颈。 因此，重点在于设计一个对于深层神经网络训练的基本操作执行效果最佳的架构。那么基本操作有哪些呢？现在的深度学习算法主要包括卷积神经网络（CNN）和循环神经网络（RNN）。基于这些算法，DeepBench提出以下四种基本运算：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;矩阵相乘（Matrix Multiplication）——几乎所有的深度学习模型都包含这一运算，它的计算十分密集。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;卷积（Convolution）——这是另一个常用的运算，占用了模型中大部分的每秒浮点运算（浮点／秒）。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;循环层（Recurrent Layers ）——模型中的反馈层，并且基本上是前两个运算的组合。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;All Reduce——这是一个在优化前对学习到的参数进行传递或解析的运算序列。在跨硬件分布的深度学习网络上执行同步优化时（如AlphaGo的例子），这一操作尤其有效。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除此之外，深度学习的硬件加速器需要具备数据级别和流程化的并行性、多线程和高内存带宽等特性。 另外，由于数据的训练时间很长，所以硬件架构必须低功耗。 因此，效能功耗比（Performance per Watt）是硬件架构的评估标准之一。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;当前趋势与未来走向&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWic45jgIOq2OCuFlIgqdSFLksgPeB588Sxlw9ODYz4RPiaX5TKibSq1pc1L6R3R5jSmnAac3jTTumIQA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;英伟达的GPU在深度学习硬件市场上一直处于领先地位。图片：英伟达&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;英伟达以其大规模的并行GPU和专用GPU编程框架CUDA主导着当前的深度学习市场。但是越来越多的公司开发出了用于深度学习的加速硬件，比如谷歌的张量处理单元（TPU/Tensor Processing Unit）、英特尔的Xeon Phi Knight's Landing，以及高通的神经网络处理器（NNU/Neural Network Processor）。像Teradeep这样的公司现在开始使用FPGA（现场可编程门阵列），因为它们的能效比GPU的高出10倍。 FPGA更灵活、可扩展、并且效能功耗比更高。 但是对FPGA编程需要特定的硬件知识，因此近来也有对软件层面的FPGA编程模型的开发。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此外，一直以来广为人所接受的理念是，适合所有模型的统一架构是不存在的，因为不同的模型需要不同的硬件处理架构。 而研究人员正在努力，希望FPGA的广泛使用能够推翻这一说法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;大多数深度学习软件框架（如TensorFlow、Torch、Theano、CNTK）是开源的，而Facebook最近也开放其 Big Sur 深度学习硬件平台，因此在不久的将来，我们应该会看到更多深度学习的开源硬件架构 。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，机器之心系今日头条签约作者，本文首发于头条号，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Fri, 18 Nov 2016 09:34:47 +0800</pubDate>
    </item>
    <item>
      <title>报告 | 从区块链到人工智能，CB Insights发布金融科技创业未来报告</title>
      <link>http://www.iwgc.cn/link/3552553</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自CB Insights&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀、李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;今天为大家推荐一篇 CB Insights 数据统计出的科技金融报告。CB Insights 使用自己的大型数据库，统计了在科技金融领域的众多创业公司。从银行到保险，区块链、人工智能等技术正在变革金融领域。机器之心对本报告每页的主要内容进行了编辑，但因为这是一份长达 116 页的报告，就不再粘贴图片。此外，CB Insights 在昨天又推出了 2016 年 第三季度全球科技金融风险投资的报告。对这两份内容感兴趣的读者可点击阅读原文下载并仔细研读。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWic45jgIOq2OCuFlIgqdSFLkn5BLZp0pzypw92DGeXpQd9B5pmEXgJFelTFFjzftyg08QkVoLJmC7A/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P1-8：CBinsights：金融科技的未来&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P9-12：创业公司成为技术发展和应用实现的重要推动力，是寻找新型商业模式的不确定性实验。创业公司是众包的 R&amp;amp;D，过去 5 年，在金融领域出现了 38135 家早期阶段的创业公司参与这些「实验」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P13：今天的新兴商业模式和创业公司会成为明天的问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P14：即使世界顶级公司也更难保持优势了，如图为标准普尔 500 指数公司的平均保持时间。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P15：创业公司带来的威胁也在增长……创立一家科技创业公司的成本逐年下降。2000 年之后两大重要的推动力：开源和水平扩张、云和 AWS&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P16：技术被采用的速度越来越快&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P17-18：新型商业模式的用户增长更快&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P19：保洁&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P20：FedEX&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P21：酒店住宿领域&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P22：汽车领域&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P24：银行业公司分类（美国）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P25：银行业公司分类（欧洲）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P26-P28：新时代的商业战争不是「金刚 vs 哥斯拉」，而是巨头和大量创业公司之间的竞争：要么吃掉，要么被吃掉。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P29：大部分创业公司都会失败，只有 4% 能走到第 6 轮&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P30-32：大部分可能会影响你的业务的创业公司都会失败，而成功成长起来的就会给已有的企业带来麻烦。对于这些威胁，个性化的服务是很关键的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P33-34：金融科技（fintech）领域很热很拥挤。金融服务占到了美国乃至全球经济的很大一部分。图为美国 GDP 中金融所占比重的年度变化（只在战争时期出现了明显下跌）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P35-36：金融服务这个价值数万亿美元的市场仍然大部分都是在线下，未来有望迎来金融科技创业的爆发。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P38：移动的普及让金融科技公司能够直接面向消费者。图为 App Store 2011 年、2013 年和 2016 年年度 100 应用中的金融应用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P39：人口分析：对于金融服务，千禧一代的看法有所不同。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;18% 的人在过去一年里更换了自己的主要银行&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;40% 的人愿意选择把谷歌作为银行&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;59% 的人认为金融产品的目标用户不是他们&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;79% 的人将他们与银行的关系看作是「相互交易」&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P40：比起现有的金融服务公司，用户更喜欢新公司&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P42：银行业的 Uber 时刻：实体银行会像旅行、音乐和视频行业一样被革命吗？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P43：存在风险的总银行利润池= 109 亿美元&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P44：自 2011 年以来，风险资本支持的金融科技公司已经获得了 3006 比融资，总额高达 344 亿美元&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P46-49：2015 年第 4 季度的金融科技投资出现了一次暴跌，但很快就反弹了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P50：风险资本在 2015 年第 1 季度到 2016 年第 1 季度向金融科技公司投资了 5 亿美元。图为北美、亚洲、欧洲的比较（单位：百万美元）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P51：企业参与了约四分之一的金融科技交易（企业在金融科技公司的风险投资中的占比）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P52：高盛、花旗、桑坦德是风险投资金融科技公司的主要银行&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P53：2015 年全球涌现出了 14 家金融科技独角兽，但 2016 年这一数字还是 0&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P54：24 家金融科技独角兽现在总价值达到了 680 亿美元；其中 15 家在支付或借贷领域……保险紧随其后&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P56：金融科技公司在 IPO 之后表现普遍不佳&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P57：风险投资金融科技创业公司的整体退出数量也在一定范围内不断波动&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P58：精明的风险投资者（Smart Money）仍然看好金融科技，交易活动在 2014 年达到峰值&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P59：Smart Money 主要投资了金融科技的哪些领域？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;PoS 信用卡/另类贷款、不动产、保险科技、机构投资工具/数据&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P60-62：金融科技投资解读：比特币和区块链。图为比特币的价格走势，最近突破了 570 美元，这是自 2014 年 8 月以来的第一次&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P63：对比特币和区块链创业公司的投资。累计投资在 2016 年超过了 10 亿美元，共实现了 351 笔投资&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P64：在媒体的聒噪之中，对比特币的投资正在逐渐转向区块链&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P66：对钱包、挖矿和交易的投资也转向了区块链&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P67：战略性的投资支撑了区块链的发展。图为 2013-2016 年最大的 5 笔区块链/比特币投资的情况，其中橙色表示涉及到企业的投资&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P68：投资比特币/区块链的公司多种多样&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P69-70：另一大投资热门领域是财富管理和个人储蓄。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;自动财富管理增长迅速，但仍然只站到总市场的一小部分。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P71：预计美国智能投顾（robo-adviser）AUM 市场到 2020 年会超过 2 万亿美元&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P72：资本继续涌入智能投顾市场&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P73：Wealthfront 和 Betterment：AUM 从 0 美元增长到了 2016 年的 30 亿美元&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P74：但 AUM 增长速度并不快，有点让人失望&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P75：已有的企业已经快速采取的行动&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P76：自动储蓄应用为智能投顾带来了只是用移动的方法。图为自动投资账号的增长数量&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P79：出于对规模化的需求，一些玩家因为技术而被一些已有的企业看中了&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P80-81：支付 &amp;amp; 汇付科技也是金融科技领域的一大热门。PayPal 仍然在网络电子商务支付上占主导地位，但其未来可能取决于以下技术：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Processsing：在 2013 年，PayPal 买下了 Braintree，这家公司在上一年处理了价值 500 亿的移动和数字支付，其客户包括 Airbnb、Uber 和 StubHub。竞争者：Stripe、Ayden、ChasePaymentech&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Remittances：PayPal 在 2015 年收购的转账公司 Xoom 让美国用户可以轻松向另外 53 个国家的人转账。竞争者：Western、Union、Ria Financial&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Peer-to-Peer：PayPal 通过对 Braintree 的收购而拿下了 Venmo，这个工具可以让用户快速轻松发送资金。PayPal 正在将这项技术扩展到消费者-商户支付。竞争者：SquareCash、Facebook Messenger、Google Wallet&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Credit Lines：PayPal Credit 让消费者可以信用支付、平衡收支，6 个月不需要支付利息，之后的利息高达 19%。竞争者：Mastercard、Visa、American Express、Affirm&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P82：Venmo 支付量从 12.5 亿美元（Q1』15）增长到了 32 亿美元（Q1』16）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P83：Adyen 在 2015 年处理了 50 亿美元，成为了支付领域的独角兽&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P84：支付领域早期阶段创业公司的交易活动增长强劲&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P85：对转账创业公司的风险投资在 2015 年达到最高&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P86：在转账创业的大赛中，风险资本资助的公司有可能取得胜利吗？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P87：Vise 的投资地图&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P88：Mastercard 的投资地图&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P89：American Express 所在是收购与投资&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P93: 全球人寿保险额：2.7 万亿&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;全球非人寿保险额：1.4 万亿&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数字化消费中消费者期望值的主要转变&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P95：服务期望值：消费者对他们的在线体验或保险公司不满意&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P96：技术：在线销售保险市场的成长&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P97：产品：在现在的用户信息和消费喜好统计中有应用&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P98：保险科技投资：从 2011 年的 1.31 亿美元到 2015 年的 27 亿美元&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P99：到目前为止，2016 年最大的 5 笔科技金融交易有 3 笔是保险科技&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P100：今年第一季度，保险科技领域有一半的交易是在种子轮&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P101：如今的保险科技场景图：创业公司发展分布或新产品&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P103：保险公司在科技金融上的投资打破了记录&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P104：覆盖性连通使得 IOT 创业公司成为保险领域中的热门——保险业和索赔防范&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P105：再保险巨头有了更多参与&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P107：聊天机器人让金融领域疯狂&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P108：在保险领域新的 P2P 模型获得关注：消费者会拥抱他们吗&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P109：跨境投资者正在投资美国经济金融公司&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P110：人工智能对机构投资的影响：人工智能驱动的对冲基金创业公司的崛起&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P111：全球还未饱和的机遇&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P113：做支付的大科技公司&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P114：房地产众筹：会出现一家风投支持的获胜者吗？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P115：Digital Challenger Banks 的崛起&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P116：围绕区块链的热情已经从银行扩展到了其他主要产业应用&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;区块链+资本市场&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;区块链+保险&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;区块链+汇付&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;区块链+合规&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;区块链+借贷&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译文章，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Fri, 18 Nov 2016 09:34:47 +0800</pubDate>
    </item>
    <item>
      <title>深度 | 谷歌新人李飞飞：击碎玻璃天花板的华裔女科学家</title>
      <link>http://www.iwgc.cn/link/3537501</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心原创&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：机器之心编辑部&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;本周二，谷歌宣布斯坦福大学教授&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720536&amp;amp;idx=4&amp;amp;sn=19fdaccf63daae29e72d2a738fd65e45&amp;amp;chksm=871b0d66b06c84708e3f803b2cec907365d5fd8a3d15401721a48bfaa4a49b5d37bded8e10a9&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720536&amp;amp;idx=4&amp;amp;sn=19fdaccf63daae29e72d2a738fd65e45&amp;amp;chksm=871b0d66b06c84708e3f803b2cec907365d5fd8a3d15401721a48bfaa4a49b5d37bded8e10a9&amp;amp;scene=21#wechat_redirect"&gt;李飞飞加入其云团队&lt;/a&gt;。作为第一代中国移民，这位图像识别领域的杰出学者是如何从普林斯顿进入斯坦福，最后成为谷歌人工智能团队新任领导者的？让我们来了解一下这名华裔学者的传奇经历吧。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;实现美国梦&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9xhznsLIp5sSbIiayEITWLFHvtX1ibmMyw0k4tVhyVwAnjbnr2Peh5hDfNWs6QguvNooRDlmG697HA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;1976 年，李飞飞出生于北京，后来在四川长大&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你真想做一件事，全世界都会来帮你。16 岁刚来美国的那两年，李飞飞却只能从依靠自己开始。在帕西悉尼的白人圈子中，这位亚裔姑娘显得有点孤独，她像所有极客一样过着简单的生活。那个时候打工与学习几乎占据了她所有的时间。李飞飞明白，这就是普通新移民的生活，需要点牺牲和决心。幸运的是她的同学和高中数学老师在这时给了她莫大鼓励和帮助。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1995 年，李飞飞进入普林斯顿大学攻读物理学，生活的大门终于渐渐为她打开。在周一到周五，她是普林斯顿物理系拿着高额奖学金的高材生，周末则必须回到 Parsippany 的洗衣房，置身于成堆的衣服中。她说「我爱普林斯顿。」因为这里有全世界最优秀的年轻天才。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然而生活的艰辛也在随着年龄增长，她见过斯坦福的优秀博士毕业生为一张绿卡四处奔波，那时的她不明白也无法想象一张绿卡，一个留在美国的机会能难倒全世界那么多优秀的人才。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有过移民经历的人对平等有着更加深刻的体会，李飞飞也如此，她坚持主张高科技产业性别平等，支持种族多样化，还有反对特朗普。她曾在 Twitter 上调侃特朗普是个不懂科学没有眼界的人。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;李飞飞说：「多样化的危机，也正是我们的社会正在应对的危机。『科技是没有灵魂的吗？』」她坦承自己对 AI 研究界的失望，因为这一领域不太欢迎不具代表性的少数群体。在她工作的部门里一共有 15 名全职人员，她是唯一的女性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;梦想与责任&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;并不是每个美国移民都能实现自己的梦想，但李飞飞做到了。当初她随父母举家搬到大洋彼岸。「他们来到这个国家是为了追求梦想。」李飞飞认为她也「应该能够追求自己的梦想。」这个「应该与能够」的选择做起来并不轻松。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1999 年，李飞飞从普林斯顿大学毕业，那时的华尔街一片辉煌，互联网泡沫的热潮接近顶峰，李飞飞接到了多家金融公司的工作邀请。然而她却没有从中选择任何一份工作来减轻家庭经济负担。她的父母支持她做出了最后选择，去西藏研究藏医。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然李飞飞知道自己终将回到学校，回到科研工作中来，读博士也是她的梦想，但西藏之行并非人生插曲。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在科学界藏医与中医一样存在很多争议，但这并不妨碍李飞飞对它的兴趣。她在媒体采访中提到，作为一个科学家，藏医可以在哲学和方法论层面上给她给多的理解。她非常看重具体科研项目在更大领域范围内的意义，每一项研究开始之前都要经过深思熟虑。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9xhznsLIp5sSbIiayEITWLFB67EIOFaYGTlRy1wfHpjtX2ktnf4FpicgwlxBGGyzgF5qRYVUpQH7icg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;她曾经放弃高盛的 offer，追随梦想来到西藏&amp;nbsp;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在李飞飞后来写给博士生们的信中可以看到她对科学探索的态度：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;每个领域的每一篇论文都应该以独特的新视角进行研究。所以当你在机械地开展你们的工作前，请扪心自问——『我的研究会重新定义这一领域的未来吗？』这意味着发表论文的意义不是『这个方向没有人写过』，或者『让我来解决这个小问题，它的成果会很容易展示』；研究意味着『如果我做了，这一重大问题就有了更好的解决方案』，『如果我做了，我就真正开拓了这一领域』。你的研究成果应该能被很多人和行业直接使用，换句话说，你的选题应该有很多『客户』，你的解决方案应该是他们想要的。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;西藏归来之后，李飞飞开始了加州理工的博士学业。博士期间母亲接连患上了癌症与中风，那是一段艰苦的日子，李飞飞说，「我们经历了很多困难，然后一起挺过来了。既要担起生活的责任，又要对得起自己的梦想」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;改变图像识别方向的人&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;是什么吸引谷歌一次性将李飞飞和她的门生李佳一齐请进公司，并委以重任的？显然是她的学术成就和影响力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;自 2009 年以来，李飞飞一直担任斯坦福人工智能实验室和斯坦福视觉实验室的负责人，并成为了终身副教授。在她 2014 年的简历上，有 95 篇在 Nature、PNAS、Journal of Neuroscience、CVPR、ICCV、NIPS 等顶级期刊与会议上发表的文章；联合发表的文章有 32 篇。从 2015 年到 2016 年，李飞飞署名发表的论文有 33 篇（斯坦福视觉实验室），还有一篇将在 2017 年发表在 CSCW 会议上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在不就之前，艾伦人工智能研究所推出了以人工智能为基础的免费学术搜索引擎&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720432&amp;amp;idx=1&amp;amp;sn=25c1224631a11ab1077fda9f2433e78e&amp;amp;chksm=871b0cceb06c85d840d98037614077761a0db0df6c75798d4fa2bc069c7380a02de81e0afed4&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720432&amp;amp;idx=1&amp;amp;sn=25c1224631a11ab1077fda9f2433e78e&amp;amp;chksm=871b0cceb06c85d840d98037614077761a0db0df6c75798d4fa2bc069c7380a02de81e0afed4&amp;amp;scene=21#wechat_redirect"&gt; Semantic Scholar&lt;/a&gt;。我们使用该引擎生成了李飞飞的论文引用量图解（注：搜索时请注意名字输入格式，Feifei Li 为另一位作者。），如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9xhznsLIp5sSbIiayEITWLFibLnDY6icE6E9f8ibWiaW4vn07NEGAibxoAE89BrePloAQWk9aRb4obxoSA/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9xhznsLIp5sSbIiayEITWLFophp9aM2mKJVXnxic179wsJHo0WydODiaibXsdbOL15hhSYhfbnibmYPNw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;过去 3 年，李飞飞论文的平均引用量为 6738。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9xhznsLIp5sSbIiayEITWLFDSftxppLcjibRovrPKLJFdIE9yMWLpnjjJ1iaHjSagIPPK2H7ibSzZ5LA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;基于可用数据，Semantic Scholar 估计李飞飞的引用量在 33215 到 44773 之间。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;回溯过去，李飞飞在计算机视觉上的研究已经花费了 15 年。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 2007 年，李飞飞和一位同事着手开始一项庞大的任务，为来自互联网的十亿张图片进行分类、打标签，从而为计算机提供样本。其中理论基础是如果机器观察到足够的事物，它们就能够在现实世界进行识别。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他们使用亚马逊 Mechanical Turk 这样的众包平台，邀请了来自 167 个国家的 5 万人帮助为其中的数百万张图像打标签。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最终，他们建立了 ImageNet 数据集。今天，这个数据集包含了使用日常英语标记的超过 1400 万张图像，跨越 21,800 个类别。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在我们用 Semantic Scholar 生成的图解中发现，李飞飞被引用最多的论文就是她于 2009 年在 CVPR 上发表的《ImageNet: A large-scale hierarchical image database》。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9xhznsLIp5sSbIiayEITWLFu7SJtX2Z8kgbviaSEKhle3O4cMuGO8NqwOeN4RtZHS8OYicic4JgUibCiaQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;iframe class="video_iframe" data-vidtype="1" style="   z-index:1; " height="375" width="500" frameborder="0" data-src="https://v.qq.com/iframe/preview.html?width=500&amp;amp;height=375&amp;amp;auto=0&amp;amp;vid=v0333il31b6" allowfullscreen=""&gt;&lt;/iframe&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;李飞飞Ted演讲&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;瓜分学界人才的科技巨头们&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谷歌的云业务负责人 Diane Greene 在新闻发布会上说，李飞飞和李佳的加入是谷歌正式将人工智能集团业务正式化的一部分。此后，该团队不会只专注于人工智能研究，而是致力于将尖端技术融入各种 Google Cloud 产品，例如让公司预测销售情况的软件。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而在宣布成立人工智能集团之前，谷歌还围绕着云服务部门产品路线图发布了一系列产品，介绍了他们如何扩大机器学习的使用。对于云计算来说，机器学习是一项关键的技术，它能训练大规模的 AI 网络，不断自我学习和提升。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Google Cloud 及其机器学习团队的产品经理 Rob Craft 也表示，这两名研究者将帮助谷歌「将机器学习的力量带入其他行业」，他们也将成为谷歌整合其研究单位及核心业务努力的一部分。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是，雇用具有机器学习和相关任务专业知识的人才并不便宜。这一行业内的激烈竞争导致谷歌这样的大公司经常会支付「NFL 球员签字费」级别的巨额资金，而越来越多的顶级学界研究人员也陆续加入了大公司的怀抱。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;近年来，学界内重所周知的大牛们基本被科技巨头筛了个遍，方式也是各种各样。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最初，谷歌先是收购了多伦多大学的一家初创公司 DNNResearch。但实际上，这家公司只有三个成员，Geoffrey Hinton 和他的两个刚毕业的、曾经赢得 2012 年的 ImageNet 大赛的学生——Alex Krizhevsky 和 Ilya Sutskever（现在加入了 OpenAI）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如今被称为谷歌最成功一笔收购的 DeepMind 也是竭尽全力的在挖空英国的人工智能人才。前几日 Business Insider 的一篇文章指出，牛津大学与剑桥大学最优秀的人工智能人才一直在被科技巨头收拢。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而且在文章中重点提到，虽然微软和 Facebook 这样的美国科技巨头也正在招募牛津大学的研究生和教授，但是 DeepMind 似乎比其他的公司挖到的人才更多。DeepMind 从被谷歌收购了之后就已经把它的团队规模从在国王十字路时的 100 人扩大到了大约 250 人。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不只是谷歌，以美国、中国为主力的科技巨头们正如同「风暴之眼」一般吸纳着一切尽可能的能量推动着公司在人工智能道路上的快速发展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;微软在人工智能研究中一直处于第一梯队，在 9 月底宣布组建 5000 人规模的专注人工智能的工程和研发团队 Microsoft AI and Research Group。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;之前我们觉得已然落后了的苹果，在 &lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719828&amp;amp;idx=3&amp;amp;sn=5f72f8b9bbd0078d483ad233e578081a&amp;amp;chksm=871b022ab06c8b3ce2ef881c941e1ea532e3f465bbc1109c74e0aa0a72b283a8408dca7b353f&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719828&amp;amp;idx=3&amp;amp;sn=5f72f8b9bbd0078d483ad233e578081a&amp;amp;chksm=871b022ab06c8b3ce2ef881c941e1ea532e3f465bbc1109c74e0aa0a72b283a8408dca7b353f&amp;amp;scene=21#wechat_redirect"&gt;10 月份拉拢到了 CMU 机器学习教授 Russ Salakhutdinov&lt;/a&gt; 作为该公司人工智能研究的负责人，开始招聘人才、组建团队。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;中国的 BAT 三巨头。百度因为有吴恩达，「声音」是最大的，我们对他们的人工智能研究也是了解最多的（开源深度学习框架 Paddle、硬件基准测算工具 DeepBench 等）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;阿里在今年的云栖大会上也「秀」了一把人工智能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;腾讯也在最近成立了腾讯 AI Lab，新一轮的招兵买马不可避免。虽然在&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720536&amp;amp;idx=1&amp;amp;sn=76e38d366841b567d38c4334df175eeb&amp;amp;chksm=871b0d66b06c8470d96d6faf9c636e0e0eed6d0e89e74abd3ecfe52c68f384a906c95efd1329&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720536&amp;amp;idx=1&amp;amp;sn=76e38d366841b567d38c4334df175eeb&amp;amp;chksm=871b0d66b06c8470d96d6faf9c636e0e0eed6d0e89e74abd3ecfe52c68f384a906c95efd1329&amp;amp;scene=21#wechat_redirect"&gt;机器之心的专访中&lt;/a&gt;他们对腾讯 AI Lab 没谈到太多内容，但隐隐可察觉出腾讯也要像谷歌一样在人工智能与自己的平台和产品结合上打通一条道路。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在接近尾声的 2016 年，我们已经明显感觉到人工智能、机器学习、深度学习等字眼成为了科技界的主流。从害怕 AlphaGo 之后因过度炒作而经历新一轮寒冬，到语音识别、神经机器翻译等的一个又一个的技术突破，再到越来越激烈的人才竞争，一个新的时代即将到来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心原创，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 17 Nov 2016 10:16:24 +0800</pubDate>
    </item>
    <item>
      <title>访谈 | CMU机器学习系负责人Manuela Veloso：人工智能与人类的未来是共生自主</title>
      <link>http://www.iwgc.cn/link/3537502</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自The Verge&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀、蒋思源&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 2021 年之前，我们日常所用的软件将会具有很大程度上的智能和能力，并将会在越来越多的任务中取代人类。难道我们就要就此落后了吗？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尽管有一些人预测会出现大规模的失业和人类与人工智能之间的全面战争，但其他人并不认为未来有那么糟糕。卡内基梅隆大学机器学习系负责人 Manuela Veloso 教授设想了一个人类与人工智能密不可分的未来，它们将同心协力持续不断地交换信息和目标，她将其称之为「共生自主（symbiotic autonomy）」。在 Veloso 眼中的未来里，我们将难以将人类代理和自动化助理区分开——但不管是人还是软件，如果没有彼此，就不会有很大的用处。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Veloso 已经在 CMU 的校园里面测试这个想法了。他们打造了可移动的、赛格威一样的机器人 cobot。它们可以自动将客人从一栋建筑护送到另一栋建筑，而且当它们短缺时它们会请求人类的帮助。这是一种新的思考人工智能的方式，并且可能会在未来五年里带来深远的影响。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;日前，The Verge 在匹兹堡对 Veloso 进行了一次专访，谈论了机器人、编程自发性（programming spontaneity）和人工智能给人类带来的挑战。下面是采访内容：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;问：自动化是过去五年里的一个大趋势。我们也看到有更多的智能被构建到了我们已经在使用的工具中，比如手机和计算机。你对未来五年的发展怎么看？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;在未来，我相信会出现人类与人工智能系统的共存，并有希望会造福于人类。这些人工智能系统将涉及到处理数字世界的软件系统，也将涉及到在物理空间中移动的系统，比如无人机、机器人和自动汽车，另外还会有处理物理空间的系统，比如物联网。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你也将在物理世界中有更多的智能系统——不只是你的手机和电脑，而是我们周围的各种物理存在，它们能处理和感知这个物理世界，并帮助我们进行涉及到大量物理世界的特征的决策。随着时间的推移，我们还将看到这些人工智能系统还将会对更广泛的社会问题产生影响：比如管理大城市的交通、做出关于气候的复杂预测、在人类进行重大决策时提供支持。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：目前，我们可以看到有一些系统并不好。当一个算法或机器人进行一项决策时，我们并不总是知道它们为什么要这样决策，这让它们难以得到我们的信任。技术可以如何解决这个问题？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：我正在研究的一件事是让这些机器能够解释它们自己——对它们做出的决定负责和透明。我们做的很多研究是让人类或用户询问该系统。当我的 Cobot 到我的办公室稍微迟到时，我可以说：「你为什么迟到了？」或「你选择了哪条路？」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以我们正在研究这些人工智能系统在学习和提升时解释自己的能力，以便提供不同详细程度的解释。我们想通过与这些机器人交互从而让人类能够更加信任这些机器人。你就可以问：「你为什么要那样说？」或「你为什么推荐这个？」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;提供那样的解释占到了我现在的研究的很大一部分，而且我相信能做到这一点的机器人能够为我们提供对于这些人工智能系统的更好的理解和信任。最终，通过这些交互，人类也将能够纠正这些人工智能系统。所以我们也在做尝试整合这些纠正的研究，让这些系统能够从指令中进行学习。我相信这会是我们与人工智能系统共存中的很大一部分。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：你认为为什么这些系统现在会提升这么快呢？在过去 50 年的人工智能研究中，你觉得是什么在拖我们的后腿？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：你必须理解，对于一个人工智能系统而言，要知道什么是手机、什么是杯子、一个人是否健康，它就需要知识（knowledge）。早期的人工智能研究实际上是获取知识。我们不得不求助于人类。要人类将信息收集起来并人工录入到计算机中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;神奇的是，在过去几年来，这些信息越来越数字化。看起来这个世界通过互联网显现了出来。所以现在人工智能就是关于可用的数据，以及处理这些数据和理解它的能力，我们仍然在寻找最好的做这些人物的方法。另一方面，我们很乐观，因为我们知道数据已经有了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在的问题变成了，我们如何从数据中学习？你怎么使用它？你怎么表征它？你怎么将这些碎片结合到一起？那就是你用深度学习和深度强化学习做自动翻译的系统和能玩足够的机器人的方式。所有这些系统之所以成为可能，是因为我们可以远远更加高效地处理所有这些数据。我们不再必须执行收集知识和表征知识这些大步骤了。就是这些。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：过去五年最大的发展之一是类似 Siri 和 Alexa 的个人助理，它们都是由机器学习驱动的。我想知道你怎么看待这些系统在过去五年内的变化？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;你知道，我是 Alexa 的大粉丝。我家里就有一个，大部分时间我与 Alexa 所谈论东西变得越来越广泛。在一开始的时候就是「天气怎样？」现在我会问「我的日历上有什么安排？」Alexa 在学习，我也在学习 Alexa 能做什么。它到底能够随时间变得多好，这会是很让我惊喜的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我告诉你一件有趣的事：当我离开家的时候，我告诉 Alexa：「Alexa, stop.」我想停止它正在播放的音乐，因为我要离开了。但如果我告诉 Alexa：「Alexa, I'm leaving」，它就无法理解「I'm leaving」意味着它应该停止了。我必须明确说出「stop」才行。所以我设想个人助理会越来越能明白这样的指令：「Alexa，当我离开时，意味着你应该停止播放音乐。」这样的指令应该被提到研究日程上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;问：你认为我们会达到这样的程度吗：我们可以问个人助理「我车子里的检查引擎指示灯亮了，我可以开这辆车吗？」或「谷歌，我刚拿到了一份工作邀约，我应该接受吗？」？&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我认为这是可能的。这种类型的问题是决策问题（decision-making questions）——假设你必须选择某个健康保险计划，但你被这些选择搞糊涂了。你可能会在你要睡觉的时候告诉 Alexa：「Alexa，你看看所有这些健康保险计划，还有那些我能够购买的汽车，或者我的孩子可以去哪些学校读书。」然后它就可以在晚上帮你编译一份报告出来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;大量的相关信息都是可以通过网络获取的。你可找到那些学校的所有特征，其他人对这些学校的评价。你能找到关于这些学校的博客和其它的选择。你可以有一个能收集这些学校的所有特征的人工智能系统——它们距离多远、得到了哪些评价……你可以进入一个关于你想从教育中得到什么的主页，而人工智能系统可以将这些信息聚集到一起。它们可以查看这些特征，它们可以从过去的经验中学习，它们可以处理所有的信息，根据你的指导和问题发送所有可用的消息，以一种你能更容易消化的方式呈现这些信息。因为网络上的这些信息非常繁杂，你根本不可能实时处理掉所有这些信息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，你可能也会想有一个能告诉你它这样建议的原因的助理。你可能会问：「为什么你说我应该买这辆车？我真的不喜欢那个品牌。」我认为这是非常重要的一步，让人工智能在决策中支持人类，尝试结合和学习所有的信息，并且整合你可能给出的反馈。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：除了个人决策之外，这些系统还能做什么？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：你可以想象这同样系统的一个版本可以用于科研论文。目前已经有很多的科研论文发表了，而且现在它们都在网上。你可以想象有一个人工智能系统能帮助研究者消化所有这些信息并找到他们感兴趣的东西。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个人工智能系统将仍然是网络上的信息的一个产物。很多人正在研究信息——文本信息、图片信息、流图表、表格——尝试理解网络上有什么并最终推理对这些信息的需求。比如，机器学习里有一个叫做「主动学习（active learning）」的领域，其中我们推理出其中一些过程的图像不够，而因此你可能会想要增加更多的图像。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我设想会有能够识别缺少什么的人工智能系统，从而能够将网络上的信息点连接起来，并在有需要时请求更多的数据。你可以想象它可以问研究者：「如果你告诉我更多有关这些细胞与这种化学品的交互方式，我就能有一个更好的关于当前情况的模型。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：你的共生自主思想的一部分已经体现到了 Cobot 中，对吗？这些机器人目前被放养在 CMU 的校园里，通过一套深度相机、WiFi 和 LIDAR 装置在计算机科学大楼里面导航。它们没有机器臂，所以对于很多简单的导航任务它们也会有麻烦，但你让它们很擅长寻求帮助。&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;是的，当我们意识到这些自动机器人也有限制时，我们也很吃惊。它们没法必须打开世界上所有的门，它们也不能理解世界上每一种口语。也许它们会随时间变得越来越好，但同样地，我相信人类也有限制——我说话有口音，我的网球打得没有其他人那么好——所以这些机器人也会有局限性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们很清楚这些机器人，这些人工智能系统最重要的一个特征就是识别它们不知道什么、不能做什么和不能理解什么，然后才向人类求救。你能按下电梯按钮吗？打开一扇门？或拿些东西放在我的篮子里，这就是我们所称呼的共生自主（symbiotic autonomy）。机器人能够对那些它不能做的、不知道的或不理解的问题自主地向人类寻求帮助。这是一种新的思路，我们将有一些围绕在我们周围并将寻求我们帮助作为它们部分任务的人工智能系统。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当这种系统实现规模化时，共生自主会以更复杂的方式发生。系统已经能用无线交流了，它在云端交流数据，或获得远程团队的协助。你可以认为人工智能系统能和其它所有事物永远成为一个共生系统，比如网络上的信息、其它人工智能系统和旁边的人类或远处的人类。它成为一个独立运行的人工智能系统也是完全没有问题的，但是一个人工智能系统要意识到什么时候它不知道、什么时候它需要信息、什么时候该用一些概率来思考问题都是不确定的。它不能预先解决所有问题，但它能依赖于周围其他的帮助来解决，这也就是我所设想的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：你怎样看待共生关系改变下已有的人工智能系统？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;所以让我们返回去设想向人工智能求教怎样决策上哪所学校或投哪种健康保险。我猜想这些人工智能系统将在某种情况下需要一些人类没有提供的信息。人工智能系统也将意识到如果它们知道那些额外的特征，这将会帮助我们更好地决策。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;真正有趣的是什么时候人工智能系统能自己认识到它们缺失了些什么信息。它们意识到是否能有更多的信息，是否能做一些明确的行为，例如它们是否能够预订那家网上订不到房间的旅馆、是否能给你订一个离开会地更近一些的旅店。我真的认为这种能力是很重要的，因为我不打算知道需要做某些决策的所有信息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在我们用的 Uber、谷歌地图或 Waze 通常对路线的的规划已经是做得很不错了，然而 Waze 会反过来问你「你现在饿了吗？我能给你一条最短路径吗？你喜欢走这条岔路看看更美的景色吗？」。如果智能助手知道我十分喜欢兰花、十分喜欢某种艺术那有怎么样？我只要稍稍地偏离路径，我就能看到更好的博物馆。它在路线规划中并不知道这些，如果知道这些，那么它一定会规划一条通过博物馆的路。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：许多现在的人工智能系统专门从事某一具体的任务，如对象识别或路径优化，但是这就导致了十分孤立的专家系统。我很好奇为什么你想的是带领我们返回一种软件中更为泛化的智能。&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：通用人工智能问题是极端困难的，我也确信深度学习就是其要求的技术基础，深度强化学习也会为通用人工智能加把料。我们也在做许多这种理解迁移学习概念的研究。我们是怎样有这些算法的——是因为它们能够从事特别的任务，但同样还能学习更多其它东西吗？我们并没有真正理解人工智能，我们还不知道做很多的事情。按照算法与技术、泛化的方法和提供解释的方法来看，我们的人工智能还真正处于婴儿期，关于很多这些事情我们还束手无策。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我真的认为通用人工智能有一天能从聚合人工智能专家系统中诞生出来，就像 Minsky 描述的那样合并他们就成为了一种心智社会（Society of Mind）。你也可以用一些特殊目的的算法来解决特别复杂的问题，就像 Simon 和 Allen Newell 在人工智能刚开始研究时预测的那样。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以通用人工智能是极其困难的，但因为现在这么多的数据它又是极其令人兴奋的。现在有很多人在使用电子设备并产生数据，而且越来越多的人在使用计算机、手机、Alexa 和 Uber，所有这些都给我们在研究通用人工智能铺平了道路。我们仍然还有很多研究要做，仍然不知道通用人工智能系统确切的样子，但是我们在一条正确的道路上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：你曾经担心过这种不确定性吗？有一些担忧是当人工智能超越人类的智能，那么人类也将会灭亡。&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我完全是一个乐观主义者，我认为我们所做的自主系统研究（包括自动驾驶汽车和自主机器人）都是要求对人类负责的。在某种意义上，这是和技术毫无关系的。技术会发展，但它是由我们由人类发明的。它不是从外星人那来的，而是我们自己的研究。它是人类智能构思的技术，它取决于人类思维也充分地利用人类思维才产生。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我很相信这将发生，之所以我很乐观是因为我看到人类已经意识到了他们需要很小心地研究这些技术，同样我也意识到了。但是最好还是投资于教育。把机器人扔在一边，它会持续变得更好，但是聚焦于教育，人们知道其他人、关照其他人、关心社会的进步、地球自然的发展和科学的进步。解决所有这些问题、治疗癌症、终结贫穷等。很多和人类相关的事都能使用这种我们正在发展的技术去解决。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在某种程度上，人工智能的人文主义将最终能将我们凝聚到一起，所以我是很乐观的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译文章，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 17 Nov 2016 10:16:24 +0800</pubDate>
    </item>
    <item>
      <title>业界 | CMU教授邢波创立公司Petuum，获1500万美元A轮融资</title>
      <link>http://www.iwgc.cn/link/3537503</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自CMU&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李泽南、杜夏德&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;卡耐基梅隆大学（CMU）教授邢波花费几年时间开发完善了一个平台 Petuum，利用工作站、分布式计算机、移动设备或嵌入式设备来解决大型机器学习的问题，现在这个平台已走出实验室，成为一家独立公司。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该公司的创始人兼首席执行官邢波表示，该公司已获得了 1500 万美元 A 轮融资，并预计明年年初将其首批产品投入市场。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器学习和人工智能技术是自动驾驶汽车、语音识别、计算机视觉、自然语言处理和电子医疗记录分析等许多科技公司在大数据分析应用和创新工作的关键。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「在十到二十年后，人工智能和机器学习程序将会接管计算设备中的大部分任务，」邢波说道「我们需要优化这些程序在设备中的设计，编程和运行效率，特别是在这些程序体量不断增大的情况下。在一些领域中，如自动驾驶汽车，目前仍然受到人工智能和机器学习——它们现在还是黑箱——的限制，无法快速发展。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「Petuum 有望成为转变这一现状的平台，让人工智能/机器学习程序能够轻松构建，并且使用标准化，透明和可重复的方法在不同的硬件平台上安装和运行，Petuum 平台允许程序快速、准确、规模化地运行，同时只需要耗费少量的计算资源，」邢波表示。「该公司的愿景是让他们的平台能够在任何硬件上运行。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我们的平台将使用不同的计算设备，从数据中心到移动设备，嵌入平台，让它们像个人电脑一样运行，」邢波说道。人工智能需要处理的大数据集通常已存在于这些设备中。Petuum 将允许机器学习系统在这些分布式计算设备中进行无缝操作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Petuum 寻求在分布式计算的更大规模上增强和扩展人工智能和机器学习的应用。计算设备之间的通信对于人工智能/机器学习来说可能是个棘手的问题，但邢波认为，他和他的同事们在 Sailing Lab 中开发的参数服务器具有高效管理通信和负载平衡的方法，在过去的以自年自动保持设备运行同步。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然一些其他团队也正在使用分布式设备解决机器学习问题，但邢波和他的团队的已经表明他们的方法为所有类型的机器学习任务提供了最佳，最有效的解决方案，不仅仅是某一方面，如深度学习。这一平台可以支持多种形式的应用，如自然语言处理，图像和视频的识别，以及交易数据中的异常检测。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了推动公司发展，「我们已经走到不得不融资的一步了」，邢波说道。未来 6 个月，他希望能招到 30 到 50 个人，需要受过高级研究训练的计算机科学家和工程师，把公司的水平维持在卡耐基梅陇大学的高度上。他补充道，「我们的目标是以匹兹堡为根据地，利用好这个城市和 CMU 的资源，帮助我们获得我们需要的顶尖人才。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;邢 &amp;nbsp;波&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;卡耐基梅隆大学计算机科学学院教授，卡耐基梅隆大学机器学习和医疗中心主任。美国新泽西州立大学分子生物学与生物化学博士；美国加州大学伯克利分校（UC，Berkeley）计算机科学博士。主要研究兴趣集中在机器学习和统计学习方法论及理论的发展，和大规模计算系统和架构的开发，以解决在复杂系统中的高维、多峰和动态的潜在世界中的自动化学习、推理以及决策问题。目前或曾经担任《美国统计协会期刊》(JASA)、《应用统计年鉴》(AOAS)、《IEEE模式分析与机器智能学报》(PAMI)和《PLoS计算生物学杂志》(the PLoS JournalofComputational Biology)的副主编，《机器学习杂志》(MLJ)和《机器学习研究杂志》(JMLR)的执行主编，还是美国国防部高级研究计划署(DARPA)信息科学与技术顾问组成员，曾获得美国国家科学基金会(NSF)事业奖、Alfred P. Sloan学者奖、美国空军青年学者奖以及IBM开放协作研究学者奖等，以及多次论文奖。曾于2014年担任国际机器学习大会（ICML）主席。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Petuum 公司简介&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Petuum, Inc. 正在开发一个服务各种人工智能和机器学习算法和应用的平台。它的产品让企业可以打造用于真实世界的人工智能和机器学习实现。&lt;br/&gt;Petuum, Inc. 有一个实力雄厚的顾问委员会，汇集了一些学界和产业界的重量级人士，包括：&lt;br/&gt;Michael I. Jordan：加州大学伯克利分校电气工程与计算机科学系和统计学系 Pehong Chen 杰出教授&lt;br/&gt;Stephen P. Boyd：斯坦福大学信息系统实验室电气工程教授和工程学院 Samsung 教授&lt;br/&gt;Kai Li（李凯）：Data Domain 创始人兼首席科学家；普林斯顿大学计算机科学系 Paul M. Wythes '55, P'86 and Marcia R. Wythes P'86 教授&lt;br/&gt;Harry Shum（沈向洋）：微软执行副总裁&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译文章，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 17 Nov 2016 10:16:24 +0800</pubDate>
    </item>
    <item>
      <title>专栏 | 第四范式先知平台的整体架构和实现细节</title>
      <link>http://www.iwgc.cn/link/3537504</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心专栏&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;Infoq授权转载&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：胡时伟、涂威威&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;在不久之前的一场演讲中，&lt;span&gt;第四范式联合创始人、研发副总裁胡时伟，以及「先知」平台的核心计算框架 GDBT 的开创者涂威威对先知平台的整体架构与实现细节进行了详细的介绍。在 12 月份，机器之心也将联合第四范式举办一场线下分享活动，感兴趣的读者可点击阅读原文报名。活动介绍附在文后。&lt;/span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717515&amp;amp;idx=1&amp;amp;sn=897ffd8a396d17ca4f785d499f7ae854&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717515&amp;amp;idx=1&amp;amp;sn=897ffd8a396d17ca4f785d499f7ae854&amp;amp;scene=21#wechat_redirect"&gt;第四范式·先知作为第四范式的核心产品，发布以来一直备受关注&lt;/a&gt;&lt;/span&gt;&lt;span&gt;。今年 10 月，先知荣获了中国智能科学界最高奖「2016 年吴文俊人工智能科学技术奖一等奖」。在正在举行的乌镇世界互联网大会上，先知将正式开放公有云版。定位于部署在公有云上的机器学习平台，先知公有云版有望帮助互联网公司零门槛地拥有人工智能技术，解决人工智能在不同行业企业、特别是互联网公司应用的问题。这也是第四范式为降低 AI 入场门槛而做出的较大突破。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;近期，先知主创团队在大数据杂谈上做了一个比较详细的系统介绍。主讲人是第四范式联合创始人、研发副总裁胡时伟，以及「先知」平台的核心计算框架 GDBT 的开创者涂威威。这也是第四范式团队首次对外披露设计、研发、部署先知过程中的一些经验，探讨机器学习从系统和工程方面的优化方向。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;具体分享内容如下，接下来主要从如下几个方面来讲述：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="list-style-type: decimal;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;为什么人工智能系统需要高维大规模机器学习模型&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;训练高维大规模机器学习模型算法的工程优化&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;机器学习产品的架构实践&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先先从人工智能发展说起，人工智能并不是一个最近出现的概念，早在 60 年代就有著名学者曾经预言二十年内机器将能够完成人能做到的一切工作。到今天我们又听到说 20 年之内，一大半的工作岗位将被机器人替代。那么 60 年代到今天发生的最大的区别是什么？这其中发生了两个重大的变化，第一个是计算能力的突飞猛进，今天的手机一个核的计算能力就足以秒杀当年的超级计算机。第二个是我们拥有了大数据，TB 级的数据存储、处理在今天已经不再困难，而 20 年前，GB 级的硬盘才刚刚兴起。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因此我们说今天人工智能=机器学习+大数据，那么什么样是好的人工智能呢？这里引入一个「VC 维」的概念。「VC」维是 1960 年代到 1990 年代由 Vapnik 及 Chervonenkis 建立的一套统计学习理论。VC 维反映了函数集的学习能力，VC 维越大则模型或函数越复杂，学习能力就越强。之前，统计建模曾经进入过一个误区，就是去追求经验风险最小化，什么意思呢？就是说我希望建立一个模型，在给定的样本上不要有误差，这样感觉非常好，但是往往这么一来，在实际的预测中非常糟糕，这是为什么呢？是因为采用了一些 VC 维很高的模型，虽然函数集学习能力是强了，但是由于数据不够，所以导致置信风险变大产生了一些类似过拟合的情况，最后这个模型还是不好用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是今天我们进入了大数据时代，样本的数量，包括样本的特征丰富程度有了极大提升，这就又带来了提升 VC 维的新机会。我们经常说经验主义害死人，过去的建模就是害怕经验主义，所以呢就把这个大脑变笨，降低 VC 维，使得模型更有效。但是今天的大数据情况下，可以通过补充更多的阅历（数据），来避免经验主义，那么一个阅历丰富的聪明的人，自然是要比一个笨的记不住东西的人要好的。因此我们说大数据人工智能时代，提升 VC 维变成了一个好的人工智能系统的关键因素。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;那么机器学习中的高维度从何而来？传统方法只能利用可以放在特征矩阵这个平面中的数据，对于立体的数据，多维度的数据，因为它们多不是数字，所以传统机器学习模型无法处理，只能选择舍弃。但在实际工业应用中，这类非数字化的数据所包含的信息，往往信息价值很高，比如它可能对个性化推荐很有影响，可能对泛化处理有帮助。为了能成分利用这些数据，我们对特征矩阵外的立体的数据通过切片等算法进行变换，使得变换后的数据成为特征矩阵的一部分，同时还对不同特征之间进行交叉组合等操作，这样特征矩阵的每一行的列数就从原始数据的列数，变成了每一行都是一个巨大（比如 2 的 64 次方）的向量，形成超高维度的模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;高维度模型真正的意义何在？通过对原来立体数据切片处理，可以使得某些过去只能有简单线性表达的数据，比如年龄等，获得更接近真实情况的细腻体现；此外，原来机器学习不能利用的非数字、没有排序关系的数据，比如姓名等，也可以发挥其价值所在。举个例子，在个性化推荐的场景中，体现个性化信息的数据之间通常是不可比的，比如，我们先只考虑热度、推荐序号和用户 ID 三个变量，其中用户 ID 这个变量就是传统机器学习模型所不能利用的，只有通过将这个数据切片处理，获得一个高维度模型，才可以真正将用户信息这个数据发挥出价值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;要获得一个成功的高维度模型，就需要好的机器学习系统，这个系统应当具备两个特征：横向可扩展的高计算性能和算法本身在收敛过程中的正确性。为此，我们的算法工程团队开发了一系列的基础设施组件，组成了大规模分布式机器学习框架 GDBT（General Distributed Brain Technology）。GDBT 是一个由 C++编写的，完全分布式的适合于机器学习计算场景的计算框架，可以运行在单机、MPI、Yarn、Mesos 等多个分布式环境。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;大规模分布式机器学习框架 GDBT&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器学习是一种数据驱动的实现人工智能的方式，机器学习在实际应用中的大数据、高维度背景导致需要一个高效计算的平台，同时，监督学习领域著名的 No Free Lunch 定理指出，没有一个机器学习模型能够对所有的问题都是最有效的。所以在不同的实际问题里，需要使用不同的机器学习算法或者对机器学习算法做适应性地调整，去达到更好的实际效果。因此在实际的应用中，需要能够非常容易地开发出适应实际问题的机器学习算法。相比于传统的 ETL 计算，机器学习算法的计算过程有很多自身的要求和特点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在框架设计上，没有普适的最好的框架，只有最适合自身应用场景的框架。GDBT 框架的设计初衷主要就是打造一个专门为分布式大规模机器学习设计的计算框架，兼顾开发效率和运行效率。GDBT 框架不是某一种算法，而是一种通用的机器学习算法计算框架，使算法工程师可以基于 GDBT 开发各种传统或者创新算法的分布式版本，而不用过多地关心分布式底层细节。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前比较流行的计算框架比如 Hadoop、Spark 其重点任务大多是 ETL 类的任务。前面提到机器学习计算任务相比于传统的 ETL 计算任务有很多自身的特点，时间有限这里可以简单地展开一下。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在计算方面：相比于 ETL 会做的一些相对「简单」的运算，机器学习算法会对数据做相对复杂的运算，一些非线性的模型，比如深度学习模型会需要比较密集的计算；在实际的应用中，需要考虑不同计算资源的特性；分布式计算中，由于分布式带来的通讯、同步、灾备等等的 overhead 需要调整计算模式来尽可能地降低。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在通讯方面：很多机器学习算法在计算过程中会频繁使用到全局或者其他节点的信息，对网络吞吐和通讯延迟的要求要远高于 ETL 任务。同时，很多机器学习任务对于一致性的要求要低于 ETL 任务，在系统的设计上可以使用放松的一致性要求。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在存储方面：ETL 需要处理来源不同的各种数据，比较少的反复迭代运算，很多机器学习算法会对数据做反复的迭代运算，可能会有大量的不断擦写的中间数据产生，对存储的使用效率、访问效率有着更高的需求。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在灾备和效率的权衡方面：容灾策略有两方面的额外开销，一方面来自于执行过程中为了容灾所需要做的额外的诸如状态保存之类的操作，另一方面来自于灾难恢复时所需要进行的额外重复计算开销。这两方面的开销是此消彼长的。与 ETL 计算任务不同，机器学习计算任务流程相对复杂，中间状态较多，在较细的粒度上进行容灾会增加执行过程中的额外开销。因此在容灾策略和容灾粒度上，机器学习计算任务和 ETL 计算任务之间的权衡点不一样。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;GDBT 计算框架针对机器学习任务在计算、通讯、存储、灾备等方面做了深入的优化。时间有限，这里可以简单的讲一点 GDBT 的工作，有兴趣了解更多的同学可以会后再和我们联系，或者加入第四范式一起解决这些有趣的问题：）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在计算方面，计算硬件发展到今天，提升计算能力的主要方式是堆积计算能力的分布式并行计算，比如现在做深度学习非常流行的 GPU 本身也是一种并行计算硬件，针对不同需求的计算硬件的种类也在变多，比如 FPGA 等等。对于大数据、高维度、复杂的机器学习计算任务，GDBT 框架充分考虑了分布式并行计算的特点，针对不同的硬件资源、不同的算法场景做了调度、计算模式、机器学习算法部件的抽象等的优化。GDBT 框架本身在设计上也刻意避免了现在一些框架设计容易走入的误区。比如：为了分布式而分布式，但是忘记了分布式带来的 overhead。GDBT 框架针对单机、分布式模式分别进行了优化，框架本身会对不同规模的计算任务、不同的计算环境做自适应的调整选择更高效的实现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然后在通讯方面，通信效率是分布式机器学习系统中至关重要的部分。首先, 相比于 ETL 任务, 很多机器学习算法在计算过程中会频繁使用到全局或者其他节点的信息, 对网络吞吐和通讯延迟的要求都很高。其次, 一些机器学习算法在通信时可能有很多可以合并处理的通讯需求。再次, 很多机器学习算法并不要 求在所有环节保证强一致性。最后, 对于不同的网络拓扑, 最优的通讯方式也会不一样。因为存在可能的合并处理、非强一致性需求、网络拓扑敏感等, 就会存在有别于传统通讯框架的优化。先知的 GDBT 计算框架内部, 针对机器学习计算任务单独开发了一套通信框架, 为机器学习任务提供了更高效、更易用的支持点对点异步、点对点同步、深入优化的组通讯 (比如类 MPI 的 Broadcast、 AllReduce、Gather、Scatter 等等) 的通信框架, 同时为应用层提供了简便易用的合并、本地缓存 等等功能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然后介绍下我们在参数服务器（Parameter Server）方面的工作，很多机器学习算法的学习过程都是在「学习」一组参数, 对于分布式机器学习任务, 不同的节点需要对「全局」的这组参数进行读取和更新, 由于是分布式并行的计算任务, 因此存在着一致性的问题, 不同的机器学习算法或者同一个机器学习算法的不同实现对一致性的要求会不尽相同, 不同的 一致性策略对整体算法的效率会产生很大的影响。参数服务器就是为了解决分布式并行机器学习任务中多机协同读取、更新同一组参数设计的, 设计上需要提供简单易操作的访问接口方便机器学习专家开发算法, 同时也需要提供可选择的一致性策略、灾备等等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外，由于是为机器学习任务设计，参数服务器的设计目标是高吞吐、低延迟。GDBT 中的参数服务器针对不同的应用场景做了更 加深入的优化, 结合高效缓存、智能合并等优化策略以及基于 GDBT 自带的高效异步通讯框架, 同 时, 还针对稀疏、稠密等不同的参数场景进行了针对性优化;内置提供了丰富的一致性策略可供用户选择或自定义一致性策略；GDBT 将参数服务器看成一种特殊的 Key-Value 存储系统, 对其进行了独立的灾备设计, 同时提供不同粒度的灾备选项, 便于在实际的部署中选择合适的灾备策略提升效率。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这次我主要讲计算框架方面的工作，以后有机会可以再详细分享我们在机器学习算法框架以及机器学习算法方面的设计工作。针对机器学习算法计算，GDBT 框架做了进一步的抽象，比如数据流、优化算子、多模型框架等等，这里简单介绍下数据流的设计。对于研究并实现机器学习算法的专家而言，算法的核心就是数据的各种变换和计算。GDBT 框架为了让机器学习专家更容易、更快速地开发出不同的机器学习算法提供了数据流的抽象，使得机器学习专家通过描述数据流 DAG 图的方式编写机器学习算法。机器学习专家只需要关注数据的核心变换和计算逻辑，GDBT 计算框架将机器学习专家描述的数据流图进行高效的分布式计算。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数据流计算框架的抽象一方面有助于降低机器学习专家的开发门槛、提升开发速度（他们不需要关注底层分布式、并行细节），另一方面也为 GDBT 框架提供了更大的空间去进行数据流执行优化，能够进一步提升执行效率（如果 GDBT 框架只在底层模块进行优化，将会非常乏力；但是数据流的抽象使得 GDBT 框架能够更全面地了解计算任务的 pattern，可以做更多的优化工作）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在存储、灾备设计等方面，GDBT 也做了深入的优化，比如多级缓存的设计、框架层面对存储读取写入、网络访问、计算过程等等的灾备设计，对不同计算规模采取不同的灾备粒度等等，这里时间有限，就不做过多介绍了。机器学习算法部分的工作以后有机会可以再一起交流。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;GDBT 定制的通信框架、算法框架以及参数服务器，为进行大规模机器学习训练提供了基石。当然 GDBT 还有一个很大的特性是算法开发者友好，对于算法开发来说，学术研究和工业应用之间存在一定的取舍。一些其他的算法框架比如 Tensorflow，比较注重研究上的易用性，从而在效率上有所舍弃，而一些注重于生产应用的算法框架特别是分布式框架，在算法二次开发和扩展上则捉襟见绌。GDBT 提供的是工业级的开发者易用性，从语言级别，GDBT 整体基于 C++ 14 标准，为算法的开发提供了更大的自由。从功能抽象上，GDBT 提供了对参数服务器和算子的良好包装，在 GDBT 上，只需要数百行代码就可以实现像逻辑回归、矩阵分解等算法的分布式版本。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;机器学习算法框架的语言选择问题&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;关于机器学习算法框架的语言选择问题，因为今天很多的大数据框架都是基于 Hadoop/Spark 这一套的，都是 JVM 上的东西，因此基于 JVM 从整体来说接入生态是比较容易的，但其实有三点理由让我们选择 C++而不是基于 JVM 去做这件事情。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先我们前面讲过，目前虽然计算能力对传统应用来说井喷，我们经常说 CPU 过剩、GPU 过剩。但是对于高维机器学习过程来说，依然是资源非常紧张的，这里面包括计算、网络、内存等多个方面，我们看 Spark 的 Project Tungsten 也做了大量堆外内存管理的工作以提升数据的处理效率，但是对机器学习来说，基本上整个过程都需要对内存和计算过程进行精细控制，以及避免不可控的 GC 过程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其次，C++的一些语言特性，比如运算符重载机制也可以使得框架上层的算法应用的语法比较简单优雅，不会变成巨大的一坨，而大规模机器学习很多时候和字符串组成的离散特征打交道，C++对字符串处理的效率也要高出 JVM-Based 语言非常多。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;再次，Spark 目前的机制和 Parameter Server 的结合很难做到优雅和完美，强行对接 PS 会破坏 Spark 自身的灾备、任务调度等特性。如果不对接，那么就基本上只能靠降低模型大小来确保效率，和高维度的目标南辕北辙。所以综合考虑，我们还是选择 C++来实现整个一套的系统，而将和大数据框架的对接以及开发门槛降低这个任务交给整个机器学习系统的架构。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;整体架构&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;上面讲了很多机器学习算法框架，但有过实践经验的朋友都知道，光有一个算法框架只相当于汽车有了发动机，离开起来还很远。我们总结一个完整的机器学习系统需要有如下部分：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;数据引入和预处理&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;特征工程&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;模型训练算法（支持参数灵活调整和二次开发）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;模型评估&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;模型上线（批量预估、实时 API 调用、线上特征实时计算）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;那么对于这所有的部分，我们开发了一个叫『先知』的整体平台产品，我们先看一下先知的整体架构图：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9xhznsLIp5sSbIiayEITWLFvJ7upAq9QqBb3WV36pNG7XMAPwQTtJxRHBZ2Y2VFmcsGiaicQxfnOpxQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;整体来说，先知平台由界面层、调度管理层、集群适配层、集群任务执行层，另外外加一个线上的预估服务云。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这套架构能够给我们带来如下几个优势：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 把整个机器学习过程作为一个整体来看待，做到各模块的深度整合。下面是我们产品的一个截图：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9xhznsLIp5sSbIiayEITWLFicrc99cjZz7gWibsAibIRbtvbz9kUPuZQllricSq1NGWBo8G4GFqiaXtzYQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;可以看到，通过一个 DAG 图的描述，可以将大数据的处理过程（SQL/PySpark/数据拆分）和机器学习的过程（特征工程、模型训练、模型评估）整体结合起来，用户不再需要去开发脚本去处理复杂的模块和模块之间的对接以及输入输出的各种判断。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;同时呢，这个 DAG 图的背后我们还做了很多工作，一个比较有意思的就是对存储的抽象和适配。我们有的客户是用 AWS 作为基础设施，而有的客户用阿里云做基础设施，有的客户则选择在 IDC 内构建自己的机房。这里面就有块存储、云盘、SSD、内存盘等多种存储服务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外，一个完整的机器学习过程，往往还要从数据库里面导入数据，最终要把数据导出到某个指定的位置。导数据在逻辑上的复杂性和由于某些开源模块不支持内存缓存和 SSD 导致的性能的低下都是困扰数据科学家的问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对此设计了一个两层的存储抽象层 API，第一层是一个开源项目 alluxio，就是以前的 tachyon，alluxio 这个东西是非常好的，好在哪里呢？他用一套解决方案一下子解决了几个问题，第一是可以支持很多分布式的文件系统，包括 S3、Ceph 等。第二还能够比较透明的解决内存和 SSD 加速的问题。针对 Alluxio 这个项目，我们将整个的数据处理、模型训练、预估体系，包括我们自己开发的 GDBT 框架都和 alluxio 做了深度的融合集成，也针对开源的产品在访问调度、吞吐、SSD 优化上做了一些增强和修补的工作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第二层是 DataManager，我们知道企业的应用，特别在意安全性，那么如果我们直接把底层的文件系统暴露给使用者，会导致权限隔离等个方面的隐患。Datamanager 提供了一个数据的逻辑沙箱，使得每个使用者在自己的 DAG 里面只能用一个唯一的名字来访问到自己安全容器内部的数据，这样不仅保证了安全，也避免了使用者直接去处理各种各样的长的数据文件的 URI。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 给开发者提供比较好的体验，相信使用大数据系统的朋友都有一个感受，就是在分布式时代，调试变得难了。一方面很多时候日志太过于复杂，不知道错误在哪里，另外一方面经常出现跑了几个小时报一个错前功尽弃的情况。先知平台从产品上做了很多工作，比如说 Schema 推断：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9xhznsLIp5sSbIiayEITWLF81jv2GXTaPrEtWSuSc9nIYwGdrCnTTLHhtpiakafHM0euW2g33ibcLicg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们可以在运行这个 SQL 之前就在界面上交互式的看到哪里出了错误，以便及时改正，而不需要整个 DAG 图跑了几个小时，运行到这个地方的时候，可能人都去睡觉了报个错，只能第二天再来。另外比如我们还提供了特征重要性评估的功能：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9xhznsLIp5sSbIiayEITWLFtlibsSn0p4UqSMSgKWmDI2WvBSglKT4vYyRe9VwttfeBBMTsicibwL3LQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个功能可以让使用者很快发现自己模型里面的问题，比如某个特征重要性极高，需要考虑自己的模型是不是有看答案（用结果去训练模型，再去评估结果，导致模型线下评估效果非常好，线上无效）的现象。值得一提的是，这个特征重要性评估的算法也是基于 GDBT 框架开发的，GDBT 不仅可以高效的支持各种模型算法开发，也能够快速的支持各种其他的大规模分布式计算逻辑。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3. 支持模型的上线，模型上线有几个技术上的难点，一是线上线下的一致性，而是性能。线上线下一致性为什么难，因为你看到训练过程是那么复杂一个 DAG 图，那么对应的线上多个数据源，也要经过一个组合、变换的过程，那如果每次都去手动开发，这个代价就不得了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;先知的架构支持从线下的 DAG 导出线上服务的核心部分，那么特征工程、模型计算就可以直接获得一个可用的 API，可以极大的节省开发者的代价。另外一个难题就是性能，因为线下批量的训练，可以花很长时间，而线上如果是实时预估，那么就要毫秒级的响应，也要求很高的 QPS。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们在线上有一个叫 Cannon 的分布式 KV 框架，可以支持到数十 T 分布式内存的模型高性能存储和查询。而模型计算的部分也可以复用 GDBT 的代码，既减少了开发量，又为一致性提供了保证。这里面也有很多有意思的工程优化，比如说如何解决机器数变大、网络条件变差情况下的可用性塌方式下降。今天时间有限就不展开说了，有机会可以再跟大家分享。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;小结&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;非常感谢大家耐心听我们分享了上面我们做的这些微小的工作。第四范式是一家人工智能技术与服务提供商，拥有大批顶尖的数据研究科学家，和追求极致匠人精神的工程师。各路 ACM 冠军选手每天在各个方向上进行深入的产品和工程优化工作，希望能够促进机器学习和 AI 在各行各业的发展，也希望能够给从业者们带来更好用的平台和工具。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当然做出好的机器学习解决方案，最关键的还是要和行业结合，工具和平台系统只是其中的一小部分，所以还希望能够向各位同仁多多学习。现在先知平台公有云版本已经向业务场景成熟的企业客户开放合作，如果有风控、内容推荐、客户经营等场景的朋友，我们也可以一起互相切磋，互相学习。谢谢大家。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Q&amp;amp;A&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Q1：请问先知平台用到深度学习框架了么？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;答：现有的开源的深度学习框架不能完全解决先知平台客户的问题，因为很多实际的问题，除了包含稠密的连续特征之外，还有大规模的稀疏离散特征，目前大部分的开源框架大多 focus 在稠密连续特征的深度学习问题上，对学术界比较关心的同学，可能可以发现 google 最近有一篇 wide&amp;amp;deep learning 的论文是做类似的事情的，这个解决方案和我们三年前在百度做的解决方案很类似，但是很可惜的是开源的 tensorflow 在这个问题上效率非常糟糕。实际问题的难点在于它是 IO 密集（大规模稀疏）且计算密集的（稠密），而且这样的模型是极其难调的，我们有很多新的算法在解决这方面的问题，不仅仅是深度学习。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Q2：是通过何种机制做到数百倍的加速的？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;答：从算法设计到 GDBT 平台设计和底层优化，都有很多工作，今天的讲座里面有涉及到一些，可以翻看记录；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Q3：有没有提出一些最优化框架，比如 SVRG 等来加速收敛？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;答：对于不同的问题，不同的场景，会对优化算法有不同的需求，比如收敛速度、稀疏性、稳定性、是否便于实现、是否便于分布式并行、是否访存友好等等，先知支持多种优化算法（batch/stochastic 的都有），比如 lbfgs、FOBOS、RDA、FTRL、SVRG、Frank-wolfe 等等都会有涉及，同时针对不同的应用场景也需要做一定的改进和调整。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Q4：超参数学习这块是通过 bayes 还是强化学习呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;答：目前产品中的是 bayesian 的，其他方式也正在尝试。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Q5：在何种情况下如何判定自动特征不能起作用而改为人工特征呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;答：有很多特征选择的算法和策略，同时，对于实际的问题，可以先用自动特征处理取得一个初步的效果，再从实际模型效果去看是否需要人工介入做进一步的优化，自动特征工程是一个很难的问题，目前其实是很难做到 100% 全自动的，我们平台期望能够尽最大可能的降低人力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Q6：先知在实现过程中用到参数服务器了没有？模型的训练，是采用异步 asp，还是同步 bsp，还是半异步的 ssp 这种？如果是异步，如何解决收敛困难的问题？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;答：前面有提到，我们用到了 parameter server。模型训练支持多种模式，对于不同的算法，不同的计算环境，会采用不同的同步方式。其实目前大部分情况下，如果数据切分 计算调度得当，异步和同步差别没有特别大，计算资源有较大差别的时候，还是建议带版本控制；更好的方式是采用类似的计算资源做好数据切分和计算调度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Q7: 第四范式的先知和谷歌的 Tensor flow 有什么区别？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;答： 从覆盖范围上，先知是一个机器学习应用全生命周期管理的平台，而 Tensorflow 对应的是先知的 GDBT 部分。而对于 GDBT 和 Tensorflow 的区别来说，前面也讲到，首先 Tensorflow 更多是为算法研究目的而存在的，已经有一些 benchmark 说明 tensorflow 比目前很多开源的深度机器学习框架都要慢。当然我个人觉得，因为 Tensorflow 本身不是为大规模工业应用设计的，只是现在好的框架的确太贫乏了。Tensorflow 的一些设计理念比如高兼容性，跨平台也是很好的。这方面 GDBT 也都有考虑和规划。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Q8：GDBT 有没有解决模型并行训练问题？还是只依靠数据并行？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;答：也分不同的算法，GDBT 同时支持模型分布式和数据分布式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Q9：GDBT 怎么能够同时支持连续、离散的这两种数据的融合训练？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;答：解决这个问题，一个是效率，首先框架底层上要能够支持很灵活的调度，能够根据连续和离散的数据的计算特性做针对性的设计，比如连续复杂模型是计算密集，可能需要调度到 GPU 运算，离散数据可能是 IO 密集，需要做好计算调度，资源异步调度；更重要的是在算法上做更多的新的改进，因为学术界大多情况下是分别考虑，我们有一系列自己重新设计的算法。对算法细节有兴趣的同学，可以考虑加入到第四范式，或者等我们的专利公开:)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Q10：请问 GDBT 对于异构计算的支持情况如何？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;答：GDBT 目前支持 CPU 和 GPU 的异构计算。在百度的时候，我们有过在模型预测时使用 FPGA，不过，最近 GPU 进展不错，比如 nvidia 有一些新的芯片比如 Tesla P4 的出现，可能会对 FPGA 有一定的冲击，对于 FPGA 的使用，目前我们研究上还是跟随状态，并没有集成到先知产品中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Q11：第四范式的人工智能平台先知可以直接替代 Spark 么？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;答： Prophet 诞生的原因是因为我们为各种行业提供服务，每个行业的差异化乍一看都不少，按照传统的方式，我们需要 case by case 的去应对，给出对应的方法，然后进行实施。但在这个 case by case 的过程中，大部分的精力是花在如何把对领域专有知识的理解（业务理解）转换为机器学习过程的具体操作（数据科学家的工作），对于端到端的两端，数据 和 服务，反而是比较通用的。那么如果能够利用技术和算法，解决专有知识到对应机器学习过程的映射问题，我们就可以建设一个通用的平台来使得 AI 应用到不同场景的代价变小，实现人工智能的傻瓜机。Prophet 就是这个目标的第一步。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先 Prophet 定位在一套完整的平台，包括核心机器学习算法框架 GDBT（没错不是 GBDT，这是个算法框架，其作者起名为 General Distributed Brilliant Technology），以及机器学习任务调度框架 TM，以及人机接口 Lamma，还有架设在整个框架上的一系列算子。当然这些都是内部名字无所谓，总的来说 Prophet 提供的是端到端的机器学习能力，进来是数据，出去是 Service。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然后关于 GDBT 和 Spark，应该说对比的是 基于 GDBT 的算法 以及 基于 Spark 的算法（MLLib 实现），由于计算架构的不同，所以简单的来说多少多少倍是没有太多的意义，因为如果特征纬度多到一定程度，MLLib 在不做数据采样的情况下是无法完成某些训练的。但是具体在几千万行，几十个核的场景下，快几百倍是实测结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外，我们在做的事情，算法框架是一个部分，性能也是很重要的，但是做这些的目的是为了降低机器学习应用于具体行业的门槛和先决要求。这个先决要求既包含硬件上的，也包含人在机器学习方面知识的要求。拥有更强大的计算能力和特征处理能力，意味着我们可以更少的让人输入信息，而更多的依靠计算机自身的学习和计算来找到机器学习算法在具体问题上应用的最佳结合点，这其中甚至还需要包括如何去利用计算资源的投入避免机器学习常见的一些缺陷。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因此 Prophet 不会替代 Spark，Prophet 里面的很多组件也是基于 Spark 的，Prophet 的目标是把 AI 的能力较为容易的带到各个应用场景，为了这个目标，我们会利用好 GDBT，也会极致的利用好 Spark，也会利用硬件技术的最新进展。一切为了 AI for everyone。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;简单的来说，先知的设计范围超出了 Spark，包含了 Spark，所以不能说是替代。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Q12：什么样的企业用得起机器学习来辅助运营？使用你们机器学习系统的门槛是什么?&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;答：从目前来看，需要有一个好的业务场景和足够的数据。互联网的 APP 或者非常大的传统行业里面的推荐、营销、定价等场景都比较适合。数据量小的就要看，通常来说 10 万多样本分布均匀就有这个可能。用这个机器学习系统目前的门槛是首先要能理解数据和业务，有一定的统计的背景和思路，然后就是能够导入导出数据，最后就是阅读一下先知的使用手册和培训视频。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Q13：电商推荐平台，怎么样能最快地应用机器学习的精准推荐？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;答：对于推荐场景，我们有相对比较成熟的接入方案，可以快速通过数据和 API 接入，通过公有云的 SaaS 服务享受到 GDBT 的能力以及先知的整体效果。有需求的朋友可以关注我们的官方网站和公众号（NextParadigm），我们会近期放出先知推荐的试用邀请。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Q14：机器学习目前哪些企业和行业应用比较广泛？国内有哪些成功案例。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;答：大规模机器学习，BAT 今日头条等，广告推荐为主。我们在银行最近的探索也有很多成功的例子，比如在营销和定价、反欺诈方面。另外风控一向是机器学习的主战场。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Q15：自动特征这套做法，跟百度凤巢的那套是一样的对吧？百度有公开论文，是 gradient boosting factorization machine，这个方法比深度学习那个自动特征相比如何？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;答：做法和夏粉老师的那套不一样；夏老师和张潼老师这篇文章和 nn-based 的各有优劣。其实 NN 没有大家想的那么万能，「人工」的很多 feature combination 是 NN 很难学出的，其中有很多有趣的问题，这里就不赘述了，可以再交流。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外：对于 FPGA 和 GPU 的未来我们有一段简单的思考，之前有准备过一段，之前没用上，现在贴这里：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;FPGA 是作为专用集成电路领域中的一种半定制电路而出现的，既解决了全定制电路的不足，又克服了原有可编程逻辑器件门电路数有限的缺点。机器学习尤其是深度学习是计算密集型的，比如深度学习里面有大量的浮点矩阵运算这种并行浮点运算需求，传统的 CPU 从设计上而言已经很难满足这种大规模浮点计算密集型任务。目前针对这种机器学习任务，CPU 主流的替代选择是 FPGA 和 GPU。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;GPU 是固定的计算架构的计算设备，有着良好的软件编程接口，但是对于特定的计算模式和模型结构不一定是最优的选择。FPGA 本身是一种可编程的硬件，对于有研发能力的厂商而言，深度优化过的 FPGA，相比 GPU，能够提供更专有的硬件加速，更重要的是 FPGA 在单位能耗上能提供的计算能力要高于 GPU。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外，企业级 FPGA 也比企业级 GPU 便宜很多。但是 FPGA 的缺点也非常明显，对相关专业人才的要求非常高，需要能够将复杂的机器学习算法映射到硬件逻辑上，同时提供高吞吐和低延迟，开发难度很大。对于中小公司而言，如果没有相应的 FPGA 研发能力，或者无法支撑高昂的研发成本，在机器学习尤其是深度学习的训练/预估硬件解决方案上可以选择架构固定的 GPU；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而对于有相应能力的大中型企业而言，FPGA 带来的硬件成本的大幅降低和能耗的大幅降低，能够轻易覆盖研发团队的费用，在机器学习尤其是深度学习预估的硬件解决方案上 FPGA 会是更合适的选择。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;同时，在制造工艺上，相比于 FPGA，GPU 是固定的专用计算架构且不提供可编程能力，可以通过不断的芯片优化，提供更强的计算能力，对于计算更加密集的深度学习训练任务，GPU 现在还是更合适的选择。随着 GPU 在芯片上不断优化提升和能耗的降低，以及 FPGA 不断提升芯片可提供的计算能力，两者的差距在不断缩小，未来两者的地位是否会有大的变革，值得期待。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;讲师介绍：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;胡时伟 第四范式联合创始人，研发副总裁&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;在大规模机器学习、广告、搜索、行业垂直应用、系统运维、研发团队管理等领域拥有丰富经验。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;曾主持架构了百度「知心」系统和链家网系统，在百度任职期间作为系统架构负责人，主持了百度商业客户运营、凤巢新兴变现、「商业知心」搜索、阿拉丁生态等多个核心系统的架构设计工作。在担任链家网研发负责人期间，从 0 开始完成了链家网新主站、经纪人新作业系统、绩效变革系统的整体架构设计以及研发团队的建设管理，参与规划及推动了链家系统和研发体系的互联网化转型。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;现任第四范式研发总工程师，负责产品技术团队以及第四范式核心产品『先知』机器学习平台的研发工作。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;涂威威 第四范式数据建模专家&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;在大规模分布式机器学习系统架构、大规模机器学习算法设计和应用、在线营销系统方面有深厚积累。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;百度最高奖 trinity 发起人之一。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;首次将 FPGA 应用于在线营销深度学习预估系统。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;设计开发百度机器学习计算框架 ELF。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;活动预告&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;12 月 3 日，机器之心将联合第四范式举办主题为「人工智能在工业应用上的技术突破和研究方向」的线下分享活动。第四范式的联合创始人陈雨强也将带来相关主题的分享，我们也将邀请知名人工智能专家共同研讨如何将机器学习用于互联网业务的提升以及机器学习未来在互联网场景中的应用与发展趋势等话题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;陈雨强个人简介&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;陈雨强，第四范式联合创始人，首席研究科学家，世界级深度学习、迁移学习专家。曾在多个国际顶级人工智能会议发表论文，其工作被全球著名科技杂志 MIT Technology Review 报道。陈雨强主持架构了世界上第一个商用深度学习系统「百度凤巢系统」，大幅提升了广告点击率并使变现能力；主持架构了中国用户量最多的新媒体人工智能推荐系统「今日头条」，以支持千亿特征、千亿数据的流式机器学习系统，实现今日头条新闻推荐的个性化、准确性与时效性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;参与人群：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;人工智能行业从业人员&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;互联网行业从业者&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;投资人&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;活动时间：2016 年 12 月 3 日 14：00-17：00&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;活动地点：北京市朝阳区酒仙桥电子城科技园 A2 楼一层 机器之心&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;点击阅读原文报名此次活动↓↓↓&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 17 Nov 2016 10:16:24 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 谷歌推出A.I. Experiments：让任何人都可以轻松实验人工智能</title>
      <link>http://www.iwgc.cn/link/3537505</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自AI Experients&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;iframe class="video_iframe" data-vidtype="2" style="   z-index:1; " height="375" width="500" frameborder="0" data-src="https://v.qq.com/iframe/preview.html?vid=a1310qakyx9&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0" allowfullscreen=""&gt;&lt;/iframe&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能正在飞速发展，但很多没有技&lt;/span&gt;&lt;span&gt;术背景但想试试机器学习的风采的人却没办法进入这一领域。作为人工智能和深度学习研究和应用的领军者，谷歌也正在尝试解决这个问题，从而让更多人能够了解和使用人工智能——不管你是有技术背景的工程师和爱好者，还是刚入门的学生，更或是仅仅对此感到好奇的吃瓜群众。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为此，谷歌创建了一个名叫人工智能实验（A.I. Experiments）的网站。该网站在线显示了一些简单的人工智能实验，让任何人只需一台联网的计算机就能轻松上手，甚至可以创建你自己的实验。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWic45jgIOq2OCuFlIgqdSFLkEJv7uM5xsFJia2y0tibAGCOZO3ROtx1iatMEBIuHaDoCRRmBdBETziaTnQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;A.I. Experiments 网址：http://aiexperiments.withgoogle.com/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该网站上的实验展示了机器学习理解各种事物（包括图像、绘画、语言、声音等等）的方式。这些项目是由各种各样背景的人创建的，他们有的是开发者、有的是音乐家、有的是游戏设计师，还有鸟鸣爱好者、数据可视化工作者……任何人都可以将他们自己的想法和机器学习结合起来进行实验！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这里列举两个可以在线试玩的项目：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Giorgio Cam：基于照片生成音乐&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Bird Sounds：使用机器学习可视化数千种鸟叫声&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谷歌在其开发者博客上表示：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们也希望能让开发者能够更轻松地进行他们自己的实验。我们给出的许多项目都是用任何人都能使用的工具开发的，比如 Cloud Vision API、Tensorflow 和其它来自机器学习社区的库。这个网站有创造者解释它们的工作方式的视频，并且还链接到了对应的开源代码让你能够快速开始。你也可在 A.I. Experiments 提交你自己的作品，或者把玩别人做出的东西。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在最后，谷歌还推荐了 Google Arts &amp;amp; Culture 团队的一些作品，戳这里：http://artsexperiments.withgoogle.com/，希望能够为你带来一些使用机器学习的灵感。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译文章，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 17 Nov 2016 10:16:24 +0800</pubDate>
    </item>
    <item>
      <title>独家专访 | 腾讯AI Lab公布首项研究：提出独特神经网络实现实时视频风格变换</title>
      <link>http://www.iwgc.cn/link/3522584</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心原创&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：老红、李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;em style="color: rgb(136, 136, 136); line-height: 1.75em; text-align: justify;"&gt;&lt;span&gt;风格变换一直是机器学习领域内的一项重要任务，很多研究机构和研究者都在努力打造速度更快、计算成本更低的风格变换机器学习系统，比如《&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719733&amp;amp;idx=3&amp;amp;sn=950a7adb4e93bca22e4ef975877482a9&amp;amp;chksm=871b018bb06c889ddc87bccaa0f35de5ca5a35c156cf1164d134d5010065d68dd06ba6e7cdfa&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719733&amp;amp;idx=3&amp;amp;sn=950a7adb4e93bca22e4ef975877482a9&amp;amp;chksm=871b018bb06c889ddc87bccaa0f35de5ca5a35c156cf1164d134d5010065d68dd06ba6e7cdfa&amp;amp;scene=21#wechat_redirect"&gt;怎么让你的照片带上艺术大师风格？李飞飞团队开源快速神经网络风格迁移代码&lt;/a&gt;》、《&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720113&amp;amp;idx=1&amp;amp;sn=b45bd28cef19a06c717717d3622d58de&amp;amp;chksm=871b030fb06c8a199334d745ad1be56b6b7aeb364596743be7215cc7c6a15a23053c8b60639f&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720113&amp;amp;idx=1&amp;amp;sn=b45bd28cef19a06c717717d3622d58de&amp;amp;chksm=871b030fb06c8a199334d745ad1be56b6b7aeb364596743be7215cc7c6a15a23053c8b60639f&amp;amp;scene=21#wechat_redirect"&gt;谷歌增强型风格迁移新算法：实现基于单个网络的多种风格实时迁移&lt;/a&gt;》。如今新成立的腾讯 AI Lab 也加入了此行列，在此文章中机器之心对腾讯 AI Lab 的视频风格变换的研究进行了独家报道。&lt;/span&gt;&lt;/em&gt;&lt;br/&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9xhznsLIp5sSbIiayEITWLFYNwvfZQmkM7jXypFBNfqVHdEqJeOPYKGLSsmw432bj0xoSm4OhJm6Q/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;几天前，Facebook 在其官方博客上宣布了一种可以用在移动设备实现实时风格的深度学习系统 Caffe2Go，称能在眨眼之间完成处理的任务，而且还能实现高质量的视频风格变换。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而鲜为人知的是，腾讯新成立的人工智能研究部门腾讯 AI Lab 也在做这方面的研究，技术团队告诉我们腾讯 AI Lab 早在 9 月中就已经研发出了实时的视频风格变换技术，并用此技术对一些电影进行了风格变化，制作了非常酷炫的艺术人工智能电影，在腾讯内部已经有过展示。腾讯 AI Lab 的研究表示，他们已通过首创深度网络学习视频的时空一致性，在很大程度上提高了视频风格变换的质量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;iframe class="video_iframe" data-vidtype="1" style="   z-index:1; " height="375" width="500" frameborder="0" data-src="https://v.qq.com/iframe/preview.html?width=500&amp;amp;height=375&amp;amp;auto=0&amp;amp;vid=w03451hmwnf" allowfullscreen=""&gt;&lt;/iframe&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;近日，机器之心对腾讯 AI Lab 的研究团队进行了独家专访，这也是腾讯 AI Lab 研究团队首次对外发声。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;风格变换简史&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;将一张图像的风格变换成另一种风格的技术已经存在了近 15 年。2001 年，当时加州大学伯克利分校的 Alexei A. Efros 联合另外一位作者在论文《Image Quilting for Texture Synthesis and Transfer》中介绍了一种简单的基于纹理合成的方法，通过「缝合」已有的小型图像块合成新的图像外貌。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但利用神经网络来做这件事是最近才出现的。在论文《A Neural Algorithm of Artistic Style》中，研究者 Gatys、Ecker 和 Bethge 介绍了一种使用深度卷积神经网络（CNN）的方法。他们的风格转换图像是通过优化（optimization）得到的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一方面，CNN 的高层特征描述了图像的主要的结构化信息。另一方面，基于 CNN 每一层的特征计算得到的 Gram matrix 又可以很好的捕捉图像的风格信息（笔触以及纹理等）。结合这两种信息定义损失函数，指导图像从某个起始点（如：随机噪声或内容图像本身）开始，不断迭代优化，逐渐转变为风格变换后的图像&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8DLuIlocGmG4BCQ8jCHJbeRTowcsFpCfs2Vnx0YUfj3aELV4rTu6mWbQEkS21RbLcNVqbpvicL3ibg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;内容+风格=另一种风格图像（图片来自：Google Reserch）&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该成果被认为是深度学习研究领域的一项突破，因为它首次提供了基于神经网络的风格变换的概念证明。不幸的是，这种为单张图像施加风格的方法对计算要求很高。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不过到了 2016 年，俄罗斯的 Dmitry Ulyanov [1] 等人以及斯坦福李飞飞团队 [2] 的研究都大大加速了这一过程。这些研究认识到可以将这个优化问题转变成图像变换问题（image transformation problem），也就是将单个固定的风格应用到任意一张内容图像（比如一张照片）上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然后该问题就可以这样被解决：训练一个前馈深度卷积神经网络来改变内容图像的语料库（corpus），从而使之匹配某画作的风格。这个训练出的网络有两重目的：保持原有图像的内容，同时匹配绘画的视觉风格。这样得到的最终结果是：以前花几分钟的图像风格转换现在通过前馈网络可以实时得到，进而应用于实时视频风格变换。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;风格变换技术如何由图像扩展到视频？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;视频是未来互联网上最多的流量载体。在图像风格变换引起爆发性关注之后，一系列的公司，譬如 Aristo，Prisma, Philm 等都开始聚焦短视频的风格变换，包括对人工智能一向深切关注的 Facebook 也将推出视频风格变换技术（智能手机移动端）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;将风格变换技术由图像向视频拓展最为直接的方式就是使用图像风格变换的技术逐帧完成视频的变换，但是这样很难保证视频帧间风格的一致性。为此 Ruder 等人提出了一种迭代式的做法 [3]，通过两帧像素之间的对应关系信息来约束视频的风格变换。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是，这种方法在生成风格化视频的时候复杂度很高，耗时很长。因此，如何构建有效的深度学习模型来学习视频的空间域以及时间域的特性以完成视频风格变换是学术界以及工业界一个重要的研究课题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为解决这种问题，这个深度学习模型需要：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="list-style-type: decimal;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;在空间域上可以将名画元素有效的提取出来并学习应用；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;在时间域上保持变换风格的时间一致性（temporal consistency）；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;保证计算的高效性以支持更多的实际应用场景。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这也是包括 Facebook 和斯坦福大学等业界领先的研究团队比较关注的研究课题。但是迄今，业界的研究团队仍然没有很好的深度学习模型和高效率（如实时）的解决方案。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;前向网络（Jonson et al.）主要应用于图像上。迭代式（Ruder et al.）的方法来处理视频的风格变换考虑了时间域的一致性，但是处理速度非常慢，处理一帧视频大约需要 3 分钟。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;斯坦福大学的 Justin Johnson（使用前向网络完成图像风格变换的作者 [2]）也谈到「将前向网络与基于光流的时间一致性结合是一个开放性的课题」，他本人认为这种结合是可能的，但是不清楚业界是否有人已经实现，而且也不太确定这种结合的正确方式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;针对视频风格变换的技术难点，腾讯 AI Lab 在业界率先构建了深度神经网络，将风格变换的前向网络与视频时空一致性结合起来，高效地完成高质量的视频风格变换。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先，腾讯 AI Lab 设计了独特的深度神经网络，该网络结合了最新的卷积层以及残差层，能够对图像和视频学习有效的表示。在训练的过程中使用大规模、多场景、多特点的视频数据（数千小时）以及相应的风格图像，一方面学习空间域的风格变换特点（在保持原有视频内容的基础上引入给定图像的风格），另一个方面捕捉视频帧之间极其复杂多变的时域特性，使得产生的风格视频相邻帧之间的时空内容与风格一致。因为是针对视频数据，定义的损失函数（Loss Function）也比做图像数据的损失函数更复杂。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;更重要的是，腾讯 AI Lab 还提出了一种针对视频数据的独特训练过程，使得他们的深度神经网络能够更好地捕捉视频时间域上的一致性信息。在风格视频生成阶段，不用做任何预处理和后处理，将输入视频在风格变换网络上进行一次前向传播，实时输出风格化的视频。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不仅如此，为了满足线上需要，腾讯 AI Lab 也挖掘了模型的深度、宽度对输出质量的影响，并基于此对模型进行压缩且输出质量没有肉眼可见损失。「我们有不同的网络模型精简策略和模型压缩算法。压缩后的模型小于 1M」。做此研究的人员说，「这里谈到的模型精简和压缩，是针对深度网络的精简以及相关的压缩策略。压缩会精简深度模型的操作并降低运算的复杂度，但是产生的图像/视频的质量（相比未压缩）不会显著性降低。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从图像的风格变换到视频的风格变化，数据量的增长是巨大的。在解决数据增长的问题上，研究人员在构建算法的时候考虑到了不同的解决方案。在云端处理时，可以通过并行化的操作来快速完成视频风格生成。在终端处理时，通过网络的精简和压缩，使得在终端上能够实时完成视频的风格变换。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，经过上述优化后的深度模型，可以在手机客户端做到针对摄像头数据的实时处理，将用户拍摄的视频画面实时进行风格变换。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除此之外，腾讯 AI Lab 内部也关注了谷歌的多种风格融合的图像风格变化工作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「整体来说，谷歌发现了不同风格的变换网络的参数之间的关系，因此使用一个基础网络以及另外一个参数变换表格来融合生成多种风格的网络。」腾讯 AI Lab 也正在研究如何将这一技术拓展到视频领域。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;手机客户端实时视频风格变换在产品上的应用&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;立足于腾讯的大数据与平台，AI Lab 作为腾讯新成立的研究部门也在探索人工智能技术的新应用和新业务，将人工智能技术融入产品，满足腾讯庞大用户的需求。这也和谷歌、Facebook、亚马逊、微软等巨头成立人工智能研究部门、开发新技术、融合新产品与业务的公司策略如出一辙。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;正如前文所言，腾讯 AI Lab 率先在业界探索了使用前向网络实现实时的视频风格变换，这是腾讯 AI Lab 在将人工智能技术与腾讯用户需求相结合的尝试。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「这使我们有理由相信更多的人工智能技术也能够应用到各类场景下的数据上面（图像/视频，文本，语音等）。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;类似之前朋友圈爆红的一款图像产品 Prisma，我们了解到腾讯 AI Lab 开发的图像滤镜技术已经在天天 P 图的 P 图实验室上线，产品名称是「潮爆艺术画」。目前他们们已经开发了上百款图像滤镜，会陆续在「潮爆艺术画」里登场。而对于视频风格变换技术，腾讯也有了一些产品上的计划。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;参考文献：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[1]Ulyanov, Dmitry, Vadim Lebedev, Andrea Vedaldi, and Victor Lempitsky. Texture Networks: Feed-forward Synthesis of Textures and Stylized Images (2016).&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[2]J. Johnson, A. Alahi, L. Fei-fei,「Perceptual Losses for Real-Time Style Transfer and Super-Resolution」, ECCV 2016.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[3]Ruder, Manuel, Alexey Dosovitskiy, and Thomas Brox. "Artistic style transfer for videos." arXiv preprint arXiv:1604.08610 (2016).&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心原创，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 16 Nov 2016 09:50:21 +0800</pubDate>
    </item>
  </channel>
</rss>
