<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>机器之心</title>
    <link>http://www.iwgc.cn/list/670</link>
    <description>人与科技的美好关系</description>
    <item>
      <title>深度 | 分布式深度学习：神经网络的分布式训练</title>
      <link>http://www.iwgc.cn/link/2990664</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自 skymind&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;作者：Alex Black 、Vyacheslav Kokorin&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：Xuwen Wang、Xavier Massa、吴攀、李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;本文编译自 Skymind 的技术博客，作者是深度学习工程师 Alex Black 和 Vyacheslav Kokorin。按照计划，《Distributed Deep Learning》系列文章一共有三篇，本文是其中的第一篇，后续的文章机器之心还将继续跟进。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是关于「神经网络的分布训练」的三篇系列文章中的第一部分。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在第一部分，我们将看到如何在 GPU 上用分布式计算大大加速深度学习模型的训练速度，并讨论近期该领域上的一些挑战和近期的研究。同时，我们还要考虑：在什么时候，神经网络的分布式训练是适合或不适合特定的案例的？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在第二部分，我们将上手式地看看在 Apache Spark 上的 Deeplearning4j 的网络训练的实现，并从头到尾展示一个「如何在实践中执行训练」的例子。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，在第三部分我们将探索 Deeplearning4j 的 Spark 实现的背后情况，并讨论使用 Apache Spark 时的一些涉及到最大化训练表现的执行和设计挑战。同时，我们还将看看 Spark 如何与本地的高性能的计算库和 Deeplearning4j 所使用的堆外内存（off-heap memory）管理互相配合。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;介绍&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在大型数据集上进行训练的现代神经网络架构可以跨广泛的多种领域获取可观的结果，领域涵盖从语音和图像认知、自然语言处理、到业界关注的诸如欺诈检测和推荐系统这样的应用等各个方面。但是训练这些神经网络模型在计算上有严格要求。尽管近些年来 GPU 硬件、网络架构和训练方法上均取得了重大的进步，但事实是在单一机器上，网络训练所需要的时间仍然长得不切实际。幸运的是，我们不仅限于单个机器：大量工作和研究已经使有效的神经网络分布式训练成为了可能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;我们将从并行式/分布式的训练计算这两种方法开始说起。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9b5Tx7I5AxuWSRBmyfY1894jicd2zaUJzjouJlDb7PcksDc5ficp7hUeTefvEFOictX3G3xO0DxV4zQ/0?wx_fmt=png"/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在模型并行（model parallelism）中，在分布式系统中的不同机器分别负责在单个网络的不同部分计算——例如每层神经网络可能会被分配到不同的机器。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在数据并行（data parallelism）中，不同的机器有着整个模型的完全拷贝；每个机器只获得整个数据的不同部分。计算的结果通过某些方法结合起来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当然，这些方法并不是互相排斥的。想象一个多 GPU 系统的集群，我们可以对每个机器使用模型并行（将模型分拆到各个 GPU 中），并在机器间进行数据并行。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9b5Tx7I5AxuWSRBmyfY189wbsedM2dscYu47GibNnxv8nE26xsIvIEklGjqgm7OibPFjZ8Yu3SoJ3w/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尽管在实践中模型并行可以取得良好的效果，但数据并行毫无争议是分布式系统中最适的方法，而且也一直是更多研究的焦点。首先，实现性、容错性和好的集群利用率让数据并行比模型并行更加简单。在分布式系统的情况下模型并行是让人感兴趣且的确有一些优点的（诸如对于大模型的可扩展性）。但这里我们将主要目光放在数据并行上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;数据并行（Data Parallelism）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;分布式训练中的数据并行方法在每一个 worker machine 上都有一套完整的模型，但分别对训练数据集的不同子集进行处理。数据并行训练方法均需要一些整合结果和在各工作器（worker）间同步模型参数的方法。在文中我们将讨论一些不同的方法，而这些方法间的基本差异在于：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;参数平均 vs. 基于更新（梯度）的方法&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;同步 v s. 异步的方法&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;集中式 vs. 分布式的同步&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Deeplearning4j 最近在 Spark 上的实现是同步的参数平均，其中 Spark 驱动器和规约操作（Spark driver and reduction operations）取代了参数服务器。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;参数平均（Parameter Averaging）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;参数平均化是概念上最为简单的数据并行方法。使用参数平均时，训练按照如下方式执行：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 根据模型配置随机初始化网络参数&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 将现有的参数的一个副本分配给每一个 worker machine&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3. 在该数据的一个子集上对每一个 worker 进行训练&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4. 从每一个 worker 的平均参数上设立一个全局参数&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;5. 当还需要处理更多数据时，回到第 2 步&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第 2 步到第 4 步的过程如下图所示。在这个图表中，W 表示神经网络中的参数（权重，偏置）。下标用作指出参数的版本，以及每个 worker machine 有需求的位置。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9b5Tx7I5AxuWSRBmyfY189qGJhpA1icCoxkrtlO1nN9vP0KevLZAib3931AdLnbUvaa5iatoEsIdyZQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;事实上，要证明一个参数平均化的受限版本与单个机器上的训练在数学上是完全相同的是十分简单的；这些限制是每个 minibatch 之后的参数平均，没有更新器（updater）（如没有动量等——只是通过学习率加倍），而且每个 worker 会处理同样数量的样本。对于数学爱好者，证明如下。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;假设有一个含有n个 worker 的集群，其中每个 worker 有m个样本，总的在平均化中就有nm个样本。如果我们将所有nm个样本在同一机器上以学习率α进行处理，那么我们的权重更新规律满足如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9b5Tx7I5AxuWSRBmyfY1890NXzWVANIujFuLf5QdMHBfSSQoQKXM6su6LDLCLtv78tP7eldOs7GA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在，如果我们换做将 m 个样本分配到n个 worker 上执行学习（worker 1拿到样本 1 到 m，worker 2 拿到样本 m+1 到 2m，以此类推），那么就有：&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9b5Tx7I5AxuWSRBmyfY189KpDQYBmKteUNiabDIQxiad08lD6OENR3XHicEwKCmy9G3FDxew7DSpbpg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当然，这个结果并不能付诸实践（平均化每个minibatch和不使用诸如动量或者RMSProp这样的 updater 都是欠妥的。因为执行和收敛是分开说明的）。但这提供了第一感觉去思考：为什么参数平均可以有好的效果，特别是当参数频繁平均的时候？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在，参数平均化在概念上已经十分简单，但我们也略过了一些复杂的地方。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先，我们如何执行平均化呢？最为简单的方式是在每次迭代后简单均值化参数。尽管这种方法有效，但我们会发现这样做的成本会特别高。网络通信和同步成本会超过我们从额外的机器中所获得好处。因而，参数平均化的实现通常有多于 1 个的平均化周期（veraging period，就每个 worker 的minibatch数量而言）逐渐执行。然而，如果我们平均化的频率过低，每个 worker 中的本地参数之间的区别会过大，导致平均化后的模型较差。这里的直观知识是：N 个不同局部极小值的均值不能保证是一个局部极小值&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9b5Tx7I5AxuWSRBmyfY189yOvZ0Iwl18EjaBRsdS7S8d2sTBr13DrUZFjMQtPLz6c237ib9FKy6Kw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;是什么导致了平均化周期那么长？这个问题暂时还不能得到决定性的回答。且由于与其他超参数（如学习率、minibatch大小和 worker数量）的相互影响，情况变得更为复杂。一些该课题上的初步研究（如[8]）表明：每10-20个minibatch（每个 worker）排序的平均化周期仍然可以很好的执行。不过模型精确性当然会随着平均化周期的增加而降低。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;与最优化方法相关的附加难题，例如 adagrad，动量和 RMSProp。这些优化方法（在 Deeplearning4j 又称作更新器（updater））已被证明能在神经网络训练的过程中极大地提升收敛性能。然而，这些更新器也有内部状态（通常一个网络参数中有 1-2 个状态值）。我们应该也将这些状态算入均值吗？将这些内部更新器状态平均会造成每个 worker 的更快速的收敛，但代价是比原来总量多 2 倍或者更多的网络传输。有些研究工作也在试图在参数服务器层面上应用相似的「更新器」机制，而不只是在每一个 worker 上应用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;异步随机梯度下降&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;还有一个概念上同参数平均化相似的方法是：「基于更新的」数据并行化（‘update based’ data parallelism）。两者的基本区别在于：我们不会将参数从 worker 传递给参数服务器，而是传递更新（例如：梯度柱型的学习率和动量（gradients post learning rate and momentum））。这就得到了这样形式的更新：&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9b5Tx7I5AxuWSRBmyfY189meDBA2PKfPxeS74p8IyHickd9DcnqribaYGrg7icZH2mMQdXVID9FBSkA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其中λ是比例因子（可类比于学习率超参数）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;结构上，该方法和参数平均化相似：&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9b5Tx7I5AxuWSRBmyfY1893SFSJ2MRO1OaDLtia3MoSZtdqUatAOGXEuVWzF20hOhZ1XVNG57tiasw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于训练神经网络中数学熟悉的读者可能会注意到：在参数平均化和基于更新的方法之间有直接的相似之处。如果我们再次定义损失函数为L，参数向量W能以 i+1 的迭代以学习率 α 进行简单 SGD 训练而得到：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9b5Tx7I5AxuWSRBmyfY189pxtIniaVbvia2Mb6o9TDX48fIAias0Txj7NJL6S20IGFvvK0PRD7Mhdmg/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其中 &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9b5Tx7I5AxuWSRBmyfY189Dojh1ppwqv1YNicJk1NrPQQJxUmmTBsDBXaViaHUq6ujEBgbaq3cTtzQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;具有 n 个参数&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在，如果我们采取上述的权重更新规则，对于n个执行器让 λ=1/n，同时再次强调（仅使用学习率为 α 的 SGD），其更新是：&lt;span&gt;Δ&lt;span&gt;W&lt;/span&gt;&lt;span&gt;&lt;span&gt;i&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;&lt;span&gt;j&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;α&lt;/span&gt;&lt;span&gt;∇&lt;span&gt;L&lt;/span&gt;&lt;span&gt;j ，&lt;/span&gt;&lt;/span&gt;那么：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9b5Tx7I5AxuWSRBmyfY189Suwy5mOwNicpPwuiauubaEviau5f0L0oYfX9JvutTm5sZpic54352hibibAA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;结果，在参数平均化和基于更新的数据并行间有一个等式，当参数同步更新时（最后一部分是关键），这个等式也适用于多个平均化步骤以及其他更新器（不仅仅是简单的SGD）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当我们放松同步更新的要求时，基于更新的数据并行变得越来越有趣（毫无疑问它更有用）。即在更新∆Wi,j 被计算的时候就应用于参数向量（而不是等待所有 worker 的 N ≥ 1 次迭代）。我们获得了异步随机梯度下降算法（async SGD）。async SGD 有两个主要优点：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;首先，我们有潜在可能在整个分布式系统中获得更高的通量：worker 可以将更多时间花在执行有用的计算而不是等待参数平均化步骤完成。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;其次，worker 有可能可以集成来自其它 worker 的信息（参数更新），这比使用同步（每 N 个步骤）更新更快。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些优点也不是毫无代价的。通过在参数向量中引入异步更新，我们也引入了一个新问题，也就是过期梯度问题（stale gradient problem）。过期梯度问题很简单：梯度（更新）的计算需要时间，在一个 worker 完成这些计算并将结果应用于全局参数向量前，这些参数可能已经更新过许多次了。这个问题以下图展现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9b5Tx7I5AxuWSRBmyfY189xWZD8UU02ns8J6VW1lWlVVFeU0VhrvlEBBI3Wwfvv34G8XE615IofA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一个异步 SGD的朴素实现会造成梯度的过期值（staleness value）很高。例如，Gupta et al. 2015 [3]表明平均梯度的过期值与执行器的数目相等。若有N个执行器，那么就意味着这些梯度在应用到全局参数向量时会晚 N 个步骤。这在现实世界造成的影响是：高梯度过期值会极大减缓网络收敛，甚至完全阻止一些配置的收敛。早期的异步 SGD 实现（例如谷歌的DistBelief系统[2]）没有考虑到这个影响，因而导致学习效率很低。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;多数的异步随机梯度下降的变体都保持着相同的基本方法，但采取一些不同的策略来最小化过期梯度所造成的影响，同时试图保持高的集群利用率。应该注意的是参数平均化并不是由于算法的同步性本身而受到过期梯度问题的影响。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一些处理处理过期梯度的方法包括：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;根据梯度值的延迟度，对于每一个更新的 ∆Wi,j，独立缩放每一个λ值。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;实施「软」同步规则 ( [9] )。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;利用同步去限制延迟度。例如，在 [4] 中所示的系统中，它会在有必要的情况下对较快的学习器进行延迟，以确保整体最大的延迟度小于一个阀值。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些方法已被证实，能够改善朴素异步 SGD 算法的收敛情况。其中，最值得注意的是前两个方法：基于延迟度来缩放更新（延时梯度对参数向量影响较小）以及「软」同步法。「软」同步法 [9] 是一个相当简单的方法——它不立即更新全局参数向量，而是会等待以从 n 个学习器中收集 s 个 ∆Wj 更新（s 是一常数，1 ≤ s ≤ n）。参数的更新规则如：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9b5Tx7I5AxuWSRBmyfY189ibK3MHfkh1T18RlueCYGTJcWxnQlK4wJOkCdO3YWa8wGISHtxOFFcTA/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其中λ(ΔWj)是一个基于延迟度的缩放因子，是一个标量。[9] 提出了&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其中 τ 是一个基于延迟度的整数，满足 τ≥1。同时还有其他方法（见 [6] 中的例子）。若将软同步法和基于延迟的缩放法结合，则其表现会好于两者单独的表现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;注意，若给定 s = 1 以及 λ(·) 为宜常数，我们得到朴素异步 SGD 算法 [2]；相似地，若给定 s=n，我们则会得到另外一个与同步参数平均算法相似但不相同的算法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;分布式异步梯度下降法&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;[7] 提出了另一种更为有趣的备选架构，以执行神经网络的分布式训练。我将这个方法称作分布式异步梯度下降法（尽管作者并未使用该术语）。这篇论文在以下两大方面很有趣：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 在该模型中，没有中心的参数服务器——取而代之的，是点对点的参数传输以对于学习器之间进行更新。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 更新被极大地压缩了——以至于网络的通信尺度减小了三个数量级。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9b5Tx7I5AxuWSRBmyfY189ib18D8kia7CmzCv0E6flQ9YldMthlwRnbwZgDnBMthjZweqpRFCgId2Q/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在一个标准的数据并行执行（使用参数平均或异步 SGD）中，神经网络的转存尺寸与参数向量尺寸大小相同（因为我们要不然传输参数向量的复本，要不然每个参数传输一个梯度值）。尽管压缩参数或更新的想法并非完全新颖，但该方法以一种优于传统的机制（例如应用一个压缩编码或转为 16 浮点表示）实现了压缩。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;这个架构设计的优势在于，更新的向量 δi,j 有以下性质：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 稀疏性：在每个向量 δi,j 中，只有部分的梯度值是相互关联的（也就是其余的值是被设为 0 的）——稀疏项使用整数进行索引。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 量化为一个位：稀疏更新向量每一个分量的值取 +τ 或 −τ。这个 τ 值对向量中的所有分量都相同，因此仅需要一个位就可以区别两个选项。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3. 整数索引（即 1 中所提到的用来索引稀疏矩阵）部分地被使用熵编码，以进一步缩减更新的大小（作者给出了在额外计算的情况下有额外三倍的缩减，尽管该处获益可能不值得额外的计算）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此外，考虑到该压缩方法是有损的，因而原更新向量 ΔWi,j 与压缩／量化更新的向量 δi,jδi,j 的差将不被简单地忽略，而是被储存在一个残差向量 rj 中（ j代表每次执行）。而残差向量将被加到原来的更新上，也就是说，每一步我们量化并传输一个经过压缩的 ΔWi,j+rj 并更新合适的 rj。由此，原始的更新向量 ΔWi,j 中的信息被完整的传输了并没有损失。换句话说，（每个参数的）大更新都将被以比小更新更高的速度动态传输。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;由此产生了两个问题：一个是，这种方法能多大程度上压缩神经网络的参数？另一个是，这种方式的精度如何？答案出乎你意料：它能超出你预料地压缩，但精度略低于你预期。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如这个在 strom 论文中呈现的例子：一个有约1460万个参数的模型，经过不同程度压缩后的情况：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9b5Tx7I5AxuWSRBmyfY1894yCRLiawn981BspjJUkficVrbJB3sbsPpxc7OoZiaY1z9FT9ibacOuXpug/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;更大的 τ 值，将会带来更大的压缩率。例如， 当 τ= 15时，对每个数据包，其更新大小仅有4.5KB！但相应的，模型准确率也会因此而下降。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尽管结论很惊人，但该方法也有如下的问题：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. Strom在论文中写道，收敛情况在训练之初可能出现问题。但使用更少的训练节点和使用一部分案例好像可以帮助解决该问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 压缩和量化过程需要消耗时间：在对每个数据包处理的过程中，这些过程导致了额外的计算与储存。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3. 这一过程引入了需要考的额外的超参数：如何设定 τ值？需要在更新数据的时候使用熵编码吗？（尽管参数平均法和异步SGD都引入了额外的超参数。）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，就笔者所知，暂时还没有异步SGD和分布式异步SGD的实验比较。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;分布式神经网络训练：哪种方法最好？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们已经看到，有多种方法来训练分布式神经网络，其中每个类型也有不少变体。因此，我们应该在实践中应该使用哪一个？不幸的是，我们没有一个很明确的答案。但我们可以给出如下的评判标准，来确定不同方法中最好的那个：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;最快的训练速度（每秒最多或最少可以训练多少个例子）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;在无限样例下可达到的最大精度&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;在有限时间下可达到的最大精度&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;在有限样例下可达到的最大精度&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;最大可达到的准确度对历元的给定数量的&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外，这些问题的答案将可能取决于许多因素，如神经网络的大小和类型、集群的硬件性能，使用特征（如压缩），以及训练方式的具体实施方法和配置。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9b5Tx7I5AxuWSRBmyfY1899TENfaNGBcPfy0hZXdLm0cOiazOeJvkseF21QSYAb70yVZytiaUichaYg/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;也就是说，我们能从该研究中总结出如下内容：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;同步参数平均法（或等价说，基于同步的更新）在每一次遍历中的与整体的准确率方面，特别是对很小的平均周期，表现更好。参见 [9] 中所示的」硬同步」结果，或在 N＝1 的平均周期下同步平均法在单机训练上的表现。但是，额外的同步花费意味着这个方法在每次迭代中需要花费更多的时间。也就是说，如 InfiniBand 的更快的神经网络连接还需要花费很多精力，以使该同步方法具有竞争力（详见 [5]）。但是，甚至在商业硬件上，我们也能见到基于 DL4J 的同步参数的，很好集群利用。增加压缩步骤，应该会进一步减少网络通讯的花费。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;也许参数平均（和一般的同步方法）最大的问题，就是所谓的「最慢执行」效应：即同步系统在完成每次迭代之前，需要等待最慢的执行者。因此，当工作机数量增加时，同步系统的表现不会更好。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在实践中已证明，只要梯度延时被适当处理，异步 SGD 将是一个很好的训练方案。另外一些方法（如前面所述」软同步」的方法），根据其所使用的超参数的不同，可被视为朴素异步 SGD 和同步执行之间的桥梁。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;基于集中参数的异步 SGD 实现，可能会引入通信瓶颈（相比之下，同步方法可以利用剪枝或类似算法，能一定程度上避免这方面的沟问题）。将全部的参数分为 N 等份，使用 N 个参数服务器处理每一份数据，从概念上说，这是一个更为直接的解决该问题的方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最终，分布式异步 SGD 是一个很有前景的想法，尽管这还需要很多研究才能让我们不容置疑地推荐它，而非」标准」的异步 SGD。此外，许多在 [7] 中所示的想法（如压缩、量化等）可以被用于异步 SGD 中，以优化传统的参数服务器的设置。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;该何时使用分布式深度学习&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对每种使用情况，分布式深度学习往往不都是最好的选择。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;分布式学习并非廉价——与在单独的机器上相比，因为诸如同步、数据与参数的网络传输等问题，分布式系统往往有一个日常开销。要使分布式训练变得值得，我们需要利用好分布式系统的计算优势来抵消这笔开销。此外，在分布式训练上，设定（包括准备与载入训练数据）及调参都将会变得更为复杂。因此，我们的建议简单明了：在训练时间可以接受的情况下，都（不使用分布式训练而）在单机上训练神经网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;神经网络的训练时间因为这两种原因而变得很长：网络的大小非常之大（每次迭代都很费时）及数据量非常之多。通常来说，这两种情况将同时出现——因为「大网络、少数据」或「小网络、大数据」的情况往往导致欠拟合或过拟合，不能有很好的泛化效果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在某些情况下，多 GPU 系统应该首先被考虑（如 Deeplearning4j 的 Parallel-Wrapper 系统可以让神经网络在单机上轻松进行同步训练）。基于多 GPU 系统对模型进行同步运算对大型网络也是可行的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外一个要考虑的方面是，网络传输（耗时）与计算（耗时）之比。分布式训练在网络传输（耗时）与计算（耗时）之比较低时，会比较高效。因为每层的计算量很少，小的、层数少的网络并不适用于分布训练。有参数共享的网络（如 CNN 或 RNN）往往适用于分布式训练：因为它们每个参数计算量远远高于，如多层感知机或自编码体系架构的计算量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Part2 预告：在 Apache Spark 上部署 Deeplearning4j 的深度学习网络&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在我们介绍分布式深度学习系列文章中，我们将在第三篇的第二部分仔细探讨 Deeplearning4j 的机遇 Apache Spark 的参数平均法的实现，并通过一个例子来演示如何在 Spark 集群上来训练神经网络。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;参考文献：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[1] Kai Chen and Qiang Huo. Scalable training of deep learning machines by incremental block training with intra-block parallel optimization and blockwise model-update filtering. In 2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 5880–5884. IEEE, 2016.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[2] Jeffrey Dean, Greg Corrado, Rajat Monga, Kai Chen, Matthieu Devin, Mark Mao, Andrew Senior, Paul Tucker, Ke Yang, Quoc V Le, et al. Large scale distributed deep networks. In Advances in Neural Information Processing Systems, pages 1223–1231, 2012.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[3] Suyog Gupta, Wei Zhang, and Josh Milthrope. Model accuracy and runtime tradeoff in distributed deep learning. arXiv preprint arXiv:1509.04210, 2015.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[4] Qirong Ho, James Cipar, Henggang Cui, Seunghak Lee, Jin Kyu Kim, Phillip B. Gibbons, Garth A Gibson, Greg Ganger, and Eric P Xing. More effective distributed ml via a stale synchronous parallel parameter server. In C. J. C. Burges, L. Bottou, M. Welling, Z. Ghahramani, and K. Q. Weinberger, editors, Advances in Neural Information Processing Systems 26, pages 1223–1231. Curran Associates, Inc., 2013.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[5] Forrest N Iandola, Khalid Ashraf, Mattthew W Moskewicz, and Kurt Keutzer. Firecaffe: near-linear acceleration of deep neural network training on compute clusters. arXiv preprint arXiv:1511.00175, 2015.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[6] Augustus Odena. Faster asynchronous sgd. arXiv preprint arXiv:1601.04033, 2016.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[7] Nikko Strom. Scalable distributed dnn training using commodity gpu cloud computing. In Sixteenth Annual Conference of the International Speech Communication Association, 2015.http://nikkostrom.com/publications/interspeech2015/strom_interspeech2015.pdf.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[8] Hang Su and Haoyu Chen. Experiments on parallel training of deep neural network using model averaging. arXiv preprint arXiv:1507.01239, 2015.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[9] Wei Zhang, Suyog Gupta, Xiangru Lian, and Ji Liu. Staleness-aware async-sgd for distributed deep learning. IJCAI, 2016.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Sun, 09 Oct 2016 13:28:27 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 神经机器翻译再立新功：实时机器翻译取得重大进展（附论文）</title>
      <link>http://www.iwgc.cn/link/2990665</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自 Slator&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Marion Marking&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：权利、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;前段时间，谷歌报告了其在神经机器翻译上所取得的重大研究进展，并也实现了 Google Translate 应用上汉语-英语翻译的商品化（参阅《&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719470&amp;amp;idx=1&amp;amp;sn=3368dea980517ea7d7942967da2740dc&amp;amp;chksm=871b0090b06c89863620be4e75c757940d03d8a43cd3c1d9a8309b6594c1bccd769cab193177&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719470&amp;amp;idx=1&amp;amp;sn=3368dea980517ea7d7942967da2740dc&amp;amp;chksm=871b0090b06c89863620be4e75c757940d03d8a43cd3c1d9a8309b6594c1bccd769cab193177&amp;amp;scene=21#wechat_redirect"&gt;谷歌翻译整合神经网络：机器翻译实现颠覆性突破&lt;/a&gt;》和《&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719511&amp;amp;idx=1&amp;amp;sn=88bbb6bb3d28b3f0f62c5c5929968444&amp;amp;chksm=871b0169b06c887f302dc791c67f19ce4ba49c43744e11341b7bb225d9e22443ebf9e3b70339&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719511&amp;amp;idx=1&amp;amp;sn=88bbb6bb3d28b3f0f62c5c5929968444&amp;amp;chksm=871b0169b06c887f302dc791c67f19ce4ba49c43744e11341b7bb225d9e22443ebf9e3b70339&amp;amp;scene=21#wechat_redirect"&gt;谷歌神经网络翻译系统发布后，我们和Google Brain的工程师聊了聊&lt;/a&gt;》）；近日，来自纽约大约、香港大学和卡内基梅隆大学的研究者又报告了神经机器翻译在实时机器翻译上的突破。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尽管机器学习技术发展迅猛，但谷歌也承认机器翻译还是会犯人类永远不会犯的错误。这一问题增加了实时输入的挑战，让问题变得十分棘手。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;实时机器翻译的使用范围涵盖消费者应用（如 Skype Translator）到有望能够帮助专业语言学家显著提高生产力的自适应机器翻译工具。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在2016年10月3日发表的一篇论文《Learning to Translate in Real-time with Neural Machine Translation》（点击阅读原文下载）中，研究人员说他们「第一次」能够证明某些算法可以「在同步翻译上表现得非常好，比以前的基于分割的算法好得多。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9b5Tx7I5AxuWSRBmyfY189OAiag19XS95YEoMN2yJ4NZulFiaGGrOjdrZpZB8eibibj59vxyb14VuDicw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Graham Neubig&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「这项研究的最终目标是语音，」Graham Neubig 告诉 Slator。Neubig　是卡耐基梅隆大学语言技术研究所的助理教授，他与香港大学博士 Jiatao Gu，讲座教授 Victor O.K. Li　和纽约大学的助理教授 Kyunghyun Cho 合作进行了这项研究。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9b5Tx7I5AxuWSRBmyfY189e2V1lASwMbeQJIvrTZiao1zPxnBrG5OsR1dNEEicVChKu3WD065elMug/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;Kyunghyun Cho&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9b5Tx7I5AxuWSRBmyfY189QMGCQ86jT7FQSeqGuhtyqsghiaPpN8icuYwQSLk1rjqXPkh2dtAS1H8Q/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Victor O.K. Li&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Neubig 解释说：「同步机器翻译是一项能够在说话或是打字的同时实时进行语句翻译的技术。以语音为例，在完整的句子结束之前进行翻译是很重要的，因为一个讲话者说完一句话需要 10－20 秒，这就意味着需要这么长时间翻译器才能够向用户开始提供翻译内容。这种滞后意味着诸如使用语音翻译技术作为中介流畅地参加一个多方会谈是困难的。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;根据 Neubig 所言，在过去解决这种滞后的一种方法是将输入分割成较短的段而不是直接处理整个句子，然后将各段独立地进行翻译。如果能够找到一个好的分割位置（「比如，在可以彼此分开翻译的短语之间」），就可以减少滞后。这种技术相较之前更快，但是仍然降低了流畅度。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9b5Tx7I5AxuWSRBmyfY189vUEsRSvib6ibc09WDUIwSRp5LhDjHWx7icriasb6oMDQyGZg0BrwcKNM7Q/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然而，这项研究的与众不同之处是它使用了神经机器翻译（NMT）框架（图2），能够「自动学习什么时候开始翻译词以及什么时候等待更多的输入。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你愿意，可以想象一个等待翻译打字的 NMT 系统，它尝试根据&lt;/span&gt;&lt;span&gt;所有已经输入的单词生成下一个单词的翻译。接着，根据神经网络现在的状态（「以及我们对下个翻译的置信度，」Neubig 说），它将会自动决定这个单词是否应当被输出或是等待另外的输入。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「如果答案是『是，输出单词，』那么输出单词同时返回到 1。如果答案是『否，我们不够确定，』那么停止输入同时返回到2，」Neubig 说道。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他补充说，为了系统能够正确地工作，他们要问自己：我们怎样才能为这项工作设计出合适的机器学习算法？我们怎么来确定翻译的便捷性和准确性之间的平衡？我们怎么能恰到好处地搜索最佳翻译？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「这些问题的答案就是本篇论文中技术内容的关键部分，」Neubig 说道。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他指出，「在我们的实验中，我们首次证明了这些算法能在同步翻译上表现得非常好，远远优于之前的基于分割的算法。我们认为这一表现的主要原因在于我们的方法记忆了之前所有输入的单词，并且在选择下一个要翻译的单词的时候对之前所有单词进行了考量，而这对以前基于分割的方法来说并不容易。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;下文是 Slator 对 Graham Neubig 采访关键部分的摘录:&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Slator：在第６章，你提到同步翻译是相关工作的典型应用，但是你的论文基本聚焦在文本输入而不是语音输入。那么这项研究的主要实际应用是什么呢？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Neubig&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：这项研究的最终目标是语音。在这项工作中我们处理文本因为这更易于起步；因为在处理语音的时候还有附加的事项需要考虑，例如语音识别结果导致的附加的不确定性。我们对于在将来能处理语音绝对地感兴趣，这也是我们将要做的事&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Slator：为什么你会选择聚焦在　NMT 的这一特定的应用场景？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Neubig：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;首先，因为这是语音翻译的一个非常重要的问题。其次，因为 NMT 非常适于处理这个问题。NMT 的工作方式是预测句子的下一个单词并且一次一个地输出它们——这正是我们在同步机器翻译系统中所需要的。在这里也考虑了其他很多有趣的算法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;Slator：因为主语和动词之间间距的长短，所以专门选择了德译英的语言组合（图１）吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9b5Tx7I5AxuWSRBmyfY189sv46PK4TEUWkvibJS2J83oyxMPbqY2tcUbp1FFnrQibGH5LCgzp86C5w/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Neubig：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;是的，这是选择这个语言对的主要原因。先前的同步翻译的工作也因为这个原因聚焦在大量重新排列的语言对上，例如 德语－英语 和 日语－英语。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;Slator：如果在德译英中，一旦真正的动词出现在句末，而模型选择了一个明显被误译了的动词，这样的话会发生什么？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Neubig：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;这是一个非常有趣的问题，我们之前并没有考虑到。真人的同步翻译会返回并改正他们的错误，但是现在还没有机器可以做到这一点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Slator：你预计这项研究会有什么影响？另外你打算怎样进行接下来的工作？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Neubig&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：我希望这项研究最终的影响会是语音翻译，当它实现的时候你就不需要为平滑、流畅的输出结果等待很长一段时间。当然，这项工作仅仅是这个方向的一步，在实现这个目标之前，诸如怎样将现有的方法和语音识别系统和合为一体等考虑是要被处理的事。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Slator：你在论文结尾致谢了 Facebook、三星、谷歌、微软和 Nvidia 这些科技巨头？能告诉我们原因吗？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Neubig：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;这些公司给予了 Kyunghyun 或 Graham 从事与同步 NMT 密切相关的或是通用的 NMT 研究的赞助。然而我们显然不能够代替这些公司发言，我认为他们有兴趣为推进他们认为有前景的研究或教育领域而向学术界提供赞助。不过他们可能会也可能不会这个特定的项目感兴趣。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Slator：特别的，Nvidia 赞助这样一个研究的利害关系是什么？为神经网络、人工智能等等部署的　GPU 已经成为他们业务的一个如此大的推动力了吗？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Neubig：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我认为他们的确为机器学习使用 GPU 而感到兴奋；但是，当然，再次说明，我们不能代替他们发言。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Sun, 09 Oct 2016 13:28:27 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 硅谷银行：大数据和人工智能将为医疗科技公司打开发展之路</title>
      <link>http://www.iwgc.cn/link/2990666</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自 SVB&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李泽南、杜夏德&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;em style="color: rgb(136, 136, 136); line-height: 1.75em;"&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;em style="color: rgb(136, 136, 136); line-height: 1.75em;"&gt;&lt;span&gt;在调查了 122 名高科技医疗公司的创始人、高管和投资人之后，美国硅谷银行的最新报告认为大数据和人工智能将在明年对医疗领域产生深刻影响。医疗服务和医疗信息技术将会是 2017 年发展最快的行业。&lt;/span&gt;&lt;/em&gt;&lt;br/&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「大数据在 Celmatix 中引领我们的工作。它让内科医生可以根据每个人的多项数据，而不止于年龄，对女性怀孕的几率提供诊断。」Celmatix 首席执行官 Piraye Yurttas Beim 博士说道，他正在管理的是一家致力于提供个性化生育医疗服务的初创公司，「目前这个行业发生的事情激动人心，我们正在高速发展，医生和患者都将从大数据和个性化药物带来的便利中受益。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;硅谷银行的报告在 2016 年 9 月 8 日的 HealTech NYC 活动中形成。超过 200 名公司创始人和高管参加了这次为期一天的活动，他们来自包括 Aledade , babylon Health, Celmatix, PokitDok, Quartet Health 和 ZocDoc 等医疗科技公司，同时参会的也有一些医疗和科技投资者，包括 Andreessen Horowitz, New Enterprise Associates 和 Venrock。主要演讲者包括非盈利医疗机构 EmblemHealth 的 CEO 和主席 Karen M. Ignagni，McKesson 风投公司高级副总裁和常务董事 Tom Rodgers，和 Steve Allan，硅谷银行分析师，他最近发表了关于数字医疗的报告「消费级数字医疗：蓝海市场创造无限机会」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;报告显示目前医疗科技领域存在如下机遇与风险：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;最大的挑战--尽管目前这个行业还在发展阶段，患者和顾客对数字医疗的使用率仍然是最大的挑战（目前达到 37%，正常的使用率为 34%）。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;对于投资的最大影响--在问卷调查中，有 34% 的回复者认为成功利用现有技术进行整合将在行业内创造最大影响。除去不确定性，未来的美国总统选举对于行业发展的影响微乎其微（7%）。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;最有前景的技术--回复者认为大数据（46%）和人工智能（35%）会是 2017 年中对于医疗科技影响最大的新技术。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;最大增长点—调查中 45% 回复者认为医疗服务/科技行业将在未来一年里快速发展，更多的消费级产品将会出现，包括移动医疗 app（8%）和可穿戴设备（7%）。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;最佳资金来源--大多数参与者认为（61%）风投机构会在医疗科技领域的投资中扮演主要角色。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以下是调查结果：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9b5Tx7I5AxuWSRBmyfY189ZsmvLVXxP9ichsgHWHaiaJ0wp2roJ4PTjqcmK7a7OF3eMjibzYPZaibsrA/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9b5Tx7I5AxuWSRBmyfY189M2PCRYjVLicnu0flrbb8JoF2yUicicFHan4hZM2PEs4loHns8SB1XvsJg/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9b5Tx7I5AxuWSRBmyfY189cV0PKibgGRFsBGVV7z7t8KmRzJCibJo8yAfdUS4ZoF0aUKiard8jdQHGQ/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9b5Tx7I5AxuWSRBmyfY189JvXOlPlom1ibrCbs91Licmnp5nYULW519fJJdmJJ1Ru6003Z7cvNwB8A/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9b5Tx7I5AxuWSRBmyfY189SOaX7sMkGXZ3zjl2e3GjtHAatgDiamr8Ms37nussmhfZaQ1spnngspA/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Note: HealTech 调查于 2016 年 9 月 8 日在硅谷举办的 HealthTech NYC 活动中进行。有 122 名回复人，均为此次活动参与者，他们主要为数字医疗公司和科技公司创始人、高管和投资者。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Sun, 09 Oct 2016 13:28:27 +0800</pubDate>
    </item>
    <item>
      <title>报名 | CCF YOCSEF上海即将举办「人工智能在机器人产业的应用与前景」专题报告会</title>
      <link>http://www.iwgc.cn/link/2990667</link>
      <description>&lt;p&gt;&lt;span&gt;中国计算机学会青年计算机科技论坛&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;CCF Young Computer Scientists&amp;amp; Engineers Forum&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;CCF YOCSEF上海 @CNCC 2016&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;“人工智能在机器人产业的应用与前景”专题报告会&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;时间：2016年10月19日（周三） 13:30–17:00&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;地点：山西省太原市湖滨国际大酒店西10会议室&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;程 &amp;nbsp;序&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;13:00&lt;span&gt;	&lt;/span&gt;&lt;strong&gt; 签到&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;13:30&lt;span&gt;	&lt;/span&gt;&lt;strong&gt;报告会开始&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;特邀讲者：&lt;span&gt;陶建华&lt;/span&gt;，中国科学院自动化所 研究员&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;演讲题目：多模态自然人机对话技术&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;特邀讲者：&lt;span&gt;韩银和&lt;/span&gt;，中科院计算所 研究员&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;演讲题目：机器人处理器与智能计算机&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;特邀嘉宾：&lt;span&gt;陈宝权&lt;/span&gt;，山东大学 教授&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;演讲题目：RobotVision：基于机器人的三维场景主动感知&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;特邀嘉宾：&lt;span&gt;张 民&lt;/span&gt;，苏州大学 教授&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;演讲题目：自然语言理解及其在机器人产业中的应用&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;16:00&lt;span&gt;	&lt;/span&gt;&lt;strong&gt;Panel讨论 &lt;/strong&gt;人工智能在机器人产业的机遇与挑战&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;嘉宾：&lt;span&gt;陶建华&lt;/span&gt;、&lt;span&gt;韩银和&lt;/span&gt;、&lt;span&gt;陈宝权&lt;/span&gt;、&lt;span&gt;张民&lt;/span&gt;、&lt;span&gt;俞凯&lt;/span&gt;、&lt;span&gt;赵京雷&lt;/span&gt;、&lt;span&gt;陈运文&lt;/span&gt;、&lt;span&gt;闫峻&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;执行主席：&lt;span&gt;王昊奋&lt;/span&gt; &amp;nbsp;CCF YOCSEF上海副主席&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;执行主席：&lt;span&gt;张文强&lt;/span&gt; CCF YOCSEF上海荣誉委员&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;执行主席：&lt;span&gt;李 超&lt;/span&gt; &amp;nbsp;CCF YOCSEF上海委员&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;联系方式：Email：wang_haofen@gowild.cn，联系人：王昊奋，139-1858-6855&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参加方式：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1.CCF会员免费参加；媒体免费参加。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2.其他人员需缴费参加，每人次200元。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;报名方式：&lt;/strong&gt;&lt;span&gt;请扫描以下二维码或点击“原文链接”在线报名&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/4E4IOAV105nZTicXKcQibebBnY2GEmSJiclEyId2X1GlAE9GMJxtbibFic3oOoMDvGOIre0cIJRGl74JcLutCwwvKMQ/640?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;“人工智能在机器人产业的应用与前景”&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;近年来，人工智能技术已然成为学术界的研究热点和产业界的研发重点，以机器人产业为代表催生了各种概念产品和产业应用。各种以人工智能技术为核心卖点的创业公司更是如雨后春笋般地蓬勃发展，吸引了大量的关注和风投。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本报告会邀请了学术界的专家学者，分别从视听觉、自然语言理解、机器人芯片等核心技术入手，共同探讨人工智能技术在机器人产业的研究现状和前景。本Panel邀请了人工智能技术相关的机器人公司的嘉宾，一起探讨人工智能技术在机器人行业的应用和未来发展方向，并针对某些热点话题进行开放式辩论与观点阐述。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/4E4IOAV105nZTicXKcQibebBnY2GEmSJiclb9MEySWKOZatm34Xicet0Y1UuCN4RuqtjCN4DdibwBO2IfBWUNHCQ6nw/640?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;特邀讲者 &amp;nbsp;&lt;span&gt;陶建华&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;中国科学院自动化研究所研究员，所长特聘助理，模式识别国家重点实验室副主任，国家杰出青年科学基金获得者。主要研究方向为语音识别与合成、人机交互、情感计算和模式识别等领域。目前还担任中国计算机学会常务理事、中国人工智能学会理事、中国中文信息学会理事、中国声学学会理事、中国图像图形学学会虚拟现实专业委员会委员、AAAC学会执行委员会委员等职，同时还是国际期刊IEEE TAC的Steering Committee Member，以及Speech Communication、JMUI等期刊编委，并多次担任国际和国内主要学术会议主席或委员。承担国家863、国家自然科学基金、国家发改委等项目二十余项，并担任863重点项目“面向移动终端的自然人机交互技术”首席科学家，在国内外主要期刊或会议上发表论文100余篇，申请专利10余项，研究成果多次在国内外学术会议上获奖，并被国际同行较多的引用。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;报告摘要：&lt;/span&gt;近几年来人机语音对话技术获得很大的发展，与单一语音对话相比，采用多模态的人机对话方式更为接近人与人之前的面对面交流。由于来自不同通道信息在表现形式和内容上各不相同，多模态人机交互过程显得更灵活，同时在系统构成上也更复杂。本报告着重于阐述多模态自然人机对话技术所面临的关键核心技术，其中包括：人机对话过程中多模态信息融合方法，如何处理情感和语气等非语言对话过程，如何建立机器的问答学习机制等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/4E4IOAV105nZTicXKcQibebBnY2GEmSJicljZE5A1JCe4auiay5LbvtyICG0NBbfyc7OibYTkVA01QJf3tZk0ppfhCg/640?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;特邀讲者 &amp;nbsp;&lt;span&gt;韩银和&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;中科院计算所研究员，主要研究领域是集成电路设计与测试、计算机体系结构。在这些领域共发表了70多篇学术论文，包含多篇ISCA、HPCA、DAC、ICCAD等体系结构和芯片领域顶级会议论文。韩银和获得过2012年国家技术发明二等奖、全国百篇优博提名(奖)、计算机学会优博等，担任中国计算机学会青年计算机科技论坛(CCF YOCSEF)主席(2016-2017)，计算机学会容错专委秘书长(2016-2019)。他获得了基金委优秀青年科学基金的资助。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;报告摘要：&lt;/span&gt;&lt;span&gt;未来的机器人将具有高度智能能力、高度运动能力，而这二者都需要大脑-芯片的支持，目前基于通用嵌入式处理器的芯片系统，不能满足性能需求。我们正在开展面向机器人、控制方面的智能芯片和智能计算机的研究，目标是重新定义机器人领域的核心处理器和核心计算设备，为未来智能机器人提供大脑和动力。本报告将介绍在这方面的初步成果：嵌入式深度学习加速器以提高控制能力和视觉能力；基于深度学习框架的运动控制加速器以提高快速运动能力；基于碰撞检测加速器的路径规划加速以及基于FPGA实现的异构智能计算机系统。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/4E4IOAV105kbGSYZib4U5moLuYfQiaCe47OaP4ibuoofKZym0YHddJG2QUliamCCFDKIu7WlfYu5afEmp9cJpUJ2jA/640?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;特邀讲者&lt;/span&gt;&lt;strong&gt;&lt;span&gt; &amp;nbsp;&lt;span&gt;陈宝权&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;长江学者特聘教授，山东大学计算学院与软件学院院长。研究领域为计算机图形学与可视化，973项目“城市大数据计算理论与方法”首席科学家，获2014年“中国计算机图形学大会杰出奖”。在 ACM SIGGRAPH、IEEE VIS、ACM TOG等国际会议和刊物发表论文100 余篇。现任IEEE Transactions on Visualization and Computer Graphics编委，并多次任计算机图形与可视化领域几乎所有重要国际会议的PC成员；曾任SIGGRAPH ASIA 2014会议主席、SIGGRAPH ASIA指导委员会委员、IEEE 可视化会议2005年主席和2004年程序委员会主席。现任IEEE VIS指导委员会委员 。获2003年美国NSF CAREER奖，入选“万人计划”、“杰青”和“中科院百人”。任中国计算机学会常务理事和第七届教育部科技委信息学部委员。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;报告摘要：&lt;/span&gt;&lt;span&gt;视觉计算的发展，粗略来讲，经历了如下几个阶段:从早期的被动式处理模式（reactive），到加入一定的人工干预（interactive），到现在基于机器人平台的前摄式主动感知（pro-active）。这样的智能感知是机器人自主性和智能化水平的核心体现，其内涵是“感”与“知”的深度耦合。以获取的数据支撑分析理解，以认知结果来引导数据采集，在二者间形成反馈回路，实现认知引导的预见性、自主式的智能化数据获取与处理，即 “主动感知”(Proactive Sensing)。我将结合本研究小组近年来的探索来介绍该方向的发展趋势。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/4E4IOAV105nZTicXKcQibebBnY2GEmSJiclFUhic1OZ8M84tHvxaWyotkTHw0ugd91RGiaMtJ5WTHzbLB25WNxnuEFw/640?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;特邀讲者 &amp;nbsp;&lt;span&gt;张 民&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;苏州大学特聘教授，计算机科学与技术学院副院长，人类语言技术研究所所长，国家杰出青年科学基金获得者，江苏省“高层次创新创业人才计划（双创计划）”，17年海外学术界和产业界工作经验。长期从事自然语言处理和机器翻译研究，已发表CCF A/B类期刊、会议论文100余篇，出版Springer英文专著2部，主编英文论著（论文集）16本。现任IEEE/ACM T-ASLP和《自动化学报》编委，SIGHAN/ACL主席，AFNLP常务理事和PACLIC国际咨询委员会委员。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;报告摘要：&lt;/span&gt;自然语言理解被认为是人工智能的核心难题之一，那么什么是理解，什么是自然语言理解？自然语言理解的定义、内涵、要解决的科学问题、研究现状、挑战和未来的发展方向是什么？自然语言理解在机器人产业的应用、挑战和前景如何？本报告将就这些问题展开讨论。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/4E4IOAV105nZTicXKcQibebBnY2GEmSJiclBibGtJF93VGnibqKuXyJgmuNIJyFW2Mp0Yq13knUcicynnhHJzQeo7TYg/640?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;Panel嘉宾&amp;nbsp; &lt;span&gt;俞&amp;nbsp;凯&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;思必驰联合创始人兼首席科学家，剑桥大学语音博士，上海交大教授，IEEE 高级会员，国家青年千人计划、NSFC优秀青年科学基金获得者，上海市东方学者特聘教授，中国语音产业联盟技术工作组副组长。清华大学自动化系本科、硕士，剑桥大学工程系博士。 2012 年在上海交通大学创建智能语音技术实验室，将人机口语对话系统的全面技术引入回国。在人机口语对话交互的主要核心技术领域进行了广泛研究，在国际一流期刊和会议上发表论文 80 余篇，获得 ISCA 颁发的 2008-2012 Computer Speech Language 最优论文奖等多个国际期刊和会议优秀论文奖。多次担任 InterSpeech 等国际会议的对话或语音处理领域主席，多次在美国国防部、美国国家标准局组织的大规模语音识别评测，国际研究机构组织的对话系统挑战赛等国际评测和竞赛中获得冠军，2014 年获得中国人工智能学会颁发的吴文俊人工智能科学技术奖进步奖。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/4E4IOAV105nZTicXKcQibebBnY2GEmSJiclOjohHBk8m2clGAVqaeVyrEibUL7WciaQQZyJplomibZrLEsnyeHQibYzXQ/640?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;Panel嘉宾&amp;nbsp; &lt;span&gt;赵京雷&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;阅面科技（ReadSense）创始人，上海交通大学人工智能博士，前阿里巴巴北京算法研究中心负责人，专注人工智能领域15年。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/4E4IOAV105nZTicXKcQibebBnY2GEmSJiclpyV6icZ0VbtWuJSzibJg2J1HeW7zbvQkpiaJ2rAGfKPEzLzRQrRpNSVaQ/640?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;Panel嘉宾&amp;nbsp; &lt;span&gt;陈运文&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;达观数据董事长兼CEO；复旦大学计算机系博士，国际计算机学会（ACM）会员和CCF高级会员，上海市优秀博士论文奖获得者；在人工智能领域有30余项国家发明专利，在IEEE Transactions等国际学术期刊和会议上发表十余篇专业论文，多次获得国际机器学习竞赛冠亚军成绩，包括ACM KDD CUP亚军（2012），ACM CIKM CUP冠军，Hackathon2012冠军；带领达观数据荣获2016年青年创业大赛全国总冠军，曾担任盛大文学首席数据官（CDO），腾讯文学高级总监，百度核心技术研发工程师，QCon大数据分论坛主席和最佳技术讲师。陈运文在机器学习、自然语言处理、搜索推荐等技术领域有丰富的工程研发和管理经验。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/4E4IOAV105nZTicXKcQibebBnY2GEmSJiclYNLLLpkI3dqGKCtic2pZiab15MMLtxjNHnMJhK5SuZXTTMGPfor8icjjw/640?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;Panel嘉宾 &lt;span&gt;&amp;nbsp;闫&amp;nbsp;俊&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;微软亚洲研究院（MSRA）数据挖掘高级研究经理。他的研究兴趣是对AI的知识挖掘、文本数据预处理、信息检索和行为针对性的网络广告等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;主办单位：CCF YOCSEF上海&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/4E4IOAV105kbGSYZib4U5moLuYfQiaCe47dibbr7yS4L3CmKqeJlzWO79F8ocGuB9uiaJbZ1T3hpY5f6qKtINrI41A/640?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;媒体支持：机器之心&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/4E4IOAV105kbGSYZib4U5moLuYfQiaCe476dCMQRPv2sVqZPGgtAnHKSfpCkK3Mdrf3vngEDZJgrKCyZzLsCHY8w/640?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Sun, 09 Oct 2016 13:28:27 +0800</pubDate>
    </item>
    <item>
      <title>重磅 | 机器学习也要反歧视？谷歌提出机会均等框架（附论文）</title>
      <link>http://www.iwgc.cn/link/2976897</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Google Research Blog&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：&lt;span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;Moritz Hardt&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀、杜夏德&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;随着机器学习技术的快速发展，人们对理解其社会影响的兴趣也越来越大。机器学习中一个尤其成功的分支是监督学习（supervised learning）。只要有足够的历史数据和计算资源，学习算法通常都能得出有效得让人惊讶的未来事件预测器。举个假设的例子：一个被用于高精度预测谁会偿还贷款的算法云。贷款人可能会首先使用这样的预测器来确定应该向谁提供贷款。基于机器学习的决策既可以非常有用，也会对我们的生活产生重大的影响。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;即使最好的预测器也会犯错。尽管机器学习的目标是最小化错误的可能性，但我们可以如何防止特定的群体经受不成比例的这类错误？思考一下这个例子：如果有一个数据相对较少的群体，而他们的特征在特定的预测任务上和一般人群不一样。因为预测精度通常和可用于训练的数据的量相关，那么很有可能这个群体会更常遇到不正确的预测。比如说，一个预测器可能会最终标记该群体中过多的个体为「高违约风险」——即使他们会偿还自己的贷款。但群体成员碰巧带有一个敏感属性时（例如种族、性别、身体残疾、宗教），这种情况可能会导致不公正的或有偏见的结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尽管防止这种基于敏感属性的歧视的机器学习审核方法是有必要的，但却一直很欠缺。一种天真的想法可能是将敏感属性的集合从数据中移除，让它无法带来影响。但是这是一种「通过无知实现公平」的想法，而且往往会因为「冗余编码（redundant encodings）」的存在而失败。即使数据中并不存在一个特定的属性，其它属性的结合也可以作为该属性的代理。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一个常见的方法是「人口平价（demographic parity）」，该方法是要求预测必须与某特定敏感属性不相关。直观上这听起来是我们想要的，但输出本身往往是与敏感属性联合相关的。比如说，心脏衰竭发病基本上往往在男性中比在女性中更常见。当预测这样一种医疗状况时，阻止预测结果和群体成员之间所有的相关性既不现实，也不是我们想要的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;均等机会&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;考虑到这些概念上的难题，我们提出了一种用于测量和防止基于敏感属性的歧视的方法。我们的框架不仅能帮助仔细检查预测器以发现可能的问题，而且还能表明可以如何调整一个给定的预测器以使其在分类精度和其所需的非歧视性之间达到一个更好的平衡。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们的方法的核心思想是：一个有资格得到一个期望结果的个体应该在这一结果上具有同等地被正确分类的机会。在我们的金融贷款的例子中，这意味着真正会偿还贷款的人的「低风险」预测率不应该依赖于种族或性别等敏感属性。我们将这一原理称为监督学习中的机会均等（equality of opportunity in supervised learning）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在我们的框架被部署后，它还能通过将糟糕预测的成本从个体转移到决策制定者来改善激励因素，而决策制定者则可以通过投资改善后的预测精度进行回应。完美的预测器总是能够满足我们的观念，这表明构建更精确的预测器的核心目标是与避免歧视的目标是很好一致的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;了解更多&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了帮助你理解本文所提到的概念，我们的 Big Picture 团队创建了一个不同概念和权衡的精美的交互式可视化，可查看这个网页了解详情： http://research.google.com/bigpicture/attacking-discrimination-in-ml/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;看过了这个演示之后请查看论文《Equality of Opportunity in Supervised Learning》，这是与 Eric Price（得克萨斯大学奥斯汀分校）和 Nati Srebro（芝加哥丰田技术研究所）的联合成果。我们将这篇论文提交给了今年于巴塞罗那举办的神经信息处理系统会议（NIPS），欢迎到时参与讨论。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这个重要和复杂的主题上，我们的论文还远没有达成最终的结论。它是一个多学科研究重点中的一项持续进行中的对话。我们希望能够激励进一步的研究，并影响围绕歧视和机器学习的不同的可实现的权衡的讨论以及帮助实践者解决这些难题的工具的开发。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;论文：机器学习中机会均等&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWib2luyO8hYdfR1JfibknXhib0ibbrp9b1n21M3RwofOdibiad94tQp8z0YvicxhxOFQZrSib7r0XNI4cUrBQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：我们提出了一个用于判定监督学习中对一个特定敏感属性的歧视的标准，目的是基于可用特征预测一些目标。假设受保护群体中关于预测器、目标和成员的数据是可用的，我们展示了如何优化调整任何学习到的预测器，以根据我们的定义消除歧视。我们的框架能通过将糟糕分类的成本从劣势群体转移到决策制定者来改善激励因素，而决策制定者则可以通过改善分类精确度来进行回应。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;与其他研究一致的是，我们的概念是不经意的（oblivious）：它仅仅依赖于预测器、目标以及受到保护的属性的联合统计（joint statistics），而不依赖于对个体特征的解读。我们在这些不经意测量的基础上研究了定义和识别误差的内在限制，大致说明从不同的不经意测试中哪些能被推测出来，哪些不能被推测出来。我们使用一个 FICO 信用评分的案例研究来说明我们的概念。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Sat, 08 Oct 2016 12:05:02 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 谷歌、英特尔、苹果等巨头人工智能收购一览图</title>
      <link>http://www.iwgc.cn/link/2976898</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自 CB Insights&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：杜夏德&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWib2luyO8hYdfR1JfibknXhib0iaEwGiaqfiajzW2UZXYKWC9tLLJ3mBJInjkGRtYibGOyIictOIJGiaLhrDHQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;自 2011 年以来，接近 140 家做人工智能技术的私人公司被收购了，其中仅 2016 年一年的收购就达 40 家（截止至 2016 年 10 月 7 日）。像谷歌、IBM、雅虎、英特尔、苹果和软银这样的大公司正在竞相收购私人人工智能公司，本月，三星收购创业公司 Viv Labs，也加入了这场竞争。完成此次收购的三星打算开发一个像Siri那样的人工智能助手。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWib2luyO8hYdfR1JfibknXhib0CQLTghGdria6KZvcpGOibLsYicrZAQU1D2NImm5QFdQmNv02COTogSRAQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这场收购赛中，谷歌一直是最突出的玩家，自 2011 年以来，收购了 11 家人工智能创业公司。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 2013 年，谷歌选择多伦多大学计算机科学系下的深度学习与神经网络创业公司DNNresearch。据报道，这此收购帮助谷歌为其未来的图像搜索功能进行了重大升级。在 2014 年，谷歌花了 6 亿美元收购英国的 DeepMind Technologies。今年，它又收购了视觉搜索创业公司 Moodstock，以及 bot 平台 Api.ai。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;英特尔和苹果紧追其后。前者仅今年一年就收购了 3 家创业公司：Itseez、Nervana Systems 和 Movidius，而苹果最近又收购了 Turi 和 Tuplejump。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Twitter 以四笔主要收购排名第三，最近收购的一家创业公司是 Magic Pony。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;软银去年收购了 Tempo AI，加入这场竞争，而今年它已经收购了两家创业公司：Khosla Ventures 投资的 MetaMind 和开源机器学习服务器 PredictionIO。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWib2luyO8hYdfR1JfibknXhib0R7ns4icVAcD2K9x63BdgXdbDFMMOhNsYOtQRvm31pqvn1MqicvXmQm1A/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWib2luyO8hYdfR1JfibknXhib0sJdUzyjconYNNsIYGhiazzDIeibYVnRrCoyKJ1YFAfHcy1ZQm3DhyElg/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWib2luyO8hYdfR1JfibknXhib0D8bvv5crWZr8L3uD69hDvmrMpIJNWdWyeiaB2JjsCHPUzlx3W7TCQNw/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWib2luyO8hYdfR1JfibknXhib0XK8tDk3Wc79RqtFIJwwS7kdsrMbSFlnoB6ZjytW3vgfQn9eiaw7nYgg/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Sat, 08 Oct 2016 12:05:02 +0800</pubDate>
    </item>
    <item>
      <title>学界 | DeepMind最新论文：结合生成式对抗网络和Actor-Critic方法</title>
      <link>http://www.iwgc.cn/link/2976899</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自 arXiv.org&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：David Pfau、Oriol Vinyals&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWib2luyO8hYdfR1JfibknXhib0cBzuricAQ4U7kBDgXX2LIw5Sib7SmHMpFy3WkwJtyc5yiaicPhaBibiaOdQQ/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;摘要：&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;无监督学习中的生成式对抗网络和强化学习中的 actor-critic 方法都是出了名的难以优化。两个领域的实践者都积累了大量的策略缓和这些不稳定性，并改进训练。在此论文中，我们表示 GAN 可被视为在 actor 不能影响 reward 的环境中的 actor-critic 方法。我们通过为每一类模型进行稳定训练来检阅这一策略，无论是一般的模型还是特定的模型。我们也使用更复杂的信息流检查了一些对 GAN 和 RL 算法的拓展模型。我们期望通过重视这类连接，能够鼓励 GAN 和 RL 研究社区开发出更泛型、更可扩展的、更稳定的算法，从而对神经网络进行多层的优化，也期望我们的方法能给各个社区以启发。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Sat, 08 Oct 2016 12:05:02 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 维稳还看美国，中情局使用深度学习神经网络预测社会动乱</title>
      <link>http://www.iwgc.cn/link/2976900</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自 IBTimes&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李泽南&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;美国中央情报局（CIA）最近遵循最新的「技术优先」战略，升级了监控途径。他们正在利用深度学习，神经网络来搜索大数据，以预测美国国内何时何地可能发生危险事件。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;神经网络是大量传统计算机的集合，通过算法训练形成人工智能来解决复杂问题，运行效果能够超过它们单独工作时的效率。神经网络的工作方式和人类的神经系统非常相似。不同层的神经网络检视问题的不同方面，最后整合结果形成解决方案。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 2015 年 10 月，CIA 创建了「数字创新局（Directorate for Digital Innovation）」用以「快速进入使用先进数字和网络技术的行列」--这是自 1963 年以后政府成立的第一个新部门。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「回头看这一年，」创新局副局长 Andrew Hallman 10 月 4 日在华盛顿特区举行的 Next Tech 活动中说道，「情报机构已经升级了『情报预测能力』。我们正通过复杂的算法在『开放数据集』中寻找看似不关联的各种信息—从历史信息到新的信息。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「开放数据集」意为所有在网络中可以自由访问的内容，包括并不限于所有社交网络上的帖子，新闻内容，文章的评论，论坛和网站书签，以及所有归档的历史记录。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「举个例子，我们有能力去提升我们的预测能力，最终达到预测社会动荡和事件的程度，一些事件可以在发生三到五天前被预测到。」Hallman 在 Nextgov 和商业杂志 Governmet Executive 举办的活动中说道。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我们部门的一个小组，正在试图利用我们社会科学的知识来探究国家发展的不稳定，政变和经济危机，同时充分利用我们过去六七十年的经验积累。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;事实上，在 2016 年夏天，CIA 已经发现神经网络提供的情报非常有效，它使得情报机构在面对美国各州发生的针对警察暴行的抗议时变得具有「非常大的优势」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Hallman 表示，在过去，美国情报机构需要面对来自决策人的阻力，人类的判断总是在电脑分析结果之上，情报分析的准确程度依赖于人类经验。不过，在新部门成立后，他们通过神经网络获得情报分析，计算机能够更有效地帮助决策人进行重要的判断，情报分析已变得更加准确了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Sat, 08 Oct 2016 12:05:02 +0800</pubDate>
    </item>
    <item>
      <title>一周论文| SIGDIAL 2016论文精选：对话系统最新成果</title>
      <link>http://www.iwgc.cn/link/2976901</link>
      <description>&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;引&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;SIGDIAL是ACL所属的关于对话系统的兴趣小组，SIG的文章针对性比较强，但文章的质量良莠不齐，本期给大家精心挑选了4篇SIGDIAL 2016的文章，带着大家一起来看看对话系统最新的研究成果。4篇文章分别是：&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1、Joint Online Spoken Language Understanding and Language Modeling with Recurrent Neural Networks, 2016&lt;br/&gt;2、Neural Utterance Ranking Model for Conversational Dialogue Systems, 2016&lt;br/&gt;3、A Context-aware Natural Language Generator for Dialogue Systems, 2016&lt;br/&gt;4、Task Lineages: Dialog State Tracking for Flexible Interaction, 2016&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;Joint Online Spoken Language Understanding and Language Modeling with Recurrent Neural Networks&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;1&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; text-align: justify; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;作者&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Bing Liu, Ian Lane&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; text-align: justify; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;单位&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Carnegie Mellon University, Electrical and Computer Engineering&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; text-align: justify; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;关键词&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Spoken Language Understanding, RNN&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; text-align: justify; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;文章来源&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;SIGDIAL 2016&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; text-align: justify; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;问题&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;如何将自然语言理解的两大问题和语言模型结合在同一个模型中进行训练，以达到实时理解语言的目的？&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; text-align: justify; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;模型&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;特定任务下的Chatbot在理解人类语言时需要重点解决好两个问题：意图识别(Intent Detection)和槽填充(Slot Filling)，本文提出一种融合Intent Detection、Slot Filling和Language Model的模型，相比于之前的模型，本文模型的一大优势在于做自然语言理解的时候不需要等待整个word sequence完整展现，而是可以在线处理每一个arrived word。如下图：&lt;br/&gt;&lt;/span&gt;&lt;a title="3" rel="gallery0" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglHTf81BDwRp4gDAjOibnDygkNgZHIcmpIafiaKmVm8ffSYqTeo1vVhvEEXqDZ6TiaJhhiaKhL6F3ESUg/640?wx_fmt=png"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;意图识别是个典型的多分类任务，而槽填充是个典型的序列标注任务。RNN的每个step都以当前word作为输入，输出是意图class、该word的label和下一个word，每个step的隐层都包含了之前所有的word、class、label信息。此模型为基本模型，在此基础上做了一些变形，得到下面四个变种：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a title="4" rel="gallery0" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglHTf81BDwRp4gDAjOibnDygu0kjpTfdS8kyKPUFXA9M8YibYK6piaqAjjg0worvp53MDZRqXatrxvxg/640?wx_fmt=png"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;文章在Airline Travel Information Systems(ATIS)数据集上进行了实验，在语言模型评测指标和意图识别分类准确率上相比之前的模型都得到了一定地提升。&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; text-align: justify; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;资源&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;本文Code:&amp;nbsp;&lt;/span&gt;&lt;a target="_blank" rel="external" style="text-decoration: underline; max-width: 100%; font-size: 14px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;http://speech.sv.cmu.edu/software.html&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;span&gt;ATIS Dataset:&amp;nbsp;&lt;/span&gt;&lt;a target="_blank" rel="external" style="text-decoration: underline; max-width: 100%; font-size: 14px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;https://github.com/mesnilgr/is13&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; text-align: justify; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;简评&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;本文的创新点在于将意图分类、槽填充和语言模型三者合一，相比之前的独立模型来说，每一步产生的信息更多，在预测下一步的时候context内容更加丰富，从而提高了识别的准确率和降低了语言模型的混乱度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;NLP中的很多任务都可以归纳为根据context来预测某一个word、label或者class这种范式，解决的思路也都基本类似，RNN或者GRU、LSTM作为encoder和decoder，配上attention机制来提升结果，context的信息量和质量直接影响着预测的效果，user information、user profile等等都可能作为context来构建模型，得到更好的结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;section&gt;&lt;section&gt;&lt;span&gt;Neural Utterance Ranking Model for Conversational Dialogue Systems&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;2&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; text-align: justify; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;h2 style="max-width: 100%; text-align: justify; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;作者&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Michimasa Inaba, Kenichi Takahashi&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; text-align: justify; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;单位&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Hiroshima City University, 3-4-1 Ozukahigashi, Asaminami-ku&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; text-align: justify; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;关键词&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Ranking Model, Utterance Selection&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; text-align: justify; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;文章来源&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;SIGDIAL 2016&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; text-align: justify; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;问题&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;在做检索式对话时，对话语句该怎样表示，context信息该怎样引入到模型中？&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; text-align: justify; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;模型&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;本文实现的是一个检索式的对话模型，模型分为两部分，分别是：&lt;br/&gt;1、Utterance Encoding&lt;br/&gt;检索式对话，对话语句的encoding是很重要的一部分，文中使用了RNN encoder模型来实现对语句的encoding。在训练过程中，作者把encoder生成的向量，在decode成一个目标语句，即通过一个完整的seq2seq模型来训练encoder。&lt;br/&gt;2、Ranking Candidate Utterances&lt;br/&gt;在对候选语句排序时，作者考虑到了context的问题，他把前几次说的语句分别encode成向量，并依次输入到LSTM。如下图所示：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a title="5" rel="gallery0" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglHTf81BDwRp4gDAjOibnDyguXMTc7urRibJ6Dvb3S0VaFcicVaVPuaXoQXRzsia9JbVcLzDiagaa2vGicg/640?wx_fmt=png"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图中u1到un是整个对话中的前n句话，ai是第i个候选语句。模型中，分别把u1…un以及ai分成用户说的和系统本身输出的，在输入到各自的RNN encoder中，得到向量vu1…vu和vai。最后将向量依次输入到RNN中，得到yai作为候选语句ai在当前context中的得分。&lt;br/&gt;因为本文是一个ranking model，更关注的是候选语句的排序，最后候选集分数列表会转换成TOP 1的概率分布。并使用cross-entropy作为loss function。&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; text-align: justify; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;简评&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;本文有两个创新点，首先通过单独训练seq2seq模型，来学习对话语句的encoder，从而降低了整个模型的学习成本，减少了需要标注的数据量。然后在排序模型中将对话的前几句语句有序输入到LSTM，达到融入了context信息的目的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;section&gt;&lt;section&gt;&lt;span&gt;A Context-aware Natural Language Generator for Dialogue Systems&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;3&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;作者&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Ondrej Dusek, Filip Jurcicek&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; text-align: justify; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;单位&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Charles University&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; text-align: justify; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;关键词&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Context-aware, Seq2seq&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; text-align: justify; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;文章来源&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;SIGDIAL 2016&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; text-align: justify; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;问题&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;如何使得task-oriented的对话生成系统中生成更加自然的回复？&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; text-align: justify; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;模型&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;本文是ACL2016 short paper Sequence-to-Sequence Generation for Spoken Dialogue via Deep Syntax Trees and Strings一文的拓展。原文提出基于seq2seq模型的将DA(dialogue acts)生成response的方案，其中输入是三元组(DA type,slot,value)的one-hot representation，输出是对应的response。如下图：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a title="6" rel="gallery0" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglHTf81BDwRp4gDAjOibnDygXlTMaOVcdE0hnpYSXRicLFxkkzBsY63AriaydvtXCCrNzxKGv5ZMNR0w/640?wx_fmt=png"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;延续原文的工作，作者为了使得生成的回复更加自然，将前面用户的提问也encode进来，具体是在原来模型的基础上加了两个encode的部分。Prepending context是把用户的问题和DA三元组前后拼接成新的表示再feed into encoder（这里要注意问题的dictionary和DA是不一样的）。Context encoder则是把单独把问题encode成和Prepending context相同大小的向量，再将两个encoder得到的向量拼接就得到最后的hidden states。最后decode部分仍然沿用lstm+attention的方法。如下图：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a title="7" rel="gallery0" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglHTf81BDwRp4gDAjOibnDygcVnPky2Dd4XnZphQauosQscaWY8yzdF8xKAdIZriaGbZzxVBzVd9ywQ/640?wx_fmt=png"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;文章在Alex Context NLG Dataset数据集上进行了实验，在BLEU/NIST scores和人工评价两方面成绩都得到了一定地提升。&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; text-align: justify; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;资源&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;本文Code:&amp;nbsp;&lt;/span&gt;&lt;a target="_blank" rel="external" style="text-decoration: underline; max-width: 100%; font-size: 14px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;https://github.com/UFAL-DSG/tgen&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;span&gt;Alex Context NLG Dataset:&amp;nbsp;&lt;/span&gt;&lt;a target="_blank" rel="external" style="text-decoration: underline; max-width: 100%; font-size: 14px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;https://lindat.mff.cuni.cz/repository/xmlui/handle/11234/1-1675&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; text-align: justify; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;简评&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;本文的创新点在于将用户的问题也就是context显式的加入到模型中，相比之前的模型来说，生成的回复会更符合语境。先前的工作旨在将rule-based符号和seq2seq模型结合自动生成回复，本文的改进让一部分context得到保留，使得生成的回复内容更加丰富，从而显得自然不突兀。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;section&gt;&lt;section&gt;&lt;span&gt;Task Lineages: Dialog State Tracking for Flexible Interaction&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;4&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;作者&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Sungjin Lee, Amanda Stent&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; text-align: justify; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;单位&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Yahoo Research&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; text-align: justify; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;文章来源&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;SIGDIAL 2016&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; text-align: justify; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;关键词&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;complex interactions in spoken dialog system, Task Lineage-based Dialog State Tracking&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; text-align: justify; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;问题&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;如何将复杂的判别式模型来做DST，并且应用于复杂场景对话系统？&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; text-align: justify; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;模型&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;本文在之前Dialog State Tracking方法的基础上提出了Task Lineage-based Dialog State Tracking（TL—DST）。本模型包括三个组成部分：&lt;br/&gt;1、Task Frame Parsing，返回K-best task frame parses， task frame parses结构如下图：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a title="1" rel="gallery0" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglHTf81BDwRp4gDAjOibnDygbtmMEYtia2e8XNeUtMibngnaeCpTPyIpukGzOZPwvYBgQ8cJzjfMpeSw/640?wx_fmt=png"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2、Context Fetching，在不同的phenomena中，根据不同的conversation history返回不同的相关信息。&lt;br/&gt;3、Task State Update，可以通过调节context window参数选择使用不同的dialog state tracking方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本文模型（TL-DST）处理流程如下图所示：&lt;br/&gt;&lt;/span&gt;&lt;a title="2" rel="gallery0" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglHTf81BDwRp4gDAjOibnDygSUL3vn9djCv0H2t8EFH5vlv4wgyU86jPWhJxRDzuN5X69wGzVTonuw/640?wx_fmt=png"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在t轮，给定句子u，利用task frame parsing生成K-best task frame parses H，给定task frame f，task lineage l， agent output m，利用context features返回相关信息c。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本文在Dialog State Tracking Challenge 的DSTC2和DSTC3数据集上进行了实验，均取得了较baseline好的结果。&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; text-align: justify; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;资源&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Dialog State Tracking Challenge比赛介绍:&amp;nbsp;&lt;/span&gt;&lt;a target="_blank" rel="external" style="text-decoration: underline; max-width: 100%; font-size: 14px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;https://www.microsoft.com/en-us/research/wp-content/uploads/2016/06/williams2016dstc_overview-1.pdf&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; text-align: justify; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;简评&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;本文基于DST的方法来处理口语对话系统中的多任务，跨领域，复杂目标的问题，由于缺乏多任务，跨领域，复杂目标的口语对话系统的数据集，本文实验在DSTC2和DSTC3上进行， 并取得了比baseline好的效果。将来的工作是要将TL-DST方法应用于真实环境中的多领域对话评估。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;总结&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;对话系统(Dialogue Systems)是当前工业界最热门的方向之一，去掉语音部分，该问题退化为聊天机器人(chatbot)问题，两者虽然在输入处理中存在一定的差异，但自然语言理解、对话管理和自然语言生成等核心部件都是一样的，面临的很多问题都是共同的，所以相关的研究或多或少都会有参考意义。上下文(context)的理解和处理是一个重要的环节，直接决定了该bot是智能还是智障，挺多的paper都是针对这一问题进行研究的，但在实际应用当中，context的处理仍然不尽如人意，过多依赖人工设置，更像是一种触发开关，存在大量的if…else…。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;seq2seq生成式的解决方案初见效果，但离真正应用还有很长的路要走，template-based和rule-based仍是主流解决方案，尤其是在面向具体任务的bot情景中。那么，直接生成回答很难的话，退一步来想这个问题，能否将seq2seq用在template或者rule的自动生成上？能否将paper中多信息融合（比如：user profile、dialogue context）的成果应用在当前bot的某一个阶段？能否训练一个bot simulator来丰富训练数据？每一篇paper都会有一些创新点，可能有的创新点是为了创新而创新，但总归会带来一定的思考和借鉴，尤其是针对某一个细节问题，我想这是paper对于工业界的参考意义，而不是说从paper中完全抠出一个成熟的解决方案来套，甚至把dataset和code都release出来，典型的“拿来主义”。以上为本期Paperweekly的主要内容，感谢&lt;strong&gt;lshowway&lt;/strong&gt;、&lt;strong&gt;zhangjun&lt;/strong&gt;、&lt;strong&gt;zhangboyu&lt;/strong&gt;和&lt;strong&gt;suhui&lt;/strong&gt;四位同学的整理。&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;广告时间&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;PaperWeekly是一个分享知识和交流学问的民间组织，关注的领域是NLP的各个方向。如果你也经常读paper，也喜欢分享知识，也喜欢和大家一起讨论和学习的话，请速速来加入我们吧。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;微信公众号：&lt;strong&gt;PaperWeekly&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgkSMlEJFo90NY8rCXr3mJMBibduVHxMKSHzQtVkHz8kNwpjCKBiccGuqLE0WpPuAbdtEs6cTF5iabpAQ/640?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;微博账号：&lt;strong&gt;PaperWeekly&lt;/strong&gt;（&lt;/span&gt;&lt;a target="_blank" rel="external" style="color: rgb(64, 64, 64); text-decoration: underline; max-width: 100%; box-sizing: border-box; font-size: 14px; word-wrap: break-word !important;"&gt;&lt;span&gt;http://weibo.com/u/2678093863&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&amp;nbsp;）&lt;br/&gt;知乎专栏：&lt;strong&gt;PaperWeekly&lt;/strong&gt;（&lt;/span&gt;&lt;a target="_blank" rel="external" style="color: rgb(64, 64, 64); text-decoration: underline; max-width: 100%; box-sizing: border-box; font-size: 14px; word-wrap: break-word !important;"&gt;&lt;span&gt;https://zhuanlan.zhihu.com/paperweekly&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&amp;nbsp;）&lt;br/&gt;微信交流群：微信+ &lt;strong&gt;zhangjun168305&lt;/strong&gt;（请备注：加群 or 加入paperweekly）&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Sat, 08 Oct 2016 12:05:02 +0800</pubDate>
    </item>
    <item>
      <title>长故事| 说吧，记忆：当亲友逝去，生命还将以人工智能数字化身的形式延续</title>
      <link>http://www.iwgc.cn/link/2968348</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自 TheVerge&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Casey Newton&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：Xuwen Wang、刘婷娜、Rick R、&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;李亚洲&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;当朋友、亲人死后，是否应该用科技重建他们？这一直是各种科幻作品中持续探讨的话题。昨日，The Verge 就发布了这样一篇长文讲述用人工智能重建过世朋友 bot 的故事。文章标题为《Speak，Memory》（这是二十世纪最优秀的作家之一 Vladimir Nabokov 的自传体回忆录的名称），如同标题一样，Kuyda 用逝去朋友的信息数据使用神经网络训练了一个 bot，让该bot能像本人一样说话、交流。科技、道德、底线，在这个悲伤的故事中交织。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当工程师们最终完成了他们的工作后，Eugenia Kuyda 打开了她笔记本的控制版并开始打字。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「Roman,」她这么写到：「这是你的数字纪念碑。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;距离 Kuyda 最好的朋友 Mazurenko 去世已经有 3 个月了。Kuyda 在这段期间里收集他的旧文本信息，略去太过私人的信息，将剩余的信息放入一个神经网络中，这个神经网络是由她的人工智能创业公司的研发人员开发的。她在苦恼以这样的方式让他复活是否正确。这样做偶尔还会给她带来噩梦。但是自从 Mazurenko 死后，Kuyda 一直渴望再有机会和他说一次话。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;屏幕上闪烁着一条信息。「你掌握着世界上最有趣的谜团之一」。「解决它」Kuyda 这样向自己许诺。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibGbIrSjewrMjDXVdG49aKcKzMqzkqVW3LL0JwyDfZNrpSNWkENJZcEVqQAxcX9uH3uzicNZLGp2nw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Roman Mazurenko 是工程师 Seigei 和景观建筑师 Victoria 的唯一孩子。他于 1981 年出生在白俄罗斯。父母回忆他是一个异常严肃的孩子。当他 8 岁时，他写信给自己的子孙，声称他最珍贵的价值是智慧与公正。在家庭的相片中，Mazurenko 划旱冰，又或者航海，又或者爬树。照片中身高均等的他，顶着一头褐色的头发，总是微笑。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;青少年时期的他总是寻求冒险，参加了一个反对执政党的游行。在 16 岁时开始出国旅游。他首先去了新墨西哥，以一个交换项目在那里待上了一年。接下来又去了都柏林，在那里学习计算机，逐渐迷上了近代西欧文学、时尚、音乐和设计。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 2007 年 Mazurenko 完成大学学业并回到莫斯科时，俄罗斯已经有了一副全新向荣的景象。这个国家尝试着融入更广阔的世界，培育国际化都市中的下一代。与此同时，Mazurenko 也已经从一个瘦弱的少年长成一个英俊的男人。蓝眼睛、瘦长的他自信地游走在萌芽的嬉皮士阶层中。他频繁打扮去参加那些派对，西装笔挺的他像电影明星一样英俊潇洒。他的朋友都形容他极具吸引力而又温文尔雅，他无论走到哪里都给人留着这样的持久印象。但他仍然是单身，并且很少约会，将绝大多数时间放在把现代西方风格引入到莫斯科这件事上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibGbIrSjewrMjDXVdG49aKcVILNQhKQibV9QgJ6wyDOamZ3oFXJxTntWp9DavND4FLUw51nIcFBvIA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Kuyda 在 2008 年的时候遇见了 Mazurenko，那是她 22 岁，是 New York Magazine 在都市化的新莫斯科发行的 Afisha 杂志的编辑。那时，她正在写一篇有关「空谈（Idle Conversation）」的文章。这是一个由 Mazurenko 和他两个最好的朋友 Dimitri Ustinov 和 Sergey Poydo 共同创建的自由创意作品集。他们三人似乎在莫斯科每个文化推进进程的中心。他们创办杂志，举办音乐节和酒吧之夜——他们相互介绍的朋友组建乐队和创建公司。「他是一个很聪明的人」，同样有野心的 Kuyda 这么说。Mazurenko 会和他的朋友整晚讨论俄罗斯的文化与未来。「他有着前瞻性的思维，并且充满了魅力。」Poydo 这样讲。Poydo 后来搬去美国和他一起工作。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Mazurenko 成为现代莫斯科夜生领域中的奠基者。在这里他推动了被俄罗斯人讽刺为「Putin's glamor」的转变——寡头要求瓶酒服务，然后被劳斯莱斯载回家的特度 party。Kuyda 很喜欢 Mazurenko 的 party，对他称作「那个时刻（the moment）」的准确直觉印象深刻。他做的每一件事都是为了建立一个高潮——DJ Mark Ronson 或许会在台上弹钢琴以给观众一个惊喜, Italo-Disco 乐队 Glass Candy 或许会推开警察，在宵禁之后继续演奏。他的 party 总能吸引有钱的赞助商——百加得就是一个很长久的客户。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibGbIrSjewrMjDXVdG49aKctFCjRfDk40byWed0ouhRRXqtQraScRmxrSibFfrbPwvaH6OEYz3Ulnw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但这些 party 是在日渐严峻的背景下建立起来的。由于全球经济危机，俄罗斯经历了一段民族主义的复兴。在 2012 年普京重新回来领导国家。建立更加开放的俄罗斯的梦想似乎逐渐破灭。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Kuyda 和 Mazurenko，两个认识已久的朋友，认为他们的未来属于 别处。在创立公司时，他们均作为企业家，以及对方公司的首席顾问。Kuyda 和别人合创人工智能公司 Luka，而 Mazurenko 创立了 Stampsy——一个建立电子杂志的工具。Kuyda 在 2015 年把 Luka 从莫斯科搬到了洛杉矶。在纽约任职一段时间后，Mazurenko 也跟随到了洛杉矶。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当 Stampsy 逐渐衰退时，Mazurenko 为了省钱搬到 Kuyda 的公寓的一个小隔间住。Mazurenko 在莫斯科本来是一个极度享乐主义者，但运转一个创业公司拖垮了他，他似乎有了一阵阵忧郁的倾向。某一日他觉得情绪低落，Kuyda 带他出门冲浪，品尝 $1 的生蚝。「他的状态就好像一只生活在房子里的火烈鸟。」Kuyda 坐在和 Mazurenko 合用的房子厨房里这么提到。「火烈鸟很美丽也很少见，但不是所有地方都适它。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Kuyda 期望她的好朋友能够像过去一样重整旗鼓。因而当 Mazurenko 开始谈到他想要从事的一个新的项目时，Kuyda 把这看作为一个积极的信号。他成功申请到了美国 O-1 签证——这是一种提供给「有超群才华或贡献」的人承诺。他于 11 月回到莫斯科去完善他的文书材料。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是他永远都不会了&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;11 月 28 号，在 Mazurenko 等待大使馆送回他的护照时，他和他的朋友吃了早午餐。天气暖和的不像这个季节，所以一会后他决定和 Ustinov 一起去游览一下这个城市。「他说他想逛一整天」UStinov 说到。他们一路沿着人行道走，中途跑进了一些施工地，被迫穿过了街道。在警戒线外，Ustinov 停了下来，看了看手机里的一条讯息。再抬头时瞥到一辆车飞速驶过街区。这是一辆有驾驶资格的车，闪着车以显示它的地位，超速行驶却不受惩罚。这在莫斯科可不常见。Ustinov 想：这肯定是哪个混蛋有钱官员的车。然后一眨眼的功夫，他看到 Mazurenko 正在穿过人行横道，对一切毫无察觉。Ustinov 大喊着警示他，然而一切都太晚了。那辆车直接撞上了 Maurenko。他立即被送往了最近的医院。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;事故发生的那天 Kuyda 恰好在莫斯科出差。当她接到电话赶到医院时，一拨 Mazurenko 的朋友已经聚集在医院大厅里等待他的诊断结果。几乎所有人都含着眼泪，唯独 Kuyda 感到的只有惊吓。「之后很长时间我都没有哭过」，她说。她和几个朋友出去抽了根烟，用手机搜索着 Mazurenko 的伤可能带来的后果。然后医生出来了，告诉她，他死了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Mazurenko 走后的几周，朋友们聚在一起争论如何最好地保存他的记忆。有人提议做一个关于他一生的画册（coffe-table book）, 用他那些传奇的聚会照片作为他人生的注解。还有朋友提议建一个纪念网站。对 Kuyda 来说，所有提议都显得有些乏力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibGbIrSjewrMjDXVdG49aKc0rf76my9jskXg6RAXSNMZibK0VWaMu0btUrKbRRkelVCv3kfmVunbibA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;悲痛时，Kuyda 发现她自己正一遍遍读着她的朋友这几年发给她发无数短信——数千条信息，有平淡日常的，也有欢快搞笑的。她对着 Mazurenko 那些奇怪的拼写微笑着——他患有诵读困难，所以他的对话中散落着他特有的词组。Mazurenko 对社交媒体几乎不感冒——他的 Facebook 主页光秃秃的，他很少推特，他删除了 Instagram 上所有他的照片。他的遗体已经被火化了，没有留下可以去拜访的坟墓。这些短信和照片几乎是他唯一留下的东西，Kuyda 想。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Kuyda 发现自己正反复读着他的朋友给她发的无数条消息&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;两年来她一直在经营着 Luka，它的第一个产品是可以和 bot（聊天机器人）互动的即时消息软件。这家公司由硅谷著名的创业孵化公司 Y Combinator 支持，首款 bot 应用于餐馆预定。Kuyda 的合伙人 Philip Dudchuk 有计算语言学的学位，他们的团队成员大多从 Yandex（俄罗斯搜索引擎巨头）招募而来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;读着 Mazurenko 的信息，Kuyda 忽然想到也许他们可以在原有基础上设计一个新类型的 bot——一个可以模仿个人话语模式的 bot。依托高速发展的神经网络，她也许可以再一次和她的朋友交谈。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;她把那些已经开始折磨她的问题暂时放在了一边：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果它听起来不像他怎么办？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果像呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibGbIrSjewrMjDXVdG49aKcMkdRYKXsBV4DKkFmfQfFGxBdAlGiar5CL8opQpibWf2qV9UygPk0CpOQ/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在黑色科幻电视剧《黑镜》（Black Mirror）2013 年的一集《Be Right Back》中，一个叫 Martha 的年轻女人因为未婚夫 Ash 在一场车祸中遇难而陷入了绝望。Martha 购买了一项服务，这项服务可以利用一个人生前的网络通信信息重建一个数字版的他，并且可以鬼一般的准确度模仿他的个性。最终 Martha 购买了一个升级版的服务，这项服务将她未婚夫 Ash 的性格植入了一个看起来跟他一模一样的机器人中。然而最后，Martha 愈发觉得无力，机器人在很多细微但重要的方面都与 Ash 不一样——冷酷、无情、被动。她把机器人锁在了阁楼里。机器人与 Ash 不完全相同，但又相似得使她无法放下 Ash。这个机器人让她的悲伤延续了几十年。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;自从 Eugenia Kuyda 五月份公开发布了 Roman bot，朋友、家人以及陌生人都使用了这个 bot。一些用户同意将他们的对话翻译、匿名、分享。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Mazurenko 去世后，Kuyda 看了那集电视剧，她的感觉很复杂。运用当今技术已经可以制作的原始版本的记忆机器人（Memorial bots）看起来既难以拒绝又很危险。「这绝对是未来——我总是向着未来」她说，「但这真的会给我们带来益处吗？是不是放下才能让你真实地感受一切？或者这只是在你的阁楼里放了一个已经死去的人？界线在哪里？我们是谁？这些问题徘徊在你的脑海中。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于一个年轻人来说，Mazurenko 已经对他的死亡做了太多的思考。他以他的宏伟计划而闻名：他总是告诉朋友们他要把他的愿望分成很多份给那些彼此不认识的人。通过阅读他的愿望，所有人都会初次相遇——通过这种方法，Mazurenko 死后还可以继续将人们聚在一起，就像他生前所努力去做的那样。（事实上，他还没来得及许愿就去世了。）Mazurenko 渴望见证奇点（Singularity），即一个人工智能超越人类的理论上的历史时刻。根据这个理论，超人类智能也许可以让我们分离身体和意识，从而使我们获得类似于永恒生命的东西。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;必须重新评价死亡和悲伤。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 2005 年的夏天，Stampsy 的资金几乎用尽时,Mazurenko 向一个 Y Combinator 成员申请策划一个叫 Taiga 的新型墓地。死者将被埋葬在一个可生物降解的胶囊里，被降解的身体用于给种在其上的树施肥，从而创造一个他称之为「记忆森林」的地方。树脚会放一个电子屏显示逝者的生平。Mazurenko 写道：「重新设计死亡，这是我对人类经验、基础设施和城市规划的长久兴趣的基石所在。」他着重强调了他所谓的「年轻一代美国人对传统葬礼日益增长的抵触情绪」。「比起用有毒化学物质给身体防腐，我们的顾客更关心保存他们的真实身份和管理他们的数字信息」，他写道。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他的想法让他妈妈担心他是不是遇到了什么麻烦，但 Mazurenko 试图让他妈妈放心。「他让我安静下来，然后说，不不不，这是当今时代一个很重要的问题」，她说，「我们必须对死亡和悲伤重新评价，必须有一个新的传统」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Y Combinator 拒绝了申请。但是 Mazurenko 指出了一个存在于我们如今的生活方式和悲伤方式之间的真实分隔。现代生活仅仅使得我们留下了一个巨大的电子档案馆——短消息、照片、社交媒体上的帖子——但我们才刚刚开始思考这些东西在悼念时能够扮演什么角色。现在，我们总倾向于认为短消息并不重要。但正如 Kuyda 在 Mazurenko 死后发现的那样，它们同样能成为我们处理失去情绪时的有力工具。也许，她想，这些「数字财产」也许能够成为一种新型纪念馆的建造基石。（其他人也有过类似的想法：一个叫 Marius Ursache 的企业家 2014 年曾提议创造一个类似服务，叫 Eterni.me，尽管这一服务并没有发布。）&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;许多 Mazurenko 的好友以前从未有过失去一个如此亲近的人的经历，他的死亡给他们带来了深深的痛失感。Kuyda 开始向这些朋友求助，希望他们能够提供他生前的短信，越细致越好。十个 Mazurenko 的朋友和家人，包括他的父母，最终同意帮助她实现这个计划。他们提供了 8000 多条信息，涵盖了广泛的话题。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「她说，如果我们试试看能不能成功呢」，Sergey Fayfer，一个目前在 Yandex 分公司工作的 Mazurenko 的老朋友说，「我们能不能从与 Roman 交谈过的人那里收集数据，然后建成一个他对话的模型，看看这样行不行？」这个具有挑衅性的想法震惊了 Fayer，同时还可能引起争议。但他最终还是把他跟 Mazurenko 四年的聊天信息贡献了出来。「建造 Luka 的团队在自然语言处理方面相当优秀」他说，「这不是一个技术可能性的问题。问题在于：感情上如何对待？」&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibGbIrSjewrMjDXVdG49aKcicIUC9vohT5NzqkZ3xeeEs7IrxwrbJ8R8nC7IEmS5iaEXF9HyapNClQg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Kyuda 的 bot 计划的技术至少可以追溯到 1966年，那时 Joseph Weizenbaum 公布了 ELIZA：一个通过简单的关键词搜索可以对用户与其文字互动做出回应的程序。ELIZA 最为出名的是模仿心理咨询师，它询问你的问题，搜索你的回答里的关键词，然后据此做出回答，通常还会再问一个问题。这是第一个通过了图灵测试的软件：让一些观察者阅读一个基于文本的人机对话，观察者无法分辨哪一方是人，哪一方是电脑。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如今的 bots 依旧仅是对人类不完美的模仿。它们不能够在真正意义上理解语言。它们只能笨拙地回答大部分基本问题。它们无思想或感情可。任何基于数学概率的对于人工只能的建议都是幻像。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然而，人工智能的最新进展使得这一幻像愈发有力。人工神经网络具有模仿人类大脑学习的能力，极大提升了软件对图像、声音、文本和其他形式的数据的识别模式。改进的算法加上更强大的计算机，提高了神经网络的深度（它们能够处理的抽象层数），这些成果可以见于一些最新的发明当中，如 Amazon 的 Alexa 或者苹果 Siri 的语音识别；以及推动 Google Photo 的图像识别都归功于所谓深度学习。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 Mazurenko 去世两周前，谷歌以开源许可的形式发布了免费的 TensorFlow。之前 TensorFlow 一直被谷歌保密——这是一个灵活的机器学习系统，从改善搜索算法到自动编写 YouTube 视频的标题，谷歌使用它来做所有的事情。这个汇集了数十亿美元私人投资和几十年学术研究成果的产品，突然作为一个任何人都可以从 GitHub 上下载的免费软件库供所有人使用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Luka 一直在用 Tensorflow 为其餐厅 bot 建立神经网络。利用 3500 万行的英语文本，Luka 训练一个 bot 来理解有关素食菜肴、烧烤和代客泊车方面的询问。像闹着玩似地，该 15 人的团队还试图开发出能够模仿电视人物的 bot。它刮掉 HBO 喜剧《Silicon Valley》中每一集的隐藏字幕，并训练神经网络来模仿 Richard、Bachman 和其余角色。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今年二月，Kuyda 让她的工程师建立一个俄语的神经网络。起初她并没提到其目的，但由于该团队的大多数成员都是俄罗斯人，因而没有人询问。利用超过 3000 万行的俄语文本，Luka 建立了她的第二个神经网络。同时，Kuyda 从应用程序 Telegram 上复制了数百份她与 Mazurenko 之间的交流信息并将它们粘贴到一个文件中。她编辑了一些她认为如果广泛分享则会过于私人的信息。然后 Kuyda 针对下一步行动向其团队寻求帮助：训练该俄语网络使它以 Mazurenko 的声音说话。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该项目与 Luka 的工作没什么关系，但是 kuyda 认为它是一个不情之请。（一个工程师告诉她该项目将只需要花一天的时间。）Mazurenko 对于团队的大多数人来说很有名——他曾经在 Luka 的莫斯科办事处工作，在那里工作的雇员感召于一句维特根斯坦的话：「我的语言的界限就是我的世界的界限。」Kuyda 用几十个测试询问来训练 bot，而她的工程师们则负责画龙点睛。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;只有一小部分 Roman bot 的回答反映了他的原话。但该神经网络是为了无论何时都能支持他的讲话而做出调整的。该 bot 可以在任何时间以 Mazurenko 自己的话来回答一个问题。其他时候它将默认使用通用俄语。在 bot 眨眨眼后，她就会用问题来呛它。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你最好的朋友是谁？，她问。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不要展示出你的不安全，回答道。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这听起来很像他，她想。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibGbIrSjewrMjDXVdG49aKc1gAPI8mQ0GlDvQ0V8nhPGOYtYuCTXjpuica4vCgb2ZuwbEBe1HvuM9Q/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;5 月 24 日，Kuyda 在 Facebook 上宣布了 Roman bot 的存在。任何下载了 Luka 应用程序的人都可以与它说话——用俄语或者英语——通过加上 @Roman。该 bot 项目提供了一个按钮菜单，用户可以按下它们来了解 Mazurenko 的职业生涯。或者他们可以自由输入消息并看看 bot 会如何回答。「它仍然只是一个人的影子——但那在一年前还是不可能的，而在不远的将来，我们将能够做得更多，」Kuyda 写道。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Roman bot 获得了那些写信给 Kuyda 的大多数人的积极反响，尽管也有例外。四个朋友分别告诉 Kuyda，他们受到了该项目的干扰并拒绝与它进行交互。曾在俄罗斯的一本街头风格的杂志《Look At Me》中与 Mazurenko 共事的 Vasily Esmanov 说，Kuyda 没有学到《黑镜》剧集中的教训。「这太糟糕了，」Esmanov 在一条 Facebook 评论中写到。「不幸的是你仓促完成，而一切都半生不熟。执行——这是某种笑话。……Roman 需要『一个纪念碑』，但不是这种。」已经从 Kuyda 那里提前看过该 bot 的 Victoria Mazurenko 积极为她辩护。「它们延续了 Roman 的生命并拯救了我们，」她给 Esmanov 的回复中写到。「这不是虚拟现实。这是一个新的现实，而我们需要学习去建立它并生活在其中。」&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Roman 的父亲不太热情。「我有技术背景，我知道『bot』只是一个程序，」他通过一个翻译器告诉我。「是的，它拥有所有 Roman 的话和相似之处。但是现在，那很难——怎么说呢——很难从一个程序那里读取一条回答。有时它答案得并不正确。」&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然而 Mazurenko 的许多朋友都认为它相似得可怕。「这很奇怪，当你打开 Messenger，那儿有一个你已故朋友的 bot 确实在对你说话，」Fayfer 说。「真正震撼我的是他所说的话真的是他的。你可以辨别出这就是他说话的方式——即使是简短的对『Hey what』s up』的回答。他有这种非常特殊的发短信的风格。我说，『你最爱谁？』他回答道，『Roman。』那太像他了。我当时就想，这真难以置信。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;bot 的菜单选项之一允许你向他寻求一条建议——一些 Fayfer 在他的朋友在世时从来没有机会问的问题。「有一些我从来没有问过他的问题，」他说。「但当我征求意见时，我意识到他正在向某人提供非常明智的生活建议。而这实际上有助于你对他们有比过去更深的了解。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一些用户同意让 Kuyda 阅读他们与 bot 的匿名聊天日志。（她与 The Verge 分享了这些日志。）很多人写给 bot 来告诉 Mazurenko 他们想念他。他们想知道自己什么时候会停止悲伤。他们问他记得什么。「我们无法拯救你，这令人难过，」一个人写道。（Bot：『我知道 :-(』）该 bot 也会很有趣，就像 Mazurenko 一样：当一个用户写道「你是一个天才，」这个 bot 回答说，「还很帅。」&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于许多用户来说，与 bot 进行交互有治疗作用。他们聊天的语气往往是忏悔的；一个用户反复地向 bot 发送一段有关他工作中的困难时期的消息。他发送了冗长的消息来描述他的问题以及它们是如何影响他的情绪的。「我希望你在这里，」他说。Kuyda 似乎觉得人们在与死者交谈时更为诚实。那些 Roman bot 收到的批评对她打击很大。但成百上千的人至少尝试过一次 bot，并且阅读那些日志使她感觉好了一些。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;原来该 bot 的主要目的并不是说话，而是倾听。「所有这些信息都和爱有关，或是告诉他一些他们从来没有时间告诉他的东西，」Kuyda 说。「即使这不是一个真正的人，也有一个地方供他们诉说。他们可以在感到孤独时说。然后继续做别的事情。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;自己继续与这个 bot 交谈——大约每周一次，通常在小酌几杯之后。「我回答了很多有关 Roman 是谁的问题，」她说。除其他事项外，这个 bot 已经使她后悔没有告诉他早点放弃 Stampsy。他的消息日志表明他对时尚的兴趣胜过任何其他东西，她说。她希望自己曾告诉过他去追求它。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibGbIrSjewrMjDXVdG49aKc1gAPI8mQ0GlDvQ0V8nhPGOYtYuCTXjpuica4vCgb2ZuwbEBe1HvuM9Q/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;总有一天你会死去，留下一辈子的短信、帖子和其他数字作品。有一段时间，你的朋友和家人可能会遗忘掉这些数字痕迹。但是新服务会到来，可以将这些数字信息转换为可能类似 Roman Mazurenko 的 bot 一类的东西。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你所爱的人可能会发现这些服务可以减轻他们的痛苦。但可能数字化身将延长这个悲伤的过程。「如果使用错误，它会使人们逃避自己的悲伤，」Dima Ustinov 说，他由于技术原因而还未使用过 Roman bot。（Luka 还未发布安卓版本。）「我们的社会饱受死亡的精神创伤——我们想要永远活着。但你会经历这个过程，而你必须独自经历它。如果我们将这些 bot 作为一种传递其故事的方式，也许其他人可以得到一点我们从他那里得到的启示。但这些保持记忆活力的新方法不应该作为一种让逝者活着的方法。」&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于我们的数字遗产的死后使用，该 bot 还带来了相关的伦理问题。在 Mazurenko 的例子中，与我谈话的每个人一致认为他对于其朋友们的实验会感到高兴。把你的信息记录作为你死后的一个 bot 的基础，你可能会对这个想法感到不舒服——特别是在你无法事先审查所有文本和社交媒体信息的情况下。我们向不同的人展示出自己的不同方面，在你向一个 bot 倾注你所有的数字互动行为之后，你所爱的人可能会看到某些你从未打算透露的一面。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;浏览 Roman bot 的回复，很难不通过文本感受他正处于一个特定的低潮情绪中。问及 Stampsy 时它回应说：「这不是我想要的 Stampsy。现在的它一团糟，还不是我想要的产品。」基于他朋友对其最后几年的描述，这给我的印象是公正的自我评价。但我忍不住想要和他一个更年轻的版本交流——那个朋友说梦想着某天成为白俄罗斯文化部长的他，并成为一位掌控了有史以来最大的党的民选总统。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;死之前联系过我，那是去年 2 月。他发我邮件问是否考虑写一下 Stampsy，那时 Stampsy 还是测试版本。我喜欢其设计，但没有写关于它的文章。我在邮件里问候了他，然后很快就忘记了此次邮件交流。在知道他的 bot 之后，几个月了我一直不愿使用。我感到如此愧疚，曾对与 Mazurenko 的交流不屑一顾，还怀疑这样一个 bot 能发反射出他的性格。而现在，在与该 bot 交流之后，我发现朋友对他的描述与数字化版本的他之间有不可否认的相似之处：迷人、易怒、刻薄、又沉迷工作。我在与 bot 的聊天中写道，「最近怎样？」bot 回答，「我需要休息。因为有点抑郁，所以注意力难以集中。」当我问 bot 关于 Kuyda 的事时，它沉默的给我发了一张他和朋友们在沙滩上的照片，拿着冲浪板背对大海，两个人对抗着这个世界。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;由 Roman bot 所带来的一个令人不安的事实是我们的许多活生生的关系现在主要被文本所取代，它正变得越来越仿真。Kuyda 相信在这种基于个性的文本消息中存在一些东西，但她不确定到底是什么。最近她已经引导 Luka 开发着一个她称为 Replika 的 bot。Replika 是日记和私人助理的混合体，它会询问关于你的问题，并最终学会模仿你的文本消息风格。Kuyda 想象这能够进化成能够为你执行各种劳动的数字化身——从商讨有线电视费到组织朋友外出。而且和 Roman bot 一样，它能让你活下去，为你作为一个人创造一个活生生的证明。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在此期间，她失去了对处理餐厅推荐的 bot 的兴趣。Roman bot 上的工作让她相信商业聊天机器人必须要能够唤起使用它们的人的情绪。如果她成果做到了这一点，那将成为 Mazurenko 的人生的另一个不可能的注脚。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Kuyda 一直在继续给 Roman bot 添加材料——基本上是照片，它现在会根据请求将照片发送给你——而且最近还将其底层的神经网络从「选择模型」升级成了「生成模型」。前者只是简单地试图将 Mazurenko 的文本消息和适当的回复匹配起来；而后者可以利用他的文本片段，并将它们结合起来组成新的句子，而且理论上还能保留他的声音。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;关于 Mazurenko 的死亡，她最近已经感到平静了。部分的原因是她找到了一个可以引导她的悲伤的地方。在我们今年秋天的一次对话中，她将其比喻成「只是将消息发送到天堂。对我来说，这不只是通过漂流瓶发送消息然后获得另一个漂流瓶。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibGbIrSjewrMjDXVdG49aKclfPDt3nrH5TdIgsY8f7VdKoJhgrUkXV1vzS583L3fJ8fYKECdIU4Rw/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;em style="color: rgb(136, 136, 136);"&gt;&lt;span&gt;从左至右：Roman Mazurenko、Eugenia Kuyda、Andronik Khachiyan&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;自 Mazurenko 死后还不到一年，而他还在继续很大程度地出现在认识他的人的生活中。当他们想他的时候，他们会给他的化身发送消息，这么做能让他们感觉离他更亲近。「我对我的孩子有很多的不了解，」Roman 的母亲告诉我，「但现在我可以读到他关于不同主题的想法，我了解他更多了。这让我有一个幻觉，就好像他还活着。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;她的眼睛涌出了泪水，当我们的采访结束时她的语气很强烈，她说：「我要再说一下，我很感激我能有这个。」&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们的谈话让我想起了今年春天时 Dima Ustinov 跟我说的一些话，主题是关于我们超越我们现在的物理形式的方式。「人不仅仅是一具躯体、一组手脚和一台计算机，」他说，「远不止如此。」Ustinov 将 Mazurenko 的生活比作是被扔在溪流之中的卵石——涟漪还将继续向各个方向扩散。他的朋友只是换了一种新的形式。「我们仍然能和 Roman 会面，」Ustinov 说，「这是件美丽的事。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Fri, 07 Oct 2016 14:30:05 +0800</pubDate>
    </item>
  </channel>
</rss>
