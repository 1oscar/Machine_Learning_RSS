<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>机器之心</title>
    <link>http://www.iwgc.cn/list/670</link>
    <description>人与科技的美好关系</description>
    <item>
      <title>深度 | 亚马逊挑中MXNet后，机器之心和他们聊了聊</title>
      <link>http://www.iwgc.cn/link/3638668</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;机器之心原创&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编辑部&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;近日，亚马逊首席技术官 Werner Vogels 在一篇博客上宣布，&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720693&amp;amp;idx=1&amp;amp;sn=6a3e467d940615ee2713c4e75a7ae72c&amp;amp;chksm=871b0dcbb06c84dd515e4444c1aed86514cfc80e1dea85b44d4ce314b7e8ab6c45ad196f66fd&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720693&amp;amp;idx=1&amp;amp;sn=6a3e467d940615ee2713c4e75a7ae72c&amp;amp;chksm=871b0dcbb06c84dd515e4444c1aed86514cfc80e1dea85b44d4ce314b7e8ab6c45ad196f66fd&amp;amp;scene=21#wechat_redirect"&gt;亚马逊选择 MXNet 作为该公司最主要的深度学习框架&lt;/a&gt;；他还宣布 AWS 将会为 MXNet 和该公司所支持的生态系统的开发提供软件代码、文档和投资。这一消息对深度学习领域和 MXNet 社区来说都无疑是重大利好的。看起来知乎上&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720536&amp;amp;idx=3&amp;amp;sn=257021a323ad878178edd28259ce07ec&amp;amp;chksm=871b0d66b06c847088cef5bc824f457336a157d3de5d85d72fbf4ce6b0cb2d369d219b8a28cf&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720536&amp;amp;idx=3&amp;amp;sn=257021a323ad878178edd28259ce07ec&amp;amp;chksm=871b0d66b06c847088cef5bc824f457336a157d3de5d85d72fbf4ce6b0cb2d369d219b8a28cf&amp;amp;scene=21#wechat_redirect"&gt;「为什么强大的 MXNet 一直火不起来？」&lt;/a&gt;的问题现在终于可以终止了，相信在亚马逊这样的巨头的支持下，MXNet 还将迎来更大的发展并被更多的实践者应用。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;MXNet 的前世今生&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;MXNet 起源于三个不同的开源项目，分别是由在美国的陈天奇，在加拿大的许冰和在香港的王乃岩牵头的 cxxnet，上海张铮老师及其学生牵头的 Minerva，以及在新加坡的 Min Lin 牵头的 purine2 。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2014 年 NIPS 上，同为上海交大校友的陈天奇与李沐碰头，讨论到各个在做深度学习 Toolkits 的项目组，发现大家普遍在进行很多重复性的工作，例如文件 loading 等。于是他们决定组建 DMLC（Distributied （Deep） Machine Learning Community），号召大家一起合作开发 MXNet，分别发挥各自的特长，避免 reinvent the wheel。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;据张铮老师回忆，早期 MXNet 的核心成员在十人左右，却曾同时分布在多达六个时区。其中张铮老师指导的 Minerva 团队主要负责后端引擎，陈天奇进行接口设计，李沐负责分布式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在打造 MXNet 的过程中，团队成员在设计上进行了十分细致的思考和讨论。MXNet 使用 Mixture 设计，融合了其他一些主流框架的优点，例如其像 Tensor Flow 一样的 符号式编程（&lt;span&gt;symbolic&lt;/span&gt;），和 Torch 一样的 命令式编程（&lt;span&gt;imperative&lt;/span&gt;）；为了方便开发者使用，MXNet 支持多种语言接口，同时在底层预步了对 Caffe 和 Torch 等运算模块的兼容等等；在内存使用方面，MXNet 大胆使用了不同于一般的系统内存优化的设计，并取得了很好的效果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9oRHIwsRf98tOqUibGlXubaqh87cpYDiaE4NUo5s1nv2ViareCXstBSlvqgNHaRS1ib8wJYdufaMialbQ/0?wx_fmt=png"/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;经过一年的努力，MXNet 现身 2015 年 NIPS 的机器学习系统 Workshop。点击「阅读原文」查看相关论文。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2016 年，越来越多的开源贡献者参与到了开发及维护 MXNet 的工作中，对 MXNet 进行了大量的扩展、优化和修复工作。其中包括后期加入 DMLC，并逐渐成为核心成员，负责 rtc 和 torch 的解浚源（Eric），扛下 RNN 部分的 Chiyuan 和张宇，负责 R 接口的 Qiang Kou，Scala 接口的 Yizhi Liu，以及施新建等。截止到 2016 年 11 月中旬，MXNet 项目拥有超过两百名贡献者。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;亚马逊背书的开源深度学习框架&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在昨天亚马逊的表态之后，机器之心第一时间联系了 MXNet 项目的主要贡献者之一解浚源（Eric），请他谈论了一些对于这一消息和 MXNet 发展情况的一些见解。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9oRHIwsRf98tOqUibGlXubaKC3h3TX13mnpghgEynZ9FMIcM8HJy2CuGfM0v7k00fDPQrk2Uk3DUg/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;解浚源（Eric）是华盛顿大学正在就读计算机科学博士三年级的学生，正与 Ali Farhadi 和 Ross Girshick 共同进行研究工作。在此之前，解浚源于中国科技大学获得了计算机科学学士学位。研究兴趣是机器学习和计算机视觉，特别是发掘使用无标签或易于获得的「自然」标注的数据训练深度神经网络的新方法。解浚源目前是 MXNet 项目的主要贡献者之一，主要负责 rtc 和 torch 的部分。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;以下是机器之心对解浚源的专访内容整理（部分回答引用自知乎）：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;1）亚马逊选择 MXNet 作为其最主要的深度学习框架，这对于你们双方而言意味着什么？这件事是从什么时候开始计划的？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该问题的答案引用自知乎：&lt;span&gt;https://www.zhihu.com/question/52906838/answer/132582817&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Eric：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;MXNet 发展到现在有一年多了，已经是一个相对成熟的项目。我对我们的技术很有信心。MXNet 的速度，节省内存，接口灵活性，和分布式效率都是可圈可点的。作为一个由爱好者发起，没有投资的项目，MXNet 以前最大的短板是文档和宣传。而 Amazon 作为大财主以后在这方面可以起到很好的作用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;实际上 Amazon 对 MXNet 的支持已经有一段时间了，在 Github 上提交了很多文档方面的改进。细心的同学可能已经发现最近网站变好看了，拼写错误也少了很多（MXNet Documents），花钱请的前端和文案就是不一样。总体来说 Amazon 对开源社区很友好，除了对文档和稳定性的要求严格了一些并没有干涉我们的开发。Code Review 还是我们自己在做，是否接收代码也是社区决定的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 Amazon 之前已经有很多公司在默默的用 MXNet 了，只是没有大肆宣传。比如图森、地平线、搞 Mathematica 的 Wolfram 都给 MXNet 贡献了很多代码。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我对 MXNet 的前景很乐观，欢迎大家试用，也欢迎贡献代码，众人拾柴火焰高嘛，不知道从哪里下手的同学帮忙完善一下文档也是好的。有意全职做 MXNet 相关工作的可以联系我们，我们可以帮忙介绍美国 Amazon 以及北京、深圳各大机器学习 Startup 的工作:)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P.S. 这篇文章里关于分布式效率的细节比较少，GPU 也是 K80，比较老。但是我以节操担保线性加速的结果是靠谱的。我们自己在 Titan X 上用 resnet 也能跑出类似的效果。大家可以来试试。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;2）在今后的发展中，你怎么看待和 Caffe、CNTK、TensorFlow 以及 Torch 的竞争？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Eric: &lt;/span&gt;&lt;/strong&gt;&lt;span&gt;Caffe 有辉煌的历史，但是随着深度学习模型发展的越来越复杂，对灵活性要求越来越高，已经很难适应需求了。yangqing 吸取了 Caffe 的经验教训，已经开始在 Facebook 内部搞 Caffe2 了。Caffe 的用户应该会在未来 1 到 2 年内迁移到其它平台;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;CNTK 目前热度不高，但是微软在持续投入，最近刚加入了 Python 前端，未来怎么样还不好说。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;值得一提的是微软的 Azure 团队最近发了若干篇在 Windows 上用 MXNet 和 R 做深度学习的 blog。个人认为是因为 MXNet 对 Windows 和 R 都有完善的支持，用 Windows 的统计学家是微软的重要客户群。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;剩下的平台都有各自的特色，我认为未来会共存很长时间，很难实现一款平台统一所有市场&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Torch 比较像一个免费且原生支持 GPU 的 Matlab，在学术圈习惯 Matlab 或者不用 Python 的人群中很受欢迎。Torch 的封装少，简单直接，前期学习和开发时的思维难度都比较低。但是由于封装少和 Lua 本身的限制，工程性不好、容易乱写、代码可复用性差，导致 Torch 不适合做大项目的开发。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;TensorFlow 希望做一个大而全的机器学习框架，而不只满足于深度学习。我认为 TF 会沿着替代 sk-learn 的方向发展，会比较适合快速实现标准算法。但是大而全的负面因素就是代码量大、抽象层数多、代码冗余，对性能和可定制性都会带来负面影响。可能并不适合需要深度定制、对性能敏感的企业和做前沿研究的 research。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;MXNet 的方向是小而精、灵活高效。我们希望把核心深度学习的做到极致。MXNet 的代码量小，容易深度定制，同时支持 imperative（类似 Torch）和 declarative（类似 TF）两种 API，所以更灵活。另外 MXNet 的单机和分布式性能都是很好的。缺点是相对于 Torch 学习难度会大一些，另外以前没有资金支持，文档和宣传做的比较差。但是有了 Amazon 的支持，相信在这些方面会有大幅改善。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;3）可否为大家讲解一下 MXNet 是如何达到拔群的 scaling efficiency 的?&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Eric：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;MXNet 的并行化部分用了李沐的 pslite 进行通信，基于 zeromq，效率很高。另外 MXNet 基于依赖引擎（Dependency Engine）调度，每一层的梯度计算完毕后马上就可以开始传输，实现最优的 communication and computation overlapping。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;4）可以介绍一些基于 MXNet 的有趣应用吗？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Eric: &lt;/span&gt;&lt;/strong&gt;&lt;span&gt;MXNet 有 Fast/Faster RCNN 和 SSD 的实现样例，&lt;/span&gt;&lt;span&gt;另外还有一个用 DQN 玩 Flappy Bird 的例子，比较有趣：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="width: 528.195px; white-space: normal;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt; Fast/Faster RCNN&lt;/span&gt; 案例：&lt;/span&gt;&lt;span&gt;&lt;span&gt;https://&lt;/span&gt;&lt;/span&gt;&lt;span&gt;github.com/dmlc/mxnet/tree/master/example/rcnn&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt; SSD案例：&lt;/span&gt;&lt;span&gt;https://github.com/dmlc/mxnet/tree/master/example/ssd&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;DQN-Flappy Bird案例：&lt;/span&gt;&lt;/span&gt;&lt;span&gt;https://github.com/li-haoran/DRL-FlappyBird&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;5）MXNet 开源社区现在发展状况如何？说点什么呼吁人们参与到 MXNet 的开发和应用中来？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Eric:&lt;/span&gt;&lt;/strong&gt;&lt;span&gt; MXNet 的社区很活跃，我们已经有超过 200 个 contributor，包括很多公司的员工，以及学生和爱好者。MXNet 需要提升的主要是文档和教程。另外陈天奇正在研究运行时编译（RTC），不久后会发布，可以带来进一步的性能提升。近期我们会发布 0.9 版本，完成了后端到 nnvm 的迁移，以及很多新的 feature，比如一个用来调试性能的 profiler。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9oRHIwsRf98tOqUibGlXubaLysfblNeAKibI38dn9RouUf7Tx2qSMqYvXAEAZdviahEFT6mgpjBGNZQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心原创文章，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 24 Nov 2016 12:19:59 +0800</pubDate>
    </item>
    <item>
      <title>前沿 | 人工智能开始学习看漫画了，但仍然还赶不上人类</title>
      <link>http://www.iwgc.cn/link/3638670</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;机器之心原创&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;/span&gt;&lt;em&gt;&lt;span&gt;最近几年来，人工智能的能力是越来越强了，围棋、看图、听话、翻译、甚至艺术创作……这些原本被认为是人类的专属技能的领域已经出现了一些在一定程度上可与人类表现媲美的人工智能程序。人类不断地被超越常常会给人一种人类就要被人工智能取代的感觉；现在，一个研究团队终于给我们带来了安慰——至少在理解漫画上，人工智能还差得远！&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;近日，来自马里兰大学帕克分校和科罗拉多大学波德分校的 Mohit Iyyer 等研究者在 arXiv 上发表了一篇论文《The Amazing Mysteries of the Gutter: Drawing Inferences Between Panels in Comic Book Narratives》介绍了他们这一可以给人类增加信心的研究结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了了解人工智能理解漫画情节的能力如何，这些研究者首先构建了一个包含了超过 120 万张漫画画格（panel）数据集 COMICS，其中每张画格还配备有相应的文本对话框转录数据，这些加起来使得这个数据集的大小达到了 120 GB。据该论文介绍，因为版权方面的原因，这些数据集是由来自 20 世纪 30 年代到 50 年代的漫画作品构成的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;众所周知，漫画是由一系列的画格构成的，而且根据创作者的不同，不同的漫画之间的绘画风格、语言风格和排版风格之间都存在很大的差异。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9oRHIwsRf98tOqUibGlXubayvff1KUraxETia7qk6wJq2Eyz3lp2Ux2Jv7Da7Qm9W6ibfiaxXY6MT73A/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;不同绘画风格的狮子（有的更卡通更抽象，有的则更为写实），但它们都是狮子&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;想要理解它们，计算机需要非常具有概括性的思维方式。而且为了让读者能够看懂，漫画往往还带有形态各异的对话框，以通过文本来描述和推进情节（为了便于计算机处理，COMICS 数据集将这些对话提取成了与画格对应的文本形式）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而更重要的是，和视频不一样，漫画的不同画格之间的时间和空间是不连贯的，中间的过渡情节往往需要读者自己的想象。这种在我们人类看来自然而然的能力对计算机来说却是难于登天。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9oRHIwsRf98tOqUibGlXubaicEa9R6ytdwzSF1094CX4bsI53ugmribw6Fzp7Mt2FtBUmWV4YhvukBg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第三格里面的蛇是从哪里来的？为什么它突然出现咬着这个男人？这一格里面的男人和第一格里面的男人是同一个人吗？要回答这些问题，读者需要阅读其中的对话框以「闭合（closure）」这些画格。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;据介绍，这种将单张画格和之前的情节抽象地联系起来的过程叫做「闭合（closure）」。这些研究者用实际行动证明了这种能力目前仍然还是人类的专属技能。要对计算机的这种能力进行测试，研究者设计了让人工智能程序根据之前见过的画面预测下一个画格的实验。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先，机器必须要学习漫画的操作过程。所以研究小组将漫画中的一个画格及其文本投给不同的机器算法，让它们学习一组漫画中的每个画格之间是怎么相互连接的。这些机器已经预训练过识别自然界中对象，但是还没有训练过识别卡通对象。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9oRHIwsRf98tOqUibGlXubaY2IMktaMdo7vzTHqicdPK8yBPAGbMv3kKtbIrTcBlB8hQxLNTOTzFjQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;来自 COMICS 的 5 个样本画格序列以及其在 COMICS 数据集中所占的比重，其中每一个都有一种不同画格之间的转换方式。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有了这些训练过的机器后，研究小组用一组机器之前没见过的漫画（包含好几个画格）测试了它们，并且要求它们预测下一张图像或者后面的一系列文本内容。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9oRHIwsRf98tOqUibGlXubagH0UiaaP24XR3oCCNuh92fU4v6fFLicNHmqL916lxTtHGRlrjnEy5cAw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在神经架构中结合图像和文本可以提升它们在 COMICS 故事中识别下一张图像或对话的能力。之前画格所呈现出的语境信息对所有任务都是有用的：只查看单张画格（NC-image-text）的模型的表现总是不及了解语境的模型。但是，即使表现最好的模型也还赶不上人类（Human）。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从结果我们可以看到，人类预测漫画情节或内容的正确率可以达到 80%，但是机器却很难做到。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当然，这倒没什么非常让人惊讶的。机器学习尽管近段时间以来已经在图像和文本模式识别上取得了相当优异的表现，但仍旧缺乏人类大脑所具有的常识和逻辑——而这些都是叙事性故事所必需的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以人类还能留有一点讲故事能力的保留地。但是这种保留地还能维持多久呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;据了解，COMICS 数据集正在准备开源的过程中，开源后将会发布在 GitHub 上：&lt;span&gt;https://github.com/miyyer/comics&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;以下是该研究论文的摘要介绍：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;论文：The Amazing Mysteries of the Gutter: Drawing Inferences Between Panels in Comic Book Narratives&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：视觉叙事（visual narrative）通常需要结合明确的信息和明智的遗漏，并依赖观看者来补充缺失的信息。在漫画中，大多数时间和空间的运动都隐藏在画格（panel）之间的「天沟（gutter）」之中。为了理解故事，读者需要通过逻辑将画格联系到一起，通过一个叫做「闭合（closure）」的过程将未见过的动作推理出来。现在计算机已经能够描述自然图像的内容了，在这篇论文中，我们将检验它们是否能够理解由漫画书画格中风格化的艺术作品和对话所传递的闭合驱动的叙事（closure-driven narrative）。我们收集了一个数据集 COMICS，其包含了超过 120 万张画格（120 GB），这些画格都匹配了自动文本框转录。对 COMICS 的一次深度分析表明，文本和图像都无法单独讲清一个漫画故事，所以计算机必须理解这两种形式才能跟得上情节。我们引入了三个填空式的任务，这些任务要求模型在被给出了 n 张之前的画格作为背景的情况下，预测一个画格的叙事和以角色为中心的一些方面。多种神经网络架构在这些任务上的表现都不及人类基准，这表明 COMICS 同时包含了视觉和语言上的基本挑战。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9oRHIwsRf98tOqUibGlXubax6f2icw1Xd7GOlicHpW6sHhpZgv9YZia6icbaok7C8ItEXD2SIaMp3zbDQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;应用于一个文本填空任务实例的图像-文本架构（image-text architecture）。预训练的图像特征与学习到的文本特征在一个分层的 LSTM 架构中结合起来构建出一个语境表征（context representation），然后该表征被用于评估候选文本。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心原创文章，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 24 Nov 2016 12:19:59 +0800</pubDate>
    </item>
    <item>
      <title>「硅谷奥斯卡」10 周年，唯一入围的中国公司是它？</title>
      <link>http://www.iwgc.cn/link/3638671</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;年末将近，美国科技博客 TechCrunch 又启动了一年一度「创业与科技奥斯卡」盛典，即年度 Crunchies 大奖的评选。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9hic1eAGtMvOApzjmnJXwDGSPLd3NRdXpmoyXwYRZ4UZnuV9qtbH2HXvibocibgorCkqfiaWk2rmdGiaQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对硅谷来说，毫无疑问这是「万众期待」的时刻。Crunchies 大奖评选每年最热门的创业公司，以及互联网和科技创新。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;往年的获奖者包括当前的许多硅谷科技巨头。例如，2012 年的获奖者就有 Airbnb、Snapchat、谷歌地图等公司和产品，而获奖人物则包括 Facebook CEO 马克·扎克伯格、在今年美国大选中备受关注的风投、《从 0 到 1》的作者彼得·蒂尔，以及 Instagram 创始人凯文·希斯特罗姆。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9hic1eAGtMvOApzjmnJXwDGuXJeJxSK2omNSzAIu29mQBtN4wSwicBrERyxiaGLk3THhhkwkst1HaLw/0?wx_fmt=png"/&gt;&lt;br/&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今年的 Crunchies 大奖还有着特殊意义：盛典 10 周年。换句话说，这一奖项在瞬息万变的科技行业拥有绝对「悠久」的历史。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在评选过程中，读者提名本年度最火爆的产品、人物和公司，TechCrunch 编辑们会根据提名来评选最终入围者。入围者的信息将被提供给由知名风投、创业者、TechCrunch 记者和科技行业意见领袖组成的 Crunchies 委员会。为了保证公平性，TechCrunch 甚至邀请了律师事务所 Perkins Cole 来对评选过程进行监督。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Crunchies 大奖的奖杯也很有趣。奖杯为 14 英寸（35.6 厘米）高，采用硬度很高的塑料来制作，灵感来自于《2001 太空漫游》。在这部电影中，史前猿人部落周围出现了黑色大石块。这给其中一个猿人带来了灵感，创造了最初的科技：作为工具和武器的骨头。这一奖杯就象征着人类对科技「从 0 到 1」的探索。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9hic1eAGtMvOApzjmnJXwDGOdxALxuzvHpFnQOZicU2SYGpxU8cSOEGIzZdlnL0Zh4rNybNj7l8EkQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;TechCrunch 此次共设置了 11 个奖项，其中包括最佳移动应用、最佳创业公司视频、年度创业者和最深刻社会影响力等等。用 TechCrunch 的说法，这样做是为了保证包容性，将更多人物和公司覆盖在内，打造一个全行业的庆典。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今年的 Crunchies 大奖已进入最终评选阶段，每个奖项都有 5 家公司入围。颁奖典礼将于 2017 年 2 月 6 日举行，地点则是在旧金山的战争纪念歌剧院。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;作为科技创业公司盛典，年度最佳创业公司一直是 Crunchies 大奖的重头戏。如果 Crunchies 被称作创业奥斯卡，那么年度最佳创业公司就是奥斯卡最佳电影。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在今年的年度最佳创业公司评选中，滴滴不仅入围最终五强，目前还暂时排名第一。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;TechCrunch 附属的 CrunchBase 对滴滴介绍如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;创立于 2012 年，滴滴是全球最大的移动出行服务平台，在中国的 400 多座城市提供了基于移动技术的广泛的交通出行选项，包括出租车、注册、顺风车、代价、巴士、试驾和企业解决方案。作为中国分享经济的领先者，滴滴平台 2015 年完成了 14.3 亿次出行订单。滴滴利用大数据能力解决了中国的交通出行和环境挑战。2016 年 2 月，滴滴成为了全球第二大在线交易平台，仅次于阿里巴巴。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前排名滴滴之后的公司分别为 Giphy、Slack、SpaceX 和 Stripe。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Giphy 是美国极为火爆的 GIF 动图服务，有着「GIF 届谷歌」之称。本月，Giphy 完成了最新一轮 7200 万美元融资，参投者甚至包括来自中国的华人文化产业投资基金。根据《华尔街日报》报道，Giphy 的投后估值达到了 6 亿美元。目前，Giphy 已发展出了一整套 GIF 产品线，包括视频转 GIF、GIF 搜索、GIF 键盘、表情包、动图制作、动图影视剧，以及帮助媒体公司将内容转换为 GIF 的企业工具。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最新数据显示，Giphy 的 GIF 动画每天被超过 1 亿用户查看，而通过搜索引擎、应用，以及与维亚康姆、迪士尼和美国职棒大联盟 MLB 的合作，该公司每天提供的 GIF 动画高达 10 亿张。今年美国总统大选的双方都用 Giphy 制作了诋毁对手的表情包。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Slack 与 Giphy 完全相反，是一款主打企业市场的即时通讯工具，在硅谷企业内备受欢迎。也有人认为，这就是硅谷版钉钉。去年底就有传闻称，阿里巴巴计划收购 Slack，将 Slack 与钉钉整合。Slack 最新的估值已达到了 38 亿美元。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;大名鼎鼎的 SpaceX 可能不需要太多介绍。作为民营航天事业的先驱，SpaceX 今年上半年完成了航天史上的创举，即火箭的发射后回收。预计这将极大地降低人类太空旅行的成本。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然而，SpaceX 今年 9 月发生了「猎鹰 9 号」火箭在发射架上的起火事故，导致了火箭和卫星损毁，发射架的损坏。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前，SpaceX 正从这起事故中恢复，预计将很快重启火箭发射。毕竟，SpaceX 已经积压了约 70 次发射任务, 价值超过 100 亿美元。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后一家入围者 Stripe 提供移动支付服务。该公司为企业简化数字结算过程，其支付方式支持客户订制，并可以立即在网站或应用中使用。Stripe 的零售合作伙伴包括百思买和梅西百货等零售巨头。最新数据显示，Stripe 的年交易额已达 10 亿美元量级，使用该公司服务的有超过 10 万家客户。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Crunchies 大奖此次设置的 11 个奖项共有 55 家入围者。值得关注的是，大部分入围者都来自美国，甚至硅谷本地，而滴滴则是唯一入围的中国公司、亚洲公司。看起来，滴滴将成为中国科技行业新势力在「硅谷奥斯卡」中的代表。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前距离 Crunchies 大奖的颁奖还有 75 天。在这个「硅谷奥斯卡」的舞台上，中国公司将会有什么样的表现令人拭目以待。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 24 Nov 2016 12:19:59 +0800</pubDate>
    </item>
    <item>
      <title>创意 | 意念控制特斯拉，美国黑客新玩法</title>
      <link>http://www.iwgc.cn/link/3638672</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自LiveScience&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李泽南&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;em style="color: rgb(136, 136, 136);"&gt;&lt;span&gt;加州黑客最近有了新玩具，使用 EEG 头盔接收驾驶员大脑中信号，并通过机器学习训练程序将大脑的活动识别为准确的命令，实现了科幻电影中的意念开车。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;iframe class="video_iframe" data-vidtype="1" style="   z-index:1; " height="375" width="500" frameborder="0" data-src="https://v.qq.com/iframe/preview.html?width=500&amp;amp;height=375&amp;amp;auto=0&amp;amp;vid=s0349wjeg0v" allowfullscreen=""&gt;&lt;/iframe&gt;&lt;br/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这辆特斯拉 Model S 只走了几十英尺，从停车场的一个车位开到另一车位。然而司机却并没有坐在方向盘后，他坐在副驾驶位置上，头戴 EEG 头盔，这套名为 Teslapathic 的设备可以让他用意念控制汽车，让我们来看看其中的奥秘吧。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这项新发明是由加州四位黑客 Casey Spencer，Lorenzo Caoile，Vivek Vinodh 和 Abenezer Mamo 共同打造的。这个团队将 Spencer 自己的 2015 款特斯拉 Model S 85D 轿车改造成为「意念驾驶汽车」，这也是本月 Cal Hacks 活动的一个参选项目。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Teslapathic 项目只用了 36 个小时就宣告完成。这个团队宣称，他们使用 EEG 头盔接收驾驶员大脑中「停止」或「加速」的信号，通过机器学习训练程序将大脑的活动识别为准确的命令，采用 k-nearest neighbors 算法来减少信号噪声。确定驾驶者的意图后，系统再将命令通过 Arduino 转换为模拟 PPM 信号，用标准 RC 无线电设备控制连接油门/刹车踏板上的铰链马达机构，另一个电机则控制方向盘。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9oRHIwsRf98tOqUibGlXubao3IBs2NCmpsTibwjC8yDrib2P1gia41jp0JIg32xYxBsSFn1pFIamdsfQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在希望「加速」时，Spencer 想象自己右脚踩油门踏板；希望「刹车」时，他想象自己紧握自己的左手。在获得「加速」指令后，线性致动器踩下油门，收回刹车；而「刹车」命令则相反。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;汽车转向的控制方式则相对有点笨拙，并不是通过意念实现的。项目组通过在方向盘上安装的汽车雨刮器电机实现转向，通过驾驶员的头戴式陀螺仪进行控制，当 Spencer 向左或向右转动头部的时候，方向盘会做出及时响应。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了安全起见，这套设备的程序代码中包含了紧急停止机制，驾驶者持有一个「红色按钮」，可以发出信号启动刹车踏板旁的额外电机，防止轿车开得太快。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前看来，这辆特斯拉还不能准确行驶在道路的正中间，如果 Spencer 不努力地想象，刹车踏板也不会踩到足够深，但这个小组充满创意性的尝试为人们打开了新的思路。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这并不是 Spencer 使用意念汽车的第一次尝试。在去年，他的小组已经可以成功控制一辆高尔夫球车了，他把当时的作品命名为「Cranium Cart」。玩坏一辆高尔夫球车与价值 8 万 5 千美元的特斯拉并不能相提并论，但 Spencer 对自己的技术很有信心，他也乐意用这个作品参加特斯拉的车主引荐奖励计划。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 2015 年 9 月，Spencer 成为了第一个打破 500 英里距离电动车一次充电里程的人，在那次距离挑战中，他以每小时 21 英里的速度横穿了整个加州。而在今年早些时候，他的特斯拉汽车在另一次挑战中战胜了一辆 2015 款宝马 M4。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9oRHIwsRf98tOqUibGlXubaxlhSyPanBn6AGq6V1SBP1QQgicMe2h7MAklrdGXg6ZAIgiaibaVeAKyfg/0?wx_fmt=png"/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「Teslapathic 的效率还很低。」Spencer 说道。机器学习算法已经可以理解大脑中的简单命令，但竞赛的时间限制没有让所有细节做得更好。在未来，他希望能够让这套设备能够接收更为复杂的指令，处理更多类型的任务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译文章，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 24 Nov 2016 12:19:59 +0800</pubDate>
    </item>
    <item>
      <title>活动 | 中国AI产业大会12月16日举行：这里有你要的未来</title>
      <link>http://www.iwgc.cn/link/3638673</link>
      <description>&lt;p&gt;&lt;span&gt;由中国人工智能学会主办，网易科技和智能君博联合承办、机器之心协办的 2016 中国人工智能产业大会暨第六届吴文俊人工智能科学技术奖颁奖盛典将于 12 月 16 日-17 日在深圳举行。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9hic1eAGtMvOApzjmnJXwDGZS8dbc5CG5fepXapRC7RfWsFQzhEgicDWmYvBiaqcrEiaicTpqffHxWmiaw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本次大会以「AI 新时代·产业新动能」为主题，聚焦人工智能在从学术、技术，到产业、应用的链条发展，展望人工智能在 2017 年给行业应用带来的聚变反应。大会将邀请国家有关部委领导、中国 AI 学术界顶级科学家、科技巨头研究院专家、中国顶级投资人、最优秀的 AI 创业公司出席大会，共同讨论人工智能 2017 年产业发展的风向标。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;会议时间：2016 年 12 月 16 日下午-17 日&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;会议地点：深圳·登喜路国际大酒店&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;报名链接：http://www.huodongxing.com/event/1360824768100（&lt;span&gt;点击阅读原文报名&lt;/span&gt;）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;拟邀嘉宾：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;中国工程院院士、中国人工智能学会理事长 李德毅&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;中国工程院院士、香港中文大学（深圳）校长 徐扬生&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;中国人工智能学会副理事长、香港科技大学教授 杨强&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;清华大学智能技术与系统国家重点实验室常务副主任 孙富春&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;浙江大学校长 吴朝晖&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;网易公司创始人兼 CEO 丁磊&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;京东集团 CTO 张晨&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;华为诺亚方舟实验室主任 李航&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;北极光创投创始人 邓锋&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;联想之星合伙人 刘维&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;峰瑞资本创始合伙人 李丰&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;英特尔中国研究院院长 宋继强&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;IBM 中国研究院研究总监 苏中&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;联想集团副总裁 芮勇&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;碳云智能创始人兼 CEO 王俊&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;思必驰首席科学家 俞凯&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;商汤科技 CEO 徐立&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;驭势科技联合创始人兼 CEO 吴甘沙&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第四范式创始人 戴文渊&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;更多嘉宾大咖持续邀请中（议程将在 12 月 1 日发布）...&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;会议亮点：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 国家有关部门领导、资深院士解读人工智能政策取向&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 近百位 AI 高校专家共话 AI 技术创新与产业崛起（包括虚拟现实、无人驾驶、模式识别、深度学习、智能机器人、大数据和智能制造等）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3. 顶级投资人商讨 2017 年人工智能的投资与应用&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4. 中国最热 AI 创业公司创始人分享&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;5. 探讨深圳在人工智能技术支撑下的产业集聚与转型升级&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;6. 吴文俊人工智能科学技术奖新闻发布会与颁奖典礼&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;7. 发布全球首款机器人大脑（云+端）开放平台&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;8.500 平米展区，观看最优秀的人工智能应用和最酷炫的机器人表演&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;票务说明：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;普通门票：680 元（12 月 1 日前 7.3 折，12 月 6 日前 8.8 折，可参加 16-17 日所有会议日程，预留会场前排座位，不含午晚餐）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;VIP 门票：2888 元（包含 16-17 日所有会议日程、午晚餐，与演讲嘉宾同区的前排座位及姓名桌签，提供专人接待引导服务，附送精编限量版获奖论文册）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2016 年，人工智能成为科技领域中最热门话题。在纪念世界人工智能 60 年同时，展望 2017 年，人工智能正在像互联网变得无处不在。在全行业的布局之下，人工智能会成就下一个互联网时代吗？语音助手会抢占秘书的工作吗？自动驾驶什么时候才能商业化？强人工智能时代何时来临？机器人会不会统治世界？学术界、科技巨头、投资界、明星创业公司，他们会擦出怎样的火花？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;12 月 16 日至 17 日，深圳登喜路国际大酒店，中国人工智能产业大会将揭开谜底。中国人工智能学会、网易科技、智能君博、机器之心、深圳大学等机构邀您共同见证！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;组织机构：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;主办单位：中国人工智能学会&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;承办单位：网易科技、智能君博&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;协办单位：机器之心、深圳大学、中国科学院深圳先进技术研究院、广东华中科技大学工业技术研究院&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;支持单位：北京大学深圳研究生院、清华大学深圳研究生院、哈尔滨工业大学 (深圳)、南方科技大学、香港中文大学（深圳）、香港城市大学深圳研究院、深圳信息职业技术学院、深圳市机器人协会&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 24 Nov 2016 12:19:59 +0800</pubDate>
    </item>
    <item>
      <title>重磅 | 巨头之间的深度学习框架战争：亚马逊选中MXNet</title>
      <link>http://www.iwgc.cn/link/3621484</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自allthingsdistributed.com&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Werner Vogels&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀、李泽南&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9hic1eAGtMvOApzjmnJXwDGm5kibo05lapL1XDllciav4QCibEKlUcmdOrozbCSjJg2HwOhHbGFibJkiaA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Werner Voegls，亚马逊副总裁，CTO&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;随着人工智能的发展，现代科技公司的目标变成了打造不需要人类干预就能执行任务的人工智能软件。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了这一目标，Amazon Web Services（AWS）选中了 MXNet 作为其最主要的深度学习框架，亚马逊首席技术官 Werner Vogels 昨日在一篇博客文章中透露了亚马逊的这一选择。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;Vogels 说 AWS 将会为 MXNet 和该公司所支持的生态系统的开发提供软件代码、文档和投资。尽管他也提到该公司也已经支持了其它深度学习框架（包括 Caffe、CNTK、TensorFlow 和 Torch），但看起来亚马逊将开始主要为 MXNet 站台了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;TensorFlow 和 CNTK 框架是分别由亚马逊的竞争对手谷歌和微软发展起来的。Caffe 来自加州大学伯克利分校的伯克利人工智能研究实验室（Berkeley Artificial Intelligence Research Lab）。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下一周，亚马逊就要举行其年度 AWS re:Invent 大会了，此时 MXNet 的消息出来，说明亚马逊的高管有望在这次大会上谈论人工智能的机会以及将支持亚马逊的 Alexa 个人助理开放给 AWS 开发者。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器之心曾经发表过一篇 MXNet 的作者之一李沐的专栏文章&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720536&amp;amp;idx=3&amp;amp;sn=257021a323ad878178edd28259ce07ec&amp;amp;chksm=871b0d66b06c847088cef5bc824f457336a157d3de5d85d72fbf4ce6b0cb2d369d219b8a28cf&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720536&amp;amp;idx=3&amp;amp;sn=257021a323ad878178edd28259ce07ec&amp;amp;chksm=871b0d66b06c847088cef5bc824f457336a157d3de5d85d72fbf4ce6b0cb2d369d219b8a28cf&amp;amp;scene=21#wechat_redirect"&gt;《为什么强大的 MXNet 一直火不起来？》&lt;/a&gt;，谈论了 MXNet 的现状；也曾发过讨论 MXNet 的优势和应用的文章（如&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718160&amp;amp;idx=3&amp;amp;sn=a2114e3324f28740d2603da26fbbdfb4&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718160&amp;amp;idx=3&amp;amp;sn=a2114e3324f28740d2603da26fbbdfb4&amp;amp;scene=21#wechat_redirect"&gt;《五大主流深度学习框架比较分析：MXNET 是最好选择》&lt;/a&gt;和&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719529&amp;amp;idx=3&amp;amp;sn=6992a6067c79349583762cb28eecda89&amp;amp;chksm=871b0157b06c8841587bdfb992c19290c8d66386a6f8accdf70998ce3f86b36330219c09672d&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719529&amp;amp;idx=3&amp;amp;sn=6992a6067c79349583762cb28eecda89&amp;amp;chksm=871b0157b06c8841587bdfb992c19290c8d66386a6f8accdf70998ce3f86b36330219c09672d&amp;amp;scene=21#wechat_redirect"&gt;《MXNet 专栏 | 陈天奇：NNVM 打造模块化深度学习系统》&lt;/a&gt;，现在我们终于可以说：MXNet 火起来了！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;下面是亚马逊首席技术官 Werner Vogels 宣布此消息的博客文章内容：&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器学习正在我们的商业和生活中的许多领域发挥越来越重要的作用，并且已经被部署到了许多无法编程出明确的算法的计算任务中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在亚马逊，机器学习已经成为了我们许多业务流程的关键：从推荐系统到欺诈检测、从库存水平到书籍分类再到检测恶意的评论。除此之外，我们还有更多广泛地使用了机器学习的应用领域：搜索、自动无人机、订单履行中心的机器人、文本和语音识别等等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在各种机器学习算法中，一种被称为深度学习的算法已经成为了机器学习的代表，这种算法可以吸收大量数据并学习数据中优雅的有用的模式：照片中的脸、文本的含义或口头话语的意图。在帮助开发者使用深度学习定义和训练人工智能模型方面已经出现了很多编程模型；另外也出现了很多将深度学习提供给普通开发者的开源框架。其中我们在 AWS 上所支持的流行深度学习框架有：Caffe、CNTK、MXNet、TensorFlow、Theano 和 Torch。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在所有这些流行的框架中，我们的结论是 MXNet 是最具扩展性的框架。我们相信为 MXNet 投入更多努力能够使人工智能社区获益。今天，我们宣布将成为我们的深度学习框架选择。AWS 将继续提供代码和改进文档，并且投资围绕 MXNet 的生态系统。我们也将会与其它组织合作来进一步改进 MXNet。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;AWS 和对深度学习框架的支持&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 AWS，我们相信应该给我们的客户提供选择。我们的目标是通过提供正确的实例、软件（AMI）和托管服务来为我们的客户提供符合他们选择的工具、系统和软件。正如在 Amazon RDS 中一样——其中我们支持多种开源引擎，包括 MySQL、PostgreSQL 和 MariaDB，在深度学习框架领域，我们也将通过为客户提供做好的 EC2 实例集和合适的软件工具来支持所有流行的深度学习框架。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Amazon EC2 有广泛的实例类型（instance types）和带有大量内存的 GPU，它已经变成了深度学习训练的重心。为此，我们最近开放了一系列工具以便用户能尽可能轻松地上手；这个工具是 Deep Learning AMI ，其预安装了上面所提到的开源深度学习框架；通过 CUDA（已经安装和预配置）的 GPU 加速；并支持 Anaconda 和 Jupyter 这样的工具。开发者也可以通过这个 AMI 使用分布式深度学习 CloudFormation 模板来使用向外扩展的弹性的 P2 实例集群以运行更大型的训练。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;亚马逊和 AWS 一直关注深度学习，并致力于提供多种工具用于技术研发，我们将持续在可用性，可扩展性和功能方面改进所有这些框架。MXNet 是这些计划的中心。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;选择一个深度学习框架&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;开发人员，数据科学家和研究人员在选择深度学习框架时主要考虑三个主要因素：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;规模化多重 GPU 能力（通过多个主机）来通过更大与复杂的数据集训练巨大且更复杂的模型。深度学习模型能用数天或数周来训练，所以甚至这一块只是一点点提升也会造成在新模型的发展和评估速度上巨大的加强。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;发展速度和可编程性，特别是有机会使用他们已经熟悉的计算机语言时，他们能够非常迅速地建造新的并更新现有的模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;大范围内设备和平台的可移植性，因为深度学习模型需要在很多不同的的地方运行：从笔记本电脑和能通过大型网络互联和大量的计算能力服务器群，到通常是连接相距甚远设备的移动通讯工具，这些将更少依赖网络互联和相当少的计算力。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于 AWS 的开发者和很多我们的客户而言，有三件事同样重要。经过慎重地评估，我们选择 MXNet 作为亚马逊的深度学习框架，我们计划在现有和即将推出的新服务中广泛使用它。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们已经开展了一系列工作，作为承诺的一部分，我们将通过贡献代码（已经做了很多工作）积极地促进和支持开源，改进在线和 AWS 的开发人员体验和帮助文档，并持续改进可视化、开发环境，帮助开发者更方便地从其他框架迁移进来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;MXNet 介绍&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;MXNet 是一个全功能，灵活可编程和高扩展性的深度学习框架，支持深度学习模型中的最先进技术，包括卷积神经网络（CNN）和长期短期记忆网络（LSTM）。MXNet 由学术界发起，包括数个顶尖大学的研究人员的贡献，这些机构包括华盛顿大学和卡内基梅隆大学。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「MXNet 是在卡内基梅隆大学中诞生的，它是我所看到的最完美的深度学习可扩展框架，它可以让计算机科学更加美好。让不同学科，不同工作的人们团结在一起。我们对亚马逊选择 MXNet 感到兴奋，MXNet 将由此变得更加强大。」卡内基梅隆大学计算机科学系主任 Andrew Moore 说道。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;MXNet 缩放&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;深度学习框架在多核心处理器中的运行效率是其性能的重要指标。更高效的缩放（Scaling）可以让训练新模型的速度显著提高，或在相同的训练时间内大幅提高模型的复杂性。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这正是 MXNet 的优势：我们正在使用越来越多的 GPU 训练图像分析算法 Inception v3（在 MXNet 中实现并在 P2 实例上运行）。MXNet 不仅具有所有已知库中最快的吞吐量（每秒训练的图像数量），而且吞吐量提高几乎与用于训练的 GPU 数量成正比（比例为 85 ％）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9hic1eAGtMvOApzjmnJXwDGPo2MKwjcjWerhgasnGhibBGich6OZicZjbZCCicRHJH7B4x6u64DMEuVdg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;用 MXNet 进行开发&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除了高可扩展性，MXNet 还提供混合编程模型（命令式和声明式），同时兼容多种编程语言（包括 Python、C ++、R、Scala、Julia、Matlab 和 JavaScript）的代码。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;MXNet 中的高效模型和可移植性&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;计算效率很重要（并且与可扩展性紧密相关），但是内存使用量也同样重要。在运行多达 1000 层的深层网络任务时，MXNet 只需消耗 4GB 的内存。它还可以跨平台移植，并且核心库（具有完整功能）可以整合进单个 C ++源文件中，并为 Android 和 iOS 进行编译。你甚至可以使用 JavaScript 扩展在浏览器中运行它。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;更多内容&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有关 MXNet 的更多细节可以关注 MXNet 主页，或 GitHub 以获得更多信息，你可以立即使用 Deep Learning AMI，或在你自己的设备中进行开发。亚马逊将在 11 月 30 日于拉斯维加斯 Mirage 酒店举办机器学习「State of the Union」会议，随后也会在 AWS re:Invent 中开展有关 MXNet 的研讨会。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;MXNet 主页：http://mxnet.io/&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;GitHub 地址：https://github.com/dmlc/mxnet&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Deep Learning AMI：https://aws.amazon.com/marketplace/pp/B01M0AXXQB&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译文章，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 23 Nov 2016 10:48:57 +0800</pubDate>
    </item>
    <item>
      <title>业界 | DeepMind与NHS再度合作：5年内建成全新人工智能临床信息系统</title>
      <link>http://www.iwgc.cn/link/3621485</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自DeepMind&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：杜夏德、朱思颖&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们很高兴地宣布与伦敦皇家自由 NHS 信托基金（Royal Free London NHS Foundation Trust）达成 5 年合作伙伴计划。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;NHS 的医生与护士把病人照顾的很好，但是他们对现在的技术很失望。大多数 NHS 医院的寻呼机、传真机和纸上的记录仍然是统一标准化的，自上而下的 IT 系统过于频繁，不能满足临床需要，因为这些东西一开始就不是为方便照顾病人而建立起来的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9hic1eAGtMvOApzjmnJXwDGCqZorvdnvVYTlff9oicoBCz6HHEL4PG1JpKCXNiapia8zKp18dZjxSEAA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些过时的技术说明，病人病情的重大变化通常无法及时达到其主治的临床医生那里，导致病情恶化，后果可能很严重，甚至是致命的。只要能及时找到对的医生采取正确的措施，英国医院每年至少有 10000 名患者死于完全可预防的事故，以及大约 40% 的病人可以避免进入重症监护式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们合作的目标是改变这个现状，以全新的思路建立新的病人护理 IT 系统。我们将携手创造世界领先的技术，与临床医生紧密合作，确保病人的信息能及时送到对的医生手中，减少可预防的死亡和病情恶化。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此前我们已经成功的合作了一个为期一年的项目，此次的五年合作关系将建立在这个成功的项目基础上。我们将开发一款名为 Stream 的智能手机 App，它能以最快的速度提醒医生病人急性肾损伤的测试结果，为他们提供必要的临床参考信息，帮助他们在病人病情恶化之前给出恰当的治疗方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;经过样机测试与英国药品与保健品管理局的注册后，第一版的 Stream 即将在 2017 年进入皇家自由医院的临床使用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;未来五年的合作中，我们会将 Stream 拓展的其他疾病诊断和治疗中，尤其是那种越早治疗效果越好的病。我们认为 Stream 可以帮助病人预防脓毒症以及引起器官衰竭的其他并发症，这些病情恶化的症状很难由医生检查出来，而早期干预的结果可能就是生与死的差别。我们还将计划满足皇家自由医院的医生一直在要求的一些功能，包括即时讯息和临床任务管理，这些功能都能提升医疗护理效率。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9hic1eAGtMvOApzjmnJXwDG65g5icH7DuLNHNd30nulB72AF69TFut13yYOFYgQOw6wBVnYJggtvyw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当这个系统完全建好时，我们相信在紧急情况下，可以将通知医生的时间从几小时缩短的几秒。把医生从同时处理多个呼叫器、桌面和纸质记录的繁琐系统中解放出来，节省了大量时间。有了这个系统，每年大概可以从管理上节省出一百万个小时，让治疗变的更加直接。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这项合作将会让数据完全和审计达到一个前所未有的水平。所有的数据接口都可以登录。我们的软件和数据中心将会经过我们委托的独立专家的深度技术审计。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此外，我们正在研发一个前所未有的新型基础架构，支持皇家自由信托的审核工作接入，从而让管理人员简便且持久的核实病人的信息，在何时何地因何缘由被谁查看。这个功能模块是目前世界上最好的信息安全工程师之一——Ben Laurie 所构建的。Ben 也是 OpenSSL 项目的联合创始人，其联合创立的 OpenSSL 项目提供网站链接的加密服务（与大部分链接地址加锁的功能类似）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;并且这个基础架构能够让 Streams 的运行更加流畅，毋庸置疑的是这个框架将会是一个可互动性操作架构的行业标杆。基础架构建成之后，对新服务功能的添加完全是支持的，并且对新功能的添加很友好。如此一来，对于那些初次接触 NHS 的开发人员来说，将会大大减少开发面临的阻力。同时也掀起了一股创新的浪潮，为第一个 AI 植入的应用工具提供无限的后序开发空间，无论那些开发是来自 DeepMind 还是其他开发者。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;DeepMind 的建立初衷就是为了解决既存的社会难题。对 DeepMind 来说，当前没有比通过这项创新技术来改革 NHS 带给社会更具实质性影响的方式了。我们会实时更新与皇家自由信托的合作进展，将会有进一步的新闻，请持续保持关注。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译文章，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 23 Nov 2016 10:48:57 +0800</pubDate>
    </item>
    <item>
      <title>MXNet专栏 | 李沐：深度学习·炼丹入门</title>
      <link>http://www.iwgc.cn/link/3621486</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心授权转载&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：李沐&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;几日前，机器之心经授权发表了李沐在知乎上回答的为什么 MXNet 不火的一篇文章。最近，他又写了一篇关于深度学习入门的文章，用诙谐的语言（对比炼丹）讲解深度学习。此外，在本文中李沐也提到自己现在到了亚马逊，要大力发展 MXNet 了，这是不是意味着几大深度学习框架的格局再起变化呢？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;作者：李沐&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：https://zhuanlan.zhihu.com/p/23781756&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;来源：知乎&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所谓炼丹，就是将大量灵材使用丹炉将其凝炼成丹。练成的灵丹蕴含灵材的大部分特性，方便携带，容易吸收。高级仙丹在炼制中更是能吸收天地灵气从而引发天地异象。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;深度学习的模型训练就是炼丹。把精选原始数据，按照神经网络的规定法则通过计算框架提炼，从而得到一个远小于数据数倍的模型。一个好的模型不仅能抓取数据中的模式，更是能提取更加一般化规则从而可以用来预测新的数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然有人会指出机器学习的模型训练也是一个类似的过程，但深度学习丹师对此是不屑的，他们认为训练「浅」模型的人最多算是老中医。因为经过了多年探索，传统机器学习模型已经解析得比较透彻，有着完整的一套理论，原材料种类趋向于固定，药方相对简单，对药罐要求也不高。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但深度学习更加神奇。灵材各式各样，可以自由组合。单方也是千奇百怪，比中药方复杂数百倍。对丹炉要求苛刻，而炼制手法更是各种出其不意。整个一套流程并没有太多理论可依循，主要是靠炼丹者对天地灵气和规则的感悟。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;随着一颗一颗各式灵丹的练出，整个修仙界已经为此疯狂。本文简要的介绍深度学习炼丹的方方面面，并对丹界新人的修仙之路提供几点微小的建议。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;炼丹简史&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;炼丹这一门在修真界存在已久。上次辉煌发生在上世纪 80，90 年代。笔者本科导师曾回忆，他参加过一次鼎盛时期的炼丹大会，场地在海边一字排开，连绵几百米。那次会有数万人参加。但现在连名字大家都不怎么记得了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;炼丹门的上一次衰退有多个原因。一个是 kernel 派的入侵，他们凭着一招无穷升维打得炼丹门措手不急。一方面上手容易，修炼不需要感受天地元气，另一方面又有一套从史前数学界偷来的泛函心法，老少皆宜。接踵而来的都是统计学习流，凸优化流，图模型流，他们凭着从数学界那里搬来的各式外门功夫迅速占领了修真界。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;炼丹门因为入门困难，操作复杂，于是人员凋落，门内坚守最后的几大长老纷纷躲在极寒之地加拿大过冬。那段时期大家只要一听到「炼丹」纷纷脸色一变绕道而行。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但数年前，炼丹门大长老的得意弟子凭借一张 AlexNet 丹方在修仙界大擂台 Imagenet 竞赛上一举夺魁。随后炼丹界突破不断，全民炼丹拉开了帷幕。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;炼丹门的复苏离不开方方面面的改进。下面列举主要的几个：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;灵材&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;整个修真界都是围绕着灵材展开，这是修仙最基本素材。一份炼丹灵材通常不止有多类灵材，例如 MNIST 有 10 类，ImageNet 则有上千类。每类中通常有数个同类但各式属性稍有不同的个体。高端的丹药可能需要多种差异颇大的灵材，例如混合灵草和妖兽。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;判断一份灵材的好快通常可以通过种类的多样性和数量来衡量。种类越多，练成灵丹的效用就越广。种类个体越多，灵丹对此对其灵性吸收就越好。一份上好的灵材是炼丹成功的必备。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前修真界流程的各样灵材，例如历史悠久的 MNIST 和近些年颇受关注的 ImageNet。丹师通常可以免费或者花费很小代价获取这些灵材。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但炼制独树一格的丹药通常需要有独一无二的灵材。有钱世家会花钱收集此类灵材，或者自家种植然后请人打理。但修真仙门通常更重视内功心法，或者觉得亲自动手也是一种锻炼，于是一般要求自己弟子动手准备灵材。主要从事这内工作的通常叫药童。很多丹师是从药童做起。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;丹方&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;丹方里最重要的是灵阵。灵阵控制如何抽取和凝结灵材中的灵性。灵阵中有若干节点，然后通过回路连接这些节点。灵材沿着回路在每个节点处进行一步一步的提纯。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;根据灵材的不同，灵阵也会不一样。例如卷积类灵阵适合具有空间属性的灵材，而 Recurrent 类则适合炼制时间类属性灵材。如何设计灵阵并没有太多套路可以依循，这个主要是取决于丹师对灵材和天地规则的感悟。对于后者，一个常用的领悟对象是灵长类动物的大脑。不过即使修仙界孜孜不倦的研究了半个世纪，但进展并不是很迅速。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;真火&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;凝丹需要借助真火。真火的强度决定了炼制的速度，所以丹师通常渴望最好的真火。真火的生产被几大世家控制，其中目前最为流行的是被称之为「核弹厂」的世家。他家真火专门为炼丹定制，数倍强劲于普通修真真火。所以每年的升级都导致丹师蜂拥而至一抢而空。其世家行情上周就长了三成。其他老牌真火世家也最近开始考虑生成炼丹专用真火。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;口袋富余的丹师会选择自己购入真火，虽然购买和维护费用均不低。更多丹师是借用世家或者仙门内公共的真火，由此也经常引发争夺以至于大打出手。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;修真界也有专门出售真火的组织，丹师花费一定灵石可以租到各式真火。目前最大一家 AWS 提供核弹厂真火，行情也颇为火爆。另外几家也已经或者马上会提供类似的服务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;丹炉&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;很少有丹师会直接使用真火，他们通常使用丹炉来简化炼制过程。丹炉形态不一，但大致流程都是先将炉放置真火上，然后加入单方和灵材。丹炉会自动借用真火之力将灵材不断牵引在灵阵中游走进而凝丹。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一个好的丹炉使用简单，能够装入大量灵材，而且能有效的使用真火。通常一股真火力量有限，需要集合多股真火之力。更高端的可以使用多个丹炉同时开火炼制一枚灵丹。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前市面上流行数个丹炉。根据某知名造丹炉师的排名，第一的是第一世家的当家丹炉，使用说明详细，一推出后广受欢迎。排第二的是数年前贾教主在出山门前闭关打造，稳定可靠。笔者也参与一款丹炉的炼制过程，目前徘徊在第三第四。特点是新潮，高效，可定制化高，而且是集合顶尖仙门和世家数十丹师打造。笔者自认为此丹炉未来发展空间宽阔，推荐大家关注。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;炼制&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在具体的炼制过程中，丹炉每次将一些灵材放入灵阵，利用真火让其在灵阵中游走一个来回，将提炼出来的丝缕灵气置于灵丹中。这个过程可能会持续数百万次直至成丹。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然经过多年发展，丹炉自动可以完成主要炼制过程，但也经常需要丹师参与。丹师可以控制每次运转的时候将多少灵气压入灵丹。比例太少会导致成丹过慢，比例太大可能会导致爆丹，极端情况下甚至会爆炉。所以炼制过程中丹师一般守在丹炉边，根据当时状态做仔细调节。但即使丹成，也有可能质量不佳，这时候可能需要对灵材和丹方做一些改进，然后重新来过。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;根据灵材多少，丹方的复杂度，和真火丹炉的质量，这个过程可能持续数小时到数天不等。单师在不断的炼制过程获取经验从而成长。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;修炼之路&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;丹师的修炼之路需要大量的资源，特别是跟主修内功流的诸多流派相比。但同时丹师回报率高，因为一枚成色十足仙丹通常可以卖到很好的价格。各个世家对于优秀的丹师也是欢迎至极，待遇颇丰。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;笔者根据自己的观察和经验，试图总结一下常见的修炼过程：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;初级：熟悉常见灵材和丹方，上手一款丹炉炼制入门灵丹。经过大量练习初级丹师可以晋级中级。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;中级：能够炼制市面上顶级灵丹。通常需要有效掌握丹炉的高级用法，拥有或能借来高级真火。熟悉炼制过程各个细节，能根据现场状况做一些调节来控制成丹质量。对于一份新灵材也能够炼制出成色不错的灵丹。参加炼丹大会并得到不错的名次。中级丹师可以满足大部分世家的要求，从而衣食无愁。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;高级：高级丹师可以主持一方，而且至少在某一方向上修炼到极致：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;灵材：能够大规模培育高质量灵材，或者发掘新的未知灵材&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;丹方：能够感应灵材和天地法则极大改进现有丹方，或者发明新丹方&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;丹炉：熟悉丹炉细节，能够有效改进丹炉，甚至是打造更好的丹炉&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;炼制：能够调集大量灵材和真火，并在短时间内炼制高质量灵丹&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但炼丹跟修真界其他流派一样，光靠正常打怪练级很难成就巅峰。丹师需要追求自己独特的机遇，道路，和体悟，并且不断最求更高。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;这才是重点&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如前所述，笔者和小伙伴这些年致力打造丹炉，其名为 MXNet。经过几年努力目前颇具规模，现诚邀各位中级高级丹师加入。在这里可以各位可以学习和参与炼丹最前线，借助大量资源和大家的帮助快速积累经验。各位可以选择加入坐落在炼丹重镇硅谷背靠斯坦福的 AWS，或者京城的各个炼丹大世家。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有兴趣的小伙伴请发简历到 mli@amazon.com&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©机器之心经授权转载，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系作者获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 23 Nov 2016 10:48:57 +0800</pubDate>
    </item>
    <item>
      <title>学界 | 过去一周，值得关注的四篇神经科学论文</title>
      <link>http://www.iwgc.cn/link/3621487</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;font color="#ffffff"&gt;&lt;span&gt;一周论文&lt;/span&gt;&lt;/font&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Ronald&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;1.一个调节反感记忆强度的反馈神经回路(&lt;span&gt;A feedback neural circuit for calibrating aversive memory strength&lt;/span&gt;)&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibZpzxicBpPVYbHDXI2dN7w0tXddKf5RXuuzMMVdNrY9lYzoBX6vLHR4VRG13PtV9Nobx2aKFibJQuA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;反感经验（aversive experiences）强有力地调节着记忆的形成。而且，记忆的强度与这些经验的强度呈正比关系。目前，抑制那些汇聚被其他感知刺激所预测的反感信号的神经环路的目的被猜想为设置联想记忆的强度。然而，为调节记忆的形成而产生这些预测性抑制行为的神经环路行为还处于未知的状态。这里，我们发现预测性感知线索运用了位于可以激活中脑导水管周围灰质（midbrain periaqueductal gray）的疼痛调节神经元（pain－modulatory neurons）中特定族群的中央杏仁核区域的递减式反馈环路来控制反感记忆的强度。这个通路的光遗传抑制解除了在存储恐惧记忆的侧杏仁核神经元上预测到的反感反应，并导致了恐惧学习水平的重置。这些结果反映了一个调整学习信号的控制机制。它以自适应的方式调节着行为学习的强度。这个回路的调节失常会导致有关于增高恐惧反应的精神疾病。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;长按二维码查看&lt;span&gt;论文原文&lt;/span&gt;：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibZpzxicBpPVYbHDXI2dN7w0nVO9u8y8WA6Mk8lxnW0icF1guHG7iavIUwG0VncyDZztOOia0XDQa4jTA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;strong&gt;2.置信的显性表达对未来重要的决定提供信息（&lt;/strong&gt;&lt;/strong&gt;&lt;strong&gt;Explicit representation of confidence informs future value-based decisions&lt;/strong&gt;&lt;strong&gt;&lt;strong&gt;）&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibZpzxicBpPVYbHDXI2dN7w0yo8olMuO5bVgicaJ7UvmFicZcqJlnq2VczcLRdl4atGaEoFk5VSXlCCg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人类可以认真推敲所作的决定以及报告不同水平的置信 (confidence)。但是，为什么有必要对已经做出而且无法被撤销的选择保持置信的显性表达？这里，我们发现，置信的显性表达可以被用于改变之后的想法。特别的是，当置信低并且同样的选择再次出现的时候，参与者更可能去改变他们的想法。这种效应被显著地反映在参与者的置信报告中。此外，我们还展示了高置信的选择遵循着一个更一致的模式（少数转移性的违反（transivitiy violation））。最后，通过追踪参与者的眼部运动，我们发现低水平的注视动态可以追踪不确定性，但无法直接影响想法的改变。这些结果表明，一个对置信的显性而且准确的表达会对未来重要决定的质量上有正面的影响。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;长按二维码查看论文原文&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibZpzxicBpPVYbHDXI2dN7w0KEibpf4xtShkbM3Lg82qRaRlp05yPyEYv3AnnicwcO3vp6s4UtN5iaF5g/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;3.由在中脑注意网络的类胆碱类环路所调节的空间上的精准视觉增益控制（&lt;span&gt;Spatially precise visual gain control mediated by a cholinergic circuit in the midbrain attention network&lt;/span&gt;）&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;中脑内的刺激选择性网络的基本功能是为注意及注视计算优先度最高的关注点。在此，我们报告了一个特定的类胆碱类环路对于这个网络的计算方面的贡献。在实验中，我们可逆地阻断了在 tegmental cholinergic nucleus isthmi pars parvocellularis（Ipc）的刺激性传递。从功能上来说，它断连了仓鸮（Barn Owls）的视顶盖 (Optic Tectum, OT) 区域和 Ipc 区域。在 Ipc 区域，焦点的阻断不仅减少了表达被分离的 Ipc 单元的视感受域（visual receptive field）位置的 OT 单元的增益和空间分辨度，还引起了视顶盖的视感受域（visual receptive field）向远离那个位置的地方迁移。这些结果表明了两个机制，类胆碱类环路控制着自下而上的刺激竞争以及自上而下的信号可以使这个竞争产生偏见。并且，这两个机制建立了与一个特定环路，增益控制以及视感受域的动态迁移之间的因果关系。这个环路可能在所有脊椎种类中表现出相同的功能。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;长按二维码查看论文原文：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibZpzxicBpPVYbHDXI2dN7w0HSkeKCdUySoYjEnRrFUeWrV5iccUUvLAnTSVTAYIypponrQdGeFrKsQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;4.抽象视觉印象的快速集成表达（&lt;strong&gt;Fast ensemble representations for abstract visual impres&lt;/strong&gt;&lt;span&gt;&lt;strong&gt;sions&lt;/strong&gt;）&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibZpzxicBpPVYbHDXI2dN7w0LV81tcKicT2ichsoiauyWia1T0lTLYoKdtPIdPt8P78NwcfbEMLqqicEQHw/0?wx_fmt=png"/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;许多丰富的感知是由隐性的，非图像的或者非特征层面的信息而汇聚而成的。例如，物体的生命特征的感受无法从只从图片层面的属性来预测。相反，感受生命特征似乎是一个推理的过程，而且，从认知的角度来说，一个人可以期待这个过程为高要求的及连续的，而非迅速的或者自动化的。如果感知机制是为了表达生命特征而存在，那么观测者理应可以同时感受到大量物体的生命特征。这里，我们报告了，观测者对于随机物体，甚至是物体群的生命特征有着高度的敏感度。观测者对于群生命特征的感知能被独立观测者对于那个物体群中的独立物体的生命特征的判断所预测。我们阐述了抽象维度的视觉印象可以被简要的统计形式所表达。这些统计表达通常潜藏于我们丰富的感知经验之中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;长按二维码查看论文原文：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibZpzxicBpPVYbHDXI2dN7w0RjYmiaDZErzgFgpFNNtgv778EKHxCt7BmMZD5ZnJTicm32j6D8yicciasQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译文章，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 23 Nov 2016 10:48:57 +0800</pubDate>
    </item>
    <item>
      <title>独家专访 | KBP2016 冠军背后，科大讯飞 NLP 实力几何？</title>
      <link>http://www.iwgc.cn/link/3605764</link>
      <description>&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;机器之心原创&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：虞喵喵&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;KBP2016 是由 NIST（National Institute of Standards and Technology，美国国家标准与技术研究院）指导、美国国防部协办的赛事，主要任务为从自然书写的非结构化文本中抽取实体，以及实体之间的关系。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;美国当地时间 2016 年 11 月 15 日，NIST 揭晓 KBP2016 EDL 大赛结果。其中，科大讯飞包揽了本届 EDL 比赛的冠亚军。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器之心第一时间采访了科大讯飞研究院研究员刘丹，从 KBP2016 比赛情况、KBP 任务难点、以及讯飞的 NLP 方向进展展开话题。以下为采访实录。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;机器之心：能请您介绍一下 KBP 这个任务的情况吗？&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;刘丹&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：本次我们参加的是 KBP 国际公开评测任务，比赛由 NIST 资助，从 2009 年起举办至今。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;KBP（Knowledge base population）任务的主要目标是知识库扩展和填充，研究的主要内容是传统的结构化知识库如 Freebase，目前它的构建绝大多数都要依靠人的编辑工作。知识库中描述的信息是物理世界的命名实体和实体之间关系的抽取，如「克林顿和希拉里之间是夫妻关系」、「克林顿毕业于耶鲁法学院」这样一个个实体的关系。但人工编辑有两个问题，一是工作量较大，再就是可能出现错误和时效性的问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibZpzxicBpPVYbHDXI2dN7w0kxNobxfVbJU2V6u2lvBXFAPcopmY7SuicW2HY5Eet9ElW1fIhLmNGUw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;KBP 任务框架，资料来自科大讯飞&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;很久以来大家都在思考，人可以通过阅读新闻和书本这样的文本语料获得相关知识，机器可不可以？KBP 公开任务的研究目标，是让机器可以自动从自然书写的非结构化文本中抽取实体，以及实体之间的关系。我们今年参加的 EDL（Entity Discovery and Linking）命名实体的发现和连接任务所做的事情，是从自然语言的文本中抽取命名实体，标注它们的类型及实体与已有知识库之间的对应关系。从 2015 年开始，这个任务采用了中文、英文、西班牙文三个语种，需要找到三个语种的文本语料中的实体，并连接在一起。中文的「克林顿」要与英文的「Clinton」、西班牙文的「Clinton」连接到 Freebase 的同一个实体上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：参赛方都有哪些公司、学校或者企业？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;刘丹&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：学校居多，也有一些公司的研究机构。今年的 KBP 比赛 EDL 任务中，参加的学校有卡耐基梅隆、UIUC、伦斯勒理工，还有很多其他的学校。以企业名义参加的有 IBM，国内的机构有国防科技大、北京邮电大学和浙江大学。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：讯飞在 KBP 任务的多个指标中获得了第一，这些指标指哪些？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;刘丹&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：命名实体连接这个项目分为很多子项目，一个是将三个语种放在一同统计，需要将不同语言的相同实体连接在一起；一个是将三个语种各自统计的指标，统计指标包括命名实体发现的正确率和命名实体连接的正确率。最终我们在整个比赛任务中的绝大多数指标都是第一，其中三个语种总体的指标是最高的，与其他参赛系统相比有比较显著的优势。单独的三个语种指标中，命名实体发现的部分都是第一。连接这部分中文我们是最高的，英文和西班牙文是第二。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：命名实体发现和命名实体连接发现的难点在哪里？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;刘丹&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：命名实体发现中部分是 NLP 传统的命名实体标注任务，但 KBP 任务同其有两个区别：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一个是传统命名实体标注不允许有嵌套关系，如提到「中国科学技术大学」时，「中国科学技术大学」就是一个命名实体；KBP 则需要在文本中抽取更多细节的关系，不仅要将「中国科学技术大学」的「中科大」标注出来，同时「中国」也要标注出来，命名实体有一定的嵌套关系。除此之外，名词性的实体如「中国科大」、「科大讯飞」、「机器之心」都是一个个独立的名字（专有名词），这样的名字更容易标注；名词性的普通名词短语如「中国人」、「美国人」、「中国的公司」，这样的名词性实体需要与一般的名词短语区分开。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外 KBP 任务需要标注的是有意义的名词性实体，如「XX 作为一个中国人」，这里的「中国人」是有明确指代的，所以需要标注；泛指性的如「中国人可以发怒了」，这里的「中国人」是不允许标注的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;KPB 任务更符合人对于事物类别的区分判断，有的内容是无法从语言语法的角度区分的，这让命名实体发现具有了比较大的难度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;命名实体连接发现最关键的部分是消歧的问题，普通的文本大多数时候不会提全名，如科大讯飞大家不会说「科大讯飞股份有限公司」，而会说「讯飞」。因为人们会使用缩写、昵称、绰号以及上下文指代的内容，使得命名实体连接时的消歧会非常难做。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;还有一个比较有意思的事情是，去年 KBP 比赛时杰布•布什正在竞选美国总统，新闻中会出现很多「布什一家」，其中以杰布•布什居多。但是因为训练语料中老布什和小布什出现的频率更高，所以在去年的比赛中，大多数参与的系统都会将杰布•布什连接到乔治•布什上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外，在语料中的昵称缩写也很容易连接错误，或错标为非实体。除了这些，偏谈论性的语调中会出现「希拉里这个女人……」。这里的「这个女人」在实体发现中被标为实体会很难；其次把「这个女人」连接到希拉里是另外一个比较有难度的事情。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：这个任务更偏向于 NLP 中的语义理解方向吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;刘丹&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：应该算语义理解。与之相似的是最近几年发展的「抽象语义表示」，希望将文本中的句子抽象出和语言无关的实体，以及实体关系、动作之间的图像表示。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：KBP 任务的评判标准是什么？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;刘丹：评判标准是正确率与召回率两者兼顾的，采用的是 NLP 中常用的 f-score。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibZpzxicBpPVYbHDXI2dN7w00WvlvCy0sf7WYbu9Ke8MicSPo3mibkbJtt5tUg1aJRFibqoic6XibDdKiaiaQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果语料中出现了一百个实体，系统标出了 105 个，其中 80 个是正确的实体，另外 25 个是系统错标的，正确率就是标出的正确实体数除以系统标出数（80/105=0.7619）；一共有 100 个实体，召回了 80 个，召回率就是召回数比总数（80/100=0.8）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果正确率和召回率只考虑一部分，往往可以做到很高，比如系统尽可能只找绝对有把握的（名词实体），或者文本中出现了 100 个实体，只找到 1 个实体并且是正确的，那么正确率总是 100%。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：因为 KBP 任务包含中文、英文、西班牙文，那么多语言之间连接部分的难点在那里？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;刘丹&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：如果按照传统 NLP 做法，会根据每个语言精细定义比较复杂的规则，系统的调节也会倾向于抽取非常大的规模特征。做传统 NLP 中国人做中文是最好的，英文还能做得来，但是西班牙文是没办法做的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们在解决 KBP 任务是采用的是基于深度学习框架下发展的技术，特点是用比较复杂的神经网络和端到端的学习，尽可能多的靠数据驱动并尽量减少人工定义的规则和特征。我们参加本次比赛的模型结构很有自己的特色，在三个语种中使用的是同一个系统，取得的结果都不错。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然西班牙文我们完全看不懂，但在西班牙文命名实体发现的部分，最终结果是我们做得最好，领先第二名不少。命名实体连接部分我们是第二，比第一差了 1.9 分（讯飞成绩为 63.5，最优为 65.4）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibZpzxicBpPVYbHDXI2dN7w0UwM3Mng3y6ktxTpDZuKoHog7EUFSWTXyI39pLKNmrQjEl42u13Y0ww/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;KBP 任务可提交参赛系统可提交两次，该图表为第一次提交时的指标结果。其中，1 号系统为讯飞与 USTC 实验室联合提交的系统。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibZpzxicBpPVYbHDXI2dN7w0PWyt5LJddmm80wuua5mfLiboLavjRtdpfLRSlxypW5icBUVf8DE0UsUA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;该图表为第二次提交的指标结果。其中，2 号系统为讯飞与约克大学联合实验室共同提交的系统。两个系统共同囊括了 EDL 任务的冠亚军。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：西班牙语比较难做的原因是因为训练语料较少吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;刘丹&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：有两方面原因。一个是传统 NLP 依赖的规则资源在西班牙语方面比较少，我们中文做的比较多，至少对于人名判断有姓氏列表，中国所有的省份也有列表，想去做规则总是做得出来。西班牙文的类似列表做得少，相关资源也很少。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外研究者不是母语使用者（Native Speaker），想要进一步调试系统都没有办法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：比赛使用的输入语料是随机语料吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;刘丹：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;是官方提供的。今年比赛和此前相比还有一点不同，前面几年的语料非常少，每个语种只有 500 篇。今年规则改为一共提供 90003 篇，每个语种平均 30001 篇。需要将 90003 篇中的实体都找出，并连接起来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：我们在比赛中主要用到的技术有哪些？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;刘丹：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;主要还是深度学习。讯飞在基于深度学习解决 NLP 问题方面已经做了很多年，在深度学习火起来但在 NLP 没有做出太多成果时，我们就已经有了思考和尝试。差不多在两年前，与我们合作的加拿大约克大学江辉教授提出基于神经网络的阅读机器（Neural Reading Machine）。对于阅读机器（Reading Machine）来说，先是将自然语言文本当作一个时序的单词序列，针对时序序列考虑各种建模方式，包括传统的卷积网络、循环神经网络，以及江辉教授提出的一种名为 FOFE 的特殊网络结构。这次比赛我们在这些基础上，用了最近两年比较流行的注意力模型（Attention）来做。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibZpzxicBpPVYbHDXI2dN7w0ekWsNicEeYVwkbgjAFVlHYk8I5SmoySzsFibyjapPicLenzSA0DxMjRibA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;约克大学·讯飞联合实验室成立于 2015 年，专注神经计算与深度学习，图为实验室成立合影&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：那么这些技术已经应用到我们的产品中了吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;刘丹&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：应该说 KBP 的最终目标是知识图谱的扩展，知识图谱对于目前的讯飞来说并没有太多用处。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但其技术有非常大应用。首先是基于神经网络端到端的学习方案，在类似的 NLP 问题上都能发挥作用。例如我们在教育方面的自动阅卷、书面作文和口头作文的评分批改、试卷难度预测，我们用了各种各样的技术，但网络结构的总体思想是类似、相关的。大体上是将时序的文本序列进行某种基于神经网络获得的抽象表示，在这种抽象表示上面定义结构，来描述所要抽取的结构信息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然说我们不做知识图谱，但 KBP 的研究是要在知识图谱上找到命名实体的对应连接，这一点对于讯飞的核心业务语音对话系统是非常重要的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前所有的对话系统都是功能引导式的对话，比如让语音助手订票、查餐馆之类。在业务范围外的百科知识和与用户闲聊的时候，往往只能利用人工规则和补资源的方式兜底，比如问对话系统「姚明身高有多少」、「奥巴马的妻子是谁」，多数情况下都表现不佳。基于刚才提到的命名实体抽取连接的相关技术，我们可以对于问题进行简单分析，将问题与维基百科、Freebase 知识库连接起来，从结构化的知识库中找到对应的答案，这是相对直接的应用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：除此之外，在 NLP 方面讯飞还有哪些成果？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;刘丹&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：首先是 NLP 中非常重大的部分——机器翻译，我们目前在机器翻译方面做得还不错，2014 年获得国际评测任务 IWSLT 的第一名，IWSLT 的特点是口语化演讲。去年 NIST 组织的 OpenMT（Open Machine Translation Evaluation）比赛，我们同样获得了第一名。目前我们在中-英语互译、中-维吾尔语互译、中-藏语互译做的还不错。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器翻译之外，讯飞在教育方面做的比较多。我本人 4 年前一直在做教育相关的业务，包括给定主题自由表述的口语开放题型、自由书面作文的评分和批改。它们不仅牵扯到语音识别、手写识别技术，在识别正确的基础上，要在偏口语、噪音干扰的情况下，将整个考生的表述脉络理清，找出其中的病句、搭配不当。对中文作文的评分要难一些，因为中国人基本不会有语法错误，要给出前后语义搭配的连贯性等方面的评价和修改建议。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：在您看来，NLP 的下一步发展需要解决哪些问题？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;刘丹&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：目前来看大家研究的比较多的是语义理解。最近一两年 Google、Facebook，当然我们也做了一些阅读理解的问题。还有文本产生，就是让机器自己去写东西。目前在文本产生这部分，机器能产生语法没有错误、比较顺滑的句子，但产生出的段落看上去没有什么意义。机器能够产生文本，但没做到「创造」。这方面 Google 也做了 DeepArtist，面临的也是同样的问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;更偏实用的是虽然对话系统大家都在做、能做到「可用」，但和真人还是有显著差距，包括我们的语音助手和友商的产品都是这样。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从技术上看，目前我认为值得深入的是两部分：一个是无监督学习，自然语言有大规模的无标注数据，但针对任务的标注如对话系统的数据是非常有限的。怎样做到使用无监督数据和少量有监督数据将问题做到大规模标注数据效果，是目前我们比较感兴趣的内容。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外从神经科学角度看，还有对人记忆的仿生。目前的神经网络，包括号称有记忆的循环神经网络，所描述的记忆还是短时记忆，只能理解人说的一句话的内容。人的智慧随着年龄不断增长，核心在于人的记忆。只有人有记忆，在看到新事物的时候，才能通过唤醒记忆的方式找到类似的解决方案和创新。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;记忆机制在机器学习尤其是自然语言领域都是近两年大家非常关注的课题，Google、Facebook 都做了非常不错的工作，Google 也在前两个月发了一篇可微分的神经计算机，记忆机制会是后续比较重要的东西。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心原创文章，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 22 Nov 2016 10:38:12 +0800</pubDate>
    </item>
  </channel>
</rss>
