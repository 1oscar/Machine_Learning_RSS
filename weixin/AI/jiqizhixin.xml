<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器之心</title>
    <link>http://www.iwgc.cn/list/670</link>
    <description>人与科技的美好关系</description>
    <item>
      <title>深度 | 使用机器学习进行语言翻译：神经网络和seq2seq为何效果非凡？</title>
      <link>http://www.iwgc.cn/link/2382697</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自medium&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;作者：Adam Geitgey&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀、李亚洲、杜夏德&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;此篇是系列文章 machine learning is fun 的第五部分，讲解了深度学习和 sequence-to-sequence 在机器翻译中的应用。此系列之前的文章机器之心也做过传播（&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717418&amp;amp;idx=1&amp;amp;sn=0b41e7fa9ee92535541f7e09ad1b519d&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717418&amp;amp;idx=1&amp;amp;sn=0b41e7fa9ee92535541f7e09ad1b519d&amp;amp;scene=21#wechat_redirect"&gt;深度 | 如何掌握Facebook自动人脸识别技术？这篇文章为你提供生动指南&lt;/a&gt;），可点开链接浏览。英文原文章可点击阅读原文查看。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们都知道而且喜欢谷歌翻译（Google Translate），这个网站可以几乎实时地在 100 多种不同的人类语言之间互相翻译，就好像是一种魔法。我们还可以通过手机和智能手表使用谷歌翻译：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9WnopMJW7r6wvVNnoiaWINha1cy7ZbjXruAUAxLEWxDNwaEd2wWdy7k8Lzhd5q7I25A7XysaTc6Jg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谷歌翻译背后的技术被称为机器翻译（Machine Translation），它已经在通过帮助人们互相交流而改变了世界。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但我们知道 15 年来，高中学生已经使用谷歌翻译……呃……辅助他们的西班牙语作业。这还算什么新鲜事吗？&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_gif/KmXPKA19gW9WnopMJW7r6wvVNnoiaWINhjl6icGHsBa2hh7bhG6yUDHPcOtlAmmcQyAeExshibndZhQOwDuVrJHibw/0?wx_fmt=gif"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;事实上，过去两年来，深度学习已经改写了我们进行机器翻译的方法。对语言翻译一窍不通的深度学习研究者拿出的相对简单的机器学习解决方案正在击败由最好的人类专家打造的语言翻译系统。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这种突破背后的技术被称为序列到序列学习（sequence-to-sequence learning）。这是一种可被用来解决许多类型问题的非常强大的技术。在我们了解了该技术可以如何被用于翻译之后，我们也将理解该算法如何被用于编写人工智能聊天机器人和描述图片。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;那就开始吧！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;让机器做翻译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以为了让计算机能翻译人类语言，我们该如何对其编程呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最简单的方法是使用目标语言中对应的词替换要翻译的句子中的每个词。下面是一个西班牙语到英语的逐词翻译的简单例子：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9WnopMJW7r6wvVNnoiaWINhPm8CXYSUg4SXNibzafNOTkVbDWcvQ6qeQzskVAkpc7tvyFjM2G5Ux1w/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;我们只是简单地将每个西班牙语词用对应的英语词替换了。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是很容易做到的，因为这么做只需要一本可以查找每个词的翻译的词典。但得到的结果非常糟糕，因为其没有考虑任何语法和上下文。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以下一步可能就是添加一些特定语言的规则以改善所得到的结果。比如说，也许需要将常见的 2 词短语作为单个词组进行翻译。另外你也许还要交换名词和形容词的顺序，因为它们在西班牙语中的顺序和在英语中的是相反的：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9WnopMJW7r6wvVNnoiaWINhm2aiawK9b5WibQV3Dyz9tzFw4M9xtXKStdWXibbqiawJz5fzCd407Jjusw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这种方法有用！如果我们不断增加更多规则，直到我们可以处理语言的每一部分，那我们的程序应该就能够翻译任何句子了，对吗？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这就是最早期的机器翻译系统的工作方式：语言学家想出复杂的规则，然后将它们逐一编程到系统中。在冷战期间，为了创造出能够更轻松地解读苏联通信的翻译系统，世界上一些最聪明的语言学家辛苦工作了很多年。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不幸的是，这种方法只对天气报道这样简单的和结构平直的文档有效。对于真实世界文档，它没法可靠地工作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其问题在于人类语言并不遵循一组固定的规则。人类语言中充满了特例、地区差异、以及纯粹的打破规则。比起坐下来定义语法规则的人，影响我们说英语方式更多的是几百年前入侵英国的人。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;使用统计学让计算机更好地翻译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在基于规则的系统失败之后，人们开始使用基于概率和统计学（而非语法规则）的模型开发新的翻译技术。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;打造一个基于统计学的翻译系统需要大量训练数据，其中包含了同样的文本在至少两种语言中的表达。这种对应的翻译文本被称为平行语料库（parallel corpora）。与 1800 年代科学家使用罗塞塔石碑（Rosetta Stone）根据希腊语解读古埃及象形文字的方法类似，计算机可以使用平行语料库猜测将一种语言的文本转换成另一种语言的方式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;幸运的是，在很多奇怪的地方存在着大量这种几种语言的对应文本。比如说，欧洲议会（European Parliament）会将他们的程序（ proceedings）翻译成 21 种语言。所以研究者可以使用这些数据来帮助开发翻译系统。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9WnopMJW7r6wvVNnoiaWINhTp26ZSKubaCO7YbgnxlmUWJboibZ3sMyxwBuxVttcB2yYoiasuLWH65A/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;训练数据这么激动人心！但这不过是几万亿行枯燥的政府公文而已……&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;以概率的方式思考&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;使用统计翻译系统的根本不同之处在于它们不会尝试生成一个确切的翻译。相反，它们会生成数千个可能的翻译，然后根据它们正确的可能性对这些翻译进行排序。它们通过检查翻译与训练数据的相似程度来确定其的「正确」程度。下面是它的工作方式：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;第 1 步：将原句子分解成块（chunk）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先，我们将我们的句子分解成简单的块，其中每一块都可以简单地翻译出来：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9WnopMJW7r6wvVNnoiaWINh48YFXD350W4wnib98pFHnvqx7iaOWbFUdA4w49QKLxuxb8ia8SUa2C7CA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;第 2 步：找到每一块的所有可能的翻译&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;接下来，我们会检查训练数据中人类对这一词块的所有翻译，然后翻译每一块。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有必要强调我们不仅是在简单的翻译词典中查找这些块，我们还会看真实的人是如何翻译真实世界中的这些同样的词块的。这可以帮助我们获取它们在不同上下文中的不同使用方式：&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9WnopMJW7r6wvVNnoiaWINhRzJb9UnVLgfqrxgbNhA58icFkgC61ejSRCTBLm2QibYhdCSf1E7kziadw/0?wx_fmt=png"/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;即使最常见的短语也有很多可能的翻译方式&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其中一些可能的翻译比另一些更常用。基于我们的训练数据集中每种翻译出现的频率，我们可以对其进行评分。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;比如说，当人们说「Quiero」时，表达「I want」的意思比「I try」的意思要常见得多。这样我们就可以根据训练数据中「Quiero」表示「I want」的频率给予这种翻译更高的权重（ weight）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;第 3 步：生成所有可能的句子，然后找到其中最有可能的一个&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;接下来，我们将使用这些块的每种可能的组合来生成一堆可能的句子。光是从第 2 步我们列出的块翻译中，我们就可以通过不同的块组合方式生成近 2500 个不同的句子变体！下面是一些例子：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;I love | to leave | at | the seaside | more tidy.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;I mean | to be on | to | the open space | most lovely.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;I like | to be |on | per the seaside | more lovely.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;I mean | to go | to | the open space | most tidy.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但在真实世界系统中，块的可能组合方式甚至会更多，因为我们也会尝试不同的词序和句子中不同的词块划分方式：&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;I try | to run | at | the prettiest | open space.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;I want | to run | per | the more tidy | open space.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;I mean | to forget | at | the tidiest | beach.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;I try | to go | per | the more tidy | seaside.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在需要扫描所有生成的句子以找到其中看起来「最人类」的翻译。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;要做到这一点，我们需要将生成的句子和来自英语书籍和新闻故事的数百万个真实句子进行比较。我们所能获取的英语文本越多，效果就会越好。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以下面这个可能的翻译为例：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;I try | to leave | per | the most lovely | open space.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;很可能之前从没有人用英语写过这样的句子，所以它与我们数据集中的任何句子都不会非常相似。我们给予这个可能的翻译一个较低的概率得分。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但再看下面这个可能的翻译：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;I want | to go | to | the prettiest | beach.&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个句子将与我们的训练集中的一些东西很相似，所以它会得到一个高概率得分。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在尝试了所有可能的句子之后，我们选出的句子将既包含最有可能的块翻译，也在整体上与真实的英语句子最相似。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们最后的翻译结果将会是「I want to go to the prettiest beach.」还不错！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;统计机器翻译是一个巨大的里程碑&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果有足够的训练数据，统计机器翻译系统的表现就将远远优于基于规则的系统。Franz Josef Och 改进了这些思想，并在 2000 年代早期使用它们开发出了谷歌翻译。这个世界终于可以使用机器翻译了！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这种基于概率的「愚蠢的」翻译方法效果比语言学家设计的基于规则的系统更好，在早期时所有人都对此感到惊讶。这带来了 80 年代在研究者之间广为流传的一句话：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;每次我开除一个语言学家，我的准确度就会上升。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;“time I fire a linguist, my accuracy goes up.”&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;— Frederick Jelinek &lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;统计机器翻译的局限&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;统计机器翻译系统效果很好，但它们的开发和维护却相当复杂。你想翻译的每一组语言对都需要专家对一个新的多步骤翻译流程进行调整和优化。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因为开发这些不同的翻译流程所需的工作实在太多了，所以必须要做出一些权衡。如果你想让谷歌将格鲁吉亚语翻译成泰卢固语，它必须先在内部将其翻译成英语作为中间步骤，因为世界上并没有那么多的格鲁吉亚语到泰卢固语的翻译，在这个语言对的互相翻译上投入巨资是不明智的。而如果你想做的是更常见的法语到英语的翻译，你所使用的翻译流程就可能会更简单一点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果我们让计算机把所有这些烦人的开发工作都做了，不是很赞吗？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;让计算机更好地翻译——不再需要所有这些昂贵的人&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器翻译的圣杯是能自己学习如何翻译的黑箱系统（black box system）——只需要查看训练数据。即使有了统计机器翻译，还是需要人类来开发和调整多步骤统计模型（multi-step statistical model）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2014年，Kyung Hyun Cho 的团队取得了突破。他们发现了一种运用深度学习来建立黑箱系统的方法。他们的深度学习模型利用了一个平行语料库来学习如何在没有人的介入下翻译两种语言。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该方法的背后有两个关键思路——循环神经网络和编码。我们可以结合这两种方法建立一种自学习翻译系统。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;循环神经网络&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们已经讨论过循环神经网络，现在快速回顾一下。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一个常规的（非循环）神经网络是一种通用的机器学习算法——输入一个数字列表，并计算出结果（基于之前的训练）。神经网络能作为一个黑箱来解决大量问题。比如，我们可以用它来基于一座房子的属性计算房子的大概价值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9WnopMJW7r6wvVNnoiaWINh1UqKb8SibK2no6oyZraK4n53zSNatib8ORjSEmDOYmJvY3ULq0DdfhUw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是像大多数机器学习算法一样，神经网络不会保存使用信息。你让输入一条数字列表，然后这个神经网络就能计算出结果。如果你在给它看同样的数字，它还会计算出同样的结果。这不是对之前的结果的记忆，换句话说，2+2 总是等于4。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一个循环神经网络（RNN）是一种稍稍调整过的神经网络，在RNN 中，之前的网络状态是下一次计算的输入之一 &amp;nbsp;，也就是说之前的计算会改变未来的计算结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9WnopMJW7r6wvVNnoiaWINhcMBDibLNoicUzoEJoNP2obyDJwib5YOianUetiaeYiabNtQod2zxHnjkYbyQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;人类讨厌他：一种让机器更聪明的奇怪小把戏！&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为什么我们想要这么做？难道说不论我们最后计算的是什么，2+2不应该总是等于 4 吗？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这种技巧能让神经网络学习数据序列中的模式。例如，你能用它来基于一句话中前面几个词来预测后面最有可能的那个词。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_gif/KmXPKA19gW9WnopMJW7r6wvVNnoiaWINhJicvZD7KNiciaES8PjOEjLcfcZ3fAQwDgqC9MJgVZdGX4algGL1HeeMibw/0?wx_fmt=gif"/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;这是智能手机键盘应用实现「自动更正」的一种方式。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;任何时间你都可以用 RNN 来学习数据中的模式。因为人类语言就是一个大且复杂的模式，RNN 被越来越多地用于自然语言处理的多个领域。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;编码（Encodings）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一个需要回顾的是编码，我们在 Part 4 中的脸部识别中讨论过。要解释编码，让我们先绕道看看如何用一台计算机来分辨两个人。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当你用计算机区分两个不同的人时，你可以收集每张脸的不同度量，并使用这些度量来对脸进行比较。例如，我们可以测量每只耳朵的大小、眼间距，然后比较测量结果来判定他们是否是同一个人。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你可能已经在《犯罪现场调查》这种热播侦探节目中熟悉了这个方法：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9WnopMJW7r6wvVNnoiaWINh3DcicfalE8Ctftg0pZmBIVQoHd0axHOImcK3pQrN2xlDib52gpLoCHbQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我非常喜欢这个来自《犯罪现场调查》的蠢蠢的 gif，所以我还会使用它，因为它能清楚的证明这个方法，虽然完全可能没有道理。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;将一张脸转变成测量的方法是一种编码的方法。我们输入原始数据（一张脸的图像）然后将它转换成一系列测量数据来表示它（编码）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是就像我们在 Part4 中看到的那样，我们没必要拿出一个特定的面部特征列表来测量自己，用一个神经网络从一张脸上生成测量数据就可以了。在找出哪种测量能最好地区分两个长相相似的人方面，计算机比我们做的更好。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9WnopMJW7r6wvVNnoiaWINh5QhcibXXHdl5vm2qAUI2KeBFP5pz9tuib4mDVeibJzptfeWE88pyjDr0A/0?wx_fmt=png"/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;经过训练的神经网络生成的面部特征测量可以用于确保不同的人脸生成不同的测量数字。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这就是编码（encoding）。用简单的事物（128 个数字）来表征非常复杂的东西（一张人脸图）。现在比较两张不同的脸更加容易了，因为我们只要去比较每张脸的 128 个数字就行了，不需要比较整张图像。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;猜猜这种方式还能做什么？我们可以同样的方式来处理句子！我们也可以生成一系列独特数字的编码来表征每可能的不同句子：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9WnopMJW7r6wvVNnoiaWINhr5YaRdSNa0qgwTKVHficLeMwsTDRyNZn2oaCO5UPLEd7icRh3FXB12sQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;em style="color: rgb(136, 136, 136); text-align: center; line-height: 1.6;"&gt;&lt;span&gt;这个数字列表表示英文句子 「Machine learning is Fun！」不同的句子可以表示成不同的数据集合。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了生成这个编码，我们会把这条句子放入这个 RNN 中，一次放入一个词。最后一个词处理后的最终结果将是代表整个句子的值：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_gif/KmXPKA19gW9WnopMJW7r6wvVNnoiaWINhEm6ibYGhH8hwuooyFRbYda1GvficKiaRIpGriaCibISnqJqqcpeTqRF7l1A/0?wx_fmt=gif"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;因为这个 RNN 对通过它的每个词都会形成一种「记忆」，它计算出来的最后编码表征了一条句子中的所有词。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;好，现在我们有了一种方法能够将整个句子表示为一系列独特的数字！我们不知道编码中每个数字的意义， 但这并不重要。只要每个句子能够根据自己的数字集合被识别出来，我们不需要知道这些数字具体是怎么生成的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;让我们开始翻译！&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们知道了如何使用一个 RNN 将一个句子编码为一系列独特的数字，这对我们有什么帮助？这里事情才开始变得有趣！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果我们采用两个 RNN 并将它们端到端的连接起来会怎样？第一个 RNN 会生成代表句子的编码。然后，第二个 RNN 会采用这些编码，并对这同样的逻辑进行反向，从而再次解码原始句子：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9WnopMJW7r6wvVNnoiaWINhJTV85jibfSbiasiamZicB16A5IKdPiaP1mhWYibbcdkkYCqRibl2hS9xicWPcQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当然，能够编码且再次解码原始语句不是非常有帮助。但如果我们能够训练第二个 RNN 将原英语解码成西班牙语会怎样呢？我们可以使用平行语料库训练数据对它们进行训练：&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9WnopMJW7r6wvVNnoiaWINhLNPwjTfqR2ZUDYFnt9K0a3BuOPYWZyFEGeG5jtR1m48INK2D2g52iaw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;就像这样，我们有了一个将英语词序列转换为对应的西班牙语的通用方法。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是一个有用的想法：&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;这一方法最大的限制是你拥有的训练数据的数量以及你所能投入的计算能力。机器学习研究者仅在两年前才创造出了这种方法，但其表现就已经能够比肩已经发展了 20 年的统计机器翻译系统了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;这种方法并不依赖于对人类语言规则的了解。算法自己能搞清楚这些规则。这意味着你不需要专家调整翻译流程中的每一步，计算机就能做到这些。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;这种方法几乎对所有类型的序列到序列（sequence-to-sequence）问题都有效！而且事实上很多有趣的难题都是序列到序列问题。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;注意我们没有谈到一些使其能在真实世界数据上有效的工作。例如，还有一项额外的工作就是处理不同长度的输入和输出句子。另外还有翻译罕见词的问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;打造你自己的序列到序列翻译系统&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你想要建立自己的语言翻译系统，这是一篇使用 TensorFlow 做英法翻译的讲解文章：https://www.tensorflow.org/versions/r0.10/tutorials/seq2seq/index.html。然而，这里面的内容不适合于新手或者预算有限的人，该技术还很新并且需要资源。即使你有一个带有高端视频卡的超快计算机，可能也要花费一个月的处理时间训练自己的语言翻译系统。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;同样，序列到序列机器翻译技术进展迅速，让人难以跟上。很多近期取得的进展（像增加一个 attention mechanism 或 tracking context）极大的改进了结果，但也因为成果太新以至于连维基百科页面都还没有。如果你确实想使用序列到序列学习，你需要时刻与这些新研究保持同步。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;序列到序列模型的强大能力&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以，我们还能使用序列到序列模型做什么呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;大约一年前，谷歌的研究者表示你能使用序列到序列模型开发人工智能 bot。想法很简单，但惊人的是它竟然有效。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先，他们抓取了谷歌员工和谷歌技术支持团队间的聊天日志。然后，他们训练一个序列到序列模型，把员工的问题作为输入句，技术支持团队的回答作为输入句的「译文」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9WnopMJW7r6wvVNnoiaWINhXUg7Gmu0sjW1eoeDiae4OicHrxmebjzgicBjBGJjSLNUtXLicATN9vNmwA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当用户与该 bot 交互时，他们可以使用该系统「翻译」用户的每条消息，从而得到 bot 的应答。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最终结果是一个半智能的 bot，它可以（有时）回答真正的技术支持难题。下面是来自他们论文（https://arxiv.org/pdf/1506.05869.pdf）的一个对话样本：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;人：连接拒绝或者类似的事情&lt;/span&gt;&lt;br/&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器：我可以知道你连接的网络连接的版本吗？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;人：我不太确信版本是多少&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器：网络连接是否提示需要任何用户证书？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;人：是的&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器：当时你是在家还是在工作？在办公室吗？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;人：我在家&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器：试下这个。转到&amp;lt;URL redacted&amp;gt;页，并输入你的用户名和密码&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;人：完成&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器：试着输入&amp;lt;NAME redacted&amp;gt;，检查现在是否正常&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;人：yes，能工作了&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器：很好。还需要帮你做什么吗？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他们也尝试基于数百万条电影字幕建立一个聊天机器人。其思路是使用字幕间的对话训练 bot ，使其能像人一样讲话。输入句是一个角色的讲白，「译文」是下个角色的对白：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9WnopMJW7r6wvVNnoiaWINhEzJU80whjZJ9aWyf9vn7Fl9ppjVrZ0MiaM7009Vux9LjcdyUpcbzpOA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;产生的结果真的很有趣。不只是 bot 像人一样交谈，它也展现出了一些智能：&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;人：我的名字是 David，我的名字是什么？&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;机器：David&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;人：我的名字是 John，我的名字是什么？&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;机器：John&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;人：你是领导者还是追随者？&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;机器：领导者&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;人：你是追随者还是领导者？&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;机器：领导者&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这只是一切可能的开始。我们并不限制于将一个句子转化为另一个句子。你也可以做一个 image-to-sequence（图像到序列）模型，将一个图像转换为文本。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谷歌的另一个团队使用卷积神经网络取代第一个 RNN 就做到了这一点。这使得输入可以是一张图片而非句子。剩下的工作基本一样：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9WnopMJW7r6wvVNnoiaWINhVAoWh4WicDtOxic8arlbeXOzxqbqyAGHXwvBek9r0A0ib6ZbOFlVBY7ZA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;就像这样，我们能将图片转化为文字内容（只要我们有大量的训练数据）！&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过单独处理一张图片的多个不同区域，Andrej Karpathy 对这些思路进行了拓展，建立了一个能够极其具体地描述图片内容的系统。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9WnopMJW7r6wvVNnoiaWINhC8ich1PXIUvC2AGtPibEbuugCoRxYfFmxzpN9UhGjhZIzGyRoMhD1xgQ/0?wx_fmt=png"/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这使得建立图片搜索引擎成为了可能，能够找到匹配搜索查询的图片：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_gif/KmXPKA19gW9WnopMJW7r6wvVNnoiaWINht7gpP7s9fDFW9Vww1Vm94TgiapwKHGTE01peScNre4lr2mrcicQ8ogWg/0?wx_fmt=gif"/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;也有研究者在研究其反向的问题——基于文本描述生成一张完整图片。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从这些例子中，你就可以想象未来的可能有多大。如今，从语音识别到计算机视觉，都有着序列到序列的应用。我敢说明年将会有大量更多的应用出现。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;</description>
      <pubDate>Mon, 22 Aug 2016 17:59:10 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 人工智能市场发展如何？六张图帮你读懂投融资现状</title>
      <link>http://www.iwgc.cn/link/2382698</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自 Raconteur&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;作者：SARAH ALLIDINA&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：段泽明、吴攀、黄清纬、李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;截止至 2016 年 6 月，人工智能已经获得了 9.74 亿美元投资，这个数字上升的原因只有一个：2016 年人工智能专利的应用比过去任何一年都多。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717343&amp;amp;idx=1&amp;amp;sn=66f29563746afdcbfc9251a5e4439128&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717343&amp;amp;idx=1&amp;amp;sn=66f29563746afdcbfc9251a5e4439128&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;根据 Narrative Science 的研究称，2018 年之前 62% 的组织都会使用人工智能&lt;/span&gt;&lt;/a&gt;&lt;span&gt;。现在，预测分析是企业中人工智能最常用的形式，并且各公司都在关注创新，以一个比过去更快的速度为它们的人工智能研发成果申请专利。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;让我们一起通过包括「人工智能顶级投资者」和「最常用的人工智能企业解决方案」的六幅图表来探索人工智能的增长。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9WnopMJW7r6wvVNnoiaWINhLocy2TYYWkibttmVWvusqZNIxia5oYlDDQ3JP7WeCRTIRrpp5c0YF3pA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;截止至 2016 年 6 月，人工智能已获得 9.74 亿美元的投资。今年的总投资额必定会超过 2015 年的总投资额，并且 CB Insights 指出，200 家人工智能公司已获得了近 15 亿美元的融资。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9WnopMJW7r6wvVNnoiaWINhHbwM0YUyYMeHQzELAT1mhx3pfoib0iaThTaXiag2IicbxLvhQWl7tiaibuzA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能并不局限于商业领域，事实上包括「护理机器人」在内的私人机器人市场能在 2020 年达到 174 亿美元的市场规模。随着世界人口老龄化现象越来越严重，护理机器人将会是一种很好的解决方案。日本政府是该领域的领跑者，将三分之一的政府预算投入到研发老年机器人中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9WnopMJW7r6wvVNnoiaWINhl1m1t8n9bkOUmabNYI2oOOLrDQ1xAValqE7K7hicImMbKLaic1rZlyvg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;富士通拥有的人工智能专利最多，他们以人为核心的人工智能 Zinrai 集成了能处理人类感觉的感官媒体技术，能提供医疗决策支援的知识处理以及能协助缓解空中交通的数学技术。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9WnopMJW7r6wvVNnoiaWINhPtjdpKTfqIPmPTicRiamI914QAYTWnWFosgUzmnpw72BXI809DnvTTZw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;IBM 以 88 个人工智能专利紧随其后。IBM 的发明家已经研发出了一项有助于机器学习，推理和各种类型的数据处理的新技术，例如：IBM 中国研究实验室，为一项帮助机器解释富有情感的单词的系统申请专利，使机器可以以一种更加自然的方式交谈。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Accel 是一家总部位于帕洛阿尔托的风险投资公司，它宣布了面向起步阶段公司 5 亿美元基金，面向后期成熟公司 15 亿美元的基金。在 9 个他们重点关注的领域中，人工智能高居榜首。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;New Enterprise Associates 也是一家世界级的风险投资公司，是人工智能领域的第二大投资商。这家公司已经投资了 WellTok’s CafeWell.co 网站，该网站将卫生保健知识融入社交网络技术，依据其健康目标做出建议，使得使用者可以把握他们的健康。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9WnopMJW7r6wvVNnoiaWINhtgn8ZvZSvjmpNZgCFu4CPG9ljSDe83wFV9tNXibJVicLrO4B7aYyahkQ/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;大部分人工智能的风险投资交易都是深度学习/机器学习方面的。Nervana System 的创始人兼首席执行官 Naveen Rao 解释到：「该方法允许计算机通过模仿人脑结构的『神经网络』系统处理任务，从而进行学习、改进。例如 AlphaGo，除了依靠暴力计算，它还能像人依靠直觉一样做出决策。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;依靠深度学习的项目是很常见的，例如 Facebook 的新闻馈送依靠深度学习，将用户最可能感兴趣的新闻组织推送，而且自动标注也采用了这种类型的人工智能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9WnopMJW7r6wvVNnoiaWINh2QxkOKiaCH4CjspmrgiaJINLjXibuOGLWLeHEfRNzGoIxc9As7hAxqjIw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;据 Narrative Science 的调查，超过 200 名 CEO、CIO、CTO 和数据科学家的透露，语音识别和响应解决方案是除机器学习外的最常用的商业人工智能解决方案。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;15% 的受调查者在使用虚拟私人助手。虚拟私人助手，如谷歌 Now、苹果 Siri ，是智能手机上的一大特色，它为商业领袖和消费者提供一站式解决方案，例如安排会议、回应网页搜索以及建议最佳的旅行路线。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，机器之心系今日头条签约作者，本文首发于头条号，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Mon, 22 Aug 2016 17:59:10 +0800</pubDate>
    </item>
    <item>
      <title>学界 | DeepMind David Silver 最新论文：学习跨多个数量级的值</title>
      <link>http://www.iwgc.cn/link/2382699</link>
      <description>&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自&lt;span&gt;arXiv.org&lt;/span&gt; &lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;作者：Hado van Hasselt, Arthur Guez, Matteo Hessel, Volodymyr Mnih, David Silver&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9WnopMJW7r6wvVNnoiaWINhacicUFMbUAibNkSLECAngbSRNA2vSBEmmZ1FvUl68Ubfg79w55iawwtcg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;摘要 &lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;大多数学习算法相对于正被逼近的函数是不变的。我们在这里提出对学习中所使用的这些目标进行自适应的规范化。这在基于值的强化学习（value-based reinforcement learning）上很有用处——在基于值的强化学习中，当我们更新行为策略时，合适的值近似（value approximation）的量级可能会随时间改变。我们的主要动力是在学习玩 Atari 游戏上的前期成果，其中的奖励（ reward）被限定在了一个预先确定的范围内。这种截取（clipping）有利于使用单一的学习算法学习许多不同的游戏，但被截取过的奖励函数可能会导致不同性质的行为。使用这种自适应规范化（adaptive normalization），我们可以在不降低整体表现的情况下移除这种特定域的启发法（domain-specific heuristic）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心经授权发布，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系作者获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;点击「阅读原文」，下载此论文↓↓↓&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Mon, 22 Aug 2016 17:59:10 +0800</pubDate>
    </item>
    <item>
      <title>活动 | 语言与智能高峰论坛：共同探讨语言与智能领域的发展趋势和创新成果</title>
      <link>http://www.iwgc.cn/link/2382700</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9WnopMJW7r6wvVNnoiaWINhvViakM9oG2f1yywzrhFiaD4jy5fYx225Kz98upqp1xBPXK5TibKps9Vag/0?wx_fmt=png"/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9WnopMJW7r6wvVNnoiaWINhsUazhuSVgBbtsGPHR8jdDDRf0giceJYvYJVS2Jl7ic5Buz2IzCdeVEzA/0?wx_fmt=jpeg"/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;span&gt;如果回到五年多前的2010年，我们谁都无法料到，人工智能竟会如此精彩。智能助手，智能硬件，智能家居，智能汽车，智能机器人，…，机器开始能够听得懂我们在说什么，能够理解我们的语言，明白我们的意图，甚至帮助我们打理生活的方方面面。人工智能好像前所未有地距离我们如此之近，人们突然发现计算机已经变得这么聪明，其中人工智能这座山峰上的一颗明珠就是自然语言处理，即让机器理解我们人类的语言。如今，自然语言处理技术发展到什么程度？离强人工智能还有多远距离？未来的技术发展趋势如何？这些问题迫切值得研究和探讨。 &amp;nbsp; &amp;nbsp;基于此背景，中国中文信息学会和中国计算机学会将于2016年8月28日在北京国家会议中心联合举办“第一届语言与智能高峰论坛”。我们邀请了国内外相关领域、学术界和工业界的多名知名专家学者，共同探讨语言与智能领域的新发展和新技术通过高峰论坛，旨在向社会公众介绍国际语言与智能及相关领域的发展趋势和创新成果，进一步推动我国语言与智能技术领域的发展。本届论坛的主题为“语言智能与深度学习”，主要讨论“深度学习”，“大数据挖掘”，“语言智能的未来发展”等关键技术。&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9WnopMJW7r6wvVNnoiaWINhAyOsaVhh2HcTicNz9eudHytfZaDCich7pgp36VeaS7dLib3No1myfiaduQ/0?wx_fmt=jpeg"/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;特邀嘉宾&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9WnopMJW7r6wvVNnoiaWINhFAQhRt1ybOXUmdPRPdiaseWibozHYEwpLujPrwwAmRTQoCSn1apuYv6g/0?wx_fmt=jpeg"/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;张钹&lt;/section&gt;&lt;section&gt;清华大学计算机系教授，中国科学院院士&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9WnopMJW7r6wvVNnoiaWINhAyOsaVhh2HcTicNz9eudHytfZaDCich7pgp36VeaS7dLib3No1myfiaduQ/0?wx_fmt=jpeg"/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9WnopMJW7r6wvVNnoiaWINhZevU1FibaIlUZwhSYZia3kkibmeIgtuvnHqPzhrLBm0qRrAz6GEfLXHKw/0?wx_fmt=jpeg"/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;怀进鹏&lt;/section&gt;&lt;section&gt;中国科学院院士，计算机软件专家&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9WnopMJW7r6wvVNnoiaWINhAyOsaVhh2HcTicNz9eudHytfZaDCich7pgp36VeaS7dLib3No1myfiaduQ/0?wx_fmt=jpeg"/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9WnopMJW7r6wvVNnoiaWINhp5pxNgazuaXYToY8C1B9icWJicUiaUkyncRJhDR6p22NVcEG4QOe7ibZFw/0?wx_fmt=jpeg"/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;洪小文&lt;/section&gt;&lt;section&gt;微软亚太研发集团主席、微软亚洲研究院院长&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9WnopMJW7r6wvVNnoiaWINhAyOsaVhh2HcTicNz9eudHytfZaDCich7pgp36VeaS7dLib3No1myfiaduQ/0?wx_fmt=jpeg"/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9WnopMJW7r6wvVNnoiaWINhX7yFe0v2hibysNbELNZ7adrdGUf6NYfBtMNOFgrad50lVCp6IVT7yAQ/0?wx_fmt=jpeg"/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;王坚&lt;/section&gt;&lt;section&gt;阿里巴巴集团技术委员会主席&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9WnopMJW7r6wvVNnoiaWINhAyOsaVhh2HcTicNz9eudHytfZaDCich7pgp36VeaS7dLib3No1myfiaduQ/0?wx_fmt=jpeg"/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9WnopMJW7r6wvVNnoiaWINhCQicwTulb3siafpfcuvTPibKN3L97BYEKjf0PIYaf4NBYPX55uK7mkoNQ/0?wx_fmt=jpeg"/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;a class="" title="link" style="box-sizing: border-box;"&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;杨强&lt;/section&gt;&lt;section&gt;香港科技大学教授，美国人工智能协会（AAAI）&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/a&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9WnopMJW7r6wvVNnoiaWINhAyOsaVhh2HcTicNz9eudHytfZaDCich7pgp36VeaS7dLib3No1myfiaduQ/0?wx_fmt=jpeg"/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9WnopMJW7r6wvVNnoiaWINhyicWhCKskAGC6zsIlJ88ShOn4WEq4MfV1y2cZ1ozatN9kTY8dcuGOpA/0?wx_fmt=jpeg"/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;a class="" title="link" style="box-sizing: border-box;"&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;邢波&lt;/section&gt;&lt;section&gt;（Eric Xing）&lt;/section&gt;&lt;section&gt;美国卡耐基梅隆大学教授&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/a&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9WnopMJW7r6wvVNnoiaWINhAyOsaVhh2HcTicNz9eudHytfZaDCich7pgp36VeaS7dLib3No1myfiaduQ/0?wx_fmt=jpeg"/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9WnopMJW7r6wvVNnoiaWINhwXCo6fXLTdK1vOEygjicWOqn9dK6DL689WSr21jASUgc0wVMu0degicg/0?wx_fmt=jpeg"/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;王海峰&lt;/section&gt;&lt;section&gt;百度副总裁，ACL主席&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9WnopMJW7r6wvVNnoiaWINhAyOsaVhh2HcTicNz9eudHytfZaDCich7pgp36VeaS7dLib3No1myfiaduQ/0?wx_fmt=jpeg"/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9WnopMJW7r6wvVNnoiaWINh4BdxicHhz0q5Y32SOdSBhGJ2VPicoszMtGHo4ItVib7WgYDGDZKnHFA9A/0?wx_fmt=jpeg"/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;a class="" title="link" style="box-sizing: border-box;"&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;胡郁&lt;/section&gt;&lt;section&gt;科大讯飞高级副总裁，讯飞研究院院长&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/a&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9WnopMJW7r6wvVNnoiaWINhAyOsaVhh2HcTicNz9eudHytfZaDCich7pgp36VeaS7dLib3No1myfiaduQ/0?wx_fmt=jpeg"/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;会议日程&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;span&gt;09:10-09:10 &amp;nbsp; &amp;nbsp;&lt;/span&gt;&lt;span&gt;李生理事长致辞&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&amp;nbsp; &amp;nbsp;&lt;/section&gt;&lt;section&gt;09:10-09:20 &amp;nbsp; &amp;nbsp; &lt;span&gt;高文理事长致辞&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&amp;nbsp; &amp;nbsp;&lt;/section&gt;&lt;section&gt;09:20-10:00 &amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;span&gt;报告：怀进鹏&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&amp;nbsp; &amp;nbsp;&lt;/section&gt;&lt;section&gt;10:00-10:30 &amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;span&gt;茶歇，嘉宾合影&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&amp;nbsp; &amp;nbsp;&lt;/section&gt;&lt;section&gt;10:30-11:10 &amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;span&gt;报告：洪小文（人工智能时代）&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&amp;nbsp; &amp;nbsp;&lt;/section&gt;&lt;section&gt;11:10-11:50 &amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;span&gt;报告：王坚（互联网 数据 计算）&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&amp;nbsp; &amp;nbsp;&lt;/section&gt;&lt;section&gt;12:00-13:30 &amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;span&gt;午餐&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&amp;nbsp; &amp;nbsp;&lt;/section&gt;&lt;section&gt;13:30-14:10 &amp;nbsp; &amp;nbsp; &lt;span&gt;报告：张钹（人工智能与自然语言处理）&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&amp;nbsp; &amp;nbsp;&lt;/section&gt;&lt;section&gt;14:10-14:50 &amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;span&gt;报告：杨强（强化迁移学习）&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&amp;nbsp; &amp;nbsp;&lt;/section&gt;&lt;section&gt;14:50-15:30 &amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;span&gt;报告：邢波（Eric &amp;nbsp; Xing）&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&amp;nbsp; &amp;nbsp;&lt;/section&gt;&lt;section&gt;15:30-16:00 &amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;span&gt;茶歇&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&amp;nbsp; &amp;nbsp;&lt;/section&gt;&lt;section&gt;16:00-16:40 &amp;nbsp; &amp;nbsp; &lt;span&gt;报告：王海峰（理解语言、拥有智能）&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&amp;nbsp; &amp;nbsp;&lt;/section&gt;&lt;section&gt;16:40-17:20 &amp;nbsp; &amp;nbsp;&lt;span&gt;报告：胡郁（让机器能听会说、能理解会思考——语音和语言为入口的认知智能革命）&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&amp;nbsp; &amp;nbsp;&lt;/section&gt;&lt;section&gt;17:20-18:20 &amp;nbsp; &amp;nbsp;&lt;span&gt;语言与智能技术的未来发展（主持：孙乐，嘉宾：邢波、胡郁、马少平、聂建云、 &amp;nbsp; 王海峰、邢波、杨强、周明等)&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9WnopMJW7r6wvVNnoiaWINhAyOsaVhh2HcTicNz9eudHytfZaDCich7pgp36VeaS7dLib3No1myfiaduQ/0?wx_fmt=jpeg"/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;会议地点&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9WnopMJW7r6wvVNnoiaWINheib1FnBJ9iasg59Wl1uyClBJJiaibicLmIvaElic1dS2yibVMNrF1icphxqHaw/0?wx_fmt=jpeg"/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;strong&gt;机场路线：&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;机场出租车：在到达大厅外，有一排出租车的长队，由于发车间隔短所以并不会等待太久。在队伍的最前面，调度人员会给您当前您搭乘的出租车的车牌号，这在您需要投诉的时候会有用。出租车的费用根据具体里程会有不同，大致在100元到150元的范围内，但在晚上11点后，您需要支付更多费用。&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;北京地铁：&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;您可以在2号航站楼或者3号航站楼搭乘机场高速到三元桥站，然后转乘地铁10好线到西土城站，最后转乘地铁8号线到奥林匹克公园站。&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;机场大巴：&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;机场高速大巴在早上5：30到晚上8：00每30分钟一班，并且覆盖了不同的路线，请您乘坐到达亚运村（安慧桥）的路线5线。这将会花费25元。&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;a class="" title="link" style="box-sizing: border-box;"&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;参与方式 ：&lt;span&gt;点击阅读原文报名&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/a&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9WnopMJW7r6wvVNnoiaWINhAyOsaVhh2HcTicNz9eudHytfZaDCich7pgp36VeaS7dLib3No1myfiaduQ/0?wx_fmt=jpeg"/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Mon, 22 Aug 2016 17:59:10 +0800</pubDate>
    </item>
    <item>
      <title>招聘 | 寻找靠谱小伙伴，赶快加入机器之心与前沿同步！</title>
      <link>http://www.iwgc.cn/link/2382701</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;strong&gt;关于机器之心&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器之心是国内领先的前沿科技垂直媒体，关注人工智能、机器人、神经认知科学等前沿科技以及深度科技思考，旨在通过高质量内容让用户更好地了解即将到来的下一次技术变革，同时启发大家对人与科技的哲学思考。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器之心作为科技媒体在去年获得了这些成绩：&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;虎嗅「2015年度十大作者」&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;今日头条「2015最佳头条号」&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz/KmXPKA19gWibibP2SGxCcicwCiaAK5k9v7SsEKLdxjrxJtibJEbDBkatUZBzFl42FGfam4CUeJiac4qyvI6Z5Eyk458g/640?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在媒体之外，机器之心还与联想之星发起的Comet Labs一起为人工智能和智能机器领域的企业提供产业服务，帮助智能机器领域优秀的创业者解决投融资、产业对接、先导用户拓展、全球市场、技术整合、资金等关键问题，推动智能机器产业发展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器之心去年10月份获得了联想之星&lt;span&gt;Comet Labs&lt;/span&gt;的天使投资，为了生产更多的高质量内容，更好的提供产业服务，我们需要更多的小伙伴加入进来！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;span&gt;编辑（翻译方向，2名）&lt;/span&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;职位描述：&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;编译、校对英文文章；&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;撰写技术、产品、公司和行业相关文章；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;职位要求：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有全球视野；&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;卓越的的英语阅读、翻译能力；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对内容有品味，文字功底深厚；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对前沿科技充满兴趣和热情，&lt;/span&gt;&lt;span&gt;拥有迅速掌握某个特定行业或领域的学习能力；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;沟通能力强；&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;有技术背景优先。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;工作地点：北京&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;span&gt;记者（2名）&lt;/span&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;职位描述：&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;挖掘国内外人工智能领域的优秀创业公司并进行报道；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;能够独立完成对国内和海外的创业者、公司高管、行业专家、科研专家的深度专访；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;职位要求：&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1-2年媒体从业经验；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有全球视野；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对内容有品味，文字功底深厚；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对前沿科技充满兴趣和热情，&lt;/span&gt;&lt;span&gt;拥有迅速掌握某个特定行业或领域的学习能力；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;沟通能力强。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;工作地点：北京&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;span&gt;实习生&lt;/span&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;职位描述：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;网站、新媒体内容更新；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;翻译、校对英文文章。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;职位要求：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;理工科背景；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;出色的英语阅读、翻译能力；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;每周能保证2-3天坐班；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;积极的学习态度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;工作地点：北京&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;你将获得&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;具有市场竞争力的薪酬；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;作为创始团队成员获得的股权；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;深度参与下一次科技变革并享受到相应受益的机会。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;联系方式&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;将个人简历发送至&amp;nbsp;&lt;strong&gt;hr@almosthuman.cn&lt;/strong&gt;&amp;nbsp;，或添加个人微信&amp;nbsp;&lt;strong&gt;zhaoyunfeng1984&lt;/strong&gt;&amp;nbsp;。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Mon, 22 Aug 2016 17:59:10 +0800</pubDate>
    </item>
    <item>
      <title>深度 | 机器学习敲门砖：任何人都能看懂的TensorFlow介绍</title>
      <link>http://www.iwgc.cn/link/2369646</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自 kdnuggets&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;作者：Soon Hin Khor&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：Rick、吴攀、李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;本文是日本东京 TensorFlow 聚会联合组织者 Hin Khor 所写的 TensorFlow 系列介绍文章的前两部分，自称给出了关于 TensorFlow 的 gentlest 的介绍。这两部分谈到单一特征问题的线性回归问题以及训练（training）的含义，机器之心将继续关注本系列文章的后续更新。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;第一部分&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;引言&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们要解决的是一个过于简单且不现实的问题，但其好的一面是便于我们了解机器学习和 TensorFlow 的概念。我们要预测一个基于单一特征（房间面积/平方米）的单标量输出（房价/美元）。这样做消除了处理多维数据的需要，使我们能够在 TensorFlow 中只专注于确定、实现以及训练模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;机器学习简介&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们从一组收集到的数据点开始（见下图），每个数据点代表两个值之间的关系——输出（房价）与影响因素（房子面积）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicbSe4wxyQYKeacKqEQU3DccV9gPia8rcrz90TiaqEUsmOaicHBDSVOu1QNgRH6tiamQHdSOkYDvTPZ8Q/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然而我们无法预测没有数据点的特征的值（见下图）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicbSe4wxyQYKeacKqEQU3Dc8EjtGtkUdpskQyhcFvV5JRnWkichLlK0IKTX7Z8SprKtyVcs8cdDEqg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们可以使用机器学习来挖掘它们之间的关系（见下图的「最佳拟合预测曲线」），即给定一个不属于数据点的特征值，我们可以准确地预测出输出（特征值和预测线的交点）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicbSe4wxyQYKeacKqEQU3Dcbwr4wW3YRY1b9DcjHTibwlMQpDm5QQdbI7czaZ5GzJrZIMW1K61OZ7Q/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;步骤一：选择一个模型&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1.模型种类&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了使用机器学习来做预测，我们需要选择一个能够拟合收集到的数据的最佳模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们可以选择一个线性（直线）模型，并通过改变其陡度/梯度和位置对其进行调整，从而匹配数据点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicbSe4wxyQYKeacKqEQU3DccpdDfice0OmOPZXEchG153NZ9hf0Gh4FecxnhsqQOwmKIcHxupkgiaiaQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们也可以选择一个指数（曲线）模型，并通过改变其曲率（curvature）和位置对其进行调整，从而匹配同一数据点集。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicbSe4wxyQYKeacKqEQU3DcoMq8O7NQc0o2k8ibqwo9APsWskoyz75h3tQ9WStKeSgkDdRFfhzecww/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2.成本函数&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了比较哪个模型拟合得更严密，数学上我们将最佳拟合定义为一个需要被最小化的成本函数。 成本函数的一个简单样例是每个数据点所代表的实际输出与预测输出之间偏差的绝对值总和（实际结果到最佳拟合曲线的垂直投影）。用图表表示，成本函数被描述为下表中蓝色线段的长度和。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicbSe4wxyQYKeacKqEQU3Dcnk4kZYVFmb2iaXMoloMgYFw9r5xcltvUR6pCM7VCLcicm604BXBJmViaw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;注意：更准确地说，成本函数往往是实际输出和预测输出之间的方差，因为差值有时是负数；这也称为最小二乘法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3.线性模型简介&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;秉持简洁精神，我们将使用线性模型来对数据点进行建模。线性模型的数学表示是：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;y = W.x + b&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp;Where:&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp;x: house size, in sqm&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp;y: predicted house price, in $&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了调整模型来更好地拟合数据点，我们可以这样做：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;调整 W 来改变线性模型的梯度&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicbSe4wxyQYKeacKqEQU3Dc1TibeGM5FkKT200VW25EuHXRl9EicLLP7aWZYfYs40AXNaC5ByONtDicg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;调整 b 来改变线性模型的位置&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicbSe4wxyQYKeacKqEQU3DcDNKfhUKxM8BUmCugHCUS9xLxUOT3ibfJmnUak2CiasINLjRgtKdwAG5A/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过使用许多个 W、b 的值，最终我们可以找到一个最佳拟合线性模型，能够将成本函数降到最小。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除了随机尝试不同的值，有没有一个更好的方法来快速找到 W、b 的值？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;4.梯度下降&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你试图从山上下降到最低点，你的视角就是这个样子。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicbSe4wxyQYKeacKqEQU3DcKuNRupC31LOtMsM594nEnPJrWQerrYjDibTftmPkzyrtRb8MpnrHkGg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下降趋势并不明显！其最佳方式是执行梯度下降：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;在当前位置以最陡的下降梯度确定方向&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;在该方向上采取步长 X&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;重复 &amp;amp; 刷新；这就是训练过程&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最小化成本函数是类似的，因为成本函数就像是起伏的山，我们想要找到其中的最低点，我们可以通过梯度下降类似地实现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicbSe4wxyQYKeacKqEQU3DcHEEWaptX2KuicRcTNTgoSmicTzibibP66c26Ddj5xqevxnMxmmgib6W4Eyw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在我们有了线性模型、成本函数和梯度下降的概念，可以开始使用 TensorFlow 了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;步骤二：在TensorFlow 中建立模型&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1.TensorFlow 中的线性模型&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;TensorFlow 的2个基本组件是：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;占位符（Placeholder）：表示执行梯度下降时将实际数据值输入到模型中的一个入口点。例如房子面积 &amp;nbsp;(x) 和房价 (y_)。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicbSe4wxyQYKeacKqEQU3DcSP6oVTgoEm0NBBZe6IlWdzdxRatWk25HsTQauJLQEibkTj9AWey57icw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;变量：表示我们试图寻找的能够使成本函数降到最小的「good」值的变量，例如 W 和 b。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicbSe4wxyQYKeacKqEQU3Dcia1yv9ib6DViaSEkicnC4nTROjOsWDOXtFwdkXL0zqJibX77yuiaftSJ6hug/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然后 TensorFlow 中的线性模型 (y = W.x + b) 就是：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicbSe4wxyQYKeacKqEQU3DcDytsxjFZnRYibqKiaDbak5WWb87ZhtIy47drY5qoxFg9RSpWjcaFhSjQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2.TensorFlow 中的成本函数&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;与将数据点的实际房价 (y_) 输入模型类似，我们创建一个占位符。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicbSe4wxyQYKeacKqEQU3DcxztlVwk8WYWXjdFPs5ebcibwQwNq9dWDT6O2ezYB9lx8t5S4P9xuEjQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;成本函数的最小方差就是：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicbSe4wxyQYKeacKqEQU3DcpFQPwJLGZKtNMyLiczVEgwrwRPDnxEQS7AQyIhwzacDwIE9NfyicE5Bw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3.数据&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;由于没有房价(y_) 和房子面积 (x) 的实际数据点，我们就生成它们。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicbSe4wxyQYKeacKqEQU3Dc8M7UBFoPsWRwGdm5pZMhutI0FrLCaypXY27fcfRRUUjV8jmiaHk5PXg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;简单起见，我们将房价 (ys) 设置成永远是房子面积 (xs) 的 2 倍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;4.梯度下降&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有了线性模型、成本函数和数据，我们就可以开始执行梯度下降从而最小化代价函数，以获得 W、b 的「good」值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicbSe4wxyQYKeacKqEQU3DcuPY3TFuh3Od8JRlw2qdmdqRqHBic4zeMvwql4ibeaicDdxxdGKaxrbVYg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;0.00001 是我们每次进行训练时在最陡的梯度方向上所采取的「步」长；它也被称作学习率（learning rate）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;步骤三：训练模型&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;训练包含以预先确定好的次数执行梯度下降，或者是直到成本函数低于某个预先确定的临界值为止。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1.TensorFlow 的怪异&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所有变量都需要在训练开始时进行初始化，否则它们可能会带有之前执行过程中的残余值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicbSe4wxyQYKeacKqEQU3DcSh70rUiac7u0QFicDrfGfmbXdwjUFXsQQOgyDY8a89yeaVWyjMQmbQXw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2.TensorFlow 会话&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然 TensorFlow 是一个 Python 库，Python 是一种解释性的语言，但是默认情况下不把 TensorFlow 运算用作解释性能的原因，因此不执行上面的 init 。相反 TensorFlow 是在一个会话中进行；创建一个会话 (sess) 然后使用 sess.run() 去执行。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicbSe4wxyQYKeacKqEQU3Dc5qk3mH3HOicTbpW8EDqib8Ihicl1AeZpLTTOCXt9yrJFozoamQia7D3CXA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;类似地我们在一个循环中调用 withinsess.run() 来执行上面的 train_step。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicbSe4wxyQYKeacKqEQU3Dc21tQgkv1Xphtt0F7O994mQiaNfHWPwfB3RXl8HWiaTCdCEaVMhYI5jTA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你需要将由 x, y_ 所组成的实际数据输入再提供给输入，因为 TensorFlow 将 train_step 分解为它的从属项：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicbSe4wxyQYKeacKqEQU3Dc38wdj9jPS1rZpTtsBfaqBBKFL4WLmNxicYfLcddNAAJU1YDVrL5M5pg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从属项的底部是占位符 x，y_；而且正如我们之前提到的，tf.placeholders 是用来表示所要提供的实际数据点值房价 (y_) 和房子面积 &amp;nbsp;(x) 的位置。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;结果&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;循环中的 print 语句将显示 TensorFlow 如何在每次迭代中学习 W 和 b 的「good」值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicbSe4wxyQYKeacKqEQU3Dc0UwwH4AyibHXU3F36K7Weic25WZk74MhLxIvZQFqzVLnUy2V0BticK2Zg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;小结&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们已经以最简单的形式学习了机器学习；从一个单一特征预测结果。（为简单起见）我们选择了一个线性模型来拟合我们的数据点，定义一个成本函数来表示最佳拟合，并通过反复调整其梯度变量 W 与位置变量 b 来训练我们的模型，使成本函数降到最小。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;第二部分&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;简单回顾&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在上一部分，我们使用 TensorFlow 构建并学习了一个带有单一特征的线性回归模型——给定一个特征值（房屋面积/平方米），我们可以预测输出（房价/美元）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面是一些总结：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="list-style-type: decimal;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;我们有一些房屋面积和房价的数据（灰色点）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;我们使用线性回归对这些数据进行了建模（红色虚线）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;我们通过训练该线性回归模型的 W（权重）和 b（偏置）找到了最小化「成本」（竖直蓝色实线的长度总和，这些蓝线代表了预测和实际输出之间的差异）的「最好」模型&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;给定任意房屋面积，我们可以使用该线性模型预测房价（带箭头的蓝色虚线）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicbSe4wxyQYKeacKqEQU3DcnA7GubTibA6P7WHH4ZzghoTP4pPODoBV0BNhVic0R1Mw81W5v9cIOUrQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;一张图解释线性回归&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在机器学习文献中，我们常常看到「训练（training）」这个词。在这一部分，我们将在 TensorFlow 中理解「训练」的含义。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;线性回归建模&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;Linear Model (in TF notation): y = tf.matmul(x,W) + b&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;线性回归的目标是寻找 W 和 b，这样对于给定的任意特征值 x，我们可以通过将 W、b 和 x 的值代入到模型中得到预测 y。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是为了找到能准确做出预测的 W 和 b 的值，我们需要使用可用的数据（许多实际特征 x 和实际输出 y_ 的配对，注意下划线）来「训练」该模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;解释「训练」&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了找到最佳的 W 和 b 值，我们可以从任意的 W 和 b 值开始。我们也需要定义一个成本函数，该函数可以衡量对于一个给定特征值 x 预测输出 y 和实际输出 y_ 之间差异。为了简单起见，我们使用最简单的最小均方误差（MSE：minimum squared error）作为我们的成本函数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;Cost function (in TF notation): tf.reduce_mean(tf.square(y_ - y))&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过最小化成本函数，我们可以得到很好的 W 和 b 值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们的训练代码实际上非常简单，并且用 [A, B, C, D] 进行了注释，后面我们还会谈到这些代码。完整代码请访问：https://github.com/nethsix/gentle_tensorflow/blob/master/code/linear_regression_one_feature_using_mini_batch_with_tensorboard.py&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;# ... (省略) 变量/常量声明 ...&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;# [A] TensorFlow图&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;y = tf.matmul(x,W) + b&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;cost = tf.reduce_mean(tf.square(y_-y))&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;# [B] 用固定「学习率（learn_rate）」训练&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;learn_rate = 0.1&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;train_step =&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; tf.train.GradientDescentOptimizer(learn_rate).minimize(cost)&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;for i in range(steps):&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp; # [C] 准备数据点&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp; # ... (省略) 准备作为x和y的数据点的代码 ...&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp; # [D] 在每个步骤/epoch将数据送入'train_step'&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp; feed = { x: xs, y_: ys }&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp; sess.run(train_step, feed_dict=feed)&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们的线性模型和成本函数[A]可以表示成下面的 TensorFlow 图：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicbSe4wxyQYKeacKqEQU3DcLN7XsX7p6YtnxiacUT7muQVJSTUk411AXH7Z6dyiaEDQHgw2uQo9EOJA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;创造一个带有模型和成本函数的 TensorFlow 图，并使用一些值初始化 W 和 b&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;接下来，我们选择一个数据点 (x, y_) [C]，然后将其送入[D] TensorFlow 图，从而得到预测 y 和相应的成本。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicbSe4wxyQYKeacKqEQU3DcpneqJG1yESjhsYn4By9fBnBU27TrSLicGPq0QGqVD74FicwYGSuzQgag/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;使用单个数据点计算预测 y 和成本&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了得到更好的 W 和 b，我们使用TensorFlow 的 tf.train.GradientDescentOptimizer [B]执行梯度下降以降低成本。用非技术的术语来说：给定当前成本，并基于成本岁其它变量（即 W 和 b）的变化方式，优化器（optimizer）将对 W 和 b 执行一些小调整（递增或递减）以使我们的预测更好地契合那个单个数据点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicbSe4wxyQYKeacKqEQU3DcDQAw9LUSRpRWsM55jsWLnjCHIPc5wRbZibyAPf099re1UicmyJTib3Lew/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;基于当前的成本，决定如何调整 W 和 b 以提升预测 y 和降低成本&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;训练周期中的最后步骤是在调整 W 和 b 对它们进行更新。注意这里的「周期」用机器学习的术语来说是「epoch」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicbSe4wxyQYKeacKqEQU3Dc3zW8rFpk1FaVhGyfCunkicMWzSibYPnHystjp9ibgTHxtaeB5Z3moq5Qg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;在下一训练 epoch 的迭代前，通过调整 W 和 b 对它们进行更新&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在下一训练 epoch 中，重复这些步骤，但使用一个不同的数据点！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicbSe4wxyQYKeacKqEQU3DcyZD7wSI08l1jFpGfq3f9Jto90FciajBw0gia8CgxicckSCtwZ2BtJbABw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;使用不同的数据点进行训练&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;使用各种数据点泛化（generalize）我们的模型，即学习可被用于预测任何特征值的 W 和 b 值。注意：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;在大部分情况下，数据点越多，模型的学习和泛化就越好&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如果你训练的 epoch 比数据点还多，你可以重复使用数据点，这不成问题。梯度下降优化总是会同时使用数据点及其成本（根据该 epoch 的 W 和 b 值从数据点中计算得到）来对 W 和 b 值进行调整；该优化器也许之前已经见过了这个数据点，但成本并不一样，因此它还是可以学到新的东西，并以不同的方式调整 W 和 b 值。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你可以用固定数量的 epoch 训练一个模型，直到其达到令人满意的成本阈值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;训练变量&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1.随机、mini-batch、batch&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在上面的训练中，我们在每个 epoch 送入单个数据点。这被称为随机梯度下降（stochastic gradient descent）。我们也可以在每个 epoch 送入一堆数据点，这被称为 mini-batch 梯度下降，或者甚至在一个 epoch 一次性送入所有的数据点，这被称为 batch 梯度下降。请看下图的比较，注意这 3 张图的 2 处不同：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;每个 epoch 送入 TensorFlow 图（TF.Graph）的数据点的数量（图右上方）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;梯度下降优化在调整 W 和 b 值时所考虑的数据点的数量（图右下方）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicbSe4wxyQYKeacKqEQU3Dc3zW8rFpk1FaVhGyfCunkicMWzSibYPnHystjp9ibgTHxtaeB5Z3moq5Qg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;随机梯度下降&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicbSe4wxyQYKeacKqEQU3DcLvibCZ8DyP39YJ33zicnpyMTZdfsqDa1DLYrVYcv0K4kb9taMnXooA4A/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;mini-batch 梯度下降&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicbSe4wxyQYKeacKqEQU3DcI38v7IgfH1jkGF8ZcBibyegmU1DSZvKZNL3q7ffIVxB9I6euDJAuAiaA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;batch 梯度下降&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;每张图中的数据点的数量有 2 个含义。当数据点更多时：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;计算成本和执行梯度下降所需的计算资源（减法、平方、加法）会增加&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;模型的学习和泛化的速度增加&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;选择随机、mini-batch、batch 梯度下降的优缺点总结在下图中：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicbSe4wxyQYKeacKqEQU3Dc43MS0408A6nKqeHxtCjQDVdlGbJvrUDiaFY0iaNCLpllt5DwDaDuMicAg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;选择随机、mini-batch、batch 梯度下降的优缺点&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;要在随机/mini-batch/batch 梯度下降之间切换，我们只需要在将数据点送入训练步骤[D]之前将这些数据点分成不同的 batch 大小，即为 [C] 使用如下的代码片段：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;# * all_xs: 所有的特征值&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;# * all_ys: 所有的输出值&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;# datapoint_size: all_xs/all_ys 中点/项的数量&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;# batch_size: 配置如下:&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;# &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 1: 随机模型&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;# &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; integer &amp;lt; datapoint_size: mini-batch模式&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;# &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; datapoint_size: batch模式&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;# i: 当前epoch数量&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;if datapoint_size == batch_size:&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp; # Batch 模式，所以选择所有数据点从 index 0 开始&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp; batch_start_idx = 0&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;elif datapoint_size &amp;lt; batch_size:&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp; # 不可能&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp; raise ValueError(“datapoint_size: %d, must be greater than &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; batch_size: %d” % (datapoint_size, batch_size))&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;else:&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp; # 随机/mini-batch模式: 从所有可能的数据点中分批选择数据点&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp; batch_start_idx = (i * batch_size) % (datapoint_size — batch_size)&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp; batch_end_idx = batch_start_idx + batch_size&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp; batch_xs = all_xs[batch_start_idx:batch_end_idx]&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp; batch_ys = all_ys[batch_start_idx:batch_end_idx]&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;# 将分批的数据点定义为xs, ys, 它们会被送入 'train_step'训练步骤&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;xs = np.array(batch_xs)&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;ys = np.array(batch_ys)&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2.学习率变化&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;学习率（learn rate）是指梯度下降调整 W 和 b 递增或递减的速度。学习率较小时，处理过程会更慢，但肯定能得到更小成本；而当学习率更大时，我们可以更快地得到最小成本，但有「冲过头」的风险，导致我们没法找到最小成本。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了克服这一问题，许多机器学习实践者选择开始时使用较大的学习率（假设开始时的成本离最小成本还很远），然后随每个 epoch 而逐渐降低学习率。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;TensorFlow 提供了 2 种方法可以做到这一点，详细解释可参考：http://stackoverflow.com/questions/33919948/how-to-set-adaptive-learning-rate-for-gradientdescentoptimizer；但这里进行了总结。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;使用梯度下降优化的变体&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;TensorFlow 带有多种支持学习率变化的梯度下降优化器，例如 &amp;nbsp;tf.train.AdagradientOptimizer 和 tf.train.AdamOptimizer.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;使用 tf.placeholder 调整学习率&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如同前面所看到的，如果我们在这个例子中声明了 tf.placeholder 来设置学习率，然后在 tf.train.GradientDescentOptimizer 中使用它，我们可以在每个训练 epoch 向其送入一个不同的值，这很像我们给 x 和 y_ 送入不同的数据点，这也是每个 epoch 的 tf.placeholders.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们需要 2 个小修改：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;# 修改 [B] ，将 'learn_rate' 设置为'tf.placeholder'&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;# 并将其提供给'learning_rate'参数名tf.train.GradientDescentOptimizer&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;learn_rate = tf.placeholder(tf.float32, shape=[])&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;train_step = tf.train.GradientDescentOptimizer(&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; learning_rate=learn_rate).minimize(cost)&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;# 修改[D]，包含送入一个'learn_rate'值,&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;# 即 'initial_learn_rate'（初始学习率）除以'i' (当前epoch数)&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;# 注: 这是过于简化的，仅用作示例&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;feed = { x: xs, y_: ys, learn_rate: initial_learn_rate/i }&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;sess.run(train_step, feed_dict=feed)&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;小结&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们解释了机器学习中「训练（training）」的含义，以及在 TensorFlow 中通过模型和成本定义、然后循环通过训练步骤（将数据点送入梯度下降优化器）来进行训练的方式。我们还讨论了训练中的常见变量，即改变模型学习时每个 epoch 所用的数据点的大小和改变梯度下降优化器的学习率。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;后续内容&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;创建 Tensor Board 来可视化 Tensorflow 的执行，从而检测我们的模型、成本函数或梯度下降中的问题&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;使用多个特征表达线性回归&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Sun, 21 Aug 2016 13:18:45 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 微软研究院Microsoft Translator产品战略总监：智能翻译背后的技术和愿景</title>
      <link>http://www.iwgc.cn/link/2369647</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;转自 微软研究院&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;作者：Olivier Fontana（微软研究院Microsoft Translator产品战略总监）&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;世界越来越小，全球协作、共同创新已经成为常态。在微软研究院，我们对此尤为感同身受——从北京到雷德蒙，从剑桥到班加罗尔，全球范围内的无边界沟通与协作是我们科研合作与产品创新的关键基础。全球一体化带来的发展机遇应该属于每个人，为了帮助全球各地的人们跨越语言的障碍，实现高效沟通与广泛协作，我们带来了 Microsoft Translator。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Microsoft Translator 是微软以机器学习、大数据、自然语言和云计算等前沿技术为基础打造的自动翻译服务，也是微软众多人工智能研究成果中投入使用最早也最广泛的应用之一。Microsoft Translator 现已支持 50 多种语言的文本翻译、8 种语言的实时语音翻译和 18 种语言的语音识别和输出。就在 2016 年 7 月底，我们在中文简体和繁体的基础上，最新加入了粤语文本翻译，进一步完善了对汉语应用环境的支持。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;自我学习的智能翻译&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「统计机器翻译」是 Microsoft Translator 背后的主要技术，它以微软十几年来在自然语言领域的研究为基础，加入了统计学与机器学习的原理。简单地说，这套翻译体系将「翻译」转变成了一个机器学习的课题，让计算机不断地对训练数据中的人工译文和语言转换结果进行判断与学习，在不断的纠错与改正中，促进系统算法的自我完善与优化。通过统计建模技术和高效的算法，不断学习优化的机器翻译系统能学会根据上下文的语境，而不是单词的意思和生硬的语法规则来匹配最恰当的翻译结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW92ZADSyWaB13W63psanKSSt6cycDGVvCL7tp3Q7v2XRy89b0FRBeMnQOlibsAXjEVDKj56LTs6kgA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;要说 Microsoft Translator 的智能来自于机器学习、自然语言等技术，而它的可靠运行与不断优化，则离不开微软在各领域的资源优势。例如，作为一项云服务，Microsoft Translator 运行于 Microsoft Azure 云平台，Azure 提供了机器学习等高级分析功能的运行平台，同时也确保了其作为 SaaS 云服务的高可用性和数据安全性，并且它还可以根据需要弹性扩展运算规模。另一方面，覆盖全球的必应搜索引擎，也为 Microsoft Translator 提供了全球规模的语言素材与学习资料，让机器学习系统得以不断地成长和完善。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;与此同时，微软旗下多样化的产品与服务，也为 Microsoft Translator 提供了施展才华的广阔天地。从 2006 年起，Microsoft Translator 便逐渐开始为越来越多的微软产品提供自动文本翻译功能，例如 Office、必应搜索、IE 和 Edge 浏览器、Skype、微软小娜（Cortana）等等。或许你还没有意识到，但它其实一直都在你身边——在电脑的 Word界面中点击「审阅」菜单项，然后选择「翻译」图标，你就能领略到 Microsoft Translator 的本领了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;让你自然交流的智能语音翻译&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 2016 年 3 月底举办的 Build2016 微软开发者大会上，微软 CEO 萨提亚·纳德拉指明了微软乃至 IT 产业未来的一个发展方向：让人类的自然语言与先进的机器智能进行交互，也就是「对话即平台（Conversation as a Platform）」的概念，并且发布了「微软机器人框架（Microsoft Bot Framework）」以及微软认知服务（Microsoft Cognitive Service），用以帮助开发者打造新一代的人工智能应用。事实上，作为一个能听会说多种语言的人工智能服务，Microsoft Translator 在语音翻译服务方面已经提前取得了成功的实践。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW92ZADSyWaB13W63psanKSSk7Q07icEodt8MOMIOKAD6MVYjqZb9aTkOu8R5YbDFMibcfTtCE3ibW4DQ/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;微软认知服务&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;早在 2014 年，Microsoft Translator 即推出了语音翻译服务，2016 年 3 月又面向开发者开放了语音翻译的 API。目前 Microsoft Translator 支持对包括中文普通话在内的8种语言的实时语音翻译（英语、法语、中文、德语、意大利语、西班牙语、阿拉伯语、葡萄牙语）。在 Skype Translator 以及 Windows、iOS 或者 Android 版的 Microsoft Translator 应用中，你都可以体验到这项私人实时口译服务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;语音翻译要比文本翻译复杂得多，需要经过自动语音识别（ASR）、TrueText 智能文本校正、自动文本翻译以及文本到语音转换（TTS）四个步骤。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW92ZADSyWaB13W63psanKSSltYsLKoibHRXehHdFBFRQdKZibb9oWS74uThZvXicmwzuSjericyvn4aDg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其中，自动语音识别借助深层神经网络，对数千小时不同语言的音频数据进行分析和学习，以达到「听懂」人类自然语音的目的——基于机器学习，语音识别的效果也会随数据的积累而不断完善。TrueText 智能文本校正则负责将人们口语化的交流转换为规范的文本，比如，去掉「嗯」、「啊」、「这个」、「那个」之类的赘词以及重复、口吃等语病，并添加断句、标点符号，从而让文本更贴近用户本来的意图，也更易阅读和翻译。在文本翻译基础上增强的语音翻译引擎，增加了更多口语文本语料库，从而为口语会话类翻译构建了更好的模型。最后是文本到语音的转换过程，如果翻译的目标语言是 Microsoft Translator 目前所支持的 18 种转换语言之一，那么就能使用语音合成技术将翻译后的文本转换成语音播放出来。整个语音翻译过程中，深层神经网络（DNNs）技术的引入，则极大程度地降低了翻译的错误率，提高了可靠性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW92ZADSyWaB13W63psanKSShYGC7eKhjVlZdBqQG7te9SB0HkgL5ZGLm0ZE8podzU4nXXVcIky7CA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;带上你的私人翻译，畅行天下&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了让更多用户可以随时随地、便捷地使用翻译服务，Microsoft Translator 面向不同平台推出了移动端应用。这款应用不仅适用于 Windows 设备，同时还支持使用 iOS、Android 平台的设备，甚至包括 Apple Watch 和 Android Wear 智能手表。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW92ZADSyWaB13W63psanKSScwr1rBpE9WgmnwL6qw4CdTIJzaTZSlFmvqvP5d8kPMrnoGQ9yiacxvg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;运行于智能终端的 Microsoft Translator 经过持续的完善与升级，目前已经发展的非常成熟，不但支持众多语言的翻译功能，而且还可以提供离线翻译选项。用户既可以用键盘输入或者粘贴文本，也可以利用麦克风直接录入语音，或者是将看到的外国文字拍摄下来，让软件自动识别并翻译。在最新版本中，我们还加入了支持 8 种语言的实时语音翻译功能，让语言不通的两个人，仅凭一部手机就能进行面对面的实时语音交流。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Microsoft Translator 移动端应用绝对是海外旅行必备的利器，它不但可以帮我问路，还能靠拍照辨认街道、商铺和没有图片的菜单，甚至可以让我和五湖四海的新朋友进行一次真正有意义的谈话，真正体会到四海一家的畅快沟通。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在中国越来越流行的「海淘」则是 Microsoft Translator 的另一个用武之地。基于Microsoft Translator 技术的必应翻译（bing.com/translator）提供了在线文本翻译和网站翻译功能，只需输入你的海淘网址，就能实现整个网页的机器翻译，并且同样支持 50多种语言，让你的海外购物无障碍。Windows 10 用户通过添加 Edge 浏览器的 Translator 扩展插件，即可一键翻译整个网页或者文本。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW92ZADSyWaB13W63psanKSSZRcEHBJ4eKcX15X3NBrtNRpib8PB8ryfB2iavewG621HEEaQPeQXuN1Q/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在你最熟悉的微信中，也有 Microsoft Translator 的身影。只需在对话界面中，长按对话气泡内出现的法语、日语或者阿拉伯语等文本，选择「翻译」，就会出现「微软翻译」给你带来的中文译文。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;企业要国际化，还是本土化？我们都能帮忙&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在全球市场一体化的今天，Microsoft Translator 在商业领域和企业市场的应用前景也越发清晰起来。无论是海外企业拓展中国市场的本土化改造，还是中国企业出海发展的「走出去」战略，我们都能助一臂之力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Microsoft Translator 所提供的文本和语音翻译服务，可以帮助跨国企业实现无障碍的内部沟通和内部培训、面向全球市场提供客户支持、建设在线社区，并实现网站、文档资料、商业智能的实时、双向或多向的翻译。相比传统的本土化手段，作为云服务出现的 Microsoft Translator 提供了按需付费的低成本、可定制的跨平台开发和接入能力，可以确保符合企业IT的安全策略，并提供了业界唯一支持行业用户定制的翻译语料库。目前，Microsoft Translator 已经服务于全球上千家企业客户，包括亚马逊、eBay、Twitter、惠普、戴尔等，都在各自的业务全球化、本土化领域中得到了 Microsoft Translator 的帮助。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW92ZADSyWaB13W63psanKSSqGMvdUibLSaiaKialVWCPQ35XwiaTgviblXib5419gbibPuicaPI25zRFP7UiaA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 7 月份刚刚结束的 WPC 2016 微软合作伙伴大会上，微软宣布将在今年年底前为Office 365 企业用户提供 Skype Meeting Broadcast 服务，它可以自动为网络会议添加字幕，并将会议实时地翻译成不同语言展现出来——这同样都是基于 Microsoft Translator 实现的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;开放的 API 带来开放的发展机遇&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今天的微软是一家生产力与平台公司，我们致力于打造创新平台，助力合作伙伴和生态系统的共同发展。在应用前景广阔的智能文本和语音翻译领域，Microsoft Translator 也为人们带来了创新机遇。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;事实上，从 2011 年起，Microsoft Translator 便开放了 API，并以 Azure 云平台 SaaS 服务的形式向第三方提供云端接入服务。目前，全球已有数千家客户在使用此服务，来实现网站本地化、多语言客户支持、电子商务、社交媒体、网络游戏、商业智能等典型应用场景。Microsoft Translator API 可以轻松实现跨平台接入第三方系统及应用，开发者只需在 Azure Data Market 网站 （datamarket.azure.com/browse/Data）上注册使用，即可获得每月 200 万字符的免费翻译服务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;微软的使命是予力全球每一人、每一组织成就不凡。我们希望 Microsoft Translator 通过微软的产品为消费者提供服务的同时，可以予力更多开发者和企业，为全球更多用户提供多样的翻译服务，打破语言间的壁垒，促进世界各地人们的沟通、交流。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心经授权发布，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系作者获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Sun, 21 Aug 2016 13:18:45 +0800</pubDate>
    </item>
    <item>
      <title>学界 | 谷歌最新论文：使用循环神经网络的全分辨率图像压缩</title>
      <link>http://www.iwgc.cn/link/2369648</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自 arXiv.org&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;作者：George Toderici、Damien Vincent等人&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW92ZADSyWaB13W63psanKSSyK4XWEtic7y6RMQkicJICtR6gkeiaA9z9sfqmTMbhwsn9sSgloayQiaEZA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;摘要&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本论文提出了一套基于神经网络的全分辨率有损图像压缩方法。这些我们所描述的每一种架构都可以在实施过程中提供可变的压缩率，而不需要对网络进行再训练（retraining）：每个网络只需要训练一次。我们所有的架构都由一个基于循环神经网络（RNN：recurrent neural network）的编码器和解码器、一个 binarizer 和一个用于熵编码（entropy coding）的神经网络构成。我们对 RNN 的类型（LSTM、关联 LSTM（associative LSTM）进行了比较，并引入了一种新的 GRU 和 ResNet 的混合结构。我们还研究了 one-shot 与附加重建架构（additive reconstruction architectures）的对比，并引入了一种新的扩展过的附加框架。对比之前的研究成果，我们的成果显示出了 4.3%-8.8% AUC（率失真曲线下的区域）提升，具体数字取决于所用的感知标准（perceptual metric）。就我们所知，在 Kodak 数据集图像的率失真曲线（rate-distortion curve ）的大部分比特率的图像压缩上，这是第一个表现优于 JPEG 的神经网络架构，不管有没有熵编码的辅助。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWicbSe4wxyQYKeacKqEQU3DcgjFHUAT5uLslF1cnRpfm6wHqBKxApicSXNVMEMhib6UZ3ibE5ibXlEc6hw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 1：我们共享的 RNN 架构的单次迭代&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;点击「阅读原文」，下载此论文↓↓↓&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;</description>
      <pubDate>Sun, 21 Aug 2016 13:18:45 +0800</pubDate>
    </item>
    <item>
      <title>深度 | 英伟达自动驾驶技术解读：用于自动驾驶汽车的端到端深度学习（附论文）</title>
      <link>http://www.iwgc.cn/link/2360659</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自NVIDIA&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;作者：Mariusz Bojarski, Ben Firner, Beat Flepp, Larry Jackel, Urs Muller and Karol Zieba&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：Rick、吴攀、李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在新型汽车应用中，我们使用卷积神经网络（CNN）将从前向摄像机得到的原始图像映射成自动驾驶汽车的驾驶命令。这种强大的端到端方法意味着只需要极少的来自人类的训练数据，该系统就能学会驾驶，且不管有没有车道标志，也不管是在地方道路上还是在高速公路上。该系统还能在停车场或未铺好的道路等没有明显视觉指引的地方运行。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW92ZADSyWaB13W63psanKSSkO86FHcibicbmSz9hkQYjFU9NV51X2fqAuuLiaAcfMwS5kVHAiaLPpQVAw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图1：英伟达的行驶中的自动驾驶汽车&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们使用了一个运行 Torch 7 的 NVIDIA DevBox 来设计用于训练的端到端的学习系统。&lt;/span&gt;&lt;span&gt;一台也带有 Torch 7 的 NVIDIA DRIVETM PX 自动驾驶计算机被用于确定行驶路线——以 30 帧每秒（FPS）的速度运行。该系统被训练用于自动学习必要处理步骤的内部表征，比如在只有人类转向角度作为训练信号的情况下，检测有用的道路特征。我们从未明确地训练它用于检测道路轮廓等事物。与运用车道标记检测、路径规划和控制等确切的问题分解方法相反，我们的端到端系统会同时优化所有处理步骤。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们相信端到端的学习可以带来更好的性能以及更小巧的系统。性能的提升是来内部组件的自我优化，以最大限度地提高整体系统的性能，而不是优化人类所选择的中间标准，比如车道线检测。为了人类理解的方便而选择这样的标准是可以理解的，虽然它不会自动保证最大化的系统性能。因为系统学习解决这一问题只需最小数量的处理步骤，所以更小的网络是可能的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本文基于 NVIDIA 的论文《End to End Learning for Self-Driving Cars》。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;处理视觉数据的卷积神经网络&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;卷积神经网络已经彻底改变了计算模式识别过程。在它得到广泛采用之前，大多数模式识别任务还是使用人工提取特征并放入分类器的初始阶段。卷积神经网络的重要突破在于现在可以从训练样本中自动学习特征。当它被应用在图像识别任务中时则尤其强大，因为卷积运算会捕获图像的二维特点。与该运算总数相比，使用卷积核（convolution kernel）扫描一张完整图像所需要学习的参数相对较少。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尽管拥有特征学习的卷积神经网络已投入商业应用 20 余年，但由于两项重要的进展，其使用者近年来才出现数量激增。第一个是带有标签的大数据集的发展，比如 ImageNet 大规模视觉识别挑战赛（ImageNet Large Scale Visual Recognition Challenge / ILSVRC）目前被广泛用于训练和验证。第二个是卷积神经网络学习算法现在可以部署在大规模并行图形处理单元（GPU）上，这能极大地提升学习与推理能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们这里所描述的卷积神经网络超越了基本的模式识别。我们开发的系统会学习自动驾驶所需的整个处理进程。这个项目的基础成果实际上是美国国防部高级研究项目局（DARPA） 于10 年前完成的、被称作 DARPA Autonomous Vehicle （DAVE）的播种项目——一辆小型无线电控制（RC）汽车行驶过一条由垃圾填充的小路。DAVE 在与人类驾驶环境类似但不完全相同的环境中训练了几个小时。训练数据包括来自两个摄像机的视频以及人类操作员所发送的转向命令。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;DAVE 在许多方面是受到 Dean A. Pomerleau 的开创性工作的启发，他于 1989 年构建了神经网络中的自动驾驶陆地载具（ALVINN：Autonomous Land Vehicle in a Neural Network ）系统。ALVINN 是 DAVE 的前身，它提供了这样一个概念的原始证明：即端到端训练的神经网络某天或许能够在公共道路上驾驶汽车。DAVE 证明了端到端学习的潜力，并且它确实被用来解释启动 &amp;nbsp;DARPA 应用于地面机器人的学习（DARPA Learning Applied to Ground Robots / LAGR ）项目的原因，但是 DAVE 的表现并不足以令人相信它能够完全替代越野驾驶更模块化的方法。（DAVE 在复杂环境中的事故平均间距约为20米。）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;大约一年前我们开始尝试去改善原始的 DAVE，并建立了一个用于公共道路行驶的强大系统。基于对这些特征的观察，这项工作的主要动机是为了免去识别专为人类标注的特征的需要，如车道标记、护栏，或其他汽车，并免于建立一个「if, then, else」规则集合。我们很高兴能够分享这一新工作的初步结果，它有个合适的名字：DAVE–2。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;DAVE–2 系统&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图2显示了一个简化的 DAVE-2 训练数据采集系统方框图。三架摄像机安装在数据采集汽车的挡风玻璃后面，而来自摄像机的时间戳视频是与人类驾驶员的转向角度同时被捕获的。转向命令是通过进入车辆的控制器区域网络（Controller Area Network / CAN）总线得到。为了使我们的系统独立于汽车的外形，我们将转向命令表示为 1/r，其中 r 代表每米的转弯半径。我们使用 1/r 而不是 r 以防止直线驾驶时的奇点（直线行驶的转弯半径为无穷大）。1/r 从左转弯（负值）转变到右转弯（正值）时平滑地通过零点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW92ZADSyWaB13W63psanKSSiaUibQR2VYgD7fDSvp7aTTf4YxuZT59QHNqvYNicEiaCHIu2H6Xw6gQdpw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图2：数据采集系统概览&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;训练数据包含视频采样得到的单一图像，搭配相应的转向命令（1/r）。只有来自人类驾驶员的数据是不足以用来训练的；网络还必须学习如何从任何错误中恢复，否则该汽车就将慢慢偏移道路。因此训练数据还扩充了额外的图像，这些图像显示了远离车&lt;/span&gt;&lt;span&gt;道中心的偏离程度以及不同道路方向上的转动。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;两个特定偏离中心的变化图像可由左右两个摄像机捕获。摄像机和所有转动之间的额外偏移是通过最近的摄像机的图像的视角变换（viewpoint transformation）进行模拟的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;精确的视角变换需要 3D 场景知识，而我们没有这些知识，因此只能做近似变换——假设水平线以下的所有点都在平地上，而水平线以上的所有点在无限远。这种方法在平面地形上产生的效果很好，但对于一个更完整的渲染，它还引入了地表以上物体的畸变，比如汽车、电线杆、树木和建筑物。幸运的是，这些畸变不会给网络训练带来大问题。变换后的图像的转向标签会在两秒内被迅速调整到正确驾驶汽车时回到的期望位置和方向。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图 3 显示了我们的训练系统框图。图像被送入一个卷积神经网络，然后计算一个被推荐的转向命令。这个被推荐的转向命令会与该图像的期望命令相比较，卷积神经网络的权重就会被调整以使其实际输出更接近期望输出。权重调整是使用Torch 7 机器学习包中所实现的反向传播完成的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW92ZADSyWaB13W63psanKSSL3pC9kZU4b0gRxoh3EVxHQ4q0CaFtatAsHSic8iaMicCRWldbjic0Pbu7g/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一旦训练完成，网络就能够从单中心摄像机（single center camera）的视频图像中生成转向命令。图 4 展示了这个配置。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW92ZADSyWaB13W63psanKSSL3pC9kZU4b0gRxoh3EVxHQ4q0CaFtatAsHSic8iaMicCRWldbjic0Pbu7g/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图4：训练过的网络用于从单中心前向摄像机中生成转向命令。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;数据收集&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;训练数据是通过在各式道路以及多样的照明和天气条件组合中驾驶汽车来收集的。我们收集了伊利诺伊、密歇根、宾夕法尼亚和纽约的高速公路数据以及新泽西中部的地面街道数据。其他道路类型包括（有以及没有车道标线的）双车道公路、带有停泊车辆的小区道路、隧道和未铺好的道路。数据是在晴朗、多云、有雾、下雪和下雨天气中收集的，包括白天和夜间。在某些情况下太阳在低空中，会导致来自道路表面反射以及挡风玻散射的眩光。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;捕获数据使用的是我们的线控测试车辆——一辆 2016 年的 Lincoln MKZ 或者 2013 年的 Ford Focus ，两辆车的摄像机被置于类似的相应位置。我们的系统独立于任何特定的车辆样式或模型。我们鼓励司机保持充分的注意力，否则要么就照往常一样驾驶。截至 2016 年 3 月28日，共收集到约 72 小时的驾驶数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;网络架构&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们训练网络的权重以尽量减少转向命令输出之间的均方误差（mean-squared error），无论它是由网络、人类驾驶员的命令所引起，还是由为了图像的去中心化和旋转而做出调整的转向命令（参见后面的「增强」一节）所引起。图 5 展示了该 9 层网络的架构，其中包括一个归一化层（normalization layer）、5 个卷积层和 3 个完全连接的层。这张输入图像被分割成 YUV 平面并被传递到网络中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW92ZADSyWaB13W63psanKSSMIovAzlGsFOD3OLLey1F5ObicicNwxx0FAqfu4PYPib2Cq9Nhjr6mNQ6w/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图5：卷积神经网络架构。该网络有大约 2700 万个连接和 25 万个参数。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;网络的第一层执行图像归一化。这个归一化器（normalizer）是硬编码的且不是在学习过程中被调整的。在网络中执行归一化允许归一化方案被网络架构更改，并通过 GPU 处理得到加速。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;卷积层被设计用于进行特征提取，并通过一系列多样化层配置的实验被经验性地选择。然后我们在头三个卷积层中使用带有一个 2×2 步幅（stride）和一个 5×5 核（kernel）的步幅卷积（strided convolutions），在最后的两个卷积层中使用一个有着 3×3 核大小的非步幅卷积。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们在这五个卷积层后面加三个全连接层（fully connected layer），得到一个最终的输出控制值，也就是逆转弯半径（inverse-turning-radius）。这个全连接层被设计用作一个转向控制器的转向功能，但我们注意到通过端到端地训练系统，要想清楚地区分网络功能的哪个部分主要作为特征提取器、哪个部分作为控制器，这是不可能的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;训练细节&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;数据选择&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;训练一个神经网络的第一步是选择所使用的帧。我们收集到的数据被标记为道路类型、天气状况和司机的活动（保持车道、转换车道、转弯等等）。要训练一个卷积神经网络进行车道跟随，我们只需选择司机保持在那条车道的位置数据，并放弃其余数据。然后我们以每秒 10 帧（FPS）的速度取样视频，因为较高的采样率会包含高度相似的图片，因此不能提供更多额外的有用信息。为了消除直线驾驶的偏差，训练数据包含了相当大一部分表征道路曲线的帧。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;增强&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;选择了最后的帧集合之后，我们通过添加人工偏移和转动来增加数据，教网络如何从一个不利位置或方向中恢复。这些扰动的大小是从一个正态分布中随机选择的。这个分布具有零均值，且其标准偏差是我们所测量的人类驾驶员的两倍。（如前所述）由于级数的增加，人为增强数据确实增加会不需要的内容。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;仿真&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在一个训练过的卷积神经网络用于道路测试之前，我们首先通过仿真评估网络的性能。图 6 展示了仿真系统的一个简化框图，而图 7 展示了一张交互模式下的模拟器截图。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW92ZADSyWaB13W63psanKSSHrmAPLuPC8STW8YfY43wySoMxOXNC4GhMTdntfTuMkZicMA9qXQoqmg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图6：驾驶模拟器框图&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该模拟器从连接到一辆人类驾驶的数据采集车的前向车载摄像机获取预先录制的视频，并生成近似于卷积神经网络替代人类驾驶车辆情况的图像。由于人类司机不总是在车道中心驾驶，我们必须手动校准车道中心，因为它是与模拟器使用的每一帧视频相联系。我们称之为「ground truth」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;模拟器转换原始图像是出于对 ground truth 偏离的考虑。注意这种转换也包括人类实际驾驶路径和 ground truth 之间的任何矛盾。这个变换是通过先前所描述的同一方法完成的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该模拟器会访问所记录的测试视频及其捕获视频时的同步转向命令。该模拟器会发送测试视频（已为 ground truth 上的任何偏移进行了调整）的第一帧作为训练的 CNN 的输入，然后其会返回该帧的一个转向命令。卷积神经网络转向命令和所记录的人类驾驶员命令一道，被送进模拟车辆的动态模型中以更新其位置和方向。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW92ZADSyWaB13W63psanKSSh0CGxfxvtbIFxWRcVGPASY4B8ibrXVVhYVNxCdaP0bAaNvIDDwicsX9w/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;图7：交互模式中的模拟器截图。参见性能指标的注解文本。由于视点变换，左边的绿色区块是未知区域。水平线以下突出的宽矩形是被发送到卷积神经网络的区域。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然后该模拟器修改测试视频的下一帧使图像出现，仿佛车辆处于跟随卷积神经网络的转向命令后所到达的位置。接着这个新的图像被送到卷积神经网络中，如此以往重复进行。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该模拟器会记录偏心距（从车到车道中心的距离）、偏航和虚拟汽车的行程。当偏心距超过一米就会触发一次虚拟人类干预，而虚拟车辆的位置和方向会被重置，以匹配原始测试视频相应帧的 ground truth。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;评估&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们的网络评估分两个步骤：首先是在仿真过程，然后是在道路测试过程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在仿真中，我们的网络在模拟器中向一套预先录制好的的测试路线提供转向命令，该路线对应在新泽西州的蒙茅斯县驾驶大约共三小时、100 英里的行程。测试数据是在不同照明和天气条件下获得的，包括公路、当地道路和住宅街道。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们通过计算模拟车辆偏离中心线超过一米时所触发的模拟人类干预数量，来评估网络（自主）驾驶车辆的时间占比。我们假设现实生活中的一个实际干预总共需要六秒：这是人类重新掌控车辆、重新确定中心、然后重新启动自动驾驶模式所需的时间。我们通过干预措施计数来计算自主性百分比，将它乘以 6 秒再除以模拟测试所消耗的时间，然后用 1 减去这一结果：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW92ZADSyWaB13W63psanKSSib3JLqB9ic1vkHyGJcYL8P2zUrshYCPvRAM8cpFc2gDaghlC5AVibHHGA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以，如果我们在 600 秒内有 10 次干预，则自主值为：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW92ZADSyWaB13W63psanKSSb27rS35xicGHhXIcQUFSkYsCDgky5Wf9KficzicmZD3JE7YrRR2Bhz89A/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;道路测试&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当训练过的网络已经在模拟器上表现出良好性能之后，我们就在测试汽车上的 DRIVE PX 中加载网络并将其用于道路测试。对于这些测试，我们将汽车执行自动驾驶的时间占比作为性能测量的标准。这个时间不包括变道以及从一条路到另一条路的转弯。对于在新泽西州蒙茅斯县的一次典型驾驶而言，从我们位于霍姆德尔的办公室开到 Atlantic Highlands，几乎 98% 的时间是处于自动驾驶状态。我们还驱车在花园州高速公路（一个带有上下坡道的多车道高速公路）上连续无障碍行驶了10 英里。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是一段我们在不同条件下驾驶测试车辆的视频：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;iframe class="video_iframe" data-vidtype="1" style="   z-index:1; " height="375" width="500" frameborder="0" data-src="https://v.qq.com/iframe/preview.html?vid=h032208kh1g&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0" allowfullscreen=""&gt;&lt;/iframe&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;内部卷积神经网络状态的可视化&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW92ZADSyWaB13W63psanKSS3wMXgezbqktRxar2GHM3MgVmtbPCACoOiblxJ4lZbOChkIsFopN65jQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图8：卷积神经网络如何「看」一条尚未铺好的路。顶部：发送到卷积神经网络的相机图像子集。左下方：第一层特征映射的激活（Activation ）。右下方：第二层特征映射激活。这表明卷积神经网络已经学会自己检测有用的道路特征，即在只有人类转向角度作为训练信号的情况下。我们从未明确训练它来检测道路轮廓。&lt;/span&gt;&lt;/em&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图 8 和图 9 展示了两个不同示例输入的头两层特征映射的激活，一条尚未铺砌的路和一片森林。在未铺好道路的示例中，特征映射激活清晰地显示出道路轮廓，而森林示例中的特征映射大多含有噪声，亦即卷积神经网络在这幅图像中没有发现有用信息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这表明卷积神经网络已学会自己检测有用的道路特征，即在只提供人类转向角度作为训练信号的情况下。例如我们从未明确地训练它来检测道路轮廓。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW92ZADSyWaB13W63psanKSSzqsPmiaeLXPZD9FfcFMiaLNhBhnFth8wz5y5JsKAaibL5IEhOk6PGTiaGQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图9：没有道路的示例图像。头两个特征映射的激活似乎大多含有噪声，即卷积神经网络没有识别出这张图像中的任何有用的特征。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;结论&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们的实验表明，卷积神经网络能够在没有人工分解道路或车道线检测、语义抽象、路径规划与控制的情况下，学习接下来的整个车道与道路任务。不到一百小时驾驶时长的少量训练数据，对于训练汽车在不同条件下的行驶来说足够了——比如在高速公路、当地和住宅道路上，在阳光、多云和下雨的情况下。卷积神经网络能够从一个非常稀疏的训练信号（只有转向信号）中学习有意义的道路特征。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该系统能从示例中学习检测道路的轮廓，而且不需要训练过程中的精确标签。但在提高系统的稳健性和提高网络内部处理过程的可视化程度上还有更多的工作要做。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;参考文献：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;1. Y. LeCun, B. Boser, J. S. Denker, D. Henderson, R. E. Howard, W. Hubbard, and L. D. Jackel. Backprop- agation applied to handwritten zip code recognition. Neural Computation, 1(4):541–551, Winter 1989. URL: http://yann.lecun.org/exdb/publis/pdf/lecun-89e.pdf.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;2. Alex Krizhevsky, Ilya Sutskever, and Geoffrey E. Hinton. Imagenet classification with deep convolutional neural networks. In F. Pereira, C. J. C. Burges, L. Bottou, and K. Q. Weinberger, editors, Advances in Neural Information Processing Systems 25, pages 1097–1105. Curran Associates, Inc., 2012. URL: http://papers.nips.cc/paper/ 4824-imagenet-classification-with-deep-convolutional-neural-networks. pdf.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;3. L. D. Jackel, D. Sharman, Stenard C. E., Strom B. I., , and D Zuckert. Optical character recognition for self-service banking. AT&amp;amp;T Technical Journal, 74(1):16–24, 1995.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;4. Large scale visual recognition challenge (ILSVRC). URL: http://www.image-net.org/ challenges/LSVRC/.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;5. Net-Scale Technologies, Inc. Autonomous off-road vehicle control using end-to-end learning, July 2004. Final technical report. URL: http://net-scale.com/doc/net-scale-dave-report.pdf.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;6. Dean A. Pomerleau. ALVINN, an autonomous land vehicle in a neural network. Technical report, Carnegie Mellon University, 1989. URL: http://repository.cmu.edu/cgi/viewcontent. cgi?article=2874&amp;amp;context=compsci.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;7. Danwei Wang and Feng Qi. Trajectory planning for a four-wheel-steering vehicle. In Proceedings of the 2001 IEEE International Conference on Robotics &amp;amp; Automation, May 21–26 2001. URL: http: //www.ntu.edu.sg/home/edwwang/confpapers/wdwicar01.pdf.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;点击「阅读原文」，下载论文↓↓↓&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;</description>
      <pubDate>Sat, 20 Aug 2016 15:08:59 +0800</pubDate>
    </item>
    <item>
      <title>学界 | 谷歌DeepMind最新论文：使用合成梯度的解耦神经接口</title>
      <link>http://www.iwgc.cn/link/2360660</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自 arXiv.org&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;作者：Max Jaderberg、Wojciech Marian、Czarnecki、Simon Osindero、Oriol Vinyals、Alex Graves、Koray Kavukcuoglu&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW92ZADSyWaB13W63psanKSSMPiaicbBlHjibpRPpTibwyr0b1QqMRJ2wfAb5TDwsQQ0PTURRI53bpzAAQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;训练 directed neural networks 通常需要将数据前向传播通过一个计算图（computation graph），然后再反向传播误差信号，从而生成权重更新。因此，网络中所有层——或称为模块（module）——就会被锁定，在某种意义上，他们必须等待该网络的剩余部分前向执行，然后反向传播误差之后才能实现更新。在本研究成果中，我们通过引入网络图（network graph）的一个未来计算模型而对模块进行解耦，从而打破了这种限制。这些模型仅使用局部信息就能预测建模的子图（subgraph）将会产生的结果。我们尤其关注建模误差梯度（modelling error gradients）：通过使用建模的合成梯度来取代真正的反向传播误差梯度，我们可以解耦子图并独立和异步地对它们进行更新，即我们可以实现解耦神经接口。我们展示了三项实验结果，前向传播模型（其中每一层都是异步训练）、循环神经网络（RNN）（预测某个未来梯度可在 RNN 可以有效建模的时间上进行扩展）、和分层 RNN 系统(在不同时间尺度上执行的)。最后，我们证明：除了预测梯度，该框架还可被用于预测输入，得到可以以前向和反向通过的方式解耦的模型——从而发展成可以联合学习（co-learn）的独立网络，它们可通过这种方式被组合成一个单一的 functioning corporation。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;点击「阅读原文」，下载此论文↓↓↓&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;</description>
      <pubDate>Sat, 20 Aug 2016 15:08:59 +0800</pubDate>
    </item>
  </channel>
</rss>
