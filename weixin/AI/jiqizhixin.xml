<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器之心</title>
    <link>http://www.iwgc.cn/list/670</link>
    <description>人与科技的美好关系</description>
    <item>
      <title>深度 | ICML 2016演讲视频公开：数百个演讲视频带你读懂机器学习（附观看地址）</title>
      <link>http://www.iwgc.cn/link/2460364</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自 TechTalks&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀、李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;今年 6 月 19 到 24 日，国际机器学习大会（ICML）在纽约举办。关注机器学习、算法以及系统的 ICML 会议包含了专题报告、 接收论文演讲以及谈论更多近期研究的研讨会。今年，有近 3000 名与会者参加了这个为期五天的会议。机器之心之在大会期间对这场会议的论文（&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716332&amp;amp;idx=2&amp;amp;sn=b43ed7510c39e7627f3081f7078c4365&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716332&amp;amp;idx=2&amp;amp;sn=b43ed7510c39e7627f3081f7078c4365&amp;amp;scene=21#wechat_redirect"&gt;业界 | ICML2016 Facebook 提交3篇论文，探索最有趣的机器学习问题&lt;/a&gt;、&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716227&amp;amp;idx=3&amp;amp;sn=7bd397912dff627725b28eea7aaad2ce&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716227&amp;amp;idx=3&amp;amp;sn=7bd397912dff627725b28eea7aaad2ce&amp;amp;scene=21#wechat_redirect"&gt;学界｜2016 ICML 微软研究者提交的十八篇论文&lt;/a&gt;）、演讲（学&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717116&amp;amp;idx=1&amp;amp;sn=c362209463d8bfe2d725b164a0ee0a2f&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717116&amp;amp;idx=1&amp;amp;sn=c362209463d8bfe2d725b164a0ee0a2f&amp;amp;scene=21#wechat_redirect"&gt;界｜ICML 2016 教学讲座全集：深度强化学习、深度残差网络、非凸优化等九大主题&lt;/a&gt;）、获奖情况（&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716316&amp;amp;idx=1&amp;amp;sn=e1c6d7364ca627d3f9964a8d3fc10efa&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716316&amp;amp;idx=1&amp;amp;sn=e1c6d7364ca627d3f9964a8d3fc10efa&amp;amp;scene=21#wechat_redirect"&gt;重磅｜ICML 2016最具时间价值奖和最佳论文奖出炉，DeepMind独揽一半奖项&lt;/a&gt;）、大会总结（&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716652&amp;amp;idx=1&amp;amp;sn=7cd76481680bfb6d65f1d625511adb16&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716652&amp;amp;idx=1&amp;amp;sn=7cd76481680bfb6d65f1d625511adb16&amp;amp;scene=21#wechat_redirect"&gt;深度｜ICML 2016大会最具影响力的三个机器学习话题&lt;/a&gt;）等都有过报道。&lt;span&gt;&lt;strong&gt;&lt;span&gt;昨日，ICML 公布了会议期间拍摄的演讲视频，本文对这些演讲视频进行了简单介绍。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;em&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;点击「阅读原文」可查看视频网址。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;br/&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9icXvYKCNT2jbZOBI4NicyLce3ndOTSIp2YibKWMyoqUqntuRZHYicbU6RclHjNdxb7hbvtnsRLmJ1kQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;开放视频&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;ICML 2016 特邀报告（Plenary Talks）&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;观看地址：http://techtalks.tv/icml/2016/plenaries/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;ICML 邀请了斯坦福商学研究生院技术经济学教授 Susan Athey、斯坦福大学计算机科学系副教授李飞飞、哥伦比亚大学统计学和计算机科学教授 David M. Blei、芝加哥大学机器学习研究专家兼 Louis Block 教授 John D. Lafferty、耶鲁大学计算机科学、数学和应用数学 Henry Ford II 教授 Daniel Spielman、卡内基梅隆大学电子和计算机工程教授 Christos Faloutsos 在大会期间做了特邀报告（Plenary Talks）。下面是对这些报告的简单介绍：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Susan Athey：Causal Inference for Policy Evaluation（用于策略评估的因果推理）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9icXvYKCNT2jbZOBI4NicyLcdg5jAyqOqEG1kpPZ4SfrKhFjzV9DGEGeqj6E3AZ5UerbSib8RD3o5ibA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;演讲简介：许多不同的科学问题需要研究者评估一项策略或干预的因果关系，比如将药给病人、改变最小工资等政府政策、为用户提供广告或在一项在线服务中将一种新算法提供给用户。这项演讲将会回顾一系列最近开发的用在带有许多协变量的环境中进行因果推理的统计方法。我们思考了在观测数据中对一项策略的平均影响进行评估的方法，以及评估随机试验中异构处理效果（heterogeneous treatment effect）和个性化策略的方法。我们将展示回归树（regression tree）和随机森林（random forest）等流行方法可以如何调整和优化以产生位于置信区间内的处理效果的评估。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;李飞飞：A Quest for Visual Intelligence in Computers（一种对计算机视觉智能的追求）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9icXvYKCNT2jbZOBI4NicyLcqFZdbj8xBfUGlsxmlwoH5XPy6SbtPKUKXtvJ38ZY2nwvnU8AfGR9bA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;演讲简介：大自然和进化用了 5 亿年时间才发展出了人类这强大的视觉系统。人工智能和计算机视觉才刚发展大约 50 年。在这个演讲中，我将简要讨论在计算机视觉智能的道路上的关键思想和最近的前沿进展。我将尤其关注我的实验室在图像和视频理解最新研究成果，这些成果都用到了大数据和深度学习（又名神经网络）架构。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;David Blei 和 John Lafferty：Dynamic topic models（动态主题模型）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9icXvYKCNT2jbZOBI4NicyLc2CiaIPs2MfuRQ1LKdgdLSI9ibgPhZjBXzydSMG5Z5qYXibTnsn0G0TMzw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;br/&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;演讲简介：David Blei 和 John Lafferty 的演讲同主题论文《Dynamic Topic Models 》是 ICML 2016 的最具时间价值奖（Test of Time Award）获奖论文。该论文的摘要如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一系列概率时间序列模型被开发出来用于分析大型文档集合中主题随时间的变化。这一方法是在表征主题的多项分布的自然参数上使用状态空间模型。开发的基于卡尔曼过滤器（Kalman filters）的变分近似法和非参数小波回归实现了对隐藏主题的近似后验推断（posterior inference）。除了给出连续语料库数量的预测模型之外，动态主题模型也提供一个进入大型文档集合的定性的窗口。这一模型的演示是通过对从 1880 至 2000 年间的 Science 杂志的 OCR（光学字符识别）档案分析完成的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Daniel Spielman：Laplacian Matrices of Graphs: Algorithms and Applications（图的拉普拉斯矩阵：算法和应用）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9icXvYKCNT2jbZOBI4NicyLcyyQyXQxyRIRMQldzD4DjQoNf22ibHaclxyZBxItj12Kt97JibrsE7W8A/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;演讲简介：拉普拉斯矩阵（Laplacian matrices）已经出现在了机器学习、计算机视觉、优化、计算科学、当然还有网络分析等领域中。我们将解释这些矩阵是什么，已经为什么会出现这么多的应用中。特别地，我们还将展示拉普拉斯系统处理器（Laplacian system solvers）可以如何被用于快速解决来自自然图问题（natural graph problem）的线性规划（ linear program）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Christos Faloutsos：Mining Large Graphs: Patterns, Anomalies, and Fraud Detection（挖掘大型图：模式、异常和欺诈检测）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9icXvYKCNT2jbZOBI4NicyLcJspX92kkHJ5kUv7YnEPxgvo3YE9XhyAa17niaLA9DaRR7vdPCM6XlbQ/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;演讲简介：给定一个大型图（如谁打电话给谁、谁喜欢谁）哪种行为是正常的？哪种行为会让人感到惊讶？哪种可能是由于欺诈行为引起的？图可以如何随时间演变？我们将关注下面这些主题：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="list-style-type: lower-roman;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;大型静态图中的异常检测&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;大型的随时间演变的图中的模式和异常。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于第一个，我们给出了一个静态的和时间上的规律列表，我们展示了如何使用它们来在网络买卖环境、Facebook、类 Twitter 网络中发现可疑活动的方法。对于第二个，我们展示了如何将随时间变化的图当作张量（tensor）处理的方法，以及在这些环境中的一些发现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;ICML 2016 Tutorials&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;观看地址：http://techtalks.tv/icml/2016/tutorials/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该部分收录了 ICML 2016 Tutorials 的 9 个视频。机器之心已经在今年 7 月份的文章《&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717116&amp;amp;idx=1&amp;amp;sn=c362209463d8bfe2d725b164a0ee0a2f&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717116&amp;amp;idx=1&amp;amp;sn=c362209463d8bfe2d725b164a0ee0a2f&amp;amp;scene=21#wechat_redirect"&gt;ICML 2016 教学讲座全集：深度强化学习、深度残差网络、非凸优化等九大主题&lt;/a&gt;》介绍了其中包含的演讲内容（包含幻灯片下载）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;ICML 2016 Orals&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;观看地址：http://techtalks.tv/icml/2016/orals/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这里收录的数百个演讲视频分成了 39 个主题（包含了学习理论、统计学习理论、聚类、监督学习/无监督学习等许多人工智能研究领域）：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9icXvYKCNT2jbZOBI4NicyLcWPM0BEr7LqOQOV5KyalVNJxCqmFzB96ticuWvK96XGZj4MbfObH3PXw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;点击阅读原文，观看演讲视频↓↓↓&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;</description>
      <pubDate>Sun, 28 Aug 2016 15:11:40 +0800</pubDate>
    </item>
    <item>
      <title>机器之心×MIT-CHIEF: | CartilaGen以载药新材料和3D打印实现精准治疗，Skelmet用3D打印个性化可穿戴</title>
      <link>http://www.iwgc.cn/link/2460365</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心原创&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：&amp;nbsp; Jiaxin Su, Chain Zhang&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;编辑：Rita Chen&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;麻省理工学院中国创新与创业论坛（简称 MIT-CHIEF) 是美东地区最大的创新创业平台，汇集了美国最尖端的人才和项目，融合了中国和美国的各项优势资源。在刚刚过去的七月里，十六支涵盖医疗健康，新能源，教育及金融等领域的创业团队和 MIT-CHIEF 一起，走访了北京，上海，深圳和成都四大城市和与其相关的创业合作基地，与当地的政府，企事业单位代表进行了卓有成效的合作与交流。机器之心有幸采访到了其中的十一支团队，这是该系列采访的第二篇（第一篇：&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718634&amp;amp;idx=2&amp;amp;sn=7346f610a9349d1c1d40387394bb951d&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718634&amp;amp;idx=2&amp;amp;sn=7346f610a9349d1c1d40387394bb951d&amp;amp;scene=21#wechat_redirect"&gt;机器之心×MIT-CHIEF | Blue Skies用激光光谱过滤营造健康环境，Ricult搭建数据平台为农民致富开路&lt;/a&gt;）。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9icXvYKCNT2jbZOBI4NicyLcESckrqicOTHWJX8Kkkz3pengJ3mIcLE8CBXGBjT4y2tZTiaYNddwsOYw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;官网：http://cartilagen.com/&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;CartilaGen Co 是一家由美国著名医学院骨科医生和生物医学工程师创立的骨科生物制剂和器材公司。公司创始团队拥有二十多年的运动损伤，骨关节炎病理生理和生物活性材料方面的深厚科研实力，同时在 3D 生物打印领域拥有核心技术。目前，CartilaGen 专注于开发用改变病程的药物，复合生物材料药物载体，3D 生物打印活性内植物和可穿戴给药装置，用于治疗由于创伤，过度运动，和老化引起的关节损伤和骨关节炎。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9icXvYKCNT2jbZOBI4NicyLcnZrvzhmoI5JGGlQ5D4eXFP6BFex8nickb4DlUHz1R91XiapxqspfRdHg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;http://www.skelmet.com/#home&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Skelmet 是一家通过 3D 扫描和 3D 打印等前沿技术颠覆传统制造业，打造个性化定制化可穿戴产品的公司。其通过智能设计+柔性生产的模式自动设计并生产出适配于每一个消费者的可穿戴产品。Skelmet 的核心智能设计包括人体 3D 扫描模型的特征识别与处理，以及产品的自动设计建模技术。目前的研究主要围绕人体的头部展开，其覆盖产品包括眼镜，头盔，面罩等等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器之心有幸采访到 CartilaGen 的联合创始人兼 CEO 于寅博士， 还有 Skelmet 的两位创始人 CEO 曹宇及 COO 王雨亭。生物科技的创新与定制化可穿戴产品理念会碰撞出怎样的火花呢？让我们一起看看这两支风格不同的团队是如何作答的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9icXvYKCNT2jbZOBI4NicyLcgPXPzNG7HrEzDbVpzBNM6eDxBDGItZvh1x9u98iaNXhUwxC0RRtH86w/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;(左一）于寅 ：CartilaGen 的联合创始人兼 CEO。医学博士，生物医学工程博士。在哈佛大学医学院以及美国麻省总医院做研究员，主要是研究方向是再生医学和 3D 生物打印。（左二）曹宇 &amp;nbsp;Skelmet 的 CEO。本科毕业于清华大学电子工程系，研究生毕业于美国哥伦比亚大学工学院。目前主要负责管理公司的发展方向以及产品技术开发。（右一）王雨亭 Skelmet 的 COO。毕业于加拿大多伦多大学，获数学和物理双学位。后就职于知名建筑师事务所 Safdie Architects，专攻基于数学原理的建筑设计。目前主要负责内部公司管理，包括人力，财务和市场推广方面。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Synced: 三位好！能否简短的和机器之心的读者介绍一下各自的团队还有公司的产品？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;于寅：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我们公司（CartilaGen）主要是由生物医学工程师，大数据工程师，骨科医生，还有前世界 500 强公司的产品经理组成。我们主要从事的是跟骨科相关的一些生物制剂，细胞治疗和医疗器械，用再生医学的方法，研发出针对运动创伤和骨关节炎的含药生物材料和具有生物活性的可植入假体，用于疾病的日常预防，手术治疗还有术后的康复。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;王雨亭&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：我们（Skelmet）是解决了穿戴产品不适配的问题。我们通过 3D 扫描和 3D 打印技术为每个人量身定做只属于他们的产品。这个想法最初是来自于曹宇。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;曹宇&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;： 对，我大学的时候骑摩托车，发现头盔非常夹头，到了美国之后发现原来外国人的头部很圆，脸很小。其实，中国人和外国人的脸部是有很大差异的。市场上 90% 的头盔和眼镜相关的可穿戴产品是为西方人设计的，不太符合中国人的人体工学。那为什么不用一种比较友好的方式来解决这种问题呢？后来我想到结合不同的算法，利用 3D 扫描和 3D 打印技术给每人设计不同的产品。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Synced: 刚才 Skelmet 讲了自己的契机, 是因为生活中的一个发现开始这方面的研发和尝试。那 CartilaGen 团队开始的初衷是什么呢？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;于寅&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：我在国内做了一段时间的骨科医生，来到美国读生物医学工程专业的博士，同时在医院的骨科工作，主要是从事再生医学研究的。我和我同事在学校里面做出了一些成果并有了专利，同时意识到这些技术在临床转化方面的价值，而现在这个公司就是在使用并且继续开发这些专利的应用，试图通过资本的帮助，尽快地将这些技术实现临床应用，惠及病人。所以说成立公司是一个很自然的过程，学校也很支持和鼓励，再加上一开始就受到了一些资金的支持，事情就做起来了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Synced : 那对于这种科研向的项目，往往会遇到很多研究上的技术难题，在你们的发展过程中，遇到最大的技术难题是什么？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;于寅&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：我们现在的专利技术是经过了过去的六到七年的不断完善而成的。在这个过程当中，必须经过基础生物医药方面的研究，材料学的研究，动物实验，临床前试验，每一步的成功与否，都是挑战。后期最大的壁垒就是怎么才能尽可能快的获得 FDA 和 CFDA 的批准，并且顺利完成临床试验，进入临床的使用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Synced: 除了技术方面，在市场或者推广方面有没有什么困难呢？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;于寅：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我们目前处于研发阶段，暂时并没有涉及市场推广。目前的主要困难是融资，期初我们在美国寻求非股权融资 (可转债)，因为对投资人和创业人来说，早期的估值比较难说。但通过这次中国行，回国谈了之后，国内的投资人都比较倾向股权融资，我们现在也开始考虑股权融资。后期进入国内，如何做好市场和医疗审批和销售方面的渠道非常重要，所以对于融资而言，我们不单单是找资金支持，而是希望找更了解国内市场的合作关系，例如专业的医疗投资机构，有医疗方面的资源和政府资源的对接。同时也希望寻找熟悉国内医疗行业运作的有经验的人加入我们团队，来克服可能预见的回国落地和开展业务方面的困难。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Synced: 谢谢! 那在 Skelmet 发展过程中遇到的最大的困难是什么呢？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;王雨亭&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：对于团队而言，目前最大的困难就是人才需求，因为我们做的事之前没有人做过，加之是一个多学科交叉的系统，需要具有很强的知识综合能力的人，所以前期我们只能先自己学各种知识，然后再教给其他员工。现在团队里做设计的大多数是工程学出身的，所以如何重新定位他们的工作，如何重新学习设计，并将软件或者算法方面的东西结合到设计中去也是我们要考虑的问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;曹宇&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：我们认为，现今不管互联网也好，信息技术也好，都是在操纵信息。我们相信在不久的未来，信息技术会最终影响到产品制造。我们现在是用编程的手段去操作这个产品设计，也就是说，未来的设计师是设计一种算法或者是很多算法，通过算法进行自动设计，而不是亲手去操作，这整套工程体系，和商业模式都是全新的。除了人才的需求外，我们现阶段需要尽快地把产品商业化，这样才有一个可持续发展的过程和人才的积累。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9icXvYKCNT2jbZOBI4NicyLcJLIzWKgMlvgXW2MlSHvOCicwAataKC6azNDLDVVVtHahTMFgulfoV7Q/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图片说明：Skelmet 的核心智能设计包括人体 3D 扫描模型的特征识别与处理，以及产品的自动设计建模技术。目前的研究主要围绕人体的头部展开，其覆盖产品包括眼镜，头盔，面罩等等。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Synced：谈到产品和商业化的问题，你能否深入给我们讲解一下你们这个商业模式给消费者带来的好处？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;曹宇&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：商业模式的话，现有的可穿戴产品，都是通过铸造或铸模的方式来制作的，一样的产品戴到不一样的人身上会有很多问题。并且消费者在购买产品时，通常需要到各种店铺去试戴，占用了许多线下店铺的资源和消费者的时间，甚至很多消费者一辈子没戴过真正适配的产品。我们的系统就能完全解决这些问题。无论是对节约消费者的时间投入，提高产品的价值和实用性，还是提高生产效率，我们可以说解决了困扰消费者和传统制造业数十年的难题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Synced: 制定化本身也满足了未来社会个性化的需求。那么，相同的，对于 CartilaGen，你是如何看待你现在所属的这个领域的发展趋势？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;于寅:&lt;/span&gt;&lt;/strong&gt;&lt;span&gt; 首先我们公司给自己的定位是给我们所在领域的疾病治疗带来新的思路和治疗标准。以往和当前对于组织器官疾病的通常的做法是，我把病人病变的组织切除或是使用金属和塑料假体给病人做替代。现在比较新的理念是促进病人自己的身体去再生它来修复它，这是在未来的 5 到 10 年，甚至更长的时间比较推崇的治疗方案。另外，在疾病或者发病之前（预防性治疗），通过基因检测也好或者对病人的生理病理指标进行追踪分析，在发病的最早期阶段就采取有效的手段阻断这个疾病后续的发展。我们做的是骨科的东西，主要针对运动损伤和老年人的骨关节炎。运动过程中总会出现损伤，比如像现在中国有很多人开始喜欢跑步，跑马拉松，大家都会感觉到膝盖的疼痛。我们研发的一个佩戴装置可以在运动的过程中，稳定运动人群的膝关节来阻断或者预防关节创伤的产生，同时我们开发出相关的含药生物材料，就是在创伤发生后尽早地进行治疗，使它不会在年纪变大之后产生骨关节炎。另外，我们跟 Skelmet 一样，他们用 3D 技术打印做定制化产品，我们用 3D 生物打印技术做组织器官的植入物。这种产品是通过植入带有生物活性的材料来修复受到创伤的病人的软骨和骨组织。我们各个技术整合起来会降低治疗过程中的副作用和并发症，并做到个性化的靶向治疗，能最有效地发挥病人身体上的再生修复的能力，更自然的缓和甚至治愈疾病。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9icXvYKCNT2jbZOBI4NicyLcQQVEHjlP8EG0VNYl3zk0SL29TQicV1OqBQ5YFQicBhPWOpJwjhsOn6nw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图片说明： CartilaGen专注于开发用改变病程的药物，复合生物材料药物载体，3D生物打印活性内植物和可穿戴给药装置，用于治疗由于创伤，过度运动，和老化引起的关节损伤和骨关节炎。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Synced: 谢谢！因为两个团队都是刚刚参加了 MIT-CHIEF 的中国行，可以跟大家分享一下这次中国行的经历和感受吗？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;于寅：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;在来波士顿之前我就知道 MIT-CHIEF 这个组织了，但之前一直在美国中部地区读书，并没有很好的接触，正好这次知道他们要举办中国行， 就报名参加了，经过筛选很荣幸我们选上了。因为我们打算今年年底在国内落地，所以这也是一个很好的机会。最大的期待就是见到相关行业的专业投资人，获得融资的机会，再者就是看看各个城市不同的需求以及当地政府的支持力度，看有没有政府的资源我们能获取来帮助我们在国内落地。所以，这些目标都实现了，感觉 MIT-CHIEF 是一个很靠谱的团队。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;王雨亭：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;因为我们之前就认识 MIT-CHIEF 的主席和副主席，所以对于他们个人还有这个团队还是挺了解的。这次中国行，刚开始并没有抱那么大的期望，因为不太清楚它整个流程或是规划是怎样的。但通过一圈多个城市的走访，接触到了很多资源，包括供应商，生产商以及投资人，在各方面都有不同程度的收获。除此之外最大的惊喜，是人，因为创业过程很艰辛，能收获一群志同道合的可以一起分享资源经验的小伙伴，我感觉特别难得。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9icXvYKCNT2jbZOBI4NicyLcDaSq7WqiaoXlRKGQlvXWzn6xkibdnRgicowicriaaWm3yQas3MQDicD69qGQ/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Skelmet 团队在 MIT-CHIEF 中国行&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Synced: 那你们认为， 在中美的创业文化上，或者在整个大的政策和国家的支持上面，环境上有没有特别明显的不同和相同？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;王雨亭：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;最大的感触是中国整体效率非常高，微信太强大了。因为在美国，每一次想找一个人，都会需要发邮件给他，一来一回，这个沟通过程往往不够流畅效率也偏低。但是这次在中国的感受就不一样，比如有一次，我去一个办公室见一个投资人，当场聊完了以后他马上打电话给另一个可以对接资源的人，过了 20 分钟，我就在另一个人的办公室，这种效率在美国是绝对不会有的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;于寅：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我也遇到了类似的事。就是在深圳的时候，一个一直跟我们有接触的投资机构，我跟他们投资经理谈，谈了一个多小时后他说，「走，我带你去见我们投过的另一个公司」。因为当时他觉得我们和这家公司有合作的可能性。于是我们打了个车就去那个公司和他们的负责人开始谈项目了。他们和我们这些创业者一样，都很拼命，我们从下午五六点一直谈到晚上十二点多，关于怎么挖掘项目，关于合作的可能性等等，同样的事儿也发生在北京，两次都是和投资人一直谈到深夜。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9icXvYKCNT2jbZOBI4NicyLcgN6uuvu60oyVdZumTwCTfPuAY3OdLyn86icWE87bXOhwU31ddLUFW7Q/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;CartilaGen 团队在 MIT-CHIEF 中国行&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Synced: 公司都是在这边建立起来的。经过了这次，是否比原来更想回国落地，还是国内竞争压力太大，还是觉得这边的环境更合适一点？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;王雨亭：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt; 我因为从小出国，对中国发展缺乏深入了解。这次回去以后，觉得无论从市场，效率还有投资这块，中国机会都非常多，所以接下来会开始拓展中国市场。现在我们主要做的是一款基于公路骑行用户的发烧级的眼镜。不仅完全保证适配性，由于 3D 打印的灵活性，用户还可以发挥自己的想象力，加入很多个性化的功能和选择。公路骑行在美国这边用户群体很大，运动眼镜的市场也非常成熟，我之前不太清楚中国体育界和骑行界到底发展到了一个什么程度，这次回去接触了一些运动平台，发现这是个极速增长的市场，给我们提供了极大的拓展机会。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;于寅:&lt;/span&gt;&lt;/strong&gt;&lt;span&gt; 我们之前做市场计划的时候其实是两块，一块中国，一块美国。我们针对的病人人群，中国病人的数量是美国的四到五倍左右。但是中国这个市场，已开发的市场的体量大概是美国的二十分之一都不到。我们这次回去跟同领域的投资人聊过之后，他们也有一个共识，在国内现在做这个方向的现在比较少，或者说几乎是没有。但在未来，五到十年之后，这个领域肯定是有那么几家公司能发展起来。所以我们是计划要回去，主要重心放在国内来做这个公司。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Synced: 感谢几位分享你们中国行的一些感受及接下来的市场规划。现在我们聊回产品技术本身，技术永远都是最值得深聊的话题之一。那首先问 CartilaGen 这边，能请您介绍一下你们公司的「可穿戴性给药装置」吗？具体长什么样？具体会有怎样的功能？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;于寅：&lt;/strong&gt;我们公司的创新是将传统的通过系统性的口服给药手段进行改变。我们有一个新型的生物材料可以直接通过注射器或是其他手术手段注射到病人受到创伤的关节内部，达到完全的「靶向治疗」。这样以来，大大减少了系统性的副作用。比如说，口服镇痛药消炎药会出现胃出血。但是我们能做到，哪里痛就给你治疗哪里，而且直接针对造成损伤的治疗靶点，这就是所谓的靶向给药。另外，可穿戴的装置主要是针对运动人群，运动过程中你穿戴在膝关节上的给药装置， 它整体外形很像一个护膝，里面会有能穿透你皮肤的小分子化合药。在你运动过度的时候，机械力的刺激就会激活那个膝关节的装置，对药物进行释放。这样你就会及时接受到镇痛药，就不感觉到疼了。我们看足球比赛运动员扭伤了之后通常要下场补药，但如果用了这个装置，他们就不需要了。下一步如果有可能的话，我们会希望这个装置能监控运动员在运动过程中的肌肉和膝关节运动数据，即作为拥有信息反馈功能的可穿戴装置。这样的话，在运动的过程中，教练就可以在场边监控，如果球员的肌肉感觉到疲劳，数据反馈到监控器上，那教练就可以把球员换下来避免运动损伤。这个是我们后续的开发。现阶段我们正在研发一个感应器，可以感受到运动时人的肌张力变化。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Synced: 那就是，之后也会结合医疗大数据这方面的。一些运动员或运动爱好者有一些骨关节的创伤，如果他们戴上 CartilaGen 的这个装置后不仅可以比较高效的给药，同时还有可能通过一些智能的数据分析来及时反馈，从而更好的运动不至于损伤。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;于寅: &lt;/span&gt;&lt;/strong&gt;&lt;span&gt;是的，算是接下来努力的一个方向。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Synced: 对于 Skelmet 而言，你们是如何将这个3D打印技术跟传统的加工方式结合起来的？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;王雨亭：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;传统的方式是铸模，未来是 3D 打印，在现阶段，有些零件由于成本和材料等问题无法用 3D 打印生产，也没必要用 3D 打印。因为传统的铸模件，像镜片，金属零件，以及硅胶垫，都是很成熟的技术，并且不涉及个性化所以无需打印。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;曹宇：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;对于我们而言，无论是 3D 打印还是传统加工，最终我们要的是一个最好的产品，并不是一个噱头。具体来讲，比如一些小配件，可能就是需要铸模，铸模件和打印件如何去加工和在设计上进行配合，这些可能就是很多公司没有去考虑的。我们所做的制造，是柔性生产，并不是说单一的 3D 打印生产。如果在未来有更好的方法提高产品的质量和性能，我们都会尝试地去做。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9icXvYKCNT2jbZOBI4NicyLcR1XEvFiap1mAXnxZQN4kCHnK75TaSA1gN6sBV1mh9oD96JKDdrDagPw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Skelmet 团队介绍产品在结合人体工学和自动调整上的创新设计&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Synced：那 CartilaGen 也会考虑一些更定制化的产品吗？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;于寅: 当然，我刚才说的那个可穿戴的装置就会使用 3D 扫描结合 3D 打印，在某种程度上实现定制。我们另一个骨科的内植物，你们可能都知道的，就是金属人工关节。我们在做的是一个有生物活性的和人体组织很类似的植入物。在这个方面，我们用的也是 3D 打印技术，但是是属于生物 3D 打印。生物 3D 打印通过生物材料和细胞组合，根据病人的骨，软骨或者膝关节的结构，以及更深一层的细胞结构通过软件重建出来。最后再进行体外培养之后，获得一定的力学强度，再把它植入进病人体内。因为这是病人自己的细胞，所以它会和体内其他组织融合性高，避免排斥，且这样植入的活性生物体较金属而言，生命周期会更长（传统的金属植入使用周期是 10 到 15 年）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9icXvYKCNT2jbZOBI4NicyLcWVodFpSFaRuXP7QsbT1RYlEUXmZdbJllDTjL6AkB5Tibzjxb29b0lpA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图片说明： CartilaGen采用的生物打印技术，即通过生物材料和细胞组合，根据病人的骨，软骨或者膝关节的结构，以及更深一层的细胞结构通过软件重建出来。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Synced: 聊完产品技术我们再来看看用户的需求。同样都是生产与用户亲密接触的装备，在生产设计产品的过程中，产品设计师对产品的设想与用户所期待的产品会有所偏差么？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;于寅: &lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我觉得取决于你这个偏差是怎么定义的。产品的第一代，第二代，第三代， 他们不断地迭代就会更新。所以我们可能会将自己第一代的的产品交给一些专业人员来尝试，拿到反馈；在进行第二代的迭代时尽可能满足多的客户的需求。一开始，肯定是满足那一些最愿意尝试新东西的人或者专业运动员等等，然后通过他们来影响普通消费者，这样我们会得到比较有意义的反馈。到了第三代或者更后期的产品，我们再针对不同人群，不同身高体重年龄的人群的反馈，制造出一款比较适合普通消费者的产品。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;曹宇：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;因为我们本身做的就是走制，所以这些产品都是通过算法为消费者设计的。我们要做的是把算法的识别率提高。作为一个专业做订制的厂商，我们肯定是为消费者着想。除非是极个别的极端数据，例如有些人的眼睛就是一只朝上，一只朝下，这样的个别情况我们会单独考虑。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9icXvYKCNT2jbZOBI4NicyLcWBtXCVjL443MeY4Poy18tPo2ibhtysv0PMnKicPXe9vG7yiaRticXgQpJA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Synced: 好的，谢谢！采访最后是我们 Synced Talk 的固定快问快答环节。每一期我们都有固定的主题，这一期我们的主题是可穿戴与智能医疗。那么这里有三个问题，请你根据直观感受作答。第一个问题，你们认为既智能手表之后，什么会成为下一代可穿戴成品的主要载体？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;曹宇&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：我觉得，智能的趋势都会逐渐向头部进行转移。因为头部的感觉器官非常多，人类大脑的构造其实是一个信息处理器。 另外，未来的可穿戴大多会服务于虚拟现实，增强现实或混合现实技术的发展，肯定需要更大的处理和计算的量，所以我倾向于脑穿戴的某种载体。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;王雨亭：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我觉得会围绕眼睛，有可能是一个类似隐形眼镜的传感器，佩戴之后从外观上和普通人毫无差异，但是可以通过眼睛和脑部的细微动态控制各种功能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;于寅：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;可能想得更远一点。我觉得应该是人身体的某个部分。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Synced: 直接就把芯片注入人体么？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;于寅:&lt;/span&gt;&lt;/strong&gt;&lt;span&gt; 不完全是。我觉得以后，人都可能不完全是生物体。我们人会变成 「Cyborg」，某些部分是机器，某些部分是肉体，我不知道有多远，但以后的人一定是和机器结合形成的一个全新的个体，所以我觉得可穿戴很有可能会发展成身体的某个部分比如人造皮肤，能实现对体温，血含氧量，酸碱度的监测。残疾的人，有一个机械假肢。然后这个假肢就可以成为他身体的一部分，来协助他的日常生活并同时来反馈他的日常数据。所以，对于可穿戴设备，无论是正常人还是残疾人，这都是有可能实现的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Synced：第二个问题，作为了一个消费者或者是用户，你会担心你自己个人信息被人盗用吗？或者是说，有哪些人可以获取这些数据的呢？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;王雨亭：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt; 我认为这是一个循序渐进的过程。类似于十年前，很多人会拒绝将自己的信用卡信息保存在网络购物的页面上，但对于今天的大部分的人来讲，这已经不是一个障碍了，大家基本都会使用记住密码或者保留信用卡信息的功能。所以，我认为数据安全性的问题一直都存在，但随着网络安全不断进步，数据使用方式更加规范后，或许问题就会减小。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;曹宇&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：在我们的平台上，消费者需要把头部的 3D 模型上传到我们的数据库才能进行定制，这里面自然涉及很多隐私的东西。如果我们的产品确实做的非常好，我觉得这可能就是一个很自然的采集数据的过程。另外我们将来会与其他穿戴产品厂商（例如滑雪镜、运动头盔、VR眼镜厂商）合作，我们利用已有用户数据和算法为企业提供设计服务。所有数据都是经过处理的，不会向其他厂商直接发送原始数据。在隐私与定制的便利性之间找到平衡。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们现在是用编程的手段去操作这个产品设计。在未来，工业设计师需要与程序员、编程建模工程师一起合作，设计一种算法或者是很多算法，通过算法进行自动设计，而不是亲手去操作，这整套工程体系，和商业模式都是全新的。除了人才的需求外，我们现阶段需要尽快地把产品商业化，这样才有一个可持续发展的过程和人才的积累。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;于寅: &lt;/span&gt;&lt;/strong&gt;&lt;span&gt;像我们做那个生物打印组织和器官，就需要大量的数据，成千上万的病人数据，这点来说，安全性在医疗领域里面是非常重要的，但是，目前也没有别的解决办法。唯一的办法就是拥有更完整的技术来防止黑客攻击或者是检测黑客攻击，包括现在MIT-CHIEF 有一个团队叫 SecurityX，专门做云端数据安全保护和检测黑客攻击的。另外，这里面还涉及到道德层面上的东西，就是你怎么把这个数据传达给病人。我举一个比较极端的例子。比如说，一个病人今年去医院做了基因测试，医生发现他有某个癌症的基因，十年之后他会得这个癌症。作为医生，我会不会需要现在告诉这个病人。这里面包含道德的问题，也跟医疗大数据有关，怎么去使用它，在什么时候使用它，这个也需要考虑。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Synced：确定值得思考。最后一个问题。对于现在的这个社会，你会认为大数据在哪一个领域会有最大的推动力?&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;于寅：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;医疗或者气象吧。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;曹宇：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我觉得像金融，经济这些领域里大数据的应用都是很关键的。它包括了很多资源调配来满足市场需求，现在有一些比较火的FinTech，可能未来不光是金融本身，也包括经济本身还有一些物联网的东西，我觉得这些都是一体，它其实都代表着人类社会的一些资源调配的形式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;王雨亭：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt; 我赞同曹宇的观点，因为经济上面的数据会影响着整个人类社会的走向和布局。然后还有就是物联网 IOT 这方面的数据，它代表了从产品到用户的整合，和从数据到资源上的整合。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Synced : 谢谢！也希望你们在中国的推广和落地一切顺利！&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Skelmet 团队正在招募软件工程师、工业设计师和市场营销经理。如果想了解更多关于 Skelmet 的信息，请关注他们的 Facebook https://www.facebook.com/Skelmet-182718695447741/ 和 Twitter #SkelmetInc 获得最新资讯。王雨亭邮箱：rain@skelmet.com&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;artilagen 团队正在招募 Chief Engineer （3D打印机开发）和 Chief Material Scientist （生物材料研发），坐标美国波士顿和中国深圳。如果想了解更多关于CartilaGen 的信息或者岗位信息，请扫描下方二维码：&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9icXvYKCNT2jbZOBI4NicyLcPCRjCbCvv2NpDbWSKyjGVicVQ16F3t5t6icf4aTIibCXA5iaOjzQbBMbdQ/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心原创，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;MIT-CHIEF 2016 Community向创业团队正式开放！点击 www.mitchief.org 了解详情！&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Sun, 28 Aug 2016 15:11:40 +0800</pubDate>
    </item>
    <item>
      <title>专栏 | 从特斯拉到计算机视觉之「图像语义分割」</title>
      <link>http://www.iwgc.cn/link/2460366</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心专栏&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&amp;nbsp;魏秀参、谢晨伟&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;说起特斯拉，大家可能立马会想到今年 5 月份发生在特斯拉 Model S 自动驾驶上的一宗夺命车祸。初步的调查表明，在强烈的日照条件下，驾驶员和自动驾驶系统都未能注意到牵引式挂车的白色车身，因此未能及时启动刹车系统。而由于牵引式挂车正在横穿公路，且车身较高，这一特殊情况导致 Model S 从挂车底部通过时，其前挡风玻璃与挂车底部发生撞击，导致驾驶员不幸遇难。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;无独有偶，8 月 8 日美国密苏里州的一名男子、特斯拉 Model X 车主约书亚•尼利（Joshua Neally）在上班途中突发肺栓塞。在 Model X 的 Autopilot 自动驾驶功能的帮助下，他安全抵达了医院。这「一抑一扬」着实让人回味无穷，略有些「败也萧何，成也萧何」之意。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9icXvYKCNT2jbZOBI4NicyLcxrZNRwCdTRu8icQldkqic0kzj59nEM9U5l148XsbManmzic5PIYGMJ6qg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;好奇的读者一定会有疑问：这「一成一败」背后的原理到底是什么？是自动驾驶系统中的哪个部分发生了失误而造成车祸？又是哪部分技术支撑了自动驾驶过程呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今天，我们就来谈谈自动驾驶系统中的一项重要核心技术——图像语义分割（Semantic image segmentation）。图像语义分割作为计算机视觉（Computer vision）中图像理解（Image understanding）的重要一环，不仅在工业界的需求日益凸显，同时语义分割也是当下学术界的研究热点之一。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;什么是图像语义分割？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图像语义分割可以说是图像理解的基石性技术，在自动驾驶系统（具体为街景识别与理解）、无人机应用（着陆点判断）以及穿戴式设备应用中举足轻重。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们都知道，图像是由许多像素（Pixel）组成，而「语义分割」顾名思义就是将像素按照图像中表达语义含义的不同进行分组（Grouping）／分割（Segmentation）。下图取自图像分割领域的标准数据集之一 PASCAL VOC。其中，左图为原始图像，右图为分割任务的真实标记（Ground truth）：红色区域表示语义为「person」的图像像素区域，蓝绿色代表「motorbike」语义区域，黑色表示「background」，白色（边）则表示未标记区域。显然，在图像语义分割任务中，其输入为一张 H×W×3 的三通道彩色图像，输出则是对应的一个 H × W 矩阵，矩阵的每一个元素表明了原图中对应位置像素所表示的语义类别（Semantic label）。因此，图像语义分割也称为「图像语义标注」（Image semantic labeling）、「像素语义标注」（Semantic pixel labeling）或「像素语义分组」（Semantic pixel grouping）。&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9icXvYKCNT2jbZOBI4NicyLcy7uxrhtRf0PicTTWYARQqh3Zexs4MaZ7bAia5LEcBGgX2644rRADiaElQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从上图和题图中，大家可以明显看出图像语义分割任务的难点便在于这「语义」二字。在真实图像中，表达某一语义的同一物体常由不同部件组成（如，building，motorbike，person 等），同时这些部分往往有着不同的颜色、纹理甚至亮度（如building），这给图像语义的精确分割带来了困难和挑战。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;前 DL 时代的语义分割&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从最简单的像素级别「阈值法」（Thresholding methods）、基于像素聚类的分割方法（Clustering-based segmentation methods）到「图划分」的分割方法（Graph partitioning segmentation methods），在深度学习（Deep learning, DL）「一统江湖」之前，图像语义分割方面的工作可谓「百花齐放」。在此，我们仅以「Normalized cut」[1]和「Grab cut」 [2]这两个基于图划分的经典分割方法为例，介绍一下前 DL 时代语义分割方面的研究。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Normalized cut （N-cut）方法&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;是基于图划分（Graph partitioning）的语义分割方法中最著名的方法之一，于 2000 年 Jianbo Shi 和 Jitendra Malik 发表于相关领域顶级期刊 TPAMI。通常，传统基于图划分的语义分割方法都是将图像抽象为图（Graph）的形式 G=（V，E） （V 为图节点，E 为图的边），然后借助图理论（Graph theory）中的理论和算法进行图像的语义分割。常用的方法为经典的最小割算法（Min-cut algorithm）。不过，在边的权重计算时，经典 min-cut 算法只考虑了局部信息。如下图所示，以二分图为例（将 G 分为不相交的 , 两部分），若只考虑局部信息，那么分离出一个点显然是一个 min-cut，因此图划分的结果便是类似 或 这样离群点，而从全局来看，实际想分成的组却是左右两大部分。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9icXvYKCNT2jbZOBI4NicyLc3388B5RgAiaT5FDOSw4iaj5gVwnlQ9b5WgoOjAqvmPRXA5IadMHfMy3w/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;针对这一情形，N-cut 则提出了一种考虑全局信息的方法来进行图划分（Graph partitioning），即，将两个分割部分 A,B , 与全图节点的连接权重（assoc(A,V) 和 assoc(B,V)）考虑进去：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如此一来，在离群点划分中，&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9icXvYKCNT2jbZOBI4NicyLcyiaa15Hfe7EJfDhQPRtavUZOHAUoO2sKcjl8x8Yx6aswcNe4PHoicPeg/0?wx_fmt=png"/&gt;中的某一项会接近 1，而这样的图划分显然不能使得&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9icXvYKCNT2jbZOBI4NicyLcyiaa15Hfe7EJfDhQPRtavUZOHAUoO2sKcjl8x8Yx6aswcNe4PHoicPeg/0?wx_fmt=png"/&gt;是一个较小的值，故达到考虑全局信息而摒弃划分离群点的目的。这样的操作类似于机器学习中特征的规范化（Normalization）操作，故称为Normalized cut。N-cut不仅可以处理二类语义分割，而且将二分图扩展为 K 路（ -way）图划分即可完成多语义的图像语义分割，如下图例。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9icXvYKCNT2jbZOBI4NicyLcMzwtpepuXCgmbFZRxR96bENrHNicFYycAZ2yvQRpaSLCUpOKyd9UUqw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Grab cut &lt;/span&gt;&lt;/strong&gt;&lt;span&gt;是微软剑桥研究院于 2004 年提出的著名交互式图像语义分割方法。与 N-cut 一样，grab cut 同样也是基于图划分，不过 grab cut 是其改进版本，可以看作迭代式的语义分割算法。Grab cut 利用了图像中的纹理（颜色）信息和边界（反差）信息，只要少量的用户交互操作即可得到比较好的前后背景分割结果。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 Grab cut 中，RGB 图像的前景和背景分别用一个高斯混合模型（Gaussian mixture model, GMM）来建模。两个 GMM 分别用以刻画某像素属于前景或背景的概率，每个 GMM 高斯部件（Gaussian component）个数一般设为 。接下来，利用吉布斯能量方程（Gibbs energy function）对整张图像进行全局刻画，而后迭代求取使得能量方程达到最优值的参数作为两个 GMM 的最优参数。GMM 确定后，某像素属于前景或背景的概率就随之确定下来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在与用户交互的过程中，Grab cut 提供两种交互方式：一种以包围框（Bounding box）为辅助信息；另一种以涂写的线条（Scribbled line）作为辅助信息。以下图为例，用户在开始时提供一个包围框，grab cut 默认的认为框中像素中包含主要物体／前景，此后经过迭代图划分求解，即可返回扣出的前景结果，可以发现即使是对于背景稍微复杂一些的图像，grab cut 仍有不俗表现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9icXvYKCNT2jbZOBI4NicyLcy4Q1Ip3R16DH0MaRicFroFSvAnJdibIRSwOJueCIQX39wTSND93yKncQ/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不过，在处理下图时，grab cut 的分割效果则不能令人满意。此时，需要额外人为的提供更强的辅助信息：用红色线条／点标明背景区域，同时用白色线条标明前景区域。在此基础上，再次运行 grab cut 算法求取最优解即可得到较为满意的语义分割结果。Grab cut 虽效果优良，但缺点也非常明显，一是仅能处理二类语义分割问题，二是需要人为干预而不能做到完全自动化。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9icXvYKCNT2jbZOBI4NicyLcPxWZzzNzRBZuUKrGQ2wQpJEGuSNdQ4XwfEOYiaWQHjwZqGWhITpt87Q/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;DL 时代的语义分割&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其实大家不难看出，前 DL 时代的语义分割工作多是根据图像像素自身的低阶视觉信息（Low-level visual cues）来进行图像分割。由于这样的方法没有算法训练阶段，因此往往计算复杂度不高，但是在较困难的分割任务上（如果不提供人为的辅助信息），其分割效果并不能令人满意。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在计算机视觉步入深度学习时代之后，语义分割同样也进入了全新的发展阶段，以全卷积神经网络（Fully convolutional networks，FCN）为代表的一系列基于卷积神经网络「训练」的语义分割方法相继提出，屡屡刷新图像语义分割精度。下面就介绍三种在 DL时代语义分割领域的代表性做法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;全卷积神经网络 [3]&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;全卷积神经网络 FCN 可以说是深度学习在图像语义分割任务上的开创性工作，出自 UC Berkeley 的 Trevor Darrell 组，发表于计算机视觉领域顶级会议 CVPR 2015，并荣获best paper honorable mention。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;FCN 的思想很直观，即直接进行像素级别端到端（end-to-end）的语义分割，它可以基于主流的深度卷积神经网络模型（CNN）来实现。正所谓「全卷积神经网络」，在FCN中，传统的全连接层 fc6 和 fc7 均是由卷积层实现，而最后的 fc8 层则被替代为一个 21 通道（channel）的 1x1 卷积层，作为网络的最终输出。之所以有 21 个通道是因为 PASCAL VOC 的数据中包含 21 个类别（20个object类别和一个「background」类别）。下图为 FCN 的网络结构，若原图为&lt;span&gt; H×W×3&lt;/span&gt;，在经过若干堆叠的卷积和池化层操作后可以得到原图对应的响应张量（Activation tensor） &lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9icXvYKCNT2jbZOBI4NicyLcnmicpb8Vj9nP4nv6vrKdK3cqwjlDmKjqyTNlNg6Br9fN7DgqRic8X9Vw/0?wx_fmt=png"/&gt;，其中， &lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9icXvYKCNT2jbZOBI4NicyLcNkdjDeiae8MFKy3S7jfXjD4gTxKpX298cMiaGMicKUTfGEPJB8ewxN9Lg/0?wx_fmt=png"/&gt;为 i 第 层的通道数。可以发现，由于池化层的下采样作用，使得响应张量的长和宽远小于原图的长和宽，这便给像素级别的直接训练带来问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9icXvYKCNT2jbZOBI4NicyLckq3ZVVJgX5Gnb0ib7TCic7WruDnicMPYAe1UQnFxLTIvWkibkhdH2EEZ1A/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了解决下采样带来的问题，FCN 利用双线性插值将响应张亮的长宽上采样到原图大小，另外为了更好的预测图像中的细节部分，FCN 还将网络中浅层的响应也考虑进来。具体来说，就是将 Pool4 和 Pool3 的响应也拿来，分别作为模型 FCN-16s 和 FCN-8s 的输出，与原来 FCN-32s 的输出结合在一起做最终的语义分割预测（如下图所示）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9icXvYKCNT2jbZOBI4NicyLcvcMeWhufjU2NibrTNibbDB4vHMEwnKlCgOgmTMoeLg4Osz2sV0rRHPIw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下图是不同层作为输出的语义分割结果，可以明显看出，由于池化层的下采样倍数的不同导致不同的语义分割精细程度。如 FCN-32s，由于是 FCN 的最后一层卷积和池化的输出，该模型的下采样倍数最高，其对应的语义分割结果最为粗略；而 FCN-8s 则因下采样倍数较小可以取得较为精细的分割结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9icXvYKCNT2jbZOBI4NicyLc6xKLFn4M08W3XsxHqcta8xY6qye1T7EhciaUObVAmzFV6gLFRaxsibmg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Dilated Convolutions [4]&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;FCN 的一个不足之处在于，由于池化层的存在，响应张量的大小（长和宽）越来越小，但是FCN的设计初衷则需要和输入大小一致的输出，因此 FCN 做了上采样。但是上采样并不能将丢失的信息全部无损地找回来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对此，dilated convolution 是一种很好的解决方案——既然池化的下采样操作会带来信息损失，那么就把池化层去掉。但是池化层去掉随之带来的是网络各层的感受野（Receptive field）变小，这样会降低整个模型的预测精度。Dilated convolution 的主要贡献就是，如何在去掉池化下采样操作的同时，而不降低网络的感受野。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以 3×3 的卷积核为例，传统卷积核在做卷积操作时，是将卷积核与输入张量中「连续」的 3×3 的 patch 逐点相乘再求和（如下图a，红色圆点为卷积核对应的输入「像素」，绿色为其在原输入中的感知野）。而 dilated convolution 中的卷积核则是将输入张量的 &amp;nbsp;3×3 patch 隔一定的像素进行卷积运算。如下图 b 所示，在去掉一层池化层后，需要在去掉的池化层后将传统卷积层换做一个「dilation=2」的 dilated convolution 层，此时卷积核将输入张量每隔一个「像素」的位置作为输入 patch 进行卷积计算，可以发现这时对应到原输入的感知野已经扩大（dilate）为 ；同理，如果再去掉一个池化层，就要将其之后的卷积层换成「dilation=4」的 dilated convolution 层，如图 c 所示。这样一来，即使去掉池化层也能保证网络的感受野，从而确保图像语义分割的精度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9icXvYKCNT2jbZOBI4NicyLcY5M5LAibDiaGKKCfYDZvWSIKujMvJ2W4ic8SYpQWIJHrAialic8QjlaZPpA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从下面的几个图像语义分割效果图可以看出，在使用了 dilated convolution 这一技术后可以大幅提高语义类别的辨识度以及分割细节的精细度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9icXvYKCNT2jbZOBI4NicyLcPlcRibHw9vibIPWtWEFKFmmPnPiaZw9jCtgngIia8tx80NQOhRmHV8K6Cg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;以条件随机场为代表的后处理操作&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当下许多以深度学习为框架的图像语义分割工作都是用了条件随机场（Conditional random field，CRF）作为最后的后处理操作来对语义预测结果进行优化。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一般来讲，CRF 将图像中每个像素点所属的类别都看作一个变量 &lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9icXvYKCNT2jbZOBI4NicyLcPdjezkeDxOsSpKSv0bdQkNDib5T2QNBibGynJQ7CPWd4EicT5WhYNCFGA/0?wx_fmt=png"/&gt;&lt;br/&gt;，然后考虑任意两个变量之间的关系，建立一个完全图（如下图所示）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9icXvYKCNT2jbZOBI4NicyLcf3yAibo5uTYI1aT59OvAOpOyBicgLe4Muvmha9ub1CQc5UktiaMF81qOQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在全链接的 CRF 模型中，对应的能量函数为：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9icXvYKCNT2jbZOBI4NicyLcFODuSr13VDAmaXkxccZBcXyqqDZd5wLvqgM3k3t1pvMU0jRX5qFbiaQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其中&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9icXvYKCNT2jbZOBI4NicyLcTJOACpd6fxUCyu9yZA4VIPalLA0yKedibp1vD4U26Fiauy5muNvicdjhw/0?wx_fmt=png"/&gt;是一元项，表示&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9icXvYKCNT2jbZOBI4NicyLcBmKfnib1jic8kfBLkdG6RwDicPXibDNvSBHpU0J7DpkpAcA9Aylp52oJ3w/0?wx_fmt=png"/&gt;像素对应的语义类别，其类别可以由 FCN 或者其他语义分割模型的预测结果得到；而第二项为二元项，二元项可将像素之间的语义联系／关系考虑进去。例如，「天空」和「鸟」这样的像素在物理空间是相邻的概率，应该要比「天空」和「鱼」这样像素的相邻概率大。最后通过对 CRF 能量函数的优化求解，得到对 FCN 的图像语义预测结果进行优化，得到最终的语义分割结果。值得一提的是，已经有工作[5]将原本与深度模型训练割裂开的 CRF 过程嵌入到神经网络内部，即，将 FCN+CRF 的过程整合到一个端到端的系统中，这样做的好处是 CRF 最后预测结果的能量函数可以直接用来指导 FCN 模型参数的训练，而取得更好的图像语义分割结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9icXvYKCNT2jbZOBI4NicyLc1fMmhyGicYGhyibakBJHh1IqKGz0WW0lHic3ofCwQiaRr1v2pXrjHTSMOA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;展望&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;俗话说，「没有免费的午餐」（No free lunch）。基于深度学习的图像语义分割技术虽然可以取得相比传统方法突飞猛进的分割效果，但是其对数据标注的要求过高：不仅需要海量图像数据，同时这些图像还需提供精确到像素级别的标记信息（Semantic labels）。因此，越来越多的研究者开始将注意力转移到弱监督（Weakly-supervised）条件下的图像语义分割问题上。在这类问题中，图像仅需提供图像级别标注（如，有「人」，有「车」，无「电视」）而不需要昂贵的像素级别信息即可取得与现有方法可比的语义分割精度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外，示例级别（Instance level）的图像语义分割问题也同样热门。该类问题不仅需要对不同语义物体进行图像分割，同时还要求对同一语义的不同个体进行分割（例如需要对图中出现的九把椅子的像素用不同颜色分别标示出来）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9icXvYKCNT2jbZOBI4NicyLcicaNcVtVCKgd9CYHmQDU73DD2XHkXkqfUslfic3SiaIj1J1YWWaUhHLHg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，基于视频的前景／物体分割（Video segmentation）也是今后计算机视觉语义分割领域的新热点之一，这一设定其实更加贴合自动驾驶系统的真实应用环境。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;References:&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[1] Jianbo Shi and Jitendra Malik. Normalized Cuts and Image Segmentation, IEEE Transactions on Pattern Analysis and Machine Intelligence, Vol. 22, No. 8, 2000.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[2] Carsten Rother, Vladimir Kolmogorov and Andrew Blake. "GrabCut"--Interactive Foreground Extraction using Iterated Graph Cuts, ACM Transactions on Graphics, 2004.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[3] Jonathan Long, Evan Shelhamer and Trevor Darrell. Fully Convolutional Networks for Semantic Segmentation. IEEE Conference on Computer Vision and Pattern Recognition, 2015.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[4] Fisher Yu and Vladlen Koltun. Multi-scale Context Aggregation by Dilated Convolutions. International Conference on Representation Learning, 2016.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[5] Shuai Zheng, Sadeep Jayasumana, Bernardino Romera-Paredes, Vibhav Vineet, Zhizhong Su, Dalong Du, Chang Huang and Philip H. S. Torr. Conditional Random Fields as Recurrent Neural Networks. International Conference on Computer Vision, 2015.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;作者简介&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;魏秀参：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;南京大学计算机系机器学习与数据挖掘所（LAMDA）博士生，研究方向为计算机视觉和机器学习。曾在国际顶级期刊和会议发表多篇学术论文，并多次获得国际计算机视觉相关竞赛冠亚军，另撰写的「Must Know Tips/Tricks in Deep Neural Networks」受邀发布于国际知名数据挖掘论坛 KDnuggets 等。 微博ID：Wilson_NJUer&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;谢晨伟：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;南京大学计算机系机器学习与数据挖掘所（LAMDA）硕士生，研究方向为计算机视觉和机器学习。&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;本文为机器之心读者投稿，如需转载请联系本公众号或作者&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Sun, 28 Aug 2016 15:11:40 +0800</pubDate>
    </item>
    <item>
      <title>学界 | 重磅论文：基准评测当前最先进的深度学习软件工具</title>
      <link>http://www.iwgc.cn/link/2460367</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自 arXiv.org&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;作者：Shaohuai Shi、Qiang Wang、Pengfei Xu、Xiaowen Chu&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9icXvYKCNT2jbZOBI4NicyLcNpY2F97rsLCjacPf1NFUulXL636FTKasJjlYYV2XULTYqooKp74zQA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;摘要&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;深度学习已被证明是一种可成功用于许多任务的机器学习方法，而且它的广泛流行也将很多开源的深度学习软件工具开放给了公众。训练一个深度网络往往是一个非常耗时的过程。为了解决深度学习中巨大的计算难题，许多工具利用了多核 CPU 和超多核 GPU 这样的硬件特性来缩短训练时间。但是，在不同的硬件平台上训练不同类型的深度网络时，不同的工具会有不同的特性和运行性能，这让终端用户难以选择出合适的软件和硬件搭配。在这篇论文中，我们的目标是对当前最先进的 GPU 加速的深度学习软件工具（包括：Caffe, CNTK, TensorFlow 和 Torch ）进行比较研究。我们在两种 CPU 平台和三种 GPU 平台上使用三种流行的神经网络来评测了这些工具的运行性能。我们做出了两方面的贡献。第一，对于深度学习终端用户，我们的基准评测结果可用于指导合适的软件工具和硬件平台的选择。第二，对于深度学习软件开发者，我们的深度分析为进一步优化训练的性能指出了可能的方向。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;实验数据&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9icXvYKCNT2jbZOBI4NicyLciaJwR5X7o2kMvdLLKM7r7IXTXmUpWJlPF5N8FywiaMdlnS4nw4FNpgjg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;表1：用于实验的软件&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9icXvYKCNT2jbZOBI4NicyLcc8lUxsh4fmsvSO9Efl8nzbPibxOVrTbnvppygtY3n2XVgEHcOXabOkA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;表2：本实验的神经网络设置&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9icXvYKCNT2jbZOBI4NicyLcfdzejeYKoH5HofJVmeK1amoJWkeO6kccRq8iab8bVrLmUZw3ibxKcn4A/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;表3：本实验的硬件设置&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9icXvYKCNT2jbZOBI4NicyLcn4kS36ZpQHCeb9J10TbLaEazXh7L9NkiaAB32XkKYwfJPZfebr3L2Ow/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;表4：对比结果（每个 mini-batch 的时间/秒；其中加粗的为最优）&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;结论&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是使用不同的硬件平台、在三种不同类型的流行深度学习方法上对 GPU 加速工具的评估。根据基准评测结果，当存在 GPU 时，我们发现 Caffe 平台在全连接网络上表现更好，而 TensorFlow 在卷积神经网络和循环神经网络上都表现突出。GPU 内存是在 Caffe 等许多工具上运行大型网络的关键指标之一，CNTK 和 Torch 不能在 GTX 980（其有 4GB 内存）上运行 32 或更多个 mini-batch 大小的 ResNet-50，而 TensorFlow 在管理 GPU 内存上表现更好，并且其基本上可以在所有的配置情况下运行。cuBLAS 是一个高性能的 BLAS 库，但其 API 参数对实现好的结果来说是很重要的。在计算一些情况下的卷积运算时，FFT 是一个更好的选择。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在仅使用 CPU 的机器上，Caffe 在 CPU 并行上表现更好，TensorFlow 也在 CPU 资源利用上有很好的表现。在 CPU 并行机制上，使分配的线程等于 CPU 的核数可以得到更好的表现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;GTX 1080 有更高的基础时钟（1733 MHz）和更多 CUDA 内核，在大部分案例中也都获得了更好的结果。但是，Tesla K80 有更大的内存（12 GB），可以支持应用运行更大型的网络和更大的 mini-batch。此外，每一个 K80 卡还配备了 2 个 GPU 芯片，这可能能让其在运行并行程序时获得更好的表现，但在我们的基准评测中，它并没有得到充分的使用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;局限：我们没有测试跨多个 GPU 和多台机器的可扩展性，因为这种方法可能无法增强一些工具的主要特性。比如虽然 CNTK 支持跨多 GPU 和机器运行，但其它工具却不行。&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;点击「阅读原文」，下载此论文↓↓↓&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;</description>
      <pubDate>Sun, 28 Aug 2016 15:11:40 +0800</pubDate>
    </item>
    <item>
      <title>深度 | 深度学习系列文章Part2：迁移学习和微调深度卷积神经网络（附论文）</title>
      <link>http://www.iwgc.cn/link/2451506</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自 RevolutionAnalytics&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：&amp;nbsp;&lt;span&gt;Anusua Trivedi&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：武竞、吴攀、李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;本文是微软数据科学家 Anusua Trivedi 所写的《Deep Learning》系列文章的第二部分，是对迁移学习和微调深度卷积神经网络的介绍。机器之心此前也已经编译了该系列的第一部分，详情点击《&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718160&amp;amp;idx=3&amp;amp;sn=a2114e3324f28740d2603da26fbbdfb4&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718160&amp;amp;idx=3&amp;amp;sn=a2114e3324f28740d2603da26fbbdfb4&amp;amp;scene=21#wechat_redirect"&gt;五大主流深度学习框架比较分析：MXNET是最好选择&lt;/a&gt;》。文中涉及到的论文可点击阅读原文下载。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是由几个部分组成的博客系列，我将在此系列中聊一聊我对深度学习的经验及认识。在第一部分，我讨论了不同的有代表性的框架的优劣，以及我选择 Theano（与 Lasagne）作为我的平台的原因。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第二部分是基于我将要在 2016 年度数据科学论坛（The Data Science Conference）上的发言内容整理的。我将在这部分讲解深度卷积神经网络（DCNN：Deep Convolutional Neural Network），以及迁移学习（Transfer learning）和微调（Fine-tuning）可以如何帮助更好地完成特定领域图像的训练过程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;引言&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一种叫糖尿病视网膜病变（DR）的眼病是视力减退的常见原因。使用荧光血管造影筛查糖尿病患者有可能降低致盲的风险。目前的研究趋势已经证明，DCNN 在自动分析大量图像和识别图像特征方面是非常有效的，它可以将图像分类的误差降到最低。DCNN 很少从头开始训练，因为得到足够大样本量的特定领域的数据集并不是那么容易。同时由于现代 DCNN 在 GPU 上训练需要耗时 2-3 周，加州大学伯克利分校的视觉和学习中心（BVLC）发布了一些最终 DCNN 检查点。在这篇文章中，我们使用一个预训练的网络：GoogLeNet。GoogLeNet 是基于大量真实图像的 ImageNet 图像库预训练的网络。我们将学习的 ImageNet 的权重迁移（transfer）作为网络的初始权重，然后微调（fine-tune）这些预训练的通用网络使它们能够识别出眼睛的荧光血管造影图像，从而提高对 DR 眼病的预测效果。 &amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;使用提取的明确特征预测糖尿病视网膜病变&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于提取 DR 患者的显著特征，人们已经进行了很多算法开发和形态图像处理方面的研究。一个标准的图像分类技术所用的一般工作流程如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;噪声去除和增强对比度的图像预处理技术&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;特征提取技术&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;分类&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;预测&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Faust 等人的论文提供了一种非常全面的分析模型来提取 DR 筛选的特征。Vujosevic 等人的论文基于 55 位病人的图像数据，建立了一个明确形成单发病灶特征的二元分类器。Acharya 等人的论文使用形态图像处理技术来提取血管和出血点，然后在一个 331 张图像的数据集上训练了一个 SVM（支持向量机）模型。Nayak 等人的论文报告称在 140 张图像的数据集的二元分类任务上实现了 90% 的准确率和 90% 的灵敏度（sensitivity）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然而，所有这些处理方法都是非常耗时耗力的。进一步提高预测精度仍需要大量有标签的数据。对于图像数据集的图像处理和特征提取是一件十分繁琐和耗费时间的事情。综上，我们需要选用一种自动处理图像和特征提取的方法——DCNN。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;深度卷积神经网络（DCNN）&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图像数据需要相关领域的专业知识来提取关键特征。DCNN 可以自动从特定领域的图像中提取特征，不需要任何特征工程技术。下列过程使得 DCNN 非常适合用来分析图像信息：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;DCNN 可以训练有很多层的网络&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;叠加多个层可以建立改进的特征空间&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;初始层用来学习最基本的特征（例如颜色、边缘等）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;后面的层用来学习更高级的特征（针对输入数据集的特征）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;最终层的特征被送入分类层 &amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW82qLcVusw1NaibR1hJB2OKfQ0qNAZXx9U0cJJ844WlDkqLJCIR66mic256h0C4L2VbUPpwemgZ64TQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;C 层是卷积，S 层是池化/采样&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;卷积&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：卷积层由矩形网格的神经元构成。卷积层中每一个的神经元的权重相同。卷积过滤器（convolution filter）由卷积层的权重确定。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW82qLcVusw1NaibR1hJB2OKf3NwwtnY1kxlJrUfoqcaODN24icc5IQS6MlK7WfTZXicbXicDqrw4URqEw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;卷积&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;池化：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;池化层从卷积层获取小矩形块，对这些块进行子抽样（subsample），以产生该块的单个输出。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW82qLcVusw1NaibR1hJB2OKfYYPTKC8qAxN3bL0kKAMFYHbCMaKvF11F9zdXoTxF0VCJtcyKCpO8Wg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;池化&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这篇文章中，我们将使用谷歌开发的 GoogLeNet DCNN。GoogLeNet 曾赢得了 2014 年的 ImageNet 挑战赛（ImageNet challenge），并创造了同期结果的最好记录。开发这个模型的动机是为了得到一个更深度的同时又在计算上更便宜的计算架构。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW82qLcVusw1NaibR1hJB2OKfPuXZgza3fEia4cvEawAJFfcq5OibkmkNmJumUTUsicSE4A5clpk3CPHDg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;GoogLeNet&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;迁移学习和微调 DCNN&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在实践中，我们通常不会完全从头开始随机初始化训练 DCNN，这是因为有能满足深度网络需求的足够大小的数据集相当的少见。作为代替，常见的是在一个大型数据集上预训练一个 DCNN，然后使用这一训练的 DCNN 的权重作为初始设置或作为相关任务的固定的特征提取器。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;微调（Fine-Tuning）：迁移学习策略取决于多种因素，但最重要的两个是新数据集的大小以及新数据集与原数据集的相似度。谨记网络前面几层的 DCNN 特征更加泛型（generic），在后面层中更加具有数据集特定性（dataset-specific），以下是 4 个主要情景：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;新数据集相比于原数据集在大小上更小，在内容上相似：如果数据过小，考虑到过拟合，这对 DCNN 的微调来说不太好。因为数据类似于原数据，我们期望 DCNN 中更高层次的特征也与此数据集相关。因此，最好的思路可能是在 CNN 特征上训练一个线性分类器。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;新数据集相比于原数据集在大小上较大，在内容上相似：由于我们有更多的数据，如果我们试图微调整个网络那我们更有信心不会过拟合。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;新数据集相比于原数据集更小但内容很不相同：由于数据较小，只训练一个线性分类器可能更好。因为数据集不同，从网络顶部就开始训练分类器可能不是最好的选择，这包含更多的数据集特定特征。另外，从网络前部的激活函数开始训练分类器可能更好一点。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;新数据集相比于原数据集较大，但内容非常不同：由于数据集很大，我们可能会期望从头开始训练一个 DCNN。然而，在实践中从一个预训练模型开始初始化权重仍然是一种有益的方法。在这种情况下，我们会有足够的数据和信心对整个网络进行微调。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;微调 DCNN&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：对 DR 预测问题而言，我们属于第四种情景。我们通过持续的反向传播来微调预训练的 DCNN 的权重。微调 DCNN 的所有层是可能的，或者保持前面一些层固定（由于担忧过拟合）而只微调网络的一些高层部分是可能的。可以这么做是因为我们已经观察到 DCNN 的一些早期特征中所包含的特征更为一般化（如边缘检测器或彩色斑点检测器），可以在许多任务中发挥作用；而 DCNN 中更靠后的层会越来越特定于该 DR 数据中所包含的分类的细节。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;迁移学习的限制&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：因为我们使用了预训练的网络，所以我们在模型架构方面受到了一点点限制。比如说，我们不能随意移除预训练网络中的卷积层。但由于参数共享的关系，我们可以很轻松地在不同空间尺寸的图像上运行一个预训练网络。这在卷积层和池化层和情况下是显而易见的，因为它们的前向函数（forward function）独立于输入内容的空间尺寸。在全连接层（FC）的情形中，这仍然成立，因为全连接层可被转化成一个卷积层。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;学习率（learning rate）&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：我们假设预训练的 DCNN 的权重是相对较好的，因此我们可以给正被微调的 DCNN 权重使用较小的学习率。我们不希望太快或过于改变它们，所以我们让我们的学习率和学习率衰减都保持得非常小。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;数据增强（Data Augmentation）&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：非正则化网络的一个缺点是它们非常灵活：它们可以同样好地学习特征和噪声，而这会带来过拟合的风险。我们在我们的模型中使用了 L2 正则化来避免过拟合。但即使在那之后，我们也还是观察到了训练和验证 DR 图像上模型表现的巨大差异，这说明对训练数据集的微调过程是过拟合的。为了解决这个过拟合问题，我们在 DR 图像数据集上使用了数据增强。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数据增强的方法有很多，例如流行的水平翻转（horizontally flipping）、随机修剪（random crop）和色彩抖动（color jittering）。因为这些图像中的颜色信息是非常重要的，所以我们只是对图像进行了不同角度（0, 90, 180, 270 度）的旋转。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW82qLcVusw1NaibR1hJB2OKfCRdvibmnto2NYUOS8cqTa82cb6wlC6Q8FBzEkaNrGCic09qGWxn9OicnA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;使用 DR 图像替换预训练的 GoogLeNet 网络的输入层。我们对所有的层都进行了微调，除了最顶上的 2 个预训练层——这 2 层包含了更一般的独立于数据的权重。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;微调 GoogLeNet&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：我们在这里所使用的用于 DR 筛选的 GoogLeNet 最初是在 ImageNet 上训练的。ImageNet 数据集包含了大约 100 万张自然图像和 1000 个标签/分类。相对而言，我们的有标注的 DR 数据集仅有 30,000 张特定领域的图像和 4 个标签/分类。因此，我们的 DR 数据集不足以用来训练 GoogLeNet 这样复杂的网络，所以我们使用了来自根据 ImageNet 训练的 GoogLeNet 网络的权重。我们对所有的层都进行了微调，除了最顶上的 2 个预训练层——这 2 层包含了更一般的独立于数据的权重。其原本的分类层 loss3/classifier 可以输出有 1000 个类别的预测，我们将其替换成了一个二元分类层。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW82qLcVusw1NaibR1hJB2OKf5icMqrlnrQNicur1yibZEGIyOfaA3U2ibGfQJxXpmIC08FbkGUiceMISGOg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;微调 GoogLeNet&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;结论&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;微调让我们能将顶级 DCNN 模型的能力带入到数据不足、时间/成本限制可能阻碍其使用的新领域。这一方法在平均准确率上取得了重大提升，也推进了最先进的基于图像的医学分类技术的发展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;span&gt;「&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718504&amp;amp;idx=4&amp;amp;sn=bc4a3996c0db3de7d80702721482becd&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718504&amp;amp;idx=4&amp;amp;sn=bc4a3996c0db3de7d80702721482becd&amp;amp;scene=21#wechat_redirect"&gt;语言与智能高峰论坛&lt;/a&gt;（嘉宾：张钹院士、怀进鹏院士、洪小文、王坚、杨强、邢波、王海峰、胡郁）」明日召开，机器之心将在斗鱼平台全程直播，房间号：985893。&lt;/span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW82qLcVusw1NaibR1hJB2OKfibDRaNMH6VibYrDpNwVHVgDviaWzAQXvYrQ9BtTX2l85TqLWCG966GEew/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Sat, 27 Aug 2016 17:17:49 +0800</pubDate>
    </item>
    <item>
      <title>机器之心×MIT-CHIEF | Blue Skies用激光光谱过滤营造健康环境，Ricult搭建数据平台为农民致富开路</title>
      <link>http://www.iwgc.cn/link/2451507</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心原创&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Yina Zhao、Rita Chen&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;麻省理工学院中国创新与创业论坛（简称 MIT-CHIEF) 是美东地区最大的创新创业平台，汇集了美国最尖端的人才和项目，融合了中国和美国的各项优势资源。在刚刚过去的七月里，十六支涵盖医疗健康，新能源，教育及金融等领域的创业团队和 MIT-CHIEF 一起，走访了北京，上海，深圳和成都四大城市和与其相关的创业合作基地，与当地的政府，企事业单位代表进行了卓有成效的合作与交流。机器之心有幸采访到了其中的十一支团队，在接下来的一个月里，我们将作为专题采访的形式呈现给大家。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW82qLcVusw1NaibR1hJB2OKfUYLYuzR2cMuSIPVZWALqib3osuc7WwoXCic2Jopic7muNy5N8A4icHlanQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Blue Skie 官网：http://www.getblueskies.com/&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Blue Skies 和 Ricult 是此次 MIT-CHIEF 中国行中两支关注环境和农业发展的团队。Blue Skies 是现阶段有且仅有的对户外过滤器产品做临床试验的公司。他们已经设计完成第一代低断面的4X过滤器，这个过滤器可以过滤掉空气污染物中常见的有害物质。Blue Skies 由哈佛大学创新实验室支持，他们最初的研究由哈佛全球健康学院赞助支持。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW82qLcVusw1NaibR1hJB2OKf4EIU12MOOIjVRXhZCiawzSjzVvTib4PTmmnYraG4zHabybbMaVRicvjSw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Ricult 官网：http://www.ricult.com/&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Ricult 是一个联系农民与农务材料供应商、农产品购买者、银行借贷、保险、兽医服务的网络平台。他们认为与当地农民建立紧密的联系可以确保他们能接触到更大的市场，好的产品以及盈利，拥有一个更好的未来。机器之心今天非常荣幸能与来自 Blue Skies 的 Annie Park 以及来自 Ricult 的 Aukrit Unahalekhaka 进行一次访谈。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW82qLcVusw1NaibR1hJB2OKffl4ichLFuJuRiaGsUIguLX1VkUk8X3ATVTcUK6pZBIqWDBqicFOIZJfcw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;em style="color: rgb(136, 136, 136); line-height: 1.75em;"&gt;&lt;span&gt;Annie Park，Blue Skies 的运营及发展部门负责人（图左）；Aukrit Unahalekhaka，Ricult 的首席产品官（图右）&lt;/span&gt;&lt;/em&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Synced：很高兴认识二位。能否简短的和机器之心的读者介绍一下各自的团队还有公司的产品？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Park （Blue Skies）&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;: &amp;nbsp;好的。我是 Annie Park 来自 Blue Skies。我们目前正在利用激光光谱过滤的科技，来研发一种可以减少婴幼儿期的哮喘以及相关空气污染的产品。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Unahalekhaka （Ricult）: &lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&amp;nbsp;我是 Aukrit Unahalekhaka，是一名 MIT 的研究生。我们公司致力于发展一个为发展中国家农民服务的金融市场，以帮助他们减少运营成本，增加盈利。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Synced: 两位当初想到做这样的创业项目是怎样一个契机呢？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Unahalekhaka:&lt;/span&gt;&lt;/strong&gt;&lt;span&gt; 我原籍是泰国，泰国像其他亚洲国家一样是一个农业大国。我们可以看到，在泰国大部分的贫困者是农民，但这里也潜藏着极大可开发的农业生产价值。为什么价值十亿美元的市场但没有人问津？这个时候，我们意识到可以用科技来解决这个社会问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Park:&lt;/span&gt;&lt;/strong&gt;&lt;span&gt; Jay Muster 是 Blue Skies 的首席执行官，他是哈佛环境工程的 PhD。他用自己的科研背景和实践经验开发了一个技术平台，使其能够过滤掉空气中物理的和化学的污染物。他曾经到过中国，所以身感受到了环境的污染对人们生活的危害。所以，他想通过自己掌握的科技技术去帮助其他有相同困扰的人们。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Synced： 解决实际生活中的问题，这是和很好的出发点。那么，你们团队什么时候开始研发你们的产品的？在你们的发展过程中，遇到最大的技术难题是什么？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Park&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;: 对于我们来说，我们有平台技术，但需要决定要发展哪块战略板块。我们能实现商业化吗？从本质上来说，我们想做有好的社会影响力的东西，我们想帮助那些最容易受害的人们。我们发现小孩和婴儿面对重度的污染没有得到很好的保护，因为大多数过滤器都不是针对小孩的。我想我们最大的挑战就是找到一个商业切入点，这就是为什么我们决定来做婴儿产品，这个产品可以放在任何一个婴儿推车上面，你可以推着婴儿车出行，非常方便。但是这个东西也可以是独立放置的，这样孩子们在睡觉或者玩耍的时候，也能得到保护。 &amp;nbsp; &amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Synced：我很好奇，你们打算把这个产品用于成人吗？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;Park: &lt;/span&gt;&lt;/strong&gt;&lt;span&gt;当然，正如我说的，这是个平台技术，我们确实希望看到它可以进入到不同的市场。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Unahalekhaka&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;: 我们的技术是一个以农民为使用者的移动互联网平台，他们不是很了解科技领域，他们不像那些在美国和北京的人们，可以从亚马逊或者其他电子商务平台上订购产品。农民的经验是非常不同的。我们希望用这个技术可以让他们生活得更好，让他们的耕作经营变得更简单更快捷。所以挑战来源于怎样理解农民看待这项技术以及我们决定怎样让农民接受这个平台。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Synced：我知道你们公司有三个这样的平台，你能谈一下么？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Unahalekhaka: &lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我们的主要平台是帮助农民点对点的服务，从帮助农民融资开始。接下来的一个平台是农民自己决定农场投入，比如你可以决定你想在哪儿种植。最后一步是将农民和城市里的终端消费者联系起来。我们正在帮助他们进入农业金融领域，运营他们的农场，帮他们卖农产品。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Synced：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;感觉是环环相扣的。那跳出公司本身放眼你们所在的行业，可以聊聊你认为的这个行业的趋势是怎样的么？有什么策略可以保证你们的创业公司保持竞争力？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Unahalekhaka: &lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我们的公司会从两方面保持竞争力。我们有算法。正如我之前提到的金融领域，农民很难进入这样的圈子因为他们没有信用记录，所以不能从一般的银行借钱来从事农业劳动。我们利用算法形成一个模型，这个模型涵盖的数据分析可以提供他们利率更低的贷款，没有人可以以这样低的贷款利率和我们竞争。另一方面，我们有经济学家帮助农民选择他们的经营能力适合于怎样的城市规模，以及帮助他们怎样最优安排农务活动。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Synced：好的，非常感谢。同样的问题也想问一下Blue Skies，什么的策略使你们的创业公司保持竞争力呢？ &amp;nbsp; &amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Park: &lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我想我们的竞争策略来自于我们的团队成员。我们有在化学物理学方面的经验丰富的研究学者，Jay 目前也在做他的环境工程研究，我们的首席科技官在做他的化学物理学方面的研究。有这样的团队，我们可以持续进行研究，提升我们的过滤器的性能。目前，我们可能是唯一可以过滤我们所罗列的那些化学物质的公司。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Synced：谢谢！因为两个团队都是刚刚参加了 MIT-CHIEF 的中国行，可以跟大家分享一下这次中国行的契机和预期么？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;Park: &amp;nbsp;&lt;/strong&gt;我们准备在美国开展业务，但也知道中国和其他亚洲国家是这个领域的主要市场。对于我们来说，我们想要开展探索，在那边建立联系，可能在一两年内，我们想在亚洲某些地方有办公室。所以中国对我们来说是非常具有战略意义的一步。我们知道中国人比美国人更知道空气污染的危害性，我们想和投资者，政府官员，风险投资建立联系。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW82qLcVusw1NaibR1hJB2OKfm9rI7xH42ibYDDqc6rVBatoBqias05k4Zu3xCMvARTK0cMxc4D5RibvbQ/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Unahalekhaka: &lt;/span&gt;&lt;/strong&gt;&lt;span&gt;对我们来说，非常相似的一点是我们想在未来和中国市场建立联系。我们的初创公司始于 MIT，我们输出的市场是巴基斯坦。中国也有成百上千万的农民。所以我们想参与 MIT-CHIEF 的项目，希望能够接触到投资者，让我们在中国发行产品钱于他们建立联系。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Synced：此行你们的这些预想在中国实现了吗？你们怎么看？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Park:&lt;/span&gt;&lt;/strong&gt;&lt;span&gt; 当然。我想这是很宝贵的经验。如果真的想进入中国市场，我们就需要和那些有市场经验的中国团队成员一起努力，因为我们进入的是消费品市场。所以我想这是我从这段经历中学到的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;Unahalekhaka:&lt;/strong&gt;对我来说，有点超乎我的预期，因为我们之前对 CHIEF 中国行没有抱太大期望。我想，如果我能见两三个投资者，在中国去几个城市，看看那边的环境，就非常好了。但是结果是，我们和将近三四十个投资人谈过，期初，我不认为投资者会对帮助农民方面的事情感兴趣。但他们中许多人确实非常感兴趣，因为食品安全在中国是个问题。作为初创公司，我们可以在中国开拓食品供应链的一环，这对我们也对中国社会有非常大的影响。所以整体下来感觉这是一个收获颇多的经历。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Synced: 那你们认为， 在中美的创业文化上，或者在整个大的政策和国家的支持上面，环境上有没有特别明显的不同和相同？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Park :&lt;/span&gt;&lt;/strong&gt;&lt;span&gt; 首先我非常尊敬中国的创新文化，就是有政府的资金支持，政府官员也表达了对于创新城市的强烈意愿。我是一个韩裔美国人。我在美国长大，在此次中国行前我也去过韩国，看到了很多不同的地方。我想也许这就是我们能在中国学到的。也许这些努力争取不仅仅是从商业角度，也是从大学和科研的角度，以及这就是整个亚洲创业市场的创新精神。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Unahalekhaka&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;: 我很同意。我们能感受到来自政府对初创公司的支持，有许多资金可以支持创业者。政府会给创业者提供资金支持和行政支持，而这在美国是不会有的。对于生态系统的建立，中国政府更为重视，但是美国这边却拥有更好的研究资源。如果中国政府将一部分 的资金投入到大学实验室或者科研项目的扶持上，会有很多本土的初创公司开始做这方面的事情。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Synced：作为此次中国行中的非中国团队代表，你们对于中国印象最深的是什么？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Park:&lt;/span&gt;&lt;/strong&gt;&lt;span&gt; 这对我来说很简单，就是吃的！我们吃一日三餐，夜宵，我们一天要吃四顿。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Unahalekhaka:&lt;/span&gt;&lt;/strong&gt;&lt;span&gt; 我也一样。就是食物。以及看到不同城市。我之前从来没去过中国，我只去过上海。但这次之后，我见到了更多中国的城市和文化。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Synced：你们最喜欢的城市是哪个？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Unahalekhaka: &lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我想是北京。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Park:&lt;/span&gt;&lt;/strong&gt;&lt;span&gt; 我觉得每个城市都觉得有好的地方。比如成都，因为我喜欢吃辣（笑），当然 还有熊猫研究中心。但是我也喜欢深圳，深圳是一个非常便捷环境友好的地方。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Synced：我这里还有些关于公司方面和产品方面的问题。对于 Blue Skies，从简介中我们得知，你们可以过滤空气中的许多化学污染物。那对于一些任意的出现在空气中的污染物呢？你们的产品可以过滤这些污染物吗？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Park:&lt;/span&gt;&lt;/strong&gt;&lt;span&gt; 我们的过滤器目前可以以非常高的效率过滤所有的物理污染物，但是化学污染物会稍微困难一些。目前能做的是针对一些常见的化学污染物过滤掉，这样就没有会导致哮喘或者引发哮喘的东西了，当然我们也会针对臭氧,和二氧化碳的，这主要是看顾客的需求和应用范围。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW82qLcVusw1NaibR1hJB2OKfuaiaS3gZkbCR39Djd07PFvjbszf7erlHXlassc7SV8ZOPAuiccFwTLxw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Synced：在整个产品研发中，你们会需要做临床试验吗?可以和我们介绍一下这些实验及其成果么？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Park: &lt;/span&gt;&lt;/strong&gt;&lt;span&gt;这就是 Jay 主要花费时间攻克的地方。现在我们整个实验结果可以公布了，而且已经发给第三方的测试中心，在那儿他们会监测我们不同的过滤器。从目前的结果来看，所有指标都是按照预期标准在进行，所以我们才准备发布这些材料并且将它们商业化。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Synced：对于 Ricult 来说。因为你们谈过你们之前有三个平台，我想知道过多关于这方面的内容。我是说融资，农产品要素输入，以及市场的部分。我想知道你们的公司是怎样将三个平台组织起来的？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Unahalekhaka:&lt;/span&gt;&lt;/strong&gt;&lt;span&gt; 我们有一个独特的模型，可以利用合伙制将不同的价值提供者带入我们的系统。比如，我们与农具公司合作，让他们给我们的平台提供农具。对于融资，我们和各种金融公司合作，让他们通过我们的平台提供农民的数据，这样，我们可以在不同构成中建立广泛的合作，让我们的平台更好的运行。反过来，全部由我们自己来做这些内容会非常困难。我们有算法可以将这些不同的合作者和农民对应起来，这样他们可以给农民展现他们的专长。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Synced: 刚刚你提高了农民的这些数据资源，你们的产品是怎样保护产品使用者的数据隐私的？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Unahalekhaka:&lt;/span&gt;&lt;/strong&gt;&lt;span&gt; 我们对用户隐私非常谨慎。我们的首席技术官是MIT计算机专业的学生，他是网络安全领域的专家。他做的加密算法可以确保用户的数据的使用安全。另外，只有一部分特定数据会提供在平台上，这些数据是全部人都可以查看和搜索的。当我们把数据发送出去，我们不会发送一些重要的信息，比如名字和他们的社保账号等等。我们只发送那些对于算法需要的数据来做评估。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Synced：当你们研发自己 的平台或者产品时，自己对产品的设想与用户 （临床试验者或者农民）所期待的产品会有所偏差么？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Park：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;这个问题非常好，这就是为什么市场调研以及用户体验对我们非常重要的原因。通过这些，我们可以得到反馈，比如有的妈妈会说：「如果我们不用一直订购过滤器，会更好，因为你必须要在宝宝的设备上面换滤芯。如果你们可以订购，你们直接给我发过来以便换滤芯的产品，会怎样」。从那以后我们明白了订阅模式，只需要一次注册，之后每个月我们会定期发货给你。当你收到的时候，只需要把滤芯换出来。再比如，如果有一个可爱的造型或者装备上铃声会怎么样？如果它看起来非常具有美感，有设计感，视觉吸引是不是会带来更多的价值？我们目前这在致力于这些方面。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Unahalekhaka:&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;对我们来说，我们非常惊讶的是在发展中国家的用户，特别是农民，和美国那些富有经验的用户很不同。当我们做这个的时候，我们面谈了成千上万的农民，想看看他们是怎么使用我们的技术的，他们会遇到什么问题，哪些功能是他们喜欢的。比如对我来说，当我去亚马逊，我会怎样寻找产品，我会怎样下单，写收货地址，付款等等。我们从农民那里了解到，美国的电子商务平台对他们来说太难理解了，所以我们必须简化这些程序，让这些东西对他们来说变得更好点击，让他们在我们的平台上下单。另一件事情是，农民已经上千年来进行种植，不需要通过科技来进行。所以挑战就是让农民觉得我们的平台更易接受采纳，来改变他们上千年来的耕作方式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW82qLcVusw1NaibR1hJB2OKfKcVv7VuwKo4MNXEFiapreickEiaMcE7DeHkVtZnh8GFD150T9QB1icrHSQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Synced：对于 Blue Skies , 你们会考虑使用大数据来给产品增加额外功能吗？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Park:&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我想大数据基于我们正在监测污染程度，监测化学污染是很有帮助的，我们也在寻找哮喘方面的 研究合作。因为哮喘确实是近来爆发比较厉害的一种疾病。我们也在看像我们这样的科技能怎样帮助那些生活在空气污染中的人们。以及怎样减少哮喘和潜在哮喘发病率。不同区域的数据整合也对我们有积极参考价值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Synced: &amp;nbsp;好的，谢谢！采访最后是我们 Synced Talk 的固定快问快答环节。每一期我们都有固定的主题，这一期我们的主题是可穿戴与智能医疗。那么这里有三个问题，请你根据直观感受作答。第一个问题，你们认为既智能手表之后，什么会成为下一代可穿戴成品的主要载体？&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Unahalekhaka:&lt;/span&gt;&lt;/strong&gt;&lt;span&gt; 我的一个朋友是 MIT 的学生，他在研究一种可穿戴设备。这个设备可以通过分析运动员赛场的表现和得分提高其各方面的协调配合能力。在亚洲，许多人踢足球但并没有方法提升他们自己。我想以后我们踢球，就穿上我朋友设计开发的这个背心，这样它能搜集到我运动中的各个数据。运动完后，我就能通过手机看到数据，看看我该怎样提升自己。这个手机应用会提示你在那段时间应该更快地跑或者在哪个区域超越更多的人。因为现在所有的大数据和可穿戴设备只是给专业运动员使用的，我觉得这种技术的普及能够大大改变人们的生活方式。所以我想下一个可穿戴设备会是衣服。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Park: &lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我想可穿戴设备应该有许多功能，而给运动员使用只是其中很特定的功能之一。我想下一代可穿戴设备应该是像手表一样的东西，因为我想智能眼镜是给那些已经用眼镜的人。下一代可穿戴设备需要是每个人都能从容使用的东西。有许多功能可以建立在这个里面。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Synced：第二个问题，作为了一个消费者或者是用户，你会担心你自己个人信息被人盗用吗？或者是说，有哪些人可以获取这些数据的呢？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Unahalekhaka: &lt;/span&gt;&lt;/strong&gt;&lt;span&gt;这是个好问题。这种科技也和隐私相关。我想未来的话，初创公司在隐私方面的研究应该需要很多，因为所有的东西现在都是基于用户的。不仅公司本身，第三方怎样保护我们数据的隐私也非常重要。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Park:&lt;/span&gt;&lt;/strong&gt;&lt;span&gt; 我想这是每个人都非常头痛的问题，无论从政府的角度，从商业角度，从消费者的角度都一样让人觉得麻烦。随着科技进步，我们可以收集更多的数据。正因为我们害怕隐私问题，我们就停止前进的脚步吗？我觉得不。所以我想总会有各种担忧。你总会担心他们会知道关于我的隐私的事情，我的隐私会得到怎样的保护。但是也无法阻止这些科技主导市场的趋势。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Synced：确实值得思考。最后一个问题。对于现在的这个社会，你会认为大数据在哪一个领域会有最大的推动力?&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Park:&lt;/span&gt;&lt;/strong&gt;&lt;span&gt; 我从两方面来说。从政府角度，当你要服务你的群众，这个是非常小的范围。当你说大数据，我知道你意味着全球，跨国家的数据。但是作为一个曾经当过老师的人，我希望大数据能更好地作用到教育上，整个数据驱动的教学确实能够事半功倍，我能针对问题设计我的课程。所以回到你的问题，大数据意味着我能从这些人身上得知什么，甚至我不用和他们面对面。我能做些什么让这些数据更有用，更好的服务我正在服务的人群。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Unahalekhaka&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;:我想有很多大数据的应用。科技使我们收据数据变得如此快捷和简单。所以我们怎样挖掘数据使其变得更有意义，以及怎样用算法分析数据才对社会更有用。事实上，我可能不知道哪一个会是最好的，但是我觉得目前我最感兴趣的是无人驾驶汽车。因为你可以收集汽车运行状态的收据从而不断完善这个模型。总有一天我们可以实现无人驾驶技术在远程旅行上的突破。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Synced：这是所有的机器之心的提问。谢谢你们!&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心原创，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;查看英文采访原文，请点击这里↓↓↓想了解更多关于MIT-CHIEF中国行的信息，请继续关注机器之心每周末的Synced Talk 专题采访栏目。MIT-CHIEF 2016 Community向创业团队正式开放！点击 www.mitchief.org 了解详情！&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;</description>
      <pubDate>Sat, 27 Aug 2016 17:17:49 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 从机器翻译到云视觉，谷歌的7大机器学习应用</title>
      <link>http://www.iwgc.cn/link/2451508</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自 medium&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：&amp;nbsp;&lt;span&gt;James Le &lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：武竞、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;本文作者 James Le 目前正就读于美国丹尼森大学计算机科学与通信系，同时也在业余时间更新一个 Medium 专栏，之前的一些文章也曾赢得了广泛的好评，本文是他最新更新的谷歌机器学习应用盘点文章。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Steven Levy 的文章「&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716356&amp;amp;idx=1&amp;amp;sn=d65d3629e67243130dc73133904e59ed&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716356&amp;amp;idx=1&amp;amp;sn=d65d3629e67243130dc73133904e59ed&amp;amp;scene=21#wechat_redirect"&gt;谷歌如何将自己改造成一家「机器学习优先」公司？&lt;/a&gt;」是这个夏天最受关注的文章之一。这篇文章的内容讲了从 2016 年初起，谷歌怎样痴迷于机器学习技术并开始了一系列举措，如开源的 TensorFlow 和 Brain Residency 项目。同时作为世界上最理想的工作场所，谷歌的使命是「整合全球信息，使人人皆可访问并从中受益」。所以谷歌在未来科技——人工智能——上投入巨大也就毫不奇怪了。大约两周前，我有幸参加了位于 Galvanize 的一场讲座，讲座介绍了谷歌一些很酷的机器学习应用。主讲人是Christine Robson——一位致力于谷歌内部机器学习开发的产品经理。以下是 Christine 所讲的谷歌 7 个最酷的机器学习应用和产品：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1.谷歌翻译（Google Translate）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谷歌翻译是免费的多语种统计机器翻译服务，它能将文本、语音、图像、网站以及实时录像从一种语言翻译成另一种语言。当谷歌翻译开始一项翻译时，它能从亿万文献中查找语言模式来帮助它确定最佳翻译。通过发现文献中已被人工翻译的语言模式，谷歌翻译可以智能地猜测（人工智能）什么是最合适的翻译结果。 &amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW82qLcVusw1NaibR1hJB2OKf37icmJEMWjU6aFVZQmbiaxIwmRT5I4X1qKAqy9NbLBYicEoIZz9opmRrA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;谷歌翻译取词镜头&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;就个人而言，我上个学期出国旅行时曾大量使用谷歌翻译。我当时住在哥本哈根，当地的语言是丹麦语，而我对它并不熟悉。每当我购买日用品时，我总要使用谷歌翻译扫一扫产品标签，以确定它在英文中的含义。当我在其它欧洲国家旅行时，我也使用谷歌翻译来弄清楚街道标志、地铁横幅以及其它指路信息。这实在是一项了不起且简单的技术，为我节省了很多时间。&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2 . 谷歌语音搜索（Google Voice Search）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谷歌语音搜索允许用户通过对手机或电脑讲话来使用谷歌搜索，也就是说，设备搜索要输入的信息是通过对设备讲话得到的。它是谷歌努力与苹果公司的 Siri 语音助手相竞争的产品，并且被认为具有惊人的反应速度和相关性，「而且比 Siri 更有深度」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW82qLcVusw1NaibR1hJB2OKfV6IhZAY9OdTDy88D5MTf5ZV6c6CiaYznHlGAJhlHPJmQxMrcl9qazSg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;谷歌语音搜索&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我有一部安卓手机，因此我更了解这项应用。我最喜欢谷歌语音搜索的地方，是它和其它产品的整合：如谷歌地图与YouTube。当我不想打字的时候，我可以说出搜索的内容，然后对应的信息就会马上弹出。 &amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3 .&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=400345622&amp;amp;idx=3&amp;amp;sn=94c95665b5b149c8f1327edc7e9d5683&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=400345622&amp;amp;idx=3&amp;amp;sn=94c95665b5b149c8f1327edc7e9d5683&amp;amp;scene=21#wechat_redirect"&gt;Gmail Inbox 智能回复 &amp;nbsp;&lt;/a&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这项功能受到繁忙的专业人士的大力推崇，这些人的收件箱每天充斥着大量邮件，而他们没有时间一一回复。智能回复（Smart Reply）使用机器学习算法自动回复邮件，为手机用户节省了很多在手机小键盘上打字的麻烦。据 Christine 说，用这项功能发送的回复邮件占到手机回复量的 10%，这是一项很不错的成就。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW82qLcVusw1NaibR1hJB2OKfeWRvUc0zepuDG0GpP6QmFIcYgub7ndMKEwEiaCtOYiao2ds4Jy8ywezA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;智能回复功能是否成功是很好衡量的，即能否给出合理的回复。因此，算法系统可以通过记录用户是否选择了建议的回复来训练。我还没有使用过智能回复（我仍然手工回复收件箱中的邮件），但毫无疑问，这将成为一个方便的助手，使我的职业生涯更轻松。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;4 .&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715927&amp;amp;idx=2&amp;amp;sn=0def34e0388942bd8aee5c40af512a66&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715927&amp;amp;idx=2&amp;amp;sn=0def34e0388942bd8aee5c40af512a66&amp;amp;scene=21#wechat_redirect"&gt; RankBrain&lt;/a&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;RankBrain 是应用深度神经网络的搜索排名算法，它帮助谷歌处理搜索并呈现更相关的结果。举例说，当 RankBrain 看到一个它不熟悉的词或词组时，它会猜测有哪些词或词组有相似的含义，并把它们筛选出来，这使得它能更加有效地处理从未见过的搜索查询。据 Christine 说，RankBrain 是继链接和内容之后排名算法中第三重要的因素。 &amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW82qLcVusw1NaibR1hJB2OKfRbwOQNsNvuRCxlv3n89U8Ng8TYtTCMrlsiaFP2jTgguAvwLJsQj1PHw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;谷歌 Rankbrain&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在 95% 的谷歌利润来自搜索引擎的广告，因此 Rankbrain 这样的技术将为谷歌赚取更多利润。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;5 .Google Photos&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你是安卓用户，相信你会很频繁地使用 Google Photos。作为一项照片/视频的分享和存储服务，Google Photos 有无限存储空间，并且有针对安卓、苹果系统以及浏览器的应用软件。只要设备上安装了应用软件，用户就可以将他们任意设备上的照片保存到云端服务器。最近，Google Photos 能把某一特定时期拍摄的照片自动创建成一个照片专辑，并根据这些照片整理出旅途中的「最佳」照片。为了确定「最佳」照片，软件使用了机器学习算法来训练计算机「学习」识别图像。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW82qLcVusw1NaibR1hJB2OKfnG9sqgaYxNbwiaBuP46ojzCaENzwDfibTkb5edaaGGtibeibu4dGFV1yRg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在专家看来，相比于对手亚马逊（Amazon Cloud Drive）、苹果（iCloud）、Dropbox和微软（OneDrive），Google Photos 是最好的照片云端存储服务。因为无缝衔接和同步，我使用它非常频繁，我的照片可以在电脑中编辑，然后同步到我安卓手机的文件夹中。 &amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;6 .谷歌云视觉 API &amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谷歌云视觉 API 是一项更有技术含量和企业化的产品，通过将强大的机器学习模型封装在易操作的 REST API 中，它使得开发人员能够使用 API 理解图像的含义。它可以把图像快速划分到成千上万种类别中，还能识别图像中的物体和人脸、读出图像中的印刷文字。作为一个开发者，你可以在图像目录里建立元数据、控制冒犯性的内容、或者通过情绪分析制定新的营销方案。&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW82qLcVusw1NaibR1hJB2OKfSiaPqnVHdicfSlcsgnqSaDFhfZdepoa9ACbibPR0Sdk3NeV9OiaOZdTU7g/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;谷歌云视觉API &amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;7 .DeepDream&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;DeepDream 是一项使用卷积神经网络的机器视觉项目，它通过空想性幻觉（pareidolia）算法发现并增强图像中的模式，从而创造了有梦幻般的迷幻外观的故意过度加工的图像。我真的对解释这个复杂算法无能为力，所以我建议你们自己去 Deep Dream Generator 平台了解并探索这项技术。 &amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW82qLcVusw1NaibR1hJB2OKfW8eZ1OtUfIAmQJ6a2Cb2FdkXLkueWL45zF2YTVGbRmOmb792n3gfjA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;DeepDream 图像 &amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果我非要从 Christine 的讲座选出最重要的一点，那就会是： &amp;nbsp; &amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;不论是什么机器学习模型，最大的困难在于数据。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;她这句话的含义是，只要你了解机器学习模型，那么实现它们就不会很难，可是，要在开始时获得一份好的训练数据集却是一件十分困难的事情。因此，如果你想加深对机器学习的理解，我建议你通过上课或者自学统计和线性代数的方法来熟悉对数据的处理。 &amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过向软件开发者开源自己的工具，谷歌已经成为机器学习技术发展的前沿者。其中，最受欢迎的要数在 GitHub 库中排名第一的 TensorFlow，它是使用数据流图的可扩展的机器学习工具。此外谷歌还有另一些计划，其中包括谷歌机器学习 Ninja Rotation 项目（仅对内部员工开放）——它选拔各团队有创造力的工程师参与人工智能培训计划，使他们的产品更聪明；和 Brain Residency 项目——有点像深度学习的博士培养项目。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Sat, 27 Aug 2016 17:17:49 +0800</pubDate>
    </item>
    <item>
      <title>专栏 | 腾讯优图人脸识别·美妆·动效自拍背后的技术——人脸配准</title>
      <link>http://www.iwgc.cn/link/2451509</link>
      <description>&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz/KmXPKA19gW87x9sm9XtruXuQIh1mLPib6nuO5TymM9fwibuoPJjrNfG5nJXUiahnSxRrODEHOp2uYwClUV3bwM43A/640?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;腾讯优图专栏&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;作者：腾讯优图&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote style="max-width: 100%; line-height: 28.4444px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;腾讯优图隶属于腾讯社交网络事业群（SNG），团队整体立足于腾讯社交网络大平台，专注于图像处理、模式识别、机器学习、数据挖掘、深度学习、音频语音分析等领域开展技术研发和业务落地。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是一个「看脸」的时代，一谈人脸技术，大家最为熟知就是人脸识别。该技术在金融、社保、教育、安防等领域表现活跃，成为人工智能技术领域的明星。优图微信公众号之前也重点介绍过优图人脸识别，本文主要介绍一些背后默默支持人脸识别的技术。欲了解优图人脸识别技术可参见《&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717606&amp;amp;idx=2&amp;amp;sn=5419a58a2bc0d580dee33e83db6b278c&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717606&amp;amp;idx=2&amp;amp;sn=5419a58a2bc0d580dee33e83db6b278c&amp;amp;scene=21#wechat_redirect"&gt;深度学习在人脸识别中的应用 ——优图祖母模型的「进化」&lt;/a&gt;》。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一般而言，一个完整的人脸识别系统包含三大主要组成部分，即人脸检测、人脸配准以及人脸识别。三者流水线操作：人脸检测在图像中找到人脸的位置，接着人脸配准在人脸上找到眼睛、鼻子、嘴巴等面部器官的位置，最后人脸识别抽取特征与既有人脸比对计算相似度，确认人脸对应的身份。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW82qLcVusw1NaibR1hJB2OKfzPG38jwTXwcDhKIXvCjLclzMJYEWyj4Wjdqu7cWtuV5tP3nLxPb2VQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 1 &amp;nbsp;人脸识别流程&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;1. 人脸配准简介&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人脸配准（Face Alignment）又称人脸特征点检测与定位。人脸特征点不同于角点或SIFT特征点等通常意义上的图像特征点，人脸特征点通常是一组由人工事先定义的点（见图 2）。根据不同应用场景，特征点有不同的数目，例如 5 点，68 点，82 点等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&amp;nbsp;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW82qLcVusw1NaibR1hJB2OKfhxjfftQ1fh39utia0qWKuvzsOIM0seav3HNmic8fCmm2TKKORJ1E7ib3A/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 2 &amp;nbsp;人脸特征点检测与定位中常用的目标检测点&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除了在人脸识别系统中起关键作用之外，人脸配准技术也在 3D 人脸建模，人脸动画，人脸表情分析，人脸美化与虚拟化妆，人脸自拍动效等领域得到了广泛的应用。打个小广告，优图人脸配准跟踪技术性能卓越，主流手机单帧处理速度可达到 3ms 以内，已经在「天天p图-动效自拍」、「手机QQ-短视频」、「手机QQ-视频聊天」「手机Qzone-动效相机」等应用场景落地。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW82qLcVusw1NaibR1hJB2OKfjA5ibFeKJydZqrFTjbvKiafkGcfJfbHvt7MiapAEzibAVk618kqFmCzNEg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;图 3 &amp;nbsp;人脸美化与虚拟化妆&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;2.人脸配准研究现状&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;传统人脸配准研究&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;和其他人脸技术类似，光照、头部姿态、表情等的变化，以及遮挡都会很大程度影响人脸配准的精度。但是人脸配准也具有自身特点，首先特征点描述了人脸的结构（轮廓和五官），人脸结构是完整稳定的，五官相对位置固定；其次，头部姿态、表情等变化造成的特征点位置变化明显。传统人脸配准研究需要一直尝试寻找更加精准的特征描述来表达这种既确定又变化的点的组合，再根据描述符选择适当的优化求解方法，从而定位人脸特征点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最直接被采用的特征描述符是颜色、灰度，利用肤色的不同对人脸各部分进行检测定位[1-3]. 稍复杂些可选择各种纹理特征描述，如基于类 Haar 纹理特征和 Adaboost 训练级联分类器的人脸配准[3]。以上特征描述都没有考虑特征点之间的位置关系，因此不具备维持合理的人脸结构。主动形状模型（Active Shape Models, ASM）[4]和主动外观模型(Active Appearance Model, AAM)[5]可以同时表达纹理和形状（shape）两种特征。二者的形状特征都由点分布模型（Point Distribution Model, PDM）来表达。图 4 为600张人脸图像中人脸特征点的统计分布图，红点表示各特征点的均值。ASM 的每个特征点的纹理特征是分别表示的，通过计算特征点周围邻域纹理信息生成每个特征点对应的响应图（Response Map）。图 5 中蓝色圈定区域用于计算响应图，红点指示实际人脸特征点位置。AAM 使用整体人脸来描述纹理特征，通过将人脸特征点位置变换到标准形状上，得到与形状无关的人脸纹理,并基于主元分析方法对形状无关的人脸纹理进行建模。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW82qLcVusw1NaibR1hJB2OKfCl4JG3zYIyGiaNuUjbe0slqqoJEy5Clrf90qeSm7PMZbTBZSSpUpLfQ/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;深度人脸配准研究&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从 2006 年开始，深度神经网络已经逐步在计算机视觉、语音识别和自然语言处理等多个领域取得了前所未有的成功，同样也给人脸配准研究带来了习习春风。学者们无需再挖空心思构建各种繁琐复杂的人脸描述符了。目前学术界工业界比较认可的深度人脸配准方法有两类：级联卷积网络人脸配准(Cascade CNN) [6]和多任务深度人脸配准。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如图 6 所示，Cascade CNN 包含三级，每级包含多个卷积网络。第一级给出一个初始点位置估计，在此基础上后两级精细调整特征点位置。多任务配准将配准与其他相关人脸属性的训练同时进行。与脸部特征点相关的属性包含头部姿态，表情等，比如笑脸的嘴部很可能是张开的，正面脸特征点则对称分布。多任务有助于提升特征点检测定位精度。然而不同的任务会有不同的收敛速度和难度，训练难度加大。目前学界提供了两种解决方案调整不同的任务的训练进程：任务提早终止准则（task-wise early stopping criterion）[7]和参数动态控制机制[8]。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW82qLcVusw1NaibR1hJB2OKfhwmZB7IhH1o3xyPnNQicQkML14jjiciaq26JZjG2b1WYqR12pPOdVic8QA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 6 &amp;nbsp;Cascade CNN 网络模型[6]&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;3.优图人脸配准&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;不同应用场景的人脸配准&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;学术界人脸配准的研究日新月异，工业界产品应用对技术的要求也越来越高，且不同应用场景对人脸配准提出了不同的要求。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人脸识别业务的核心问题是人脸图像像素之间高层语义的对齐，即人脸关键特征点的定位。错误的特征定位会导致提取的人脸描述特征严重变形，进而导致识别性能下降。为了更好地支持人脸识别，我们加大了人脸框的变化的范围，以减少对人脸检测框大小的依赖。人脸特征点我们选择五点，既保证一定的人脸结构描述能力，又减小了配准误差对人脸识别的影响。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW82qLcVusw1NaibR1hJB2OKflVmichs1muByruBhLibkIm8r2Qf4l0OawasgdOV0Goo1aRcrWrWlAdEA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图7 人脸识别&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;美妆需要人脸特征点达到超高精度定位，例如眼妆中的眼线睫毛，只有定位够精准，才能达到自然贴合的美妆效果。为了提供精度，我们采用了级联模型，先粗略定位人脸面部特征，再对五官进行精细化定位。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW82qLcVusw1NaibR1hJB2OKfhax8YruZibFmkicenKqnKANSHEFzCz3z0wzxIibUIlymGxeBMibFXHjQfg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 8 &amp;nbsp;智能美妆&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人脸自拍动效应用处理移动端视频，对配准的处理速度要求严格。传统人脸配准技术不具备判定跟踪是否成功的能力，为避免跟踪过程中出现跟丢的现象（跟踪到非人脸区域），必须依赖耗时较长的人脸检测，我们的人脸配准增加了人脸判定功能，减少对人脸检测的依赖。另外我们采用了瘦长型深度神经网络，并应用 SVD 分解进行模型压缩和算法加速，算法模型大小控制在 1M，主流手机上的处理时间仅需 3ms。模型大小和计算速度均为业界最高水准。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;span&gt;&lt;em&gt;&lt;iframe class="video_iframe" data-vidtype="1" style="   z-index:1; " height="375" width="500" frameborder="0" data-src="https://v.qq.com/iframe/preview.html?vid=m0323nx26rf&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0" allowfullscreen=""&gt;&lt;/iframe&gt;&lt;br/&gt;&lt;/em&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;视频1 人脸自拍特效&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;优图人脸配准的更新换代&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;优图实验室不断跟进技术发展趋势，更新版本。优图人脸配准技术从传统方法迁移到深度学习方法，从最新学术研究成果到最佳工程取舍，我们经过多轮的迭代更新，做了大量的创新和尝试。于 2013 年 4 月发布了人脸配准 1.0 版本，粗略定位人脸五官，4 个月后精准定位的 2.0 版本也成功发布，并应用在趣味类产品中。之后的版本3.0精度大幅提高，同时在美妆产品中落地。4.0 版本开始应用深度学习方法，精度得到了进一步提高，平均精度超过了人工水平。今年 5 月我们发布的最新版本 5.0 采用深度多任务学习方法，在速度和深度网络模型大小都得到了大幅优化，主流手机帧率超过 200，模型 1M，并自带人脸判定功能。简介中提到的人脸自拍动效应用就得到了此版本的支持。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;4. 后续的研发计划&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;未来我们一方面着力提升已落地应用的用户体验，另一方面也积极探索新的应用场景。目前自拍视频的人脸配准跟踪效果仍存在不足。要解决此问题，提升用户体验依赖于进一步研究如何提升人脸配准的稳定性和精准度。除本文已提到的应用以外，优图人脸配准技术还可以应用于智能门禁系统、互联网金融核身、直播行业等众多领域。在新的应用领域，研究人脸配准技术如何满足新需求是我们必将面对的另一课题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;参考文献:&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[1] R．Hsu，A．Mohamed，A．K．Jain．Face detection in color images，2001．Proceedings of &amp;nbsp;2001 International Conference on Image Processing．Volume 1, 2001:1046-1049&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[2] H．Fu，P．Lai，R．Lou，H．Pao．Face detection and eye localization by neural network based color segmentation, Neural Networks for Signal Processing X，2000．Proceedings of the 2000 IEEE Signal Processing Society Workshop．volume 2．2000：507-5 16 v01．2．&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[3] D．Cristinacce，T．F Cootes．Facial feature detection using adaboost with shape constraints，British&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Machine Vision Conference，2003．&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[4] Cootes T, Taylor C (1992) Active shape models-'smart snakes'. In: Proceedings of British Machine Vision Conference, pp 266-275&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[5] T Cootes，G．Edwards，C．Taylor．Active appearance models, 5th European Conference on Computer Vision．1998:484-498．&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[6] Sun Y,Wang X, Tang X (2013) Deep convolution network cascade for facial point detection. In: Proceedings of IEEE Conference on Computer Vision and Pattern Recognition, pp 3476-3483&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[7] Zhang Z, Luo P, Chen C L, et al. Learning and Transferring Multi-task Deep Representation for Face Alignment[J]. Eprint Arxiv, 2014, 38(5):1.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[8] Zhang Z, Luo P, Chen C L, et al. Learning Deep Representation for Face Alignment with Auxiliary Attributes[J]. IEEE Transactions on Pattern Analysis &amp;amp; Machine Intelligence, 2016, 38(5):1-1.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;hr style="max-width: 100%; white-space: normal; color: rgb(0, 117, 188); font-family: 微软雅黑; line-height: 23.2727px; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;p&gt;&lt;strong&gt;只有0.1%的人知道这么&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_gif/Z0ib7VCNKpRqk083ejZLlxCEyQ9W2WWiaZbUnkuaeoL2BJA3YorezStzibfdGLg9haUKs0RQ1bjuGPB5h05HbbjmA/0?wx_fmt=gif"/&gt;&lt;section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/Z0ib7VCNKpRqk083ejZLlxCEyQ9W2WWiaZ6beFQfzdibhBJTxyTJJYI4IFl4S3NBrG2AS7AiaGHIgKavbiblrtsUNGw/640?wx_fmt=png"/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/Z0ib7VCNKpRqk083ejZLlxCEyQ9W2WWiaZ6beFQfzdibhBJTxyTJJYI4IFl4S3NBrG2AS7AiaGHIgKavbiblrtsUNGw/640?wx_fmt=png"/&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote style="max-width: 100%; line-height: 25.6px; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;p&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;em style="max-width: 100%; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;机器之心&lt;/span&gt;&lt;/em&gt;在为大家传播国外产、学、研动态的同时，也在将目光投放在国内优秀的人工智能公司和专家。为此，机器之心增设「公司专栏」，为国内人工智能公司和专家更好的传播思想和知识。欢迎国内人工智能公司与机器之心联系开设公司专栏，联系邮箱：e&lt;strong&gt;ditor@almosthuman.cn&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Sat, 27 Aug 2016 17:17:49 +0800</pubDate>
    </item>
    <item>
      <title>专栏 | 基于客户行为事件的跨领域统一推荐模型探讨</title>
      <link>http://www.iwgc.cn/link/2451510</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心专栏&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：袁峻峰&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;跨领域深度学习模型一直是近几年推荐系统主要研究方向之一， 本文探讨一种个人客户画像构建的新思路， 并讨论对应的基于个人行为事件的跨领域统一推荐模型。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;一、基于个人客户画像推荐&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为方便读者理解，摘抄部分前文[2]内容。目前业界的个人画像主要在机构内部数据结合外部数据基础上构建。如对原始数据进行特征提取，得到如下客户特征：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW82qLcVusw1NaibR1hJB2OKff0oRry7TQH8icVgtDbAOfgbw0dicXtEUFA0LOuTHmGh7pcXIYaVsrHkg/0?wx_fmt=png"/&gt;&lt;/span&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图一 （来源[2]）&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在实施过程中可以为个人客户画像中每个人打上几千个各类标签。再结合具体的推荐场景如股票购买概率预测模型[3]中特征要求，应用于具体推荐模型中。实践中一般还使用特征选择模型来决定哪些特征适用具体场景。并且由于很多关键属性缺失，还需要一些数据挖掘模型用于特征推断，比方逻辑回归，决策树，标签传递等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;二、特征体系能完全标记人的行为吗？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;什么是特征，「那个被选作确切的同一性和差异性之场所的结构，就是被称作特性。」[1]特征是为了差异更是为了相似性，福柯认为相似性与特征（符号）是必然联系，因为相似性是建立在对这些特征（符号）的记录和辨认上。而且他一直强调相似性的重要：「直到 16 世纪末，相似性在西方文化知识中一直起着创建者的作用。」[1]「产生于特殊事件的一般归纳，或者不如说科学的种类、逻辑和所有抽象观念，都是借助相似性而形成。」[1]同样，相似性在模式识别、分类、监督学习、非监督学习等机器学习概念中的有着同样的重要性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;进一步而言，特征体系是系统研究相似性，标识个体与分类的合理的、必然的途径。福柯对体系的定义是「选择一组确定的和相对有限的特征，其恒定和变换能在任何自身呈现的个体中得到研究」 [1]，他在认可这一途径的同时也指出该方法的不足。书中举了个例子：「中国某部百科全书中动物可以划分为：1属皇帝所有，2有芬芳的香味，3驯顺的，4乳猪，5鳗螈，6传说中的，7自由走动的狗。」他在惊叹如此分类的想象力的同时也指出「体系在展开过程中是任意的」[1]，「有可能把方法凭经验而限定的从外部强加的修正应用于一般特性：被人们认为对一个种群来说重要的一个特征，很可能只是另一些动物的特殊性」 [1]。让我们回顾上一部分中客户特征分类以及特征，似乎还比较合乎常理，但似乎也有些随意。前文[2]也试图从行为金融学相关观点应用于个人金融画像特征提取，但不足以根本解决这个问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;福柯大师也意识到「特征的确立，既是容易的，又是困难的。」[1]，「为了确立起所有的同一与差异，将有必要考虑在一个描述中可能被提及的每一个特征。这是一毫无止境的任务。」 [1]而且他还意识到特征「都是在相互联系，相互混合并且或许能相互转换」[1]。现在，我们非常容易理解这些特征之间的这种关系。认为基因和特征存在映射关系的话，在遗传算法中，会通过一系列的遗传算子来确认后代，包括交叉算子、变异算子这些都可以导致基因相互联系与转换，从而导致特征同样变化。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而且人的行为更是动态的，情景的，那可想而知构建合理的特征体系作为客户画像的难度。那我们是不是可以试试其他途径呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;三、基于个人行为事件的客户画像&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「每个插曲，每一个决心，每一种不合时宜的行动，都象征着唐吉坷德」[1]&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果塞万提斯不是用那么一部伟大的长篇巨著描写唐吉坷德的总总境遇，而是用一堆特征来标记。哪怕他是塞万提斯，哪怕他用 8888 个特征标记唐吉坷德，难道我们能比现在更感受到那样的一个唐吉坷德吗？如果要狗尾续貂一部《唐吉坷德游中国》，难道不是原著中那些事件的描述比 8888 个特征更能预测唐吉坷德游骑士在中国游中的种种行为吗？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;接下来让我们试着忘记特征体系，是否可以尝试只通过那些在时间轴上，在特定场景下的总总事件来构建客户画像呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;假设已合法的收集个人行为数据。一行样本数据包括，客户编号，事件类型，该类事件环境，事件行为的描述（当然还是可能需要用特征标识）等。那么我们将得到如下数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW82qLcVusw1NaibR1hJB2OKfuZN6vkR3CZ1zUOhqG5lDldPibPA0FIQo3xCXMG8CADDMxexzANZw5rQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;四、跨领域统一推荐模型&lt;/strong&gt;&lt;/span&gt;&lt;span&gt; &amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;接下来，探讨基于个人行为事件的客户画像构建跨领域统一推荐模型。我们假设这些事件是独立，正样本是历史上不同客户在各领域已发生事件。通过深度学习，得到在转换函数用于预测在新的场景下，不同客户发生指定事件的概率。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW82qLcVusw1NaibR1hJB2OKfUdL5EziblKnTiahk1ofo9rxkuKcibgr1jia308NibEsrpe8yD4k1wiaIKLlg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该框架不同于以往跨领域深度学习模型中样本数据，不再基于客户特征画像体系，而是用事件轴上的系列事件标记客户，并用于深度学习预测当前事件发生概率。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;五、总结&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本文以福柯《词与物》[1]中立场讨论了个人客户画像特征体系构建中的问题，充分认识到构建完善客户画像体系的复杂性。并从书中得到启发，探讨不再基于特征体系客户画像，而是用事件轴上的系列事件标记客户，并通过跨领域统一推荐深度学习模型预测事件发生概率。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;参考文献：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[1] 米歇尔•福柯, 莫伟民 译．词与物 [M]．上海三联书店. 2002.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[2] 袁峻峰. 人格量化-个人金融画像探索[OL]. 蚂蚁金服评论. 2016-03-07.&amp;nbsp;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[3] 袁峻峰. 大数据下客户金融产品购买概率预测[OL]. 大数据文摘,量化派 等(公众号). 2016-02-19.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;作者介绍&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：袁峻峰，花名观妙，蚂蚁金服人工智能部，复旦金融学硕士，FRM 金融风险管理师。10 年以上从事金融IT相关领域工作经验：国内银行间市场金融产品（包括衍生产品）的量化分析、市场风险管理以及相关系统实现。目前从事并关注于金融领域机器学习相关主题与应用，欢迎探讨, 邮箱yuanjunfeng_fr@163.com &amp;nbsp;。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;本文版权属于袁峻峰，仅代表个人观点。如需转载请联系作者（微信号 jake-80 ）&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Sat, 27 Aug 2016 17:17:49 +0800</pubDate>
    </item>
    <item>
      <title>深度 | Facebook的图像识别很强大，一次开源了三款机器视觉工具（附论文）</title>
      <link>http://www.iwgc.cn/link/2437236</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自 Facebook Research&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：&amp;nbsp;Piotr Dollar&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：黄清纬、吴攀、李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Facebook 的图像识别功能一直为人所赞叹，也是一些专业人士介绍相关技术的范例。今日，Facebook 官方发布博客称开源 DeepMask 分割构架、SharpMask 分割精炼模块、MultiPathNet 的代码。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;计算机能够像人眼一样轻松分辨图片中的许多物体吗？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当人看一张图片的时候，他们能将物体识别到最后一个像素。在 Facebook 人工智能研究实验室（FAIR），我们正在努力将机器视觉推进到下一阶段——我们的目标是在像素的层面上理解图像和物体。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在过去短短几年内，深度卷积神经网络的发展和更多强大的计算构架的出现使得机器视觉系统在精确度和能力上快速提升。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibe1E2S1UFpGAgoOpd52PuWgS0blkeWAIAkfo7cjZuat189YIOUp8zg7GGgiaURWNvUQzqG3OzSPNQ/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们目睹了图像分类（图片中有什么？）和物体探测（物体在哪里？）的巨大进步。请看下面的图（a）和图（b）。这只是理解任何图像或视频中最相关的视觉内容的开始。最近我们正在设计能够识别和分割图像中每个物体的技术，就像下面最右边的图（c），这项关键能力将会带来很多全新的应用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;推动着我们的进步的最主要的新算法是 DeepMask 分割构架以及我们的 SharpMask 分割精炼模块。它们一起使得 FAIR 的机器视觉系统能够探测并精确勾画出一张图片中所有物体的轮廓。我们识别过程的最后阶段使用了一个特定的卷积网络 MultiPathNet 来标记出每个物体掩码（mask）所含有的物体类型（例如人、狗、羊）。下面我们会谈论这个过程的细节。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们现在决定将 DeepMask+SharpMask 以及 MultiPathNet 的代码——以及我们的研究论文和相关演示——向所有人开放，我们希望它们能帮助机器视觉领域快速发展。随着我们不断改进这些核心技术，我们会继续公开我们的最新结果，并更新我们提供给社区的开源工具。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;开源地址：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;DeepMask+SharpMask：https://github.com/facebookresearch/deepmask&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;MultiPathNet：https://github.com/facebookresearch/multipathnet&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;演示：https://www.facebook.com/aidemos/&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;寻找像素模式&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;让我们看一看这些算法的构造模块。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;看一下下面第一张图，左边那张。你看到了什么？一个摄影师正在操作他老式的照相机、一片草地、作为背景的建筑物。你可能还会注意到其他无数的细节。机器看不见这些；一张图片被编码成数字数组，每个像素点都有一个值来表征颜色，就如第二张图片那样——右边那张。所以我们如何使机器视觉从像素点中挖掘对一张图片更加深刻的理解呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibe1E2S1UFpGAgoOpd52PuWpq5F1Gr5GS8JGvfjpGMQQsGpJ0hiazIK4qyaQo9GCgYr8ZCH7Lc1vaA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;由于现实世界的物体和场景的近乎无限的可变性，这不是一项简单的任务。物体的形状、外表、大小、位置、纹理以及颜色都会变化，加上现实场景的内在复杂性、变化的背景和灯光条件、以及我们的世界的一般丰富性，你会发现对于机器来说这个任务可以有多困难。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在看看深度卷积神经网络。比起编程式地定义基于规则的物体检测系统，深度网络是相对简单的构架，数千万个参数是训练而来的，而不是设计出来的。这些网络自动从上百万个注释过的样本中学习模式，并且在看过足够多的样例后，能推广至新图像。深度网络特别擅长回答关于一张图像的是或否问题（分类）——例如，这张图中含有羊吗？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;分割物体&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以我们如何利用深度网络进行检测和分割呢？我们在 DeepMask 中使用的技术是将分割看成大量的二元分类问题。首先，对于一张图像中的每个（部分重叠的）片（patch），我们思考：这一片中含有物体吗？然后，如果第一个问题的回答是「yes」，那么对于该片中的每一个像素点，我们思考：那个像素是该片中的中心物体的一部分吗？我们使用深度网络来回答每个是或否问题，并通过精心设计我们的网络，使计算是共享于每个片和每个像素，这样我们就能够快速发现并分割图像中的所有物体。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;DeepMask 使用了一种相当传统的前馈深度网络设计。在该网络中，随着网络深度的增加，信息变得更加抽象且更具有语义意义。例如，深度网络中早期的层可能能捕获到边和斑点，然而更上的层往往会捕获到更多语义概念，如动物的脸或四肢的存在。这些更上一些的层的特征被特意设计在一个相对低的空间分辨率中计算（为了降低计算量和减少像素点位置小幅位移的影响）。这产生了一个掩码预测（mask prediction）的问题：更上面的层的特征能被用于预测捕获物体大概形状的掩码，但是不能精确捕获物体的边界。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因此我们设计了 SharpMask。SharpMask 将 DeepMask 的输出提炼，能生成高保真的、更精确地勾画物体边界的掩码。当 DeepMask 能在穿过网络的前向通过过程中预测粗糙的掩码时， SharpMask 颠倒深度网络中的信息流方向，并通过使用网络中信息流逐渐经过的更早期层的特征，提炼 DeepMask 做出的预测。这样设想一下：为了捕获物体大概的形状，你必须对你正在看的东西有一个高水平的理解（DeepMask），但是为了精确地定位边界，你需要回去检查那些低级的特征，直到像素的层面（SharpMask）。本质上，我们的目标是以最小的成本利用所有网络层中的信息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面是一些由 DeepMask 生成、SharpMask 提炼的输出样例。为了保持样例的可视性，我们仅展示与图片中与物体真实位置完美对齐的预测掩码（人为注释）。注意该系统还不完美，红色轮廓的物体是被人工注释，但被 DeepMask 错过的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibe1E2S1UFpGAgoOpd52PuWJ4uHUAIqtHPAv1IjbhvbqTTZUzZQC8UX3aPt3vTBMYhwq56Pr6TiaBA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;分类物体&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;DeepMask 不知道任何特定类型的物体，所以尽管它可以同时描绘狗和杨，它却不能分辨它们。另外，DeepMask 并不是非常有选择性的，而且可能生成并不是特别相关的图像区域的掩码。所以我们该如何收缩相关掩码的选择范围，从而识别出真正存在的物体呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;正如你所可能预料的，我们再一次求助于深度神经网络。给定一个 DeepMask 生成的掩码，我们训练一个单独的深度网络用来分类每个掩码的物体类型（而且「none」也是一个有效的答案）。这里我们遵从了一个名叫 Region-CNN（或 RCNN）的基本范式，该范式是由 Ross Girshick 首创的（他现在也是 FAIR 的一位成员）。RCNN 是一种两阶段的程序，其第一阶段用于将注意力吸引到特定的图像区域，而在第二阶段则使用一个深度网络来识别存在的物体。在开发 RCNN 的时候，第一阶段可用的处理是相当初级的。通过使用 DeepMask 作为 RCNN 的第一阶段并利用深度网络的力量，我们在检测精度上得到了相当显著的提升，同时也获得了分割物体的能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了进一步提升性能，我们也专注使用专用网络架构来分类每个掩码（RCNN 的第二阶段）。正如我们讨论的那样，真实世界照片包含了多种尺度的物体，背景常常很杂乱，而且往往有遮挡。标准的深度网络在这样的情况中存在困难。为了解决这个问题，我们提出了一种名叫 MultiPathNet 的修改过的网络。正如其名，MultiPathNet 允许信息沿多条路径穿过网络，从而使其可以利用多个图像尺度上的信息和图像中周围背景的信息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;总而言之，我们的物体检测系统按以下三个步骤执行：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="list-style-type: decimal;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;DeepMask 生成初始的物体掩码；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;SharpMask 提炼这些掩码中的信息；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;MultiPathNet 识别由每个掩码所描绘出的物体。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面是我们完整系统的一些输出例子：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibe1E2S1UFpGAgoOpd52PuWxdd44rJQkHjskIm7gsr5c73xNEcNMX5Z2AbY7AGnz5PE3yzamy9NCA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;结果并不完美，但鉴于能做到这一点的技术几年前甚至还不存在，所以也不算太差啦！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广泛的应用&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;视觉识别技术有着非常广泛的潜在应用。例如构建这一已有的计算机视觉技术，使得计算机能够识别图像中的物体，这就使得我们可以更容易地在没有每张图都被标记的情况下搜索特定的图像。失去视觉能力的人也能够可以理解朋友们分享给他们的图片内的内容，因为系统可以告诉他们是什么，不论图片旁边有没文字描述。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不久之前，我们展示过为盲人用户开发的技术，也就是评估图片并向用户描述图片内容。如今，视觉障碍用户在收到 News Feed 中的图片时，他们只能听到向他们分享图片的人的名字，后面缀着「Photo」一词。而我们想要提供更丰富的描述，就像「图片中包含沙滩、树、和 3 个在笑的人。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此外，借用我们开发出的分割技术，我们的目标是提供更沉浸式的体验，在用户手指滑过图片时能够「看到」图片，希望有一个系统能够描述他们触摸到的内容。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在前进的过程中，我们将继续改进我们的检测和分割算法。你可以想象有一天，这些图片检测、分割、识别能力在商务、健康这些领域应用于增强现实。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibe1E2S1UFpGAgoOpd52PuWGQDULxlIPIHAZjhBDBAP53ovDsBVdlZFRgiahkwcxc4LwPGld3N3WvA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此外，我们的下一个挑战是将这些技术应用于视频，视频中的物体是移动的、交互的、随时间变化的。在计算机视觉技术观看视频以及理解并分类视频中的实时内容上，我们已经取得了一些进步。实时分类能够在 Facebook 上帮助将相关的、重要的直播视频推荐到封面，同时应用更精致的技术在时间和空间上检测场景、物体和行为能够在有一天实现实时的描述。我们非常兴奋能够推进这一前沿技术并在 Facebook 上为每个人提供更好的体验。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;参考论文（点击阅读原文下载）&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;[1] DeepMask: Learning to Segment Object Candidates. Pedro O. Pinheiro, Ronan Collobert, Piotr Dollár (NIPS 2015)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;[2] SharpMask: Learning to Refine Object Segments. Pedro O. Pinheiro, Tsung-Yi Lin, Ronan Collobert, Piotr Dollàr (ECCV 2016)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;[3] MultiPathNet: A Multipath Network for Object Detection. Sergey Zagoruyko, Adam Lerer, Tsung-Yi Lin, Pedro O. Pinheiro, Sam Gross, Soumith Chintala, Piotr Dollár (BMVC 2016)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Fri, 26 Aug 2016 15:33:46 +0800</pubDate>
    </item>
  </channel>
</rss>
