<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器之心</title>
    <link>http://www.iwgc.cn/list/670</link>
    <description>人与科技的美好关系</description>
    <item>
      <title>重磅 | 深度揭秘谷歌「量子霸权」计划：有望明年底突破经典计算极限</title>
      <link>http://www.iwgc.cn/link/2514055</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自 New Scientist&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：&amp;nbsp;Jacob Aron&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀、李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;昨日，New Scientist 发表文章解密谷歌量子计算机的进展。文章中写到，量子计算领域正在快速重组，谷歌的工程师已经悄悄拿出了计划要成为该领域的霸主！&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWichcWU2hkia3ZnF1OnoykPjiciauj4GYo1qDf3hIJLH99VSibLSUhmUrVLa5BlliaXYkpZReOtL6eMljkA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;上图是超导量子位，来自 UCSB&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在加利福尼亚州的某个地方，谷歌正在打造某种能将计算技术带进一个新时代的设备——量子计算机（quantum computer）。谷歌正在打造的这台量子计算机是有史以来最大的，其目的是为了一劳永逸地证明这种使用了奇异的物理学的机器能够超越当下顶级的超级计算机的性能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而 New Scientist 也了解到这一目标的实现可能将会比所有人的预期更早——甚至可能就在明年年底之前！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;量子计算革命已经等待了很长的时间了。20 世纪 80 年代时，理论学家认识到基于量子力学的计算机有望在特定的任务上远超普通或经典计算机的性能。但说起来简单做起来难，直到最近，可以击败经典计算机的量子计算机才有望从实验室研究变成现实真正可用的东西，而谷歌想造出第一台。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这家公司的规划目前还是机密，谷歌也拒绝就这篇文章发表评论。但 New Scientist 接触过的一些科学家都相信现在它们已经处在了实现重大突破的边缘，紧接着就将有大会和私人会议上的演示出现了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「他们现在肯定是世界上最领先的，这是毫无疑问的，」日本新兴物质科学中心（RIKEN Center for Emergent Matter Science）Simon Devitt 说，「谷歌稳操胜券。如果谷歌最后没有成功，那一定是什么地方出了问题。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们简单了解了谷歌的意图。上个月，谷歌的工程师悄悄发布了一篇描述了他们的计划细节的论文《Characterizing Quantum Supremacy in Near-Term Devices（在短期的设备内表征量子霸权）》。他们的目标被大胆地命名成了「Quantum Supremacy（量子霸权）」，其目标是打造世界上第一个可以执行经典计算机无法执行的任务的量子计算机。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「这是他们未来几年规划的蓝图，」得克萨斯大学奥斯汀分校 Scott Aaronson 说，他曾和谷歌的这个团队讨论过这个规划。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以他们会怎么做？量子计算将信息作为量子位（qubit）进行处理。和经典的位（bit/比特）不一样，由于量子叠加原理，量子位可以同时存储 0 和 1 的混合状态。正是这样的潜力让量子计算机在一些特定的任务上具备了优势，比如大数因子分解。但普通的计算机在这些任务上也能取得很好的表现。要证明量子计算更好，会需要用到数千个量子位，而这远远超出了我们现有的技术能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而谷歌想要实现 50 个量子位的成果。这仍然是一个很有雄心的目标——就目前公开的消息来看，他们只公布了一个 9 量子位的计算机——但这是一个可以实现的目标。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;谷歌稳操胜券。如果谷歌最后没有成功，那一定是什么地方出了问题。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了成功实现这一目标，谷歌已经开始了量子核心问题的攻关。他们正在专注解决对普通计算机来说极度困难，而对量子计算机来说可以自然地解决的问题：模拟量子电路（quantum circuits）随机排布的行为。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些量子电路中输入的任何微小变化都可能带来非常不同的输出，所以对经典计算机来说，是很难通过逼近以简化该问题的方法来作弊式地解决这个问题的。「他们正在打造一个量子版本的混沌（chaos），」Devitt 说，「其输出本质上是随机的，所以你必须计算所有东西。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了找到经典计算的极限，谷歌寻求了 Edison 的帮助。Edison 是世界上最先进的超级计算机之一，安置在美国国家能源研究科学计算中心（ US National Energy Research Scientific Computing Center）。谷歌用其模拟了越来越大的量子位网格（grids of qubits）的量子电路的行为，发现最多能模拟 6×7 网格的 42 个量子位。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这种计算非常困难。因为随着网络大小的增长，存储所有数据所需的内存就会快速暴增。一个 6×4 的网格仅需要 268 MB，比一般的智能手机的内存还小。而一个 6×7 的网格则需要 70 TB，差不多是高端个人计算机的 10,000 倍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谷歌没再继续增大网格，因为再增大一点对现在的技术来说就已经是不可能的了：一个 48 量子位的网格需要 2.252 PB 的内存，这差不多相当于现在世界上最强大的超级计算机的两倍。如果谷歌可以解决 50 个量子位的量子计算机的问题，那么它就将超越世界上任何已经存在的计算机。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;矢志不移&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过设置这个明确的测试，谷歌希望能够避免那些困扰过之前的宣称量子计算机超越普通计算机的断言的问题——其中包括谷歌宣称的一些。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;去年，该公司曾宣布通过使用一台 D-Wave 量子计算机（一款饱受争议的已经商业化的设备），该公司以超过经典计算机 1 亿倍的速度解决了一些特定的问题。相关专家立即反驳了这一结果，他们说这并不是一次公平的比较。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谷歌在 2013 年购买了一台 D-Wave 计算机，想要搞清楚它是否可以被用于改善搜索结果和人工智能。后一年，该公司聘请了加州大学圣塔芭芭拉分校的 John Martinis 来设计自己的超导量子位（superconducting qubit）。Aaronson 说，「他的量子位的质量要高得多。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在正是 Martinis 及其同事想要尝试实现 50 量子位的 quantum supremacy（量子霸权），而且许多人相信他们很快将取得成功了。「我认为这将在两到三年内实现，」瑞士苏黎世兰邦理工学院的 Matthias Troyer &amp;nbsp;说，「他们已经让人们看到了他们将怎么做的具体步骤。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Martinis 及其同事已经就实现这一里程碑的时间表做过很多讨论了，Devitt 说。最早的估计是今年年底，但看起来不太可能。「我比较乐观，我觉得可能会是在明年年底。」他说，「就算他们在接下来的五年之内才完成，那也将会是一个巨大的飞跃。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一个成功的量子争霸实验并不能直接给我们带来可以执行任何可以想象的任务的计算机——基于目前的理论，这种计算机将会非常庞大。但有一个可以工作的小型计算机可以推动创新或者增强现有的计算机，从而使之成为一个新时代的开始。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Aaronson 将其比作是第一个自持核反应（self-sustaining nuclear reaction）——1942 年由曼哈顿计划在芝加哥实现。他说：「这可能会让人们说：如果我想要一台完全可扩展的量子计算机，就让我们谈谈数字：要花多少亿美元？」解决构建 50 量子位设备的难题之后，谷歌就为更大的目标做好了准备。「这是构建完全可扩展的机器之路上的绝对重大进展，」牛津大学 Ian Walmsley 说。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了量子计算机能在长远上真正有用，我们还需要稳健的量子纠错（quantum error correction）技术——一种用来减轻量子态脆弱性的技术。Martinis 等人已经在研究这方面的问题了，但这将要花费比实现 quantum supremacy（量子霸权）更长的时间。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不过，霸权的实现不会被取消。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「一旦一个系统达到了量子霸权，并且表现出了明显的规模化行为，那么它就将成为私有企业天空上耀眼的火炬。」Devitt 说，「就为走出实验室做好了准备。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「这个领域的发展速度比原来预想的快得多，」Troyer 说，「现在是时候将量子计算从科学变成工程并真正打造设备了。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;论文：在短期的设备内表征量子霸权（Characterizing Quantum Supremacy in Near-Term Devices）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWichcWU2hkia3ZnF1OnoykPjicunShQ2rE9GqryiauSHDuhejmwAgH2U5E4zpAbzoB80fraxUW0f9ZUCQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于近未来的量子计算领域，一个关键的问题是：没有纠错（error correction）的量子设备能否执行定义良好的计算任务，并在这些任务上超越当前最好的经典计算机的能力，从而实现所谓的量子霸权（quantum supremacy）。我们研究了从（伪）随机量子电路的输出分布中进行采样的任务——这是一个用来评测量子计算机的自然任务。重要的是，对这样的分布进行采样需要该电路的直接数值模拟（direct numerical simulation），同时计算成本会随量子位的数量指数式地增长。这是混沌系统（chaotic systems）的典型要求。我们在计算复杂度上延展了之前的结果，以更正式地说明这种采样任务会在经典计算机上消耗指数级更多的时间。我们研究了混沌状态（chaotic regime）的收敛（convergence），该研究使用了应用广泛的超级计算机模拟建模了多达 42 个量子位的电路——这是目前在实现量子霸权的任务上最大的量子电路。我们认为尽管混沌状态对错误非常敏感，但量子霸权可以通过大约 50 个超导量子位在短期内实现。我们引入了交叉熵（cross entropy）作为量子电路的评测基准，这近似于电路保真度（circuit fidelity）。我们证明这种交叉熵可在电路模拟可用时测定。除了传统上可测量的状态，该交叉熵还可通过电路保真度的理论估算进行比较来进行推断，从而可以定义出一种实用的量子霸权测试方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;点击「阅读原文」，下载此论文↓↓↓&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 01 Sep 2016 12:51:51 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 谷歌开放Inception-ResNet-v2：一种新的图像分类卷积神经网络模型</title>
      <link>http://www.iwgc.cn/link/2514056</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自 Google Research&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：&amp;nbsp;Alex Alemi&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;昨天，&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718786&amp;amp;idx=4&amp;amp;sn=274bbf2332427a274123f6b9e009487e&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718786&amp;amp;idx=4&amp;amp;sn=274bbf2332427a274123f6b9e009487e&amp;amp;scene=21#wechat_redirect"&gt;谷歌宣布开放 TF-Slim&lt;/a&gt;，这是一个在 TensorFlow 中定义、训练、和评估模型的轻量软件包，同时它还能对图像分类领域中的数个有竞争力的网络进行检验与模型定义。今天，谷歌再次宣布开放 Inception-ResNet-v2，一个在 ILSVRC 图像分类基准上取得顶尖准确率的卷积神经网络。文中提到的论文可点击「阅读原文」进行下载。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了在该领域取得更多进展，今天我们非常高兴的宣布开放 Inception-ResNet-v2，这是一个在 ILSVRC 图像分类基准上取得顶尖准确率的卷积神经网络。Inception-ResNet-v2 是早期发布的 Inception V3 模型的变体，该模型借鉴了微软 ResNet 论文中的思路。具体内容可在我们的论文：Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning 中看到。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;残差连接（Residual connections ）允许模型中进行 shortcut，也使得研究员能成功的训练更深的神经网络从而产生更好的性能。这也使得 Inception 块的极度简单化成为可能。下图对比了这两个模型架构：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWichcWU2hkia3ZnF1OnoykPjichFlv1fnX95Nx8y9PcYQQH2ibJKiaemaIdEjWB1ltqkPM0GBrX9L8tdFg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Inception V3 图解&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWichcWU2hkia3ZnF1OnoykPjicZ4F2Hsx4qrOA9ibPlTdAdIH63dGnOejppiabrAKHDTibydwuwFdbe3LYA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Inception-ResNet-v2 的图解&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在第二张图解的顶端，你可以看到全部的网络拓展，可以注意到该网络比之前的 Inception V3 要深得多。主图的下面是更简单阅读同一网络版本的方式，里面重复的残差块是被压缩了。注意，里面的 Inception 块被简化的，比先前的 Inception V3 包含更少的并行塔 （parallel towers）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Inception-ResNet-v2 架构比之前的前沿模型更加准确。下表报告了在基于单类图像的 ILSVRC 2012 图像分类基准上的 Top-1 和 Top-5 的准确度检验结果。此外，该新模型相比于 Inception V3 大约只需要两倍的存储和计算能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWichcWU2hkia3ZnF1OnoykPjicfLibjPtmia7JBzZ17QXFWJyGKHZuuBQJo0Hic75cxJgVB5wZNo5V2zXhQ/0?wx_fmt=png"/&gt;&lt;br/&gt;结果援引于 ResNet 论文&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;举个例子，Inception V3 和 Inception-ResNet-v2 模型在识别犬种上都很擅长，但新模型做的更好。例如，旧模型错误报告右图中的狗是阿拉斯加雪橇犬，而新的 Inception-ResNet-v2 模型准确识别了两张图片中的狗的种类。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWichcWU2hkia3ZnF1OnoykPjicnpLbvzB7Xkw42kWBeuqhrTubTg5zPrltNLdNvu6iaxlAoe0ibHv35gIg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;阿拉斯加雪橇犬（左），西伯利亚爱斯基摩狗（右）&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了让人们能立即进行试验，我们也发布了 Inception-ResNet-v2 模型的一个预训练案例作为 TF-Slim 图像模型库的一部分。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果想进行试验，这是如何训练、评估或微调网络的指导：https://github.com/tensorflow/models/blob/master/slim/README.md&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 01 Sep 2016 12:51:51 +0800</pubDate>
    </item>
    <item>
      <title>学界 | FAIR实验室与微软研究院合著论文：通过虚拟问答衡量机器智能</title>
      <link>http://www.iwgc.cn/link/2514057</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自 arXiv.org&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;作者：C. Lawrence Zitnick、Aishwarya Agrawal、Stanislaw Antol、 Margaret Mitchell、Dhruv Batra、Devi Parikh&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：孙宇辰、李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWichcWU2hkia3ZnF1OnoykPjicpJmzzqfzO3LnWwZj6Hw7dkXFeNN4tRABdx6u26HwFtysniamy7kGg7w/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;摘要&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;随着机器逐渐变得更加智能，社区内对衡量机器智能程度的方法再次产生了兴趣。一种常用的方法是使用人类可以处理的、但机器做起来困难的任务。然而，这样的一个理想任务应该容易进行评估，同时不那么容易蒙出来。我们从最近图片描述（image captioning）以及其局限性作为一个衡量机器智能的任务开始探索。另一个更有前途的任务就是虚拟问答，测试机器语言与视觉上思考的能力。我们为了这项任务搭建了前所未有的数据集，包含 76 万人们对图片内容生成的问题。使用一千万左右人类产生的回答，机器可能很容易被评估。&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;点击「阅读原文」，下载此论文↓↓↓&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 01 Sep 2016 12:51:51 +0800</pubDate>
    </item>
    <item>
      <title>深度 | 从硬件到软件：OpenAI 解读自家的深度学习基础架构</title>
      <link>http://www.iwgc.cn/link/2499489</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自 OpenAI&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：VICKI CHEUNG, JONAS SCHNEIDER, &lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;ILYA SUTSKEVER, AND GREG BROCKMAN&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：孙宇辰、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;em style="line-height: 1.75em; color: rgb(136, 136, 136);"&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;em style="line-height: 1.75em; color: rgb(136, 136, 136);"&gt;&lt;span&gt;深度学习是一门经验科学，群组基础架构的质量不断地改善。幸运的是，如今的开源生态环境让任何人都可以搭建很出色的深度学习基础架构。&lt;/span&gt;&lt;/em&gt;&lt;br/&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这篇文章中，我们将要分享深度学习的研究通常是如何进行的，我们如何选择适当的架构辅助研究以及一个为 Kubernetes 的批优化过的扩展管理器（ batch-optimized scaling manager）开源项目「kubernetes-ec2-autoscaler」。我们希望这篇文章能对你在搭建你自己深度学习基础架构时有所帮助。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;用例&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一个典型的深度学习进展通常从有一个想法，在小问题上进行测试开始。在这个阶段，你想非常快地运行许多 ad-hoc 实验。理想情况是，你通过 SSH 接入机器，在屏幕上运行一个脚本，然后在不到一小时的时间内得到一个结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;想让一个模型确实可以工作，通常需要观察它在各种可以想象到的方式失败，然后找到某种方式修复这些限制。（这和你搭建一个新的软件系统类似，你需要运行你的代码很多次才能建立对其工作方式的直觉。）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;iframe class="video_iframe" data-vidtype="1" style="   z-index:1; " height="375" width="500" frameborder="0" data-src="https://v.qq.com/iframe/preview.html?vid=g032571v3vh&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0" allowfullscreen=""&gt;&lt;/iframe&gt;&lt;br/&gt;&lt;/span&gt;&lt;em style="color: rgb(136, 136, 136); line-height: 1.75em; text-align: center;"&gt;&lt;span&gt;你需要从许多角度检查你的模型，从而对它们实际所学习的内容有一种直觉上的认识。Dario Amodei 运用强化学习的代理（agent）（控制右侧的球拍）在 Pong 这个游戏上获得很高的分数，但是当你看它玩的时候，你会认为它就坐在某个地方进行游戏。所以深度学习的基础架构必须允许使用者灵活地检视模型，仅仅显示汇总统计是不够的。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当模型表现出足够的成效时，你就可以将其扩展到更大的数据集以及更多的 GPU 上。这是一个很耗时的工作，需要用掉许多计算周期并且持续很多天。你需要注意你的实验管理工作，并且对你选择的超参数范围进行认真思考。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;早期的研究工作是非结构化的、急促的，而现在是有条理的，还伴随着些许痛苦，但是为了得到一个良好的结果这绝对是必须的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;一个例子&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;论文《Improved Techniques for Training GANs（改进过的训练 GAN 的技术）》开始于 Tim Salimans 构想出的一些用于改进生成对抗网络（Generative Adversarial Network）训练的想法。我们将描述这些想法中最简单的一些（这也碰巧是其中能生成最好看的样本的那些，尽管并不是最好的半监督学习）。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;GAN 由一个生成器（generator）网络和一个鉴别器（discriminator）网络构成。其中生成器会尽力欺骗鉴别器，而鉴别器则会尽力分辨出生成的数据和真实数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;直觉上看，一个能够欺骗每一个鉴别器的生成器是相当好的。但总是存在一个难以修复的故障模式：生成器可以通过一直输出完全一样（很可能非常逼真！）的样本使网络「崩溃」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibCficthDQHbyjskJ3ia44KfnlCia7yqquZ96icjm3VWPJKJM8IDXibuibeFdMwnzfEdDsSXstZVvEnEnQw/0?wx_fmt=png"/&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;我们的模型学习生成 ImageNet 图像&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有了更大的模型和数据集，Ian 还需要将该模型并行化到多个 GPU 上。即使每一项工作都让多台机器上的 CPU 和 GPU 的使用率达到了 90%，但即便如此，该模型的训练还是花费了许多天的时间。在这种情况下，每一次实验都变得非常宝贵，他也会一丝不苟地记录每一次的实验结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，尽管结果很不错，但仍然没有我们希望的那么好。为了找到原因，我们已经测试了很多假设，但仍然还没有解决它。这就是科学的本质。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;基础架构&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;软件&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibCficthDQHbyjskJ3ia44KfnynDzmYmad4NQ7Tw1foM6NUoPMpUAOsfMzZObOb0fm6h3C8HuQtHeGQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;我们的 TensorFlow 代码中的一节&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们的研究的绝大多数代码都是用 Python 写的，可参见我们的开源项目：https://github.com/openai/imitation 、https://github.com/openai/improved-gan 、 https://github.com/openai/iaf 、https://github.com/openai/vime 。在 GPU 计算上，我们大部分使用的是 TensorFlow（一些特殊案例使用了 Theano）；在 CPU 上我们也使用了这些或 Numpy。研究者有时候还在 TensorFlow 之上使用了 Keras 这样的更上层的框架。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;和大部分深度学习社区一样，我们使用的是 Python 2.7。我们通常使用 Anaconda，它有一些方便的软件包；其它情况我们还使用了一些困难的软件包，比如 OpenCV 和针对一些科研方面的库的性能优化：https://docs.continuum.io/anaconda/#high-performance&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;硬件&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于一个完美的 batch 工作，让你的集群中的节点的数量加倍可以让运行时间减半。不幸的是，在深度学习中，人们常常会看到一些来自许多 GPU 的非常次线性（sublinear）的加速。因此顶级的性能需要顶级的 GPU。我们也在模拟器、强化学习环境或小型模型（在 GPU 上运行不会更快）上使用了相当多的 CPU。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibCficthDQHbyjskJ3ia44KfnlyDSxDoScEL5bmTVrmp0iaMoo309LKHHf4sibhnN6DQP6C1StvXEibpWQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;nvidia-smi 查看完全负载的 Titan X&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;AWS 慷慨地同意向我们捐赠大量的计算。我们现在已在使用它们计算 CPU 实例和水平扩展 GPU 的工作。我们也运行着我们自己的物理服务器——基本上是运行在 Titan X GPU 上。我们预计会有一个用于长期作战的混合云：在不同的 GPU、互连（interconnect）和其它可能会在深度学习的未来变得重要的技术上进行实验是很有价值的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibCficthDQHbyjskJ3ia44KfndJuF16nfkEs09tl415a00CIVfLgMOqvJzfMKz84X8dChibmhZPIVPgg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;同样物理基础的 htop（http://hisham.hm/htop/）表现出了大量空余的 CPU。我们通常将我们 CPU 密集型负载和 GPU 密集型负载分开运行。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;配置&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们的基础架构方法就和许多公司对待产品一样：它必须有一个简单的界面，而且易用性和功能一样重要。我们使用一套统一的工具来管理我们所有的服务器，并将它们尽可能配置得完全一样。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibCficthDQHbyjskJ3ia44KfncQgPQ6sQOFenxZ64kwCianWgAnBDgE4rwgNFU3V7H1Srm62D7moU0ow/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;我们用来管理 Auto Scaling 组的 Terraform 配置的一个片段。Terraform 可以创造、修改或破坏你的运行云资源以匹配你的配置文件。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们使用 Terraform 来设置我们的 AWS 云资源（如，网络路由、DNS 记录等）。我们的云和物理节点使用的是 Ubuntu，并配置了 Chef。为了更快的 spinup times，我们使用 Packer 预焙（pre-bake）了我们的集群 AMI。我们所有的集群都使用了互不重叠的 IP 地址范围，并且通过用户笔记本电脑上的 OpenVPN 和物理节点上的 strongSwan（作用类似 AWS Customer Gateways）与公共互联网进行了互连。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们将人们的主目录、数据集和结果存储在 NFS（物理硬件）和 EFS/S3（AWS）上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;编排&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;可扩展的基础设施往往最后会使简单的情况变得更困难。我们在用于小型和大型工作中的基础设施上投入了同等的努力，而且我们正在积极地充实我们的用于将分布式用例变得本地可访问的工具包。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们提供了一个用于 ad-hoc 实验的 SSH 节点集群，并使用了 Kubernetes 作为我们的物理和 AWS 节点的集群调度器。我们的集群横跨 3 个 AWS 区域（regions）——我们的工作是很有突发性的，我们将在某个时候达到单个区域的能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Kubernetes 要求每项工作都是一个 Docker 容器（container），这给我们带来了依赖隔离（dependency isolation）和代码快照（code snapshotting）。但是，构建一个新的 Docker 容器会给研究者宝贵的迭代周期增加额外的几秒钟时间，所以我们也提供了可以帮助研究者将笔记本中的代码透明地转换成标准图像的工具。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibCficthDQHbyjskJ3ia44KfnB6ibgm3oYsZga0THYxFECMDP23o0zlN3Mhch1xXIHF2woHrnEa0C4mA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;TensorBoard 中的模型学习曲线&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们直接向研究者的笔记本电脑公开了 Kubernetes 的 flannel network，让研究者可以无缝网络接入他们的运行中的工作。这对于获取 TensorBoard 这样的监控服务尤其有用。（我们最初的方法——从严格的隔离角度来看更清洁——需要人们为每个他们想要公开的端口创建 Kubernetes Service，但我们发现这会带来太多的麻烦。）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;kubernetes-ec2-autoscaler&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们的工作具有突发性与不可预测性：研究的线路可能很快地从单机实验到需要 1000 个核。例如在几周内，我们的一个实验就从处于在一台 Titan X 上运作的阶段，到了在 60 台Titan X、需要 1600 块 AWS GPU 上进行实验的阶段。因此我们的云架构需要动态提供 Kubernetes 的节点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在一个 Auto Scaling 组中运行Kubernetes节点是很容易的，但是很难正确管理这些组的大小。在提交一个批任务之后，所在集群（cluster）知道自己需要什么资源，应该直接分配这些资源。（相反的，AWS 的 Scaling Policies（扩展策略）则需要多次迭代，一点点释放新的节点，直到资源不再紧张。）此外，在终止它们以避免丢失正在运行的任务之前，集群还需要消耗节点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;仅使用 raw EC2 来完成大批量的任务是具有吸引力的，这也是我们开始的地方。然而，Kubernetes生态环境增加了很多内容：低摩擦工具（low-friction tooling）、记录日志、监控、独立于运行实例管理物理节点的能力等等。让 Kubernetes 正确地自动扩展要比在 raw EC2 上重建这个生态系统更加简单。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们正在发布 kubernetes-ec2-autoscaler （https://github.com/openai/kubernetes-ec2-autoscaler），这是一个 Kubernetes 的批优化过的扩展管理器（batch-optimized scaling manager ）。它作为一个普通的 Pod 运行在 Kubernetes 上，仅仅需要的是你的节点在 &amp;nbsp;Auto Scaling 组中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibCficthDQHbyjskJ3ia44KfnB0ibLRk5qQIAPibB55ngn7odVQ9sQv7M1NmKgHiaolSEvnubBmjbZMWLg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;em style="color: rgb(136, 136, 136); line-height: 1.75em; text-align: center;"&gt;&lt;span&gt;Kubernetes 集群的启动配置&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;自动扩展器（autoscaler）是通过对 Kubernetes master 的状态进行查询的方式工作的，其中包括计算集群资源的询问与容量所需的一切。如果超出容量限制，它将耗尽相应的节点，最终停止它们。如果需要更多的资源，它会计算哪些服务器要被创建，并适当地增加你的 Auto Scaling 组的大小（或就简单地使用 uncordons drained 节点，这可以避免新的 spinup time）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;kubernetes-ec2-autoscaler 可以处理多种 Auto Scaling 组、CPU 之外的资源（内存和GPU）以及在 AWS 区域以及实例的大小等细节上约束你的任务 。另外，突发的工作负载可以导致 Auto Scaling 组超时、出错，这是因为即使 AWS 也没有无限的容量。在这些情况下，kubernetes-ec2-autoscaler 会检测错误，并将超出部分转移到下一级的 AWS 区域。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 31 Aug 2016 15:40:57 +0800</pubDate>
    </item>
    <item>
      <title>深度 | 机器人为什么能写稿，以及它们能拿普利策奖吗？</title>
      <link>http://www.iwgc.cn/link/2499490</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心原创&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：赵云峰&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;里约奥运会期间，写稿机器人「Xiaomingbot」通过对接奥组委的数据库信息，可以进行实时撰写新闻稿件，在 16 天内发布了 456 篇资讯报道，平均新闻生成到发布时间为 2 秒钟，几乎达到电视直播的传播速度。Xiaomingbot 是今日头条实验室研发的AI机器人，可以通过两种文本生成技术产出新闻：一是针对数据库中表格数据和知识库生成自然语言的比赛结果报道，即简讯；二是利用体育比赛文字直播精炼合成比赛过程的总结报道，即资讯。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibCficthDQHbyjskJ3ia44KfnfUPF9p3Jq7zkdsLBcEz0Z9icA0jBAliczUnyWA0OmpRzLeuWc1DGqbiaQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;随着自然语言处理、知识库等人工智能技术的发展，许多媒体已经开始了机器人报道的探索。《纽约时报》数字部门开发了机器人编辑 Blossomblot ，每天推送 300 篇文章，每篇文章的平均阅读量是普通文章的38倍。此外，《纽约时报》还会在财报季、运动比赛报道的时候使用机器人来写稿；美联社在过去一年多时间里使用 Wordsmith 系统编发企业财报；在华尔街引起巨大反响的 Kensho 可以通过接入美国劳工部等数据源来自行创造投资分析报告；电讯社也计划使用雅虎在报导梦幻橄榄球联赛时用到的技术，用来发布一些美式橄榄球回顾；Automated Insights 的写作软件去年写了 150 亿篇文章，宣称自己是世界上最大的内容生产者；路透社也在发表机器撰写的文章，该系统的负责人认为「在一次盲测中，机器的作品表现得比人类作品更具可读性。」；此外，还有专门提供「标题党」服务的 Click-o-Tron 公司。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;媒体领域出现这种趋势的原因在于相关技术已经达到了一定的成熟度，而且这种成熟度是和新闻媒体的要求很好的匹配在了一起。在卡斯韦尔的「结构化故事」系统中，所谓的「故事」完全不是个故事，而是一个信息网，我们可以像对待文案、信息图表或者其它表达形式一样去组装它，阅读它，就像我们摆弄音乐音符一样。任何一类信息——从法院报道到天气预报——都能够最终能放入到这个数据库中。这样的系统的潜力是巨大的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「大多数自然语言系统都是在简单地描述一个事件。但是大多数新闻都是描绘性的，甚至是事件驱动的」来自密苏里大学 Donald W Reynolds 新闻机构的大卫·卡斯韦尔说。「事件们在不同的地点发生，这些事件之间的因果关系是这些事件的核心叙述结构。」需要把它们放到古老的新闻术语中：谁，发生了什么，在哪里，什么时候。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;根据 Donald W Reynolds 的说法，人工智能系统在进行新闻创作时需要解决非常多的技术难题，包括自然语言处理中的自动摘要、文本分类等，还有知识库和知识发现（KDD）等相关技术，比如实体定义、关系抽取、问答系统等。简单来说，就是机器首先需要理解自然语言，然后通过知识管理弄明白新闻中各个要素（各类知识）之间的关系。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;自然处理技术所有信息密集型处理过程的核心，也是今年以来谷歌、Facebook 和微软等科技巨头都最为重视的研究方向，在刚刚结束的语言学顶级会议 ACL 上，他们也都发表了众多重磅论文。谷歌开源了SyntaxNet，将神经网络和搜索技术结合起来，在解决歧义问题上取得显著进展——能像训练有素的语言学家一样分析简单句法；Facebook 推出了文本理解引擎 DeepText ，每秒能理解几千篇博文内容，语言种类多达 20 多种，准确度近似人类水平。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其中，阅读和理解人类语言对机器来说是一项极具挑战性的任务，这需要对自然语言的理解以及根据多种线索推理的能力。阅读理解是现实世界中的一个普通问题，其目的是阅读和理解给定的文章或语境，并基于此回答问题。在多种类型的阅读理解问题中，完形填空式的查询是基础的一类，并且也已经变成了解决机器理解问题的起点。与普通的阅读理解问题类似，完形填空式的查询（Taylor, 1953）是基于文档的本质提出的，尽管其答案是文档内部的单个词。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了教会机器完成完形填空式的阅读理解，需要学习给定文档和查询之间的关系，因此必须要大规模的训练数据集。通过采用基于注意（attention）的神经网络方法（Bahdanau et al.,2014），机器可以学习大规模训练数据中的这些模式。为了创造大规模训练数据，Hermann et al. (2015) 发布了用于完形填空式的阅读理解的 CNN/Daily Mail 新闻语料库，其中的内容由新闻文章及其摘要构成。之后 Hill et al.（2015）发布了 Children’s Book Test （CBT：儿童图书测试）数据集，其中的训练样本是通过自动化的方式生成的。此外，Cui et al.（2016）也发布了用于未来研究的汉语阅读理解数据集。正如我们所见，自动生成用于神经网络的大规模训练数据对阅读理解来说是至关重要的。此外，语境的推理和总结等更复杂的问题需要远远更多的数据才能学会更高水平的交互。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今年六月份，人工智能创业公司 Maluuba 公司发表了一篇关于机器理解的论文，提出了目前最先进的机器阅读理解系统 EpiReader ，该模型在 CNN 和童书测试（CBT）两个数据集上的成绩都超过了谷歌 DeepMind 、Facebook 和 IBM 。EpiReader 采取两个步骤来确定问题答案。第一步(Extractor), 我们使用了一个双向 GPU 逐字阅读故事和问题，接着采用一种类似 Pointer Network 中的 Attention 机制在故事中挑选出可能作为答案备选的单词。第二步( Reasoner )，这些备选答案被插入「完型填空」式的问题中，构成一些「假设」，接着卷积神经网络会将每个假设与故事中的每个句子加以比较，寻找文本蕴涵( Textual Entailment )关系。简单来说, 蕴涵是指，两个陈述具有很强的相关性。因此，最近似故事假设的蕴涵得分最高。最后，将蕴涵得分与第一步得到的分数相结合，给出每一个备选答案正确的概率。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;国内的哈工大讯飞实验室也提出了一种用于完形填空式阅读理解任务的全新模型，这被称为 attention-over-attention（注意之上的注意）阅读器。我们模型的目标是在文档级的注意之上放置另一种注意机制（attention mechanism），并诱导出「attended attention（集中注意）」以用于最后的预测。和之前的成果不同的是：我们的神经网络模型只需要更少预定义的超参数，并且可以使用一种简洁的架构进行建模。实验结果表明我们提出的 attention-over-attention 模型在大量公共数据集中都显著优于当前许多最佳的系统，例如 CNN 和「（Children’s Book Test）儿童图书测试」数据集。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;CMU 的 Mrinmaya Sachan 和邢波在 ACL 2016 上发表论文《用丰富的语义表征来实现机器理解》，通过用如指代和修辞结构这种跨句现象来合并组成句子的 AMR，从而为给出的文本和每个问答对建构意义表征图（meaning representation graph）。然后将机器理解降格成为了一个图包含问题（graph containment problem）。假定问答含义表征图（question-answer meaning representation graph ）和文本含义表征图（text meaning representation graph ）之间存在一个隐含的映射，该映射能够解释该答案。他们提出了一个统一的最大边缘框架，它能学习发现这个映射（给定一个文本语料库和问答对），并使用它学到的来回答关于新文本的问题。他们发现这个方法是目前完成这类任务的最好方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在知识库方面，谷歌自然语言处理技术专家 Enrique Alfonseca 认为，挑战包括知识库的实体解析和一致性问题。两年前，谷歌的一些员工发布了一个实体解析注释的超大文集，这个大的网络文集包括对 Freebase 主题的110亿次引用，它是由世界上研究信息提取的研究人员开发的。知识集指的是真实世界（或者虚拟世界）的结构化信息，在许多其他应用中，人们能够对文字进行语言分析。这些一般包括主题（概念和实体）、属性、关系、类型层次、推理规则、知识表征和人工、自动知识获取的研究进行了许多年，但是这些都是远未解决的难题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;CMU 的 Sujay Kumar Jauhar 认为，问答需要一个知识库来检查事实和推理信息。自然语言文本形式的知识学习起来比较简单，但是自动推理很难。高度结构化的知识库能让推理变得容易一些，但是学习起来又难了。他们在近期 ACL 上发表论文，探讨了半结构形式主义（semi-structured formalism ）的表来平衡这两种情况。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而上文提到的Xiaomingbot的主人今日头条实验室近期也在这方面取得进展——通过深度学习和知识库的结合来解决知识类问答问题。今日头条实验室科学家李磊博士表示，知识在知识库里表达成三元组形式的结构化信息，系统要做的事情是问了这个自然语言问题后，从知识库里找出这样的答案。这个问题的难度在于：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1）知识库非常大，从海量数据中找出答案是非常困难的；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2）自然语言问题本身比较复杂，因为有多种问法和表达方式；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3）训练数据非常有限。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而今日头条实验室提出的深度学习加上知识库的CFO方法是，首先观察到需要把自然语言问题表达成结构化 query ，把这个结构化 query 里的条件信息从问题里找出来。和传统方法不同，CFO 通过神经网络用了一个 Stacked Bidirectional GRU ，它是一个上下叠加起来的多层双向循环神经网络，通过这个模型去计算出问题中的实体以及实体之间的关系，之后就是构建结构化的查询语句以及从知识库里寻找答案。在测试结果上，准确率超过了微软和 Facebook。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些在自然语言处理、知识库方面最新的研究进展将会传导到人工智能在新闻领域的应用，就像今日头条此前所做的智能推荐一样，通过每天观察数千万用户的刷新，点击，搜索，收藏，评论的行为，不断加强对用户兴趣偏好的理解，从而能够不断提高推荐的准确性，成为在资讯推荐领域的人工智能。希望靠算法连接内容创作者和消费者。而现在，技术的进步将使这个边界获得再次延伸。就像今日头条创始人兼 CEO 张一鸣预言的那样，未来人工智能演化的第一阶段首先是在各个垂直领域诞生若干超级智能，比如资讯推荐领域的今日头条，健康和知识问答领域的沃森，围棋领域的 AlphaGo 。这些垂直超级智能可以在特定领域内展现出远超人类的能力，但是在擅长领域之外没有任何作为。不过，他们将为诞生在所有领域内都具备超人能力的终极智能打下基础。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而越来越多的机器人创作将成为媒体领域超级智能的开始，目前 Xiaomingbot 的资讯生成部分即实时文本生成研究是今日头条同北大计算机所万小军教授团队合作，用于问答系统的 CFO 也将应用在今日头条的其他媒体产品中。李磊表示，今日头条有个产品叫「头条问答」，我们希望对于一些简单的问题和事实类的问题可以通过自动回答的方式去解决，这样就可以节省专家人力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Xiaomingbot、CFO 只是头条实验室众多研究布局中的阶段性成果，后者旨在推动人工智能技术研究，让算法更好地理解文字、图片、视频、环境场景和用户兴趣，从而促进人类信息与知识交流的效率和深度。今日头条不仅仅是新闻客户端，是一款基于机器学习的个性化资讯推荐引擎，是所有信息、内容分享创作的平台。人工智能和机器学习的算法起到了重要作用，能够帮助高效精准地把用户感兴趣的内容推荐出去。今日头条的内容平台对应着双边用户：一边是内容的创作者，另一边是内容的消费者。所以为了把最好的内容推荐给最需要的读者，就需要机器学习的技术。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今日头条等媒体巨头对人工智能技术在研发和应用上的加码，让我们看到了人工智能在未来对媒体业造成的巨大影响。《浅薄》中提到，互联网作为一种智力工具，在给我们带来便利的同时也在重塑着我们的思维方式。随之而来的问题是，互联网这种媒介传递的信息越多，我们想找到优质或者自己所需信息的难度也就越大。而这正是人工智能的优势所在，它可以让大数据从负担变成便利，会重塑媒体的内容生产和分发。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在采用 Wordsmith 之前，美联社需撰写约 300 家公司的财报文章，可想而知这并不是个轻松的工作量。在使用机器人 Wordsmith 之后，美联社每季度可以出 3000 家公司财报，虽然其中仍有 120 篇需要人力更新或添加独立的后续报道，但显然它替人类编辑承担了绝大部分的工作量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在哥伦比亚大学庆祝普利策奖诞生一百年之际，智能机器人也将在财经报道、体育实况报道、骗点击的标题党新闻（clickbait）以及其它原本只有受过训练的记者才能报导的领域开始一展身手。「总有一天，机器人会赢得普利策奖」，来自 Narrative Science 的 Kris Hammond 如此预测。这家公司专注于「自然语言生成」。「我们能讲述隐藏在数据中的故事。」最近的进步味着，人工智能现在能够撰写出具有可读性的流畅文字，并且还能比亢奋的写手更快地大量炮制模板型文章。「有了自动化，我们现在能为 4,000 家公司追踪、 撰写季度收益报告，」来自世界第一个也是迄今为止唯一个使用自动化编辑的通讯社——美通社的贾斯汀· 迈尔斯说，「以前我们只能做到 400 家。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而对于机器人能否拿普利策新闻奖这个问题，迈尔斯也「绝对相信」——因为机器人已经做到了。Bill Dedman 因一篇抵押贷款中存在种族主义问题的调查报道，而获得了普利策奖。这篇报道虽然发表于 1988 年，却是由电脑协助写作成的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;自动化新闻不仅仅具有数量优势，还有助于定位客户需求——通过用户画像、情感分析等技术为用户提供个性化内容，或者对于智能对话系统与用户进行交互。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;随着人工智能技术在新闻领域的参与程度越来越高，对于人工智能技术是否造成失业问题的争论也愈演愈烈。牛津大学此前发布了一篇报告称，目前 47% 的工作岗位将最终被自动化。但对此的批评意见认为，工作被取代，并不意味着劳动者将失去工作，正如曾经汽车的出现取代了许许多多的马车夫和马童，但同时创造了更多修建高速公路和服务加油站的工作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于媒体领域来说同样如此，机器人负责这项单调而又乏味的工作就能把记者们解放出来，让他们追求一些需深度思考的报道，同时机器人也可以将消费者从海量信息中解放出来，提高他们获取信息和知识的效果和效率，而这就是人工智能对媒体的最重要影响。不久的未来，我们将看到人工智能作为工具在新闻产业产出发挥重要的作用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心原创，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 31 Aug 2016 15:40:57 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 自动驾驶汽车怎么和人类交流？创业公司Drive.ai正在解决这个问题</title>
      <link>http://www.iwgc.cn/link/2499491</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自 IEEE Spectrum&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：&amp;nbsp;Evan Ackerman&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：Rick. R、吴攀、杜夏德&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;em style="color: rgb(136, 136, 136); line-height: 1.75em;"&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em style="color: rgb(136, 136, 136); line-height: 1.75em;"&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;em style="color: rgb(136, 136, 136); line-height: 1.75em;"&gt;&lt;span&gt;在自动驾驶研发领域都在专注于在自动驾驶的机制上开发时，创业公司 Drive.ai 另辟蹊径选择了与自动驾驶汽车与周围环境（主要是人类）进行通信的发展方向。今天，这家神秘的创业公司走出了隐身模式，发布了一款帮助将现有的汽车改装成自动驾驶汽车的套件。另外，本文还包含了 IEEE Spectrum 对 Drive.ai 联合创始人兼总裁 Carol Reiley 博士的专访。&lt;/span&gt;&lt;/em&gt;&lt;br/&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;大多数自动驾驶方面的研究者们都非常专注于使汽车免于碰撞之类的事情，这可以理解。而在一般情况下，这恰恰是自动驾驶汽车已经非常擅长做的事情——特别是在公路上以及其他一些区域中，驾驶员不必担心周围会出现突如其来的行人，从而不必进行更复杂和更困难的思考。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Drive.ai 是一小部分正在推动自主驾驶技术快速商业化的创业公司之一。这家公司于今年四月走出了隐身状态，IEEE Spectrum 也曾写了有关其自上而下的深度学习（top-to-bottom deep learning）解决方法。如今，Drive.ai 是「正式出山」了，而我们已经了解到了有关该公司的更多内容。Drive.ai 正在兜售一种改装套件——一组为商业车提供的可以使现存车辆变身成为完全自动驾驶的工具。但与众不同的是，它含有一个 HRI（人机交互）组件，即一个能使汽车直接与人进行交流的超大显示器。乍一看这似乎是个全新的东西，但它却是自动驾驶汽车迫切需要的一个功能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;理解自动驾驶汽车被赋予这种交流能力的原因是非常重要的，试想一下当你试图走过一条无法被控制的人行横道的情况。一辆迎面而来的汽车可能会因为你而减速，但通常情况下，在你穿过道路之前会与司机进行眼神交流，确保他们已经看到你了并且会停止前进。现在想象同一情形下的一辆无人驾驶汽车。在无人控制的情况下，你如何知道汽车是否已经：1）完全检测到你；2）明白你想做什么；3）决定是否会为你停下？&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;无论是在行人、骑自行车或其他驾驶员之间，这样的交流发生得比你可能会意识到的更加频繁。它也可能没有实际上应该发生的那么频繁（我认为自己是一个这方面的专家，因为我上周末从纽约开车到了华盛顿。）。实际上自动驾驶汽车不仅会使用其转向信号，也会传达更复杂的概念，它们甚至可以礼貌地要求并道，提供诸如「减速防止前方事故」这样的有用信息，或者甚至是在超车占道时向你道歉，当然它们可能不会那么做。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在第一代商业化的自动驾驶汽车中聚焦 HRI 的基本必要性源自这样一个事实：大部分人类驾驶员与大部分自动驾驶汽车之间将有一个重要的过渡期。一旦道路上行驶的都是自动驾驶汽车，而且车辆之间可以进行无线通信，那么这就不是个大问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有时能感觉到自动驾驶汽车公司高度关注于那个终极目标。而由于过渡期将是混乱不堪的，常见的解决方案就是要么忽略它（「我们以后会处理它」），要么试图规避这个问题。回到人行横道的例子，与确实帮助人们安全过马路相反，区别在于能否确保你的自动驾驶汽车不会在人行横道上撞到别人。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibCficthDQHbyjskJ3ia44KfnYGaOC9cLZfE94v1dzlZibVk2okS69bJhWHLONczcM15LRpEBZ8uicaDg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了得到更多无人驾驶汽车应用 HRI 的细节，以及更多有关 Drive.ai 自动驾驶的全栈深度学习（full stack deep learning）方法，我们采访了 Drive.ai 的联合创始人兼总裁 Carol Reiley 博士：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;IEEE Spectrum：Drive.ai 的自动驾驶技术有什么特别的地方？&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Reiley：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我把自动驾驶汽车看作大多数人将与之互动的第一个社会机器人。它不是人形的，而是一个通过人工智能实现的智能机器。（我们不得不问自己），一旦你解决了从 A 点到 B 点的问题，这些自动驾驶汽车如何与道路上的所有其他玩家互动？这种关系是什么样的？以及发生在人行横道上、路口或当你试图并道时的非语言之舞是什么？当你替代了方向盘后的人类时，这辆车会如何反应？它如何进行沟通才能让每个人都感到安全并信任它呢？我们觉得这是一个人们还没有太多谈论的话题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;Spectrum：在你谈到通过人工智能来实现一个更智能的机器人时，它是如何在自动驾驶背景下进行的？在 2007 DARPA Grand Challenge 中运用的人工智能与目前自动驾驶汽车所使用的有何不同？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Reiley：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;这个问题有很多不同层面。我们正在从头运用深度学习来创建公司；在美国国防部高级研究计划局（DARPA）的那段时间进行的是前期的深度学习。 Sebastian（即 Thrun (http://robots.stanford.edu/)，他在谷歌开发自动驾驶汽车之前，带领的是斯坦福大学的 DARPA Grand Challenge团队）曾说：「计算机视觉行不通，我支持高清地图和激光雷达。」而谷歌的自动驾驶汽车计划就是这样被建立的：在计算机视觉行不通的设想之上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2012 年，Google Brain 彻底改变了计算机视觉与感知方面的人工智能，而现在这个行业都是由深度学习支撑的。在这一点上，谷歌已经在非深度学习方法上投资了数年，而他们正在一个模块一个模块地进行切换，但很难从根本上改变这个方法。这是我们创业的优势之一：我们是在从头创办一家深度学习自动驾驶汽车公司。而且我们不仅用它来进行感知，也将它用于决策。这是一个更加闭环的方法。这是我自从 DARPA Grand Challenge 时期以来对人工智能所发生的变化的一个看法。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Spectrum：你们的汽车用的是什么传感器？你觉得摄像头和激光雷达相比如何？&lt;/span&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Reiley：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;这正是我们的深度学习流程所面临着的问题：什么样的传感器适合你的车，我到底要收集多少数据，以及到底需要驾驶多少英里才够。在深度学习方面，我们目前是希望把传感器的成本降得比以往任何时候都更低。摄像头是非常便宜的传感器，而且有了深度学习后，就可以对图像置于语境中处理。对于冗余的部分，我们有其他的传感器，但是比起其他团队，我们真的在推动摄像头要努力得多，而机器学习帮我们做到了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;某些团队把激光雷达安放在车的前面和中心位置，否则他们就会认为没有高清地图，你就不能解决这个问题。即便没有地图人也能在熟悉的附近开得很好，他们基本上有一个相当于（立体）相机的东西。我们的团队欢迎任何低成本的传感器；如果 Quanergy 能拿到 100 美元的传感器，那就太棒了，我们一定会用它的。我们并不是在炫耀我们能用摄像头做高难度的事情；我们只是尝试建立安全且人们能真正使用并能负担得起的系统。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;Spectrum：为什么HRI 对于自动驾驶汽车来说如此重要？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Reiley：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;一个人开车时，他会观察周围环境中的所有相关线索。例如，你看见前面有辆车，如果它的车轮向右转，你就可以推测它下一个动作：它可能要右转。真实世界中有很多这种微妙的线索可以用来帮助我们导航，而且使[我们的汽车]看起来具有更多社会智能，因为你能在它们做出动作之前就能预测到会发生什么。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们正在推动自动驾驶汽车在社会互动方面的技术。人类与人类的非语言交流有时可能会很让人困惑。当你把人移开，这些车就得智能到可以自己导航，而且能被这条道路上的所有人接受，同时要保证非常安全。所以，在一个四岔路口，路人与车之间会发生什么呢？我们正在探寻车该如何表达自己，我们用 LED 灯，像 R2-D2 这样的声音来传递信息，或者通过不同的移动方式来显示车的意图。我们正在考虑如何让我们的汽车与其他人沟通。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;驾驶的一个有趣之处是它是动态的，涉及到很多人类，而人类是不可预测的。对于一辆必须进行实时决策的自动驾驶汽车而言，它需要在切换模式时保持非常透明，所以它不只是显得不稳定。我们如何向外部世界说明这辆汽车是自动的呢，以及我们如何表示我们的意图是什么呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;Spectrum：这种对 HRI 的重视是否意味着汽车自动化的实际驾驶部分已经（几乎）得到解决了呢？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Reiley：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我觉得这个行业的大部分都在关注驾驶的机制。这不是说 HRI 与那是完全不同的；我将其看作是高度的耦合，是应该并行发展的东西，而不是一样一样地做。这不只是某种实验室里面的机器人。存在许多与人类相关的问题需要考虑。我认为汽车行业在很多事情上采用了模块化的方法，但自动驾驶汽车并不是模块化的问题：它们是一种基于软件的、整体性的东西，你必须退后一步了解其整体面貌。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;Spectrum：Drive.ai 在这方面有什么计划？&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Reiley：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我们不造汽车；我们的业务是创造改装套件。所以需要选择有兴趣交付货物或交付人的合作伙伴。已有的汽车进入 Drive.ai &amp;nbsp;的工厂，然后我们为其添加带有传感器和 HRI 组件和软件的车顶架，而且我们也在与这些合作伙伴合作做固定路线的驾驶。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们将这看作是自动驾驶汽车的安全的、逻辑上的第一步。我认为自动驾驶汽车的全球部署将会带来大规模的混乱。我认为人们目前还没有将人类看作是其中的一环。即使我们解决了自动驾驶汽车的问题，更大的问题实际上是人类。人类会搞砸一切，而且你必须为人类使用自动驾驶汽车的情况进行设计，还有他们会怎样理解他们周围的事物。我们想要快速推出这项技术，我们将这种与我们合作伙伴的固定路线的策略看作是第一步。而且我们肯定有兴趣做一种 4 级的（完全自动）方法，因为 3 级的（其中人类还控制着一些事情）也是很混乱的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibCficthDQHbyjskJ3ia44KfnmkKtzBWGuyuumlMw71jkhG9k89TbjrIWqIgxjZSrlTu4VbdKJUYHUw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Drive.ai 有其自己的车队，它们将在加州山景城附近进行测试。该公司的愿景涉及到汽车「能够与我们透明地沟通，即使没有人类司机」。最后 Drive.ai 的业务将会扩展到公共和私人货运领域。有媒体报道称他们目前已经和一些重要的 OEM 和汽车供应商建立了合作关系。再加上他们已经获得了 1200 万美元的融资，也许一两年之内，我们就能在加州的道路上看到带有友好的大屏幕的汽车了吧。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 31 Aug 2016 15:40:57 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 谷歌开放TF-Slim：在TensorFlow中定义复杂模型的高层库（附论文）</title>
      <link>http://www.iwgc.cn/link/2499492</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自 Google Research Blog&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：&amp;nbsp;Nathan Silberman 、 Sergio Guadarrama&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：杜夏德、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今年早些时候，我们发布了一款在 TensorFlow 上的最先进的图像分类模型实现——Inception -V3。这些代码允许用户使用一个单一的本地机器或机器集群在 Image Net 分类数据集上通过同步梯度下降（synchronized gradient descent）的方式训练模型。该 Inception-V3模型建立在 TenorFlow 的 TF- Slim 实验库上，它是一个用于在 TensorFlow 中定义、训练和评估模型的轻量软件包。这个TF-Slim 库提供了常见的抽象，可以使用户简要快速地定义模型，同时还能维持模型架构透明和其超参数的明确性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;自发布以后，TF-Slim 增长迅速，添加了多种类型的层、损失函数和评估指标，用于训练和评估模型的方便的例程（routine）也越来越多，。这些例程考虑到了扩展工作时你需要担心的所有细节，比如并行读取数据、在多台机器上部署模型等等。此外，我们已经利用标准数据集创建了 TF-Slim 图像模型库（TF-Slim Image Models library），可以为许多广泛使用的图像分类模型提供定义和训练脚本。TF-Slim 和它的组件已经在谷歌内部得到了广泛使用，而很多改进已经被集成到 tf.contrib.slim 中。（https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/slim）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今天，我们很高兴与 TF 社区共享最新的 TF-Slim 版本。以下几点需要强调：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;许多新种类的层（如 Atrous Convolution 和 Deconvolution）丰富了神经网络架构的大家庭。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;支持更多的损失函数和评估指标（例如，mAP，IoU）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;一个部署库，可以使得用多个 GPU / CPU在同一台机器或多台机器上执行同步或异步训练变得更简单：https://github.com/tensorflow/models/blob/master/slim/deployment/model_deploy.py&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;用于定义和训练许多使用广泛的图形分类模型的代码（例如，Inception[1][2][3]，VGG[4]，AlexNet[5]，ResNet[6]）：https://github.com/tensorflow/models/tree/master/slim/nets&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;用于上述图像分类模型的预训练模型权重。这些模型已经在 ImageNet 分类数据集上训练过了，但是也能用来执行很多其他的计算机视觉任务。举个简单的例子，我们提供了可以微调这些分类器以适应一个新的输出标签集合的代码。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;容易处理标准图像数据集的工具，如 ImageNet，CIFAR 10 和 MNIST。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;想尝试一下 TF-Slim 吗？这条链接（https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/slim）可以帮到你。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你想试试图像分类模型可以看下这条介绍（https://github.com/tensorflow/models/blob/master/slim/README.md）或者 Jupyter notebook（https://github.com/tensorflow/models/blob/master/slim/slim_walkthough.ipynb）&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;参考文献：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;em style="color: rgb(136, 136, 136); line-height: 1.6;"&gt;&lt;span&gt;[1] Going deeper with convolutions, *Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, Andrew Rabinovich, CVPR 2015*&lt;/span&gt;&lt;/em&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[2] Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift，*Sergey Ioffe, Christian Szegedy, ICML 2015*&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[3] Rethinking the Inception Architecture for Computer Vision , *Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens, Zbigniew Wojna, arXiv technical report 2015*&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[4] Very Deep Convolutional Networks for Large-Scale Image Recognition, *Karen Simonyan, Andrew Zisserman, ICLR 2015*&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[5] ImageNet Classification with Deep Convolutional Neural Networks , *Alex Krizhevsky, Ilya Sutskever, Geoffrey E. Hinton, NIPS 2012*&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[6] Deep Residual Learning for Image Recognition, *Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun, CVPR 2016*&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;点击「阅读原文」，下载论文↓↓↓&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 31 Aug 2016 15:40:57 +0800</pubDate>
    </item>
    <item>
      <title>学界 | Ian Goodfellow 论文更新：通过视频预测的用于物理交互的无监督学习（附论文）</title>
      <link>http://www.iwgc.cn/link/2499493</link>
      <description>&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自 arxiv.org&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：&amp;nbsp;Chelsea Finn、Ian Goodfellow、Sergey Levine&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：杜夏德、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibCficthDQHbyjskJ3ia44KfnRL0HAwJABDSRicpCV3caCj42bES2sdqm9UluzWfFUXY5M6rbOKicz59g/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;摘要：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;代理（agent）学习与世界交互的一个核心挑战是预测行动如何影响环境中的物体。现有的学习物理交互中的动力学的很多方法需要有标注的对象信息。然而，要将真实世界的交互学习的扩展到多种场景和对象中，获取有标注的数据变得越来越不切实际。为了在无标注的情况下学习物理对象的运动，我们通过从前面的帧来预测像素运动分布的方法，开发出一种以行动为条件的视频预测模型（action-conditioned video prediction model），其能明确地对像素运动建模。因为我们的模型可以明确地预测运动，所以它相对于对象外观是部分不变的，这使它可以归纳之前没看到过的对象。为了探索用于真实世界交互代理的视频预测，我们还引进了一个包含 50,000 次机器人交互的涉及推这个动作的数据集，包括一个带有全新对象的测试集。在这个数据集中，对以机器人未来动作为参照条件的精确视频预测达到了学习在不同行动过程基础上对未来进行「视觉想象（visual imagination）」的程度。试验发现，与之前的方法相比，我们提出的方法不仅产生了更精确的视频预测，还更精确地预测到了对象运动。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 31 Aug 2016 15:40:57 +0800</pubDate>
    </item>
    <item>
      <title>深度 | DeepMind官方深度解读：使用合成梯度的解耦神经接口（附论文）</title>
      <link>http://www.iwgc.cn/link/2487208</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自 DeepMind&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：&amp;nbsp;Max Jaderberg&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：&lt;strong&gt;ACsync、吴攀&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;DeepMind 开发的许多算法都使用到了神经网络。例如，AlphaGo 使用卷积神经网络对围棋棋盘进行评估。同时在电子游戏中，DQN 与深度强化学习算法使用神经网络来选择操作，从而在视频游戏上实现了超人级的水平。8 月 20 号，机器之心发布的文章《&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718429&amp;amp;idx=2&amp;amp;sn=2dad7f9aab23cf05323bb9d01c49d11b&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718429&amp;amp;idx=2&amp;amp;sn=2dad7f9aab23cf05323bb9d01c49d11b&amp;amp;scene=21#wechat_redirect"&gt;学界 | 谷歌DeepMind最新论文：使用合成梯度的解耦神经接口&lt;/a&gt;》介绍了他们在此方面的新研究。今日，DeepMind 发表官方博客对此研究进行了详细解读。文中提到的论文可点击「阅读原文」下载。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这篇文章介绍了我们最近一些关于神经网络能力的进步与相应的训练过程的研究，我们称其为使用合成梯度的解耦神经接口（Decoupled Neural Interfaces using Synthetic Gradients）。这项工作给了我们一种在神经网络之间实现通信的方式，从而让它们可以学习彼此发送消息；这种方法是通过一种去耦合、可扩展的方式在多个神经网络之间实现通信，或者提升循环神经网络的长期时间依赖性（ long term temporal dependency ）。这是通过使用一个逼近误差梯度（error gradients）的模型实现的，而没有特别使用反向传播来计算误差梯度。这篇文章的剩余部分假设读者对神经网络与如何训练神经网络已有一定的了解。如果你是刚刚接触这部分领域的新手，我们推荐 YouTube上的《Nando de Freitas lecture series》系列了解深度学习与神经网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;神经网络与锁的问题&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;考虑神经网络中的任意一层或一个模块，当其之后网络中的模块已经执行并且梯度已经回传给它，那它只能被更新一次。例如这样一个简单的前馈网络：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9cWoqBBEwZh1YaiazSWTkg1DrXg4NvHGDYB4kU5hxpgsFnm1Oq979rPzGdQCZ4rxicsNbuP1bTbCvQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;span&gt;在 Layer 1 处理完输入后，它只能在输出激活（output activations，黑线）被传播通过神经网络的剩余部分、然后产生一个损失（loss）并反向传播误差梯度（绿线）直到达到 Layer 1 之后才能被更新。这一系列的操作意味着 Layer 1 在其能更新之前必须等待 Layer 2 与 Layer 3 的前向传播与反向传播的计算。对于神经网络剩余部分，Layer 1是被锁住的、是耦合的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为什么这是个问题？显然对于如前描绘的前馈网络而言，我们并不需要担心这个问题。但考虑一下带有多个网络的、以异步和不规则的时间尺度在多种环境中工作的复杂系统。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9cWoqBBEwZh1YaiazSWTkg1ljcaibWX6JFGiaWZmdOWLcbKVwaibPXl88vZEYmdjYr74ca20YgF5sf6g/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;或者一台分布于多台机器的大型分布式网络。有时候需要网络中的所有模块需要等待网络中的其它所有模块都执行完成和反向传播梯度，这个过程非常耗时，而且甚至无法解决。如果我们解耦了这些模块之间的接口——连接，那么我们就能让每一个模块都独立地更新，而不会受到网络中其它的部分的锁定。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以，我们如何解耦神经接口（即解耦网络模块之间的连接），并同时仍然能保证这些模块能够继续从交互中学习呢？在这篇论文中，我们移除了对获取误差梯度（error gradient）的反向传播的依赖，并转而学习了一个可以预测哪些梯度将仅基于局部信息的参数模型。我们将预测出来的梯度称为合成梯度（synthetic gradients）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9cWoqBBEwZh1YaiazSWTkg1NywbAnY40n0r9qicZs5sE68Q6Coibg9hEDcaMl700UTq401pDiaCd5FtA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该合成梯度模型可以从模块中获取激活（activation），并产生将会成为误差梯度（error gradient）的预测——误差梯度是指在特定激活下网络的损失的梯度。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;回到我们简单的前馈网络的例子，如果我们有一个合成梯度模型，我们可以执行下图的操作&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9cWoqBBEwZh1YaiazSWTkg1HI4IEGrh9QRWtYbujph9Nfso3f1mDcknaukPH8iaE7iawJPkJiaYSBZIg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;并甚至能在网络中其它部分得到执行之前就使用该合成梯度（蓝色）更新 Layer 1.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该合成梯度模型本身的训练是为了回归（ regress）目标梯度——这些目标梯度可能是从损失（loss）或其它合成梯度反向传播回来的真实梯度；而那些其它合成梯度又是从更下游的合成梯度模型中反向传播得到的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9cWoqBBEwZh1YaiazSWTkg1gp5r5a9zSTKGpFBumBRuhadu709icm6N7rLreDEaxnJVvSMOvQ3Qumw/0?wx_fmt=png"/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这种机制普遍出现在任意两个模块之间的通信，而不只是在前馈网络中。这种机制的具体工作流程如下图，其中一个模块的颜色变化代表该模块的权重的更新。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_gif/KmXPKA19gW9cWoqBBEwZh1YaiazSWTkg1bjAoSXezKOEvjfic7K8iaSgakaPzAWfhe2OpiaoWaOZMibAWtlyzoMgWIw/0?wx_fmt=gif"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因此在一个神经网络中使用解耦神经接口（DNI）去掉了之后的模块对先前的模块的锁定。在论文的实验部分，在 CIFAR-10 图像分类问题上，我们使用合成梯度，并且每层均为去耦合的这种方式训练网络，可以和使用反向传播方式进行训练达到同样的准确度。 要认识到 DNI 不是如魔法般地允许不使用真实的梯度信息训练网络。真实的梯度信息确实会通过网络向后渗入，但是相比于通过合成梯度模型的损失值，其速度较为缓慢，并且需要大量的训练迭代次数。合成梯度模型近似以及平滑真实梯度的消失。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这点上有一个适当的问题需要考虑，这些合成梯度模型增加了多少计算复杂度——大概你需要一个与网络本身复杂度相同的合成梯度模型架构。令人惊喜的是，合成梯度模型能够非常简单。对于前馈网络，我们的确可以发现，即使单线性层（single linear layer ）也能作为合成梯度模型良好地工作。因此，这是非常容易训练的，并且能够迅速产生合成梯度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;DNI 能适用任一通用的神经网络架构，而不只是前馈网络。一个有趣的项目就是循环神经网络（RNN）。一个 RNN 有一个展开的、反复使用的循环核心（recurrent core）来处理序列数据。训练 RNN 的理想情况是：我们能在整个序列（可能无限长）上展开该核心，使用沿时间的反向传播（BPTT）将误差梯度传播穿过整个图（graph）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9cWoqBBEwZh1YaiazSWTkg1CgKulH9k7vabq3Co2NZibb2aibOazun6ZbmC1cOn4EbrAaibZo3kOoxibQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;span&gt;然而在实践中，由于内存的约束以及需要频繁计算更新我们的核心模型，我们只能在有限的步上展开。这被称之为截断的沿时间的反向传播（truncated BPTT），下图给出了截断成 3 个步骤的示意：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9cWoqBBEwZh1YaiazSWTkg1vSw5ygsJjdLwVSjWGDNfib84HvoIHkVkbibHwzdAbrG3CFBhEfpuSUlA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;核颜色的改变代表着核的更新，即权重得到更新。在这个例子中，截断 BPTT 看起来解决了训练的一些问题——我们现在能够每三个步骤更新一次我们核的权重，并且只需要内存中的三个核心（core）。然而事实上，并不存在超过三个步骤的误差梯度的反向传播，这意味着核的更新并不会受到未来超过 2 个步骤的误差的直接影响。这限制了 RNN 可以学习用来建模的时间依赖。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果我们不在 BPTT 的边界之间使用反向传播，而是使用 DNI 和产生合成梯度，那么未来的误差梯度将会成为哪种模型？我们可以将一个合成梯度模型整合到核心中，以使得在每一个时间步骤，该 RNN 核都会在产生输出的同时产生合成梯度。在这个案例中，该合成梯度是在考虑了之前时间步骤的隐状态激活后所预测出的所有未来损失的梯度。这个合成梯度只能用在截断 BPTT（ truncated BPTT ）的边界（我们之前在这里无法得到梯度）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9cWoqBBEwZh1YaiazSWTkg18r2mDlKOLT2jkAGsZjXic72XmibpiaZiaibqTHmEC7vU7tVciaiaVTgnVVLUw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这可以在训练过程中非常高效地执行——它几乎不需要我们像图中那样在内存中保留额外一个核。其中绿色虚线边框表示的只是关于输入状态的梯度的计算，而绿色实线边框则是额外考虑了核参数的梯度计算。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9cWoqBBEwZh1YaiazSWTkg1O9WxyaVBsBjEicC0MdX9iasiaLEKKHgplf1oIz6UE1mXAdqic37YCMFyyA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过与 RNN 一起使用 DNI 和合成梯度，我们近乎是在一个无限展开的 RNN 中进行反向传播。事实上，这可以得到能建模更长的时间依赖（ longer temporal dependencies）的 RNN。下面是来自这篇论文的一个结果例子：&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;训练过程中的 Penn Treebank 测试误差（更低更好）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9cWoqBBEwZh1YaiazSWTkg1TlRviakoWdaUEPO7V0dCKWXBQxrMrTIn9TIOyoRJBc916wZKQvsKnIA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Penn Treebank 是一个语言建模问题；这幅图给出了在 Penn Treebank 上的下一个字符预测（next character prediction）上训练的一个 RNN 应用。y 轴表示每字符位数（BPC: bits-per-character），其数字是越小越好。x 轴表示训练过程中该模型所看到的字符的数量。蓝色、红色和灰色的虚线是使用截断 BPTT 训练的 RNN，分别展开了 8 步、20 步和 40 步——RNN 在执行沿时间的反向传播（BPTT）前被展开的步数越多，模型就越好，但训练就越慢。当将 DNI 用在展开了 8 步的 RNN 上时（蓝色实线），该 RNN 能够实现 40 步模型那样的长期依赖（long term dependency），但训练速度却达到了它的两倍（在常规的带有单个 GPU 的桌面机器上，但数据时间和实际时间上都更快）。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;重申一下，我们增加的合成梯度模型让我们可以解耦在网络的两个部分之间的更新。DNI 还可以应用在分层 RNN 模型（以不同时间尺度运行的两个或更多个 RNN）上。正如我们在论文中给出的那样，DNI 能通过实现更高水平模块的更新率来显著提升这些模型的训练速度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;希望本文的解释能让你了解我们在这篇新论文中所报告的实验：显然创造解耦神经接口是可能的。这是通过创建能够获取局部信息和预测误差梯度的合成梯度模型实现的。在较高的层面上，这可被认为是一种两个模块之间的通信协议。一个模块发送信息（当前激活），另一个接收这个信息并使用一个效用模型（model of utility ，即该合成梯度模型）来对其进行评估。该效用模型允许接收方向发送方提供实时反馈（合成梯度），而不再需要等待该信息的真实效用的评估（通过反向传播）。这个框架也可以在误差批评（error critic）的角度进行思考（论文：&lt;/span&gt;&lt;span&gt;&lt;span&gt;HANDBOOK OF INTELLIGENT CONTROL&lt;/span&gt;&lt;span&gt;），这有些类似于在强化学习中使用批评（论文：&lt;/span&gt;&lt;span&gt;Dire&lt;/span&gt;&lt;/span&gt;&lt;span&gt;ct Gradient-Based Reinforcement Learning:II. Gradient Ascent Algorithms and Experiments&lt;/span&gt;&lt;span&gt;）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些解耦神经接口允许网络的分布式训练、能增强用 RNN 学习到的时间依赖、还能加速分层 RNN 系统。我们很兴奋地将继续探索 DNI 的未来，因为我们认为这将成为一个重要的基础，让我们可以开拓更模块化的、解耦的和异步的模型框架。最后，相关的更多细节、技巧和全部实验请查阅论文《Decoupled Neural Interfaces using Synthetic Gradients》。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;论文：使用合成梯度的解耦神经接口（Decoupled Neural Interfaces using Synthetic Gradients）&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9cWoqBBEwZh1YaiazSWTkg1VFYuZHAsctmKrBffWYPda3rAQlkTibYzfQsf7dPuXmjUyOYfiamky2OQ/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：&lt;/span&gt;&lt;span&gt;训练 directed neural networks 通常需要将数据前向传播通过一个计算图（computation graph），然后再反向传播误差信号，从而生成权重更新。因此，网络中所有层——或称为模块（modules）——就会被锁定，在某种意义上，它们必须等待该网络的剩余部分前向执行，然后反向传播误差之后才能实现更新。在本研究成果中，我们通过引入网络图（network graph）的一个未来计算模型而对模块进行解耦，从而打破了这种限制。这些模型仅使用局部信息就能预测建模的子图（subgraph）将会产生的结果。我们尤其关注建模误差梯度（modelling error gradients）：通过使用建模的合成梯度来取代真正的反向传播误差梯度，我们可以解耦子图并独立和异步地对它们进行更新，即我们可以实现解耦神经接口。我们展示了三项实验结果，前向传播模型（其中每一层都是异步训练）、循环神经网络（RNN）（预测某个未来梯度可在 RNN 可以有效建模的时间上进行扩展）、和一个分层 RNN 系统(在不同时间尺度上)。最后，我们证明：除了预测梯度，该框架还可被用于预测输入，得到可以以前向和反向通过的方式解耦的模型——从而发展成可以联合学习（co-learn）的独立网络，它们可通过这种方式被组合成一个单一的 functioning corporation。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 30 Aug 2016 17:19:34 +0800</pubDate>
    </item>
    <item>
      <title>ACM月刊 | 艾伦人工智能研究所CEO：设计遵循人类法律和价值观的人工智能系统</title>
      <link>http://www.iwgc.cn/link/2487209</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自 CACM&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：&amp;nbsp;Amitai Etzioni、Oren Etzioni&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李亚洲、杜夏德、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;运行人工智能系统（Operational AI systems，例如，自动驾驶汽车）需要遵循我们的法律和价值观。本文提议人工智能监管系统（人工智能卫士，AI Guardians）作为解决这一挑战的一种途径，同时也回应了对于日益增长的人工智能系统潜在威胁的担心。这些人工智能监管系统是为了查实运行系统没有过度背离程序员的指令，而且如果背离了要把它们带回到指令下。引入这样的二级指令，并不意味着监管系统应该是严厉、强势、或者说是硬性的控制。为了遵循它们从额外的数据挖掘与经验中学习到的内容，并且能够至少实施半自主决策（接而是更大的自主权），运行系统需要很大程度上的自由度。然而，所有的运行系统都需要边界，既是为了不违反法律也是为了遵循道德准则。开发这样的监管系统——人工智能卫士——是人工智能社区的一项新使命。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;纵观历史，所有的社会都有监管系统。工人有监工；商业有会计人员；教师有校长。也就是说，所有的这些系统都有层级，第一梯队的操作人员服从于第二层的监管，并期望回应来自监管者的纠正信号。（反过来也期望监管方能考虑来自第一梯队的建议或者甚至是要求。）1996 年，John Perry Barlow 在其著名的《网络空间独立宣言（Declaration of the Independence of Cyberspace）》一书中将迅速繁盛的网络世界描述成受到用户间形成的社会合约监管的世界。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;未知领域&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能系统不只是需要一些监管，而是必须不能由——至少部分不由——人类提供，而是由新类型的人工智能系统提供——监管类型的人工智能系统。人工智能需要由人工智能监管。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一个原因是人工智能运行系统是学习系统。这些系统一经发布就会不断地收集数据，然后挖掘数据和经验用于改进自己的性能。这些人工智能系统可能因此偏离最初程序员设定的指令。但人类无力监控（更别说实时监控了）这些变化并决定它们是否合法或合乎道德。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第二，人工智能系统正变得高度不透明，对人类来说就是「黑箱」。来自加州大学伯克利分校信息学院的 Jenna Burrell 指出了算法变得不透明的三种方式：刻意的不透明，比如政府或者公司想在算法专利上保持机密；技术盲区，算法的复杂性和功能是否超出了公众的理解能力；应用规模，其中「机器学习」和/或一些不同的程序员实施了一个甚至对编程者自己而言都不透明的算法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;一项技术不管有多聪明，它都仍然是服务于人类的工具。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最终，人工智能指导的系统自主性增加——它们能「依靠自己」做出大量的决策。也就是说，这些器械能使用复杂的算法独立回应环境输入信息，它们甚至可能反抗最初程序员设定的指令。一个简单的例子就是自动紧急刹车系统，在感知到危险时没有人类输入的情况下就会停止汽车。消费者抱怨这里面有很多错误警报，突然刹车对其它汽车而言也是很危险的，而且这些刹车系统即使在司机想要转向的情况下也会强制汽车直行。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这些所有理由之下，人工智能监管系统是必须的。我们将它们称为人工智能卫士，对卫士的一个简单定义是「一个监管、保护、维持的人」。该定义很好地诠释了监管系统需要足够强大，因为它可能会抑制运行人工智能系统的创新和发展，但却是不可避免的。确实，人工智能的一个主要任务是在不久之后开发出这样的监管系统。我们现在描述下谁有责任开发这样的监管系统，又该向谁汇报成果，以及它们关乎到谁的价值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;不同类型的人工智能卫士质问者&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一家公司制造的无人机发生了一系列坠毁事故，另一家购买了数百个无人机的公司肯定想要找到造成坠毁的原因。他们是故意的吗（例如，是由反对使用无人机的工人造成的）？特定无人机品牌一些未知缺陷？作为无人机大脑的人工智能操作系统的缺陷？由于之前讨论的一些原因，没有人能提供一个准确回答。我们需要设计并部署一个质问者（interrogator）人工智能系统来回答该问题。近年来，多次事故表明我们需要这样的质问。2015 年，卡耐基梅隆大学和国际计算机科学研究中心的一组研究人员发现谷歌的算法更倾向于将高回报管理职位的广告展示给男性而非女性。谷歌解释说没有故意歧视，影响因素是广告商的喜好。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2014年，Facebook 开展一项未向用户公开的研究，Facebook 的算法会操纵用户的帖子，移除里面的「情感内容」从而评估用户朋友的反应。Facebook 后来对其未能通知用户而道歉。Twitter 近期删除了 12.5 万个账户，解释说这些里面的账户是连接到伊斯兰国（ISIS）的。如果这些公司的董事会或外部团体想要查证这些各类声明，他们需要一个人工智能监管系统。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;审计者（Auditor）&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：耶鲁生物伦理跨学科中心（ Yale's Interdisciplinary Center for Bioethics ）的一位学者 Wendell Wallach 指出，「在医院，APACHE 医疗系统帮助决定重症监护室病人最佳的治疗方案，特别是那些在死亡边缘的人。Wallach &amp;nbsp;指出，即使医生看起来有自主权，但在特定情况下反对机器的建议是非常难的 ，特别是在一个流行诉讼的社会里。」无疑，医院想要寻找做这样决定的审计，而且没有人工智能审计系统他们做不到这一点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;监管者（Monitor）&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：因为自动驾驶汽车被编程可以学习和改变，所以它们需要一个特定类型的人工智能卫士程序——一个人工智能监管者——来保证自动驾驶汽车的学习行为不会导致其违法，比如向老司机学习超速，并模仿其行为。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;执法者（Enforcer）&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：在少数情况下，人工智能卫士可能帮助实施一项法律或条规。例如，如果军事承包商的计算机反复被黑，人工智能执法者可能警示承包商需要加固其网络防护。如果这样的警示被忽略，人工智能执法者将会向承包商的客户警示，或者怀疑其是否清白。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;伦理机器人&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：人工智能的运行系统不仅必须要遵守法律，也一定要遵循社会的价值准则。如此一来自动驾驶汽车就需要被告知它们是应该在法律限制的速度内驾车，还是以最省油环保的方式驾车，又或者在车上有孩子的情况下保持在慢车道行驶。还有，如果它们「预见」车祸，是否应该叫醒后座的乘客。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;关于在何种情况下人工智能系统或许需要遵循道德，这里有几种建议。在之前发表的一篇文章中，我们发现让系统工具的每个用户输入他或她的伦理偏好是不现实的，而且借鉴社会持有的伦理同样是有问题的。我们建议则是利用伦理机器人（ethics bot）。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一个伦理机器人就是一个人工智能程序，它能分析数千条信息——不仅仅是网上公开可用的信息还包括从个人电脑中收集到的特定个人的行为，这些行为揭示了其道德偏好。然后用这些来指导人工智能的运作系统（个人使用的工具，比如无人驾驶汽车。）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;基本上，伦理机器人做的很多道德选择与人工智能程序深挖消费者的喜好和定向广告的行为类似。然而，在这个案例中，机器人被用来按照人类的价值观指导人类而不是一些营销公司（或政治竞选活动）拥有或操作的工具。例如，这样一个伦理机器人也许会在过去学习到的人类行为的基础上，引导某人的金融项目投资只针对有社会责任的公司（一般是公益项目），尤其是绿色企业，而且每年还向塞拉俱乐部（Sierra Club）捐款。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;简短来说，没有理由让数字世界变得几乎像非数字世界那样阶层分化。然而， 在确保人工智能运行系统的行为守法并观察拥有和操作它们的人的道德价值上，不断增长的人工智能领域已经超过了某种监管水平。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能卫士没有必要比它们所监管的系统更加智能。应该是这些监管卫士只需要有足够的能力和智能避免被它们监管的系统欺骗或破坏就行了。想象，例如家中的断路器：它远没有整个电路系统（和相关的电器）复杂，但是它非常可靠，能在紧急情况下让人类断掉电源。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能研究者可以按照这个思路从至少三个方向上开展工作。第一，他们可以尝试将我们的法律和价值观形式化，遵循一种类似于概述「损害」这个概念的方法。第二，研究者可以建立一个有标注的数据集，通过预想的结果找出道德和法律难题的标签，提供给机器学习算法。最后，研究者可以构建可以方便关掉开关的「掌控系统的人工智能」，就像是强化学习中的「Safely Interruptible Agents（安全可中断代理）」。我们的主要观点是：我们需要把人工智能卫士提上该领域的研究议程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;谁来防卫人工智能的卫士？&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个问题可以分为两个方面。一方面关涉谁来决定可以开动哪种人工智能监管系统来持续监测运行的系统。软件程序员会按照这些特殊技术的拥有者和用户的要求引进一些监视系统。例如，制造无人驾驶汽车的人和使用它们的人会想办法确保他们的汽车不会一直加速下去。这确实是个问题，因为自动驾驶汽车的运行系统——重申一遍，是学习系统——会注意到道路上的很多传统汽车都会违反限速。法院和执法部门会部署一些其他的人工智能监视系统。比如，为了确定谁或者什么该对事故负责，以及是否是有意的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从这个角度看，伦理机器人是独特的人工智能卫士。它们会注意用户的价值，而不是拥有者、程序员或者政府支持的那些人的价值。这里可以解释一下。社区有两套社会和道德价值观。一种包括社区拥有的价值观，这是特别重要的，因此这种价值观不会考虑个人的具体选择，要注意的是这些价值观是通过法律强制执行的，包括禁止谋杀、强奸、盗窃等。在人工智能世界，要注意这些是之前概述的各种人工智能卫士的主体。第二种价值观是社区拥有的同时给个人留有选择余地的价值观，包括是否捐赠器官、加入慈善机构、做志愿者等。这由道德机器人在人工智能世界中执行的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;问题来了，谁来看守这些卫士呢？人类应该持有关于人工智能操作和人工智能监视系统的角色和行动的最终话语权；事实上，所有这些系统都应该有一个开关。它们没有一个应该是完全拥有自主权的。最终，无论一种技术有多聪明，它仍然是为人类目的服务的工具。考虑到那些开发和使用这些技术的人对编程和使用负有责任，这些人应该作为人工智能的设计、运作和监督的最终权威。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;参考文献&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;1. Burrell, J. How the machine 'thinks': Understanding opacity in machine learning algorithms. *Big Data &amp;amp; Society 3, 1* (2016).&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;2. Etzioni, A. and Etzioni, O. AI assisted ethics. *Ethics and Information Technology 18*, 2 (2016), 149–156;http://bit.ly/28Yymx0&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;3. Kapnan, C. Auto-braking: A quantum leap for road safety. *The Telegraph*, (Aug. 14, 2012);http://bit.ly/2917jog.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;4. Limer, E. Automatic brakes are stopping for no good reason. *Popular Mechanics*, (June 19, 2015);http://bitly/28XVSxP.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;5. Mayer-Schönberger, V. and Cukier, K. *Big Data: A Revolution That Will Transform How We Live, Work, and Think.* 2014, 16–17.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;6. New algorithm lets autonomous robots divvy up assembly tasks on the fly. *Science Daily*, (May 27, 2015);http://bit.ly/1FFCIjX.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;7. Phelan, M. Automatic braking coming, but not all systems are equal. *Detroit Free Press*, (Jan. 1, 2016);http://on.freep.com/2917nnZ.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;8. Weld, D. and Etzioni, O. The First Law of Robotics (a call to arms). In *Proceedings of AAAI '94.* AAAI, 1994; http://bit.ly/292kpSK&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 30 Aug 2016 17:19:34 +0800</pubDate>
    </item>
  </channel>
</rss>
