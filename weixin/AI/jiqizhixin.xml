<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>机器之心</title>
    <link>http://www.iwgc.cn/list/670</link>
    <description>人与科技的美好关系</description>
    <item>
      <title>深度 | 雅虎开源首个色情图像检测深度学习解决方案</title>
      <link>http://www.iwgc.cn/link/2914329</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Yahoo!&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Jay Mahadeokar、Gerry Pesavento&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：Rick、李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;雅虎开源了一个进行色情图像检测的深度学习解决方案。据文章介绍，这可能是首个识别 NSFW 图像的开源模型。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;开源地址：https://github.com/yahoo/open_nsfw&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;自动识别一张对工作做来说并不适合/不保险的图像（Not Suitable/Safe For Work - NSFW）——包括暴力图像和成人图像——是研究者们几十年来一直在试图解决的重要问题。由于当下图像与用户生成的内容主宰了互联网，过滤 NSFW 图像成为网页应用和移动应用的一个重要组成部分。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;随着计算机视觉、改进的训练数据和深度学习算法的发展，计算机现在能够以更高的精度来自动分类 NSFW 图像内容。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;NSFW 素材的定义是主观的，而识别这些图像的任务并非没有价值。此外，在某一语境下使人反感的东西却可以适合于另一语境。为此，我们下文所描述的模型只侧重于一种 NSFW 内容：色情图像。NSFW 简笔图、漫画、文字、写实暴力图像或其他不当内容的识别解决方案不适用于此模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;据我们目前所知，还没有用以识别 NSFW 图像的开源模型或算法。秉承合作精神并怀揣推进这一努力的希望，我们发布了自己的深度学习模型，它能让开发者使用一个 NSFW 检测分类器来进行实验，同时向我们提供反馈以改善分类器的性能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们的通用 Caffe 深度神经网络模型（general purpose Caffe deep neural network model）以图像作为输入并输出一个概率（即一个介于 0 和 1 之间的数字），可用于检测和过滤 NSFW 图像。开发者可以针对具体使用情况来用这个概率过滤掉 ROC 曲线上低于某个适当阈值的图像，或用在搜索结果中进行图像排名。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicCYYBeS6htTRphzMKNPJbRZcreC3YkXs36WEOib25Oq1ZicFg9ubZqWLSA0ria45CPNrTm3oQ5wYMWg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;卷积神经网络架构和权衡&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;近年来，卷积神经网络已经在图像分类问题中取得了巨大成功。自 2012 年以来，新的卷积神经网络架构一直在不断改进标准 ImageNet 分类挑战的精度。一些主要突破包括了 AlexNet（2012）、GoogLeNet、VGG（2013）和残差网络（Residual Networks）（2015）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些网络在运行时间、内存需求和准确性方面有不同的权衡。运行时间和内存需求的主要指标是：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Flops 或连接——一个神经网络中的连接数量决定了向前传播过程之中的计算操作数量，这与图像识别时的网络运行时间成比例。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;参数——一个神经网络中的参数数量决定了加载网络所需的内存量。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;理想情况下，我们希望一个网络拥有最少的 flops 和最少的参数，而达到最大精度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;训练用于 NSFW 识别的深度网络&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们使用一个包含正（即 NSFW）图像和负（即 SFW-suitable/safe for work）图像的数据集来训练模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;由于数据属性的问题，我们没有发布训练图像或其他细节，但我们开源了可用于开发者独立进行分类的输出模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们使用 Caffe 深度学习库（Caffe deep learning library）和 CaffeOnSpark；后者是一个用于分布式学习的强大开源框架，令你可以在 Hadoop 和 Spark 模型训练集群中使用 Caffe 深度学习。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在训练过程中，图像被重新调整到 256x256 像素，水平翻转进行数据增强，并被随机裁剪为 224x224 像素，然后送入网络。在训练残差网络时，我们使用了 ResNet 论文中所描述的规模增大（scale augmentation）来避免过度拟合。我们评估各种架构来找到运行时间和精度之间的权衡。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;MS_CTC——这种架构是由微软限制时间成本的那篇论文提出。它在卷积层和全连接层相结合的速度和精度方面秒杀了 AlexNet。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Squeezenet——这种架构提出了 fire 模块——包含层挤压，然后扩大输入数据团。这有助于节省参数数量，使 Imagenet 的精度与 AlexNet 的一样好，尽管内存需求仅为 6MB。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;VGG——这种架构有 13 层卷积层和 3 层 FC 层。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;GoogLeNet——GoogLeNet 提出了 Inception 模块并拥有 20 个卷积层阶段。它还在中间层中使用 hanging loss functions 来解决深度网络中的梯度递减问题。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;ResNet——ResNet 使用快捷连接来解决梯度递减问题。我们使用了作者所发布的 50 层的残差网络。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;ResNet-thin——该模型是使用我们的 pynetbuilder 工具生成，并复制了残差网络论文中的 50 层网络（每层过滤器的半数）。你可以在这里（https://github.com/jay-mahadeokar/pynetbuilder/tree/master/models/imagenet）找到更多有关如何生成和训练模型的细节。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWicCYYBeS6htTRphzMKNPJbRIfekY6SgaWP3blrD8LauxnzYHulHyMZx20wFS4EjNZ1HwWdf7s5mKg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;不同架构之间的权衡：精度 vs（网络中的）flops 数量 vs（网络中的）参数数量。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;深度模型首次在 ImageNet 1000 类数据集上进行预训练。我们将每个网络的最后一层（FC1000）更换为 2 节点的全连接层。然后我们精调 NSFW 数据集中的权重。注意我们让与最后的 FC 层相乘的学习率是精调后的其他层的 5 倍。我们还调整了超参数（hyper parameters）（步长、基本学习率）以优化性能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们观察到，NSFW 分类任务的模型性能与 ImageNet 分类任务中的预训练模型性能有关，所以如果我们有一个更好的预训练模型，它将有助于精调分类任务。下面的图表显示了我们所提出的 NSFW 评估集合的相对性能。请注意，图中的假正率（FPR）和一个固定的假负率（FNR）所针对的是我们的评估数据，在这里作说明用。要用该模型进行 NSFW 过滤的话，我们建议你们使用自己的数据来绘制 ROC 曲线并挑选一个合适的阈值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWicCYYBeS6htTRphzMKNPJbRSH4GUZa09JUIVWHUT2HNSeIIoL3a4vgE2ER1v4xWmyGA7Sa0WqRYMQ/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;在 Imagenet 上的模型与在 NSFW 数据集上精调的模型的性能比较&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们发布了 thin ResNet 50 模型，因为它在准确度方面做了很好的折中，并且该模型在运行时间（CPU 上运行时间 &amp;lt; 0.5 秒）和内存（~ 23 MB）方面体量轻巧。请参阅我们的 Git 库来查看我们的模型指令和用法。我们鼓励开发者尝试将此模型用于 NSFW 过滤的情况。如有任何关于模型性能的问题或反馈，我们都会支持并尽快回复。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;结果可以通过在你的数据集上精调模型来改进。如果你改善了性能或者训练了一个使用不同架构的 NSFW 模型，我们都鼓励那么为模型贡献出力或将链接分享到我们的描述页面。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Sat, 01 Oct 2016 12:28:58 +0800</pubDate>
    </item>
    <item>
      <title>活动 | 这个十月，机器之心将带你开启北美人工智能之旅</title>
      <link>http://www.iwgc.cn/link/2914330</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;机器之心北美系列技术分享暨中国人工智能公司北美巡回招聘会&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;10 月 2 日-15 日，「机器之心北美系列技术分享暨中国人工智能公司北美巡回招聘会」即将开启，我们将和十余家优秀的人工智能公司走向北美多个城市和顶尖高校。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWicCYYBeS6htTRphzMKNPJbRv9XJRVia8tBJCoicUgbicnJicQDFqWmxibeoI9lFWCnfnmoMBFHEeITD8MA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这期间，我们也将会及时呈现最新的技术分享和现场报道。如果对我们的活动感兴趣，可以通过扫描如下二维码，我们的活动助手将协助大家进入相应的站点群。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWicCYYBeS6htTRphzMKNPJbRexVQHpibcx8d8ZpZqtCNzbibanmwNnGSlsZJfOCVfibpP0FZNEamx0FYQ/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本系列活动对北美地区的参与者免费，但因场地限制我们会控制参会人数，请提前报名预约。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;首站波士顿报名开启&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;波士顿站活动将于当地时间 10 月 2 日举行，报名已经开启，请添加上方的「机器之心小助手」进行报名。&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;strong&gt;波士顿站&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;演讲嘉宾：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;blockquote&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;KITT.AI 创始人姚旭晨；联合创始人陈果果&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;搜狗语音团队负责人兼首席科学家 陈伟（视频）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;图普科技创始人兼 CEO 李明强（视频）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;时间：&lt;/strong&gt;&lt;span&gt;EST：18:30-21:00，10月2日；北京时间：6:30-9:00，10月3日&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;地址：&lt;/strong&gt;&lt;span&gt;2 Amherst St, Cambridge, MA 02142&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;联合主办：&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;NECINA，MIT CSSA&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;多伦多站的活动嘉宾和报名也即将开始，机器之心将第一时间公布，敬请关注。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;若有其他人工智能公司对参与此次活动感兴趣，请联系 zhaoyunfeng@almosthuman.cn&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Sat, 01 Oct 2016 12:28:58 +0800</pubDate>
    </item>
    <item>
      <title>MXNet专栏 | 陈天奇：NNVM打造模块化深度学习系统</title>
      <link>http://www.iwgc.cn/link/2914331</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心专栏&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：陈天奇&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;本文是机器之心 MXNet 系列专栏的第一篇，作者是 MXNet 的打造者之一陈天奇。MXNet 专栏是机器之心之后将发表的系列文章，包括 MXNet 打造者的人物专访、技术博客等，敬请期待！&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是一个深度学习的大航海时代，不仅算法和应用日新月异，深度学习硬件发展势头也很迅猛。虽然目前主流硬件是 Nvidia GPU，但 Intel 也试图通过下一代 Xeon Phi 摇头赶上。而在用于汽车自动驾驶和智能硬件的低功耗深度学习硬件上，多家公司在同时发力。深度学习计算框架也是百花怒放，既有成名已久的 Torch 和 Caffe，也有一年前开源就名声大噪的 TensorFlow 和刚刚公开的 PaddlePaddle。我们 DMLC 小伙伴也在上面耕耘了好几年，从早期的 CXXNet, Minerva 和 Purine 到现在用户稳步增长的 MXNet，深刻的感受到了技术的变革。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们也一直在琢磨，我们需要什么样的技术和系统来更好的服务未来几年深度学习的发展。为了弄清这个问题，我们先来大胆预测下未来深度学习需要什么样的编程和计算环境。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然大家都说深度学习能火归功于数据量大和计算能力的提升，但我们觉得它能够在众多领域上快速铺开，更主要得益于它的灵活性。反过来看传统机器学习，每个算法都是针对特定的应用，例如 SVM 主要是对分类，输入一个定长向量得到一个类别标量。大家的发挥余地基本是在特征的抽取上。而深度学习则可以是更多样的输入和输入，例如任意维度的张量，甚至大小都是可以变化。同时模型设计上也很灵活，更宽？更深？空间还是时间？更加精巧的内部连接？从这一点上，深度学习其实是一种语言，我们通过它来描述对问题的理解。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个灵活性必然导致了深度学习框架前端用户接口的多样化。而且这个趋势肯定是越来越剧烈。因为随着进入这个领域的人越来越多，大家关注的应用各不相同，熟悉的编程语言又各不一样，所以很难会有一个统一的前端语言来满足这些要求。所以我们觉得深度学习的前端很有可能像编程语言那样，风潮涌动。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一方面，深度学习应用需要大量的计算，目前没有，甚至未来几年内也不会有单一的硬件架构解决所有需求。所以必然是根据场景选择不同的硬件。例如 GPU 适合模型训练，CPU 由于大量存在也经常用作云端模型预测，但很多厂商也开始走 FPGA 路线。ARM 主要用在手机等低功耗的场景上，但很可能很快就会被定制的 FPGA/ASIC 取代。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不同硬件需要不同的优化。例如 GPU 计算单元多，需要算法并行度高，而 ARM 通常内存小而且结构复杂，需要重点优化。而定制化硬件则有更多的特殊打开方式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以在前端和后端都在快速发展的今天，要求每一个前端都对每个硬件做更好的支持明显是不能可持续发展的。所以我们要更好的解决方案。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;幸运的是历史总是在重复。如果我们往回看，会发现我们曾面临一样的问题。当年编程语言层出不穷，CPU 架构也不断翻新，于是大名鼎鼎的 LLVM 横空出世，通过很好的模块化分离前后端，为新语言和新硬件提供和非常好的支持。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于深度学习，我们需要类似的项目。学习 LLVM 的思想，我们将其取名 NNVM。他的工作原理如下所示：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9ibicGpNCBjqeDIoXuzlnTBl96xpsHMBZh8Tc2Jb5QzpNzkQZStK8tfKicgvOzXOQ8WAW0xhHUrwiadw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;示意图&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;前端把计算表达成一个中间形式，通常我们称之为计算图，NNVM 则统一的对图做必要的操作和优化，然后再生成后端硬件代码。简单地说, NNVM 是一个神经网络的比较高级的中间表示模块，它包含了图的表示以及执行无关的各种优化（例如内存分配，数据类型和形状的推导）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;设计这样一个模块最困难的地方并不是加入新的功能，而是可以在支持新的功能的情况下保持最小的接口，零依赖但是可以扩展未来可能可以想要的各种需求。我们总结了主流的深度学习框架 (TF, caffe2, MXNet) 的 operator 接口设计，设计了一个简洁但是扩展性极强的计算图结构和优化接口。利用这些模块，我们可以很容易地加入新的功能，或者删除我们不需要的功能来组合新的执行框架。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在第一阶段，我们通过把 MXNet 的符号执行模块转移到 NNVM，验证了接口的可靠性。未来我们会给 NNVM 加入更多的执行后端和优化。作为机器学习系统研究人员，我们也会基它来进行深度学习系统优化研究的探索。对于深度学习系统有兴趣的同学不妨一起来参与贡献代码。我们可以利用 NNVM 来很容易地为新的机器学习系统生成各种前端，并且复用通用的优化用以方便地实现各种后端。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前 NNVM 发布在 https://github.com/dmlc/nnvm。我们相信可以模块化各个部件，从而可以相互组装成满足各种需求的深度学习平台，使得更好的适应未来算法，应用，前端编程环境，后端硬件的高速发展。这是一个 开始，相信未来会有更多更加灵活，模块化和通用的组件出现，使得大家轻松打造深度学习平台不再是一个不可能的事情。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;不知道如何使用? 我们同时开放了一个两千行代码的样例项目，教你如何从头开始打造一个和 TensorFlow 一样 API 的深度学习系统 https://github.com/tqchen/tinyflow。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心经授权发布，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Sat, 01 Oct 2016 12:28:58 +0800</pubDate>
    </item>
    <item>
      <title>业界 | Google发布Open Images图像数据集，包含9百万标注图片</title>
      <link>http://www.iwgc.cn/link/2914332</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Google Research&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;最近，谷歌不断加大开源的力度。前天，&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719494&amp;amp;idx=1&amp;amp;sn=5c796cf9da81e6532750cea04667467c&amp;amp;chksm=871b0178b06c886e12aa5bc32a1cd9d585d4a2d624aab1c660e63ea619fd4c3aa8430ae8da0c&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719494&amp;amp;idx=1&amp;amp;sn=5c796cf9da81e6532750cea04667467c&amp;amp;chksm=871b0178b06c886e12aa5bc32a1cd9d585d4a2d624aab1c660e63ea619fd4c3aa8430ae8da0c&amp;amp;scene=21#wechat_redirect"&gt;谷歌发布YouTube-8M&lt;/a&gt;，这是单个GPU一天就能完成训练的一个最大视频数据集；昨天，&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719511&amp;amp;idx=3&amp;amp;sn=0674ef2a2e995d180ca081ed3a6ae1b9&amp;amp;chksm=871b0169b06c887feefc5604f1f53081e919eadec5c3d02c25d8da786de0bfa23141bd3f184e&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719511&amp;amp;idx=3&amp;amp;sn=0674ef2a2e995d180ca081ed3a6ae1b9&amp;amp;chksm=871b0169b06c887feefc5604f1f53081e919eadec5c3d02c25d8da786de0bfa23141bd3f184e&amp;amp;scene=21#wechat_redirect"&gt;谷歌开放了图像压缩模型&lt;/a&gt;，能高质量地将图像压缩得更小；今天，谷歌再次发布大规模图像数据集 Open Images。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;过去几年机器学习的发展使得计算机视觉有了快速的进步，系统能够自动描述图片，对共享的图片创造自然语言回应。其中大部分的进展都可归因于 ImageNet 、COCO（监督学习）以及 YFCC100M（无监督学习数据集） 这样的数据集的公开使用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今天，我们向公众介绍 Open Image，这是一个包含~900 万张图像 URL 的数据集，里面的图片通过标签注释被分为 6000 多类。我们试图让该数据集更为实用：该数据集中的标签要比 ImageNet（1000 类）包含更真实生活的实体存在，它足够让我们从头开始训练深度神经网络。&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;开源地址：https://github.com/openimages/dataset&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;使用谷歌云视觉 API 这样的视觉模型自动进行图像层次的注释已经变得很流行。在验证数据集上，我们有人类评定等级查证这些自动标签，并移除里面的假正例。平均而言，每个图像有大约 8 个标签。如以下示例：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicCYYBeS6htTRphzMKNPJbRelX2ovtCHict3zXUXWqH80icGnt0SsqSXibNGBmqt06LXoiaXia7Qg6XmJA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;来自 Open Images 数据集的带有注释的图片。左图：Kevin Krejci 的 Ghost Arches；右图：一些银器&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;仅基于 Open Images 注释，我们已经训练出了一个 Inception V3 模型，而且该模型被用于微调应用和其他事件时表现足够的好，比如用于 Deep Dream 或艺术风格迁移这样的需要较好层次结构的过滤器的任务。我们希望在接下来几个月能改进 Open Images 数据集中图像注释的质量，因此能改进训练的模型的质量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Sat, 01 Oct 2016 12:28:58 +0800</pubDate>
    </item>
    <item>
      <title>一周论文| 神经网络机器翻译下的字符级方法</title>
      <link>http://www.iwgc.cn/link/2914333</link>
      <description>&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;引&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;神经网络机器翻译(NMT)是seq2seq模型的典型应用，从2014年提出开始，其性能就接近于传统的基于词组的机器翻译方法，随后，研究人员不断改进seq2seq模型，包括引入注意力模型、使用外部记忆机制、使用半监督学习和修改训练准则等方法，在短短2年时间内使得NMT的性能超过了传统的基于词组的机器翻译方法。在27号谷歌宣布推出谷歌神经网络机器翻译系统，实现了NMT的首个商业化部署，使得NMT真正从高校实验室走向了实际应用。本期Paperweekly的主题是神经网络机器翻译下的字符级方法，主要用来解决NMT中的out-of-vocabulary词问题，分别是：&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1、A Character-Level Decoder without Explicit Segmentation for Neural Machine Translation，2016&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2、Achieving Open Vocabulary Neural Machine Translation with Hybrid Word-Character Models，2016&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3、Character-based Neural Machine Translation，Costa-Jussa, 2016&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4、Character-based Neural Machine Translation，Ling, 2016&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;5、Neural Machine Translation of Rare Words with Subword Units，2016&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;A Character-Level Decoder without Explicit Segmentation for Neural Machine Translation&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;1&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;作者&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Junyoung Chung, Kyunghyun Cho, Yoshua Bengio&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;单位&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Universite de Montreal&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;关键词&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Segmentation, Character-level, Bi-scale recurrent network&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;文章来源&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;ACL 2016&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;问题&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;能否在不需要分词的前提下直接在字符级进行神经机器翻译。&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;模型&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;在讲模型之前，本文花了大量篇幅论证为何需要在不分词的前提下进行字符级翻译，首先作者总结了词级翻译的缺点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;词级翻译的缺点包括：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1、任何一个语言都没有完美的分词算法，完美的分词算法应该能够将任意句子划分为lexemes和morphemes组成的序列&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2、导致的问题就是在词典中经常充斥着许多共享一个lexeme但有着不同morphology的词，比如run,runs,ran,running可能都存在于词典中，每个词都对应一个词向量，但是它们明显共享相同的lexeme——run&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3、存在unknown word问题和rare word问题，rare word问题是指某些词典中词在训练集中出现次数过少，导致无法训练得到很好的词向量；unknown word问题是指不在词典中的词被标记为UNK（OOV词）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;接着作者指出使用字符集翻译可以解决上述问题：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1、使用LSTM或GRU可以解决长时依赖问题&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2、使用字符级建模可以避免许多词态变形词出现在词典中&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然而上述字符级方法依然需要进行分词，然后对每个词的字符序列进行编码，因此引出了本文的motivation，即是否能直接在不分词的字符序列上进行翻译。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本文使用的模型同样是经典的seq2seq模型，其创新点主要在decoder端，引入了一种新的网络结构biscale RNN，来捕获字符和词两个timescale上的信息。具体来说，主要分为faster层和slower层，faster层的gated激活值取决于上一步的faster和slower层的激活值，faster层要想影响slower层，则必须要是faster层处理完当前数据，并且进行重置。换句话说，slower层无法接受faster层输入，直到faster层处理完其数据，因此比faster层要慢，而这样的层次结构也对应字符和词在timescale上的关系。下图为网络结构示意图。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a title="1-figure1" rel="gallery0" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnekfxYfFp7qEgOSnjdr3Wy2cw2RcyoK9Z5LnM9eJJw7oiabz4ViaNOU9PKVmz3XBesWsPtI9RFEoWw/640?wx_fmt=png"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在4种语言翻译任务上的实验显示完全可以在不分词的情况下进行字符级翻译，性能优于state-of-the-art的非神经翻译系统&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;相关工作&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Sennrich ACL2016提出使用BPE算法对subword建模。Kim AAAI2016中提出直接对字符进行encode，Costa-jussa ICLR2016中将该模型用在了NMT任务中。Ling ICLR2016的工作中使用Bi-RNN来编码字符序列。以上工作基于字符级展开，但它们都依赖于知道如何将字符分为词，即分词。本文研究能否在不分词的情况下进行字符级翻译。&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;简评&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;本文是Bengio组工作，Bi-scale RNN受启发于该组之前提出的GF-RNN，本文创新点主要是提出了一种新的RNN结构，可以在字符和词两个timescales上进行处理，输出字符序列不需要进行分词。不足是未考虑encoder端是否也可以直接使用未分词的字符序列，而是仅仅使用了分词后的BPE序列。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;span&gt;Achieving Open Vocabulary Neural Machine Translation with Hybrid Word-Character Models&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;2&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;作者&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Minh-Thang Luong and Christopher D. Manning&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;单位&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Stanford University&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;关键词&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;OOV, hybrid word-character models, NMT&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;文章来源&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;ACL 2016&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;问题&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;机器翻译里面的OOV问题, 如何处理UNK&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;模型&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;提出了一种混合word-character的NMT模型.在训练难度和复杂度不是很高的情况下,同时解决源语言和目标语言的OOV问题.&lt;br/&gt;&lt;/span&gt;&lt;a title="2-1" rel="gallery0" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnekfxYfFp7qEgOSnjdr3WyYET3Qko2GTpMpJBgLjt7WHriabA5vciaJydibZ05ictyLcYuzudU1Ec6zw/640?wx_fmt=png"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个图表达了模型的整体思路. 大多数情况下,模型在word-level进行translation. 当出现&amp;lt;unk&amp;gt;&lt;/span&gt;&lt;unk style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;的时候,则会启用character-level的模型. 对source&amp;nbsp;&amp;lt;unk&amp;gt;&lt;/span&gt;&lt;unk style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;, 由character-level模型来得到它的representation; 对target &amp;lt;unk&amp;gt;&amp;nbsp;&lt;/span&gt;&lt;unk style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;, 用character-level模型来产生word.&lt;/span&gt;&lt;/unk&gt;&lt;/unk&gt;&lt;/unk&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1、整体上采用他们组以前提出的基于global attention的encoder-decoder模型. RNN采用的是deep LSTM.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2、源语言端和目标语言端的character-level模型都是基于character的deep LSTM. 对源语言端来说, 它的character-level模型是context independent的. 隐层状态全部初始化为0, 因此在训练时可以预先计算mini-batch里的每一个rare word的representation. 而对于目标语言端来说, 它的character-level模型是context dependent的.它的第一层的hidden state要根据当前context来初始化, 其它部分都初始化为0.训练时, 在目标语言的decoder阶段, 首先用word-level的decoder产生句子, 这时句子里包含了一些&amp;lt;unk&amp;gt;&lt;/span&gt;&lt;span&gt;. 接着对这些&amp;lt;unk&amp;gt;&lt;/span&gt;&lt;unk style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;, 用character-level模型以batch mode来产生rare word.&lt;/span&gt;&lt;/unk&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3、对于目标语言端character-level模型的初始化问题, 作者提出了两种方法来表示当前的context. 一种叫做same-path, 用预测&amp;lt;unk&amp;gt;的softmax层之前的ht来表达. 但是因为ht是用来预测&amp;lt;unk&amp;gt;的, 所以所有ht的值都会比较相似,这样很难用来产生不同的目标rare word. 因此作者提出了第二种表达叫做separate-path, 用ht’来表达context. ht’不用预测&amp;lt;unk&amp;gt;, 是专门作为context在character-level的输入的. 它的计算方法和ht’相同,只是用了一个不一样的矩阵.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4、模型训练的目标函数是cross-entropy loss, 同时考虑了word level和character level的loss.&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;相关工作&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;NMT的模型分为word-level和character-level的. 对于word-level模型,要解决OOV问题, 之前的工作提出了unk replacement(Luong et al. 2015b), 使用大字典并在softmax时进行采样(Jean et al. 2015), 对unk进行Huffman编码(Chitnis et al. 2015)等方法. 而对于character-level的模型, 本身可以处理OOV词, 但是训练难度和复杂度会增加.&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;简评&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;本文的创新之处在于提出了混合word-character model的NMT模型. 这个混合模型结合了二者的优点, 在保证模型复杂度较低的同时,实现了很好的效果.因为加入了character, 特别适合单词有丰富变形的语言.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;span&gt;Character-based Neural Machine Translation&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;3&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;作者&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Marta R. Costa-jussa and Jose A. R. Fonollosa&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;单位&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;TALP Research Center, Universitat Politecnica de Catalunya, Barcelona&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;关键词&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;NMT，character-based word embeddings，CNN&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;文章来源&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;ICLR2016&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;问题&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;本文提出使用character-based word embeddings的NMT，可以在一定程度上克服机器翻译中OOV问题。&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;模型&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;a title="3-encoder_decode" rel="gallery0" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnekfxYfFp7qEgOSnjdr3WymIxIEiazRz0lib8ZIRcgS3zWuwL8ib8ZtfLwLJWn2x6MRortvtwtRhwCQ/640?wx_fmt=png"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如上图所示，这篇论文使用的基本模型架构是一个带attention机制的seq2seq的encoder-decoder的架构，使用的神经网络单元是GRU。encoder把源句子转化成一个向量（双向），使用attention的机制来捕获context信息，decoder把context解码成目标句子。网络的输入仍然使用word embedding，但是作者在获取word embedding的时候使用的方法不同。本文是基于词中的character来生成word embedding的，具体方法如下图所示。&lt;br/&gt;&lt;/span&gt;&lt;a title="3-embedding" rel="gallery0" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnekfxYfFp7qEgOSnjdr3WyQ86BuDUTpC3F6zJP51JIIYxUR9qLnIZq5rx4TibzcbQjKmgOA95NUtg/640?wx_fmt=png"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;上图中，最底层是一个character-based embedding组成的序列，对应的是每个词中的字母。然后这个序列被送入一个由不同长度的一维卷积过滤器组成的集合中进行处理，不同的长度对应单词中不同数量的字母（从1到7）。对于每个卷积过滤器，只取最大的值作为输出。然后把每个卷积过滤器输出的最大值连接起来组成一个向量。最后这个向量再通过两层Highway layer的处理作为最终的word embeddings。这个方法的详细信息可以参考Kim的论文&lt;/span&gt;&lt;a target="_blank" rel="external" style="text-decoration: underline; max-width: 100%; font-size: 14px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;Character-Aware Neural Language Models&lt;/span&gt;&lt;/a&gt;&lt;span&gt;(2016)。&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;资源&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;1、本文数据集[German-English WMT data] (&lt;/span&gt;&lt;a target="_blank" rel="external" style="text-decoration: underline; max-width: 100%; font-size: 14px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;http://www.statmt.org/wmt15/translation-task.html&lt;/span&gt;&lt;/a&gt;&lt;span&gt;)&amp;nbsp;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2、建立对比模型使用的软件包&lt;/span&gt;&lt;a target="_blank" rel="external" style="text-decoration: underline; max-width: 100%; font-size: 14px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;DL4MT&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;相关工作&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;1、2003年，基于短语的统计机器翻译模型。Statistical Phrase-Based Translation&amp;nbsp;&lt;br/&gt;2、2013年，基于神经网络的机器翻译模型。Recurrent continuous translation models&amp;nbsp;&lt;br/&gt;3、2014年，seq2seq的神经网络模型用于机器翻译。Sequence to sequence learning with neural networks&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;简评&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;本文作者将基于character来产生word embedding的方法应用于机器翻译，可以在一定程度上克服OOV的问题。同时，由于利用了单词内部的信息，这篇论文提出的方法对于词形变化丰富的语言的翻译也产生了更好的效果。但是，作者只是在source side使用了上述方法，对于target side，仍然面临词典大小的限制。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;span&gt;Character-based Neural Machine Translation&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;4&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;作者&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Wang Ling, Isabel Trancoso, Chris Dyer, Alan W Black&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;单位&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;1、LF Spoken Systems Lab,Instituto Superior Tecnico Lisbon, Portugal&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2、Language Technologies Institute, Carnegie Mellon University Pittsburga, PA 15213, USA&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;关键词&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;NMT, Character-Based&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;文章来源&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;ICLR 2016&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;问题&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;尝试在字符级别上应用神经机器学习方法&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;模型&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;在带注意力机制的神经机器学习模型的前后端增加字符到词（C2W)和词向量到字符（V2C）的模块。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a title="4-C2" rel="gallery0" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnekfxYfFp7qEgOSnjdr3Wyh8X9FicJK164GXVibA6sT2w5oZd4UZaNEZo03oTYlHWFtgQTTSaxe0Ng/640?wx_fmt=png"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图中，小矩形是一个双向LSTM，双向LSTM的前向和后向的最终状态以及bias之和为词的向量表示。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a title="4-V2" rel="gallery0" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnekfxYfFp7qEgOSnjdr3WyanesZGRKjDOObevUXzwdYdibCr4bEIEGkJjWPLLWV1TMDn8r1HiceI8w/640?wx_fmt=png"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个模块主要由三个步骤组成：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1、将字符转换为向量表示。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2、将字符向量和之前模型产生注意力向量的a和目标词在前向LSTM中产生的向量表示做拼接并输入到LSTM。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3、将得到的向量输入到softmax层得到结果。&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;相关工作&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;1、Neural machine translation by jointly learning to align and translate.&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;简评&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;这篇文章在基于注意力机制的机器翻译模型上增加了两个模块。由于是基于字符集别的模型，该模型自然可以学得一些语言中的前后缀在翻译中的关系。此外，基于字符级别的模型在翻译未知词时有灵活性。可是，文中也提到，该模型为能够准确的翻译未知词。并且该文也没有明确表明该模型和其他模型相比具有哪些明显的优势。从实际上来说，该模型在V2C部分的训练速度慢是一个很大的弱点，因此若仅根据文章的表述，该模型的实际应用价值应该有限。&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/h2&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;span&gt;Neural Machine Translation of Rare Words with Subword Units&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;5&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;作者&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Rico Sennrich and Barry Haddow and Alexandra Birch&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;单位&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;School of Informatics, University of Edinburgh&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;关键词&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;NMT, Rare Words, Subword Units, BPE&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;文章来源&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;ACL 2016&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;问题&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;NMT中的OOV（集外词）和罕见词（Rare Words）问题通常用back-off 词典的方式来解决，本文尝试用一种更简单有效的方式（Subword Units）来表示开放词表。&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;模型&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;本文从命名实体、同根词、外来语、组合词（罕见词有相当大比例是上述几种）的翻译策略中得到启发，认为把这些罕见词拆分为“子词单元”(subword units)的组合，可以有效的缓解NMT的OOV和罕见词翻译的问题。&lt;br/&gt;子词单元的拆分策略，则是借鉴了一种数据压缩算法：Byte Pair Encoding(BPE)(Gage,1994)算法。该算法的操作过程和示例如Figure1所示。&lt;br/&gt;&lt;/span&gt;&lt;a title="5-Fig1" rel="gallery0" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgnekfxYfFp7qEgOSnjdr3Wyn4xW7akEoHY7IO1icj2kD6JEFe3ybmOHezvOeWhZ88FeLnl4r2WTcibQ/640?wx_fmt=jpeg"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不同于(Chitnis and DeNero,2015)提出的霍夫曼编码，这里的压缩算法不是针对于词做变长编码，而是对于子词来操作。这样，即使是训练语料里未见过的新词，也可以通过子词的拼接来生成翻译。&lt;br/&gt;本文还探讨了BPE的两种编码方式：一种是源语言词汇和目标语言词汇分别编码，另一种是双语词汇联合编码。前者的优势是让词表和文本的表示更紧凑，后者则可以尽可能保证原文和译文的子词切分方式统一。从实验结果来看，在音译或简单复制较多的情形下（比如英德）翻译，联合编码的效果更佳。&lt;br/&gt;实验结果分别在WMT15英德和英俄的任务上得到1.1和1.3个BLEU值的提升。&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;资源&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;本文提出的子词拆分算法代码在&amp;nbsp;&lt;/span&gt;&lt;a target="_blank" rel="external" style="text-decoration: underline; max-width: 100%; font-size: 14px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;https://github.com/rsennrich/subword-nmt&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;span&gt;实验所用的NMT系统为Groundhog: github.com/sebastien-j/LV_groundhog&lt;br/&gt;实验数据来自WMT 2015&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;相关工作&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;OOV的处理一直是机器翻译研究的重点。&lt;br/&gt;基于字符的翻译在短语SMT模型中就已被提出，并在紧密相关的语种对上验证是成功的(Vilar et al., 2007; Tiedemann,2009; Neubig et al., 2012)。 此外还有各种形态素切分方法应用于短语模型，(Nießen and Ney,2000; Koehn and Knight, 2003; Virpioja et al.,2007; Stallard et al., 2012)。&lt;br/&gt;对于NMT，也有很多基于字符或形态素的方法用于生成定长连续词向量(Luong et al., 2013; Botha and Blunsom, 2014; Ling et al., 2015a; Kim et al., 2015)。与本文类似的一项工作 (Ling et al., 2015b)发现在基于词的方法上没有明显提升。其与本文的一个区别在于，attention机制仍然在词层级进行操作，而本文在子词层级上。&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span&gt;简评&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;这篇文章的创新点在于提出了一种介乎字符和单词之间，也不同于字符n-gram的文本表示单元，并借鉴BPE压缩算法，在词表大小和文本长度两个方面取得一个较为平衡的状态。应用在非同源/近源的语言对（如英汉）是否可以有类似的效果，尚待研究。在NMT模型的优化上，也还有探讨的空间。&lt;br/&gt;本文的实验评价方法值得学习，单看BLEU值并不觉得有惊艳之处，但加上CHR F3和(对所有词、罕见词和集外词分别统计的)unigram F1这两个评价指标，尤其是Figure2和3画出来的效果，还是让人比较信服的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;总结&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;OOV词对于翻译性能和实用性的影响非常巨大，如何处理OOV词并达到open vocabulary一直是NMT的主要研究方向。传统方法基于单词级别来处理该问题，比如使用UNK替换、扩大词典规模等方法，往往治标不治本。因此最近一些研究者提出基于字符的NMT模型，取得了不错的成绩，字符级方法的主要优势包括不受语言的形态变化、能预测出词典中未出现的单词并降低词典大小等。值得一提的是，基于字符的模型不仅局限于NMT上，任何生成模型都面临OOV词问题，因此是否能够将字符级方法用在其他NLP任务，比如阅读理解或文本摘要上，让我们拭目以待。&lt;/span&gt;&lt;span&gt;以上为本期Paperweekly的主要内容，感谢&lt;strong&gt;EdwardHux&lt;/strong&gt;、&lt;strong&gt;Mygod9&lt;/strong&gt;、&lt;strong&gt;Jaylee1992&lt;/strong&gt;、&lt;strong&gt;Susie&lt;/strong&gt;和&lt;strong&gt;AllenCai&lt;/strong&gt;五位同学的整理。&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;广告时间&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;PaperWeekly是一个分享知识和交流学问的民间组织，关注的领域是NLP的各个方向。如果你也经常读paper，也喜欢分享知识，也喜欢和大家一起讨论和学习的话，请速速来加入我们吧。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;微信公众号：&lt;strong&gt;PaperWeekly&lt;/strong&gt;&lt;/span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgkSMlEJFo90NY8rCXr3mJMBibduVHxMKSHzQtVkHz8kNwpjCKBiccGuqLE0WpPuAbdtEs6cTF5iabpAQ/640?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;微博账号：&lt;strong&gt;PaperWeekly&lt;/strong&gt;（&lt;/span&gt;&lt;a target="_blank" rel="external" style="color: rgb(64, 64, 64); text-decoration: underline; max-width: 100%; box-sizing: border-box; font-size: 14px; word-wrap: break-word !important;"&gt;http://weibo.com/u/2678093863&lt;/a&gt;&lt;span&gt;&amp;nbsp;）&lt;br/&gt;知乎专栏：&lt;strong&gt;PaperWeekly&lt;/strong&gt;（&lt;/span&gt;&lt;a target="_blank" rel="external" style="color: rgb(64, 64, 64); text-decoration: underline; max-width: 100%; box-sizing: border-box; font-size: 14px; word-wrap: break-word !important;"&gt;https://zhuanlan.zhihu.com/paperweekly&lt;/a&gt;&lt;span&gt;&amp;nbsp;）&lt;br/&gt;微信交流群：微信+ &lt;strong&gt;zhangjun168305&lt;/strong&gt;（请备注：加群 or 加入paperweekly）&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;</description>
      <pubDate>Sat, 01 Oct 2016 12:28:58 +0800</pubDate>
    </item>
    <item>
      <title>专访 | 谷歌神经网络翻译系统发布后，我们和Google Brain的工程师聊了聊</title>
      <link>http://www.iwgc.cn/link/2899977</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心原创&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;记者：老红&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt; 参与：吴攀、张俊、李亚洲、杜夏德&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;9 月 27 日，谷歌在 arXiv.org 上发表论文《Google`s Neural Machine Translation System: Bridging the Gap between Human and Machine Translation》介绍谷歌的神经网络翻译系统（GNMT）后，「机器之心」第一时间进行了详细的解读和报道，&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719470&amp;amp;idx=1&amp;amp;sn=3368dea980517ea7d7942967da2740dc&amp;amp;chksm=871b0090b06c89863620be4e75c757940d03d8a43cd3c1d9a8309b6594c1bccd769cab193177&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719470&amp;amp;idx=1&amp;amp;sn=3368dea980517ea7d7942967da2740dc&amp;amp;chksm=871b0090b06c89863620be4e75c757940d03d8a43cd3c1d9a8309b6594c1bccd769cab193177&amp;amp;scene=21#wechat_redirect"&gt;重磅 | 谷歌翻译整合神经网络：机器翻译实现颠覆性突破（附论文）&lt;/a&gt;。&lt;/span&gt;&lt;/em&gt;&lt;br/&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在最新报道发出后的第二天，「机器之心」受邀来到谷歌中国和来自 Google Brain 的软件工程师陈智峰聊了聊人机翻译、GNMT 和谷歌的技术创新等问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以下为采访对话，「机器之心」略有删改：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;机器之心：神经网络翻译系统（NMT）将整个输入的句子视作翻译的基本单元，相比于之前基于短语的翻译系统，除了所需的工程设计更少这个优点外，句子意思理解的精确度有多大的提升？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;陈智峰：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我们过去的方法有很多翻译出来给人看，会发现有很多错误。机器会给这些翻译结果打个分，而我们新的系统作出的翻译所得的分会很高。我们在翻译结果的正确率在一些分数上会提高大概 0.5 分到 1 分，这是非常巨大的进步。比如，刚才我的同事讨论在微信上最近有些人开始测试「小偷偷偷偷东西」这个句子，相比过去的模型，这个翻译会非常非常正确。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;机器之心：GNMT 有利用外部对准模型（External Alignment Model）对罕见词进行处理吗？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;陈智峰：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我们这个模型是没有 External Alignment Model 的，其他一些地方需要使用到外部对准模型来帮助神经网络模型来达到同样的效果，我们这个模型是不需要外面帮助的，整个训练和整个模型就是端对端的模型，它的迅速速度非常简单，你对照着中文句子，对照着英文句子就可以告诉我们，当中几乎没有任何其他的帮助就能够学习到这样的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;机器之心：那在罕见词的处理上是用了什么方法呢？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;陈智峰：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我们有两种方法，你可以把中文一个句子分成一个词一个词，比如说「我们今天见面」，你可以把它分成三个词，我们、今天、见面，你也可以把它分成六个字，传统的方法还有很多其他的类似系统里面大多数都是把它分成词来进行建模和训练的。英文也有同样的规律，比如说这个英文里是两个词，我们现在用的方法是把中文词全部打成字，然后把英文单词全部打成像词根一样的部分，比如说英文词语言、图像它的前缀都是一样的，所以说我们把这些前缀作为一个单元进行翻译，而不是像过去那样三个词分别翻译。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;机器之心：我们都知道人在阅读时有一种能力是可以忽略文字排序错乱的问题，机器面临这种情况如何像人类一样高效处理这些内容？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;陈智峰：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;不受顺序的影响我觉得是一个程度，比如说你随便打出一个中文的十个字的句子，你任意打乱的话很有可能是错误表达的，但如果你随机调整两个的话是可以跳过一些错误拼写出来的字。现在的模型也能做到，因为整个模型是统计模型，就是你看到前面几个字，然后猜下一个字是什么，有些字的可能性大一些，有些可能性低一点，也可能它会说下一个字就应该是一个空格，这样的话它就会跳过去。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们做过一些测试。中文里经常会有一些标点符号，比如前面是双引号，写了句子以后会发现最后忘了加引号，你可以很清楚地看到这个模型会意识到这个地方你是想写一个双引号的，但你没有写。这些现在都能在一定程度上避免这些错误。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;机器之心：你觉得 GNMT 在技术上的新突破以及未来的发展是否会完全取代人工翻译？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;陈智峰：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我觉得完全替换，或者说在任何情况下替换人的翻译还是有一定难度的。现在的机器翻译都是基于已经出现过的语言现象，但是整个人类不停地在发展，比如说网络上经常出现不同的新的语言现象，比如说有些短语、有些常用语，也是不停地在变化的。所以说机器是很难发明新的规则来表达你现在的意义，最终还是要靠人来创造出新的表达方式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;就是机器从人那边学习到怎么表达这个意思更加贴近时代，比如说同样一个英文词一百万，在英国和美国 20 年前是不一样的。还有对于同样的单词，如果是英国长大的人搬到美国，他会自己调整适应度。也就是说英语环境变化了，它的意思发生了微妙的变化，而你要让一个机器翻译的系统能够捕捉到这样细微的变化还是很难的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;机器之心：在结构化比较高的文章中，比如论文、科技文献上的处理是不是会更接近一些？可以取代一些？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;陈智峰：对，那些我觉得可能，比如说翻译一些医学的文章，就是这个领域非常非常固定的，有些很成文的规则表达的东西，我觉得将来会非常依赖于机器翻译来处理各个语言之间的信息交流，帮助会很大，而且精确度也会很快提高。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;机器之心：从你们一些产品的实验中，就是从更大的范围来看，您觉得有哪些领域是现在特别适合机器翻译来做，或者机器翻译的水平和人的水平最接近的？哪些领域是目前不太适合机器翻译来做的？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;陈智峰：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;比如说在时事新闻方面，因为很多时事新闻写作都是有套路的，比如说美国总统今天怎么样，中国国家主席怎么样，这些模式比较固定的情况机器翻译就能够做得比较好，而且读新闻的人不太注重时事新闻的写作文笔，更注重的是信息的传达，所以说在一些修辞方面或者情感的传达方面要求比较弱。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器翻译就能够很快地帮助你获得信息，这是主要机器翻译目前对人类的帮助。目前来讲我觉得在人与人之间的自然沟通上，机器翻译还是有很大的工作需要做，才能达到真正能够让你感觉到跟你说话的人是一个真的人，而不是一个机器，这还需要很多年的努力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;机器之心：在科幻小说《银河系漫游指南》里，有一个种叫「巴别鱼」的生物能实时翻译任何语言，你觉得 Google 实现这样的水平还需要多久？（也就是说在更高层次上与自然语言处理上，实现两种语言对话的实时翻译，预计这种情景能多久实现？中间有着什么样的技术难题？）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;陈智峰：很难预测，但我觉得从目前来看如果是要达到信息交互的过程还是很有可能的，但是要达到让你感觉是跟你家人说话的亲切感还是有很大的距离的，尤其是如果你要实时地和另一个人交互。我觉得现在要做到实时翻译还是有一些距离的，尤其是实时的语言翻译还是有一些距离的，但是三年五年可能会有一些突破。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;机器之心：除了在机器翻译上，你们现在在其他语言和产品（例如 Allo）上这项技术应用的进展如何？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;陈智峰：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;GNMT 是非常针对机器翻译这个产品做的，但是它的顶层研究，就是模型本身是非常广的，可以使用到很多领域里的，每一个产品都在这个基础模型上做一些开发的。举例来讲大家都有 iPhone，但是每个公司做的每个项目上的 APP 不一样。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;机器之心：现在 seq2seq+attention 的模型已经在 NMT 及其他众多 NLP 任务上取得了非常好的效果，本次发布的 paper 中提到用了更多层的网络得到了更好的效果，请问是否还可以不断地增加网络层数来提升效果？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;陈智峰：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;现在所谓你的层数增加，大家会普遍认为你的模型的能力就相对增强，但是在现有的技术条件下盲目地增加深度的话也有缺点。你的层次增加了，在应用时候的速度会变慢，因为它的计算量会增加，所以在现实当中都是有不同的考虑的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;机器之心：seq2seq+attention 的模型在效果方面是否达到了上限，从而需要更新的模型来解决问题？如果有的话，Google 最近在研究什么新的模型？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;陈智峰：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我觉得在机器翻译这个问题上，就是在基本的模型上还有很多扩展的余地，就是说你可以把这个模型变得更大，程序增加，它的模型架构是基本上一样的，但是在这方面你可以进一步推展。当然，这个领域变化很快，每年都会有不同的细分结构、模型结构出来，我们会不停地取长补短，就是有没有可能更快地提供更好的翻译服务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;机器之心：我有注意到现在移动版和网页版的 Google Translate 的汉英翻译已经在 100% 使用 GNMT 机器翻译了，为什么会率先在汉英 翻译上去应用呢？现在是有什么技术难点或者考虑吗？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;陈智峰：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;有两个基本考虑，第一个考虑是在所有的 Google Translate 领域中，中文翻英文和英文翻中文的确是很大的一部分。用户很多，这也是在很多翻译任务当中相对较难的一部分，因为这是两个非常不同的语言，所以从传统上来讲这是一个比较难的。另外一点，在整个项目开发过程中有很多中国同事参与，有很多能懂中文也能懂英文的人在第一个系统的时候可以帮助调试，这会有很大帮助，所以这是主要的考虑。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;机器之心：不同语言的语料规模差别很大，英文中的语料非常多，但中文语料就显得非常少。请问，能够将 NMT 的研究成果应用在不同语言语料构建上，从而提升其他语言 NLP 研究水平？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;陈智峰：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;其实中文语料也是很多的，在我们的数据库里中文语料是英文语料的一半，但是这两个语言的语料库中我们掌握的语料是非常非常巨大的，世界上有很多其他语言没有足够的数据，所以这也是一个研究难点，就是怎么通过其他的语言来帮助翻译一些小语种，也是我们正在努力的方向。因为 Google 不光是要服务英文、中文，它的目的是让世界上所有的国家、所有的人都能够获得同样的服务，所以说我们非常致力于全世界有 100 多种语言，我们希望这 100 多种语言我们都能够做到很快翻译。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;机器之心：刚才提到 Google Brain 和 Translate 这次的合作，我想知道在 GNMT 这次的技术研发包括产品的应用上，两个团队之间的分工是怎么样的？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;陈智峰：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我们主要是在初期建模的工作上做的工作比较多，在怎么使用最新的那些 GPU上，我们早期工作做的比较多。在 Google Translate 里面，他们负责很多怎么获得数据的工作，有些数据的有关情况需不需要调试，还有最后怎么把这个模型应用到产品里去，他们也做了巨大的工作，这是主要的工作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其实 Google 很多技术开发都是这个模式的，不同的团队之间都会有很强的合作，因为 Google Brain 更多的是一个注重于神经网络、人工智能方面研发的团队，而 Google Translate 主要负责的是翻译这个产品，当然他们也有研究团队。所以各个团队不同，他们花了很多的时间，那么多年，就是需要采集数据，比如说我们训练的时候可以完全用他们已有的训练数据，每个团队的目标不一样，但是合作非常流畅，没有任何问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;机器之心：你们的新论文描述了让 NMT 在非常大型的数据集上工作的许多挑战，你觉得当前最大的技术难点在哪里？在翻译速度和准确度的提高上你们又做了哪些创新？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;陈智峰：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;这个项目在三年前，也就是 2013、2014 年的时候 Google Brain 就想做了，当时从硬件和软件上都无法支持训练这个模型，在过去两三年中 Google Brain 开发了 TensorFlow，使得训练类似的模型可以充分利用分布式计算，利用很多很多不同的硬件类型。另外，如果你这两三年没有一些专门的硬件加速器的话也是很难在短时间内完成这个训练。而过去两三年 Google 在机器学习、在人工智能方面的巨大投入，使得类似的操作才变得可行。当然，我们也做了很多，对于具体的训练在我们现有的硬件资源上做了很多优化，这也是一方面的努力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;机器之心：您说这个短时间是短到什么程度？是多久训练一次？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;陈智峰：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;一般来说我们训练一个语言现在需要五天到六天的时间，差不多需要将近一百个 GPU 的加速器才能做完，差不多一星期才能处理一个方向的语言模型。但是 Google 有大概一万个语言的模型需要训练，当然我们有巨大的资源投入，也在不停地改进算法，所以说都在努力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;机器之心：这次我们这个系统昨天晚上的新闻发出来以后，很多人拿一些有趣的句子去测试，我想了解一下你们内部也有很多中国人，有这种有趣的句子测试它吗？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;陈智峰：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;上市之前我们每个同事都绞尽脑汁想出一些办法考考我们这个系统，大家都觉得不太容易考倒它，所以最后决定我们可以拿出来给用户用一下。当然，肯定不是一百分，但是我们还是相对满意的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因为 Google 以前有那么多年积累下来的难题，用户在使用Google翻译时，可能当时觉得翻译得不好，他们就会有记录，然后发给我们。我们会把那些东西放进新的系统看看这次做得好不好，比如说把中国的一些歌词拿出来放进去看看翻译出来的结果会不会比原来好，其实那种测试主要是防止它说出一些不太好的话。我们都做了很多测试，所以我们觉得还是有信心的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;机器之心：我昨天晚上做了一个测试，我输入中文「我要下班」，结果翻译成「I want to work」。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;陈智峰：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;哈哈，这个我们也有收到反馈并修复了这个问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心原创，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Fri, 30 Sep 2016 11:39:19 +0800</pubDate>
    </item>
    <item>
      <title>深度 | Kaggle创始人Quora问答：深度学习会淘汰其他的机器学习方法吗？</title>
      <link>http://www.iwgc.cn/link/2899978</link>
      <description>&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Quora&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：Leonardo Luke、杜夏德&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Kaggle 联合创始人兼 CTO Anthony Goldbloom 在 Quora 上公开回答问题，&lt;em style="color: rgb(136, 136, 136); text-align: justify; white-space: pre-wrap;"&gt;&lt;span&gt;内容涉及了 数据科学、Kaggle 入门方法等&lt;/span&gt;&lt;/em&gt;。机器之心整理了他回答的所有问题。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1.未来 5 年，数据科学将会发生什么变化？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这个问题上，我不打算谈太多数据前沿如何发展，而更多关注于数据科学逐渐成为主流变得无处不在。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在预测数据科学未来五年的发展时，回想其过去五年的进展大有裨益。2010 年 Kaggle 成立时，「数据科学」一词还不常见。我们社群的同僚们用其他的词汇来描述自己的工作，比如高级分析、统计学、机器学习、生物信息学、计量经济学或者其他和数据以及统计技术相关的专业之一。很多公司也用职能来称呼其负责数据相关工作的部门：市场分析、风险控制、包销、化学信息学等等。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2011 年 O`Reilly 的 Strata 大会让数据科学一词红了起来。会议聚集了一千五百名「数据科学家」，也让有着不同职称的人们有了根据他们的技能来称呼自己的方式。会议也让高级管理人员明白，不同部门的数据人员实际上有着同样的技能组合。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果说 O`Reilly 的 Strata 大会是棒球里面的第一局（注：棒球共 9 局），我认为现在我们正在进入第二局。现在很多的公司将他们的数据科学家整合成单个数据科学部门。最有效率的公司架构就是数据科学部门将其数据科学家分配给业务部门（市场、风险等等）。这种架构十分有效，因为数据科学部门会学习如何吸引和招募数据科学团队，同时也允许数据科学家和具体问题语境中的人一起工作。Airbnb 就是有效利用这种架构的公司之一。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;随着公司不断挖掘现存数据科学团队的价值，这些团队也会继续发展。最终，我认为中央的数据科学团队会消失，每个业务部门会有自己专门的大型数据科学团队。如果数据科学成为了公司中主要的决策工具，那么它就获得了成功——当需要作出决定时，管理层的第一反应是问「数据科学怎么说？」&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从另外一个角度回答这个问题的话，我认为在下一个十年，数据科学领域的规模会比软件工程更大。如果我们把使用 R 或者 Pythong 数据工具的人定义为数据科学家，目前大约有 150 至 300 万数据科学家（根据 Kaggle 的用户量 65 万 和 Jupyter 计划用户数约 300 万估算，目前全球软件工程师约有 2000 万）。同时，目前全球有约 800 万 SAS 用户和 1.2 亿 Excel 用户。我认为 SAS 会慢慢衰落，重度依赖 SAS 和 Excel 的工作都会转向 R 和 Python。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2.初学者如何在 Kaggle 上入门？&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Kaggle 对于喜欢边学边做（而不是通过读书或者看讲座）的人来说是一个非常好的入门方式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于喜欢从非常具体问题开始的人，我建议从四个「入门」竞赛（compeition）开始。我们最简单的竞赛是根据性别、舱位等级来预测谁能在泰坦尼克号事故中幸存。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你的电脑上还没有 Python 或者 R 的运行环境，我们为你准备了 Kernels 工具，这是一个在线的脚本编辑器，可以让你在不安装 R 或者 Python 的情况下运行代码（并且已经连接好了数据）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我建议从「fork」（程序员词汇，意为复制）别人的 Kernel 并进行编辑入手，而不是自己从头开始。如果你想从 Python 开始（我推荐），我建议用 Omar El Gabry 的 Kernel，这个 Kernel 是一个优秀的端到端的工作流程，从探索数据开始，到基本的机器学习模型结束。如果你喜欢 R，我推荐 Megan Risdal 的 Kernel。如果你还没准备好从 Python 或者 R 开始，我们准备了一个简单的 Excel 教程 (https://www.kaggle.com/c/titanic/details/getting-started-with-excel)。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你喜欢自由探索，或者就是不喜欢竞赛，我建议看一看我们的开源数据集 。这些数据集和竞赛没有关系，但通过共享代码和论坛讨论，他们依然对学习有所帮助。你可以从美国婴儿名字开始，这是一个简单、有趣的数据集，记录了过去一百多年以来美国婴儿起名的趋势变化。再说一遍，我建议从 fork 别人的 Kernel 开始，相比从空白屏幕上的一个光标开始，这样学习不那么困难。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3.哪些工具可以让数据科学家更有效率？&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们认为目前数据科学工具差不多和 15 年前软件工程的工具一样。现在做数据科学工作比 5 至 10 年之后要痛苦得多。目前，数据科学工作流程的共享和协作非常痛苦（甚至让其他人的分析在你的机器上运行都需要一些技巧），将机器学习模型用于生产也是一项挑战。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;实际上，我们正在开发一个叫做 Kaggle Kernels 的环境，致力于让数据科学工作流的共享、协作更加便捷（最适合的类比是给数据科学家的 Github）。有人用了 Kaggle Kernels 进行分析之后，你就可以 fork 他的分析（复制代码，Docker 容器以及数据连接）。这样你就可以立刻运行他们的分析，并可以迭代。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前，Kaggle Kernels 只对 Kaggle 竞赛和 Kaggle 上分享的开源数据集开放。明年年中，我们将会有商业化的产品，数据科学团队可以使用其进行团队内协作并分享结果。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;至于将模型投入生产，是大型的云服务提供商正在专注的领域（比如微软的 AzureML、亚马逊的 Amazon Machine Learning）。对于他们现存的计算和数据存储业务来说，这是顺其自然的扩展。目前还没有大型云服务商成功，但我预测在未来几个月至几年的时间我们会看到他们的进展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前，数据科学家需要将专用于工作流上不同细分领域的工具拼凑起来。Git 是控制代码版本的最佳选择。类似 RStudio 和 Sublime Text 这样的 IDE 可以让编程效率更高。呈现结果的工具有 Jupyter Notebooks 和 Shiny。Kaggle 之前使用 Make 来作为编制工具。我也听说一些公司使用 PMML 部署简单的模型，取得了成功。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;4.深度学习会淘汰其他的机器学习方法吗？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我不这么认为。我认为在一些场合中深度神经网络是最佳选择，而在其他的地方则需要其他的技术。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前，我们发现深度神经网络在一些无结构的数据竞赛中能够获胜（比如图像、视频、脑电图）。对图像和视频来说，卷积神经网络较好；对于脑电图数据和其他包含序列的数据来说，循环神经网络较好。对于结构化的数据问题，我们发现巧妙的特征工程结合梯度提升机器（特别是整合 XGBoost）获胜最多。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于自然语言处理问题，情况会复杂一些：有些时候需要循环神经网络，有些时候需要结合 XGBoost 的信息检索方法。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;深度神经网络的支持者说在数据集「足够大」时，深度神经网络就会超越其他方法。在 Kaggle 的竞赛中我们还没有发现能够佐证这一说法的证据。可能是因为我们的竞赛还没有「足够大」的数据。然而，即便足够大的数据会让深度神经网络显出优势，很多应用还是只有小、中规模的数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;作为相关方，我们在大部分的竞赛结束之后都会在我们的博客上对获胜者进行采访，问他们采用了什么方法。我们把这看作是记录有监督的机器学习问题中的优秀方法的「活日志」。我们也把所有获胜者的采访作为数据集发布在了 Kaggle 上，你可以使用 Kaggle Kernel 来发现机器学习的发展趋势，看出在哪些场合深度学习占优，哪些场合深度学习处于劣势（比如这个简单的 Kernel 就说明深度学习在在 Kaggle 竞赛中呈现上涨趋势）。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;5.Kaggle 如何盈利？&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前我们有两个主要的现金流来源于主持的竞赛和我们提供给的工作招聘版块。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们有三种比赛：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 特色比赛：公司可以利用这种比赛提升自己在数据科学社群的知名度，接触新的方法或者解决疑难杂症&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 招聘比赛：公司利用这种比赛吸引并招揽之前通过其他方式招募不到的人才&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3. 研究比赛：研究人员用把这种比赛作为与数据科学家协作的另一种方式。这对于非常具体且具有挑战性的问题大有裨益。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在未来，Kaggle 计划增加额外的服务。我们打算让 Kaggle Kernels 成为免费增值服务，付费后，公司可以将其用为数据科学团队的协作环境。在更远的未来，还有更多的有意义 d 附加服务（包括数据科学家咨询服务的市场）。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;6.招聘者在职位申请上看到 Kaggle 竞赛会怎么想？&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;公司用不同的方式使用 Kaggle 进行招聘。Facebook 和沃尔玛单独举办竞赛来招聘人才：他们会对竞赛中表现出色的人进行面试。Google DeepMind 这类的公司会关注我们的竞赛，并主动接洽表现出色的人才。我们了解到有些公司要求在工作申请中放上 Kaggle 资料链接。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们听说招聘方喜欢在简历中有 Kaggle 结果的数据科学家，因为这样显得应聘者对数据科学有一定的热情（即并不只是为了工资），也让招聘方了解到应聘者的能力如何。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们也了解到招聘方希望看到应聘者在竞赛之外的其他信息。就这一点，我们最近上线了开源数据平台，并对 Kaggle 资料进行了改版，以突显个人在优秀 Kernel 以及我们论坛上的贡献（在竞赛表现之外）。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;7.Kaggle 目前的重点是什么？&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Kaggle 目前的重点是从数据科学家业余项目的站点，变为数据科学家常用工作站点。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了完成这一点，我们正在着重发展 Kaggle Kernel，让其成为数据科学家共享和协作工作的地方。目前，数据科学家可以使用 Kaggle Kernel 来共享代码、竞赛结果和开源数据集。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;到明年年中，我们计划把 Kernel 向小型团队开放，让他们在团队内部使用。小型团队将可以使用 Kaggle Kernel 来 fork 同事的工作，或者从来自社群公开分享的庞大资源中选择并 fork。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;8.数据科学家最佳的协作方式是什么？&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前还没有好的解决方案。正如上面说到的一样，现在就连把一个人的分析放到另外一台机器上运行都是一个挑战（需要一样的数据，一样的语言版本，一样的库，有时候库的版本也需要一致）。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这也是我们在 Kaggle Kernel 上积极解决的问题。Kernel 整合了 Git（代码版本控制）、Docker（运行环境版本控制）以及数据连接。Kernel 可以用于竞赛协作和 Kaggle 上的开源数据集。目前 Kernel 还不对小团队开放。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前，小团队的高效协作方式之一是自己把这些技术整合起来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;9.Kaggle 竞赛和数据科学家的工作有多相似？&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Kaggle 竞赛涵盖了很多数据科学家的工作内容。缺少的两块内容是：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 把一个业务问题具体化为一个数据科学问题（包括提取数据，进行结构化，以解决业务问题）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 将模型投入产品&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Kaggle 竞赛间接帮助训练了数据科学家对问题进行结构化。竞赛让我们的社区了解到了大量的、精巧的结构问题。所以即便社区并没有直接参与，他们也会看到我们如何对不同问题进行结构化，并且将这些结构应用到解决实际的业务问题中。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们现在也有开源数据平台了，这样一来，社区可以更早地接触到问题。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前我们的社区很少有模型产品化的接触。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Fri, 30 Sep 2016 11:39:19 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 详解谷歌神经网络图像压缩技术：如何高质量地将图像压缩得更小</title>
      <link>http://www.iwgc.cn/link/2899979</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Google Research&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Nick Johnston 、David Minnen&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀、李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;谷歌 Research Blog 今日发布文章解读了其不久前在论文&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718466&amp;amp;idx=3&amp;amp;sn=ffeb503724abb0934c5c60e1202b12c0&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718466&amp;amp;idx=3&amp;amp;sn=ffeb503724abb0934c5c60e1202b12c0&amp;amp;scene=21#wechat_redirect"&gt;《Full Resolution Image Compression with Recurrent Neural Networks》&lt;/a&gt;中报告的神经网络图像压缩技术。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数据压缩已经在互联网上无处不在。你在网上看的视频、图片，听的音乐，甚至现在正在阅读的这篇文章的背后都有使用到数据压缩技术。压缩技术让我们可以更快更高效地分享内容。如果没有数据压缩，获取你需要的信息的时间和带宽成本将会高得吓死个人！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在论文《Full Resolution Image Compression with Recurrent Neural Networks》中，我们在我们之前的使用神经网络的数据压缩的研究上进行了延展，探索了机器学习是否能够像在图像识别和文本总结上一样提供更好的图像压缩结果。此外，我们也通过 TensorFlow 发布了我们的压缩模型，这样你也可以使用我们的网络实验压缩你自己的图像。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;发布地址：https://github.com/tensorflow/models/tree/master/compression&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们介绍了一种新架构——该架构使用了门控循环单元（Gated Recurrent Unit，一种允许单元保存激活和处理序列的 RNN）的一种新变体「残差门控循环单元（Residual GRU: Residual Gated Recurrent Unit）」。我们的 Residual GRU 将已有的 GRU 和论文《Deep Residual Learning for Image Recognition》中介绍的残差连接（residual connections）结合了起来，从而在给定的压缩率下实现了显著的图像质量增益。我们没有和今天所用的许多压缩方法一样使用 DCT 来生成新的位表示（bit representation），而是训练了两组神经网络——一组用于创造图像的编码（编码器（encoder）），另一组用于从这些编码中创造图像（解码器（decoder））。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们的系统可以迭代式地细化原始图像的重建，其中的编码器和解码器都使用了 Residual GRU 层，这使得更多的信息可以从一次迭代传递到下一次迭代。每一次迭代都会给编码增加更多比特，从而可以实现更高质量的重建。从概念上讲，该网络的工作方式如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 初始残差 R[0] 对应于原始图像 I ：R[0]=I&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 第一次迭代，设 i=1&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3. 第 [i] 次迭代以 R[i-1] 作为输入，并运行编码器和二值化器（binarizer）将该图像压缩成 B[i]&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4. 第 [i] 次迭代在 B[i] 上运行解码器以生成一个重建出的图像 P[i]&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;5. 计算出第 [i] 次迭代的残差：R[i] = I - P[i]&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;6. 设 i=i+1，然后转到第 3 步（直到达到所需的迭代次数）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;残差图像（residual image）表示了当前版本的压缩图像与原始图像之间的差异。然后该图像被用作该网络的输入，以便为压缩图像的下一个版本移除压缩误差。现在压缩图像被表示成了 B[1] 到 B[N] 的级联。对于更大的 N 值，解码器可在减少误差和生成更高质量的原始图像的重建上获得更多的信息。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了了解其工作方式，可以看一下下面这个图像压缩网络的前两次迭代的例子，如下图所示。我们从一张灯塔的图像开始。在该网络的第一次前向通过中，原始图像作为输入（R[0]=I）。P[1] 是重建的图像。原始图像和编码图像之间的差异是残差 R[1]，其表示了压缩过程中的误差。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9ibicGpNCBjqeDIoXuzlnTBl1ncctWPibxyMYem9piaQUNALribwwNrsuic4u6N8jUkrpm7ZyTAZPkYjnw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;左图：原始图像 I=R[0]；中图：重建的图像 P[1]；右图：残差 R[1]，其表示压缩中所产生的误差&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在该网络的第二次前向通过中，R[1] 作为该网络的输入（见下图），然后创造出一张更高质量的图像 P[2]。所以该系统是如何从残差 R[1] 中创造出一张如此高质量的图像（下面的中图 P[2]）的呢？因为该模型使用了带有记忆的循环节点（recurrent nodes with memory），所以该网络会保存每一次迭代的信息以便在下一次迭代中使用。它在第 [1] 次迭代中从原始图像上学到的东西被用在了对 R[1] 的处理上，从而可以从 B[2] 中生成更好的 P[2]。最后，通过从原始图像中减去 P[2]，该网络生成了一个新的残差 R[2]（右图）。这一次的残差更小，因为原始图像和重建的图像之间的差异更小了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9ibicGpNCBjqeDIoXuzlnTBllDk1bnTgvB0WpXO3oqLV2WPicAxsokQOvawP0eCUwJRibJPpjHH5RticA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;该网络的第二次前向通过。左图：用作输入的 R[1]；中图：更高质量的重建 P[2]；右图：原始图像减去 P[2] 所得到的更小的残差 R[2]&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在更进一步的每次迭代中，该网络都会获得更多有关压缩中所引入的误差的信息（这些信息可在残差图像中获取）。如果其可以使用这些信息来预测残差（即使只有一点点），那也能得到更好的重建。我们的模型可以使用额外的比特，直到达到收益递减的程度——此时该网络的表达力（representational power）就耗尽了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了验证文件大小和质量差异，我们使用了一种日本犬种 Vash 的一张照片生成了两张压缩图像：一张 JPEG，一张 Residual GRU。这两张图像的目标都是达到 0.9 MS-SSIM 的感知相似度（perceptual similarity）——该感知质量标准如果达到 1.0 则表示完全等同。我们训练好的模型所生成的图像的文件大小比 JPEG 小 25%。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9ibicGpNCBjqeDIoXuzlnTBlpRhlMus1xqL3xeFibOwibXahRk4ibibI4fl8OKg4nfLPvGgMW87265MINQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;em&gt;&lt;span&gt;左图：原始图片（1419 KB PNG）~1.0 MS-SSIM；中图：JPEG（33 KB）~0.9 MS-SSIM；右图：Residual GRU（24 KB）~0.9 MS-SSIM。图像质量差不多的情况下，图像大小减小了 25%。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;观察一下图中狗的鼻子和嘴巴，我们发现我们的方法在图像中不会产生红色块和噪声。这是由于 JPEG 产生的块效应（blocking artifacts），然而我们的压缩网络一次性地在整个图像上起作用。我们的模型会在细节上有所权衡，图像中的纹理会丢失，但在消除块效应上，该系统显示出了极大的潜力。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9ibicGpNCBjqeDIoXuzlnTBl1ibiaHF8E8RbUQ4DmcObjYBLUp5xnUaClckLhhdTClfjnubYd6MJia3ibw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;左图：原始图片；中图：JPEG；右图：Residual GRU&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然如今的编解码器表现很好，但我们的研究表明使用神经网络压缩图片能得到更高的质量和更小的文件大小。想要了解关于该研究的更多内容，可以阅读下面的论文：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;论文：Full Resolution Image Compression with Recurrent Neural Networks&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9ibicGpNCBjqeDIoXuzlnTBlytLqtJcJyIudRV0cbvwa2eE81IMFjxynU7qwQtiaaTODSwbgIRE2C2g/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;摘要：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本论文提出了一套基于神经网络的全分辨率有损图像压缩方法。这些我们所描述的每一种架构都可以在实施过程中提供可变的压缩率，而不需要对网络进行再训练（retraining）：每个网络只需要训练一次。我们所有的架构都由一个基于循环神经网络（RNN：recurrent neural network）的编码器和解码器、一个 binarizer 和一个用于熵编码（entropy coding）的神经网络构成。我们对 RNN 的类型（LSTM、关联 LSTM（associative LSTM）进行了比较，并引入了一种新的 GRU 和 ResNet 的混合结构。我们还研究了 one-shot 与附加重建架构（additive reconstruction architectures）的对比，并引入了一种新的扩展过的附加框架。对比之前的研究成果，我们的成果显示出了 4.3%-8.8% AUC（率失真曲线下的区域）提升，具体数字取决于所用的感知标准（perceptual metric）。就我们所知，在 Kodak 数据集图像的率失真曲线（rate-distortion curve）的大部分比特率的图像压缩上，这是第一个表现优于 JPEG 的神经网络架构，不管有没有熵编码的辅助。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9ibicGpNCBjqeDIoXuzlnTBlytT5xhqc4nfmECDRKLMxO1aHBtRqDkr0WIds4FUKRLyTmkDSKDbDeQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 1：我们共享的 RNN 架构的单次迭代&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Fri, 30 Sep 2016 11:39:19 +0800</pubDate>
    </item>
    <item>
      <title>专栏 | 超限学习机提出者黄广斌教授：生物脑与物理世界的相似性指出了机器学习的另一个方向</title>
      <link>http://www.iwgc.cn/link/2899980</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心中文首发&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;编译：Terrence、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;黄广斌教授最近被南洋理工大学授予了全职终身教授的头衔（编者注：在新加坡南洋理工大学每年只有1-2%的教师提升为正教授）。在最近的英文采访中（点击阅读原文查看英文原文），他愉快地分享了自己的背景，以及目前在新加坡南洋理工大学电子电气工程学院的一些经验和感受。采访中，黄教授提到三个主要机器学习趋势：1）机器学习和生物学习存在收敛趋势，也许几十年后有明显作用，我们已经感觉到脚步声；2）生物脑和物理世界存在惊人的相似性；3）机器学习和达尔文的进化论存在一致性。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;过去十五年在南洋理工大学的研究和教学生活是我最享受的一段时光，我非常珍惜和同事间的亲密友谊，过去这些年他们一直鼓励并支持着我。我们组成过许多临时的研究团队，我们共同的研究兴趣将我们联系在了一起。我非常敬佩身边的每一位同事和合作伙伴，他们的求知欲和探索欲深深地扎根在研究当中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我也特别感激南洋理工大学和南洋理工大学电子电气工程学院的管理层给予我们的在研究课题与兴趣方面的自由。这种灵活性对于成功的研究至关重要。伟大的研究思路从来不会在压力与紧迫的时限下诞生，它们产生于真正的兴趣。人工智能与机器学习（尤其是人工神经网络）领域近来非常的成功，也变得非常的流行。然而在 15 年前，很多人都怀疑神经网络是否真的有用。一些研究人员也开始撤离神经网络的研究领域。就好像整个世界都将精力花费在调整神经网络的参数上，从而导致缺乏明智的机器学习研究进展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我强烈地感觉到，一些具有挑战性的研究问题可能让神经网络研究社区陷入困境。这一点给了我很大的驱动力，让我想要在这些领域进行研究，因为我坚信我能够利用自己的跨学科研究和工程背景为这些研究做出自己的贡献。就这样，我决定离开制造业，怀着强烈的使命感和承诺加入南洋理工大学，感觉也许可以帮助机器学习社区尤其是神经网络研究社区从研究局限中走出来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一直以来和同事及研究伙伴们在不同的场合讨论不同的研究课题都是令人享受的。这些谈论将会在我的记忆中永存留鲜。有时我们会聚集在 NTU 的餐厅或者躲在 NTU 电子电气工程学院的某些角落里继续讨论，燃烧某些余热未尽的想法，这些时刻我永远不会忘记。我们一起努力研究这些想法并将它们应用于现实，这些想法及其成果在过去几年最终吸引了数以千计的研究人员采纳使用。它们或许在未来会成为关键的机器学习技术，闪亮耀眼——准确的说，是非常绚丽。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;黄教授着重谈及他早期的研究历程中难忘的时刻：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 2001 年加入 NTU 之后，我花费大部分的时间研究和琢磨两个问题：&lt;strong&gt;1）为什么大多数学习算法的学习效率很低？；2）为什么人脑比电脑更加智能和高效？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;起初并没有明确的答案，所以我开始认为从这个方向开展研究有些令人绝望。之后为了不至于让自己对研究感到太压抑，我开始沉浸阅读文学作品中，这段时间虽然短暂但重振了我失落的精神。我开始阅读经典文献，从头到尾把四大名著中的《三国演义》读了好几遍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其中有一段奇特的经历。在 2002 年的某个午夜，我第七次阅读这本名著。脑中满是书中独特鲜活的人物性格，我突然意识到，过去的数百万年产生了数万亿人类和动物，每一个人或动物都有不同的大脑，却很难在这么多的大脑中安装用于不同的应用和任务的不同学习算法。我想之后可能会出现一些通用的学习算法，可以安装在这数万亿个不同的大脑中，用于不同的应用和任务，而大脑中的这些算法都应该和数据和应用相互独立无关的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我马上给我的学生打电话，让他来实验室，就在当天凌晨我们测试了我们的 data-independent 算法。然后我最终将该算法命名为超限学习机（Extreme Learning Machines，ELM）。在那时，我们意识到我们可能已经发现了生物学学习机制的一些秘密，生物学习可以不依靠调整神经元来实现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;随机神经元和随机「连线」可能是实现「不依靠调整隐藏神经元来学习」这一学习机制的两种特殊方式。神经元也可以从它们的祖先那里遗传。整体来说，整个活跃的大脑都是结构化的、有序的，但它们在某一特定的层或者大脑神经元薄片上或许是「随机的」、「非结构化」的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;令我们感到惊讶的是，大脑作为宇宙中最复杂的物体之一，竟然和虽然整体结构化但是局部满是随机布朗运动的物理世界如此相似，二者之间竟然有如此强的相似性！生物学习正是因为其全局的结构化构造与局部的随机性的共存才能如此地完美。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;神经元与具体的训练数据无关。这一学习理论后来在 2013 年和 2015 年分别在老鼠和猴子的大脑中被发现。这一发现可能彻底颠覆了传统生物学习对于神经元调整可能是学习关键的认知。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这种新的学习理念与传统的神经网络学习原理完全不同。我们也希望与一些神经网络领域的前辈和先驱们讨论我们的想法，但几乎没有人愿意在最开始相信我们。在最开始从理论上证明它们也是一件难事。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于研究人员来说研究生活有时候很寂寞。但最终在 2005 年，我们觉得我们是正确的了，证明了我们理论中假设的正确性（在很多次错误的证明之后）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最终，理论上的证明在 2006 年正式公开发表。我感到比较自豪的是，我们在加入 NTU 的 5 年内的努力最终奠定了今后研究的基础。&lt;strong&gt;我们最终得到的学习技术比传统的学习技术快了将近一万倍，为实时的学习、认知和推理指明了方向。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;令人惊讶的是，尽管早期的一些机器学习领域的前辈们几乎不相信超限学习机的理论和技术，但是当我与大多数生物学家和神经学家讨论时发现，他们对于超限学习机的理论和技术是很容易接受的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器学习的研究人员通常遵循传统的机器学习和神经网络理论，认为学习智能只能基于精细的调整来实现。许多在一开始不相信超限学习机有效性的机器学习界的前辈们现在也开始转到超限学习机的研究领域中来了！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;自那以后，生物学家、神经科学家和人工神经网络专家展开了非常多有趣的讨论！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;超限学习机（ELM）成功和持续发展大都要归功于我的博士生们。和他们在一起的那些非正式的讨论启发了我们很多重要的想法。我过去常常请他们周末到家里，下厨给他们做点我拿手的菜，并且通过在周末打牌等不拘一格的形式来讨论一些至关重要的研究课题。有一次我们发现，正流行的机器学习技术——支持向量机（Support Vector Machines）——实际上提供了次优解。接下来我的研究人员和我花费了 6 个月的时间写了一篇关于支持向量机的论文——这篇论文成为了自那年开始发表的20多万IEEE 出版物中被引用得最多的一篇论文。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尽管我们一直专注于研究是希望能得到丰硕的成果，但现实并不总是尽如人意。&lt;strong&gt;我们相信超限学习机理论可以帮助解释达尔文主义的某些方面。&lt;/strong&gt;因此在 2014-2015 年我们决定来调查这一思想的分支。&lt;strong&gt;我认为：从祖先的神经元遗传到某些随机性（比如随机神经元和神经元之间的随机「连线」）在每一代都会给系统（甚至是那些生物体的系统）的进化和自然选择带来帮助。&lt;/strong&gt;然而，经过两年多的努力，由于缺乏可靠的大数据，我们暂时中止了这方面的工作——但是我们会在将来的某个时候在开始这方面的研究的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;黄教授也给出了他对于他当前所参与的电子电气工程相关项目的一些评价：「我以前在制造行业工作过，并喜欢它带给我的现实生活的那些实际操作的经验。话虽如此，我在 NTU 电子电气工程学院的研究经历也一样充实。我在这里的时候，我也一直主持负责一些由 BMW、Rolls Royce、Delta Electronics 和 ST Engineering 资助的和工业应用相关的研发项目。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;黄教授也对他全新的全职教授的职位充满了期待：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我很期待和我大学里的同事建立更密切的合作，并和其他世界顶级学府和公司的合作者们一起共事。总之，我相信，我们可以发现一些有效的解决方案，从而克服机器学习应用方面的一些具有挑战性的的瓶颈。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从长远来看，看到机器学习和生物学习不断靠近是令人兴奋的。&lt;strong&gt;超限学习机（ELM）可能会是弥补机器学习和生物学习间隔的基本「学习粒子」之一。&lt;/strong&gt;我希望我们能做出一些重要的贡献，来填补在机器学习、脑科学、智能材料以及智能传感器交叉研究的协同性方面的空白。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器学习在很多的实现成果中仍然是费力的和昂贵的。我们的目标是帮助研究界和工业领域走出机器学习研究的局限区域。在不久的将来，我们希望有一些有趣的机器学习解决方案能够：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1）用更小的数据来处理复杂的应用；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2）能够普适学习（pervasive learning）和普适智能（pervasive intelligence）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;帮助机器学习从工程学走向科学是十分有趣的。我相信「机器学习科学」最终将发挥重要作用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们也希望能成立一个公司并能稳步向前发展。我相信这家公司不仅会帮助将技术转换为实际的产品，同时也会给整个合作伙伴都带来益处。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;黄教授在 NTU 电子电气工程学院最喜欢的地方：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我最喜欢的地方包括员工休息室，以及校园内其它拥有舒适的沙发桌椅的角落，因为在那里我可以与同事和学生们关于研究想法开展头脑风暴——也可以自由地谈论我们对于研究和未来计划的梦想。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;闲暇时间的兴趣爱好：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我喜欢看电影，经常在家里和电影院看一些有趣的影片。新加坡的裕华园自然之美吸引我常去进行锻炼。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我有机会时也会经常和其他研究人员一起去爬山。在我们登山的过程中集思广益头脑风暴总是会令人享受并富有成效。当你呼吸着新鲜的山区空气的时候，你会为这些创造力感到惊叹。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;给学生和其他教师的一些建议：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;致我所有亲爱的 NTU 电子电气工程学院的教职工：我发现，除了教学和研究，我们的友谊是让我们作为教育工作者更加和谐、创新、高效和愉快的原因。NTU 电子电气工程学院一直是温暖的大家庭。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我只想说，我很珍惜我拥有的友谊，并期待和大家建立更紧密的合作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我亲爱的 NTU 电子电气工程学院的学生们：尤其是在这个机器学习和大数据的时代，有很多很多极佳的黄金机会正在向你们招手！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心首发，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Fri, 30 Sep 2016 11:39:19 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 硅谷安全教父加盟滴滴：AI将成未来信息安全关键</title>
      <link>http://www.iwgc.cn/link/2899981</link>
      <description>&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;9 月 29 日，滴滴出行今天宣布，硅谷知名信息安全科学家、AssureSec 联合创始人弓峰敏和卜峥加入滴滴。弓峰敏将担任滴滴信息安全战略副总裁和滴滴研究院副院长，卜峥将担任滴滴信息安全副总裁，全面负责滴滴信息安全的运营。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是滴滴在信息安全领域相关内容的首次重大披露。目前，全球信息安全市场正面临新挑战，同时也充满机遇。在两位重量级安全大佬加盟之后，滴滴很可能将尝试用人工智能和机器学习技术去发展信息安全技术。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;安全威胁日益严峻&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;作为 Palo Alto Networks 联合创始人及多家知名信息安全公司高管，弓峰敏指出，过去几年，信息安全威胁的发展很快。相对于安全防御者，黑客似乎总是可以更快地利用网络和移动技术去发动攻击，找到绕开防御的种种规避手段。另一方面，黑客工具的制造者、僵尸网络的运营者之间已形成了「高效」的信息分享产业链。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一系列事件证明了信息安全形势的严峻。例如，在 9 月 19 日的国家网络安全宣传周上，百度安全发布了《百度安全打击网络黑产白皮书》。白皮书显示，2016 年上半年，涉嫌泄露或窃取用户信息的事件超过 10.6 亿次，其中用户信息泄露超过 5.4 亿条，用户隐私窃取超过 6.3 亿次。与此同时，网络黑产的规模不断「壮大」。上半年，网络黑产从业者已达 56 万人，市场规模超过 1482 亿元，从业者人均收入 26.5 万元。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在美国，信息安全事故同样频发。2014 年，索尼影业遭遇了大规模信息安全攻击，损失至少达 1500 万美元。2013 年底，美国零售巨头塔吉特在数据泄露事件中丢失了 1. 8 亿用户的信用卡和其他个人信息。今年 9 月，雅虎也曝出了安全事故，5 亿帐号的信息被黑客窃取，引发了业内哗然。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这样的情况下，企业 IT 团队应对信息安全威胁的能力依然有限。以往，企业信息安全防护着眼于孤立的网络连接、数据存储和计算资源，通常只在安全威胁出现后才会被动地去响应。随着云计算和移动设备的普及，企业 IT 环境正变得日趋复杂。而物联网的发展，家电、汽车和工业设备纷纷接入网络则进一步导致了可能被黑客突破的「攻击面」不断扩大。换句话说，传统信息安全策略在新环境中很可能顾此失彼，难以实现整体式防御。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;策略：以业务为中心&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;弓峰敏指出，信息安全行业以往强调入侵防御，对攻击的应对策略是「拒敌于国门之外」。但实际上，近期出现了越来越多传统方法难以检测的高级安全威胁。同时，日趋多样化的安全威胁往往有着不同意图：一部分会对企业业务产生重大威胁，而另一部分则是黑客或业余爱好者的恶作剧。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9ibicGpNCBjqeDIoXuzlnTBlvxDMNSMWNtia6XQf2HMMdQ6FZuSejKttdJS8Z0pM2Ud8xicicrtlcbic5Q/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;滴滴信息安全战略副总裁弓峰敏&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以往，大多信息安全产品只关注安全问题的某个阶段或某个侧面，例如软件是否存在漏洞。然而，这些漏洞并不一定会给业务造成不利后果，例如数据丢失，交易信息泄露。企业并不需要去处理所有安全漏洞。如果继续沿用传统的信息安全策略，那么效果通常不佳，安全防御只能被动地跟随黑客的步伐。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于这样的局面，弓峰敏认为，安全防御重点应当转向以业务为中心，以不间断、大规模的监测为基础，并利用大数据和人工智能技术去判断是否有威胁和异常的出现。简而言之，这就是分布式的安全检测配合中心化的威胁数据分析。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;安全的未来：人工智能&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;传统上，企业信息安全团队需要在沙箱中运行恶意软件，人工分析，进而得出潜在威胁的属性，并在此基础上制定防御规则，将规则应用于安全网关或其他网管设备。这样的流程耗时耗力，且分析能力有限。在这种架构下，安全网关等设备对企业的信息安全能力至关重要。一旦安全网关被攻破，企业内部网络将门户洞开。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;与此不同，弓峰敏和卜峥团队的技术摆脱了中心化的安全网关。这一技术基于软件和虚拟配置，在终端设备中部署分布式「探针」，从而充分利用终端设备去收集潜在威胁信号，在威胁刚刚出现时捕捉其中的蛛丝马迹。与此同时，系统利用机器学习和人工智能技术，通过云计算平台沙箱对终端设备收集到的海量数据进行自动化分析和学习，不断寻找恶意软件和非恶意软件所表现出的不同模式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;用机器学习算法去取代传统的「if-else」逻辑带来了很强的通用性，能将数千输入信号考虑在内。与此同时，利用持续输入的数据，机器学习算法能以流程化方法不断建立新模型，并随恶意软件的变化而主动调整，增强检测能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这样做带来了两方面优势。一方面，系统对信息安全风险的监测将不再是孤立的，而是有能力全面了解各方面环境因素。因此，无论是底层硬件还是业务逻辑，各种异常都可以被检出。另一方面，这将成为基于云计算的一体化产品，并具备极强的自主运行能力。企业 IT 团队将无需去维护碎片化工具，减少所投入的人力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;滴滴助力信息安全研究&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;实际上，弓峰敏和卜峥团队加入滴滴正是由于，滴滴提供了团队迫切需要的大数据集。弓峰敏指出，其团队的技术要求与业务数据密切交互，而利用滴滴的框架和资源，团队能更方便地去展开技术研究。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9ibicGpNCBjqeDIoXuzlnTBlKl51kmoQmHJrFu7ACr2aicF8ADqcTPHRaeicSZ7Ec1R6VCYogz4ZCkpw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;滴滴信息安全副总裁卜峥&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一方面，滴滴也带来了丰富的安全场景。这既包括基本的安全攻防问题，也包括如何应对网络欺诈和犯罪，预防用户信息泄露，交易出现风险。通过滴滴的业务实践，以及滴滴自身对云计算、大数据和人工智能等前沿技术的开发，研发团队将获得第一手研究素材，使持续发展的新技术在第一时间得到尝试和应用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;信息安全市场仍在快速发展。根据市场研究公司 Gartner 的数据，2016 年全球信息安全产品和服务支出将达到 816 亿美元，同比增长 7.9%。这一市场正受到传统企业 IT 巨头的密切关注。例如，甲骨文上月宣布收购云计算信息安全公司 Palerra，而思科和赛门铁克近期也均在这一领域进行过收购。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在国内，移动互联网的发展也给信息安全带来了挑战和机遇。弓峰敏认为，作为具有代表性的移动互联网公司，滴滴在这笔收购后有望实现突破性的成功应用案例，进而给整个中国互联网安全市场产生积极影响。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心发布&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Fri, 30 Sep 2016 11:39:19 +0800</pubDate>
    </item>
  </channel>
</rss>
