<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>机器之心</title>
    <link>http://www.iwgc.cn/list/670</link>
    <description>人与科技的美好关系</description>
    <item>
      <title>深度 | MIT开发新型神经网络训练技术，让模型决策不再黑箱(附论文)</title>
      <link>http://www.iwgc.cn/link/3277436</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自MIT&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：Terrence L、李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;来自MIT计算机与人工智能实验室的研究者设计了一种新的神经网络训练方法，利用这种方法训练过的神经网络不仅可以预测和分类还能给出决策理由。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最近几年，人工智能研究领域表现最好的系统都来自于神经网络，它能够寻找训练数据中的模式，产生有用的预测或分类。例如，神经网络经过训练可识别数字图像中的某些目标或者推断文本的主题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是神经网络是黑箱子。在训练之后，神经网络或许能非常好地分类数据，但即使其创建者也不知道为什么。通过可视化数据，有时有可能自动操作那些决定神经网络响应哪些视觉特性的实验。但是文本处理系统往往更加不透明。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在计算语言学会自然语言处理实证方法会议（Association for Computational Linguistics』 Conference on Empirical Methods in Natural Language Processing）上，MIT 计算机科学与人工智能实验室（CSAIL）的研究人员将提出一种新的训练神经网络的方法，使他们不仅提供预测和分类，而且为他们的决策提供理论依据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;MIT 电气工程和计算机科学研究生、论文第一作者 Tao Lei 说道：「在现实应用中，有时人们真的想知道为什么模型做出这种预测。医生不相信机器学习方法的一个主要原因是没有证据。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;MIT 电子工程与计算机科学系教授、Tao Lei 的论文导师 Regina Barzilay 补充说：「不仅仅是医学领域。在任何领域，错误预测的成本都是非常高的。你需要证明你为什么这样做。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;论文第三作者 Tommi Jaakkola 说，「这项工作还有更广泛的影响，你可能不想只是验证模型是以正确的方式进行预测；你可能还想对它应该做出的预测类型施加一些影响。外行人如何与一个复杂的、他们所不知道的算法训练出的模型进行交流？他们可能有能力告诉你做出特定预测的理由。在这个意义上，它打开了一种与模型交流的不同方式。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;虚拟大脑&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;神经网络的得名是因为它们大致模仿了大脑的结构。它们由大量的处理节点组成，像单个神经元一样只能进行非常简单的计算，但是在密集网络中彼此连接。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在被称为「深度学习」的方法中，训练数据被馈送到网络的输入节点，网络的输入节点对其进行修改（modify）并将其馈送到其它节点，其它节点修改并将其馈送到另外的节点，并重复该过程。然后存储在网络输出节点中的值与网络尝试学习的分类类别相关联——例如图像中的目标或文章的主题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在网络训练的过程中，由各个节点执行的操作被连续地修改，从而在整个训练样本集合上产生一致的良好结果。在过程结束时，编程网络的计算机科学家通常不知道节点的设置是什么。即使他们明白，也很难将低级信息转换回系统决策过程的可理解性描述。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在新论文中，Tao Lei、Barzilay 和 Jaakkola 专门描述了在文本数据上训练的神经网络。为了能够解释神经网络的决定，CSAIL 研究人员将网络分为两个模块。第一模块从训练数据中提取文本段，并且根据它们的长度和它们的相干性来对分段进行评分：分段越短，并且从连续单词串中提取的越多，其分数越高。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然后将由第一模块选择的文本段传递给执行预测或分类任务的第二模块。两个 模块一起训练，训练的目标是最大化所提取文本段的分数以及预测或分类的准确性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;研究人员测试他们的系统的数据集之一是来自用户评价不同啤酒的网站的一组评论。数据集包括评论的原始文本和相应的评级，评级使用五星级系统在三个属性上评定：色（appearance）、香（aroma）、味（palate）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该数据集对自然语言处理研究者有吸引力的原因是它也被手动注释过，指示评论中哪些句子对应于哪些分数。例如，评论可以包括八个或九个句子，并且注释可以突出显示指示啤酒的「大约半英寸厚的棕褐色泡沫」，「显著爱尔兰啤酒气味」和「缺乏碳酸化」等等。每个句子与不同的属性等级相关联。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;验证&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因此，数据集为 CSAIL 研究人员的系统提供了一个很好的测试。如果第一模块已经提取了这三个短语，并且第二模块将它们与正确的评级相关联，则系统已经识别了人类注释器所做的判断的相同基础。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在实验中，系统与人类对于色和香评级的一致性分别为 96％和 95％，对于更浑浊的味觉概念则是 80％。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在论文中，研究人员还报告了在自由形式技术问答的数据库上测试他们的系统，其中任务是确定给定问题是否之前就已经被回答。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在未发表的成果中，他们已经将该系统应用于数千份关于乳腺活检的病理报告，在那里它已经学会提取文本来为病理学家作解释以提供诊断基础。他们甚至使用它来分析乳房的 X 线照片，其中第一个模块提取图像的部分而不是文本的部分。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;东北大学计算机与信息科学助理教授 Byron Wallace 说：「现在关于深入学习有很多炒作，特别是用于自然语言处理的深度学习。」「但这些模型的一个很大缺点是，它们通常是黑箱。拥有一个不仅可以做出非常准确的预测，还可以告诉你为什么做这些预测的模型是一个非常重要的目标。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「实现这一目标后，我们在同一会议上会提交一份主旨相似的论文，」Wallace 补充说。「我当时不知道 Regina 正在做这个，实际上我认为她的更好。我们的方法在培训过程中，当有人告诉我们，例如，某个电影评论是非常积极的，我们假设他们会标记一个句子并给你理由。我们利用这种方式来训练深度学习模型去提取这些理由。但他们不做这个假设，所以他们的模型运行时没有使用带有标记的直接注释，这是一个非常好的方式。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;论文：Rationalizing Neural Predictions&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Ik2rVaj7QnMX8iavbkiaBj4oVJqFxefuKYEbJdV00AECicSeecFibiciasxwoRl99Fh6HcAZ8kicnALoLw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：没有根据（justification）的预测往往限制了其应用。作为补救，我们学习提取输入文本的碎片作为根据（或者说论据，rationales），裁剪出的文本要短却具有相干性，而且足够做出同样的预测。我们的方法是结合两个模块，也就是生成器和编码器，训练后的模块要很好的协同运行。生成器指定在文本段上的一组分布作为候选论据，然后将这堆论据输入编码器进行预测。论据不是在训练过程中给出的。该模型通过渴求论据而被正则化。除了手动注释的测试案例，我们在多方面情感分析上评估该方法。我们的方法以显著的优势超过了基于注意力的基线，我们也成功的在问题检索任务上解释了该方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Sat, 29 Oct 2016 11:11:23 +0800</pubDate>
    </item>
    <item>
      <title>机器之心x CMU | 360°VR摄影师：从内容分享中诞生的新职业</title>
      <link>http://www.iwgc.cn/link/3277437</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;机器之心原创&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;编辑：张晨卉 、Rita Chen&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「人们总是进去前好奇，出来后深信不疑」巴沃尔说。谷歌VR主管克莱·巴沃尔（Clay Bavor）将谷歌山景城总部一间普通的会议室改造成了专门的虚拟现实体验室，里面布置了各种音响、隔音材料和头戴设备。通过Value（半条命系列游戏的开发商）的VR设备，谷歌员工可以在这个房间里畅游太平洋，或是置身于演唱会现场。「对于谷歌来说，VR是一个有力的转折点。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谷歌推出Cardboard到现在的两年时间里，虚拟现实市场出现了一大批头戴设备竞争产品。Facebook旗下的Oculus VR推出了人们期盼已久的Rift和Touch控制器，可以适配微软的Windows和Xbox平台；三星也推出了Gear VR，该设备是和Oculus合作开发的，由基于Android系统的Galaxy设备驱动。HTC推出了Vive，谷歌推出了搭配Pixel手机的Daydream view，就连索尼大热的PlayStation游戏主机也迎来了VR系统。相关产品相继涌现，虚拟现实日趋主流。德意志银行在年初的报告中将今天的虚拟现实比作2007年的智能手机，但同时也指出VR领域面临挑战：虚拟现实普及的关键并不在于硬件，而在于内容。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Ik2rVaj7QnMX8iavbkiaBj4hYcFUZWGH2azWc7cnNAQ4FbEDrsn1oX0YVbQ3JRIsibB6jjsQ7B1VpQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;于是，VisualPathy应运而生。位于纽约的初创公司VisualPathy是一个VR内容的分享平台与社交网络，帮助摄影爱好者发布管理分享360°视频/图片作品并互相交流，旨在将 VR 内容的创建者和 VR 内容的消费者连接起来，支持用户通过手机或PC浏览以360° 全景照片的模式抓拍下自己的生活记忆并一键分享，同时融入了很多社会化元素，包括好友关系的建立、回复、分享和收藏等互动设置，具有轻便，跨平台，易分享的特点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Ik2rVaj7QnMX8iavbkiaBj4LmSorFjWlTr42oiciaEyX7vmV2MCudVyLGHqCUEf5t3qAdp4TcHMia3lA/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器之心有幸采访到VisualPathy的联合创始人兼CEO潘洋Sean。VisualPathy创建的契机？虚拟现实何去何从？内容平台的发展模式？一起来看他会如何回答。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;hr&gt;&lt;h2&gt;&lt;/h2&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;采访嘉宾&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Ik2rVaj7QnMX8iavbkiaBj4iar8fT57VAF4WrBGETPiaoWS7Cj8Qmue47rd75DhUo0dcQxg6WJjx64w/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Synced：你好，能否简单的和机器之心的读者介绍一下自己以及你们的团队？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Sean：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;大家好，我叫潘洋，2015年初我创立了虚拟现实内容分享平台VisualPathy，总部位于美国纽约。VisualPathy的名字来自于Telepathy心灵感应，一个很美的词，我们希望通过我们的VR平台提供给大家一种很美妙的沉浸式体验。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;VisualPathy 现在的团队有10人左右，其中技术开发人员占7成。还包括另外3名合伙人：负责市场运营的Kenny Liao；纽约州立大学石溪分校计算机视觉博士温成峰，负责VR成像技术；负责VR内容生成工作的Mark Qu。此外我们的种子投资人 Joanna Wei魏乔，是北京创客空间联合创始人，还是美国奇点大学Global Solution Program项目学员。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8Ik2rVaj7QnMX8iavbkiaBj4m0BePMiao2tXFibmbpC3WcYoXjfAiaebChbSo0ArIZKLDjI6D3hf3Uahw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;VisualPathy 团队在TC Dusrupt上展出项目&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Synced：VisualPathy的理念是专注于还原活动现场的真实体验，具体提供的是怎样的产品呢？是什么样的契机让你开始做这方面的尝试呢？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Sean：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;VisualPathy的内容确实是还原现场真实体验，但是我们更关注的其实是人的需求，是摄影师和相关爱好者的需求，为他们提供一个作品分享交流的平台，是一个Showcase的属性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;开始做VisualPathy的契机在14年的一次科技见面会。在会场上当我要体验一款VR游戏时，现场调试占用了很多时间，做web出身的我当时就在想能不能用网页来展示VR，有没有更为简易的方式来展示VR内容。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;Synced：可不可以介绍一个VisualPathy 的一个工作流程？较之其他同类型的平台而言你们最大的不同是什么？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Sean：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;VisualPathy 软件的工作流程是很简单的，学习门槛很低，非常类似 Instagram 和Flickr。用户可以建立账户上传作品，也可以点赞留言发送消息等等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;同时有三个特点，使我们的软件不同于其他同类型的平台：第一，技术上采用插件式分享。我们提供的360VR播放器，可以支持通过链接全网分享，同时用户也可以把我们的播放器嵌入其它网站，共享重型高质量的VR内容；第二，品牌建设方面我们追求高品质内容。我们认为现阶段市场初期消费者对VR内容质量期待值并不高，积累高质量的VR内容在一定程度上会拖慢我们的发展速度，但是我们坚持高品质内容作为品牌方向，着力发展和专业VR摄影师的合作，目标市场放在相对小众高端的群体。第三，组合推出全方位VR360相关教程。虽然我们现阶段聚焦的是一个小群体，当下的VR摄影师和内容生成者人数并不多，但是潜在的VR爱好者有很多，所以我们推出了一个完全公开持续更新的VR主题博客，从概念、内容、拍摄技巧、相机选购、后期处理到商业推广，全角度对VR进行科普，引导爱好者入门，挖掘潜在用户。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8Ik2rVaj7QnMX8iavbkiaBj4m99ExrOkroA26NgWvnhpor5cbakX5PVI6fpwPW1u7ia6tXibia8kFHrzg/0?wx_fmt=jpeg"/&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;VisualPathy工作流程图&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Ik2rVaj7QnMX8iavbkiaBj4toViaH31kmnEbhXfw0POUR3rBiaDia0p06vJ0MEjSddUHulzwV1nqvGmw/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;VisualPathy 360/VR 播放器&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;Synced：从今年五月份完成天使轮融资到现在也差不多有半年的时间了，这半年来VisualPathy 的发展和现状大概是怎样的？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Sean：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;拿到天使轮融资之后，我们做的第一件事就是重新优化了产品。VisualPathy 面对的是摄影师设计师这样的用户，是一个对于产品设计非常严苛甚至挑剔的群体，所以我们聘请了新的团队成员进行UI设计和前端及数据库优化，可以说除了我们的内核 360VR 播放器之外，产品的其他部分都进行了重新设计。九月份VisualPathy 发布了app 的新版本，同时网站也进行了更新。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;同时，VisualPathy 在着力寻找更多和专业摄影师的合作机会。当下市场上其实并没有360VR 摄影师这样的行业，我们在自己定义360VR专业摄影师：他们拥有相关相机设备，懂摄影技术，且能够后期拼接修图。虽然市场上现在有能够360一次成像的相机设备，但是图片质量不高，我们需要的专业人才还是很少的。最近我们整理列出了全球1000名左右优秀的360VR摄影师，不仅在对话请求合作，同时还收集反馈优化产品，根据他们的需求调整产品开发方向。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8Ik2rVaj7QnMX8iavbkiaBj4B81oq6x6UicKlU4P8Yt24dyVSIzbhncjzRLxa8qerJIjhJJ09hlSzHw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此外，我们还在重点开发VR相关内容的博客。目前在Alexa系统内我们的全球排名达到了25万左右，活跃度达到了每个月几万人的访问量，对于一个垂直博客来说已经形成了一个品牌，也让我们看到了VR的市场潜力。我们把这些对VR内容感兴趣的访问者称为外围流量，通过博客的影响力建立可信度，我们相信通过博客教程这些访问者最终可以转化为我们的用户。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;Synced：无论是专业360VR摄影师，或者通过博客学习进行VR创作的爱好者，VisualPathy对于目标群体都会要求一定的技术门槛，那么现在市场上手机也可以拍摄全景，也有360拼接功能相机发布，对于普通的消费者而言，你们认为VisualPathy在用什么吸引用户？&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Sean：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我们的产品开发基于一种假设－－我们认为360VR能够成为继文字、图片、视频之后的第四种媒介。不久的将来，人们会愿意付费收看或付费创作360VR内容。我们看到了这样的需求和巨大的商业价值，我们愿意做长期的高质量内容积累，这样当VR普及的时候，我们是准备好了的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;Synced：可不可以分享一下接下来一年或者近几年的一个VisualPathy战略规划？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Sean：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;未来一年内，我们会重点发展已注册用户，使VisualPathy作为一种工具普及到位；随着VR技术的发展和商业市场需求的扩大，我们会转向高品质内容平台的战略，成为内容提供商。再之后的几年，我们会视市场发展状态，考虑配件和实体等方向。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;Synced：你认为VR会成为即智能手机之后的最主要的平台么？为什么？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Sean：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我觉得是有可能的。我个人认为现在VR有两个可实现的方向：一是摄影视频方面，生成门槛并不高，硬件支持到位；二是游戏方面，主要是一些大厂，比如Oculus和Sony，很大可能会出现杀手级应用。但是我认为这都是不是虚拟现实的最终幻想。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我心中的VR最终形态是一种交互方式。就好比智能手机的出现，其实是完成了两个变化，一个是移动互联网的出现，一个是改变了人与计算机的交互方式。VR可以改变的也是后者。运算能力的改变可能需要的是大数据、人工智能这些，交互方式我认为一定会向VR的方向发展。如果说人工智能是未来计算机的CPU的话，我觉得VR是未来计算机的屏幕、鼠标、键盘，是未来的输入输出设备。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmsns.qpic.cn/mmsns/KmXPKA19gW8Ik2rVaj7QnMX8iavbkiaBj4Fu5AXDTKwb7XVXicEERz0xw/0"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;Synced：现阶段的VR行业具体有哪些商业模式？你认为未来还会出现哪些可能的新模式？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Sean：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我认为看一个行业可以用从上到下看产业链的方法来分析。VisualPathy在VR产业链是应用层；应用层之下是内容生成者，通过内容交换盈利；再往下是内容解决方案，比如VR医疗手术、VR看房、VR体验店等。应用层向上看就是硬件的更新，包括相机、头盔、计算机等等；再往上就是底层算法的更新。每个环节都存在商业模式的机会。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8Ik2rVaj7QnMX8iavbkiaBj4CBuhQaoVia3YWFTpO2BzsxZXz8elhbNplRabexj4g83eN57Sc10QxvA/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8Ik2rVaj7QnMX8iavbkiaBj4cN4HLia6oBXkLrDmJIrBY7slyGHMQ8WSLHojsyLW34KDNW0vHWXu4Sg/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;Synced：调查反映人们对于VR可穿戴设备还存在很多适应性的问题，一个比较直接的就是大部分的VR产品长时间佩戴后人还是有视觉不适应或者大脑疲劳。你觉得这会成为影响VR 普及的一个障碍么？你怎么看待VR设备适应性的问题？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Sean：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我觉得讨论VR设备适应性，其实讨论的是两个需要改进并可以解决的问题：一个是延迟问题，这种延迟问题是由手机或者电脑的GPU决定的，可以依靠底层技术行业来解决；一个是分辨率问题，关乎屏幕的分辨率和内容质量两部分。现在很多设备屏幕比如Oculus的屏幕是1080p，而理想的屏幕显示需要达到4k，如果达不到人们在观看时就能够看到明显的颗粒感，严重影响体验，产生视觉不适应或者大脑疲劳。同时好的观看体验还要求除了设备屏幕的分辨率，内容的分辨率也需要提高达到4k，实现兼容，这也是我们VisualPathy运营方向从高质量内容切入的原因。而且我认为设备和底层算法，相比内容，是可以更快地得到解决的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;Synced：可是如果所有的内容都实现了高质量高分辨率，这会不会对平台的容量有更高的要求？会不会影响平台功能体验，比如上传加载等？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Sean：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;这确实是我们需要考虑的。Youtube 和 Vimeo 就是很好的两个例子：为了更大范围的收视群体，Youtube 在上传时内容会被自动调试到720p左右；而Vimeo上传时如果原始为4k，显示时就会为4k。我们要做的是后者。我们的VR图片平均每张16MB左右，VR视频可以达到1GB／min。现在我们已经进行了优化，具体过程是先压缩再分割成小的碎片，让用户在观看时不会有很明显的停顿。到以后内容很多的时候，高质量的内容会要求很高的服务器费用，我们会考虑做订阅服务，向上传者收取费用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;Synced：我相信 VisualPathy不仅是一个真实体验的平台，可能在未来也会成为一种生活方式。但这个平台上承载的内容却也是有双向的作用，这里面有很多值得讨论的社会道德规范的东西。索尼在它的PS4免责声明里多了一些有关它的内容，并特别强调： PlayStation VR 不能给 12 岁以下的孩子使用。VR对于正常生活的介入，这方面你有什么看法么？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Sean：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我认为VR会干预人们看待世界的视角和方式，尤其是当这样的体验非常真实时，一定会具有一定的迷惑性。所以关于VR和使用VR，需要有一个教育的过程，需要有引导类的材料或者组织来提供专业的建议。我们的博客也是这样一个教育的部分，但我相信以后会有更强大的专业组织，制定更完善的规则来规范 VR 的使用，比如说低于一定年龄的孩子不能使用 VR 内容，比如说每天的VR使用不能超过一定的时间等等。当人们都能够规范地使用 VR，甚至这些规则方式成为社会共识的时候，我觉得就没有问题了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;iframe class="video_iframe" data-vidtype="1" style="   z-index:1; " height="375" width="500" frameborder="0" data-src="https://v.qq.com/iframe/preview.html?vid=a0335wl2xkg&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0" allowfullscreen=""&gt;&lt;/iframe&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em style="color: rgb(136, 136, 136); text-align: justify;"&gt;&lt;strong&gt;&lt;span&gt;Synced：越来越多有强硬技术实力和背景的高校开设了VR课程和Seminar。你怎么看待高校的学术教育和工业界需求之间的关系？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Sean：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我和我接触的学术界有进行过讨论，发现他们更专注解决底层技术节点式的问题，比如说延迟、压缩等等。在工业界，有一些公司也在做底层技术节点式的问题，同时也有公司在现有技术的基础上进行更新，研究解决方案和发展商业应用，比如VR看房、VR旅游等等。两者不同主要就在一个偏向技术本身，一个更基于需求。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;Synced：听说明年四月的CMU 中美创新创业峰VisualPathy计划参加，会上专门的VR论坛版块也会参与讨论。就中美在VR领域的发展相比，有哪些异同？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Sean：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;在投融资方面中美在VR领域的发展并没有明显的偏差。当然我接触范围是有限的，但是我观察到的大家看待VR的方式是一致的。最初都有很多硬件项目，比如头盔、手势捕捉等；接着投资人都会先考虑底层技术节点问题和解决方案；现在逐渐开始关注商业应用层面的VR。从下到上，是一个行业布局的常见趋势。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不过我发现在线下体验方面中美VR领域有点不大一样。中国的VR体验店很多，美国线下体验反而是少的。我觉得这和市场结构有关，加上VR设备的普及程度不同。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8Ik2rVaj7QnMX8iavbkiaBj4IcnB7KpnLUATVics98aoFzTO8BQxH9vavrEKQcPabDUVTUhXenvq8sw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;Sycned: 采访最后是我们 Synced Talk 的固定快问快答环节。每一期我们都有固定的主题, 这一期的主题是 VR/AR， 三个问题：&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;1.虚拟现实( VR）和 增强现实( AR）技术能让我们足不出户就能看到听到另一个世界。如果你拥有这样一个穿戴设备，你会最想去哪里看到什么？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Sean&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：我最想通过VR／AR来和国内的家人朋友交流。因为现在离家比较远，我就会想利用VR在我家拍一个3D视频，感觉非常酷。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;2.随着虚拟现实(VR）和 增强现实( AR）技术的发展和成熟，你最担心它在哪个领域被滥用？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Sean：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我会担心未成年人对VR／AR的使用。比如儿童，他们对于真实世界的认知都没有建立完善，让他们来体验非常有真实感的虚拟现实，我会担心他们没有能力进行区分，所以我觉得VR／AR的使用需要更加规范化，制定年龄限制。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;3.虚拟现实（VR ) 给人呈现的是虚幻的快乐，而增强现实 (AR) 则是改变现实的态度。 如果要你选择，AR和VR 的世界，你会更倾向哪种生活状态？&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Sean：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我自己是做VR行业的，尽量客观来说，我觉得VR可以给我一种沉浸式的体验，比较偏向娱乐方面，我会想要每天有1个小时来畅游在虚幻的世界；而AR技术可以帮助提升工作效率和生活品质，比如说AR最典型的例子－GPS。一个是休闲，一个是工作，两者是不一样的方向，在我的生活中都需要。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;SYNCED = Science and You Now are ConnectED！&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人人都能回答，人人都能发问，这就是 Synced Talk。机器之心向所有人发问，让我们来聊一切和科学有关的事情，让科学入侵你的生活，让你思索周围的世界。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本期主题「虚拟现实和增强现实：真亦假时假亦真」三个问题：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1.虚拟现实(VR）和 增强现实( AR）技术能让我们足不出户就能看到听到另一个世界。如果你拥有这样一个穿戴设备，你会最想去哪里看到什么？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2.随着虚拟现实(VR）和 增强现实( AR）技术的发展和成熟，你最担心它在哪个领域被滥用？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3.虚拟现实（VR ) 给人呈现的是虚幻的快乐，而增强现实 (AR) 则是改变现实的态度。 如果要你选择，AR和VR 的世界，你会更倾向哪种生活状态？&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;欢迎留言加入畅聊，我们喜欢每一种想法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心原创，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Sat, 29 Oct 2016 11:11:23 +0800</pubDate>
    </item>
    <item>
      <title>资源 | 牛津大学公布自动驾驶研究成果，开放一千公里RobotCar数据集</title>
      <link>http://www.iwgc.cn/link/3277438</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自robotcar-dataset.robots&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李泽南、李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;牛津近日公布&lt;span&gt; RobotCar 自动驾驶数据集 &lt;/span&gt;，该数据集包含一年内英国牛津市内固定驾驶线路 100 次的重复驾驶数据。该数据集捕捉了许多不同的天气、交通、行人结合出来的路况，也包含建筑和道路施工这样的长期变化。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;数据集下载链接&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;：http://robotcar-dataset.robots.ox.ac.uk/#citation&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Ik2rVaj7QnMX8iavbkiaBj40ZMMCFzmHCsB7msQGEyfJAzKsZ0cbicjmKUa4fRVoW0sStBPIKecHbQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;数据集中不同位置的 3D 地图&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;自动驾驶汽车研究极其依靠大量高质量的真实数据，因其在公共道路部署前需要开发、测试并验证算法。但是，少有团队有能力开发并维持一个适用的自动驾驶平台，定期校准并收集新数据。在计算机视觉业内，目前已有一系列基于视觉的自动驾驶数据集，其中包括 KITTI 和 Citycapes 数据集。这些数据集主要用于算法研究，如在自动驾驶中进行运动估算，三维重建，行人车辆探测和语义分类。它们无法解决自动驾驶长期面临的挑战：同一地点在不同交通状况和环境下的情形，以及随时间变化不停改变的地图映射。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;牛津大学的研究人员推出了一个新的基准：牛津 RobotCar 数据集。这一数据集包含牛津大学从 2014 年 4 月到 2015 年 12 月间通过牛津 RobotCar 平台（使用日产 LEAF 自动驾驶汽车）平均每周在牛津市中心运行 10 公里路线产生的数据。总计约 1010 公里驾驶数据，同时包含超过 2000 万张由六台车载相机拍摄的图片，以及激光测距，GPS 和惯性导航收集的地貌资料，容量 23.15TB。在数据收集期间，车辆完全处于人工驾驶状态。这些数据中存在所有天气情况，包括雨雪，夜间，直射阳光。在数据集收集的一年时间里，车辆运行在同一区域，但这一地区的道路和建筑情况出现了很大改变。通过一年时间频繁地通行在同一路线中，研究人员可以探究在现实世界动态城市环境中自动驾驶车辆如何进行定位和地图映射。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Ik2rVaj7QnMX8iavbkiaBj4GhL5JrsE2wnK8h25DEoRa4ohDdkYdYTXialyWc5LIVQmzzdTw5ic1DGw/0?wx_fmt=png"/&gt;&lt;/span&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;数据集中不同天气条件下车辆的运行次数&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;牛津大学已将这一数据集和研究成果发布，可供下载。他们同时提供一组 MATLAB 开发工具，以便于访问和操作数据集。其功能包括加载和显示图像，激光测距扫描等简单功能。以及一些高级功能，包括从推扫式 2D 扫描生成 3D 点云，以及将 3D 点云投影到相机图像中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Sat, 29 Oct 2016 11:11:23 +0800</pubDate>
    </item>
    <item>
      <title>一周论文| 记忆网络及其变体模型</title>
      <link>http://www.iwgc.cn/link/3277439</link>
      <description>&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;Paper Weekly&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;微信公众号：paperweekly&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;/h1&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;引言&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;Memory Networks是由Facebook的Jason Weston等人提出的一个神经网络框架，通过引入长期记忆组件(long-term memory component)来解决神经网络长程记忆困难的问题。在此框架基础上，发展出许多Memory Networks的变体模型，本期精选了5篇Memory Networks相关的论文，分别如下：&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1、Memory Networks&lt;br/&gt;2、End-To-End Memory Networks&lt;br/&gt;3、Ask Me Anything: Dynamic Memory Networks for Natural Language Processing&lt;br/&gt;4、THE GOLDILOCKS PRINCIPLE: READING CHILDREN’S BOOKS WITH EXPLICIT MEMORY REPRESENTATIONS&lt;br/&gt;5、Key-Value Memory Networks for Directly Reading Documents&lt;/span&gt;&lt;/p&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;Memory Networks&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 10px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;作者&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Jason Weston, Sumit Chopra, Antoine Bordes&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 10px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;单位&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Facebook AI Research&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 10px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;关键词&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Question Answering, Memory Network&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 10px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;文章来源&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;ICLR 2015&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 10px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;问题&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;为解决长期记忆问题, 提出一类称为Memory Networks的模型框架, 基于该框架构造的模型可以拥有长期(大量)和易于读写的记忆。&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 10px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;模型和思路&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Memory Networks可以理解为一种构造模型的框架, 该类模型由如下五部分组成:&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1、记忆m: 模型记忆的表示,由一个记忆槽列表[m1-mi]组成,可被G,O组件读写&lt;br/&gt;2、组件I (input feature map): 将模型输入转化模型内部特征空间中特征表示&lt;br/&gt;3、组件G (generalization): 在模型获取新输入时更新记忆m，可以理解为记忆存储&lt;br/&gt;4、组件O (output feature map): 根据模型输入和记忆m输出对应于模型内部特征空间中特征表示，可以理解为读取记忆&lt;br/&gt;5、组件R(response): 将O组件输出的内部特征空间的表示转化为特定格式，比如文本。可以理解为把读取到抽象的记忆转化为具象的表示。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;假设模型输入为x:&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="max-width: 100%; color: rgb(62, 62, 62); font-size: 16px; white-space: normal; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;记忆的更新过程表示为 mH(x)&amp;nbsp;= G(mi, I(X), m), ∀i, H(x)为选择记忆和遗忘机制&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;记忆的读取过程表示为 r = R(O(I(x), m))&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;再次强调Memory Networks是一类模型框架, 组件I,G,R,O可以使用不同的实现&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 10px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;资源&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;ul class=" list-paddingleft-2" style="max-width: 100%; color: rgb(62, 62, 62); font-size: 16px; white-space: normal; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;facebook MemNN实现&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 10px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;简评&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;文章提出了一个通用的解决长期记忆问题的算法框架, 框架中的每一个模块都可以变更成新的实现, 可以根据不同的应用场景进行适配。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 10px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;End-To-End Memory Networks&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 10px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;作者&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston, Rob Fergus&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 10px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;单位&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Dept. of Computer Science Courant Institute, New York University&lt;br/&gt;Facebook AI Research&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 10px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;关键词&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Memory Networks, End-to-end, Question Answer&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 10px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;文章来源&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;NIPS 2015&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 10px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;问题&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;本文提出了一个可以端到端训练的Memory Networks，并且在训练阶段比原始的Memory Networks需要更少的监督信息。&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 10px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;模型&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;本文提出的模型包括单层和多层两种情况。下面先介绍单层情况。&lt;br/&gt;1、单层&lt;br/&gt;如图(a)所示，输入的序列可以通过不同的Embedding矩阵A和C分别被表示成Input和Output向量的集合。同样的，通过Embedding矩阵B，我们将Question表示成一个向量u，向量u和Input向量集合中的每个向量计算内积，然后通过softmax得到一个概率向量p（attention过程），概率向量p中的每一个概率值表示每个Output向量对应输出的权重大小。通过p和Output向量集合，对Output中的向量进行加权求和得到输出向量o，将输出向量o和问题向量u相加，再最后通过一个权值矩阵W和softmax来预测最终的label。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkaRn6tS3s8P7RN0LoDuQTdCrUFwh4Ygz6uahrYaUIJ2rOGicfZsiaUKJt4ayEVzjkz1TGIgcPvknBQ/0?"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2、 多层&lt;br/&gt;多层的情况如图(b)所示，每层的输出向量oi和问题向量ui相加获得新的问题表示ui+1，然后重复上述单层的过程,直到最后一层通过softmax来预测label。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本文在bAbi数据集、Penn Treebank以及Text8三个数据集上进行实验，均取得了较好的实验效果。&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 10px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;资源&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;ul class=" list-paddingleft-2" style="max-width: 100%; color: rgb(62, 62, 62); font-size: 16px; white-space: normal; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;[bAbi] (https://research.facebook.com/research/babi/)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 10px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;简评&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;本篇论文提出的模型是在Facebook提出的原始Memory networks基础上进行的改进。在Memory networks的框架下，将原来依赖于中间监督信息的非端到端Memory networks改进为端到端的Memory networks。基础模型之外，本文针对时序编码提出了一些有趣的trick，可作参考。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 10px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;Ask Me Anything: Dynamic Memory Networks for Natural Language Processing&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 10px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;作者&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Ankit Kumar, Ozan Irsoy, Peter Ondruska, Mohit Iyyer, James Bradbury, Ishaan Gulrajani, Victor Zhong, Romain Paulus, Richard Socher&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 10px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;单位&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;MetaMind&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 10px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;关键词&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Memory Networks, Neural Networks, Question Answering&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 10px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;来源&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;arXiv&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 10px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;问题&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Question Answering: 给定一段Context，一个与此Context相关的Question，利用模型生成一个单词的Answer。&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 10px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;模型&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;下图给出了dynamic memory networks的框架。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkaRn6tS3s8P7RN0LoDuQTdvmW0GUy3I04libc1Ny8fVdP5gs4asWQmFHHpqK3YJqk5zl9rfLzTLNw/0?"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先Context和Question都经过Gated Recurrent Unit(GRU)转换成成vector形式，分别作为episodic memories e和m储存下来。e代表的是一连串vectors，Context中每句话都会被转换成一个e vector，然而Question只会被转换成一个m vector。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下一步是episodic memory updates，在每一个episode, 每一个e vector会和m计算一个attention，本文中使用一个two layer feed forward neural network计算attention score。然后利用attention scores来update episodic memories。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkaRn6tS3s8P7RN0LoDuQTdBNymEIiaPQZMnHAob39yIloDFXEJaphqmGxXzibs3BZy07BlDLhY6BzA/0?"/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkaRn6tS3s8P7RN0LoDuQTdAICjD2uvct7J1SJcWWcrOqibbeccmic0nibiatF70yKHYNjVXolos6n0Uw/0?"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;输出答案也采用了一个GRU decoder&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkaRn6tS3s8P7RN0LoDuQTd5eG5jPDBibpz0liaqEZzcTlVoS74nU3ubjKALEB0jEGgoAiaX8jUq7jEg/0?"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这里的a0是最后一个memory state m。&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 10px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;简评&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;总体来说这是一篇很有趣的文章。其中应用了episodically update memory的想法，期望模型能够借此学到一些logical reasoning的能力。并且模型中多次用的GRU，每一层都使用GRU的encoding或者decoding，比较有趣。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然后我认为本文的写作有一些问题，比如我自始至终也没有找到e的下标究竟代表什么，我的理解是每一句话都被encode成一个e作为episodic memory，那么每次Update 其中一个e都要经过所有其他的e是为了更好的融合所有context sentences的信息吗？那么每一层的hidden states h究竟又是什么？上一层的hidden state如何更新到下一层？文章中似乎没有给出明确的公式，也没有在model figure中展示出来，似乎写作不够明确。既然e是有h穿过层层GRU得到，我会揣测下一层的h是上一层e的一个function。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 10px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;THE GOLDILOCKS PRINCIPLE: READING CHILDREN’S BOOKS WITH EXPLICIT MEMORY REPRESENTATIONS&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 10px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;作者&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Felix Hill, Antoine Bordes, Sumit Chopra &amp;amp; JasonWeston&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 10px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;单位&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Facebook AI Research&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 10px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;关键词&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Memory Networks,self-supervised training,window-based memories,The Children’s Book Test(CBT)&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 10px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;文章来源&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;ICLR2016&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 10px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;问题&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;本文对于语言模型（RNN/LSTM/Memory Network生成）到底能够多好或者在多大程度上表示The Children’s Book做了一项测试。测试结果表面Memor　Network上的效果最好。&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 10px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;模型&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;文中主要对比了一系列state-of-the-art的模型，每个用不同的方式对之前已经读过的文本进行编码，然后进行CBT评比。&lt;br/&gt;实验中使用的模型以及结果如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkaRn6tS3s8P7RN0LoDuQTdueWBHT810mCgEnyjnYU7RwTrFFldlricowFUBF7FvbGt80rKHkkCnHQ/640?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;CBT简介：数据来自Project Gutenburg所创建的数据集，里面的内容都选自儿童书籍。每20句话产生一个问题，让不同的语言模型去进行预测，看谁预测的效果更好。&lt;br/&gt;问题产生于20句话中的某一句话抠掉一个词A。候选集产生分为如下两步:&lt;br/&gt;1、从构成20句话的词表中随机选出和抠掉词A具有相同词性的词集合C 。&lt;br/&gt;2、从C中随机抽选10个词作为答案的备选集。&lt;br/&gt;实验最后在CNN QA的语料上进行测试，在新闻文章中识别命名实体，得到的准确率能到69.4%.&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 10px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;资源&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;ul class=" list-paddingleft-2" style="max-width: 100%; color: rgb(62, 62, 62); font-size: 16px; white-space: normal; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;n-gram language model:the KenLM toolkit (Scalable modified Kneser-Ney language model estimation.)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 10px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;简评&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;本文提供了一种测试语言模型效果的测试方法，这对于语言模型的评判做出了贡献。在做实验过程中，作者还发现在单层记忆表示中文本被编码的数量对结果有很大的影响：存在一个范围，使得单个词信息和整个句子的信息都得以较好的保留。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 10px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;Key-Value Memory Networks for Directly Reading Documents&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 10px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;作者&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Alexander H. Miller, Adam Fisch, Jesse Dodge, Amir-Hossein Karimi, Antoine Bordes, Jason Weston&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 10px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;单位&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Facebook AI Research&lt;br/&gt;Language Technologies Institute, Carnegie Mellon University&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 10px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;关键词&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Memory Networks, Key-Value, Question Answering, Knowledge Bases&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 10px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;文章来源&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;arXiv 2016&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 10px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;问题&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;鉴于知识库有知识稀疏、形式受限等问题，本文提出了一种可以通过直接读取文档来解决QA问题的新方法Key-Value Memory Networks。&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 10px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;模型&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;如下图所示，Key-Value Memory Networks(KV-MemNNs)模型结构与End-to-end Memory Networks(MemN2N)基本相同，区别之处在于KV-MemNNs的寻址（addressing）阶段和输出阶段采用不同的编码（key和value）。&lt;br/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本文主要提出了以下几种Key-value方法：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1、KB Triple&lt;br/&gt;针对知识库中的三元组(subject, relation, object),将subject和relation作为Key，object作为Value。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2、Sentence Level&lt;br/&gt;将文档分割成多个句子，每个句子即作为Key也作为Value，该方法与MemN2N相同。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3、Window Level&lt;br/&gt;以文档中每个实体词为中心开一个窗口，将整个窗口作为Key，中间的实体词作为Value。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4、Window + Center Encoding&lt;br/&gt;该方法与Window Level基本相同，区别之处在于中心实体词与窗口中的其他词采用不同的Embedding。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;5、Window + Titile&lt;br/&gt;很多情况下文章的题目可能包含答案，因此在上述提出的Window方法基础上，再添加如下Key-value对：Key为窗口，Value为文档对应的title。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本文为了比较使用知识库、信息抽取和直接采用维基百科文档方法之间的效果，构建了新的语料WIKIMOVIES。实验结果表明，KV-MemNNs直接从文档读取信息比信息抽取方法的效果好，却仍比直接利用知识库的方法差不少。其中几种Key-Value方法中，“Window + Center Encoding”方法效果最好。此外，本文还在WikiQA上进行实验，验证了KV-MemNNs的效果。&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 10px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;资源&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;ul class=" list-paddingleft-2" style="max-width: 100%; color: rgb(62, 62, 62); font-size: 16px; white-space: normal; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;[WikiQA](https://www.microsoft.com/en-us/download/details.aspx?id=52419)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;[WikiMovies](https://research.facebook.com/research/babi/)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 10px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;简评&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;本篇论文提出了一个在新的Memory Networks变体Key-Value Memory Networks，旨在探索在QA过程中，如何消除采用知识库和自由文本（维基百科）之间的效果差距（gap），并为此构建了一个新的数据集WikiMovies。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 10px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;总结&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;长程记忆（long-term memory）问题一直是深度学习中的一个难点，Attention机制就是解决这一问题的经典方法。本文介绍的几篇Memory Networks试图通过构建长期存储记忆组件来解决过去神经网络无法存储过长内容的问题。如何存储大量的外部信息以及如何利用这些外部信息推断是Memory Networks乃至很多NLP任务的难点。本期引入的这几篇论文中，Memory Networks提出了一个整体的框架，End-To-End Memory Networks使memory networks可以端到端的训练学习。Key-Value Memory Networks主要解决外部信息如何存储表示，而THE GOLDILOCKS PRINCIPLE这篇论文则在推理方面有所创新，直接利用attention的打分来预测答案。目前深度学习方法中，无论是存储更新长期记忆的方法还是结合长期记忆进行推理的方法都还很初级，仍需诸君努力前行。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以上为本期Paperweekly的主要内容，感谢&lt;span&gt;&lt;strong&gt;cain&lt;/strong&gt;&lt;/span&gt;、&lt;span&gt;&lt;strong&gt;destinwang&lt;/strong&gt;&lt;/span&gt;、&lt;span&gt;&lt;strong&gt;zeweichu&lt;/strong&gt;&lt;/span&gt;、&lt;span&gt;&lt;strong&gt;chunhualiu&lt;/strong&gt;&lt;/span&gt;等四位同学的整理。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;广告时间&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;PaperWeekly是一个分享知识和交流学问的学术组织，关注的领域是NLP的各个方向。如果你也经常读paper，也喜欢分享知识，也喜欢和大家一起讨论和学习的话，请速速来加入我们吧。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;微信公众号：PaperWeekly&lt;/span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgkSMlEJFo90NY8rCXr3mJMBibduVHxMKSHzQtVkHz8kNwpjCKBiccGuqLE0WpPuAbdtEs6cTF5iabpAQ/640?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;微博账号：PaperWeekly（&lt;/span&gt;&lt;a target="_blank" rel="external" style="max-width: 100%; font-size: 14px; box-sizing: border-box !important; word-wrap: break-word !important; text-decoration: underline;"&gt;&lt;span&gt;http://weibo.com/u/2678093863&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&amp;nbsp;）&lt;br/&gt;微信交流群：微信+ zhangjun168305（请备注：加群 or 加入paperweekly）&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;</description>
      <pubDate>Sat, 29 Oct 2016 11:11:23 +0800</pubDate>
    </item>
    <item>
      <title>深度 | 40年认知架构研究概览：实现通用人工智能的道路上我们走了多远？（附论文）</title>
      <link>http://www.iwgc.cn/link/3265307</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自arxiv.org&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：机器之心编辑部&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;今日，加拿大约克大学（York University）电气工程与计算机科学系在 arXiv 上发表了一篇关于认知架构研究的概览性论文，在感知、注意、学习和应用四个方面对认知架构方面的研究和应用进行了概述性的总结。机器之心对该论文进行了略有删减的编译，原论文可点击文末「阅读原文」下载。另外，作者还为本项目开发了直观的交互示意图，连同相关的额外资料可以在这里查看：&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;http://www.data.nvision2.eecs.yorku.ca/cognitive-architecture-survey/&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibsC7CE9mCiaYfYOVgk5GVGTPwDx8IonZxg8ia1QMqGo5pnibAws61icOpMjvunUib3ibbOvDceeZJtlxeg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;摘要&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这篇论文中，我们呈现了关于过去 40 年认知架构（cognitive architecture）研究的宏观概述。尽管目前已有架构的数量已经有数百种了，但绝大多数已有的调研都没有反映出这种增长，而只是重点强调了一小部分地位稳固的架构。虽然它们的贡献是不可否认的，但它们只能代表该领域研究的一部分。因此，在这篇调研中，我们将超越对重点的关注，而将我们的范围扩展成对认知架构研究的更具包容性和高层面的概述。我们最终的集合有 86 种架构，其中包括 55 种仍在活跃发展的架构，另外还从一些不同的学科（涵盖从心理分析学到神经科学等）中借用了一些。为了保证本论文长度合理，我们仅讨论了核心的认知能力，比如感知（perception）、注意机制（attention mechanism）、学习（learning）和记忆（memory）结构。为了评估认知架构的实际应用的广度，我们收集了超过 700 个使用了我们列表中的认知架构的实际项目的信息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们使用多种可视化工具重点突出了该领域发展的整体趋势。我们对实际应用的分析表明大部分架构都非常关注于一个特定的应用领域。因此，在机器人和计算机视觉领域的一般研究和在认知架构领域内的研究之间存在一个明显的鸿沟。可以非常明显地看到：生物启发的模型与基于工程原理和启发式的系统相比，在范围和效率上都不一样。我们观察到的另一个情况是合作的普遍缺乏。有几个因素妨碍了人们的交流沟通，比如许多项目封闭的本质（这里审查的架构中仅有三分之一是开源的）和术语差异。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;1 介绍&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本论文的目标是提供关于过去 40 年认知架构研究的宏观概述，并重点关注了感知、注意和实际应用。尽管认知架构领域一直以来都在稳健地增长，但过去 10 年来发表的大多数调研都没有反映出这种增长，而基本上只是关注了十几个最成熟的架构。上一次大规模的研究是在 2010 年由 Samsonovich et al. [1] 进行的，他们试图编目已经实现的认知架构。他们的调查包含了 54 种由它们各自的作者提交的认知架构。这些信息以「认知架构对比表」的形式发表到了网上（http://bicasociety.org/cogarch/architectures.htm）。当然，也还有其它认知架构的列表，但它们通常只是一个简短描述加上一个项目网址或软件库的链接而已。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;由于目前还没有详尽的认知架构列表，所以它们的准确数字还是未知的，但是据估计应该有大约 300 种左右，而且其中至少有三分之一的项目目前是活跃的。为了为我们的研究得到这份最初的列表，我们组合了其它调查（发表于最近 10 年内）中提及的架构以及一些大型的在线编目。我们还包含了这些调研文献未提及的最近的架构。图 1 展示了来自 17 个来源（调查、在线编目和谷歌学术）的 195 种认知架构的可视化。很明显可以看到 ACT-R、Soar, CLARION、ICARUS、EPIC、RCS 和 LIDA 等一小部分架构出现在了许多来源中，而所有其它项目只是在在线编目中有简短的提及。尽管这些主要架构的理论和实际贡献是不可否认的，但它们只能代表该领域研究的一小部分。因此，在这篇概述中，我们将避开对重量级架构的特别关注（其他人已经做了很多了），而是将对这整个领域进行一次高层面的概述。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibsC7CE9mCiaYfYOVgk5GVGTD7cvtOsLAuQZQNNmj5KQriaqVGkTiaHYyMicKak8mCNZqfAQNe8n1icicxQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 1. 来自调查、在线编目和谷歌学术的认知架构的组合列表。左侧的节点表示架构的调查和在线编目，右侧的节点表示单独的项目。节点的厚度表示连接到该节点的边（edge）的数量，即该架构出现的次数（右侧）或所包含的架构的数量（左侧）。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了使这次调研足够可操作，我们将原有架构列表缩减到了 86 项。因此，我们重点是至少有一个实际应用和多篇有同行评议的论文的已经实现的架构，我们没有考虑一些哲学上的架构（如 CogAff、Society of Mind、Global Workspace Theory、Pandemonium theory）。我们也排除了大规模脑建模项目（brain modeling project），这是较低层面的，不能轻易映射到由其它认知架构所建模的认知能力的广度上。另外，许多脑模型尚还没有任何实际的应用，因此也不满足本调查的参数。图 2 显示了本调查给出的所有架构和它们根据发表情况得出的大概时间表。它们中有 55 个项目目前是活跃的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;正如我们早些时候提到的，给已经实现的认知架构创建一个广泛的和有组织的编目的第一步是 [1]。这个概述包含了 26 个项目的扩展描述，其中包含的信息有：简要概述、主要元素的原理图、共同组分和特征（记忆类型、注意、意识等）、学习和认知发展、认知建模和应用、扩展性和局限性。这一类的调查将一些不相交的社区的研究者聚集到了一起，并帮助建立了这些不同方法和他们所使用的术语之间的映射。但是，这种描述性的和表格式的格式让我们无法对这些架构轻松地进行比较。因为我们的架构样本很大，所以我们实验了可做替代的可视化策略，例如冲积图（alluvial diagram）和圆图（circular diagram），它们常常被用于组织复杂的表格数据。这些图的交互式版本让我们可以探索这些数据和查看相关索引。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在后续的章节中，我们将提供关于认知的定义和分组认知架构方法的整体概述。作为我们的贡献之一，我们会根据认知架构的感知模式（perception modality）、注意的实现机制、记忆组织、学习类型和实际应用对它们进行映射。认知架构的其它特征，比如元认知（metacognition）、意识（consciousness）和情绪（emotion），不在本次调查的范围内。在准备这篇论文的过程中，我们广泛地审阅了文献，这项活动让我们得到了一个包含 2000 项的相关发表情况的参考目录（bibliography）。我们提供了这份参考目录，同时还带有每篇论文的简短摘要作为补充材料（发布地址：http://www.data.nvision2.eecs.yorku.ca/cognitive-architecture-survey/bib_html/index.html）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2 什么是认知架构？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;认知架构是通用人工智能（general AI）的一个研究分支，它起源于 20 世纪 50 年代，其目标是创建能够解决不同领域问题的程序、培养洞察力、能自己适应新情况并做出反应。同样，认知架构研究的最终目标是实现人类水平的人工智能。根据 Russell 和 Norvig [2]，这样的人工智能可以以四种不同的方式实现：像人类一样思考的系统，能理性思考的系统，像人类一样行动的系统，以及能理性行动的系统。现有的认知架构已经探索了所有四种可能性。例如，像人类一样的思想是源于认知模型的架构所追求的。因此，只要智能系统造成的错误如同相似情况下人类通常做出的错误，则它们的错误是可以容忍的。这与理性思维系统相反，理性思维系统需要为任意任务作出一致和正确的结论。像人类一样行动的机器和理性行动的机器之间的区别也与之相似。在后两种情况中，机器并不期望能像人类一样思考，我们关注的只是它们的行动或反应。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibsC7CE9mCiaYfYOVgk5GVGTcSNhfXYmcWq2Imz316ZXypibc6lygRfiaruFnlmW4Y4t0o3icxwPhgnaA/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 2 此次调查的 86 种认知架构的时间表。每条线对应一个认知架构。认知架构按照开始日期排序，因此最老的认知架构在图的最下部。由于只明确知道几个项目的开始和结束日期，因此我们按照项目网页的发布和活动日期还原了时间表。颜色对应于不同类型的架构：symbolic（符号式，绿色），emergent（层创式，红色）和 hybrid（混合式，蓝色）。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然而，由于认知没有明确的定义和一般理论，每个架构都是基于不同的前提和假设，使得比较和评估不同的认知架构变得困难。几篇论文试图解决这种不确定性，最著名的是 Sun 对认知架构的期望 [3] 和 Newell 的实用性标准（最初发表在论文 [4] 和 [5] 中，后来重新被 Anderson 和 Lebiere 提及 [6]）。Newell 的标准包括灵活的行为、实时操作、理性、海量知识库、学习能力、发展能力、语言能力、自我意识和大脑觉悟。Sun 的期望更广泛，包括生态、认知和生物进化现实主义、适应性、模块化、常规化和协同互动。除了定义标准，并把它们应用到认知架构的范围，Sun 也指出，明确界定认知的假设和方法存在缺失，这种缺失阻碍了智能研究的进展。他也提到了关于基本二分法（essential dichotomy）（隐式/显式，程序化/声明化等）、模块化认知和结构化记忆，存在一种不确定性。但是，快速浏览一下这些已有的认知架构就可以发现，这些架构在研究目标、结构、操作和应用方面长久存在分歧。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibsC7CE9mCiaYfYOVgk5GVGT4IeDicOpHzSXIG0c2B1XxxYtWrqnbWWwNMad0wZjfXz3mbOAUOOek7A/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 3 1973 至 2016 年间，活跃的符号式（symbolic）、层创式（emergent）和混合式（hybrid）架构的可视化。在图上显示了同时活跃的项目的最大数量。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相比于为智能寻求一个特定的定义，也许将智能定义为一个系统所体现的能力和行为的集合更为实际。虽然不存在一个智能所要求的能力的综合列表，但一些已经被认可的宽泛的方向也许可以作为目前认知架构领域工作的指导。例如，Adams 等 [7] 提议了 14 个方向，分别是感知、记忆、注意、社会交互、规划、动机、驱动、推理、交流、学习、为自身/他人建模、建造/创造以及算术能力（perception, memory, attention, social interaction, planning, motivation, actuation, reasoning, communication, learning, emotion, modeling self/other, building/creation and arithmetic abilities.）。这些可以进一步划分为更小的领域。可以说，其中一些类别也许看起来比其他的更重要，且历史上也受到更多关注。比如，根据 Metzler 和 Shea[8]，在近期认知架构的发表中最常被提到的认知功能仅包括感知、学习、推理、决策、计划和行动。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然而，即使在一个单一架构中仅实现一个缩减的功能集合，也是一个任务繁重的工程。因此，目前只有一小部分架构（如：Soar, ACT-R, NARS [9], LIDA [10]）和几个最近的项目（SiMA [11] 和 OpenCogPrime [12]）在追求通用人工智能（Artificial General Intelligence，AGI）。其他架构则专注某一特定的认知功能，例如注意（ARCADIA [13], STAR [14]）、情绪（CELTS [15]），对称感知（认知对称引擎（Cognitive Symmetry Engine）[16]）或者问题解决（FORR [17], PRODIGY [18]）。还有一些为特定应用设计的专门的架构，比如为平面视觉检测设计的 ARDIS[19]，以及为音乐理解和分类设计的 MusiCog[20]。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;使得一个软件系统能够被称为认知架构的标准也鲜被强调。大多数综述宽泛地定义认知架构为智能的一个蓝图，更具体地，是一个关于心智表征以及运行在这些表征之上的计算过程的设想，它们使得一定范围内的智能行为成为可能（[21], [22], [23], [24], [25]）。总的来说，新的认知架构不需要包括已有的认知架构，例如 Soar，ACT-R，EPIC，LIDA，ICARUS 等。然而，当它并不是那么常见或是一个全新的项目时，我们并不知道考虑现有的这些认知架构是否必要。举个例子，AKIRA 是一个明显的不能自我统一地认为其是一个认知架构 [26]，但是它的特性仍然被很多综述提及 [27]。类似的，知识库 Cyc [28] 从未对任何通用智能有所声称，却仍然在一篇论文中被总结为一个 AGI 架构 [29]。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Larid [30] 讨论了认知架构与其他软件系统有何不同。虽然它们都有记忆存贮、控制部件、数据表示和输入/输出设备，但其它软件系统只提供了一个用于一般计算的固定模型。而认知架构则必须随着发展而改变，并且高效地运用知识完成新的任务。此外，他认为用工具包（toolkit）和框架（framework）建立的代理（agent）架构也不能被当做认知架构，因为它们缺乏理论支持。这是一个相当严格的条件，除了 Soar 和 ACT-R，只有很少的架构能够符合这个要求。这一观点在综述论文里也不常见，通常代理架构和用来建造它们的工具包也会被包括在内。例如，代理架构 3T、PRS 和 ERE 被包括在了 [31] 内；Pogamut，一个用于建立智能代理的框架，也被包含在了 [1] 中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最近，谷歌（DeepMind）声称深度学习能够「解决人工智能（solving AI）」。类似地，Facebook 人工智能研究实验室（FAIR）及其它一些公司也在这个方向上活跃地进行研究。这些研究在认知架构方面具有怎样的地位呢？在目前，深度学习一些最广为人知的成就包括用于自动驾驶汽车的视觉处理（Mobileye）和谷歌的能够下围棋 [32] 和玩多种视频游戏 [33] 的神经网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一方面，DeepMind 发表的论文（没有在媒体上打广告）涵盖了范围很广的主题。比如说，许多论文都致力于与循环神经网络和深度神经网络相关的理论问题。此外，神经网络也被用来构建复杂的视觉注意和记忆（visual attention and memory）模型，比如：一种用于识别图像中多个对象（如门牌号序列）的基于注意的模型 [34]。记忆（memory）在深度学习领域具有特殊的重要性，因为为了寻找和利用数据中的复杂模式，网络应该要能执行链式的顺序计算。但是，在深度网络中，来自过去的计算的信息会受到新信息的影响。网格式长短期记忆（Grid Long Short-Term Memory/Grad LSTM）通过提供一种动态式选择或忽略输入的方式而解决了这个问题，从而可以在学习过程中保留重要的记忆 [35]。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;整体上看，DeepMind 的研究解决了人工智能领域里一些重要的问题，比如自然语言理解、感知处理、通用学习和用于评估人工智能的策略。尽管特定的模型已经证明了在有限领域内的认知能力，但目前它们还无法代表一种统一的智能模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;和 DeepMind 不一样，Facebook 的研究团队是在开发智能机器的更广阔的语境中明确讨论他们的成果 [36]。他们的主要观点是：人工智能是在太复杂了，以至于不能一次性开发出来，而是应该首先定义智能的通用特征。他们已经定义出了两个智能的通用特征：交流（communication）和学习（learning），并且还提出了一个逐渐发展它们的具体的路线图。这个方向的第一步是人工生态系统（artificial ecosystem，或称「幼儿园」），其被提出用于教育智能代理（intelligent agent），从而强调了这个过程的发展性本质。他们的计划是从更简单的模拟环境开始，然后逐渐增加其复杂度，直到最后它能够将人工代理和真实世界连接起来。鉴于这种对交流和学习的强调，这种智能机器的一种主要应用就是电子助理。作者承认类似的想法在过去已经得到过尝试（如，常被符号架构用于学习的 Blocks World 模拟），但它们都过于依赖于其创造者所提供的数据。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前没有文献提及这样的系统，但 FAIR 追求的研究主题与其人工智能展望也与各家公司的商业利益相一致。常见的相关话题包括可视化处理，特别是分割和目标探测、数据挖掘、自然语言处理、人机交互和网络安全。目前深度学习技术主要用于解决实际问题，并不代表一个统一框架，所以不包括在此次调查的范围内。当然，鉴于深度学习的潜力，这一方法将来可能会在认知架构中发挥作用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于其他架构，我们定义了以下选择标准，努力实现包容和一致：自我识别作为认知，机器人或代理架构，已有实现（不必是开源的），以及用于感知、注意和学习的机制。为了进一步缩小调查的范围，我们需要至少存在同行评审的论文和应用，而不能只有简单的演示。但为包括一些仍在开发中的新架构，其中的部分条件得到了放宽。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3 认知架构的分类&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;过去十年发表的许多论文提出的多是认知架构的评估而非分类。像之前提到的，Newell 的标准和 Sun's Desiderata 就属于评估这一类。相似的，Langley 等人将认知架构的能力，性能和评估标准定义成一个综合的列表。认知能力的建议集合包括识别，作出决定，感知，预测，计划，行动，交流和学习。为了评估构架，提出了例如通用性，多能性，自主性的标准。与此同时，Vernon 等人列出了比较认知和浮现式方法的 12 个特征，包括体现，感知，行为，适应，动机，自主化和其他。相似的，Asselman 等人则通过 7 个标准（认知，记忆，学习，模块化，目标设定，基本模型和解决问题）评估构架。Thorisson 和 Helgasson 基于 4 个标准（实时操作，学习，注意和元学习）来决定自主化的水平。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;许多标准可以被用来划分架构，但它们应用在一般的构架时会显得过于细致。因此，基于它们表现出的信息加工的种类来划分认知架构是更为常见的方法。三个分类方法被称作：符号式（认知主义），层创式（联结主义），混合式。这种基于信息加工的分类方法被 Duch 等人 [21] 拓展到含每个类别的典型记忆和学习性能（[38], [39])）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;符号式系统通常在一系列可用于表现世界的真相的符号中作为 if-then rules（也被称作 production rules）执行。因为它是知识的一种自然而直观的表达方式。符号式操作十分普遍。尽管经过设计，但符号式系统在计划和推理方面有优势，而在被要求处理变化的环境和感知过程时缺乏灵活性和坚固性。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;层创式方法通过建立大量的并行模型，类比神经网络（此处信息流是通过从输入节点的信号波及表现的）解决了上述问题。但是，这样的系统也丧失了它的透明性。因为知识不再是一系列符号化的实体而是分布在网络中。因而同样，传统意义上的推理在层创式架构中存在问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;自然地，每个范例都有着它的优缺点。例如，任何符号式架构都需要大量的工作去建立一个初始的知识基础。但一旦它建立好，整个架构就会变得十分有效。而另一方面，层创式架构更容易设计，但它们必须经过训练才能完成有效的动作。更重要的是，它们的已存在网络可能会因为接下来学习的新行为而被摧毁。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;由于没有任何一个范式（paradigm）可以单独处理全部的人工智能问题，混合架构试图结合符号式和层创式两种元素。总的来说，两者如何混合没有一个明确的限制，但有的方法更加直观且易于执行。例如，CLARION 基于不同知识类型有不同的表现形式：明确的事实知识用符号式，程序中暗含的知识用亚符号式 [40]。4CAPS 将传统的符号式生产系统用联结主义的计算机制：如阈值、激活、权重和并行处理来诠释 [41]。这种混合方式被 Duch 等人 [21] 称作符号式联结主义（symbolicconnectionist）。同时他们也定义了一种替代的地区性分布方法。后者很好的例子就是 Leabra，它在学习不变事物的检测时用到了标签的地方主义（localist）表征和特征的分布式表征 [42]。在 [43] 中，这两种混合式的表征被分别称作平行和垂直的整合。一个混合联结主义-符号化模型的更为细致的分类方法在 [44] 中呈现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibsC7CE9mCiaYfYOVgk5GVGTwPKQRvuL5Xia8Kfd5Qc9iazEm1FNLlIjcJdDVHRnMOw1ZGWkls5SNpjA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;图 4：Duch et al. 在 [21] 中提出的分类方式；&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;图 5：Sun 在 [45] 中提出的分类方式；&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;图 6：Gray 在 [46] 中提出的分类方式&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有趣的是，层创式架构只在最近时期才获得更多的比重，尽管这一方向的研究至少与传统人工智能一样活跃。例如 Langley 等人 [22] 在他们的调查中没有加入联结主义模型，因为他们没有发现这一架构与符号模型和混合模型相同的功能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;考虑到混合方式的优点，这样的架构有最高的增长趋势便不足为奇了（图 3）。所以，我们的数据证明了 Duch 等人 [21] 在 10 年前的预测。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;文献资料中仍没有多少其他的分类方法。Sun[47]（图 5）的方案强调模块化和模块之间的通信。然而，遵循此类方法需要所有架构的实现方式细节，这些信息经常不能获得。其他分类方案也很具体，如 Gray[46] 提出的方案，其重点在于架构的目的及使用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因此，在本次研究中，我们遵循符号、层创和混合架构的传统区分方式。由于我们介绍的架构的背景跨越从哲学到神经生物学的广泛研究领域，我们不会试图创立一个单一的体系来适应它们。我们不会对每一个认知功能分别进行讨论，而是以功能（即：感知、注意、记忆和学习）进行分类的讨论。我们从发表情况中提取了数据，并按频率进行了分组。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;4. 感知&amp;nbsp;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibsC7CE9mCiaYfYOVgk5GVGTYvZtXxTdJS6AVgQkJyMLia6RLppZ6NcHd0303DHU3MgLW3KGb9vmmfQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;图 7 显示了认知架构的感知通道（sensory modalities）。该架构分成三组： 符号式（绿色），层创式（红色）和混合式（蓝色），位于图底端。图中其他部分对应不同的感知通道，包括视觉、听觉、触觉、嗅觉和本体感觉。这个感知分类还包含了不对应任何人类感官的多种感知。「符号输入」类别表示的是认知架构中的输入只限于文本形式，或者需要通过 GUI。这不包括文本输入模拟音频、视觉或其他类型的信息。图中每个大类别扇形中的带表示的是这些感知通道的子类别（例如视觉类别下包括 Kinect、单眼相机、模拟等）。感知通道与架构之间的条形是用来表示它们之间的连接。如果一个架构控制多个感官，条形就越不透明。每个认知架构的感知方式列表都带有相关文献，被包括在补充材料和图形的互动版本中。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;5. 注意&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibsC7CE9mCiaYfYOVgk5GVGTODj3J4qfDrvz6XHWfwIUd2MQrIW3fertoBibdgTbhbXpj48E9aSuYDQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 8 显示了认知架构中不同类型的注意。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;6. 记忆&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibsC7CE9mCiaYfYOVgk5GVGTbXT8r3Blfib0wJpO1icJd0NonawYPt4RwBQc4GSjKOFn7RkI25W1jf8A/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 9 显示了认知架构中不同类型的短期记忆（STM）和长期记忆（LTM）&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;7. 学习&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibsC7CE9mCiaYfYOVgk5GVGTarZcGlmck6KU39GuEq8Km2pXwT1Lqp6rDmzI6kNkEkErW9VKeB5Eug/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 10 显示了认知架构中的学习机制。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;8. 认知架构的应用&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本论文中的回顾的大部分认知架构都是研究工具几乎很少被开发到学界之外的应用。然而，还是可以讨论一下他们的实际应用的，因为不同情境下有用的行为被认为是许多认知结构的目标。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;彻底研究过这些发表的论文后，我们使用 86 个认知架构确定了 700 多条 project，如图 11 显示。所有的应用都可以划分到几个大组（group）中，即人类表现建模（human performance modeling，HPM）、游戏和拼图（puzzles）、机器人、心理学实验，自然语言处理和其他杂项，还包括了不属于任何大组的项目，它们由于太少所以无法独立成大组。这样的分组强调了每个 project 的应用，即便每个研究者有不同的目的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一些应用可能会被划分到多个组。例如，装上一只机器手臂的 Soar 一直被用来玩棋盘游戏，这就同时关涉到机器人、游戏和拼图以及心理学实验。为了避免让这张图过于复杂，在这些案例中我们只将 project 放在了主要的组中考虑，在 Soar 的例子被划为游戏，因为它在机器人上的应用并不是很大，而且心理学实验组主要是使用 ACT-R 的 fMRI 实验。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;人类表现模型（HPM）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人类表现模型是一个与建立某个特定任务环境中的人类表现的量化模型相关的研究领域。这些模型主要用于几个工程领域，在这些领域中，设计可能性的空间非常大，导致实证的评估方式不可行或者成本太高。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这种建模类型一直用于军事应用，例如，Apache 直升机机组人员的负荷分析，战场感知中通信任务的影响建模 [230]，AAW 领域的决策制定 [231] 等等。普通的民用包括空中交通管制任务的模型（例如，COGNET[232]）, 飞机滑行失误 [233]，911 调度员 HPM 用的是少数专用架构，包括 OMAR、 APEX、COGNET,、MIDAS 和 IMPRINT。Soar 在大规模分布式军事模拟战中用于部署某个飞行员模型&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;例如，导航中会用到一个机器人，无论是从推理上还是作为某个学习算法的演示，它都会被归为机器人组。唯一的例外是心理学试验组，其中还包括心理社会学、fMRI 和 EEG 试验。这个组中的 project 是由认知架构执行的，用于与人类数据对比的特定的心理实验（例如倒数 n 任务、调节或注意的盲目性）。游戏和拼图类别包括不同领域中的棋盘游戏、视频游戏、拼图和逻辑推理的应用。HPM 对关于机组人员（aircraft crew）、核电站的操作员以及执行其他复杂任务的人的建模很有用，例如电话接线员和空中交通运维人员。大部分自然语言处理应用都关涉到对说出或打出来的命令的理解，也与社交机器人有关。然而该组中也有一些 project 用于意义排歧和句子整体意义理解的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;人机交互（HRI）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;HRI 是研究人与机器人对话中不同方面的多学科领域。这些互动大部分都发生在社交式的、辅助式的或发展式的机器人语境中。根据机器人的自动化水平，互动可以扩展到从直接控制机器人（遥控）到其完全自动化的任务中，实现人机对等合作。虽然该项研究中的系统还没有一个能达到完全自动化的水平，但它们可以实现一定程度上的监控，从用单韵母表示机器人的运动方向 [SASE236] 到自然语言指令（例如 Soar[237]，HOMER[88]、iCub[238]）。通常的假设是，一个命令有一个特定的形式，而且使用的词汇有限。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;某些架构也用于 HRI 的非口语（non-verbal）方面，例如对话的自然轮转（Ymir[239]，Kismet[240]，改变面部表情（Kismet [241]）或者转向护理机器人（MACsi[242]）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibsC7CE9mCiaYfYOVgk5GVGTSVPcJVrGPISd6CabzcNUwTDRkyq7G7YquAT7c2q796DTto1sbyVKhg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;图 11. 认知架构的实际应用图。这些架构被分成了三组：符号式（绿色）、层创式（红色）和混合式（蓝&lt;/span&gt;&lt;/em&gt;&lt;span&gt;&lt;em&gt;色）。应用被分成了代表不同领域的组。其中每一个应用都是使用了一种认知架构实现的特定项目，并且还得到了相关论文、软件或视频演示的支持。其中不包括仅有部分结果或实物模型的项目。另外，涉及与该架构中其它部分隔开的特定算法的例子也没有被包括进来。可视化使用 http://www.circos.ca (http://www.circos.ca/) 完成。关于每种认知架构的应用列表及相关索引可见于补充材料中，也可以在该图的交互式版本中查看。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;自然语言处理（NLP）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这一组的应用是关于理解书面语言和口头语言。尽管使用现成的软件来进行语音识别和文本解析对认知架构来说很常见，但也有一些架构为 NLP 研究做出了贡献。特定的例子包括：照明分辨率（Polyscheme [243]，NARS [244]，DIARC [245]）、语音识别基准（Sigma [246]，[247]，SASE [248]）和学习英语被动语态（NARS [244]）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;归类和聚类（Categorization and Clustering）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;归类（categorization）、分类（classification）、模式识别和聚类是从大数据集中提取概括信息（general information）的常见方式。在认知架构的背景中，这些方法可被用于处理嘈杂的感官数据。这一组的应用几乎完全都是用层创式架构（emergent architectures）实现的，比如 ART 和 HTM，它们被用作是复杂的神经网络。尤其是 ART 网络已经在范围广泛的领域的分类问题上得到了应用，包括电影推荐（Netflix 数据集 [249]）、医疗诊断（Pima-Indian 糖尿病数据集 [250]）、错误诊断（气动系统分析 [251]）、元音识别（Peterson and Barney 数据集 [252]）、气味识别 [253] 等等。HTM 架构面向时序数据分析（analysis of time series data），例如预测 IT 故障（grokstream.com）、监测库存（numenta.com/htm-for-stocks）、预测出租车乘客需求 [254] 和基于按键模式识别手机使用类型（电子邮件、电话等等）[255]。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一些非层创式架构（non-emergent architecture）的例子包括根据追踪套装识别手势（Ymir [256]）、电信网络故障诊断（PRS [257]）和基于关于作者和引用的信息分类文档（OpenCogPrime [258]）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;计算机视觉&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这一新兴的认知架构也被应用于解决典型的计算机视觉问题。目前只有一些独立的例子，例如笔记特征识别（HTM[259],[260]）、图像分类基准（HTM[261],[262]）、视角无关性字母识别（ART[263]）、纹理分类基准（ART[264]）、不变目标识别（Leabra[265]），等。计算机视觉的的应用经常是任务处理的一部分，如机器人导航，这在本论文的相关章节也有谈及。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;游戏和解谜&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该分类内的应用包括棋盘游戏、视频游戏以及解决有限领域内的难题。简单的包含重叠旗子的棋盘游戏如井字棋，八数码和五数码问题经常被用来证明知识迁移（例如 Soar[227]，FORR[266]）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;视频游戏也是认知架构应用的虚拟领域。在最受欢迎的游戏《虚幻竞技场 2004》（UT2004）中有一个开源工具包 Pogamut[267] 可以自由创建智能的虚拟角色。另外，它还有许多同类型的竞争者，玩家们在这些游戏中不仅需要关注得分和效率，同时也得保持与游戏中虚拟角色的关系（2K BotPrize Contest7）。Pogamut 不仅 实现了很多认知功能，它还是 BotPrize 比赛推荐的软件，可以经过修改实现更多的特性（[268], [269], [270], [271], [271], [272]）。其他的此类游戏包括《Freeciv（REM [273]）》，《Atari Frogger II（Soar [274]）》，《Infinite Mario（Soar[275]）》，网页端游戏（Star[276]）和一些定制游戏。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;心理实验&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;心理实验的应用是使用认知架构的多种心理生理学研究，包括 fMRI 和 EEG 实验。此类实验利用认知架构可以对人类指标进行数字化建模，或对心理现象给出合理的解释。如果由模拟产生的数据在一些或大多数方面与人类数据匹配，则说明给定认知架构可以模仿人类生理机制。随后，认知模型可以用于对不同情况下的行为进行预测或进一步分析，最后可帮助人们对已知现象背后的心理机制进行解释。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;大多数实验在模拟环境中进行，尽管在实体机器人中也存在一些例子（例如，在 DarwinVII 机器人上的感知分类模型 [181]）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;机器人&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在机器人中，认知架构有许多应用。导航和避障是基础的行为，对机器人自身有帮助，也可作为更复杂行为的一部分，比如辅助机器人。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在机器人早期研究中，做杂务是非常的流行的用来有效证明机器人能力的方式。一些著名的样例包括垃圾收集移动机器人（3T [277]）、苏打罐收集机器人（Subsumption [278]）。通过结合简单的视觉技术（比如边缘检测和模板匹配）和传感器技术（导航），这些机器人能够在未知环境中发现感兴趣的目标。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最近的认知架构倾向于分开解决搜索和目标操控任务。典型的，有的实验是在可控环境中完成视觉搜索，对明亮颜色或者可识别的形状的喜好可用来最小化视觉处理任务。有时会使用到标记（markers），比如将条形码附属到目标上进行更轻松的识别（Soar[279]）。需要主要的是，这些案例中的视觉搜索通常是更复杂任务的一部分，比如通过指令进行学习。在视觉搜索和定位是最终目标时，环境更为真实（例如，通过传感器和 SIFT 特征的结合，CoSy 控制机器人在书架上找到一本书 [280]）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目标操控涉及到控制机械臂触碰并抓取（reach and grasp）目标。虽然触碰是相对简单的一个问题，且许多架构部署不同形式的机械臂控制，在模拟环境中抓紧目标却更具挑战性。抓取的复杂性由多种因素决定，包括抓手的类型、目标的特性。一种变通方案是用软体目标进行试验，比如毛绒玩具（ISAC [281]）。近期的研究涉及到通过 DIARC [282], [282]控制的机器人证明可以抓取不同类型的目标（在顶部或边缘有抓手的目标）。另一个例子是 iCub[283] 根据抓取瓶罐的大小、抓取的箱子和直尺等不同目标进行适应。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其他应用包括机器人销售员、教师、医疗机器人等。工业应用由单个架构 4D-RCS 所代表，已经被远程控制的吊机机器人 [284]、架桥机器人[285]、自动清洗和去毛刺工作站机器人[286]和美国邮局自动邮票分发中的机器人[287]等使用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;虚拟代理&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;模拟和虚拟现实总是被频繁用为物理化身的替代。例如，在军事领域，危险情境下军人的模拟模型行为不会对身体造成伤害。其他例子包括在自杀式炸弹袭击场景中建模代理（CoJACK [73]）、维和部队训练（MAMID [190]）、在复杂的城区地形的指令和控制（RCAST[288]）、坦克战模拟（CoJACK[289]）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在民用领域，模拟建模智能代理的行为也非常常见。虚拟环境的一个优势是它能提供关于代理任意时间点的状态信息。这对学习临场情感影响非常有帮助，例如在社交环境（ARS/SiMA[290]）或学习场景中，比如与虚拟的狗狗玩耍（Novamente[291]）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;9 讨论（略）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;参考文献见下载论文&lt;/span&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Fri, 28 Oct 2016 15:48:33 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 机器已经学会隐藏自己：谷歌教会神经网络自己设计加密算法（附论文）</title>
      <link>http://www.iwgc.cn/link/3265308</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自NewScientist&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李泽南&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;计算机总是和秘密有关，人们将加密算法输入其中传递信息，又利用计算能力破译密码，信息的保护和破解随着硬件性能的加强不断升级。最近，谷歌深度学习项目 Google Brain 的一个小组提出了新方法，让计算机加密的方式更上一层楼，他们的系统可以自我增强加密算法。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibsC7CE9mCiaYfYOVgk5GVGTwwX28CpN3NSKVZkLp85IHDiceTEOw6t5eibWdrUR1uDYGPjryB1rGL2w/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;em style="color: rgb(136, 136, 136); text-align: center;"&gt;&lt;span&gt;机器已经学会如何互相传递秘密（图片：John Lund/Getty）&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谷歌科学家 Martín Abadi 和 David Andersen 在最近的研究中发现，神经网络——基于人工神经元的计算系统——可以学习如何使用加密技术。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在他们的实验中，计算机能够使用机器学习形成自己的加密形式，而不需要人类输入特定的加密算法。与目前的复杂计算机系统相比，这些加密算法相对简单，但它是探究神经网络的一个有趣进展。这一研究「仍不意味着密码学的发展」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Google Brain 团队首先使用名为 Alice，Bob 和 Eve 的三个神经网络，每个系统各司其职，互相联系。Alice 发送一串加密信息给 Bob，Bob 负责解密这条信息，而 Eve 则尝试窃取信息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了确保秘密，Alice 在自我训练中开始将明文信息转变为专业术语，让窃听者（Eve）无法理解。这种专业术语「密电」必须只能被 Bob 理解。此时 Alice 和 Bob 开始使用预先约定好的一组数字作为秘钥，以帮助解密，而 Eve 无法访问这组秘钥。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibsC7CE9mCiaYfYOVgk5GVGTytCv5hibjC8O0bmEzpaibc2gDicWSW3uIbRV8iclverH5w8XRmicrgIQeJQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;三个神经网络在系统中的训练方式&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;熟能生巧&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最初，神经网络发送的加密消息非常简单。但是随着它们不断的自我练习，Alice 慢慢发展出了自己的加密策略，Bob 则不断试图通过秘钥解密信息。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这一任务被分为 4096 批同时进行，研究人员发现，在执行约 15,000 次以后，Bob 学会了将 Alice 发出的密电转回原文本，而 Eve 平均只能猜出信息中二进制 16 位数字中的 8 位。鉴于二进制只有一和零两种表示，这表明它的解密结果只是纯粹的猜测。此项研究已经于 10 月 21 日在 arXiv 上发表。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibsC7CE9mCiaYfYOVgk5GVGT5vDHa3Xep8aqZBkhNXib8By30tu5uKuLI9XplzXM1JJHKztzKKnkNgw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Bob 和 Eve 解密信息的错误率随实验次数的变化&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;大多数人并不知道加密算法的机制，但机器学习的过程已经告诉我们它是如何产生的。目前为止，机器学习提供的加密算法并不能提供安全保证，该项研究对于网络安全的意义可能还很有限。但这种探索可以为加密算法的进一步研究提供新的思路，同时，研究人员认为神经网络在未来也可用于破解密码。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;总部位于密尔沃基的加密软件公司 PKWare 首席技术官 Joe Sturonas 评论道：「这个级别的神经网络计算机在近几年才投入使用，所以我们还只是在一切的开始。如果计算机想要接近人类设计出的密码的复杂性，还有很长的路要走。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;论文：对抗神经密码学——保护通信安全的研究（Learning to Protect Communications with Adversarial Neural Cryptography）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibsC7CE9mCiaYfYOVgk5GVGTFlSK5uCLOXicJAdH7VIrfhh3p3icWrMjYnY4ZRejludJlBx2Gof1qlOA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：在本研究中，我们让神经网络学习使用秘钥来保护从其他神经网络传递过来的信息。具体方法是：我们为了确保多代理系统（multiagent system）中的保密性进行秘钥升级，同时根据破解者的方式不断改变秘钥的属性。在试验中，系统中的神经网络名为 Alice 和 Bob，我们需要阻止名为 Eve 的第三个神经网络窃取前两者之间的通信内容。我们不对这些神经网络事先输入已有的加密算法；相反，我们以点对点的形式让它们互相对抗自我训练。我们证明了神经网络可以学习如何加密与解密，以及如何有选择地应用各种操作来让信息保密。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，机器之心系今日头条签约作者，本文首发于头条号，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Fri, 28 Oct 2016 15:48:33 +0800</pubDate>
    </item>
    <item>
      <title>学界 | MIT CSAIL 实验室新算法：能在损坏数据中寻找模式</title>
      <link>http://www.iwgc.cn/link/3265309</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;选自MIT CSAIL&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;包括 MIT 计算机科学与人工智能实验室（MIT CSAIL）的研究员在内一组团队创造出了一系列新算法，能够高效的在高维数据中拟合概率分布。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibsC7CE9mCiaYfYOVgk5GVGTJgniclw3b75ZFXKDvL80cz2aZJdoKticDksp4B1kLmibjK1RURibNtVBxw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数据分析，尤其是大数据分析，大多是将数据拟合到数学模型的问题，最熟悉的例子就是线性回归，也就是找到数据点近似分布的线。将数据拟合到概率分布，比如贝尔曲线，也很常见。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然而，如果数据集只有一些损坏的条目，也就是说损坏的难以测量，标准的数据拟合技术就不行了。该问题在高维数据或带有许多变量的数据中更为严重，而这类数据在数字化时代又是普遍存在的。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;众所周知，从 20 世纪 60 年代早期开始，就有一些算法能够除掉高维数据中的损坏数据（corruption），但过去 50 年提出的算法没有一个在变量超过 12 的时候很实用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该进行改变了。在本月初，来自 MIT CSAIL 实验室、南加州大学、加州大学圣迭戈分校的一组研究人员在 IEEE Symposium on Foundations of Computer Science 上展示了一系列新的算法，能够高效的在高维数据中拟合概率分布。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;引人注目的是，在同一会议上，来自 Georgia Tech 的研究人员提出了一个非常类似的算法。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在能够忍受损坏数据的「稳健统计」或统计方法上的首创工作是由统计学家完成的，但新的论文都来自一堆计算机科学家。这可能反射出该领域内注意力的转向，开始注意模型拟合技术的计算效率。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;MIT Rockwell International Career Development 助理教授 Ankur Moitra 说，「从理论计算机科学的优势来看，很明显一个能被有效解决的问题有多稀少。如果你从假设作为开始，就会很糟糕，因为这是低效的。你应该从你知道你能高效进行的事情开始，并搞清楚如何将它们合在一起从而更稳健。」Moitra 也是 MIT-USC-UCSD 项目的领导者之一。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;抵制损坏数据&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了理解稳健统计之后的原理，Moitra 解释说想想正态分布，贝尔曲线，数学的说法也就是一维高斯分布。一维高斯分布完全由两个参数所描述：平均值和方差。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果数据集中的数据（假设是给定人群的身高）能被高斯分布很好的描述，那平均值就是算术上的平均。但假设你有一个包含 100 位女性身高的数据集，其中大部分身高是 64 英寸，一些很高，一些很低。其中一人的身高因某些原因达到 1000 英寸。用算术平均得到女性平均身高是 6.4 英尺，不是 5.4 英尺。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一种避免这种荒谬结果的方法是评估平均值，不采用数据的算术平均，而是找到其中值。使用中值评估平均值的算法要更为稳健。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;中值只是平均值的近似值，而且随着变量的增多该近似的准确率会急剧下降。大数据分析可能需要测试千个甚至百万个变量。在这种情况下，平均值的中值近似法基本不能用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;异常点识别&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一种将高维数据集中的损坏数据清除掉的方法是采用数据图的 2-D 交叉界面，并观察它们看起来是否像高斯分布。如果不是，你可能置入了一类假的数据点，比如 80 英尺高的女人，这些数据点可被轻易的切除。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;问题是，将先前已知的算法应用到该方法时，找到损坏数据所需要的交叉界面的数是维度量的一个指数函数。相比之下，这组研究人员发现一种算法，这种算法的运行时间随着数据维度的数量以更合理的比率增长（计算科学术语来讲就是 polynomially）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他们的算法依赖两种洞见。首先是在测量数据集离分布范围（近似同样的形状）多远时使用什么 metric。这能让他们分别是否淘汰了足够的损坏数据，从而更好的拟合。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一种洞见是如何识别界面开始交叉时的数据的区域。为了做到这一点，研究人员依靠被称为分布的峰态（kurtosis of a distribution）来测量其 tails 的大小，或者说是数据距离平均值降低的速率。再次强调，有多种从数据样本中推断 Kurtosis 系数的方法，选择正确的一个是该算法的核心。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;研究人员的这种方法能结合高斯分布，也能结合其他常见的分布——乘积分布（&lt;span&gt;product distribution&lt;/span&gt;）。他们相信该方法可被扩展到其他类型的分布上，在接下来的研究中，他们将主要关注将该技术用到真实数据上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Fri, 28 Oct 2016 15:48:33 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 迪士尼推出新面部捕捉系统：更少的数据捕捉更精确的表情</title>
      <link>http://www.iwgc.cn/link/3265310</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;选自Disney Research&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：杜夏德&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;em style="color: rgb(136, 136, 136);"&gt;&lt;span&gt;迪士尼研究（Disney Research）开发出一种新的面部捕捉系统（facial capture system）用于捕捉演员的特定表情，相对于常规的系统，该系统需要的时间与投入更少。&lt;/span&gt;&lt;/em&gt;&lt;br/&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;研究者发现他们可以使用采用小样本的录像，然后合成生成必要的数据来训练这个系统，无需详尽地录下演员在多种灯光条件的组合与机位下表现出的各种表情。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这种生成数据的方法能够使他们来确定一组小于常规量的数据（小了几十到几百倍）训练数据，不会影响到面部捕捉的精确性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在今年 10 月 25 日在帕洛阿尔托举办的 3D 视觉国际大会上（International Conference on 3D Vision）展示了他们的这项技术。「由于机器学习的进展，实时无标记的面部表情捕捉在电影和视频游戏制作中已经逐渐流行起来，」迪士尼研究的副总裁 Markus Gross 说到。「通过减少训练这些系统所需的面部图像数量，我们的团队已经大大增加了这项技术的灵活性和效率。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibsC7CE9mCiaYfYOVgk5GVGTia3w2TPIwjWMFASmbUbOHhHZVSicjJ2jmcRjUna7Ac7zQtkxXuuMPn4g/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器学习技术加速了从视频中推断面部几何的过程，但这需要详尽的训练程序使用大量经过注释的人脸图像。「不仅需要捕捉到所有的表情，还要考虑不同的灯光条件和拍摄角度，这会花掉大量的精力，」高级研究员 Kenny Mitchell 说到。「我们的想法是如果我们能够利用策略在特定的条件下捕捉某个演员的表情，我们可以合成所有的训练数据来得到一个目标场景，节省很多时间。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;iframe class="video_iframe" data-vidtype="1" style="   z-index:1; " height="375" width="500" frameborder="0" data-src="https://v.qq.com/iframe/preview.html?vid=l0341irgjtf&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0" allowfullscreen=""&gt;&lt;/iframe&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;研究员使用一台多相机捕获设备在均匀光照条件下，初步记录某个演员脸上的 70 个表情。这些表情数据被用来创建一个面部合成机器（face rig），也是一个可移动的、可塑造型的该演员脸部的模型。之后这个 face rig 被用来生成经过修剪的合成训练数据，可用于多种环境条件和不同性能的相机，而且能达到和制片人期望的实际设置差不多的效果。迪士尼研究的博士后 Martin Klaudiny 说。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些研究员确定他们可以通过训练更多的表情和光照变化数据来达到最佳精确度，同时保证摄像视角的变化对最终结果的影响相对较小。「我们的试验结果显示，最佳的设计策略能够减少一到两个数量级的图像数量，同时计算量也会成比例地减少，而且不损害精确度。」该研究小组另一位关键的博士后研究员 Steven McDonagh 补充道。该研究延续了迪士尼利用最新技术讲述故事建设未来娱乐的传统。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Fri, 28 Oct 2016 15:48:33 +0800</pubDate>
    </item>
    <item>
      <title>深度 | 谷歌增强型风格迁移新算法：实现基于单个网络的多种风格实时迁移（附论文）</title>
      <link>http://www.iwgc.cn/link/3247856</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Google Research&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Vincent Dumoulin、Jonathon Shlens、Manjunath Kudlur&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李亚洲、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;pastiche 是一个法语词，它的意思是将一件艺术品模仿另一件艺术品的风格（请不要与看起来和它接近的更幽默的希腊源词 parody 混淆）。尽管这种方法已经在视觉、音乐和文学等艺术领域被使用了很长一段时间，但 pastiche 直到最近才在 Reddit 网络论坛（https://www.reddit.com/r/deepstyle/）上将大众的注意力吸引到了给图像染上著名画作的风格的任务上。通过使用一种叫做风格迁移（style transfer）的技术，用户可以通过手机或网页应用让他们自己的图片带上著名艺术作品的风格。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尽管用户已经能通过当前的技术得到美轮美奂的 pastiche 了，但我们觉得我们可以将其做得更吸引人。目前，每一种画作都有它自己的独特风格，也就是说：用户提供一张内容图像，选择一种艺术风格，然后得到一张 pastiche。但如果我们能结合多种不同的风格，探索著名艺术家风格的独特混合从而创造出一种完全独特的 pastiche 呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;学习艺术风格的表征&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在我们的论文《A Learned Representation for Artistic Style》中，我们介绍一种可以让单个深度卷积风格迁移网络（deep convolutional style transfer network）同时学习多种风格的简单方法。该网络在学习了多种风格之后可以做到 style interpolation（风格插补），其中 pastiche 可以平滑地从一种风格变成另一种风格。我们的方法也能实现实时的风格插补，让其不仅可以应用于静态图像，还可应用于视频。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;iframe class="video_iframe" data-vidtype="1" style="   z-index:1; " height="375" width="500" frameborder="0" data-src="https://v.qq.com/iframe/preview.html?vid=d0340au56y5&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0" allowfullscreen=""&gt;&lt;/iframe&gt;&lt;/em&gt;&lt;/span&gt;&lt;em style="color: rgb(136, 136, 136); line-height: 1.75em;"&gt;&lt;span&gt;扮演者：Google Brain 团队办公室的狗 Picabo&lt;/span&gt;&lt;/em&gt;&lt;span&gt;&lt;em&gt;&lt;br/&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在上面的视频中，多种风格被实时地结合到了一起，最后得到的风格通过一个单风格迁移网络（single style transfer network）得到了应用。其用户可获得 13 种不同的绘画风格，可以通过滑块调整最终风格中这些风格的相对强度。在这个演示中，该用户是产生该 pastiche 的一位活跃的参与者。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;风格迁移简史&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尽管将一张图像的风格迁移成另一张的风格的技术已经存在了近 15 年时间 [1][2]，但利用神经网络来做这件事还是最近才出现的，而且这很吸引人。在论文《A Neural Algorithm of Artistic Style》，研究者 Gatys、Ecker 和 Bethge 介绍了一种使用深度卷积神经网络（CNN）分类器的方法。其 pastiche 图像是通过优化（optimization）找到的：该算法会寻找一张给出了该 CNN 的底层中同种类型激活（activation）的图像，这些底层会获取风格输入（宽笔触和立体美感等等）的整体粗糙美感；该算法还会在更高层产生激活，这是获取能使对象可被识别出来的东西，这接近于那些由内容图像所得出来的东西。从某个起始点（如：随机噪声或内容图像本身）开始，该 pastiche 会逐渐细化直到这些要求都得到满足。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9ud9Ce5mvD8vXXnwE6wtH7FXl0TjqY2cgXict45vYD7zHictjrSIfh1kI4gZ47Qpgu0Y7ttooMsjbw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;内容图像：Andreas Praefcke 拍摄的 Tübingen Neckarfront；提供风格的画作：Georges Rouault 的「Head of a Clown」&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过这个算法生成的这个 pastiche 看起来很壮观（spectacular）：图片来自 L. Gatys et al. "A Neural Algorithm of Artistic Style" (2015).&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9ud9Ce5mvD8vXXnwE6wtH7IC5VE6SOaTBmwq4ibtotHMfbmntRtQ2hJV4s8IwGSU0s8ZeHXcogtAQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该成果被认为是深度学习研究领域的一项突破，因为它首次提供了基于神经网络的风格迁移的概念证明。不幸的是，这种为单张图像施加风格的方法对计算的要求很高。比如说，在网络上首次可用的演示中，用户需要将图片上传到一个服务器，然后还要等上足够喝一杯咖啡的时间才能得到结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;后续的研究 [4,5] 为这一过程提速了不少，这些研究认识到可以将这个优化问题转变成图像变换问题（image transformation problem），其希望将单个固定的风格应用到任意一张内容图像（比如一张照片）上。然后该问题就可以这样被解决：训练一个前馈的深度卷积神经网络来调整内容图像的 corpus 以使之匹配某画作的风格。这个训练出的网络有两重目的：保持原有图像的内容，同时匹配绘画的视觉风格。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这样得到的最终结果是：一旦在一张静态图像上花了几分钟后，就可以实时运行了（例如，将风格迁移应用于实时视频）。但是，实现实时风格迁移的速度提升是有代价的——一个给定的风格迁移网络只能固定于一种单一画作的风格，失去了一些原来的算法的灵活性，因为原来的算法并不固定于任何一种风格。这意味着：如果要开发一个能够建模 100 幅画的风格迁移系统，就需要训练和存储 100 个单独的风格迁移网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;我们的贡献：学习并结合多种风格&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们开始于对印象派时期的许多艺术家的观察，采用类似的笔触和调色板。此外，说到莫奈的画，视觉上更是相似。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9ud9Ce5mvD8vXXnwE6wtH7PdZj9hUXXlLGeXmpBXib5UGYLBmn2g9Zp3YzicZsbVAED8Uh7U4MiczhA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Poppy Field (左) 和 Impression, Sunrise (右) by Claude Monet&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们在机器学习系统的训练中用到了这一观察。也就是，我们训练一个能够捕捉且概括众多莫奈作品、或者其他流派不同画家作品的单个系统。产生的 &lt;span&gt;pastiche &lt;/span&gt;足以媲美之前工作产生的画，同时源自同样的风格迁移网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9ud9Ce5mvD8vXXnwE6wtH7QPanSDuj6JxCcrbibLRMNia7WsTGyqqXY98ia6AXR7GSOAJosZ1bRo10Q/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;由我们的单网络产生的 &lt;span&gt;pastiche &lt;/span&gt;实在 32 个不同的风格上训练得到的。这些画质量上等同于由单风格网络创造的作品。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们开发的该技术简单易部署，也不需要密集的存储。此外，我们的网络在数个艺术风格上进行训练，允许实时结合多个绘画风格，就像文中视频展示的那样。下面就是 4 种风格按不同比例结合的成果：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9ud9Ce5mvD8vXXnwE6wtH70qy0tMKiafOoGEZLT8nnPDAqibhKwDNuGmFsrSFKddeyhtCaDrHibFB8g/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不像之前快速迁移风格的方法，我们认为这种同时建模多种风格的方法开启了一种让用户与风格迁移算法交互的新方式，不仅是允许基于多个风格的混合进行自由创造，而是这个过程是实时的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;关于该算法的细节和运行该模型的 TensorFlow 源代码将在未来发布。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;论文：A Learned Representation For Artistic Style&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：绘画风格的多样性对构建图像而言代表丰富的视觉词汇。如果不是通常画像，学习或捕捉这些视觉词汇的程度表达出了我们对更高层次绘画的理解。在此研究中，我们调查了如何构建单个、可延展深度网络，能够贪婪的捕捉不同派别的艺术风格。我们证明这样的网络能够通过将一种绘画降低到到嵌入空间的一个点，从而概括不同的艺术风格。重要的是，该模型允许用户通过任意结合单个绘画的风格来探索新的绘画风格。我们希望这项研究能够为迈向建立丰富的绘画模型提供帮助，也希望在艺术风格表征学习的建构上提供一个窗口。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;References&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[1] Efros, Alexei A., and William T. Freeman. Image quilting for texture synthesis and transfer (2001).&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[2] Hertzmann, Aaron, Charles E. Jacobs, Nuria Oliver, Brian Curless, and David H. Salesin. Image analogies (2001).&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[3] Gatys, Leon A., Alexander S. Ecker, and Matthias Bethge. A Neural Algorithm of Artistic Style (2015).&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[4] Ulyanov, Dmitry, Vadim Lebedev, Andrea Vedaldi, and Victor Lempitsky. Texture Networks: Feed-forward Synthesis of Textures and Stylized Images (2016).&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[5] Johnson, Justin, Alexandre Alahi, and Li Fei-Fei. Perceptual Losses for Real-Time Style Transfer and Super-Resolution (2016).&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 27 Oct 2016 12:10:56 +0800</pubDate>
    </item>
    <item>
      <title>深度 | NVIDIA CEO黄仁勋解读智能工业革命：基于GPU的深度学习大爆炸</title>
      <link>http://www.iwgc.cn/link/3247858</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Nvidia&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：黄仁勋&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：武竞、王旭雯、杜夏德&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;随着深度学习的兴起，支持大规模并行计算的 GPU 已经成为人工智能发展的重要硬件基础。作为 GPU 行业的领军者，NVIDIA 公司最近以来一直在推动应用于机器学习的 GPU 技术的发展和创新。近日，NVIDIA 联合创始人兼 CEO 黄仁勋（Jen-Hsun Huang）在 NVIDIA 博客上发表了一篇题为The Intelligent Industrial Revolution（智能工业革命）的文章，解读了自己在最近的 GPU Technology Conference（GTC）会议上的所讲所学所见以及对计算发展的未来的看法。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;过去六个星期，NVIDIA 搞了一个世界巡回的开发者大会。GPU 技术大会（GTC）于 2009 年开始，旨在促进使用大规模并行处理的 GPU 来开发高性能计算的新方法。GTC 已经成为 GPU 深度学习的中心——这个新的计算模型引发了现代人工智能的大爆炸。人工智能正在像野火一样蔓延。GPU 深度学习开发者的数量在短短两年内就跃升了 25 倍。已经有大约 1500 个人工智能创业公司出现。这种爆炸式增长刺激了世界各地对 GTC 大会的需求。到目前为止，我们已经在北京、台北、阿姆斯特丹、东京、首尔和墨尔本举办过活动。华盛顿定于本周举办大会，孟买定在下个月举办。我参加了其中 4 场 GTC 大会的开幕式。人工智能是下一个计算浪潮，给一个又一个行业带来了革命，关于它，下面是我在大会上的所讲所学，以及我对不久未来看法的总结。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9ud9Ce5mvD8vXXnwE6wtH7LrG8TV2htQzm8ay0O3Xh2nvlwFty8Blic9TvhbKxSicqPQO7qhMvbgBA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;计算的新时代&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;由人工智能计算机驱动的智能机器可以学习、推理和与人互动已经不再是科学幻想的场景。今天，由人工智能驱动的自动驾驶汽车可以找到路，并曲折地穿过夜间的乡村道路。人工智能机器人可以通过反复尝试来学习运动技能。这是一个不同寻常的时代。在我 30 年的计算机行业生涯中，没有什么比这个有更多潜力、更有趣的了。人工智能的时代已经开始。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;计算机行业推动了大规模的工业和社会变革。随着计算机行业的发展，成立了新公司，创造出新产品，我们的生活因此而改变。回顾过去几轮计算浪潮，每一个背后都有革命性的计算模型来支撑，在当时，这个计算模型架构扩展了计算能力和计算范围。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 1995 年，PC-Internet 时代是由低成本微处理器（CPU），标准操作系统（Windows 95）和一个新的信息门户（Yahoo!）的集成引发的。PC-Internet 时代给大约十亿人带来了计算能力，实现了微软将「计算机放在每一个桌子和每个家庭」的愿景。十年后，iPhone 在我们的口袋里放了一个「互联网通信」设备。加上亚马逊 AWS 的推出，Mobile-Cloud 时代诞生了。大量应用程序走进我们的日常生活，有约 30 亿人因此享受移动计算提供的自由。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今天，我们站在下一个时代的开端，人工智能计算时代，被一个新的计算模型——GPU 深度学习——点燃。这种新模型——其中深层神经网络被训练以识别大数据中的模式——已被证明能「不可理解的」高效解决计算机科学中的一些最复杂的问题。在这个时代，软件可以自己编写，机器可以自己学习。不久之后，数以亿计的设备将注入智能。人工智能将彻底改变每个行业。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;GPU 深度学习「大爆炸」&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为什么是现在？我在早前的博文（「Accelerating AI with GPUs: A New Computing Model」）中提到，2012 年将是人工智能标志性的一年。多伦多大学的 Alex Krizhevsky 创建了一个深度神经网络，能够从一百万个样本中自动学习识别图像。在 NVIDIA GTX 580 GPU 上仅仅用了几天的训练，「AlexNet」就赢得了那一年的 ImageNet 比赛，打败了所有人类专家磨炼了几十年的算法。同一年，在意识到更大的网络、更大的大脑、更多的学习之后，斯坦福大学的吴恩达和英伟达研究院（NVIDIA Research）组队开发使用大型 GPU 计算系统来开发训练神经网络的方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9ud9Ce5mvD8vXXnwE6wtH7kZ99Bw0Wgk7icWjaribVOm1LPWAE4GibHhkgClRubCUj3wqeicwfFb5X6A/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;世界开始关注到这一点了。各个地方的人工智能研究者都转向了 GPU 深度学习。百度、谷歌、Facebook 和微软最先用它来进行模式识别。到了 2015 年，他们开始实现「超人类」的结果——一台计算机识别图像的能力比人类还要高。在语音识别领域，微软研究院（Microsoft Research）使用 GPU 深度学习使对话语音达到了和人类相同的水准，实现了历史性的里程碑。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图像识别和语音识别——GPU 深度学习已经为机器学习、感知、推理和解决问题提供了基础。GPU 的使用从模拟人类想象引擎开始，魔术般地跳跃到视频游戏和好莱坞电影中惊人的虚拟世界里。现在，英伟达的 GPU 能够运行深度学习算法，模拟人类智能，作为计算机、机器人和自动驾驶汽车的大脑，感知并理解这个世界。就像人类想象和智能是连在一起的一样，计算机图形和人工智能在我们的架构中也是一同运作的。人脑有两种模式，GPU 也有两种模式。这或许就解释了为什么英伟达的 GPU 被广泛用于深度学习，英伟达也逐渐成为大家熟知的「人工智能计算公司」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;一种用于新计算模型的端到端平台&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;作为一个新的计算模型，GPU 深度学习正在改变软件的开发过程和运行方式。过去，软件工程师创造了程序并精心编码算法。现在算法能从成堆的现实世界的例子学习，软件可以自己编写出来。编程实际上是编码指令，深度学习就是创建和训练神经网络。这个网络可以被部署到数据中心，通过学习大量新数据来执行推断（infer）、预测和分类工作。网络还能被部署到如相机、汽车和机器人之类的智能设备中来理解世界。有了新的经验后，新数据会被收集来进一步训练和精炼这个网络。从数十亿的设备中学习能让网络上的设备变得更加智能。神经网络会收益于 GPU 处理和大型网络效应的指数增长。也就是说，它们会以一种比摩尔定律更加快的方式变得更加聪明。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9ud9Ce5mvD8vXXnwE6wtH7HnbI7iaQmwJYeicnFEXRYBA3EdFib1FhbMC6Fgpxic6czEEe3lkJsyCoibw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;旧有的计算模型是「指令处理」密集型的，而这种新的计算模型须要海量的「数据处理」。为了推进人工智能的全面进展，我们正在建立一个端到端的人工智能计算平台，一个能够跨越训练、接口以及数十亿设备的架构很快就会出现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们从训练开始。我们的新 Pascal GPU，投入 20 亿美元，动用了数千名工程师，花了三年时间才弄好。它是第一台用于深度学习的经过优化的 GPU。Pascal 训练的网络比 Kepler GPU（Alex Krizhevsky 在这篇论文中使用的 [1]）训练的网络要大 65 倍，而且速度更快。一个单一的配备 8 个 Pascal GPU 与 NVLink 连接的计算机，创造了有史以来吞吐量最高的互连，训练网络的速度比传统的服务器快 250 倍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9ud9Ce5mvD8vXXnwE6wtH7fsM8jAsFfVwjY2b3bz9RyN7uhXTfgU4ugUnJjkjoWibzAsD9p7mwDYA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;很快，每天数百亿个来自互联网的请求（queries）都会需要人工智能，也就意味着，每个请求将需要超过数十亿词数学运算。云服务上的总装载量需要足够大以保证实时响应。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有了更快的数据中心推理性能，我们发布了 Tesla P40 and P4 GPUs。P40 将数据中心的推理吞吐量加速了 40 倍。P4 仅需要 50 瓦的电源，设计用于加速 1U OCP 服务器，典型的超大规模数据中心。软件是英伟达深度学习平台中重要组成部分。在训练上，我们有 CUDA 和 cuDNN。在推理（inference）上，我们发布了 TensorRT，一个优化的推理引擎。TensorRT 通过在一个层内和跨层融合操作，修剪低贡献权重，降低 FP16 或 INT8 的精确度，以及其他多个技术，在不影响精度的情况下，提升了性能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;终有一天，数十亿个智能设备会利用深度学习来实现看似智能的任务。无人机会自动导航飞到仓库，寻找并拿到特定的物品。便携的医药器械会利用人工智能当场检测血液样本。智能相机能够学会仅在我们关心的情景中提醒我们。我们创造了高效能的人工智能超级计算机，Jetson TX1，应用到那些智能物联网设备中。只有信用卡大小的模块，Jetson TX1 可以仅用 10 瓦的电源，达到 1TeraFLOP FP16 的工作性能。它和我们最强大的 GPU 拥有相同的构架，并且可以运行所有相同的软件。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;简单地说，我们提供了一个端到端的人工智能计算平台——从 GPU 到深度学习软件和算法，从训练系统到车内的人工智能计算机，从云到数据中心到 PC 到机器人。NVIDIA 的人工智能计算平台无处不在。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;适用于所有领域的人工智能计算&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们端到端的平台是保证每个领域都能接入人工智能的第一步。NVIDIA GPU 深度学习下的全球生态系统正在快速扩张。突破性的成果引发了一场将人工智能运用到消费者网络服务的竞争——搜索、识别、推荐、翻译以及更多。云端服务供应商，从阿里巴巴、亚马逊，到 IBM 和微软，让大大小小的公司都用上了 NVIDIA GPU 深度学习平台。全球最大的企业技术公司已经在基于英伟达的 GPU 配置服务器。很高兴能够在我们的 GTC 巡回中强调我们在重要领域中的战略：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能交通：交通是一个人工智能可以改变的，价值 10 万亿美元的产业。无人驾驶车辆可以减少事故，提升卡车和出租车的效率，使得新的移动服务成为可能。我们宣布百度和 TomTom 均选择 NVIDIA DRIVE PX2 用于无人驾驶车辆。对它们每家公司，我们都会建立一个包含高清地图，人工智能算法和人工智能超级计算机的「云端-车」的平台。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;驾驶是我们学习获得的第二天性，但我们目前还不能让计算机学会开车。无人驾驶要求每个方面都能做到人工智能——感知环境，合理地决定环境的状态，计划行动的最佳过程。同时，也持续学习以提升对于这个多样化世界的认识。大范围的无人驾驶需要一个开放的，可升级的构架——从高速路上自动巡航，到自主驾驶到目的地，到没有司机的全自动公共汽车。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9ud9Ce5mvD8vXXnwE6wtH7PccPIbgHiacVlX6cxC3U0ciaBpdc1lqShb5bfhHF3kMlIpCqw2LjLrbA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;NVIDIA DRIVE PX2 是一个用于自动驾驶的可升级架构，包含了整个范围的人工智能技术。在 GTC，我们发布了 DRIVE PX 2 AutoCruise 专为高速公路上自动驾驶设计，带有持续定位和地图。我们还发布了 DriveWorks Alpha 1，我们无人驾驶车上的操作系统几乎涵盖了无人驾驶的所有方面——侦查，定位，计划路线，行动。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们将所有的功能集中在我们的无人驾驶车 NVIDIA BB8 上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;NVIDIA 着重在视觉处理的交叉点的创新，以及人工智能和高性能的计算——一个在智能和自主的机器核心的特殊结合。这是第一次，我们有了让无人驾驶车辆和自主机器人成为可能的人工智能算法。但它们需要一个实时的，有成本效益的计算平台。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 GTC，我们介绍了 Xavier。Xavier 是我们有史以来做过的最有雄心的单片机，是世界第一个人工智能超级计算机芯片。Xavier 有 7 亿个晶体管——比起最先进的服务器级别 CPU 更复杂。但神奇的是，Xavier 和今年早些时候在 CES 发布的 DRIVE PX 2 有相同的马力——每秒钟 20 万亿次深度学习的操作——仅用 20 瓦的电源。像 Forbesnoted 一样，我们加倍生产了带有 Xavier 的无人驾驶车。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;人工智能企业&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：IBM，一个在认知计算领域看到价值二十亿美元机会的公司，发布了新 POWER8 和 NVIDIA Tesla P100 服务器，它们均是为将人工智能带入企业而设计的。在软件上，SAP 声称他们已经收到了了 2 台第一批的 NVIDIA DGX-1 超级计算机，并正在为 190 个国家的 320，000 个消费者建立机器学习的企业解决方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;人工智能城市&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：到了 2020 年，世界上将会有 10 亿台相机。Hikvision 是全世界检测系统的领导者，它正在运用人工智能让我们的城市更加安全。它用 DGX-1 进行网络训练，现已在 16 Jetson TX1 中央处理器上建立了一个突破性的服务器，叫做「Blade」。Blade 只需要基于 21 个 CPU 的服务器的 1/20 的空间和 1／10 的能量就可以达到相同的性能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;人工智能工厂&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：在全球范围内已有 20 亿左右的工业机器人。日本是机器人创新的中心。在 GTC，我们宣布 FANUC，一个日本的工业机器人巨头，将会在 NVIDIA 人工智能平台上建造一个端到端的未来工厂。它的深度神经网络将由 NVIDIA GPU 来训练，GPU 驱动下的 FANUC Fog 单元将控制一群机器人，让他们能够共同学习。每个机器人都会植入 GPU，使之成为实时人工智能。麻省理工技术评论对他的故事这么写到：「日本的机器人巨头为它的武器加上了大脑」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;创业公司的爆发是人工智能横扫各个产业的又一指示。Fortune 最近写到，深度学习会「改变美国的大公司」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9ud9Ce5mvD8vXXnwE6wtH7dR8B1mKFedIv4S8msicYlA4b83t41NCYSALiaSsvMlDd6Fprxv7I880g/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能可以提前解决我们能力范围外的问题。从现实生活中的数据，计算机可以学会认识那些对于人工编写的软件甚至是人来说太复杂、太巨大或太微小的图案。通过 GPU 深度学习，这个计算机模型现在已经被熟练应用在解决世界上最大的产业的问题上。无人驾驶汽车将会改变 10 万亿美元的交通运输业。在医疗保健上，医生可以使用人工智能帮助你更早发现疾病、或是了解人类基因组的奥秘去治疗癌症、又或是从大量的药物数据和研究中学习，向你建议最好的治疗方法。人工智能会开创第四次工业革命——继蒸汽机、大规模制造和自动化之后——智能机器人会引领巨大的生产力提高的新浪潮，为大规模客户定制化提供了可能。人工智能将会触及每一个人。人工智能的时代已经到来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 27 Oct 2016 12:10:56 +0800</pubDate>
    </item>
  </channel>
</rss>
