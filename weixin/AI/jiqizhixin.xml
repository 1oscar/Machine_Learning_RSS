<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>机器之心</title>
    <link>http://www.iwgc.cn/list/670</link>
    <description>人与科技的美好关系</description>
    <item>
      <title>重磅论文 | 解析深度卷积神经网络的14种设计模式（附下载）</title>
      <link>http://www.iwgc.cn/link/3377505</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自arXiv.org&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀、武竞、李泽南、蒋思源、李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;这篇论文的作者是来自美国海军研究实验室的 Leslie N. Smith 和来自美国马里兰大学的 Nicholay Topin，他们在本论文中总结了深度卷积神经网络的 14 种设计模式；其中包括：1. 架构结构遵循应用；2. 扩增路径；3. 努力实现简洁；4. 增加对称性；5. 金字塔形状；6. 用训练数据覆盖问题空间；7. 过训练；8. 增量特征构造；9. 规范层输入；10. 可用资源决定网络深度；11. 转换输入；12. 求和连接；13. 下采样过渡；14. 用于竞争的 MaxOut。该论文已被提交到了 ICLR 2017。论文原文可点击文末「阅读原文」下载。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;摘要&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;深度学习领域近来的研究已经产出了大量的新架构。与此同时，也有越来越多的团队在将深度学习应用到新的应用和问题上。这些团队中的许多都可能是由没有经验的深度学习实践者构成的，他们可能会对让人眼花缭乱的架构选择感到困惑，因此会选择去使用一个更古老的架构，如 AlexNet。在这里，我们尝试挖掘近来深度学习研究中包含的集体知识（collective knowledge）以发现设计神经网络架构的基本原理，从而帮助弥合这一差距。此外，我们还描述了几种架构创新，其中包括 Fractal of FractalNet、Stagewise Boosting Networks 和 Taylor Series Networks（我们的 Caffe 代码和 prototxt 文件将会在被 ICLR 接受后公开）。我们希望这项初步的工作能够激励进一步的研究。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1.引言&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最近，关于新型神经网络架构的文章已经出现了很多，特别是关于残差网络（Residual Network）的，比如 He et al. (2015; 2016); Larsson et al. (2016); Zhang et al. (2016); Huang et al. (2016b)。这促使我们在一个更高的层面上来看待这些架构——将这些架构看作是普遍设计原理的潜在来源。这是相当重要的，因为现在有许多没有经验的实践者在想办法将深度学习应用到不同的新应用上。缺乏指导会导致深度学习实践新手忽视最新的研究而选择 AlexNet（或一些类似的标准架构），不管其是否合适他们的应用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这种研究的极大丰富也是一个机会：可以确认能为特定背景的应用带来好处的元素。我们提出了一些基本的问题：深度网络设计的普遍原理是否存在？这些原理可以从深度学习的集体知识（collective knowledge）中挖掘出来吗？哪些架构选择在哪些特定的背景（context）中效果最好？哪些架构或部分架构看起来很简洁优美？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;设计模式（design pattern）的概念最早由 Christopher Alexander (Alexander (1979)) 引入到建筑物和城镇的结构设计上。Alexander 写道：一种永恒的架构可以一直存在，这种质量可以通过基于普遍原理进行设计而实现。这种设计模式的基础是它们能在给定的背景中解决力量的冲突，并实现类似于自然生态平衡那样的均衡。设计模式既是高度特定的（使得它们可以很清楚地遵循），也是灵活的（让它们可被适配到不同的环境和情景中）。受 Alexander 的工作的启发，「gang of four」（Gamma et al. (1995)）将设计模式的概念应用到了面向对象的软件的架构设计上。这本经典的计算机科学书籍描述了 23 种可以用来解决软件设计中普遍存在的问题的模式，例如「需求总是在改变」。我们受到了之前这些在架构上的工作的启发，决定阐释神经网络架构的可能设计模式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;设计模式可以提供普遍性的指导原则，在这里我们首先要定义用于神经网络架构的设计模式。整体而言，要为所有的神经网络和所有的应用定义设计原理是一项巨大的任务，所以我们将这篇论文的范围限制在了卷积神经网络（CNN）及其基本的图像分类应用上。但是，我们认识到架构必须依赖于具备我们的第一设计模式的应用——设计模式 1：架构结构遵循应用；但相关的细节留待未来解决。此外，这些原理让我们可以发现已有研究中的一些缺陷和阐释全新的架构特征，比如 freeze-drop-path（参见 4.1 节）。这里阐述的经验法则可能对有经验的和新手的实践者都有价值。另外，我们真心希望这项初步的研究能够成为其它研究的垫脚石，能帮助其他人发现和分享其它深度学习设计模式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2.相关工作&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本节介绍和总结了其它一些神经网络架构上的相关研究工作，但由于篇幅限制，机器之心未对此节进行编译，详情请查看原论文。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3.设计模式&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;就我们所知，提供合适架构选择的指导与理解的文献资料很少。《Neural Networks: Tricks of the Trade》(Orr &amp;amp; Muller, ¨ 2003) 这本书包含了网络模型推荐，但没有参考过去几年的大量研究。与这项工作最接近的可能是 Szegedy et al. (2015b)，作者在其中描述了几种基于他们自己的经验的设计原理。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们仔细审阅了文献以提取出它们的共性并将它们的设计归结成了基本的元素——这些元素也许可被认为是设计模式。在审阅文献的过程中，我们似乎很清楚一些设计似乎是简洁优雅的，而另一些则没那么简洁优雅。在这里，我们将首先描述一些高层面的设计模式，然后再提出一些更为详细的设计模式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3.1 高层面的架构设计&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一些研究者已经指出 ImageNet 挑战赛 (Russakovsky et al., 2015) 的获胜者在不断使用越来越深度的网络（参见：Krizhevsky et al. (2012), Szegedy et al. (2015a), Simonyan &amp;amp; Zisserman (2014), He et al. (2015)）。另外在 ImageNet 挑战赛上很明显的一点是：将通过网络的路径的数量倍增是最近的一个趋势；如果看一看 AlexNet 到 Inception 到 ResNets 的演变，就能明显看到这个趋势。比如说，Veit et al. (2016) 表明 ResNets 可被看作是带有不同长度的网络的指数集合（exponential ensemble）。这引出了设计模式 2：扩增路径。开发者可以通过将多个分支包含在架构中来实现。最近的例子包括 FractalNet (Larsson et al. 2016)、Xception (Chollet 2016) 和决策森林卷积网络（Decision Forest Convolutional Networks (Ioannou et al. 2016)）。我们甚至可以更进一步预测今年的 ImageNet 获胜者也还会增加他们的架构中的分支数量，而不是继续增加深度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;科学家们已经拥抱简洁性/简约性（simplicity/parsimony）几个世纪了。简洁性的例子可参考论文「Striving for Simplicity」(Springenberg et al. 2014)，其使用更少类型的单元实现了当时最佳的结果。我们将其加为设计模式 3：努力实现简洁——使用更少类型的层以保持网络尽可能简单。我们还在 FractalNet (Larsson et al. 2016) 设计中注意到了一种特定程度的简洁性，我们将其归功于其结构的对称性。架构的对称性（architectural symmetry）通常被看作是美丽和质量的标志，所以我们在这里得到了设计模式 4：增加对称性。除了对称性以外，FractalNets 还遵循了「扩增路径」设计模式，所以它是我们第 4 节的实验的基础。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了理解相关的力量，考察权衡是设计模式的关键元素。一种基本的权衡是最大化表征的力量 vs 冗余的和非区分的信息的压缩。这普遍存在于所有卷积神经网络中，从数据到最后的卷积层，激活（activation）被下采样（downsample）并且信道数量增加。一个例子是深度金字塔残差网络（Deep Pyramidal Residual Networks (Han et al. (2016))）。这让我们得到了设计模式 5：金字塔形状，其中在整个架构中应该有一次整体的平滑的下采样，而且该下采样应该与信道数量的增长结合起来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;深度学习中另一个重要的权衡是：训练精度 vs 网络泛化到其从未见过的案例的能力。泛化的能力是深度神经网络的一个很重要的性质。一种提升泛化的方法是设计模式 6：用训练数据覆盖问题空间（Ratner et al. 2016, Hu et al. 2016, Wong et al. 2016, Johnson-Roberson et al. 2016）。这让训练精度可以直接提升测试精度。此外，正则化（regularization）常被用于提升泛化。正则化包括 dropout (Srivastava et al. 2014a) 和 drop-path (Huang et al. 2016b) 等方法。正如 Srivastava et al. 2014b 指出的那样，dropout 可通过向架构中注入噪声来提升泛化能力。我们将在训练过程使用正则化技术和谨慎的噪声注入可以提升泛化（Srivastava et al. 2014b, Gulcehre et al. 2016）的结论归结为设计模式 7：过训练（over-training）。过训练包含网络在一个更艰难的问题上训练的任何训练方法——该问题的难度超过了必要，因此在更容易的推理情况中的表现可以得到提升。除了正则化方法，设计模式 7 还包括有噪声的数据的使用（Rasmus et al. 2015, Krause et al. 2015, Pezeshki et al. 2015）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3.2 细节上的架构设计&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;很多更成功的架构的一个共同点是使每个层更容易完成任务。使用极深层网络（very deep network）就是这样的例子，因为任何单个层只需要递增地修改输入。这部分解释了残差网络（residual network）的成功，因为在极深层网络中，每层的输出可能与输入相似，因此将输入代替层的输出能使层更容易完成任务。这也是扩增路径设计模式背后的一部分动机，但是使每个层简化任务的想法超越了这一概念。设计模式 8 ：增量特征构造（Incremental Feature Construction）的一个例子是在 ResNets 中使用短距离跳跃（skip）。最近的一篇论文（Alain &amp;amp; Bengio (2016)）证明在深度 128 的网络中使用长度为 64 跳越会导致网络的第一部分不训练，并且导致不变化的权重，这是需要避免的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;设计模式 9：规范层输入（Normalize layer inputs）是另一个简化层任务的方法：使层输入标准化。已经显示，层输入的标准化能改善训练结果和提高准确性，但是潜在机理并不清楚（Ioffe &amp;amp; Szegedy 2015, Ba et al. 2016, Salimans &amp;amp; Kingma 2016）。Batch 标准化的论文（Ioffe &amp;amp; Szegedy 2015）将提高归因于解决内部协变量偏移问题，而流标准化（streaming normalization）的作者（Liao et al. 2016）认为这也许是其它原因造成的。我们认为标准化使所有输入样本更加平等，就好像它们通过单位转换进行缩放一样，这使得反向传播（back-propagation）训练更有效。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一些研究，如 Wide ResNets（Zagoruyko &amp;amp; Komodakis 2016），显示增加信道（channel）的数量提高了性能，但是多余的信道会产生额外的代价。许多基准数据集的输入数据有 3 个通道（即颜色 RGB）。几乎是普遍现象，CNN 的第一层的输出增加了信道的数量。设计模式 11：转换输入。增加信道的几个例子 / ImageNet 的第一层输出的数量分别为 AlexNet (96)，Inception (32)，VGG (224)，以及 ResNets (64)。直观上讲，第一层中信道数量从 3 增加是合理的，因为它允许以多种方式检查输入数据，但是不清楚使用多少个过滤器。另一个是成本与精确度的权衡。成本包括网络中的参数的数量，这直接反映在训练的计算量和存储成本中。增加信道数量会增加成本，这导致设计模式 10：可用资源决定网络深度。除了在下采样（down-sampling）时使输出数量加倍（见设计模式 13），根据内存、计算资源和期望的精确度来选择第一层的深度。深度学习的计算开销很高，每个从业者必须平衡这些成本与其应用程序的性能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3.2.1 分支连接：串联、求和/平均与 Maxout&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当存在多个分支时，有三种方法来合并输出：串联、求和（或平均）与 Maxout。目前看来研究人员对它们的看法各不相同，没有哪一种方式更具优势。在本节中，我们提出一些简单的规则来决定如何合并分支。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;求和是合并输出的最常见方法之一：求和/平均将分支间的近似工作分割，最终形成设计模式 12：求和连接（Summation Joining）。求和是残差网络的最佳连接机制。因为它允许网络计算校正项（即残差）而无需整个信号。sum 和 fractal-join（平均）之间的差异最好通过 drop-path 来理解（Huang et al.，2016）。在输入跳跃连接总是存在的残差网络中，求和能使卷积层学习残差（与输入的差）。另一方面，在具有若干分支的网络中，如 FactalNet（Larsson et al.，2016），使用均值是最佳方式，因为随着分支被随机丢弃，它可以保证输出平顺。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一些研究者似乎更喜欢串联（concatenation，例如 Szegedy et al，2015）我们相信串联对于增加池化时的输出数量是最有用的，这让我们得到了设计模式 13：下采样过渡（Down-sampling Transition）。这就是说，当池化或使用步幅（stride）超过 1 的下采样时，组合分支的最好方法是串联输出信道，它可以平滑地实现通常以下采样方式实现的信道连接和信道数量增加。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Maxout 已经被用于竞争，如本地竞争网络（Srivastava 等人，2014）和多尺度竞争网络（Liao 与 Carneiro，2015）Maxout 只选择一种激活，形成设计模式 14：MaxOut for Competition。它与求和或平均「合作」的激活方式相反，其中存在「竞争」关系，只有一个「赢家」。例如，当分支由不同大小的核（kernel）组成时，Maxout 可用于尺度的不变性，这类似于最大池化（max pooling）的平移不变性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们认为所有这些连接机制可以同时加入单独网络，不同于典型情况。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9H8eXM2kHRdtPPzmmGVKfMoZKibvyjic6RNFKY4Pqst8zLTUcMAdvyLva0m0R2oKanPbPYhX4nZfCw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 1：这是 FractalNet 模块（a）和 FoF 架构（b）。曾表示如下：卷积层粉红色，连接层（如均值）是绿色，池层是黄色，预测层是蓝色。（b）中的灰色模块表示（a）中的 FractalNet 实例。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;4 实验&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;4.1 架构创新&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本论文的重点是阐明基本设计原则，这样做的原因就是帮助我们发现一些架构上的创新，在本节中，这些创新将进一步被描绘出来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先，我们建议将求和/平均、串联和 maxout 连接机制与单一架构中的不同角色结合起来。接下来，通过增加分支的设计模式 2 来让我们能够大规模修饰 FractalNet 架构的顺序。最后按照我们称之为 Fractal of FractalNet (FoF) 网络，也就是 1b 中展示的分形模式调整模块，而不是按照最大深度来调整。该架构可将深度替换成更大数量的路径。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;4.1.1 Freeze-Drop-Path 和 Stagewise Boosting Networks（SBN）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Drop-path 是被 Huang 等引进的（2016b）. 它通过迭代训练随机移除分支路径，就好像这条路径在整个网络中是不存在的。出于对对称性的考虑，我们使用了一个叫 freeze-path 的相反的方法。我们冻结权重来达到零的学习率（learning rate），而不是在训练期间直接移除网络中的分支路径。循环神经网络领域也已经有一种类似的想法被提了出来 (Krueger et al. 2016)。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们称结合了 drop-path 和 freeze-path 效用的模型为 freeze-drop-path，这个可以在非随机情况下得到很好的解释。图 1 显示了一个 FractalNet 分形结构。我们从最左侧路径开始训练，并将 drop-path 应用到其他分支上面。这个分支的训练速度会很快，因为相对于整个网络只需要训练少量的参数。随后冻结那条分支路径的权重并激活在原来右边的一条分支路径。最左边的分支也就可以提供一个很好的近似函数，并且下一条分支也能在矫正的基础上运行了。因为下一个分支路径相比前一个包含了更多的层，所以和原来的相比更容易逼近矫正项的近似值，因此这样的分支允许网络获得更大的准确性。这样也就可以继续从左至右来训练整个网络。freeze-drop-path 将最后加入 FoF 架构（图片 1b），这个称之为梯度递增网络（Stagewise Boosting Networks (SBN)），因为它就是类似于梯度递增的（Friedman et al. 2001）。递增神经网络 (boosting neural network；Schwenk &amp;amp; Bengio 2000) 并不是个新概念，但是这个构架就是新的。在 B 部分我们将讨论测试的实施。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;4.1.2 泰勒级数网络（Taylor Series Netwroks，TSN）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;泰勒级数是一个经典的、众所周知的函数逼近方法。泰勒级数的扩展是：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;由于神经网络也是函数近似，将网络的分支（branch）看成一个泰勒级数展开的项，它可以作为 SBN 的延伸。这意味着，在求和连接单元（summation joining unit）之前使第二分支的结果平方，类似于泰勒展开中的二阶项。类似地，使第三分支立方。我们将它称作「泰勒级数网络」（TSN），并且存在多项式网络的优先级（Livni et al. 2014）和网络中的乘式项（例如 Lin et al. 2015 年的论文）。TSN 与 SBN 类比的实现细节详见附录讨论。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;4.2 结果&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该章节内的实验主要是验证上面提到的架构创新的验证，但并非完全进行测试。未来会有更完整的评估。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9H8eXM2kHRdtPPzmmGVKfMXZnhzEGhib28CCoMjV0icy0CichWxZFiaNWHSsWwz7qRNMz4B3ibGFQNRYg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;表 1：在 CIFAR-10 和 CIFAR-100 上各种架构的测试准确率对比。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9H8eXM2kHRdtPPzmmGVKfMbQeIqKibKIgUdQx91GCQEhhDgicHjlqdoFPv8bzQgjB1UbEytm6FQP2w/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 2：对比原 FractalNet 与用 Concatenation 或 Maxout 替代了一些 fractal-joins 的 FractalNet。同样展示的还有当用平均池化替代了最大池化时的测试准确度。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9H8eXM2kHRdtPPzmmGVKfM0yS5vLEpsH4qpFrOo7nanbukINFzwNe51Cy9oFHmaN7aSiaKpu5Rs0Q/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 3：对比原 FractalNet 与用 Concatenation 或 Maxout 替代了一些 fractal-joins 的 FractalNet。同样展示的还有当用平均池化替代了最大池化时的测试准确度。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;表一和图 3 接下来对比 4.1 章节中描述的架构创新的最终测试准确率的结果。最终的结果显示要比 FractalNet 基线差一点，但从 3a 和 3b 图中可以明显看到新架构训练起来要比 FractalNet 更快。FoF 架构最终测试准确率类似于 FractalNet，但 SBN 和 TSN 架构（使用 freeze-drop-path）在学习率下降的时候准确率会落后。这在 CIFAR-100 上要比 CIFAR-10 更加明显，表明这些架构可能更适合带有大量分类的应用。但是，我们也遗留下了对更多合适应用的探索，以后再做。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;5. 结论&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在此论文中，我们描述了通过研究近期深度学习论文中的新架构而发现的卷积神经网络架构的设计模式。我们希望这些设计模式对希望推进前沿结果的有经验的实践者和寻求深度学习新应用的新手都有所帮助。接下来也有许多的潜在工作可以做，一些工作我们也在此论文中有所指明。我们的努力主要限定在进行分类的残差神经网络，但希望这一初步工作能启发其他人进行循环神经网络、深度强化学习架构等等其它网络的架构设计模式的研究。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Sat, 05 Nov 2016 14:40:38 +0800</pubDate>
    </item>
    <item>
      <title>产品 | 机缘巧合诞生的讯飞语音输入法，如何累积了 4 亿用户？</title>
      <link>http://www.iwgc.cn/link/3377506</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心原创&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：虞喵喵&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 10 月 18 日的锤子发布会上，除焦点 M1L 之外，语音输入部分惊艳了不少观众。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;台上的老罗对着手机说出「今天上午，我们一行人从火车站来到了洲际酒店」，被迅速识别转换成文字出现在手机屏幕上。接着，老罗开始「长时间的胡说八道」，讲了一段自己没吃晚饭不舒服、吃药、喝冰水、来不及去医院、直接上发布会的过程。16 秒不间断的高语速大段口语内容，不到 1 秒便准确呈现在屏幕上，现场雷鸣般的掌声和欢呼声久久不能平息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9H8eXM2kHRdtPPzmmGVKfMxbh2TeZWg3qUm2RA8jy7sR6ZInPM1SjicVGU2HaWibdQ3xtUkMkUOCyw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;老罗现场「胡说八道」的内容&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;老罗的现场演示展示出语音输入的便捷、可靠与高效。支持这一切的，正是讯飞输入法的语音输入功能。自 2010 年发布以来，讯飞输入法已累积超 4 亿用户，活跃用户超 1.1 亿。据称，随着深度学习技术的不断突破和应用，其语音识别准确率高于 97%，1 分钟可识别 400 字。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 11 月 2 日的讯飞输入法沟通会上，讯飞输入法产品总监翟吉博分享了讯飞输入法背后的故事，包括这是一个最初仅 4 人的「小项目」、涟漪效应为这款输入法带来的提升、以及他们对输入法这一产品的思考。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;三个月，四个人&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2010 年 6 月 8 日，苹果发布了拥有「100 多项创新设计」的经典产品 iPhone 4，引发全球排队购机热潮。据称，iPhone4 的全球销量虽次于诺基亚「神机」1100，但总销售量也超过 1 亿大关。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不过 iPhone 4 屏幕仅为 3.5 英寸。虽说在当时已经算「大屏」，但现在看来也不过是 iPhone7plus 屏幕的二分之一，用全键盘打字时仍有不少困难。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;既然用手指输入文字体验不好，可不可以用语音输入？当时做语音相关工作的翟吉博「基于纯技术的思维，将手写输入、语音识别和拼音放在一起，做出了输入法的 Demo」。虽然自己不以为意，但当时的上司看到成果，认为这个产品应该让更多人使用。于是技术出身的翟吉博，开始了学习了解市场、分析用户需求，成为了一名「产品经理」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9H8eXM2kHRdtPPzmmGVKfMSaDlEs69wEmkljRNLicP2twtyVyPsUxoKLKKnn5tWzgpso2gxLrjhMw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;通过讯飞听见，嘉宾分享的内容可以实时呈现在屏幕上&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2010 年 10 月，在 iPhone4 发售 4 个月后，讯飞输入法正式上线。6 年积累，曾经由 4 人小团队封闭 3 个月打造的产品，已经牢牢占据各大应用商店输入法类下载量第二。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为什么是讯飞？回想这款输入法出现的时机，虽然 PC 上已有搜狗输入法、百度输入法等相关产品，但移动端市场还处在前期，针对手机端优化的输入法还是空白。「我们认为手机端的输入方式会发生变化，语音交互的比重会越来越大。而且语音输入已经达到可使用的基本门槛，加上对涟漪效应的理解，我们认为通过几年的时间，讯飞输入法可以成熟。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如今的讯飞输入法团队成员，最开始多是热心用户。曾在论坛里吐槽功能不好用、给产品经理提建议的粉丝成为了讯飞输入法的运营经理，机锋论坛里做 ROM 的「大神」正在负责起渠道推广。曾在电脑城卖过光盘、做过网站，因设计输入法皮肤获奖的用户，也成为了讯飞输入法的专职皮肤设计师。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;如何获取更多用户？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;满足了使用的基本需求后，如何让更多人使用这款产品？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;经过细致的思考和调研，翟吉博团队发现用户在使用语音输入时有四种需求需要被满足：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先是网络，当时的讯飞输入法需要调用云端极度依赖网络，但移动互联网并不稳定，用户对流量也很敏感；其次是方言，不同方言区的用户的特殊词难以被识别；再其次是个性化语言，不同的人有不同的语言习惯、说话方式和自己的惯用词汇；最后是跨语言交流，让不同语言的人可以通过文字互相了解，方便沟通。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过推出离线版、方言版、学习个人习惯和中英文实时翻译等版本和功能，讯飞输入法不断满足着这些需求。目前讯飞输入法支持包括粤语、东北话、河南话、四川话能在内近 20 种方言，「秃噜皮儿」、「辣子」等名词都能被迅速识别；选择中英文翻译功能，对准话筒说中文，屏幕上会自动翻译为英文。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9H8eXM2kHRdtPPzmmGVKfMm1TsaHFtia5CN7SEicPnGWEibhYNFjEWu7Ux9Q0ksAKukNCceQDBukj7w/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;产品总监翟吉博现场展示方言版效果，「巴适」、「马路牙子」都能识别出来&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除此之外，为满足明星粉丝用户的需求，推出了明星皮肤和图片；为满足二次元用户，可以用讯飞输入法上轻松打出颜文字，甚至还有斗图功能……&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这大概是对用户最友好的输入法了。作为高依赖度的工具类产品，获得 4 亿累计用户，1.1 亿活跃用户似乎也就不足为奇。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;为什么识别得快又准？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;世界上最早的语音识别系统是由 AT&amp;amp;T 贝尔实验室开发的 Audrey，可以识别 10 个英文数字。到了 1960 年代，人工神经网络被引入语音识别，两大突破是线性预测编码（Linear Predictive Coding，LPC) 与动态时间弯折（Dynamic Time Warp），不过大都是基于单词、孤立词或是特例人的研究。上世纪 80 年代末，李开复实现了基于隐马尔科夫模型的大词汇量语音识别系统 Sphinx，才完成了语音识别向随机内容、非特例人的句子识别的转变。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;直到 2010 年，深度神经网络技术开始应用于语音识别，识别的效果和速度才得到了跨越式的提升。通过海量训练语料基础上的高精度声学模型和语言模型训练，结合解码引擎工程技术，人工智能技术的加入给语音识别带来全新的发展前景。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9H8eXM2kHRdtPPzmmGVKfMd3tajJ4gmMOGlKMjiacYEoQ0mVyUDjDyyO7YPXvMW0SQY0WJtrs1W9Q/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;主流语音识别系统框架&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不过仅有核心技术的提升是不够的，对于深度神经网络来说，真实的数据就是养料和智慧。科大讯飞轮值总裁胡郁曾用「涟漪效应」解释过数据和技术应用的关系：当某一项核心技术刚刚被大众所使用时，就像一滴水滴入水面，水波纹的起伏就是核心技术与用户期望之间的误差。水波纹逐步传播，就像核心技术正在逐步被更多的用户所使用，虽然这时效果还不太好，接触到的用户也不多，但这些用户不知不觉中贡献的经验和数据已经被系统自动学习和更新。当水波纹向外扩散，接下来接触到核心技术的人已经在使用更新过的系统。随着使用的人群越来越多，水波纹扩散的越来越广，大家会发现其实水波的振幅也越来越小，系统的性能也大幅提高。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;正是 6 年间用户不断的贡献真实数据，才让讯飞输入法达到了「语音输入通用识别率为 97%，正常的语音输入文字已经不再有很大障碍」的程度，用户体验也在这一过程中逐步提升。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除了语音识别，讯飞输入法的手写识别部分也用到了神经网络和图像识别技术，还可以支持连续书写的文字识别。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这样一个「低头时代」，又会有多少人选择语音输入？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;答案可能远比想象的多。讯飞输入法后台数据显示，虽不是主要输入手段，语音输入的用户比例一直在提升，已经接近手写输入的比例。在这个追逐效率的时代，选择语音输入的用户大概会越来越多。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以及，如果真的很忙来不及发文字，可以考虑试一试语音输入。毕竟在微信上收五条 60 秒语音的经历，有过一次就不想再有一次啦。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心原创，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Sat, 05 Nov 2016 14:40:38 +0800</pubDate>
    </item>
    <item>
      <title>业界 | DeepMind牵手暴雪：要让人工智能征服星际争霸</title>
      <link>http://www.iwgc.cn/link/3377507</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Bloomberg&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Jeremy Kahn&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李泽南、蒋思源&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;谷歌的 DeepMind 团队在今年 3 月刚刚使用 AlphaGo 击败了围棋世界冠军李世乭，现在他们终于把注意力转向了经典即时战略游戏《星际争霸 2》。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;DeepMind 刚刚在一年一度的 Blizzcon 上宣布他们与著名游戏公司暴雪达成了协议，在《星际争霸》系列游戏中进行合作，这家隶属谷歌的公司将在游戏平台中引入机器学习方法，进行人工智能研究。DeepMind 总部位于伦敦，在 2014 年被谷歌以 4 亿英镑巨资收购。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前，DeepMind 还没有宣称自己的程序已经能够玩《星际争霸》了。「要打败人类职业选手，我们还有很长的路要走。」DeepMind 科学家 Oriol Vinyals 说道（此人曾是西班牙顶尖的星际争霸玩家），但公司在活动上的声明表示现在他们正像对待围棋一样认真对待《星际争霸》，并决心以此作为机器智能研究的突破点。&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;《星际争霸》一直被人工智能研究者视为下一个目标，因为它相比国际象棋与围棋更接近「复杂的现实世界」，Vinyal 表示：「能玩《星际争霸》的人工智能必须能够有效利用记忆，能够进行长期战略规划，同时还得根据不断出现的新情况做出反应调整。以这种标准开发的机器学习系统，最终完全可以应用到现实世界中的任务中去」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;双方的合作目前仍在开始阶段，暴雪《星际争霸 2》首席制作人 Chris Sigaty 说道：「目前我们正在进行一系列讨论。」他同时表示目前《星际争霸 2》的电脑玩家与 DeepMind 想要实现的人工智能系统有很大区别：「它们的设计难度不在一个级别上，游戏中的电脑玩家其实有一点「作弊」，因为它可以得知人类玩家无法知道的信息，例如电脑可以在同一时间向所有单位发出指令，即使对于你来说有些单位「不在屏幕中」。暴雪制作电脑玩家的目的是创造一个比人类更强的 AI 玩家，同时保证它受到游戏规则的约束。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;虚拟扩张&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在《星际争霸》里，游戏实时在线进行，玩家需要从三个种族之中选择一个进行游戏，每个种族都有不同的优缺点。玩家在游戏中必须掌控生产，探索地图，开采水晶和气矿，然后开拓新的矿点。富有经验的玩家会记住地图中的大量信息以获得优势，即使地图还未被探索。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;玩家的视角下，对手的信息是有限的——这与围棋这样的棋盘游戏不同。而且，不像棋类游戏的回合制玩法，机器学习系统在即时战略游戏中需要不断适应变化的环境。《星际争霸》需要玩家能够同时具有长期战略规划与应变对手的快速决策能力——设计能够同时处理这两种类型任务的系统对于研究人员来说是一个巨大的挑战。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Facebook 和微软的行动&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Facebook 和微软的人工智能研究者们都已发表过人工智能在《星际争霸》一代中进行游戏的研究。一些玩《星际争霸》的机器人已经被开发出来，但目前这样的程序距离击败人类职业玩家还相去甚远。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;微软 CEO 萨提亚·纳德拉对谷歌在人工智能研究中注重游戏的路线进行过抨击，他曾在 9 月份亚特兰大的一次活动中告诉观众「微软不会把钱花在让人工智能在游戏中击败人类」，微软希望把人工智能「用在解决急迫的社会与经济问题上去」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;电子游戏一直是人工智能研究和测试的重要组成部分。在二十世纪九十年代中期，IBM 的超级计算机「深蓝」数次击败了国际象棋世界冠军卡斯帕罗夫。后来到了 2011 年，IBM 的沃森人工智能在游戏《危险边缘》就击败了最优秀的人类玩家，并展示了 IBM 在自然语言处理的进展。早在 2015 年，DeepMind 就开始使用机器学习来训练人工智能玩一些复古的雅达利游戏（Atari games），并使其至少能做得和人类一样好。后来在 2016 年的三月份，DeepMind 通过另一种方法训练了 Alpha Go，并击败了围棋世界冠军李世乭。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;《星际争霸》自从 1998 年发行以来，已经积累了大量的忠实粉丝。在第一个十年里就售出了 950 多万册的原版游戏，其中超过一半的销售量出现在韩国，它在那里实在是太受欢迎了。2011 年发行的《星际争霸 2》以 48 小时内售出 150 万册打破了即时战略游戏的销售记录。让两个玩家实时互相对垒，这种方式使《星际争霸》成为首屈一指的专业视频竞赛游戏。尽管它的地位目前已被其他游戏取代，但仍然是一个重要的世界级电竞游戏。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9H8eXM2kHRdtPPzmmGVKfMrWRibw2pDuP2B29ytmnR9wyKXYYvDaIkNYewdP6DiacDc5GaBfEz4rfg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;em style="text-align: center;"&gt;&lt;span&gt;DeepMind这次的对手也许不是韩国人，在WCS2016中，美国选手Neeb获得了世界冠军&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;暴雪和 DeepMind 计划在明年第一季度发布一个新环境，对所有人工智能研究人员开放。在新界面里，《星际争霸 2》的图形将被简化以便于机器学习系统进行识别，同时他们也将开放 API，允许系统读取游戏中的数据，实现原先电脑玩家的部分功能。暴雪将在未来发布游戏 replay 文件数据集以供机器学习。DeepMind 的最终目标是让人工智能系统和人类玩家一样，通过处理视觉信息理解游戏。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;那么什么时候人工智能可以击败世界冠军呢？暴雪和 DeepMind 都对此持谨慎态度，两者都没有给出一个确切的日期，虽然 AlphaGo 的胜利比大多数人预测的要早。「我认为人工智能的支持者们会很兴奋，以至于曲解我们的话。」Sigaty 说道，所有人都十分期待这一刻。无论这需要多久时间，现在基础已经打下，《星际争霸 2》的舞台上，又一段传奇即将上演。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Sat, 05 Nov 2016 14:40:38 +0800</pubDate>
    </item>
    <item>
      <title>资源 | TensorFlow 生态系统：与多种开源框架的融合</title>
      <link>http://www.iwgc.cn/link/3377508</link>
      <description>&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Github&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;该 repository 包含 TensorFlow 与其他开源框架融合的样例。这些样例是有限的，但可以作为模板使用。用户也可以根据自己的使用情况特制这些模板。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;项目地址：https://github.com/tensorflow/ecosystem&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;内容：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;docker-Docker 配置用来在 cluster managers 上运行 TensorFlow&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;kubernetes-用来在 kubernetes 上运行分布式 TensorFlow 的模板&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;marathon-使用 Marathon 用来运行分布式 TensorFlow 的模板，在 Mesos 上部署&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;hadoop-为 Hadoop MapReduce 和 Spark 备录 InputFormat/OutputFormat 的 TFRecord 文件&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;分布式训练的常见设置&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;每个分布式训练项目都有一些常见设置。首先，定义 flags，以便于该 worker 知道其他 works 在分布式训练中扮演的角色：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;# Flags for configuring the task&lt;br/&gt;flags.DEFINE_integer("task_index", None,&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; "Worker task index, should be &amp;gt;= 0. task_index=0 is "&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; "the master worker task the performs the variable "&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; "initialization.")&lt;br/&gt;flags.DEFINE_string("ps_hosts", None,&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"Comma-separated list of hostname:port pairs")&lt;br/&gt;flags.DEFINE_string("worker_hosts", None,&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"Comma-separated list of hostname:port pairs")&lt;br/&gt;flags.DEFINE_string("job_name", None, "job name: worker or ps")&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然后，开始自己的 server。因为 worker 和 parameter servers（ps jobs）通常共享常见的程序，parameter servers 应该在此停顿，所以他们和该 server 可以结合。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;# Construct the cluster and start the server&lt;br/&gt;ps_spec = FLAGS.ps_hosts.split(",")&lt;br/&gt;worker_spec = FLAGS.worker_hosts.split(",")&lt;br/&gt;&lt;br/&gt;cluster = tf.train.ClusterSpec({&lt;br/&gt; &amp;nbsp; &amp;nbsp;"ps": ps_spec,&lt;br/&gt; &amp;nbsp; &amp;nbsp;"worker": worker_spec})&lt;br/&gt;&lt;br/&gt;server = tf.train.Server(&lt;br/&gt; &amp;nbsp; &amp;nbsp;cluster, job_name=FLAGS.job_name, task_index=FLAGS.task_index)&lt;br/&gt;if FLAGS.job_name == "ps":&lt;br/&gt; &amp;nbsp;server.join()&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;之后，代码的不同由你打算做的分布式训练的形式所决定。最常见的形式是图间复制（between-graph replication）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Between-graph Replication&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在此模式中，每个 worker 独立构建同一图。然后每个 worker 独立运行该图，只和 parameter servers 共享梯度。该设置可又下图进行解释，注意每个虚线框表示一个任务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9H8eXM2kHRdtPPzmmGVKfMU9icFb5ttxdcfsOaIgtQ29e1xdWtAH9b6t3QnhySJwhEhI1sG7CJe2g/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在为该训练模式构建图之前，你必须明令设置此设备。下面的代码显示了该设置：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;with tf.device(tf.train.replica_device_setter(&lt;br/&gt; &amp;nbsp; &amp;nbsp;worker_device="/job:worker/task:%d" % FLAGS.task_index,&lt;br/&gt; &amp;nbsp; &amp;nbsp;cluster=cluster)):&lt;br/&gt; &amp;nbsp;# Construct the TensorFlow graph.# Run the TensorFlow graph.&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;运行这些样例的需求&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了运行这些样例，Jinja 模板必须被安装：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;# On Ubuntu&lt;br/&gt;sudo apt-get install python-jinja2&lt;br/&gt;# On most other platforms&lt;br/&gt;sudo pip install Jinja2&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Jinja 是用作模板的扩展。还有其他的特定框架需求，请阅读 README 文件查看每个框架的需求。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Sat, 05 Nov 2016 14:40:38 +0800</pubDate>
    </item>
    <item>
      <title>一周论文| 文本摘要</title>
      <link>http://www.iwgc.cn/link/3377509</link>
      <description>&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;span&gt;&lt;strong&gt;引&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;文本摘要是自然语言处理的一大经典任务，研究的历史比较长。随着目前互联网生产出的文本数据越来越多，文本信息过载问题越来越严重，对各类文本进行一个“降维”处理显得非常必要，文本摘要便是其中一个重要的手段。传统的文本摘要方法，不管是句子级别、单文档还是多文档摘要，都严重依赖特征工程，随着深度学习的流行尤其是seq2seq+attention模型在机器翻译领域中的突破，文本摘要任务也迎来了一种全新的思路。本期PaperWeekly将会分享4篇在这方面做得非常出色的paper：&lt;/p&gt;&lt;p&gt;1、A Neural Attention Model for Abstractive Sentence Summarization, 2015&lt;br/&gt;2、Abstractive Text Summarization using Sequence-to-sequence RNNs and Beyond, 2016&lt;br/&gt;3、Neural Summarization by Extracting Sentences and Words, 2016&lt;br/&gt;4、AttSum: Joint Learning of Focusing and Summarization with Neural Attention, 2016&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;span&gt;&lt;strong&gt;1、A Neural Attention Model for Abstractive Sentence Summarization&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="作者" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;作者&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Rush, A. M., Chopra, S., &amp;amp; Weston, J.&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="单位" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;单位&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Facebook AI Research / Harvard SEAS&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="关键词" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;关键词&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Neural Attention, Abstractive Sentence Summarization&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="文章来源" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;文章来源&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;EMNLP 2015&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="问题" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;问题&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;这篇来自Facebook的paper的主题是基于attention based NN的生成式句子摘要/压缩。&lt;/p&gt;&lt;p&gt;&lt;a title="1" class="" rel="gallery0" style="color: rgb(37, 143, 184); max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgnYVBY4h2lIdnkAFQHjjYTsM6P0uRGicib5XMWHQl2WDqsJnMOB89YGWHroJsbzaEicB0r20iaerUNyWA/640?wx_fmt=jpeg"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="模型" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;模型&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;该工作使用提出了一种encoder-decoder框架下的句子摘要模型。&lt;/p&gt;&lt;p&gt;&lt;a title="encoder" rel="gallery0" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgnYVBY4h2lIdnkAFQHjjYTsx8La2MOcmlq0xqh13k3PlbcqriciaynHD5rMYNUe7nDXV4xibqhicAyNRQ/640?wx_fmt=jpeg"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;作者在文章中介绍了三种不同的encoding方法，分别为：&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="list-style-type: lower-alpha;"&gt;&lt;li&gt;&lt;p&gt;Bag-of-Words Encoder。词袋模型即将输入句子中词的词向量进行平均。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;CNN encoder&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Attention-Based Encoder。该encoder使用CNN对已生成的最近c（c为窗口大小）个词进行编码,再用编码出来的context向量对输入句子做attention，从而实现对输入的加权平均。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;模型中的decoder为修改过的NNLM，具体地：&lt;/p&gt;&lt;p&gt;&lt;a title="1" rel="gallery0" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgnYVBY4h2lIdnkAFQHjjYTs8blhWgkdoyBibRWTQTu0rR917ycUbUm2nTqxAleXmXFGt1SoQBJJKiag/0?"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;式中y_c为已生成的词中大小为c的窗口，与encoder中的Attention-Based Encoder同义。&lt;/p&gt;&lt;p&gt;与目前主流的基于seq2seq的模型不同，该模型中encoder并未采用流行的RNN。&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="数据" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;数据&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;该文章使用了English Gigaword作为语料，选择新闻中的首句作为输入，新闻标题作为输出，以此构建平行语料。具体的数据构建方法参见文章。此外，该文章还使用了DUC2004作为测试集。&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="简评" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;简评&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;在调研范围内，该文章是使用attention机制进行摘要的第一篇。且作者提出了利用Gigaword构建大量平行句对的方法，使得利用神经网络训练成为可能，之后多篇工作都使用了该方法构建训练数据。&lt;/p&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;br/&gt;&lt;/h1&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;span&gt;&lt;strong&gt;2、Abstractive Text Summarization using Sequence-to-sequence RNNs and Beyond&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="作者" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;作者&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Nallapati, Ramesh, et al.&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="单位" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;单位&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;IBM Watson&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="关键词" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;关键词&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;seq2seq, Summarization&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="文章来源" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;文章来源&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;In CoNLL 2016&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="问题" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;问题&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;该工作主要研究了基于seq2seq模型的生成式文本摘要。&lt;br/&gt;该文章不仅包括了句子压缩方面的工作，还给出了一个新的文档到多句子的数据集。&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="模型" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;模型&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;a title="" rel="gallery0" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgnYVBY4h2lIdnkAFQHjjYTsgtn4GR8WU5SskYLJKL7l3ct7bONsUIFebXfYEclemKRswaPr4YOHlA/640?wx_fmt=jpeg"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;该文章使用了常用的seq2seq作为基本模型，并在其基础上添加了很多feature：&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="list-style-type: lower-alpha;"&gt;&lt;li&gt;&lt;p&gt;Large Vocabulary Trick。&lt;br/&gt;参见Sébastien Jean, Kyunghyun Cho, Roland Memisevic, and Yoshua Bengio. 2014. On using very large target vocabulary for neural machine translation. CoRR, abs/1412.2007.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;添加feature。例如POS tag， TF、IDF， NER tag等。这些feature会被embed之后与输入句子的词向量拼接起来作为encoder的输入。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;pointing / copy 机制。使用一个gate来判断是否要从输入句子中拷贝词或者使用decoder生成词。参见ACL 2016的两篇相关paper。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Hierarchical Attention。这是用于文章摘要中多句子的attention，思路借鉴了Jiwei Li的一篇auto encoder的工作。大致思路为使用句子级别的weight对句子中的词进行re-scale。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="数据" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;数据&lt;/strong&gt;&lt;/h2&gt;&lt;ol class=" list-paddingleft-2" style="list-style-type: lower-roman;"&gt;&lt;li&gt;&lt;p&gt;English Gigaword&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;DUC 2004&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;提出了CNN/Daily Mail Corpus&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="简评" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;简评&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;该工作为在第一篇文章基础上的改进工作，做了大量的实验，非常扎实。文章提出的feature-rich encoder对其他工作也有参考意义，即将传统方法中的特征显式地作为神经网络的输入，提高了效果。&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;span&gt;&lt;strong&gt;3、Neural Summarization by Extracting Sentences and Words&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="作者" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;作者&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Cheng, Jianpeng, and Mirella Lapata.&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="单位" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;单位&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;University of Edinburgh&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="关键词" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;关键词&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Extractive Summarization, Neural Attention&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="文章来源" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;文章来源&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;ACL 2016&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="问题" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;问题&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;使用神经网络进行抽取式摘要，分别为句子抽取和单词抽取。&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="模型" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;模型&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;a title="" class="" rel="gallery0" style="color: rgb(37, 143, 184); max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgnYVBY4h2lIdnkAFQHjjYTsRw8Z6DNxGnR8PiaepwSNPEiaDT3ZbibCicenGHU7nU0pSOSy1HXSEV3qlA/640?wx_fmt=jpeg"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;h3 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="句子抽取" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;句子抽取&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;由于该工作为文档的摘要，故其使用了两层encoder，分别为：&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="list-style-type: lower-alpha;"&gt;&lt;li&gt;&lt;p&gt;词级别的encoder，基于CNN。即对句子做卷积再做max pooling从而获得句子的表示。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;句子级别的encoder，基于RNN。将句子的表示作为输入，即获得文档的表示。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;由于是抽取式摘要，其使用了一个RNN decoder，但其作用并非生成，而是用作sequence labeling，对输入的句子判断是否进行抽取，类似于pointer network。&lt;/p&gt;&lt;h3 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="词的抽取" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;词的抽取&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;对于词的抽取，该模型同样适用了hierarchical attention。与句子抽取不同，词的抽取更类似于生成，只是将输入文档的单词作为decoder的词表。&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="数据" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;数据&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;从DailyMail news中根据其highlight构建抽取式摘要数据集。&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="简评" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;简评&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;该工作的特别之处在于对attention机制的使用。该paper之前的许多工作中的attention机制都与Bahdanau的工作相同，即用attention对某些向量求weighted sum。而该工作则直接使用attention的分数进行对文档中句子进行选择，实际上与pointer networks意思相近。&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="AttSum: Joint Learning of Focusing and Summarization with Neural Attention" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;span&gt;&lt;strong&gt;4、AttSum: Joint Learning of Focusing and Summarization with Neural Attention&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="作者" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;作者&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Cao, Ziqiang, et al.&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="单位" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;单位&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;The Hong Kong Polytechnic University, Peking University, Microsoft Research&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="关键词" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;关键词&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Query-focused Summarization&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="文章来源" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;文章来源&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;COLING 2016&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="问题" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;问题&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Query-focused多文档抽取式摘要&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="模型" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;模型&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;a title="" rel="gallery0" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgnYVBY4h2lIdnkAFQHjjYTsybLdicPicmaSyrDzJVyMiaE7DuoRCqgWicrFCVSeG7znwicV3iaDu2Ins6rw/640?wx_fmt=jpeg"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;由于该任务为针对某个query抽取出可以回答该query的摘要，模型使用了attention机制对句子进行加权，加权的依据为文档句子对query的相关性（基于attention），从而对句子ranking，进而抽取出摘要。具体地：&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="list-style-type: lower-alpha;"&gt;&lt;li&gt;&lt;p&gt;使用CNN对句子进行encoding&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;利用query，对句子表示进行weighted sum pooling。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;使用cosine similarity对句子排序。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="数据" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;数据&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;DUC 2005 ∼ 2007 query-focused summarization benchmark datasets&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="简评" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;简评&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;该文章的亮点之处在于使用attention机制对文档中句子进行weighted-sum pooling，以此完成query-focused的句子表示和ranking。&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="总结" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;span&gt;&lt;strong&gt;总结&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;本次主要介绍了四篇文本摘要的工作，前两篇为生成式（abstractive）摘要，后两篇为抽取式（extractive）摘要。对于生成式摘要，目前主要是基于encoder-decoder模式的生成，但这种方法受限于语料的获得，而Rush等提出了利用English Gigaword（即新闻数据）构建平行句对语料库的方法。IBM在Facebook工作启发下，直接使用了seq2seq with attention模型进行摘要的生成，获得了更好的效果。对于抽取式摘要，神经网络模型的作用多用来学习句子表示进而用于后续的句子ranking。&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;广告时间&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;PaperWeekly是一个分享知识和交流学问的学术组织，关注的领域是NLP的各个方向。如果你也经常读paper，也喜欢分享知识，也喜欢和大家一起讨论和学习的话，请速速来加入我们吧。&lt;/p&gt;&lt;p&gt;微信公众号：PaperWeekly&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgkSMlEJFo90NY8rCXr3mJMBibduVHxMKSHzQtVkHz8kNwpjCKBiccGuqLE0WpPuAbdtEs6cTF5iabpAQ/640?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;微博账号：PaperWeekly（&lt;a target="_blank" rel="external" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;http://weibo.com/u/2678093863&lt;/a&gt;&amp;nbsp;）&lt;br/&gt;微信交流群：微信+ zhangjun168305（请备注：加群 or 加入paperweekly）&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Sat, 05 Nov 2016 14:40:38 +0800</pubDate>
    </item>
    <item>
      <title>深度 | 专访Facebook人工智能实验室负责人Yann LeCun：错过DeepMind也不算一件坏事</title>
      <link>http://www.iwgc.cn/link/3362551</link>
      <description>&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Business Insider&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Sam Shead&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：蒋思源、李泽南&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Yann LeCun是人工智能界的著名学者，现任Facebook人工智能研究部门的主管。就在上周，LeCun作为神经网络的先驱获得了Lovie终身成就奖，Business Insider专访了这位来自巴黎的学者。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Yann LeCun 教授是人工智能三巨头之一（另两位是 Hinton 与 Bengio），在 20 余年的研究历程中，他已累积发表了超过 180 篇论文，现在 LeCun 是 Facebook 人工智能研究机构的主管。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他最广为人知的研究在 1988 年，LeCun 参与开发了著名的「卷积神经网络」，可以识别手写数字。随着数据训练的不断持续，这种革命性的系统开始从图片像素中识别视觉特征，这就像为计算机打开了双眼，让它们可以从数据中自我学习。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们在上周 LeCun 刚刚获得 Lovie 终身成就奖之后见到了这位来自巴黎的学者，并专访了他。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：谈谈你的部门在 Facebook 中的角色吧。&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：我领导的部门：FAIR（Facebook Artificial Intelligence Research）的任务——我们总称自己为「FAIRies」——是推进人工智能的科学与技术；并通过实验发展这一技术在各个领域中的应用，如计算机视觉，对话系统，虚拟助手，语音识别，自然语言识别等等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能的背后存在很多基础科学，它们也许并不面向应用，你的研究可能也只是通向对智能和人工智能的理解。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们也同 Facebook 的另一个小组合作研究，应用机器学习团队（AML），他们的人数是我们的一半。是它们将科学转化为可见的技术，通过为公司构建应用平台，他们正将人工智能服务变为产品团队可以使用的东西。所以我得说 Facebook 里有很多人都在做着 AI 相关的工作，不仅仅是 FAIRies。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：你能说说有多少人在你的实验室里工作吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：当然，有大约 75 个人正在 FAIR 工作，就像我说的，AML 的两倍，公司中还有很多其他人处理 AI 应用方面的事务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：FAIR 的员工仅在加利福尼亚，还是遍布全球？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：有一些员工在纽约工作，我也在那里。此外，Menlo Park（Facebook 总部所在地，位于加利福尼亚州）和巴黎也有一些成员，还有一个小团队在西雅图。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWicKYha6n6vemibmx6zUztu84WAoBNicztvyb6csXhGHRTG5oOicsXdsRlB1uCsEaMgialMewh19h2e8icg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Facebook 在 Menlo Park 的总部&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：你认为 Facebook 的哪个部分可以用人工智能加以改善？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：Facebook 面临的最大问题，时刻需要解决的问题，就是我们需要将最好的内容向每个人呈现。所以你必须理解内容，理解每个人，然后把内容和对它们感兴趣的人相匹配。这是非常重要的一个方面。只有做到这一点，人们才会选择 Facebook Feed。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而在这之上，我们的远期目标，是建立一个真正的智能机器，让你可以与它直接对话，它需要能回答任何问题，并对你的生活提供帮助。这件事对于当今的人工智能而言非常具有挑战性。对话系统，自然语言识别，所有这些的基础在于让机器学会人类的常识。我们现在还不知道到底应该怎么做，但我们对此有很多想法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：所以，比如我是一个 Facebook 的用户，我厌倦了 News Feed 里面晒娃的消息，我能用自然语言告诉 Facebook 让它屏蔽这类推送吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;答：这是一种方式，但其实是一种非常不方便的方式，让人告诉 Facebook 怎么做。如果我们拥有了对话系统，你可以对它说：「请不要再推送婴儿照片了。」但是现在已有的方式是 Facebook 通过学习用户习惯知道了你不看这些图片。你或许会很快地浏览这些图片，或者点击它们但没有评论之类。所以我们已经可以通过你的习惯了解你的兴趣所在了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：你觉得目前的人工智能军备竞赛谁是赢家？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;答：没有谁跑在前面。有许多公司正在做着大量的人工智能研发，对于人才的竞争也很激烈，但现在并没有谁发明了远远领先于其他公司的新技术，我是说需要别人花费三个月以上才能赶上的新技术。我认为有三四家公司现在处于第一集团，Facebook，谷歌——特别是其中的 DeepMind，其实我的意思是 Alphabet，它已经不是谷歌的一部分了——还有微软，人工智能是他们的传统优势项目，IBM 也进步了很多。然后才是其他很多公司。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：你提到了谷歌和 DeepMind。DeepMind（以创纪录的 40 亿英镑价格被谷歌收购）开发了 AlphaGo，击败了围棋的世界冠军，我听说 Facebook 也在这一领域有所研究，当 DeepMind 超过你们的时候你是否很失望？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;不不，我们没有失望，因为这是整个人工智能领域的伟大胜利。我的一些学生和博士后参与了 DeepMind 项目。分析围棋棋盘并决定落子位置的系统实际上是卷积神经网络，这是我的发明。所以说这一成就建立在所有人的努力之上。我们 Facebook 对围棋的研究不多，基本上只有两个人在做。我们的围棋研究主要作为计划和勘探研究的载体。我们做这个，我们的系统工作得不错，然后我们把它开源了，这跟 DeepMind 的系统相比体量相差很多。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：在人才方面，你们如何保证 Facebook 可以招揽人工智能最好的人才？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：你知道，这需要和大学实验室保持良好关系，这些机构输出各类人才，进行各种可能的研究，同时项目和成果也是公开的。事实上，对于 FAIR 而言，公开性不止于可能，而是需求。假设你是一名研究者，你肯定总是想公开发表你的研究成果，对于科学家来说这很重要，因为你的地位在于学术影响。而要有影响，你不能简单地告诉人们「我正在为 FAIR 工作，但我不能告诉你们我在研究什么」，这样你的职业生涯就毁了。这很重要，我觉得在这一点上我们领先于其他公司，同时在 Facebook 你可以和世界上最棒的同事们交流。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们还在做很多事，都有关和学术界保持良好关系。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：进去工作的薪水是多少？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：哦，这是很重要的，特别是现在我们还在和微软，谷歌及其子公司竞争的情况下。但是其他的基本待遇也要给到，如果条件不够好，那么都没人愿意过来了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：你能大概告诉我们顶级 AI 从业人大概的薪水吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：不，我不能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：你的聊天机器人 M 现在怎么样了？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：最初 M 只是一个研究人们是怎样使用类人虚拟助手的试验，不过 M 的大多数工作实际上是由人类完成的。也就是说你不能把它扩展到数以百万计的用户，这也就是为什么我们把用户数量限制在很小的范围内。随着研究的进展，我们学到了很多人类会问的问题，开始让机器执行一些人类的工作，并为特定领域开发了一些相对专业的机器人，这就是它的现状。所以相对专业的机器人都是在电影，餐厅或别的什么地方。而能回答任何问题的机器人的基础研究还在网页里，比如在维基百科上，这还处于研究阶段。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：你们正在倡导与 AI 伙伴关系，Facebook 如何确保人工智能发展的伦理和安全？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：对于人工智能，现在还有一些真实存在或想象下的危险。如像终结者那样的危险情况，或者是 Nick Bostrom 书中的超级智慧（Superintelligence），你知道他说人们本来想要开发一个高效制造回形针的人工智能，最后整个银河系都会塞满回形针。这不是我们需要但有的，因为我们的技术水平还差得很远。而且现在已有各种会议，研讨会，论文等正在讨论更远未来超级智能机器的伦理问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们现在努力解决的 AI 伙伴关系问题在于如何让人工智能系统不出现偏见，比如，数据中可能会有偏见。举个例子，我们并没有驾驶自动驾驶汽车，但是如果你是在建立一个机器学习系统让它自己驾驶汽车，你就想彻底地测试它，不过由于最佳的实践方案还不完全清楚，所以我们还有很多工作要做。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：有传言说 Facebook 一度考虑收购 DeepMind，Facebook 收购 DeepMind 是一个好的选择吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;你也知道事情已经过去了，现在 DeepMind 还有很多优秀的人。我认为如果不是谷歌收购了 DeepMind，那么 DeepMind 的现状还要有很多不同的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我认为 DeepMind 的挑战就是在地理上和加州的总部所隔开了，这使得他很难将技术转化为产品。所以这也在一定程度上让 DeepMind 需要靠自己生存下去。也许它会发展一些应用，例如将 AI 运用到医疗。他们十分强调公共关系，因为这对于整个团队是很重要的。特别是他们很难自己生产应用级产品，这将对他们是个巨大的挑战。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这样一个几家公司同时为一个目标而努力的时代实在是很棒的体验，因为我们能在彼此的基础上思考问题。每当我们有个好想法，DeepMind 都会在我们想法上更进一步提升，反之亦然。有时候我们会一起工作在一个团队几天或几个月，他们基本上雇佣了我一半的学生。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：DeepMind 基本处于 Sergey Brin 和 Eric Schmidt 的掌控中，这意味着谷歌高管们强烈支持 DeepMind，这肯定能帮助 DeepMind 把技术转化为产品，对吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：研究这种先进的技术，你必须获得管理层的支持，因为基础研究的影响在比较长时间后才能体现出来。你不能幻想种下一颗种子，然后技术就自然而然地有了，突然冒出了实体产品线，商业形式发生了彻底改变。你需要来自高层的支持，因为这是一种长期投资。这不是那种我投资进去，半年后就能收回成本的事情。它需要的是有远见的人，这样的人谷歌有，Facebook 也有。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Fri, 04 Nov 2016 14:24:33 +0800</pubDate>
    </item>
    <item>
      <title>专访｜百度语音识别技术负责人李先刚：如何利用Deep CNN大幅提升识别准确率？</title>
      <link>http://www.iwgc.cn/link/3362552</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心原创&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：赵云峰&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;技术顾问：赵巍、Yuxi Li&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;近日，百度将 Deep CNN 应用于语音识别研究，使用了 VGGNet ，以及包含 Residual 连接的深层 CNN 等结构，并将 LSTM 和 CTC 的端对端语音识别技术相结合，使得识别错误率相对下降了 10% （原错误率的 90%）以上。 &lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;iframe class="video_iframe" data-vidtype="1" style="   z-index:1; " height="375" width="500" frameborder="0" data-src="https://v.qq.com/iframe/preview.html?vid=a0342d35pi3&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0" allowfullscreen=""&gt;&lt;/iframe&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器之心对百度语音技术部识别技术负责人，同时也是 &lt;/span&gt;&lt;strong&gt;Deep Speech 中文研发负责人李先刚博士&lt;/strong&gt;&lt;span&gt;进行了独家专访，李先刚博士详细解读了 Deep CNN 中的各项技术以及研究思路，并表示此次语音识别技术的提升将在接下来用于语音搜索产品。而百度正在努力推进 Deep Speech 3 ，这项研究不排除将会是 Deep Speech 3 的核心组成部分。以下是采访内容：&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：能先大体介绍一下 Deep CNN 吗？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;李先刚&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：百度这次利用深层卷积神经网络技术（Deep CNN）应用于语音识别声学建模中，将其与基于长短时记忆单元（LSTM）和连接时序分类（CTC）的端对端语音识别技术相结合，大幅度提升语音识别产品性能。该技术相较于工业界现有的 CLDNN 结构（CNN+5LSTM+DNN）的语音识别产品技术，错误率相对降低 10% 。该技术借鉴了图像识别在近些年的成果，以及语音与图像在利用 CNN 模型训练的共通性，是在端对端语音识别技术的革新之后取得的新的技术突破。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其实最早 CNN 在语音领域是有应用的，这两年语音研究专注的主要是 RNN ，而图像领域专注的 CNN 。在语音领域的研究者把 LSTM 和 RNN 做的很好之后，发现 CNN 的发展在语音领域是可以借鉴和有所帮助的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;比如从 ImageNet 竞赛中就可以看出深层卷积神经网络方面的进展。这些网络结构有一个明显的发展趋势，就是越来越深的卷积神经网络层级（CNN）：从最初的 8 层网络，到 19 层，22 层，乃至 152 层的网络结构。ImageNet竞赛的错误率也从 12 年的 16.4% 逐步降到了 3.57% 。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8E4TjIhibUIREOamYfQmmEwvVYr1IKP7et4lNAB3G09srQWvwRuJEAibr6lGTp7t8DHE6WCFHVz1tg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这个背景下，深层 CNN 成为今年语音领域前沿研究中最火的东西，很多公司都在做这方面研究。而我们这次做 CNN 有个很好的点是有个 baseline ，这是基于 Deep Speech 2 端对端基础上，进一步通过引入 CNN 来实现更好效果，这是我们的研究背景。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这个情况下，我们做了一些非常有意思的实验和希望得到最好性能的工作。为什么说最好性能呢？因为我们做的工作都是大数据，调参时有上万小时，做产品时甚至有 10 万小时。我们希望通过这些来验证，Deep CNN 是真的可以发挥作用，因为你会发现，现在很多基于数据集做的算法在大数据时可能就没用了，但我们发现它是有用的，在端到端框架下也是有用的，这可能算是我们的一个突破点和贡献。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;机器之心：微软最近也公布了一项语音识别的突破，能对比一下这两项研究吗？&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;李先刚&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：微软这次研究更加学术，是在一些标准数据库上做的，是一个口语数据库，叫做 switchboard ，数据库只有 2,000 小时。这个工作是微软研究院做的，他们的关注点是基于这样一个数据库最终能做到什么样的性能。而我们的关注点是我们的语音技术能够深入到大家的日常应用中，去把语音识别服务做到更好，我们的数据是数万小时。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;机器之心：这项研究涉及的过程和具体技术工作有哪些？&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;李先刚&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：在 ImageNet 竞赛得到广泛关注的 DeepCNN 结构，包括 VGGNet ，GoogleNet 和 ResNet 等。其中 ResNet ，可以通过 Residual 连接，训练得到一百多层的 CNN 网络，这样的网络虽然能够显著提升性能，由于其无法实现实时计算，使得其难以在产品模型得到应用。但是我们可以借鉴 Residual 连接的思想，训练一个数 10 层的包含 Residual 连接的 DeepCNN ，以用于工业产品中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8E4TjIhibUIREOamYfQmmEwRmvNJUuPTicCNV3NZ25Ccd1icZdOqj0w2kqVdvHviaVTt8OZxhXFic7JYA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8E4TjIhibUIREOamYfQmmEw8etWC0zYQxQyYCIicicj08mnpYgYzlv2d4GFkMia25mkd6RicrZc2ecavA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8E4TjIhibUIREOamYfQmmEwG70wwCLLwaaNzZvTa3zE7PsBt4U1XjxgDcZECeWxy7NK19jWnia1hfA/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;从上至下为 VGGNet 、GoogleNet 和 ResNet&lt;/span&gt;&lt;/em&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因此，百度做了以下的对比试验：1）HMM 框架中基于 VGGNet 结构的声学模型；2）在 HMM 框架中包含 Residual 连接的 CNN 网络结构的声学模型；3）在 CTC 框架中使用纯 VGGNet 实现端对端建模；4）在 CTC 框架中，在 CLDNN（CNN+5LSTM+DNN）结构中的 CNN 借鉴图像领域的研究成果，尝试 VGGNet ，包含 Residual 连接的深层 CNN 等结构。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们发现，深层 CNN 结构，不仅能够显著提升 HMM 语音识别系统的性能，也能提升 CTC 语音识别系统的性能。仅用深层 CNN 实现端对端建模，其性能相对较差，因此将如 LSTM 或 GRU的 循环隐层与 CNN 结合是一个相对较好的选择。可以通过采用 VGG 结构中的 3*3 这种小 kernel ，也可以采用 Residual 连接等方式来提升其性能，而卷积神经网络的层数、滤波器个数等都会显著影响整个模型的建模能力，在不同规模的语音训练数据库上，百度需要采用不同规模的 DeepCNN 模型配置才能使得最终达到最优的性能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因此，我们认为：1）在模型结构中，DeepCNN 帮助模型具有很好的在时频域上的平移不变性，从而使得模型更加鲁棒（抗噪性）；2）在此基础上，DeepLSTM 则与 CTC 一起专注于序列的分类，通过 LSTM 的循环连接结构来整合长时的信息。3）在 DeepCNN 研究中，其卷积结构的时间轴上的感受野，以及滤波器的个数，针对不同规模的数据库训练的语音识别模型的性能起到了非常重要的作用。4）为了在数万小时的语音数据库上训练一个最优的模型，则需要大量的模型超参的调优工作，依托多机多 GPU 的高性能计算平台，才得以完成工作。5）基于 DeepCNN 的端对端语音识别引擎，也在一定程度上增加了模型的计算复杂度，通过百度自研的硬件，也使得这样的模型能够为广大语音识别用户服务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：CNN 适用于语音识别的原理是什么，是如何带来效果的大幅提升的？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;李先刚&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：语音识别建模是需要对语音信号和文字内容间的关系建模。通常情况下，语音识别都是基于时频分析后的语音谱完成的，而其中语音时频谱是具有结构特点的。要想提高语音识别率，就是需要克服语音信号所面临各种各样的多样性，包括说话人的多样性（说话人自身、以及说话人间），环境的多样性等。卷积神经网络，由于其局部连接和权重共享的特点，使得其具有很好的平移不变性。将卷积神经网络的思想应用到语音识别的声学建模中，则可以利用卷积的不变性来客服语音信号本身的多样性。从这个角度来看，则可以认为是将整个语音信号分析得到的时频谱当作一张图像一样来处理，采用图像中广泛应用的深层卷积网络对其进行识别。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8E4TjIhibUIREOamYfQmmEwNp3MrvxXYSR2eXFdMfUyTrJSVGc1fHcJwn4SQciaszWouOdr07HCicjw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Deep CNN语音识别的建模过程&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2013 年过后，语音领域开始做 RNN ，图像领域做 CNN 。卷积操作是一种相较于全连接更加通用的计算形式，在 2013 年之后有很多进展，从 ImageNet 就可以看出来，首先发现 VGG 模型很有用，这种结构使用的是 3*3 这种小 kernel ； 此外 GoogleNet 结构，里面设计了一个 Inception 模块，也是基于 CNN 来实现的；比较有趣的是，微软 2015 年做的残差网络直接把十几层一下拉到 152 层，但 100 多层在工业上肯定没法用，因为算不过来。但这告诉大家，通过这种方式可以非常简单直接的提升性能，也就是提出了 residual 连接。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从这几个方面来看，CNN 在语音领域都没得到充分的研究，但大家能意识到这是我们可以探索的一个方向。有了这个出发点之后，我们就有好几个点可以做，比如说 VGGNet 里的 3*3 的 kernel 在语音领域应该怎么做；residual 连接怎么融合进来。我们在语音识别最早用的 CLDNN 结构是一层卷积，我把其做到 10 层，变成 VGG 结构，再加上一些残差连接，通过做一些大量实验模型的结构调整，最终得到性能提升。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8E4TjIhibUIREOamYfQmmEw8YBghpiaFhiaPhDskIZSLicDP5JV9us5S7rgxHM9wd9yHweLiadlLL1aJw/0?wx_fmt=png"/&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;语谱图&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从另外一个角度来看，如果你把语音当成一个图像，把语音视频信号分析过后就是一张图像，所以图像和语音是可以相互借鉴的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：能否介绍一下 CTC 端对端学习？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;李先刚&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：在深度学习兴起以前，机器感知算法（如语音识别，说话人识别，图像识别，等）通常都会包含以下几个部分：特征提取及学习，模式分类等。研究者们发现，在这样的级联系统里面，特征学习起到了非常关键的作用。在深度学习中，特征学习和模式分类两个模块则通常联合起来优化，从而使得通常意义下，深度学习的模型至少有两层。从而也带来了一个新的研究趋势：减少流水线中的模块，使用一个单独的学习算法来完成从任务的输入端到输出端的所有过程，也就是所谓的端对端学习的兴起。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;端对端学习使用一个算法将输入和输出联系了起来，通常采用的是一个深层的神经网络。端对端学习推崇更少的人工特征设计，更少的中间单元。端对端学习的系统包括：基于 CTC 的语音识别，基于注意机制的机器翻译，都已经在工业界得到了应用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：Warp-CTC 、Stanford CTC 和 TensorFlow 等在使用上有什么明显区别么？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;李先刚&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：我对 Stanford CTC 了解不多，但不管是哪种，我相信都是对 CTC 这种算法的功能实现，都是加速的问题。TensorFlow 不太一样，它是深度学习框架，不是针对 CTC 来做，客观来说，它的好处是方便研究者做实验预研。但坏处是速度慢。你可以在实验室里很快的尝试一个新的网络结构，做个 100 小时的实验，但如果规模上去了，TensorFlow 是不够的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：语言模型采用 n-gram models 的主要好处是什么？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;李先刚&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：n 元文法技术相对较老，但它可以很好的把规模弄上去，百度是一个文本大数据公司，在这样的背景下，你会发现基于大数据做一个很好的 n 元文法是很容易的，而且性能很好。通过这样一个大模型，通过海量数据，加上工程师做解码器的特别优化，使得系统在很好的实时性下的情况去达到很好的识别率。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;说到语言模型，还有一个研究比较多的是神经网络语言模型。对于神经网络语言模型，我们也希望能做到 first-pass decoding ，神经网络语言模型还有一些工程上的东西需要突破，我们都是把它放在第二遍 second-pass rescoring 上。总之，两者相比的话，神经网络语言模型的计算量特别大，优势是性能好。这个需要做很多工程方面的工作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：训练数据里的「模拟语音数据」和 10 万小时的精准标注语音数据对最后性能提升的贡献各有什么样的价值？如何获取「精准标注」数据？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;李先刚&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：训练模型的根本还是精确标注的数据，这是决定整个性能的基础。一般来说可以有这样的结论：数据增加十倍，性能提升10%，这是针对精准人工标注的数据。一般情况下，在获取什么样的精确标注数据的问题上，我们也会结合主动学习的思想，去收集那些对识别率影响更加直接的数据拿来人工精标。那为什么还要用模拟数据呢？所谓的模拟数据就是在精准标注的基础上做些信号变化，加一点背景噪声、混响的冲击响应，加上这些数据以后，会使模型能够见过更加多样的数据，这样对于模型的推广性和性能有一定程度的帮助，这算是一个保证模型具有更强能力的方法。所以，从根本上来说还是那 10 万小时。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：百度自主研发的硬件技术对计算效率有多少贡献？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;李先刚&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：百度开源了 Warp-CTC ，CTC 算法本质是一个前向后向算法在里面，要实现它的并行化还是比较难的，Warp-CTC 在这方面做的比较好。我们在做实验时发现，有了 Warp-CTC 这样一个高速的算法，还有我们自己内部有一个非常高效的多机训练的平台。使得我们整个模型训练的规模性比较好，当我们从一台机器扩展到十台机器，我们训练速度上的提升基本可以接近线性。有了这样的平台，才能使我们的近十万小时的模型才能做实验。否则连实验也做不了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此外，基于百度自主研发的硬件，才使得这样的计算复杂度更好的 Deep CNN 技术得以成为线上的服务。只有这些硬件技术的不断升级，才给了我们声学建模研究更大的空间。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：CNN 是目前语音领域的最新研究进展，你能介绍一下深度学习以来语音领域出现过的其他突破性研究吗？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;李先刚&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：大约是在 2011、2012 年开始将深度学习用于语音研究，最早是用最简单的前馈 DNN 模型，发现比 GMM 有 30% 的提升，大家就意思到这是一个划时代的突破。2013 年，研究者开始尝试做一些激活函数（例如ReLU，Maxout），其中的 Maxout 发现对 low-resource 的任务有帮助，对真实的大数据库不一定有显著帮助；2013-2014 年，大家开始做 CNN ，而非深层的；2014 年开始做 RNN ，尤其是 LSTM 。2014 年底 2015 年初，Hinton 的博士后 Alex Graves ，把以前做手写体识别的 LSTM 加 CTC 的系统应用在了语音识别领域，在 TIMIT 上做了结果。紧接着谷歌认为这个很有前途，就开始把这些技术推广在大数据上面。LSTM 和 CTC 引入进来之后，相较于之前的 DNN ，LSTM 能够更好的帮助模型来捕捉输入中的重要的点，CTC 打破了隐马尔科夫的假设，把整个模型从静态分类变成了序列分类，这是很重要的。百度在 2015 年中期开始做，年底 LSTM 和 CTC 上线。现在的 Deep CNN 是在我们整个研究框架中把 CNN 的潜力挖掘的更彻底。其实 CNN 和 LSTM 有相通也有不一样的地方，如果 CNN 在时间上做卷积的话，和 LSTM 有很多相似之处。而不同在于 LSTM 擅长做整个时间域信息的整合，而 CNN 要想达到同样效果做的配置就要更加复杂。但 CNN 有很强的平移的不变性，对于整个语音识别任务来说，要获得更好的鲁棒性，CNN 比 LSTM 做的好。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：这次 Deep CNN 带来的提升会应用在哪些产品中？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;李先刚&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：这项技术会在搜索产品，如手机百度的语音搜索先使用，然后再推广到其他产品。近一年来，手机百度上的语音识别的准确率提升了 20% 以上，效果感觉完全不一样。这次会带来效果的再次提升。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：你提到，现在做的技术研究都是要和产品相结合。对于整个语音识别行业来说，识别率一直在提升，但目前语音识别产品还没有被大范围使用，这里的原因是识别准确度还没有达到一个临界点？还是说产品层面的原因？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;李先刚&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：有各方面的问题，首先，识别率如果从现在的 97% 达到 99% ，那肯定会不一样。其次，产品上也有很多问题，你要做好一个输入法，或者语音搜索，是要把很多方面结合在一起的。像我们的语音搜索很早也具备了语音纠错功能，语音纠错对整个语音输入和搜索非常关键，仅仅做好一个识别率还不错，怎么样让你的产品体验更好，还有很多事情要做。因此，一方面是从研究的角度提高准确度，另一个是从产品角度提升用户体验。还有一个是用户习惯的养成，我们发现小孩对语音输入的接受程度很高。此外，之前百度硅谷人工智能实验室和斯坦福合作过一篇论文，在实验中，相比于在手机屏幕上打字，人类能够语音识别能更快、更准确的组织文本消息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：能否介绍一下百度目前整体的语音技术研究，这次 Deep CNN 对百度语音研究有着怎样的意义？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;李先刚&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：此前，百度语音每年的模型算法都在不断更新，从 DNN ，到区分度模型，到 CTC 模型，再到如今的 Deep CNN 。基于 LSTM-CTC 的声学模型也于 2015 年底已经在所有语音相关产品中得到了上线。比较重点的进展如下：1）2013 年，基于美尔子带的 CNN 模型；2）2014年，Sequence Discriminative Training（区分度模型）；3）2015 年初，基于 LSTM-HMM 的语音识别 ；4）2015 年底，基于 LSTM-CTC 的端对端语音识别；5）2016 年，Deep CNN 模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicKYha6n6vemibmx6zUztu84bo6Kb7z8B5oHUoSyyyN3jvgibHt1gU9haic71hHRXxqksXZNotkdtceQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;百度语音识别技术每年迭代算法模型&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在识别精度提升方面，通常在海量数据库上稳定提升 10% 以上就可以称作显著进步（significant improvement），这次我们就达到了这样一个效果。举个例子，我们语音技术部最开始用 CTC 提升了 15% ，这次用 Deep CNN 又提升了 10% 。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们正在努力推进 Deep Speech 3 ，这项研究不排除将会是 Deep Speech 3 的核心组成部分。而在工程领域，我们一直在做一些语音识别应用，手机百度和输入法要提升性能。我们希望在未来的几年内，将语音识别的准确率在某些任务上做到 99% ，从现在来看是有希望的。同时还有一些周边技术也在研究，包括说话人切分、远场语音识别应用等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心原创，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Fri, 04 Nov 2016 14:24:33 +0800</pubDate>
    </item>
    <item>
      <title>前沿 | 量子计算新进展，MIT联手哈佛用激光束实现单个中性原子的囚禁</title>
      <link>http://www.iwgc.cn/link/3362553</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自MIT&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Jennifer Chu&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：杜夏德&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;近日MIT哈佛的量子研究团队发明了一项新技术，用激光束将原子从原子云中一个一个孤立出来，而且不带电荷。&lt;span&gt;目前他们已将创造出了由 50 个原子构成的原子阵列，其中的每个原子都能单独控制。&lt;span&gt;科学家们会用照相机拍下这些被囚禁的原子及其位置的图像，然后基于这些图像，操作激光束的角度，来移动单个原子形成任意数量的不同组态（configurations）。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;原子、光子和其他量子粒子天生顽固；很少处于停顿状态，同一种量子粒子间常常产生碰撞。如果能把大量量子一个个单独用量子围栏拦起来控制住，就可以将它们作为量子比特——一种极小的信息单元，其状态和方向可用来进行计算，速度要比当下基于半导体的计算机芯片快上很多。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最近几年，科学家想了很多方法来把每个量子单独囚禁起来控制住。但是这类技术很难能扩展，因为缺少操控大量原子的可靠方法，这是实现量子计算的重大障碍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在，来自哈佛和 MIT 的科学家发现了一种有望解决这一问题的方法。相关论文发表在近日的 Science 杂志上，论文中提到他们发现一种新的方法，使用激光器或「光钳」（optical「tweezers」）来将原子一个一个从原子云中挑出来囚禁在某个地方。当原子被「囚禁」时，科学家们会用照相机拍下这些原子及其位置的图像。然后基于这些原子的图像，操作激光光束的角度，来移动单个原子形成任意数量的不同组态（configurations）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该研究团队目前已将创造出了由 50 个原子构成的原子阵列，并操控它们进入各种无缺陷的形状（pattern），其中的每个原子都能单独控制。论文作者之一，MIT 物理系的 Lester Wolfe 教授 Vladan Vuletic，将这一过程比喻为「从底部向上建立一个原子的小晶体。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们已经展示了一个可重复组态的（reconfigurable）单个原子的陷阱阵列，在这里面我们能确切地在分开的陷阱中将 50 个原子单独囚禁，用于未来的量子信息处理、量子模拟或者精确度测量，」Vuletic 说，他也是 MIT 电子研究实验室的成员。「就好像把原子当乐高积木来玩，你可以决定每块积木的位置。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicKYha6n6vemibmx6zUztu84n2mchsVsicibkFia9d9BL8gL0VSWB05nF5U4m9PKvglyx1T8icjWvHibCTA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;保持中性&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该研究团队设计的操纵中性原子的技术是不带电荷的。其他大多数量子实验中的原子总会带上电荷，或者离子，因为带上电荷的原子比较容易被囚禁。科学家还发现特定条件下的离子可被作为量子门——两个量子比特之间的逻辑运算，类似于经典的电路中的逻辑门。然而由于天生带电荷，离子间相互排斥，很难组成密集的阵列。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;与离子不同，中性原子之间在紧密性上没有问题。使用中性原子作为量子比特的主要障碍是，它们受到的外力非常微弱，很难被控制在一个地方。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;设陷阱&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了囚禁单个的中性原子，研究者们首次使用了一个激光器来将一团铷原子云冷却成超冷原子，其温度接近绝对 0 度，让原子从正常的高速轨道上慢下来。之后他们让第二个激光光束通过仪器分成很多小的光束，其数量和角度可以通过导流板（deflector）上的无线电频率来控制。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;研究者将这些小光束聚焦通过超冷原子云，并发现每一个光束的聚焦点——光束强度最高的点，都吸引了一个单个原子，将它们从云中完全孤立出来控制在某个地方。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「这就好像在某种毛织物上摩擦梳子带电，然后 用它来捡起一小片纸，」Vuletic 说。「这个过程类似于被吸引到光场（light field）中高强度区域的原子。」科学家使用电荷耦合器件相机捕获的原子虽然被囚禁住了，但它们还能发光。通过查看它们的图像，研究者可以辨别出哪些激光束或者「光钳」控制住了原子，哪些没有。然后，他们可以改变每个激光束的无线电频率来「关掉」无原子的光束，重新排列那些带有原子的光束，该研究小组最终创建了 50 个原子的阵列，这些原子被囚禁在某个地方的时间长达几秒。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「现在的问题依然是这次你能执行多少次量子运算？」Vuletic 说。「通常中性原子的时间刻度（timescale）大约是 10 微妙，所以你可以在一秒内做 10 万次运算，我认为这是一个很好的结果了。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在，该研究团队仍在他们是否能够促使中性原子作为量子门——两个量子比特之间的最基本的信息处理。虽然有其他研究者在量子中性原子之间展示了这一过程，但他们还无法在大量原子的系统中保留量子门。如果 Vuletic 和他的同事能成功地在他们的 50 个原子的系统中诱导出量子门，他们就会在实现量子计算的道路上迈出意义重大的一步。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「对于除量子计算外的其他实验，比如用具有预定数量的原子模拟凝聚态物理。用我们的技术就可以实现，」Vuletic 说这让他非常兴奋。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Fri, 04 Nov 2016 14:24:33 +0800</pubDate>
    </item>
    <item>
      <title>开源| 汉字风格迁移项目Rewrite：利用神经网络学习设计汉字新字体</title>
      <link>http://www.iwgc.cn/link/3362554</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心经授权编译&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：&lt;span&gt;Yuchen Tian&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀、李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;日前，Flipboard 软件工程师 Yuchen Tian 在 GitHub 上发布了用于汉字字体的神经风格迁移的项目，该项目介绍了如何通过神经网络学习设计汉字新字体的方法。机器之心授权编译发布。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;项目地址：https://github.com/kaonashi-tyc/Rewrite&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;项目目的&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;创建字体是一件难事，创建汉字字体更是艰难。要做一个兼容 GBK（中国政府设定的字符集标准）的字体，设计师需要为超过 26000 个不同的汉字字符设计外观，这是一项艰巨的工作，可能需要数年时间才能完成。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;可不可以让设计师仅设计其中一部分字符的字体，然后让计算机来确定剩下的字符应该是什么模样呢？毕竟，汉字是由一些被称为「偏旁部首」的基本元素构成的；在不同的汉字上，相同的偏旁部首看起来也都相当雷同。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个项目是使用深度学习的一个探索性的应用。具体而言，整个字体设计流程可被表示成一个风格迁移问题（style transfer problem）——将标准样式字体（比如 SIMSUN 体）转换为目标风格的字体。本项目通过向一个神经网络提供配对样本的子集来训练该神经网络近似学会两种字体设计之间的转换。一旦学习完成，该神经网络就可被用来推理其它字符的外形。下面的框图大概说明了这个思想：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicKYha6n6vemibmx6zUztu84Th3GjdWmRMPA7AeQLsotfrEuGZia0RbRBNI2RA0GbPIOeicHL3vmr2dw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个项目的灵感很大程度上来自于 Erik Bernhardsson 的博客《Analyzing 50k fonts using deep neural networks》和 Shumeet Baluja 的好论文《Learning Typographic Style》。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;网络结构&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在尝试过了各种不同的架构（包括具有残差（residuals）和去卷积（deconvolution）的更复杂的架构）之后，我最终选择了一种更为传统的自上而下的 CNN 架构，如下所示。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicKYha6n6vemibmx6zUztu84nGfVqUymuxs2DBhaEkuNmfCR5VGrIfMSnynnSib7N1lZM4gEMSF5rXA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;注意事项：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;每一个卷积层之后都有一个批规范化（Batch Normalization）层，然后是一个 ReLU 层，然后一直向下零填充（zero padding）。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;该网络基于预测输出和 ground truth 之间的像素级的平均绝对误差（MAE）进行最小化，而没有使用 Erik 的博客中提到的更常用的均方误差（MSE）。MAE 往往能产出更锐利和更清晰的图像，而 MSE 则会得到更模糊和灰蒙蒙的结果。另外为了图像的平滑度，还使用了总变差损失（total variation loss）。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;层数 n 是可配置的，更大的 n 往往会生成更详细和更清晰的输出，但也需要更长的训练时间，通常的选择是在 [2, 4] 之间。大于 4 的时候似乎会达到收益递减的点，即虽然运行时间增加了，但在损失或输出上不会有明显的提升。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;大卷积能带来更好的细节。在我的实验过程中，我开始使用的是堆叠的平直的 3×3 卷积，但它最后表现并不好或无法在更困难和更奇异的字体上收敛。所以最后我选择了这种涓滴形状的架构（trickling down shape architecture），其不同的层有不同大小的卷积，每一个都具有差不多相同数量的参数，所以该网络可以获取不同层面的细节。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;dropout 是收敛（convergence）的基础。没有它，该网络就只能放弃或受困于毫无价值的解决方案，比如全白或全黑图像。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;在 Erik 和 Shumeet 的工作中使用的全连接层（fully-Connected layers）对汉字字符的效果不是非常好，会生成噪声更多和不稳定的输出。我猜想是汉字字符的结构比字母的结构要远远复杂得多，而且从本质上来说更接近于图像，所以一个基于 CNN 的方法在这种情况下更为合理。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;和真实世界图像不一样的是，我们可以生成任意分辨率的字符图像。我们可以对这个事实加以利用：用高分辨率的源图像来逼近低分辨率的目标，从而可以保留更多的细节以及避免模糊和噪声。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;可视化&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;训练中的进展&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;上图展示了模型在多种字体上的训练过程中的验证集上所取得的进展。它们全都在 2000 个样本上进行了训练，层数设置为 3。看该模型如何从随机噪声收敛是很有意思的：首先获取一个字符的可识别的形状，然后获取更为细微的细节。下面是训练过程中某种字体的进展过程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicKYha6n6vemibmx6zUztu84T9hhLmicDj02BqPaK9NkAdsGLcVhq8icFOiabicTbXexzTC4NibT6ADzGZw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;与 ground truth 比较&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面的图像给出了对比 ground truth 的预测结果。对于每一种字体，我们都选取了最常用的 2000 个字作为训练集，运行 3000 次迭代。另外还有一个包含 100 个字的测试集用于推理。对于所有的字体，源字体都是 SIMSUN。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicKYha6n6vemibmx6zUztu84BgXzjofH5bALY2o9dthzSsmCdJ12JcyUJSWh1JaVc4R1ghQRSv3f8w/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于其中大部分字体，该网络都能成功做出合理的猜测。实际上其中一些还跟 ground truth 非常接近。另外值得一提的是，该网络还保留了微小的但可辨认的细节，比如偏旁部首的弯曲的端部。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但正如许多其它的神经网络所驱动的应用一样，当该网络出错时，就会错得非常离谱。对于一些字体（尤其是笔画粗的字体），它只会得到一些模糊的字迹斑点。另一方面，对于这些笔画粗的字体，它会失去让该字符可被辨认的关键的空白处细节，而只会获取到整体的轮廓。即使是在成功的案例中，偏旁部首的损失问题似乎也很常见。此外，网络似乎在宋体上可以做的更好，但在楷体上表现并不好，这主要是因为 SIMSUN 字体本身也是一种宋体。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因为空间的限制，对于每一种字体，我们从测试集中仅随机取样了一个字符。如果你想看到在更大的字符测试集上的结果，请查阅：https://github.com/kaonashi-tyc/Rewrite/blob/master/images/bigger_test.png&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;需要多少字符？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2000 字也许只有 GBK 集的 10%，但也仍然很多了。这个数字是我靠直觉选择的，而且看起来这个选择在很多字体上都表现不错。但必需这么多吗？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了搞清这一点，我选择了一种字体（在每种字体上都进行这个实验会太耗时间）进行了不同数量的训练样本的实验，数量的范围是从 500 到 2000，然后让该模型在一个常用的测试集上对字符进行渲染，下面是得到的结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicKYha6n6vemibmx6zUztu84x1rBw1bO99xgkKCrYLoH661swZWiacjjvickgict3ATTrrJDo78jxYLLA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从上到下，上图分别给出了训练集大小从 500 到 2000 增长时的不同结果。当训练集大小在 1500 到 2000 之间，表现的提升会变得更小，这表明 sweet point 就在这之间的某个地方。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;使用方法&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;要求&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;要使用这个软件包，需要安装 TensorFlow（已在 0.10.0 上测试过）。其它的 Python 要求列在 requirements.txt 文件里。另外强烈推荐使用 GPU——如果你想在合理的时间内看到结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我的所有实验都运行在一个 Nvidia GTX 1080 上。以 16 的 batch 大小进行了 3000 次迭代，这需要小型模型计算 20 分钟、中规模模型计算 80 分钟、大模型则需要 2 小时。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;样例&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在训练之前，你需要运行预处理脚本为源字体和目标字体生成字符位图（character bitmap）：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicKYha6n6vemibmx6zUztu84nerWn2WTgicU6AGn7tbUpz4DwNet52Icw549FWiaAOJXOSPdLV3L7Mow/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该预处理脚本支持 TrueType 和 OpenType 字体，它会获取一个字符列表（一些常见的字符集内置于本 repo 的 charsets 目录中，比如 3000 个最常用的简体汉字字符），然后将这些字符的位图保存为 .npy 格式。对于源字体，每个字体会被默认保存为字体大小为 128 的 160×160 的尺寸，而目标字体则是字体大小为 64 的 80×80 的尺寸。这里并不需要特别的对齐，只要确保字符不被截断即可。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在预处理步骤之后，你就能得到源字体和目标字体的位图，分别是 src.npy 和 tgt.npy，然后运行以下命令开始实际的训练：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicKYha6n6vemibmx6zUztu847BTMMLzicr4VT4wtfoOgzIpSbpAshZoR9uoib2KS0rOWu5icJLYVdiaQtQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这里给出了一些解释：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;mode：可以是 train 或 infer，前者不言而喻，后者我们将在后面讨论&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;model：表示模型的大小。它有三个可用选择：small、medium 或 big，分别对应的层数为 2、3、4&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;tv：总变差损失（total variation loss）的权重，默认 0.0001。如果输出看起来是损坏的或有波动，你可以选择增大权重迫使模型生成更平滑的输出。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;keep_prob：表示训练过程中一个值通过 dropout 层的概率。这实际上是一个非常重要的参数——这个概率越高，图像越锐利，但输出可能会损坏。如果结果不好，你可以尝试减小这个值，这会得到噪声更多但更圆润的形状。通常的选择是 0.5 或 0.9&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;ckpt_dir：用于保存模型的 checkpoint 的目录，用于后续的推理步骤&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;summary_dir：如果你想使用 TensorBoard 来可视化一些指标（比如迭代中的损失），这就是保存所有总结的地方。默认在 /tmp/summary。你可以检查训练 batch 的损失，以及验证集上的损失及其 breakdown&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;frame_dir：保存在验证集上获取的输出的目录。用于选出用于推理的最好模型。在训练之后，你也可以找到一个名为 transition.gif 的文件，可以看到该模型在训练过程中的进展动画，同样也在验证集上。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于其它选择，你可以使用 -h 查看确切的使用案例。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;假设我们最后完成了训练（终于完成了！），我们就可以使用前面所提到的 infer 模式了，看模型在之前从未见过的字符上表现如何。你可以在 frame_dir 中参考获取的帧来帮助你选择你最满意的模型（说明一下：通常不是误差最小的那个）。运行以下命令：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicKYha6n6vemibmx6zUztu84OHdVibs11KTnx6tXDDSBW7iaPDl2ccmhj3A1QuOX6oUIYpzhAZLfIpaA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;注意这里的 source_font 可以不同于训练中所使用的那个。事实上，它甚至可以是任何其它字体。但最好选择相同或相似的字体进行推理，以得到最佳的结果。在推理之后，你将能找到所有输出字符的图像序列以及一个包含了这些推理出的字符位图的 npy 文件。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;讨论&amp;amp;未来工作&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该项目只是一个个人项目，来帮助我学习和理解 TensorFlow，但也顺利发展成了一件更为有趣的事，所以我认为值得与更多的人分享。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前，该网络一次只能学习一种风格，如何将它扩展到一次性掌握多种风格会是一件有趣的事。2000 个字符比完整 GBK 数据集的 10% 还少，但它还是比较多的，少于 100 字符的情况下有可能学习到字体的风格吗？我的猜测是 GAN 可能会对此有所帮助。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在网络的设计上，该架构被证明在不同的字体上是有效的，但每个卷积层的数量的优化还需要搞清楚，或者一些卷积层是否有必要？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我想要探索的另一个有趣的方向是创造混合多种风格的字体。在损失函数上简单结合两种字体的表现并不好。可能我们应该为字体单独训练一个 VGG 网络，然后劫持（hijacking）特征映射？或者在网络设计上使用潜在更多的新变化，从而解决这个问题？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，该项目证明了更专门化的应用深度学习的可能性，CNN 帮助加速了汉字字体的设计流程。研究的结果很是振奋人心，但并非从无到有的创造新字体，这也不是该项目的内容。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;感谢&amp;amp;有用的资料&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;谷歌的 TensorFlow 教程：https://www.tensorflow.org/versions/r0.11/tutorials/mnist/pros/index.html&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;来自 Justin Johnson 的在快速神经风格迁移网络上的补充材料：http://cs.stanford.edu/people/jcjohns/papers/eccv16/JohnsonECCV16Supplementary.pdf 和 https://github.com/jcjohnson&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;来自 Ian Goodfellow 的视频：https://www.youtube.com/watch?v=NKiwFF_zBu4 。非常好的东西，非常实用，说明了很多如何使用深度学习解决问题的要点；看完之后，我就觉得没必要自己再写一份笔记了。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;感谢我的朋友 Guy 帮助我在合理的预算内搭建了一台 PC&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;证书&lt;/strong&gt;&lt;br/&gt;&lt;br/&gt;GPLv3&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心经授权编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Fri, 04 Nov 2016 14:24:33 +0800</pubDate>
    </item>
    <item>
      <title>学界 | Vicarious在ICLR 2017提交无监督学习论文，提出层级组合特征学习</title>
      <link>http://www.iwgc.cn/link/3362555</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Open Review&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李亚洲、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;人工智能领域的明星创业公司 Vicarious 一直受到了业内的极大关注，亚马逊 CEO 贝佐斯，Facebook CEO 扎克伯格，Salesforce CEO Marc Benioff 和 Box CEO Aaron Levie 等都是其投资人。近日，Vicarious 发表了他们的一篇有关无监督学习的新论文，该论文已提交 ICLR 2017。点击阅读原文可下载此论文。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicKYha6n6vemibmx6zUztu84QgNQhVDXwJW3dnz80gY2Cj51qlobiajxmicOvZbpsyxh4vha2jCicr9Bw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;摘要&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们介绍了一种层级组合网络（hierarchical compositional network，HCN），它是一种定向的生成式模型（directed generative model），能够在无监督的情况下发现并解开二值图像（binary images）集合的构建模块。这些构建模块是被层级式地定义为网络后层中一些特征（以某种特别的形式排布）的组合的二值特征。从高层面来说，HCN 类似于带有池化的 S 型信念网络（sigmoid belief network）。HCN 中的推断和学习非常具有挑战性，而且现有的变分近似法的效果不太令人满意。该研究的一个主要贡献是发现：使用经过特别安排的（不需要 EM）max-product message passing（MPMP），刚才提到的两个问题都能解决。而且，使用 MPMP 作为 HCN 推断引擎使得新任务更为简单：加入监督信息、分类图像或执行图像修复——全部都对应于将模型的一些变量固定于模型的已知值，然后在剩余部分上运行 MPMP。当被用于分类时，HCN 的快速推断几乎与带有线性激活函数和二值权重的卷积神经网络有同样的函数形式。然而，HCN 的特征在质量上却有很大的不同。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;关键词：无监督学习&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Fri, 04 Nov 2016 14:24:33 +0800</pubDate>
    </item>
  </channel>
</rss>
