<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器之心</title>
    <link>http://www.iwgc.cn/list/670</link>
    <description>人与科技的美好关系</description>
    <item>
      <title>深度 | 提升深度学习模型的表现，你需要这20个技巧（附论文）</title>
      <link>http://www.iwgc.cn/link/2808920</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自machielearningmastery&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;作者：&lt;span&gt;&lt;a title="Posts by Jason Brownlee" rel="author" style="border: 0px; outline: 0px; vertical-align: baseline; color: rgb(136, 136, 136); font-weight: bold; background: transparent;"&gt;Jason Brownlee&lt;/a&gt;&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：杜夏德、陈晨、吴攀、Terrence、李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;本文原文的作者 Jason Brownlee 是一位职业软件开发者，没有博士学位的他通过「从应用中学习」的方法自学了机器学习，他表示对帮助职业开发者应用机器学习来解决复杂问题很有热情，也为机器学习社区贡献了很多实用的建议和指南，本文所讲解的是「能帮助你对抗过拟合以及实现更好的泛化」的 20 个技巧和技术。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你可以怎样让你的深度学习模型实现更好的表现？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是一个我常被问到的问题：「我该怎么提升准确度？」或者「如果我的神经网络表现很糟糕我该怎么办？」……&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我常常给出的回答是：「我也不完全知道，但我有很多想法。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然后我开始列出所有我可以想到的可能能够带来效果改进的想法。我将这些想法汇集到了这篇博客中，这些想法不仅能在机器学习上为你提供帮助，而且实际上也适用于任何机器学习算法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;提升算法的表现的想法&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这份列表并不是完整的，但是却是一个很好的开始。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我的目标是给你大量可以尝试的想法，希望其中会有一两个是你从来没有想到过的。毕竟，你总是需要好的想法来获得进步。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我将这份列表分成了 4 个子主题：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1. 通过数据提升性能表现&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2. 通过算法提升性能表现&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3. 通过算法微调提升性能表现&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;4. 通过整合提升性能表现&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;列表越往后，其所能带来的增益就越小。比如说，关于你的问题的新型框架或更多的数据所带来的效果总是会比微调你表现最好的算法所带来的效果更好。尽管并不总是如此，但一般而言确实是这样。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其中一些想法是特定于人工神经网络的，但还有许多是很通用的，你可以借鉴它们从而在使用其它技术来提升你的性能表现上获得灵感。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面就让我们正式开始吧！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1. 通过数据提升性能表现&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;修改你的训练数据和问题定义可以给你带来巨大的好处，也可能能带来最大的好处。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面是一些我们将会涵盖的内容的一个短列表：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 获取更多数据&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 创造更多数据&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3. 重新调整数据的规模&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4. 转换数据&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;5. 特征选择&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1）获取更多数据&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你能获取更多训练数据吗？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;基本上，你的训练数据的质量就限制了你的模型的质量。你需要为你的问题寻找最好的数据，而且是很多很多数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;深度学习和其它现代非线性机器学习技术都是数据越多越好，深度学习尤其是这样。这也是深度学习如此激动人心的主要原因之一。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;让我们看一下下面的图：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicF8wXlBVVVUGiahn69Rw7OWrnfOexOlSRqbv4eLgEeurnbmPA9GX4qnGibE6JbLviaGHibB0rr7BR2SQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;为什么选择深度学习？来自吴恩达的幻灯片&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;更多的数据并不总是有用，但它可以有用。如果要我选择，我肯定会希望获得更多的数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相关推荐：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;算法上的数据集&lt;/span&gt;&lt;span&gt;（https://www.edge.org/response-detail/26587）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2）创造更多数据&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;深度学习算法得到的数据越多，通常就表现得越好。如果你无法合理地得到更多数据，你可以创造更多数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如果你的数据是数字的向量，就在已有的向量上进行随机的修改来创造数据。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如果你的数据是图像，就在已有的图像上进行随机的修改。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如果你的数据是文本，就在已有的文本上进行随机的修改……&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个过程常被称为数据增强（data augmentation）或数据生成（data generation）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你可以使用生成模型，也可以使用某些简单的技巧。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;比如，对于照片图像数据，你可以通过随机移位和旋转已有的图像来获得新图像。这能够提升模型对于数据中这种变换的归纳能力——如果它们也预计会出现新数据中。这也和增加噪声有关，我们过去叫做添加抖动（adding jitter）。这可被用作是抑制过拟合训练数据集的正则化方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相关推荐：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;使用 Keras 进行深度学习的图像增强（http://machinelearningmastery.com/image-augmentation-deep-learning-keras/）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;什么是抖动？（使用噪声进行训练）（ftp://ftp.sas.com/pub/neural/FAQ3.html#A_jitter）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3）重新调整数据的规模&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是个快速的方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;将传统的拇指规则应用于神经网络：将你的数据的规模重新调整到你的激活函数的范围内。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你使用的是 S 型激活函数，那么就将你的数据调整到值位于 0 到 1 之间。如果你使用的是双曲正切（tanh），就将你的值调整到 -1 到 1 之间。这适用于输入（x）和输出（y）。比如说，如果你在输出层有一个 S 型函数来预测二元值，你可以将你的 y 值规范为二元的。如果你使用的是 softmax，你仍然可以从规范化 y 值中获益。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这仍然是一个好的拇指规则，但我会更进一步。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我建议你按以下形式创造你的训练数据集的不同版本：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;规范成 0 到 1；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;重新调整到 -1 到 1；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;标准化。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然后在每一个数据集上评估你的模型的表现。选择其中一个，然后再双倍下注。如果你修改了你的激活函数，再重复这个小实验。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;网络中大数值的积累并不是好事。此外，还有一些让你的网络中的数值变小的方法，例如规范化激活和权重，但我们会在后面谈论这些技术。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相关推荐：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;我应该标准化输入变量（列向量）吗？（ftp://ftp.sas.com/pub/neural/FAQ2.html#A_std）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如何在 Python 环境中利用 Scikit-Learn 包来为机器学习准备数据？（http://machinelearningmastery.com/prepare-data-machine-learning-python-scikit-learn/）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;4）转换你的数据&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这和上述建议的规模重调相关，但是需要更多的工作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你必须真正了解你的数据，并将其可视化，然后寻找出那些离群的数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;估计每个列的单变量分布。&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;列是否看起来像是一个倾斜的高斯分布，考虑用 Box-Cox 变换来调整倾斜的情况&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;列是否看起来像是一个指数分布，考虑用对数变换&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;列是否看起来像是拥有一些特征，但正在被一些明显的东西冲击，试着利用平方或者平方根&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;能否用某些方式让特征更具体或者离散来更好地强调这些特征&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;根据你的直觉，去尝试一些新的东西。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;能否利用主成分分析一类的投影方法预处理数据？&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;能否将多个属性聚合成为一个单一变量？&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;能否用一个新的布尔标志揭示问题的一些有趣的地方？&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;能否用其他方式探索时间结构或者其他结构？&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;神经网络可以进行特征学习。它们能做到这点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但如果你能更好地将问题的结构展示给神经网络用于学习，它们能更好地解决问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;抽查大量的不同转换形式的数据或者某些特定属性，看看什么可行什么不可行。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相关推荐：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如何定义你的机器学习问题（http://machinelearningmastery.com/how-to-define-your-machine-learning-problem/）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;挖掘特征工程。如何设计特征以及如何合理利用它们（http://machinelearningmastery.com/discover-feature-engineering-how-to-engineer-features-and-how-to-get-good-at-it/）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如何用 Python 和 Scikit-learn 结合的方式为机器学习准备数据（http://machinelearningmastery.com/prepare-data-machine-learning-python-scikit-learn/）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;5）特征选取&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;神经网络一般都对无关联的数据是稳健的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;它们将使用一个接近于零的权重并边缘化那些非预测属性的贡献。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不过，这是运用在那些无需做出好的预测的数据上的数据、权重和训练周期。能否从你的数据中删除某些属性？有很多特征选择方法和特征重要性的方法可以给你一些关于特征的想法，从而能更好的利用它们。尝试一部分。尝试全部。这样做是为了获得想法。。同样，如果你有时间，我会建议利用相同的网络来评估一些不同选择视角下的问题，看看它们的表现如何。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;也许你可以用更少的特征做得一样好，甚至有更好表现。是的，更快！&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;也许所有的特征选择方法可以引导出相同特定子集的特征。是的，对无用的功能达成共识！&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;也许选定的子集给你提供了一些想法或者更多的你可以执行的特征工程。是的，更多的想法！&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;相关推荐：&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;特征选择简介（http://machinelearningmastery.com/an-introduction-to-feature-selection/）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;Python 环境中机器学习的特征选择（http://machinelearningmastery.com/feature-selection-machine-learning-python/）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;6）重构你的问题&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;退一步再看你的问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你所收集的观察是唯一能构建你问题的方式吗？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;也许还有其他更好的地方。也许其他的问题框架可以更好地展示问题的某些结构从而能更好地进行学习？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我真的很喜欢这项练习，因为这迫使你打开你的内心。这很难，尤其是当你现阶段已经投资了你的自负、时间和金钱。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;即使你只是列出了 3 到 5 个备用的框架并让它们打了折扣，至少你正在你选择的方式中建立你的信心。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;也许你可以在某个允许时间步骤的窗口或方法中整合时间元素&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;也许你的分类问题可以变成一个回归问题，或者相反&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;也许你的二元输出可以变成一个 softmax 输出&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;也许你可以对一个子问题建模&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是一个想清问题的好方法，这也是一个在你想要利用工具之前的可行框架，因为你在解决方案上的投资会更少。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不管怎样，如果你卡住了，这个简单的方式还可以让你思若泉涌。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此外，你不必丢弃任何你之前的工作，看看之后的整合吧。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相关推荐：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如何定义你的机器学习问题（http://machinelearningmastery.com/how-to-define-your-machine-learning-problem/）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2. 通过算法提升表现表现&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器学习就是关于算法的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所有的理论和数字都描述了运用不同的方式从数据中学习一个决策过程（如果我们将自己限制在一个可预测模型中）。你已经选择利用深度学习来处理问题。这是你可以选择的最好方式吗？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在本节中，在继续深入研究你为何选择深度学习方法的某些细节之前，我们讨论一些关于算法选择的小的想法。&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Spot-Check Algorithms. 抽查算法&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Steal From Literature. 从文献中获取&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Resampling Methods. 重采样方法&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;让我们开始吧。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1）抽样算法&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;振作起来，你在事前可以不知道哪种算法能最好地执行你的问题。如果你知道，你可能不会需要机器学习。你收集的什么证据能证明你所选择的方法是一个好的选择？让我们来解决这个难题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当表现在所有的问题中处于平均值时，没有一种单独的算法可以比其他任何的都运行地更好。所有的算法都是平等的。这是从没有免费的午餐定理中总结归纳的。也许你的算法并不是解决你的问题的最好的方式。现在，我们不是要解决所有可能的问题，但是在所有算法中最新最热的那个不一定是你处理某个特定训练集最好的方法。我的建议是收集证据。想象可能会有更好的算法并给它们一个处理你问题的公平的机会。抽查一系列顶级的算法，看看哪些表现不错，哪些表现不好。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;评估某些线性方法，比如逻辑回归和线性判别分析&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;评估一些树的方法，比如分类回归树、随机森林和 Gradient Boosting&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;评估一些实例方法，比如支持向量机和 K 最近邻&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;评估其他的一些神经网络算法，比如 LVQ、MLP、CNN、LSTM、混合结构等等&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;重点关注表现最佳的，并通过进一步的调整或者数据准备提高表现。对你选择的深度学习方法进行结果排名，它们如何比较？也许你可以放下深度学习模型，并使用一些更快更简化的方式去训练，这甚至可以很容易理解。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相关推荐：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;一种用于机器学习的数据驱动方法（http://machinelearningmastery.com/a-data-driven-approach-to-machine-learning/）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;为什么你应该在你的机器学习问题上进行算法抽查（http://machinelearningmastery.com/why-you-should-be-spot-checking-algorithms-on-your-machine-learning-problems/）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;在 Python 环境中使用 Scikit-learn 抽查分类机器学习算法（http://machinelearningmastery.com/spot-check-classification-machine-learning-algorithms-python-scikit-learn/）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2）从文献中获取算法&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一种获取好算法的捷径是从文献中获取。还有谁跟你处理过一样的问题，他们用了什么方法？查看论文、书籍、博客、问答网站、教程和一切谷歌丢给你的东西。写下所有的想法，并按照你自己的方式处理它们。这不是研究的复制，这是关于一些你没有想到过的但可能能够提升你的思路的新想法。发表出来的研究是高度优化过的。有很多聪明的人写下了很多有趣的事情。在这些广袤的资源中挖掘你需要的金矿吧。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相关推荐：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如何研究一个机器学习算法（http://machinelearningmastery.com/how-to-research-a-machine-learning-algorithm/）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;谷歌学术搜索（http://scholar.google.com/）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3）重采样方法&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你必须知道你的模型有多好。你对你的模型的性能估计可靠吗？深度学习算法的训练很慢。这通常意味着我们不能使用黄金标准方法来估计模型的性能，比如 k-fold 交叉验证。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;也许你正在使用一个简单的训练集／测试集分割，这是很常见的。如果是这样，你需要确保这个分割能够代表这个问题。单变量统计和可视化将会是一个良好的开端。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;也许你可以利用硬件来提高评估结果。比如，如果你有一个集群或者 Amazon Web Services 的账户，我们可以并行训练 n 个模型然后再取领军和标准差去得到一个更稳健的估计。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;也许你可以使用一个验证 hold out 集来在它正在训练时获得一个验证模型性能的想法（对过早终止有用，见后文）。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;也许你能撤回一个你只在模型选择演算后使用的完全无效的验证集。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;走另一条路，也许可以使数据集更小，使用更强的重采样方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;也许你可以在一个只在某一样本中训练的模型和在整个样本中训练的模型之间看到很强的相关性。也许你可以进行模型选择并利用小数据集微调，然后将最终的技术扩展到完整的数据集上。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;也许你可以任意约束数据集，然后取样，并将其用于所有的模型开发&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你必须对你模型的性能估计有充足的信心。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相关推荐：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;评估 Keras 中深度学习模型的性能&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;评估利用重采样方法的 Python 中机器学习算法的性能&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3. 通过算法调优改进性能&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这才是肥肉所在。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你总能够从抽查中找出一两个不错的算法。得到表现最好的算法可能要花费一定的时间。下面是一些调优神经网络算法从而得到更好的表现的方法：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;诊断&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;权重初始化&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;学习率&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;激活函数&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;网络拓扑&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Batches 和 Epochs&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;正则化&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;优化与损失&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;早停&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你可能需要对给定网络的配置训练许多次（3-10 次或更多），从而对该配置的表现作出很好的评估。在这个小节中你学到的微调技可应用于所有方面。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;推荐一篇很好的讲解超参数优化的文章：http://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1) 诊断&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你知道架构的表现为什么没有改进，那你就能更好的改进其表现了。比如，是因为模型过拟合或者欠拟合？要切记这个问题。网络总是会在拟合上出问题，只是程度不同而已。一个快速了解你的模型的学习行为的方式是在每个 epoch 在训练和验证数据集上对模型进行评估，并标绘结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicF8wXlBVVVUGiahn69Rw7OWe4iaeP8XqgPFU4WpUohPSHnsNHoEUE7eHPOOKtkcoqMWQdkPlRz4k0A/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;模型在训练和验证数据集上的准确率&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如果训练比验证集的结果更好，你可能过拟合了，可以使用正则化技术进行调整&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如果两个结果都很低，你可能欠拟合了，可以通过增加网络的容量并进行更多、更长的训练进行调整&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如果有一个训练高于验证结果的拐点，你可以使用早停（Early Stopping）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;经常标绘这样的图，并研究使用不同的技术改进模型的表现。这些图可能是你所能创造的最有价值的诊断方法。另外一个有帮助的诊断方法是学习网络正确和错误的观察值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在一些问题上，下面这些建议可以尝试一下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;在难以训练的样本上，你可能需要更多的或增强的样本。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;在容易建模的训练数据集上，你可能需要移除大量样本。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;可能你需要使用专门的模型，专注于输入空间不同的明确区域。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相关推荐：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;在 Keras 中显示深度学习模型训练历史（http://machinelearningmastery.com/display-deep-learning-model-training-history-in-keras/）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;深度学习算法的过拟合和欠拟合（http://machinelearningmastery.com/overfitting-and-underfitting-with-machine-learning-algorithms/）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2）权重初始化&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;过去的经验法则是：使用小型随机数值进行初始化。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在实践中，这个法则仍然很好，但对你的网络而言它是最好的吗？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不同的激活函数也所启发，但我在实践中不记得看到过有什么不同。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;修定好你的网络并尝试不同的初始化方案。记住，权重是你一直想要找到的模型的实际参数。有许多套权重能给出好的表现，但你需要的是更好的表现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;尝试所有的初始化方法，看有没一个是最好的。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;尝试用自编码器（autoencoder）这样的无监督方法进行预学习。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;为了解决你的问题，尝试使用已有的方法重复训练新的输入和输出层（迁移学习）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;记住，改变权重初始化方法会影响到激活函数，甚至是优化函数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相关推荐：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;深度网络的初始化：http://deepdish.io/2015/02/24/network-initialization/&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3）学习率&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;调整学习率总会有所收获。下面是一些可以探索的方法：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;用超大或超小的学习率进行试验&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;从文献中找到常用的学习率值，看你能将网络改进到什么地步&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;尝试随着 epoch 降低学习率。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;尝试经过一定量的 epoch 训练后，就按一定概率降低学习率&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;尝试增加一个动量项，然后同时对学习率和动量进行网格搜索&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;越大的网络需要越多的训练，反之亦然。如果你增加更多的神经元或更多的层，请增加你的学习率。学习率与训练 epoch 的数量、batch 的大小、优化方法是紧密相关的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相关推荐：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;在 Python 中对深度学习模式使用学习率方案：http://machinelearningmastery.com/using-learning-rate-schedules-deep-learning-models-python-keras/&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;反向传播应该使用什么样的学习率？：ftp://ftp.sas.com/pub/neural/FAQ2.html#A_learn_rate&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;4）激活函数&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你或许应该使用 rectifier 激活函数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;它们用起来更好。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在那之前，在输出层上，一开始是 sigmoid 和 tanh 函数，然后是一个 softmax 函数、线性函数或者 sigmoid 函数。我不推荐做更多的尝试，除非你知道你在做什么。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尝试这三个函数并且调整你的数据以满足这些函数的边界。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;很明显，你想选择适合输出的形式的传递函数（transfer function），但是要考虑利用不同的表征。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;例如，从二元分类（binary classification）的 sigmoid 函数切换到解决回归问题的线性函数，然后后处理（post-process）你的输出。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这或许也需要将损失函数换成某些更加适合的东西。下面是关于数据转换的更多的想法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相关推荐：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;为什么要使用激活函数：ftp://ftp.sas.com/pub/neural/FAQ2.html#A_act&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;5）网络拓扑&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;改变你的网络结构会有回报。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你需要多少层和多少个神经元？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;没人只知道，所以别问。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你必须为你的问题开发出好配置。试验。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;尝试一个隐藏层包含很多个神经元（宽）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;尝试每层只有少量神经元的深度网络（深）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;尝试将以上结合起来&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;从最新的论文中找出与你类似的架构并尝试它们&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;尝试拓扑模式（扇出然后扇入）和书与论文中的好的经验规则（见下面链接）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;后面的网络需要更多的训练，在 epochs 和学习率上都需要。做相应的调整。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相关推荐：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面的链接可以给你很多尝试的想法，对我很有用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;我应该用多少个隐藏层？：ftp://ftp.sas.com/pub/neural/FAQ3.html#A_hl&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;我应该用多少个隐藏单元？：ftp://ftp.sas.com/pub/neural/FAQ3.html#A_hu&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;6）Batches 和 Epochs&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Batch 的大小限定了梯度以及多久更新权重。一个 epoch 是分批（batch-by-batch）暴露给网络的整个训练数据。你试验过不同的 batch 大小和 epochs 量吗？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;上面我已经谈过学习率、网络大小和 epochs 之间的关系了。带有大 epoch 的小 batch 和大量的训练 epoch 在现在的深度学习部署中很常见。以下这些方法可能不符合你的问题：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;尝试将 batch 大小与训练数据的大小对等，这依赖于内存（batch learning）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;尝试大小为 1 的 batch（在线学习）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;尝试不同 mini-batch 大小（8、16、32...）的网格搜索&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;尝试分别训练一些 epoch 以及大量的 epoch&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;考虑下接近无限量的 epoch，并设立抽查点捕捉最好的表现模型。一些网络架构要比其他架构对 batch 的大小更敏感。我认为多层感知机对 batch 大小比较稳健，LSTM 和 CNN 比较敏感，但这只是传闻。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相关推荐：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;What are batch, incremental, on-line, off-line, deterministic, stochastic, adaptive, instantaneous, pattern, constructive, and sequential learning?：ftp://ftp.sas.com/pub/neural/FAQ2.html#A_styles&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;直观上，mini-batch 的大小如何影响（随机）梯度下降的性能？：https://www.quora.com/Intuitively-how-does-mini-batch-size-affect-the-performance-of-stochastic-gradient-descent&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;7）正则化&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;正则化是遏制过拟合训练数据的很好的方法。最新的热门正则化技术是 dropout，你试过吗？Dropout 在训练期间随机跳过神经元，并强迫层内其他算法重拾这些神经元。简单而有效，开始 dropout 吧！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;网格搜索不同的 dropout 百分比。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在输入层、隐藏层和输出中试验 dropout&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;关于 dropout 的想法还有一些扩展，可以像 drop connect（http://cs.nyu.edu/~wanli/dropc/）那样尝试它们。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你也可以考虑其他更传统的神经网络正则化技术，比如：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;权重衰减以惩罚最大的权重&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;激活约束，以惩罚最大激活&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在可被惩罚的不同方面和可以应用的不同类型的惩罚（L1，L2，L1 和 L2 同时使用）上进行试验。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相关推荐：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Keras 的深度学习模型中的 dropout 正则化：http://machinelearningmastery.com/dropout-regularization-deep-learning-models-keras/&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;什么是权重衰减：ftp://ftp.sas.com/pub/neural/FAQ3.html#A_decay&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;8）优化和损失&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;曾经的方法是随机梯度下降，但现在有很多可以优化的方式。你有试过不同的优化程序吗？随机梯度下降是默认的。首先用不同的学习率、动量和学习率计划充分利用它。许多更高级的优化方法会提供更多的参数，更多的复杂性以及更快的收敛性。这是好是坏，取决于你的问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了最大化给定的方法，你真的需要深入到每一个参数，然后根据你的问题网格搜索不同的值。这困难，且耗费时间。但也可能有回报。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我发现新的/流行的方法可以收敛得更快并且能对于一个给定的网络拓扑结构的能力给出一个很快的想法，例如：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;ADAM（论文请点击「阅读原文」下载）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;RMSprop&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你还可以探索其他的优化算法，比如更传统的（Levenberg-Marquardt）和不太传统的（遗传算法）。其他的方法可以为随机梯度下降法提供很好的起点和优化的方式。要优化的损失函数和你将要解决的问题是密切相关的。不过，你会有一些回旋的余地（用于回归的 MSE 和 MAE 度量，等等），你也可能会通过换算你问题的损失函数得到一个小的凸点。这也可能与输入数据的规模和正在使用的激活函数的规模紧密相关。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相关推荐：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;梯度下降优化算法概述：http://sebastianruder.com/optimizing-gradient-descent/&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;什么是共轭梯度，Levenberg-Marquardt 等？ftp://ftp.sas.com/pub/neural/FAQ2.html#A_numanal&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;深度学习的优化算法，点击「阅读原文」下载&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;9）早停&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一旦性能开始下降，你可以终止学习。这可以节省大量的时间，甚至可能让你使用更复杂的重采样方法来评估模型的性能。早停是一种遏制训练数据过拟合的正则化手段，要求你在每一个 epoch 中监控训练模型的表现并验证数据集。一旦验证数据集的表现开始下降，训练就可以停止。如果这一条件得到满足（测量精度损失），你还可以设置检查点来保存模型，并允许模型继续学习。检查点可以让你在没有停止的情况下早停，给你几个模型在运行结束时进行选择。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相关推荐：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如何在 Keras 的深度学习模型中设置检查点：http://machinelearningmastery.com/check-point-deep-learning-models-keras/&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;什么是早停？：ftp://ftp.sas.com/pub/neural/FAQ3.html#A_stop&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;4. 用模型组合（Ensemble）来提升表现&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你可以将多个模型的预测相结合。算法调试后，这是需要改进的下一个大区域。事实上，你可以从多个足够好的模型的预测结合中获取好的表现，而不是多个高度调整（脆弱）的模型。我们会看看你可能要考虑的模型组合的三大领域：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Combine Models. 模型结合&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Combine Views. 视角结合&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Stacking. 堆&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1）模型结合&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不要选择一个模型，把它们结合起来。如果你有多个不同的深度学习模型，每个模型都在这个问题上的表现良好，那么通过取均值来结合它们的预测。模型越不相同，效果越佳。例如，你可以使用完全不同的网络拓扑结构或者不同的技术。如果每个模型都很灵巧，但方式不同，那么集成预测将更为强劲。或者，你可以用相反的位置进行试验。每次训练网络的时候，你要用不同的权重对这个网络进行初始化，该网络会收敛成一组不同的最终权重。将此过程重复多次，生成许多的网络，然后结合这些网络的预测。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;它们的预测将是高度相关的，但它可能会在这些模式上给你一个更难预测的小凸点（bump）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相关推荐：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;在 Python 中用 scikit-learn 组合机器学习算法：http://machinelearningmastery.com/ensemble-machine-learning-algorithms-python-scikit-learn/&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如何提高机器学习算法的结果：http://machinelearningmastery.com/how-to-improve-machine-learning-results/&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2）视角结合&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;正如上文所述，但是以你的问题的一个不同视角或框架来训练每个网络。再一遍，目标是得到熟练的的模型，但是用不同的方式（比如不相关的预测）。你可以依靠非常不同的缩放（scaling）和上文中提到的转换技巧。用于训练不同模型的问题的转换和框架越多，就越有可能改善你的结果。运用预测的简单平均将是一个良好的开端。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3）层叠&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你还可以了解如何最好地结合多种模型的预测。这就是所谓的层叠泛化，简称层叠（是 stacking）。通常情况下，你可以利用像正则回归这样学习如何为不同模型的预测加权的简单线性方法来取得更好均值结果。基准结果使用多个子模型的预测的平均，但是会用学到的模型权重提升表现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相关推荐：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;层叠泛化（层叠）：http://machine-learning.martinsewell.com/ensembles/stacking/&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;附加资源&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有很多很好的资源，但很少能将所有的想法都联系在一起。我将列出一些资源和相关的发布信息，如果你想深入了解，你会发现这很有趣&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相关推荐：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;神经网络常见问题解答：ftp://ftp.sas.com/pub/neural/FAQ.html&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如何在 Python 中使用 Keras 网格搜索深度学习模型的超参数：http://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;必须知道的深度神经网络提示/技巧：http://lamda.nju.edu.cn/weixs/project/CNNTricks/CNNTricks.html&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如何增加深度神经网络验证的准确性：http://stackoverflow.com/questions/37020754/how-to-increase-validation-accuracy-with-deep-neural-net&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Fri, 23 Sep 2016 17:15:03 +0800</pubDate>
    </item>
    <item>
      <title>业界 | Show and Tell：谷歌在TensorFlow上开源图像描述系统</title>
      <link>http://www.iwgc.cn/link/2808921</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Google Research blog&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;作者：Chris Shallue, Software Engineer, Google Brain Team&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;em style="color: rgb(136, 136, 136);"&gt;&lt;span&gt;2014 年，Google Brain 团队的研究科学家训练了一个自动准确描述图像内容的机器学习系统。后来对该系统的进一步开发使其赢得了微软 COCO 2015 图像描述挑战赛的并列冠军，这项比赛是为了对比出准确描述图像的最佳算法。&lt;/span&gt;&lt;/em&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;今天，该团队在 TensorFlow 上开源最新版本的图像描述系统。此次公开的版本相比于原始版本包含了对图像描述系统计算机视觉组件的极大改进，可更快速的进行训练，并产出更精细、准确的描述。这些改进在论文 Show and Tell: Lessons learned from the 2015 MSCOCO Image Captioning Challenge 中有详尽的概述与分析。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicF8wXlBVVVUGiahn69Rw7OWP82TzictcbiclPIwSHpC8m0AnmcwVibcEpBAc4SPibsQI5E4kCft0ZNvdg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;我们系统生成的对图片的自动描述&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;新旧版本有什么不同？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 2014 年的系统中，我们使用 Inception V1 图像分类模型初始设定图像编码器，它可产生对识别图像中不同物体有帮助的编码。当时，它是可用的最好的图像模型，在 ImageNet 2012 图像分类任务基准上获得了 89.6% 的准确率。在 2015 年，我们使用最新的 Inception V2 取代了 V1，V2 模型当时在同样的分类任务上取得了 91.8 % 的成绩。在此视觉组件上的进步使得我们的描述系统在 BLEU-4 标准（该标准普遍使用于机器翻译中，用来评估机器生成的句子的质量）上的准确率上升了 2 个点，这也是它能在微软图像描述挑战赛中取得成功的关键因素。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今天开放的版本使用 Inception V3 初始设定图像编码器，V3 在 ImageNet 分类任务上取得了 93.9% 的准确率。使用更好的视觉模型初始设定图像编码器使得该图像描述系统有更好的能力识别图像中的不同物体，生成更细节、更准确的描述。相比于图像挑战赛中使用的那代系统，最新的系统在 BLEU-4 标准上的准确率又有了 2 个点的改进。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对视觉组件的另一个关键改进是对图像模型的精调。在该系统中，图像编码器是由对图像中物体分类的模型进行初始化的，此次精调就解决了这个问题，因为图像描述系统的目标是使用由图像模型生成的编码描述图像中的物体。例如，一个图像分类模型可以告诉你图像中有狗、草地和飞盘，但自然描述也可以告诉你草的颜色、狗与飞盘的关联。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在精调阶段，通过在人类生成的图像描述数据上联合训练视觉和语言组件对图像描述系统进行了改进。这使得该系统能从图像中迁移出对生成描述有帮助但对物体分类没必要的信息。特别的，在精调之后，该系统能更准确的描述物体的颜色了。更重要的是，精调阶段必须发生在语言组件学会生成描述之后，否则随机初始化语言组件的噪声会不可逆的破坏视觉组件。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicF8wXlBVVVUGiahn69Rw7OWlF3P4ic9Cocroh4Ee0ZcibicvO3jBQklCKf9nIK6Urfkz0d3g1dlwkDFw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;左图：更好的图像模型使其能生成更详细、更准确的描述；右图：在精调图像模型之后，图像生成系统更能准确的描述物体颜色。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;直到最近，我们的图像描述系统才被部署到 DistBelief 软件框架中。今天公开的在 TensorFlow 中的实现取得了同样等级的准确率和极大的速度进步：在英伟达 K 20 GPU 上，相比于在 DistBelief 中每训练一步的 3 秒时间，在 TensorFlow 框架中每训练一步的时间降到了 0.7 秒，意味着总体训练时间只是之前的 25%。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;关于该系统的一个天然问题是它是否能够生成之前从未看到过的环境与互动的新型描述。该系统是通过千百张人类描述过的图像进行训练的，在看到类似于之前的场景时它总会重复使用人类的描述。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicF8wXlBVVVUGiahn69Rw7OWnQgsFfs8Ym03sZnefMPMgOzWjlhSicksT47qJIlruXFNLpbrib3IYBQg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;在看到类似于之前的场景时，该系统总是重复使用人类的描述&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以，它真的理解每张图像中的物体和物体之间的关联吗？或者说它总是在从训练数据中反刍图像的描述？无比令人激动的是，我们的模型真的开发出了在全新场景上生成准确的图像描述的能力，表明对图像中物体与环境的更深的理解。此外，它也学习如何用自然口音的英语表达知识，尽管除了阅读人类描述之外它没受过额外的语言训练。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicF8wXlBVVVUGiahn69Rw7OWKYv58Kl9eeveic4PIVeVSZhiaKswEv17I9EzMibACS2lIh00icVNf64wDg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;我们的模型使用从训练集类似场景中学到的概念，生成全新的图像描述。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们希望在 TensorFlow 中开源的这一模型能推进图像描述研究与应用，也使得更多刚兴趣的人能进行学习。想要训练自己的图像描述系统以及获取更多关于该神经网络架构的细节，浏览该模型的代码主页：https://github.com/tensorflow/models/tree/master/im2txt。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然我们的系统使用的是 Inception V3 图像分类模型，你也可以尝试使用最新发布的 Inception-ResNet-v2 模型训练该系统，看看结果是否会更好。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;点击阅读原文，下载论文↓↓↓&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Fri, 23 Sep 2016 17:15:03 +0800</pubDate>
    </item>
    <item>
      <title>学界 | Yoshua Bengio新论文提出量子化神经网络：训练带有低精度权重和激活的神经网络</title>
      <link>http://www.iwgc.cn/link/2808922</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自 arxiv.org &lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicF8wXlBVVVUGiahn69Rw7OW29rANRz9RFqWWMk0a4avNA9uWaiaZoedA7VjARzMUFgcVTZZL9qq6lA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：我们在这里介绍一种用来在运行时间（run-time）训练量子化神经网络（QNN：Quantized Neural Networks）——一种带有极低精度（如：1 bit）的权重（weights）和激活（activation）的神经网络——的方法。在训练时间（train-time），量子化的权重和激活被用于计算参数梯度。在前向通过的过程中，QNN 会极大地减少内存大小和接入，并使用位形式的运算（bit-wise operations）代替大部分算术运算。这样有望极大地降低功率消耗。我们在 MNIST、CIFAR-10、SVHN 和 ImageNet 数据集上训练了 QNN。训练出的 QNN 实现了可与 32 bit 的同类媲美的预测精度。比如说，我们的带有 1 bit 权重和 2 bit 激活的 AlexNet 的量子化版本实现了 51% 的 top-1 精度。此外，我们还将参数梯度量子化到了 6 bit，这使得梯度计算仅能使用位形式的计算。量子化循环神经网络（quantized recurrent neural networks）在 Penn Treebank 数据集上进行了测试，仅使用 4 bit 就实现了其同类的 32 bit 网络所达到的精度。最后但并非不重要的是，我们编程了一个二元矩阵乘法 GPU 核（kernel）；比起未经优化过的 GPU 核，在我们的 GPU 核上运行 MNIST QNN 的速度可以快上 7 倍，而且在分类精度上不会出现任何损失。该 QNN 代码已经在网上发布。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;代码发布地址：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Theano 框架：https://github.com/MatthieuCourbariaux/BinaryNet&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Torch 框架：https://github.com/itayhubara/BinaryNet&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;点击阅读原文，下载论文↓↓↓&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;</description>
      <pubDate>Fri, 23 Sep 2016 17:15:03 +0800</pubDate>
    </item>
    <item>
      <title>SyncDaily | 苹果收购机器学习公司Tuplejump、谷歌放出测试版VR SDK</title>
      <link>http://www.iwgc.cn/link/2808923</link>
      <description>&lt;blockquote&gt;&lt;em style="color: rgb(136, 136, 136); line-height: 1.75em; text-align: justify; white-space: pre-wrap;"&gt;&lt;span&gt;苹果收购机器学习公司Tuplejump、Facebook Messenger 新功能：投票+自动转账......机器之心日报，精选一天前沿科技优质内容。&lt;/span&gt;&lt;/em&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h2 style="margin-top: 8px; font-weight: bold; max-width: 100%; white-space: normal; border-color: rgb(216, 40, 33); text-align: justify; color: rgb(216, 40, 33); line-height: 28px; font-family: 微软雅黑; border-bottom-width: 2px; border-bottom-style: solid; min-height: 32px; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;span&gt;&lt;/span&gt;确认收购Tuplejump，苹果又买了一家机器学习公司&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicF8wXlBVVVUGiahn69Rw7OWQIOAMu0xicBf3Rn6Bq7ewOeoyGSYxzURaIP9UicKJGTmjiacnzjeB7JhA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;苹果今日确认收购 Tuplejump，一家来自印度的初创企业，该公司目前主要做的是对数据进行储存、处理、查询数据以及可视化的工作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是继去年底收购 Perceptio 和不久前收购 Turi 后，苹果又一次收购的机器学习公司。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;苹果的发言人未证实也未否认此消息，这是该公司事实上收购了的标准做法，收购协议的条款并未披露。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Tuplejump 公司 2013 年成立于印度海得拉巴，与多数机器学习公司一样，其并非家喻户晓。目前该公司网站无法进行访问。该公司自称是大数据技术早期使用者，主要帮助财富 500 强公司来使用这些技术。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Tuplejump 还建立了一个开源目录搜索系统，简化数据管理技术，使数据使用起来变得非常简单。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;据悉苹果对 Tuplejump 开发的开源项目 FiloDB 特别感兴趣，FiloDB 主要由 Evan Chan 负责，据他的 LinkedIn 资料页面显示，他是在 2015 年 8 月加入 Tuplejump，该技术可将应用机器学习概念和分析有效应用到大量复杂数据中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;h2 style="margin-top: 8px; font-weight: bold; max-width: 100%; white-space: normal; border-color: rgb(216, 40, 33); text-align: justify; color: rgb(216, 40, 33); line-height: 28px; font-family: 微软雅黑; border-bottom-width: 2px; border-bottom-style: solid; min-height: 32px; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;span&gt;&lt;/span&gt;Facebook Messenger 新功能：投票+自动转账&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Facebook 打算在自家聊天应用 Messenger 中增加两项新功能：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;一个是群聊投票&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;另一个是通过机器学习技术来检测转账交易&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些新功能最快本周就能上线，不过目前仅限美国用户使用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicF8wXlBVVVUGiahn69Rw7OWIqxfgpRBIXoYLKz8a0agXwFiavO1sZznVeI5X9Kj1dy4AncY2RWExfQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;聊天应用一大好处就是群组聊天十分便利，但也正因为人数众多，每当大家要做决定时众口难调。所以 Facebook 计划只在群组聊天中推出「投票」这项新功能，只要输入问题和一些选项，群组中任何人都能直接发起投票，且投票没有时间限制。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicF8wXlBVVVUGiahn69Rw7OWRkXqiaHtbKJ9k2Hyxy09sCJdflLprtFUyWKFChALCVNeaicX56yddlIQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;另一个新功能是利用机器学习技术来检测用户的转账交易，通过这项技术对用户对话中的内容进行分析。当出现相关词汇时，在 Facebook Messenger 应用中将会出现转账链接，用户可以通过这个链接直接进行转账操作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h2 style="margin-top: 8px; font-weight: bold; max-width: 100%; white-space: normal; border-color: rgb(216, 40, 33); text-align: justify; color: rgb(216, 40, 33); line-height: 28px; font-family: 微软雅黑; border-bottom-width: 2px; border-bottom-style: solid; min-height: 32px; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;span&gt;&lt;/span&gt;Uber的新加坡对手Grab也能叫到无人车了&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicF8wXlBVVVUGiahn69Rw7OWt2bbGicjJd5NUTwZAePBp77wX4bMr1zahxu09I9ylibFrXdY01kpUr5w/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;据外媒报道，新加坡打车应用 Grab 与创业公司 nuTonomy 达成合作，在新加坡测试自动驾驶技术。从周五开始，Grab 用户将能够预约到 nuTonomy 的无人车。就在几天前，Uber 开始在匹兹堡面向公众测试自动驾驶汽车。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前，科技公司和汽车制造商都在争相开发自动驾驶汽车，制定新的商业计划。从长期来看，自动驾驶汽车预计将改变个人出行方式。Grab 表示，其应用将允许选定通勤者在新加坡西部地区和毗邻区预约并乘坐 nuTonomy 无人车。nuTonomy 无人车目前正在新加坡西部地区进行测试。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Grab 和 nuTonomy 在一份声明中称，每一辆无人车中都将配备一位负责安全的司机和一位技术支持工程师。nuTonomy 从今年 8 月份开始在新加坡对其首辆无人驾驶出租车进行公开测试，该公司希望于 2018 年在新加坡推出 100 辆可商业化运营的无人驾驶出租车。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h2 style="margin-top: 8px; font-weight: bold; max-width: 100%; white-space: normal; border-color: rgb(216, 40, 33); text-align: justify; color: rgb(216, 40, 33); line-height: 28px; font-family: 微软雅黑; border-bottom-width: 2px; border-bottom-style: solid; min-height: 32px; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;span&gt;&lt;/span&gt;微软编程语言 TypeScript 2.0 发布&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicF8wXlBVVVUGiahn69Rw7OWjSaIfiaCEpZbmCMxECgNmB8jia2UWibXCEicdx238BmLQJEkUibseUiaQzLw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;微软在 JavaScript 基础上开发的编程语言 TypeScript 发布了 2.0 版。开发 JavaScript 大型程序是一大挑战，原因是它在程序运行时才执行错误检查，而其它静态编译语言开发的程序是在编译时就会执行错误检查。通过 TypeScript，微软在保证兼容性的同时为 JavaScript 引入了类似其它语言的错误和验证。在 TypeScript 2.0 中，微软引入的最大变化是对 null 值的控制。null 被用于表示没有任何值的变量。但 null 引用会导致很多问题，它的发明被作者称为是「十亿美元错误」，然而所有主流编程语言都支持 null 概念。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;微软为 TypeScript 2.0 加入了控制 null 值的选项，启用选项后变量默认被要求设定一个值，避免无意中将变量值设为 null。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;h2 style="margin-top: 8px; font-weight: bold; max-width: 100%; white-space: normal; border-color: rgb(216, 40, 33); text-align: justify; color: rgb(216, 40, 33); line-height: 28px; font-family: 微软雅黑; border-bottom-width: 2px; border-bottom-style: solid; min-height: 32px; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;span&gt;&lt;/span&gt;谷歌放出测试版VR SDK，开发者可开发Daydream应用了&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicF8wXlBVVVUGiahn69Rw7OWjcxR8ictagyjbAW9AicibDGbcZoO9LkLStuVtlDW2qian9QTp8Jyt8rwWA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;据外媒报道，在今年 5 月的 Google I/O 大会上，谷歌推出了高质量的移动 VR 平台 Daydream。在收集了数月的反馈后，它们终于放出了测试版的谷歌 VR SDK，开发者可以开始打造 Daydream 应用了。此外，由于谷歌已经与 Unity 和 Unreal 达成合作，开发者们还能直接用上两家公司的游戏引擎和开发工具。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一版 SDK 简化了 VR 开发任务，允许开发者集中精力打造「沉浸感十足的移动交互 VR 应用。」同时，它还支持异步投影技术（asynchronous reprojection，可提高刷新率）和高保真立体音效。此外，Daydream 的手柄可玩性也很强。谷歌 VR SDK 原生就支持 Unity 的引擎和开发工具，因此游戏可以得到更好的优化。此外，SDK 中还加入了对头部追踪和深度链接的支持。同时，Unreal Engine 4 的加入也让开发者如虎添翼。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编辑整理，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Fri, 23 Sep 2016 17:15:03 +0800</pubDate>
    </item>
    <item>
      <title>深度 | 从硬件配置到软件安装，一台深度学习机器的配备指南</title>
      <link>http://www.iwgc.cn/link/2792414</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自graphific.github.io &lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;作者：Roelof Pieters&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李亚洲、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;本文作者 Roelof Pieters 是瑞典皇家理工学院 Institute of Technology &amp;amp; Consultant for Graph-Technologies 研究深度学习的一位在读博士，他同时也运营着自己的面向客户的深度学习产品。对于写作这个系列文章的动机，他写道：「我已经习惯了在云上工作，并且还将继续在云上开发面向产品的系统/算法。但是在更面向研究的任务上，基于云的系统还存在一些缺陷，因为在研究时你要做的基本上就是尝试各种各样的算法和架构，并且需要快速改进和迭代。为了做到这一点，我决定自己使用 GPU 设计和打造自己的量身定制的深度学习系统。在这一些方面这比我想象的简单，但另一些方面却更困难。在接下来的文章中，我会和你分享我的『冒险之旅』，不关你是深度学习实践的新手还是老手，希望这都对你有用。」目前该系列文章已经更新了两篇，机器之心将其统一编译到了这篇文章中。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;第一部分：硬件平台搭建&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOwIooT5Fz9r9ps6LXYb0t2PmyWquGMTbbX6edQEjaPueF9TeznG0Lgrg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你像我一样，每天（和每夜）都在和实际的机器学习应用打交道，你就知道在完成一项任务时如果没有合适的硬件会有多么痛苦。不管你是业界人士还是在学术界工作，为了一项实验或计算的结果等待不必要长的时间总是会让人感到烦恼。对于用于生产的研究和开发，高速硬件是必需的，而 GPU 通常是我们所面临的主要瓶颈，尤其对于深度神经网络（DNN）更是如此。是的，确实是这样：亚马逊这样的云提供商以低于每小时 1 美元的价格出售可以执行 GPU 计算的实例和可以导出、共享和重复使用的可以直接进行生产的虚拟机。如果你常常从头开始安装库，你可能知道软件和硬件库都可以使用定期更新的安装脚本或 dockerized 容器轻松地完成安装。这些都还不错。但是如果一个应用的需求超过了亚马逊所能提供的 4GB GPU 呢（即使他们最新的 g2.8xlarge 仍然也只提供同样的 4GB GPU）？其它云提供商也很少提供更大的 GPU（通常是 6GB），而且似乎都是专门为特定的应用（视频版或生物科学）定制的。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;那么如果你有这种需求，你该怎么做呢？很简单，搭建你自己的 GPU 平台！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;目录&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;了解你的研究&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;起步：选择正确的组件&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;将它们组装到一起&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;DIY 或寻求帮助&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;选项 A：DIY&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;选项 B：外界帮助&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;了解你的研究&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一旦我决定了搭建我自己的 GPU 系统时，我首先想到的是：为什么要这么麻烦自己去搭建一个呢，英伟达不是刚发布了其强大的 DevBox 吗，而且还可能有其它供应商也在为深度学习应用做同样的事？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;确实如此，也有一些其它公司在生产面向研究的机器，但它们都不面向欧洲发售。英伟达的 DevBox 也仅在美国出售，而且价格还高得离谱（大约 9000 美元的硬件组件售价 1.5 万美元），而且还要排队等待。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以该怎么办呢？简单：搭建你自己的 GPU 平台！&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;起步：选择正确的组件&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;浏览网络时我发现 Tim Dettmers 的博客（http://timdettmers.com/）很好地讲解了如何为深度学习应用选择合适的 GPU 和硬件。在这里我不打算将他说过的内容再完全重复一遍。你可以自己去他的博客看！文章和下面的评论都值得一读。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;简而言之：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;双精度（比如英伟达的 Tesla K20/40/80）完全是浪费钱，因为 DNN 不需要这样的精度；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;想想你现在和未来需要多少个 GPU。4 个 GPU 是最多了，因为再多也不能再带来太多性能增益了。这主要是因为最好的主板最多只支持最多 40 个通道（以 16x8x8x8 的配置）。另外，每个 GPU 都会增加一定的管理工作——你的系统需要决定使用哪个 GPU 来执行哪项任务。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;获取一个支持 PCIe 3.0 的主板，它还要支持一根线缆上带有 8pin + 6pin 的 PCIe 电源连接器，这样你才能添加到 4 个 GPU。主板还应该支持你的 GPU 配置，即支持 x8/x8/x8/x8 的 4 GPU 设置的物理线路；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;找一个能把所有东西都装进去的机箱。越大的机箱空气流动就越好。确保有足够的 PCIe 槽以支持所有 GPU 以及其它你可能需要安装的 PCIe 卡（比如高速千兆网卡等）。一个 GPU 通常会占据 2 个 PCIe 插槽的空间。一个典型的机箱需要有 7 个 PCIe 槽，因为最后一个安装在底部的 GPU 可以仅使用一个槽。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;CPU 不需要非常快，也不需要有很多核。只需要确保 CPU 的核数至少是你的 GPU 的数量的两倍就可以了（再次强调：要考虑未来的使用情况；英特尔的 CPU 通常一个核有两个线程）。还要确保该 CPU 支持 40 个 PCIe 通道，一些新的 Haswell CPU 只支持 32 个；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;RAM 大小是你的全部 GPU 内存之和的两倍；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;SSD 很不错，但除非决定有必要才用——如果你加载的数据无法配入到 GPU 内存和 RAM 的组合中。如果你确实要使用一个 SSD，它的容量至少应该大于你最大的数据集；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;至于普通的机械硬盘，你可能需要大量的磁盘空间来存储你的数据集和其它类型的数据。如果你需要至少 3 个同样大小的磁盘，RAID5 就很不错。基本上一旦发生单个错误时，你不会丢失你的数据。用于提升性能的 RAID0 等其它 RAID 配置通常没多大用处：你可用 SSD 提速，而且它已经超过了你的 GPU 通过 PCIe 带宽加载数据的速度；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;至于供电单元（PSU），只要你负担得起，就尽可能选一个最高效的，并且要把你所需要的总功率考虑在内（要考虑未来的使用）：钛或铂金品质的 PSU 值得你花钱购买：你能省钱和保护环境，因为其所节省的电力开销用不了多久就能把你的额外购买成本节省回来。对于 4 GPU 系统，你大概需要 1500 到 1600 W；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;冷却是非常非常重要的，因为它会同时影响到性能和噪音。你需要一直将 GPU 的温度保持在 80 度（约 26.7 摄氏度）以下。更高的温度会拉低该单元的电压并影响到性能。另外，太高的温度也对你的 GPU 有害；这是你需要避免的。冷却有两种主要选项：风冷（风扇）和水冷（管道）：&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: circle;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;风冷更便宜、安装和维护更简单、但会制造大量噪音；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;水冷价格更高、难以正确安装，但没有任何噪音，而且对组件的冷却效果也好得多。但你总归需要机箱风扇来冷却其它组件，所以你总会听到一些噪音，但会比全风冷的系统的噪音小。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;将它们组装到一起&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;根据我读到的内容、Tim Dettmers 的回复和英伟达的 DevBox and Gamer 论坛的建议，我开始将这些组件组装到一起。很明显这台机器受到了英伟达 DevBox 的部分启发（至少机箱是这样），但价格差不多只有 DevBox 的一半。&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;机箱：Carbide Air 540 High Airflow ATX Cube&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;主板：华硕 X99-E WS 工作站级主板，带有 4 路 PCI-E Gen3 x16 支持&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;RAM：64GB DDR4 Kingston 2133Mhz (8x8GB)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;CPU：Intel(Haswell-e) Core i7 5930K (http://ark.intel.com/products/82931/Intel-Core-i7-5930K-Processor-15M-Cache-up-to-3_70-GHz) (6 Core 3.5GHz)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;GPU：3 块 NVIDIA GTX TITAN-X 12GB&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;HDD：3 块 RAID5 配置的 3TB WD Red&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;SSD：2 块 500GB SSD Samsung EVO 850&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;PSU： Corsair AX1500i (1500 W) 80 Plus Titanium (94% 的能效)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;冷却：用于 CPU 和 GPU 的自制水冷系统（软管）：在机箱顶部钻了一个注水孔，前面有一个透明的储水器（见下图）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOwXTqYO0hetKia6KrHt1ZlrrrHsXKibrldc6zqhFHbWP6xSyk1C5gKMLzA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;左图：正在构建中的系统。你可以看到用于水冷的塑料管穿过 Carbide Air 540 机箱上原本就有的孔洞。主板是竖直安装的。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;中图和右图：建造好的系统。注意可以从外面看到的储水器。还可以看到从上至下的红色塑料管：上连注水口，下接水泵，穿过安装在 GPU 上的散热器模块。还可以看到 CPU 上有一个类似的结构。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;DIY 或寻求帮助&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;选项 A：DIY&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当然，如果你有时间和意愿自己动手打造所有的一切，这将成为你完全理解各个组件的工作方式以及哪些硬件可以很好适配的绝佳方法。另外，你也可能能更好地理解当组件出现故障时应该做什么并更轻松地修复它。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;选项 B：外界帮助&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一种选择是寻找专业的公司预定零件并让他们帮助组装好整个系统。你要寻找的这类公司应该是定制游戏机电脑的公司，他们常常为游戏玩家打造定制化的系统。他们甚至有水冷系统的经验，尽管游戏机电脑通常只需要水冷 CPU，但他们会有很好用的工具套件。当然，为了安装全水冷系统，你需要将 GPU 外壳打开，将芯片暴露出来安装散热片，再装上水管、压缩机帽等等各种所需的组件。不过水冷也有麻烦的地方：一旦出现漏水，你的 GPU 和其它组件就会被毁坏。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因为我觉得我不能将这些东西装在一起以及正确地安装水冷气系统，而且我还没有多少时间阅读操作手册，所以我选择了第二种方案：找了一个非常熟练的硬件打造商帮我组装了我的深度学习机器的第一个版本。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;第二部分：安装软件和库&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;目录&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;软件和库&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="list-style-type: decimal;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;安装 CUDA&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;测试 CUDA&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;深度学习库&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;软件和库&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在，我们有了一台裸机，是时候安装软件了！网上已有有了一些好的博文指导安装深度学习工具和库。为了简单化，我临时把一些要旨放在一起。这篇个文章将帮助你安装英伟达 CUDA 驱动，以及我青睐的一些深度学习工具与库。此外，我也假设你已经在电脑上安装了 Ubuntu 14.04.3 作为操作系统。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1.安装 CUDA&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;让图像驱动程序能正常工作是一件很痛苦的事。我当时的问题是 Titan X GPU 只能得到 Nvidia 346 的支持，这些驱动不能在我特定的监控器下工作。经过一些 xconfig 改装，我终于让它能在高于 800×600 的分辨率下工作了，我使用了 LINUX X64 (AMD64/EM64T) DISPLAY DRIVER 352.30 版本作为图像驱动。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;设置演示安装的是 CUDA 7.0，我选择安装最新的 CUDA 7.5。虽然该版本的确有所改进，但在一些库上也难以正常工作。如果你想快速启动并运行，可以尝试 7.0 版本。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;!/usr/bin/env bash&lt;br/&gt;# Installation script for Cuda and drivers on Ubuntu 14.04, by Roelof Pieters (@graphific)&lt;br/&gt;# BSD License&lt;br/&gt;if [ "$(whoami)" == "root" ]; then&lt;br/&gt; &amp;nbsp;echo "running as root, please run as user you want to have stuff installed as"&lt;br/&gt; &amp;nbsp;exit 1&lt;br/&gt;fi&lt;br/&gt;###################################&lt;br/&gt;# &amp;nbsp; Ubuntu 14.04 Install script for:&lt;br/&gt;# - Nvidia graphic drivers for Titan X: 352&lt;br/&gt;# - Cuda 7.0 (7.5 gives "out of memory" issues)&lt;br/&gt;# - CuDNN3&lt;br/&gt;# - Theano (bleeding edge)&lt;br/&gt;# - Torch7&lt;br/&gt;# - ipython notebook (running as service with circus auto(re)boot on port 8888)&lt;br/&gt;# - itorch notebook (running as service with circus auto(re)boot on port 8889)&lt;br/&gt;# - Caffe &lt;br/&gt;# - OpenCV 3.0 gold release (vs. 2015-06-04)&lt;br/&gt;# - Digits&lt;br/&gt;# - Lasagne&lt;br/&gt;# - Nolearn&lt;br/&gt;# - Keras&lt;br/&gt;###################################&lt;br/&gt;&lt;br/&gt;# started with a bare ubuntu 14.04.3 LTS install, with only ubuntu-desktop installed&lt;br/&gt;# script will install the bare minimum, with all "extras" in a seperate venv&lt;br/&gt;&lt;br/&gt;export DEBIAN_FRONTEND=noninteractive&lt;br/&gt;&lt;br/&gt;sudo apt-get update -y&lt;br/&gt;sudo apt-get install -y git wget linux-image-generic build-essential unzip&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;# manual driver install with:&lt;br/&gt;# sudo service lightdm stop&lt;br/&gt;# (login on non graphical terminal)&lt;br/&gt;# wget http://uk.download.nvidia.com/XFree86/Linux-x86_64/352.30/NVIDIA-Linux-x86_64-352.30.run&lt;br/&gt;# chmod +x ./NVIDIA-Linux-x86_64-352.30.run&lt;br/&gt;# sudo ./NVIDIA-Linux-x86_64-352.30.run&lt;br/&gt;&lt;br/&gt;# Cuda 7.0&lt;br/&gt;# instead we install the nvidia driver 352 from the cuda repo&lt;br/&gt;# which makes it easier than stopping lightdm and installing in terminal&lt;br/&gt;cd /tmp&lt;br/&gt;wget http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1404/x86_64/cuda-repo-ubuntu1404_7.0-28_amd64.deb&lt;br/&gt;sudo dpkg -i cuda-repo-ubuntu1404_7.0-28_amd64.deb&lt;br/&gt;&lt;br/&gt;echo -e "\nexport CUDA_HOME=/usr/local/cuda\nexport CUDA_ROOT=/usr/local/cuda" &amp;gt;&amp;gt; ~/.bashrc&lt;br/&gt;echo -e "\nexport PATH=/usr/local/cuda/bin:\$PATH\nexport LD_LIBRARY_PATH=/usr/local/cuda/lib64:\$LD_LIBRARY_PATH" &amp;gt;&amp;gt; ~/.bashrc&lt;br/&gt;&lt;br/&gt;echo "CUDA installation complete: please reboot your machine and continue with script #2"&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2. 测试 CUDA&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;完成安装了？很好，接下来让我们看一下 CUDA 驱动是否能够正常工作。直接进入 CUDA 样本目录，运行 ./deviceQuery。你的 GPU 应该会被显示如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOwE3NZHSXicdLje6gyeoCPEMnFH9Miby043ZzufY4ctqO3ic0BIAmfWfrbQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;#!/usr/bin/env bash&lt;br/&gt;# Test script for checking if Cuda and Drivers correctly installed on Ubuntu 14.04, by Roelof Pieters (@graphific)&lt;br/&gt;# BSD License&lt;br/&gt;&lt;br/&gt;if [ "$(whoami)" == "root" ]; then&lt;br/&gt; &amp;nbsp;echo "running as root, please run as user you want to have stuff installed as"&lt;br/&gt; &amp;nbsp;exit 1&lt;br/&gt;fi&lt;br/&gt;###################################&lt;br/&gt;# &amp;nbsp; Ubuntu 14.04 Install script for:&lt;br/&gt;# - Nvidia graphic drivers for Titan X: 352&lt;br/&gt;# - Cuda 7.0 (7.5 gives "out of memory" issues)&lt;br/&gt;# - CuDNN3&lt;br/&gt;# - Theano (bleeding edge)&lt;br/&gt;# - Torch7&lt;br/&gt;# - ipython notebook (running as service with circus auto(re)boot on port 8888)&lt;br/&gt;# - itorch notebook (running as service with circus auto(re)boot on port 8889)&lt;br/&gt;# - Caffe &lt;br/&gt;# - OpenCV 3.0 gold release (vs. 2015-06-04)&lt;br/&gt;# - Digits&lt;br/&gt;# - Lasagne&lt;br/&gt;# - Nolearn&lt;br/&gt;# - Keras&lt;br/&gt;###################################&lt;br/&gt;&lt;br/&gt;# started with a bare ubuntu 14.04.3 LTS install, with only ubuntu-desktop installed&lt;br/&gt;# script will install the bare minimum, with all "extras" in a seperate venv&lt;br/&gt;&lt;br/&gt;export DEBIAN_FRONTEND=noninteractive&lt;br/&gt;&lt;br/&gt;# Checking cuda installation&lt;br/&gt;# installing the samples and checking the GPU&lt;br/&gt;cuda-install-samples-7.0.sh ~/&lt;br/&gt;cd NVIDIA\_CUDA-7.0\_Samples/1\_Utilities/deviceQuery &amp;nbsp;&lt;br/&gt;make &amp;nbsp;&lt;br/&gt;&lt;br/&gt;#Samples installed and GPU(s) Found ?&lt;br/&gt;./deviceQuery &amp;nbsp;| grep "Result = PASS"&lt;br/&gt;greprc=$?&lt;br/&gt;if [[ $greprc -eq 0 ]] ; then&lt;br/&gt; &amp;nbsp; &amp;nbsp;echo "Cuda Samples installed and GPU found"&lt;br/&gt; &amp;nbsp; &amp;nbsp;echo "you can also check usage and temperature of gpus with nvidia-smi"&lt;br/&gt;else&lt;br/&gt; &amp;nbsp; &amp;nbsp;if [[ $greprc -eq 1 ]] ; then&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;echo "Cuda Samples not installed, exiting..."&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;exit 1&lt;br/&gt; &amp;nbsp; &amp;nbsp;else&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;echo "Some sort of error, exiting..."&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;exit 1&lt;br/&gt; &amp;nbsp; &amp;nbsp;fi&lt;br/&gt;fi&lt;br/&gt;&lt;br/&gt;echo "now would be time to install cudnn for a speedup"&lt;br/&gt;echo "unfortunately only available by registering on nvidias website:"&lt;br/&gt;echo "https://developer.nvidia.com/cudnn"&lt;br/&gt;echo "deep learning libraries can be installed with final script #3"&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3. 深度学习库&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;好了，来到最后一步，它也是很有趣的一部分：选择个人偏好的深度学习库，这也是由所在领域所决定的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;作为研究人员，Theano 能给你最大的自由度，做自己想做的事。你可以自己部署许多事，也因此更能深度理解 DNN 如何工作。但对想首先尝试下的初学者来说可能不合适。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;我个人是 Keras（主要贡献者：François Chollet，已经加入了谷歌）和 Lasagne（8 个人的团队，但主要贡献者是 Sander Dielemans，近期读完了博士，如今加入了谷歌 DeepMind）的粉丝。这两个库有很好的抽象水平，也被积极的开发，也提供插入自己模块或代码工程的简单方式。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如果你习惯 Python，那使用 Torch 会具有挑战性，因为你需要学习 Lua。在使用 Torch 一段时间之后，我可以说它是一个很好使用的语言。唯一一个问题是从其他语言接入到 Lua 很难。对研究目的，Torch 表现也很好。但对生产水平管道而言，Torch 难以进行测试，而且看起来完全缺乏任何类型的错误处理。Torch 积极的一面有：支持 CUDA，有很多可以使用的 程序包。Torch 看起来也是产业内使用最普遍的库。Facebook（Ronan Collobert &amp;amp; Soumith Chintala）、DeepMind（Koray Kavukçuoğlu）、Twitter（Clement Farabet）的这些人都是主要贡献者。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Caffe 是之前占据主导地位的深度学习框架（主要用于 Convnets），如今仍在被普遍使用，也是一个可以作为开始的很好的框架。训练制度（solver.prototxt）与架构（train val.prototxt）文档之间的分离使得实验更容易进行。我发现 Caffe 也是唯一一个支持使用电脑外多 GPU 的框架，你可以穿过 GPU 或 GPU id 参数使用所有可用的 GPU。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;Blocks 是最近的一款基于 Python 的框架，很好的分离了自己编写的模块与被称为 Brick 的模块。特别是其 partner「Fuel」，是一个处理数据的很好方式。Fuel 是一个对许多已有的或你自己的数据集的 wrapper。它利用「iteration schemes」将数据导流到模型中，并可以「transformers」所有类型的数据转换和预处理步骤。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Neon 是 Nervana System 公司基于 Python 的深度学习框架，建立在 Nervana 的 GPU Kernel（对英伟达 CuDNN 的替代）之上。Neon 是运行该特殊 Kernel 的唯一框架，最新的基准测试显示在一些特定任务上它是最快的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOwHWOlLv9578czee8dNRibGZhoiaEAia8Aibr7wemR7urChwUm0kICZpX4Zg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;展示深度学习库（面向 Python）的另一种方式：从更低层次的 DIY 到更高层次的、更功能性的框架。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;准备好了吗？下面的脚本将安装 Theano、Torch、Caffe、Digits、Lasange、Keras。我们之前用过 Digits，但它是一个建立在 Caffe 之上的图形网页接口。这相当的基础，但如果你刚开始的话，训练一些 ConvNets 以及建立一些图形分类器会是很简单的方法。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;#!/usr/bin/env bash&lt;br/&gt;# Installation script for Deep Learning Libraries on Ubuntu 14.04, by Roelof Pieters (@graphific)&lt;br/&gt;# BSD License&lt;br/&gt;&lt;br/&gt;orig_executor="$(whoami)"&lt;br/&gt;if [ "$(whoami)" == "root" ]; then&lt;br/&gt; &amp;nbsp;echo "running as root, please run as user you want to have stuff installed as"&lt;br/&gt; &amp;nbsp;exit 1&lt;br/&gt;fi&lt;br/&gt;###################################&lt;br/&gt;# &amp;nbsp; Ubuntu 14.04 Install script for:&lt;br/&gt;# - Nvidia graphic drivers for Titan X: 352&lt;br/&gt;# - Cuda 7.0 (7.5 gives "out of memory" issues)&lt;br/&gt;# - CuDNN3&lt;br/&gt;# - Theano (bleeding edge)&lt;br/&gt;# - Torch7&lt;br/&gt;# - ipython notebook (running as service with circus auto(re)boot on port 8888)&lt;br/&gt;# - itorch notebook (running as service with circus auto(re)boot on port 8889)&lt;br/&gt;# - Caffe &lt;br/&gt;# - OpenCV 3.0 gold release (vs. 2015-06-04)&lt;br/&gt;# - Digits&lt;br/&gt;# - Lasagne&lt;br/&gt;# - Nolearn&lt;br/&gt;# - Keras&lt;br/&gt;###################################&lt;br/&gt;&lt;br/&gt;export DEBIAN_FRONTEND=noninteractive&lt;br/&gt;sudo apt-get install -y libncurses-dev&lt;br/&gt;&lt;br/&gt;# next part copied from (check there for newest version): &lt;br/&gt;# https://github.com/deeplearningparis/dl-machine/blob/master/scripts/install-deeplearning-libraries.sh&lt;br/&gt;&lt;br/&gt;####################################&lt;br/&gt;# Dependencies&lt;br/&gt;####################################&lt;br/&gt;&lt;br/&gt;# Build latest stable release of OpenBLAS without OPENMP to make it possible&lt;br/&gt;# to use Python multiprocessing and forks without crash&lt;br/&gt;# The torch install script will install OpenBLAS with OPENMP enabled in&lt;br/&gt;# /opt/OpenBLAS so we need to install the OpenBLAS used by Python in a&lt;br/&gt;# distinct folder.&lt;br/&gt;# Note: the master branch only has the release tags in it&lt;br/&gt;sudo apt-get install -y gfortran&lt;br/&gt;export OPENBLAS_ROOT=/opt/OpenBLAS-no-openmp&lt;br/&gt;export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$OPENBLAS_ROOT/lib&lt;br/&gt;if [ ! -d "OpenBLAS" ]; then&lt;br/&gt; &amp;nbsp; &amp;nbsp;git clone -q --branch=master git://github.com/xianyi/OpenBLAS.git&lt;br/&gt; &amp;nbsp; &amp;nbsp;(cd OpenBLAS \&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;amp;&amp;amp; make FC=gfortran USE_OPENMP=0 NO_AFFINITY=1 NUM_THREADS=$(nproc) \&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;amp;&amp;amp; sudo make install PREFIX=$OPENBLAS_ROOT)&lt;br/&gt; &amp;nbsp; &amp;nbsp;echo "export LD_LIBRARY_PATH=$LD_LIBRARY_PATH" &amp;gt;&amp;gt; ~/.bashrc&lt;br/&gt;fi&lt;br/&gt;sudo ldconfig&lt;br/&gt;&lt;br/&gt;# Python basics: update pip and setup a virtualenv to avoid mixing packages&lt;br/&gt;# installed from source with system packages&lt;br/&gt;sudo apt-get update -y &lt;br/&gt;sudo apt-get install -y python-dev python-pip htop&lt;br/&gt;sudo pip install -U pip virtualenv&lt;br/&gt;if [ ! -d "venv" ]; then&lt;br/&gt; &amp;nbsp; &amp;nbsp;virtualenv venv&lt;br/&gt; &amp;nbsp; &amp;nbsp;echo "source ~/venv/bin/activate" &amp;gt;&amp;gt; ~/.bashrc&lt;br/&gt;fi&lt;br/&gt;source venv/bin/activate&lt;br/&gt;pip install -U pip&lt;br/&gt;pip install -U circus circus-web Cython Pillow&lt;br/&gt;&lt;br/&gt;# Checkout this project to access installation script and additional resources&lt;br/&gt;if [ ! -d "dl-machine" ]; then&lt;br/&gt; &amp;nbsp; &amp;nbsp;git clone git@github.com:deeplearningparis/dl-machine.git&lt;br/&gt; &amp;nbsp; &amp;nbsp;(cd dl-machine &amp;amp;&amp;amp; git remote add http https://github.com/deeplearningparis/dl-machine.git)&lt;br/&gt;else&lt;br/&gt; &amp;nbsp; &amp;nbsp;if &amp;nbsp;[ "$1" == "reset" ]; then&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;(cd dl-machine &amp;amp;&amp;amp; git reset --hard &amp;amp;&amp;amp; git checkout master &amp;amp;&amp;amp; git pull --rebase $REMOTE master)&lt;br/&gt; &amp;nbsp; &amp;nbsp;fi&lt;br/&gt;fi&lt;br/&gt;&lt;br/&gt;# Build numpy from source against OpenBLAS&lt;br/&gt;# You might need to install liblapack-dev package as well&lt;br/&gt;# sudo apt-get install -y liblapack-dev&lt;br/&gt;rm -f ~/.numpy-site.cfg&lt;br/&gt;ln -s dl-machine/numpy-site.cfg ~/.numpy-site.cfg&lt;br/&gt;pip install -U numpy&lt;br/&gt;&lt;br/&gt;# Build scipy from source against OpenBLAS&lt;br/&gt;rm -f ~/.scipy-site.cfg&lt;br/&gt;ln -s dl-machine/scipy-site.cfg ~/.scipy-site.cfg&lt;br/&gt;pip install -U scipy&lt;br/&gt;&lt;br/&gt;# Install common tools from the scipy stack&lt;br/&gt;sudo apt-get install -y libfreetype6-dev libpng12-dev&lt;br/&gt;pip install -U matplotlib ipython[all] pandas scikit-image&lt;br/&gt;&lt;br/&gt;# Scikit-learn (generic machine learning utilities)&lt;br/&gt;pip install -e git+git://github.com/scikit-learn/scikit-learn.git#egg=scikit-learn&lt;br/&gt;&lt;br/&gt;####################################&lt;br/&gt;# OPENCV 3&lt;br/&gt;####################################&lt;br/&gt;# from http://rodrigoberriel.com/2014/10/installing-opencv-3-0-0-on-ubuntu-14-04/&lt;br/&gt;# for 2.9 see http://www.samontab.com/web/2014/06/installing-opencv-2-4-9-in-ubuntu-14-04-lts/ &lt;br/&gt;cd ~/&lt;br/&gt;sudo apt-get -y install libopencv-dev build-essential cmake git libgtk2.0-dev \&lt;br/&gt; &amp;nbsp; pkg-config python-dev python-numpy libdc1394-22 libdc1394-22-dev libjpeg-dev \&lt;br/&gt; &amp;nbsp; libpng12-dev libtiff4-dev libjasper-dev libavcodec-dev libavformat-dev \&lt;br/&gt; &amp;nbsp; libswscale-dev libxine-dev libgstreamer0.10-dev libgstreamer-plugins-base0.10-dev \&lt;br/&gt; &amp;nbsp; libv4l-dev libtbb-dev libqt4-dev libfaac-dev libmp3lame-dev libopencore-amrnb-dev \&lt;br/&gt; &amp;nbsp; libopencore-amrwb-dev libtheora-dev libvorbis-dev libxvidcore-dev x264 v4l-utils unzip&lt;br/&gt;&lt;br/&gt;wget https://github.com/Itseez/opencv/archive/3.0.0.tar.gz -O opencv-3.0.0.tar.gz&lt;br/&gt;tar -zxvf &amp;nbsp;opencv-3.0.0.tar.gz&lt;br/&gt;&lt;br/&gt;cd opencv-3.0.0&lt;br/&gt;mkdir build&lt;br/&gt;cd build&lt;br/&gt;&lt;br/&gt;cmake -D CMAKE_BUILD_TYPE=RELEASE -D CMAKE_INSTALL_PREFIX=/usr/local -D WITH_TBB=ON -D BUILD_NEW_PYTHON_SUPPORT=ON -D WITH_V4L=ON -D WITH_QT=ON -D WITH_OPENGL=ON ..&lt;br/&gt;make -j $(nproc)&lt;br/&gt;sudo make install&lt;br/&gt;&lt;br/&gt;sudo /bin/bash -c 'echo "/usr/local/lib" &amp;gt; /etc/ld.so.conf.d/opencv.conf'&lt;br/&gt;sudo ldconfig&lt;br/&gt;ln -s /usr/lib/python2.7/dist-packages/cv2.so /home/$orig_executor/venv/lib/python2.7/site-packages/cv2.so&lt;br/&gt;&lt;br/&gt;echo "opencv 3.0 installed"&lt;br/&gt;&lt;br/&gt;####################################&lt;br/&gt;# Theano&lt;br/&gt;####################################&lt;br/&gt;# installing theano&lt;br/&gt;# By default, Theano will detect if it can use cuDNN. If so, it will use it. &lt;br/&gt;# To get an error if Theano can not use cuDNN, use this Theano flag: optimizer_including=cudnn.&lt;br/&gt;&lt;br/&gt;pip install -e git+git://github.com/Theano/Theano.git#egg=Theano&lt;br/&gt;if [ ! -f ".theanorc" ]; then&lt;br/&gt; &amp;nbsp; &amp;nbsp;ln -s ~/dl-machine/theanorc ~/.theanorc&lt;br/&gt;fi&lt;br/&gt;&lt;br/&gt;echo "Installed Theano"&lt;br/&gt;&lt;br/&gt;# Tutorial files&lt;br/&gt;if [ ! -d "DL4H" ]; then&lt;br/&gt; &amp;nbsp; &amp;nbsp;git clone git@github.com:SnippyHolloW/DL4H.git&lt;br/&gt; &amp;nbsp; &amp;nbsp;(cd DL4H &amp;amp;&amp;amp; git remote add http https://github.com/SnippyHolloW/DL4H.git)&lt;br/&gt;else&lt;br/&gt; &amp;nbsp; &amp;nbsp;if &amp;nbsp;[ "$1" == "reset" ]; then&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;(cd DL4H &amp;amp;&amp;amp; git reset --hard &amp;amp;&amp;amp; git checkout master &amp;amp;&amp;amp; git pull --rebase $REMOTE master)&lt;br/&gt; &amp;nbsp; &amp;nbsp;fi&lt;br/&gt;fi&lt;br/&gt;&lt;br/&gt;####################################&lt;br/&gt;# Torch&lt;br/&gt;####################################&lt;br/&gt;&lt;br/&gt;if [ ! -d "torch" ]; then&lt;br/&gt; &amp;nbsp; &amp;nbsp;curl -sk https://raw.githubusercontent.com/torch/ezinstall/master/install-deps | bash&lt;br/&gt; &amp;nbsp; &amp;nbsp;git clone https://github.com/torch/distro.git ~/torch --recursive&lt;br/&gt; &amp;nbsp; &amp;nbsp;(cd ~/torch &amp;amp;&amp;amp; yes | ./install.sh)&lt;br/&gt;fi&lt;br/&gt;. ~/torch/install/bin/torch-activate&lt;br/&gt;&lt;br/&gt;if [ ! -d "iTorch" ]; then&lt;br/&gt; &amp;nbsp; &amp;nbsp;git clone git@github.com:facebook/iTorch.git&lt;br/&gt; &amp;nbsp; &amp;nbsp;(cd iTorch &amp;amp;&amp;amp; git remote add http https://github.com/facebook/iTorch.git)&lt;br/&gt;else&lt;br/&gt; &amp;nbsp; &amp;nbsp;if &amp;nbsp;[ "$1" == "reset" ]; then&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;(cd iTorch &amp;amp;&amp;amp; git reset --hard &amp;amp;&amp;amp; git checkout master &amp;amp;&amp;amp; git pull --rebase $REMOTE master)&lt;br/&gt; &amp;nbsp; &amp;nbsp;fi&lt;br/&gt;fi&lt;br/&gt;(cd iTorch &amp;amp;&amp;amp; luarocks make)&lt;br/&gt;&lt;br/&gt;cd ~/&lt;br/&gt;git clone https://github.com/torch/demos.git torch-demos&lt;br/&gt;&lt;br/&gt;#qt dependency&lt;br/&gt;sudo apt-get install -y qt4-dev-tools libqt4-dev libqt4-core libqt4-gui&lt;br/&gt;&lt;br/&gt;#main luarocks libs:&lt;br/&gt;luarocks install image &amp;nbsp; &amp;nbsp;# an image library for Torch7&lt;br/&gt;luarocks install nnx &amp;nbsp; &amp;nbsp; &amp;nbsp;# lots of extra neural-net modules&lt;br/&gt;luarocks install unup&lt;br/&gt;&lt;br/&gt;echo "Installed Torch (demos in $HOME/torch-demos)"&lt;br/&gt;&lt;br/&gt;# Register the circus daemon with Upstart&lt;br/&gt;if [ ! -f "/etc/init/circus.conf" ]; then&lt;br/&gt; &amp;nbsp; &amp;nbsp;sudo ln -s $HOME/dl-machine/circus.conf /etc/init/circus.conf&lt;br/&gt; &amp;nbsp; &amp;nbsp;sudo initctl reload-configuration&lt;br/&gt;fi&lt;br/&gt;sudo service circus restart&lt;br/&gt;&lt;br/&gt;cd ~/&lt;br/&gt;&lt;br/&gt;## Next part ...&lt;br/&gt;####################################&lt;br/&gt;# Caffe&lt;br/&gt;####################################&lt;br/&gt;&lt;br/&gt;sudo apt-get install -y libprotobuf-dev libleveldb-dev \&lt;br/&gt; &amp;nbsp;libsnappy-dev libopencv-dev libboost-all-dev libhdf5-serial-dev \&lt;br/&gt; &amp;nbsp;libgflags-dev libgoogle-glog-dev liblmdb-dev protobuf-compiler \&lt;br/&gt; &amp;nbsp;libatlas-base-dev libyaml-dev &lt;br/&gt; &amp;nbsp;&lt;br/&gt;git clone https://github.com/BVLC/caffe.git&lt;br/&gt;cd caffe&lt;br/&gt;for req in $(cat python/requirements.txt); do pip install $req -U; done&lt;br/&gt;&lt;br/&gt;make all&lt;br/&gt;make pycaffe&lt;br/&gt;&lt;br/&gt;cd python&lt;br/&gt;pip install networkx -U&lt;br/&gt;pip install pillow -U&lt;br/&gt;pip install -r requirements.txt&lt;br/&gt;&lt;br/&gt;ln -s ~/caffe/python/caffe ~/venv/lib/python2.7/site-packages/caffe&lt;br/&gt;echo -e "\nexport CAFFE_HOME=/home/$orig_executor/caffe" &amp;gt;&amp;gt; ~/.bashrc&lt;br/&gt;&lt;br/&gt;echo "Installed Caffe"&lt;br/&gt;&lt;br/&gt;####################################&lt;br/&gt;# Digits&lt;br/&gt;####################################&lt;br/&gt;&lt;br/&gt;# Nvidia Digits needs a specific version of caffe&lt;br/&gt;# so you can install the venv version by Nvidia uif you register&lt;br/&gt;# with cudnn, cuda, and caffe already packaged&lt;br/&gt;# instead we will install from scratch&lt;br/&gt;cd ~/&lt;br/&gt;&lt;br/&gt;git clone https://github.com/NVIDIA/DIGITS.git digits&lt;br/&gt;&lt;br/&gt;cd digits&lt;br/&gt;pip install -r requirements.txt&lt;br/&gt;&lt;br/&gt;sudo apt-get install graphviz&lt;br/&gt;&lt;br/&gt;echo "digits installed, run with ./digits-devserver or &amp;nbsp; &amp;nbsp; ./digits-server"&lt;br/&gt;&lt;br/&gt;####################################&lt;br/&gt;# Lasagne&lt;br/&gt;# https://github.com/Lasagne/Lasagne&lt;br/&gt;####################################&lt;br/&gt;git clone https://github.com/Lasagne/Lasagne.git&lt;br/&gt;cd Lasagne&lt;br/&gt;python setup.py install&lt;br/&gt;&lt;br/&gt;echo "Lasagne installed"&lt;br/&gt;&lt;br/&gt;####################################&lt;br/&gt;# Nolearn&lt;br/&gt;# asbtractions, mainly around Lasagne&lt;br/&gt;# https://github.com/dnouri/nolearn&lt;br/&gt;####################################&lt;br/&gt;git clone https://github.com/dnouri/nolearn&lt;br/&gt;cd nolearn&lt;br/&gt;pip install -r requirements.txt&lt;br/&gt;python setup.py install&lt;br/&gt;&lt;br/&gt;echo "nolearn wrapper installed"&lt;br/&gt;&lt;br/&gt;####################################&lt;br/&gt;# Keras&lt;br/&gt;# https://github.com/fchollet/keras&lt;br/&gt;# http://keras.io/&lt;br/&gt;####################################&lt;br/&gt;git clone https://github.com/fchollet/keras.git&lt;br/&gt;cd keras&lt;br/&gt;python setup.py install&lt;br/&gt;&lt;br/&gt;echo "Keras installed"&lt;br/&gt;&lt;br/&gt;echo "all done, please restart your machine..."&lt;br/&gt;&lt;br/&gt;# &amp;nbsp; possible issues &amp;amp; fixes:&lt;br/&gt;# - skimage: issue with "not finding jpeg decoder?" &lt;br/&gt;# "PIL: IOError: decoder zip not available"&lt;br/&gt;# (https://github.com/python-pillow/Pillow/issues/174)&lt;br/&gt;# sudo apt-get install libtiff5-dev libjpeg8-dev zlib1g-dev \&lt;br/&gt;# &amp;nbsp; &amp;nbsp; libfreetype6-dev liblcms2-dev libwebp-dev tcl8.6-dev tk8.6-dev python-tk&lt;br/&gt;# next try:&lt;br/&gt;# pip uninstall pillow&lt;br/&gt;# git clone https://github.com/python-pillow/Pillow.git&lt;br/&gt;# cd Pillow &lt;br/&gt;# python setup.py install&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;原文链接：http://graphific.github.io/posts/building-a-deep-learning-dream-machine/&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;br/&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;br/&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 22 Sep 2016 15:54:20 +0800</pubDate>
    </item>
    <item>
      <title>业界 | Nature：对抗偏见，大数据算法需要更多责任</title>
      <link>http://www.iwgc.cn/link/2792415</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Nature&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：杜夏德&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;从搜索结果到个性化广告，算法在不知不觉中渗透进生活的方方面面。它既带来的信息和方便也造成了很多隐性的不平等，甚至是偏见。然而算法造成的偏见该如何消除，它虽不像人类偏见那样固执，但消除起来也没那么容易，涉及到公开算法使用的数据，以及算法本身的设计，然而这些又牵涉到设计算法的公司的隐私。幸运的是学界和业界已经意识到这一问题，并开始「问责算法」。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;关于科学平等的呼吁一次次出现在媒体中，不是声称要追求最完美的平等就是呼吁找出不平等的根源。无害的废话？之所以说这些是废话，依据的并不是批评家在社交媒体和博客上抱怨的那些伪科学和其中牵扯的商业利益。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一些审查应该有一个更重要的目标。在很短的时间内，大数据算法的平等已经渗透到我们生活的每一个方面。一个巨大的产业已经成长起来，它们梳理并融合多个海量的数据集——文档，例如，上网习惯——来生成个人的档案。它们常常以广告为目的，但也传递了关于信用保险等的决策，它们帮助控制我们看到的新闻或广告，而且不论我们是否启用了它们。他们能决定是否让监控和法律执法机构像社会活动家和持不同政见者鞭策我们——或潜在的安全或刑事威胁。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不仅仅是缺少受欢迎的审查。而是在很大程度上缺少能够广泛使用的算法，比如管理民主生活方方面面的规则和保障的算法：充分监督、制衡、上诉、法定诉讼程序，以及过了法定时间后，将过去的罪行从记录中删除的权利。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;算法，从最简单的到最复杂的，都是遵从几组指令或者学习完成一个目标。原则上说，它们可以通过减少人类的偏见和成见来做出公正的分析和决策。但是另一个风险是，它们也有可能增加偏见或成见，并且会复制或者加剧人类犯错。在一个强大的计算机、机器学习和大数据时代，这些平等问题自然就出现了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;产生偏见，消除偏见&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在美国的部分地区，司法部门使用的服务一般由商业公司提供，这些服务通常使用算法来预测某人再次犯罪的可能性。但事实上这些算法用来进行量刑决策，比如某人是否得到缓刑或假释。然而结果是有争议的，批评家们强调了该算法有造成对黑人偏见的风险。国家监督和执法机构正在采用类似的技术。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;算法中存在很多偏见产生的根源。一个是规则的硬编码和数据集的使用，这已经反映在共同的社会自旋中，产生偏见，去除偏见。虚假或可疑的相关性是另一个陷阱。一个广泛引用的例子是使用算法会给那些需要较长通勤时间的人打负分，因为数据显示，长距离通勤与员工流失有关。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这有歧视贫困人口的风险，这些人往往是那些倾向于住的离中央商务区更远的少数群体。这反过来又加剧了这些地区的失业，并形成一个恶性循环。很多算法在使用犯罪或者其他数据时也容易陷入自我实现预言（self-fulfilling prophecies），造成对贫困人口和少数群体地区的偏见。还一个大问题是人们通常无从知晓他们的档案是基于什么来源建立起来的——或者它们根本就不存在。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;「对算法简单过度的依赖存在严重缺陷」&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;立法者应该纠正算法的权力和责任中的不对称。最起码，应该对个人数据属于个人这个原则进行更广泛的讨论。人们有权知晓自己的数据，以及他们的数据档案是怎么建立起来的，同时也有权质疑这些数据。一些研究者强调尽管网络和社交媒体已经表现出有益于民主，但推荐算法还是会破坏社会结构——例如，给于极端观点生存空间，以及赋予那些煽情肤浅的虚假新闻或产生误导的谣言以特权。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今年 7 月，卫报总编辑 Katharine Viner 曾说，需要加入一些个性化算法以实现让算法可以按个人所想计算。但是这会可能会导致增强预先存在的观点，同时催生出一个让谎言和非理性繁荣的共鸣空间。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;幸运的是，目前学术界正在推进更好的「算法责任（algorithmic accountability）」，，值得赞扬的是，像谷歌和微软这样的技术产业公司也参与进来。不断加快的速度和机器学习以及其他人工智能（AI）技术的采纳大大刺激了「算法责任」的推进。一个明智的做法是增加透明度，让算法设计者公开他们训练和使用的数据集源头。披露算法的设计本身就会向审查开放，但几乎可以肯定的是这将会与公司的保密措施产生碰撞。研究者希望找到一种在不透露算法的情况下纠正偏见的方式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;提出的补救措施中有一些是技术性的，比如开发出新的计算技术，能更好的处理和纠正训练数据集和算法中的偏见——一种对算法持肯定态度的措施。深入研究的目标是如何监控高度自主化的人工智能系统，对于这种系统，即便连设计者也不知道这个机器是如何做决定，或者达成结论的。这种深入研究有望开发出监控算法的算法。关于这项研究还需要很多讨论和工作。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;由于在研究评估中使用了科学指标，所以过分依赖算法能存在严重缺陷。很明显，（更为复杂的）算法会导致世界上的一部分人落后于其他人。确实如此，无处不在甚至更复杂的人工智能算法已经存在。社会需要认真讨论如何摆脱会犯人类错误的软件和机器。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;em style="color: rgb(136, 136, 136); text-align: justify;"&gt;&lt;span&gt;原文链接：http://www.nature.com/news/more-accountability-for-big-data-algorithms-1.20653&lt;/span&gt;&lt;/em&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em style="color: rgb(136, 136, 136); text-align: justify;"&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 22 Sep 2016 15:54:20 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 一张图包览零售业45家人工智能创业公司</title>
      <link>http://www.iwgc.cn/link/2792416</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自 CB insights&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李亚洲、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;2016 年第二季度的人工智能投资达十亿五千万美元，创下新高，然而人工智能对生活的影响已经超出了我们的想象。甚至零售和电子商务公司都在不断将人工智能整合进自己的业务。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最近，主要的零售商巨头宣布了自己的人工智能计划和相关收购：就在本周，Etsy 收购 Blackbird，通过人工智能增强其搜索功能；之后第二天，亚马逊就收购 Angel.ai（前身是 GoButler），这是另一个人工智能支持的搜索工具。这个月初，电商独角兽 Houzz 宣布一项深度学习计划，通过点击图片帮助用户发现并购买产品。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;使用 CB Insights 的数据，我们深入大量的专注于零售与电商的人工智能创业公司，包括人工智能支撑的个性化购物 App、面向购物网站的自然语言处理和图像识别工具、预测库存分配的工具、等等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是一个新兴领域，大部分专注零售人工智能的公司都还处于非常早期的阶段。然而，我们在近几个月已经看到了几笔大型交易。ViSenze 让用户通过图像或发现看起来类似产品搜索电商网址，它在九月份完成了 1050 万美金的 B 轮融资；通过视觉追踪货架上商品的 Trax Image Recongnition 在 6 月份完成了 4000 万美元的 C 轮融资。此外还有数家创业公司得到了顶级投资者的投资，比如搜索优化工具 Zettata 得到了 Accel Partners 的投资；预测消费目标品平台 AgilOne 得到了红杉资本的投资。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然还有其他大量的人工智能创业公司宽泛的专注于个性化市场和定位，我们将此次的市场图限定在了核心关注零售与电商的创业公司。图中所有创业公司的融资总额大约为 6.5 亿美元：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOwcRZMnAZOB3Rqtj8QtNV9CJhRJSfBaCCyf3QiaZ4gfpzNTic5M2albLiaw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;零售产业人工智能创业公司市场图&lt;/span&gt;&lt;/em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该图并不代表包含了该领域的所有创业公司，只包含私人的、独立的公司。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;分类&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们将市场图景分为以下 12 类：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;实时产品定位：机器学习向在线消费者进行个性化产品推荐。这些公司实时更新电商网页，向消费者呈现最合适的产品选择。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;实时价位&amp;amp;激励机制：使用机器学习实时调整价位、销售选择、奖品和优惠券，吸收犹豫不决的消费者。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;自然语言搜索：使用自然语言处理的算法改进电商网页的搜索功能。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;可视化搜索：图像识别平台帮助电商网页让用户通过图像搜索产品，而不是文本。同时，也能对特定图像匹配相关的产品。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;店内可视化监控：人工智能支撑的软件分析货架上的图片和视觉内容，帮助品牌实时追踪产品的储备和推广情况。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;会话商务：聊天软件和聊天机器人使用自然语言处理以会话文本的形式帮助消费者购买商品。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;预测销售：大数据分析优化各店面和电商之间的销售、配置和产品种类。目标是更好的预测不同地方的产品需求，避免浪费、预防售罄。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;尺寸和造型：人工智能支撑的软件帮助零售商融合改进的产品尺寸和装备建立工具到他们的网站中。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;多渠道市场：创业公司使用人工智能在桌面、邮件和其他电子渠道创造有针对性的市场营销。也包括限定的专注于电商的创业公司。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;融合在线和店内分析：结合数字和实体店分析的创业公司，帮助零售商更好了解消费者。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;基于位置的市场&amp;amp;分析：创业公司结合数字和实体店分析，同事融合信标技术追踪消费者位置。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td colspan="3" rowspan="1" style="color: rgb(51, 51, 51); background-color: rgba(0, 153, 26, 0.0470588); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;零售人工智能私营公司列表&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(255, 255, 255); background-color: rgb(0, 102, 153); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;公司&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(255, 255, 255); background-color: rgb(0, 102, 153); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;类别&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(255, 255, 255); background-color: rgb(0, 102, 153); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;部分投资者&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(249, 249, 249); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;Plexure&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(249, 249, 249); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;整合的在线和店内分析&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(249, 249, 249); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;Vix Investments&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;Manthan Software Services&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;整合的在线和店内分析&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;Norwest Venture Partners, Eight Roads Ventures&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(249, 249, 249); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;Satisfi&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(249, 249, 249); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;对话式商务&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(249, 249, 249); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;DreamIt Ventures&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;Conversable&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;对话式商务&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;未披露&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(249, 249, 249); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;Mona&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(249, 249, 249); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;对话式商务&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(249, 249, 249); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;Techstars&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;Deepomatic&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;对话式商务&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;Alven Capital&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(249, 249, 249); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;Niki.ai&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(249, 249, 249); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;对话式商务&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(249, 249, 249); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;Unilazer Ventures&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;Kip&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;对话式商务&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;StartFast Venture Accelerator&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(249, 249, 249); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;Staqu&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(249, 249, 249); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;视觉搜索&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(249, 249, 249); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;Indian Angel Network&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;ViSenze&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;视觉搜索&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;Rakuten Ventures, Walden International, Enspire Capital, WI Harper Group&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(249, 249, 249); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;Cortexica&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(249, 249, 249); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;视觉搜索&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(249, 249, 249); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;Imperial Innovations&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;Tamecco&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;基于位置的营销和分析&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;Yume no Machi SoZo Iinkai&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(249, 249, 249); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;DataBerries&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(249, 249, 249); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;基于位置的营销和分析&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(249, 249, 249); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;ISAI, Mosaic Ventures&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;Invisible Media&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;基于位置的营销和分析&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;SMS Marketing&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(249, 249, 249); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;Grey Jean Technologies&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(249, 249, 249); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;基于位置的营销和分析&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(249, 249, 249); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;Cosmas Wong&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;iTraff Technology&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;店内视觉监控&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;Innovation Nest&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(249, 249, 249); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;Eversight&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(249, 249, 249); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;店内视觉监控&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(249, 249, 249); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;Emergence Capital Partners, Sutter Hill Ventures, Industry Ventures&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;Cosy (Cognitive Operational Systems)&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;店内视觉监控&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;500 Accelerator&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(249, 249, 249); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;Trax Image Recognition&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(249, 249, 249); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;店内视觉监控&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(249, 249, 249); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;未披露&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;Blue Yonder&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;预测推销&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;Warburg Pincus&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(249, 249, 249); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;Celect&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(249, 249, 249); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;预测推销&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(249, 249, 249); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;In-Q-Tel, August Capital&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;Unata&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;多渠道营销&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;MaRS Investment Accelerator Fund, Golden Triangle Angel Network&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(249, 249, 249); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;Thirdshelf&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(249, 249, 249); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;多渠道营销&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(249, 249, 249); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;iNovia Capital, Otimo Retail&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;Emarsys&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;多渠道营销&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;Vector Capital&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(249, 249, 249); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;Appier&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(249, 249, 249); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;多渠道营销&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(249, 249, 249); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;JAFCO Asia, Sequoia Capital India, TransLink Capital&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;Jetlore&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;多渠道营销&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;Fenox Venture Capital, Sierra Ventures, CRV, Alsop-Louie Partners&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(249, 249, 249); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;Tinyclues&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(249, 249, 249); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;多渠道营销&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(249, 249, 249); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;Elaia Partners, ISAI, Alven Capital&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;ReSci (Retention Science)&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;多渠道营销&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;Forerunner Ventures, Baroda Ventures, Mohr Davidow Ventures&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(249, 249, 249); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;SmarterHQ&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(249, 249, 249); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;多渠道营销&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(249, 249, 249); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;Battery Ventures, Simon Venture Group&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;Crobox&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;多渠道营销&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;Ventech, Keadyn&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(249, 249, 249); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;CrossCues&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(249, 249, 249); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;多渠道营销&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(249, 249, 249); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;Bank Innovation INV&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;AgilOne&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;多渠道营销&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;Sequoia Capital, Mayfield Fund, Tenaya Capital&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(249, 249, 249); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;Zettata&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(249, 249, 249); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;自然语言搜索&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(249, 249, 249); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;Accel Partners, Helion Venture Partners, Milliways Ventures&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;Twiggle&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;自然语言搜索&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;阿里巴巴, Naspers, State of Mind Ventures&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(249, 249, 249); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;AddStructure&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(249, 249, 249); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;自然语言搜索&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(249, 249, 249); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;Techstars&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;ZenClerk&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;实时定价与激励&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;Social Starts&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(249, 249, 249); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;Suzu&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(249, 249, 249); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;实时定价与激励&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(249, 249, 249); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;Entrepreneur First&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;Personali&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;实时定价与激励&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;Cedar Fund, Gemini Israel Ventures, Norwest Venture Partners&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(249, 249, 249); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;Granify&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(249, 249, 249); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;实时定价与激励&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(249, 249, 249); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;Extreme Startups, iNovia Capital, Social Starts, Valar Ventures, BDC Venture Capital&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;Hugefly&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;实时产品定位&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;Mayak Singhal&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(249, 249, 249); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;AntVoice&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(249, 249, 249); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;实时产品定位&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(249, 249, 249); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;Alven Capital, Nestadio Capital&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;Reflektion&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;实时产品定位&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;Intel Capital, Nike, Battery Ventures&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(249, 249, 249); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;Predictry&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(249, 249, 249); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;实时产品定位&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(249, 249, 249); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;Multimedia Development Corporation&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;Oorace (Search’XPR)&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;实时产品定位&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;Unicore Technology Company, Sofimac Partners&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(249, 249, 249); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;FindMine&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(249, 249, 249); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;尺寸和造型&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(249, 249, 249); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;XRC Labs&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;Fashion Metric&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;尺寸和造型&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255); text-align: justify;"&gt;&lt;p&gt;&lt;span&gt;Techstars&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;原文链接：https://www.cbinsights.com/blog/ai-retail-smart-shop-startups/&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 22 Sep 2016 15:54:20 +0800</pubDate>
    </item>
    <item>
      <title>SyncDaily | 谷歌Allo永久保存用户聊天记录惹争议、物理学家打造纳米器件，或可用于量子计算</title>
      <link>http://www.iwgc.cn/link/2792417</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p&gt;&lt;span&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;谷歌Allo永久保存用户聊天记录惹争议、物理学家打造纳米器件，或可用于量子计算......机器之心日报，精选一天前沿科技优质内容。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;h2 style="margin-top: 8px; font-weight: bold; max-width: 100%; white-space: normal; border-color: rgb(216, 40, 33); text-align: justify; color: rgb(216, 40, 33); line-height: 28px; font-family: 微软雅黑; border-bottom-width: 2px; border-bottom-style: solid; min-height: 32px; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;Deeplearning4j 0.6.0 版本发布&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Deeplearning4j 是唯一的商业级别的，使用 Java 和 Scala 编写的开源深度学习库。它融合了 Hadoop 和 Spark，经过特殊设计可在分布式 GPU 和 CPU 上的商业环境中运行。最新发布的 DL4J 0.6.0 版本包括对算法更细节的构造，在 CPU 和 CUDA 后端的改进，更支持 Spark 环境。更多详细的更新如下：&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;支持自定义层&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;支持自定义损失函数&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt; 支持压缩的 INDArrays，在大型数据上节省存储&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;对 BooleanIndexing 在合适的地方的本地支持&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;对在 CUDA 上联合运算的初始支持&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;在 CPU 和 CUDA 后端上极大的性能改进&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;更好的支持 Spark 环境，多 GPU 集群的使用 CUDA &amp;amp; cuDNN&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;新的 UI 工具：FlowIterationListener 和 ConvolutionInterationListener，更好的洞见神经网络的内部流程&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;对性能追踪部署特殊的 ItetarionListener：PerformanceListener&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;为 ParagraphVectors 增加推理实现，还有使用已有的 Word2Vec 模型的选择&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;降低 DeepLearning4j API 文档大小&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如今 cuda 8 RC 可用 nd4j-cuda-8.0 后端&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;增加多个新的内置损失函数&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;支持自定义预处理器&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Spark 训练部署的性能改进&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;使用 InputType 功能改进网络配置验证工具&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;h2 style="margin-top: 8px; font-weight: bold; white-space: normal; max-width: 100%; border-color: rgb(216, 40, 33); text-align: justify; color: rgb(216, 40, 33); line-height: 28px; font-family: 微软雅黑; border-bottom-width: 2px; border-bottom-style: solid; min-height: 32px; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;span&gt;人工智能写出披头士风格的音乐&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;索尼 CSL 研究实验室首次实现了用人工智能创作完整的歌曲《Daddy's Car》和《Mister Shadow》。这些研究者开发了一个名叫 FlowMachines 的系统——一个可以从一个大型的音乐数据库中学习音乐风格的系统。通过使用独特的风格转换、优化和交互技术，FlowMachines 谱出了很多不同风格的音乐曲。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;iframe class="video_iframe" data-vidtype="1" style="   z-index:1; " height="375" width="500" frameborder="0" data-src="https://v.qq.com/iframe/preview.html?vid=q0330at4q9f&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0" allowfullscreen=""&gt;&lt;/iframe&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;《Daddy's Car》是一首披头士风格的音乐。法国作曲家 Benoît Carré 安排将这首音乐演奏了出来，并为其编写了歌词。这两首歌将作为人工智能制作音乐的专辑的一部分于 2017 年推出。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;h2 style="margin-top: 8px; font-weight: bold; white-space: normal; max-width: 100%; border-color: rgb(216, 40, 33); text-align: justify; color: rgb(216, 40, 33); line-height: 28px; font-family: 微软雅黑; border-bottom-width: 2px; border-bottom-style: solid; min-height: 32px; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;物理学家打造纳米器件，或可用于量子计算&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOwIQXzJmFx98uVeS2xycZ30BYNicceLI5icUaTtr3qRlVC5w2uEtToxzZg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;加拿大卡尔加里大学量子科学与技术研究所和国家纳米技术研究所的 Barclay 及其团队已经利用金刚石单晶打造出了世界上第一款纳米尺度的光学谐振器（或称光学腔（optical cavity）），其也是一款机械谐振器（mechanical resonator）。&lt;/span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该团队测定了——在该装置的光与机械运动的耦合中——由受限于金刚石微盘光学腔中的光能的震荡所引起的高频率的、长持续时间的机械振动。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「金刚石光机械装置为我们提供了研究微观尺度的量子行为的平台，」物理学和天文学副教授 Barclay 说，「这种装置也有很多潜在的应用场景，包括最先进的传感技术、移动光的颜色的技术和量子信息与量子计算技术。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;h2 style="margin-top: 8px; font-weight: bold; white-space: normal; max-width: 100%; border-color: rgb(216, 40, 33); text-align: justify; color: rgb(216, 40, 33); line-height: 28px; font-family: 微软雅黑; border-bottom-width: 2px; border-bottom-style: solid; min-height: 32px; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;谷歌Allo永久保存用户聊天记录惹争议&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOwydYf2BMlibVhgZT4fysWriahLZdGF1pJj4ibqaEoO3uT5hRfeMj7AdmbQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;据外媒报道，昨天，谷歌最新的信息应用 Allo 正式上线，这款应用内置谷歌助手，可以借助 AI 进行自动回复，成为你日常生活的好帮手。不过，为了深度挖掘 Allo 的能力，谷歌选择忽略用户隐私。本周三，该公司确认，用户的聊天信息会一直存在服务器上，除非你选择手动删除。这一消息可谓是重磅炸弹，毕竟在今年 5 月的 Google I/O 上，谷歌可不是这样承诺的。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;原本，谷歌是想将用户的聊天信息「短暂」存在服务器上，但经过测试它们发现，服务器上的信息越多，智能回复功能的可用性就越好。这一改变让 Allo 马上成了众矢之的，其隐私政策已经与其他信息应用背道而驰。同时这也引起了用户的担心，因为谷歌的行为正在给爱监控的美国政府提供好机会。不过，在声明中谷歌对隐私问题闭口不提，反而称此举将提升用户的使用体验。而且它们认为自己已经给了用户充分的选择权，他们可以调节内置选项来选择所谓的「加密」和「不加密」模式。不过，分析师认为谷歌的解释不成立，因为普通用户很容易弄混这些模式，或者说有些人从一开始就不知道 Allo 还有这样的「玩法」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;h2 style="margin-top: 8px; font-weight: bold; white-space: normal; max-width: 100%; border-color: rgb(216, 40, 33); text-align: justify; color: rgb(216, 40, 33); line-height: 28px; font-family: 微软雅黑; border-bottom-width: 2px; border-bottom-style: solid; min-height: 32px; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;马斯克火星殖民计划前瞻：疯狂背后挑战相当巨大&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;据凤凰网报道，下周二，SpaceX CEO 马斯克就要向我们阐述他宏伟的火星殖民计划了。这一目标他已固执坚持多年，但却始终没有透露许多细节性的东西。对于火星殖民，马斯克一直非常看重，因为他认为这是保证人类永存的重要方式。不过，现在发表火星殖民计划确实有些尴尬，毕竟 SpaceX 的火箭刚刚在发射台上化为了灰烬。眼下，这家公司正在苦苦寻找事故发生的原因，一系列发射计划也不得不被束之高阁。&lt;/span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;马斯克的火星计划有两大枢纽：一是大推力运载火箭，二是运载能力超强的宇宙飞船。前者将从地球升空，将宇宙飞船送入太空，随后后者将「孤独」的飞向火星。此前，这套系统只为火星服务，但上周马斯克称他的目标是「星辰大海」，于是他给新系统取名为星际运输系统。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;至于马斯克到底会在演讲中放个什么样的「卫星」？我们下周二正式揭晓。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;h2 style="margin-top: 8px; font-weight: bold; white-space: normal; max-width: 100%; border-color: rgb(216, 40, 33); text-align: justify; color: rgb(216, 40, 33); line-height: 28px; font-family: 微软雅黑; border-bottom-width: 2px; border-bottom-style: solid; min-height: 32px; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;沃尔沃为巴士研发自动行人检测系统&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;据外媒报道，沃尔沃近日宣布，他们为旗下巴士车队开发了一种称为「行人及自行车手检测系统」的检测技术，可探测到前方的行人或自行车骑行者，并向未受保护的道路使用者发出警告声。这项技术依托于沃尔沃巴士上安装的一种摄像头，能够扫描巴士周围的环境，随后利用图像处理系统和算法来检测出行人或自行车骑行者。&lt;/span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果危险不大，巴士将发出低频率声音以免造成干扰。而当情况危急时，巴士喇叭将自动被激活，同时使用声光信号来提醒前方的行人。沃尔沃表示，这项技术与在其他车辆中采用的行人探测技术具有相似之处，不过这套系统并不具有自动刹车的能力。该系统旨在减少繁忙城市环境中行人面临的潜在危险。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;h2 style="margin-top: 8px; font-weight: bold; white-space: normal; max-width: 100%; border-color: rgb(216, 40, 33); text-align: justify; color: rgb(216, 40, 33); line-height: 28px; font-family: 微软雅黑; border-bottom-width: 2px; border-bottom-style: solid; min-height: 32px; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;美国政府出台首份自动驾驶汽车政策&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;据雷锋网报道，美国当地时间 20 日，交通运输部（US Department of Transportation）在华盛顿正式颁布了首份专门针对自动驾驶车辆的联邦政策《联邦自动驾驶汽车政策》，规定新的自动驾驶汽车/技术都必须满足 15 个要点的安全评估，为自动驾驶技术提供了制度保障。&lt;/span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;《联邦自动驾驶汽车政策》主要包括：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;15 项安全评估：该规范的 15 个要点包括数据记录和共享、隐私、车辆网络安全、耐撞性能、消费者教育和培训、车辆在撞击中的存活能力、车辆在撞击之后的反应表现、操作设计、对道路上物体和事件的探测等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;针对州政府政策：条例明确了联邦政府和州政府在自动驾驶车辆监管中承担的不同责任，并且列出了一些列供州政府在制定相关政策时可参考的条例和范围。这部分的目标在于统一联邦政府和州政府的监管，共通开发出针对自动驾驶车辆的监管体系。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;美国国家公路运输安全管理局（NHTSA）的监管方式：该部分讨论了 NHTSA 目前的一些监管方式，并且列出了其中能持续被用在自动驾驶车辆监管的方式。此外，该部分还对现有的规定进行了完善，使自动驾驶车辆的设计拥有更高的灵活性和空间。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;新的监管方式：该部分明确了新的监管方式和相关法定机构，这些是政策制定者们讨论决定的未来能在自动驾驶车辆领域起到监管作用的因素。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h2 style="margin-top: 8px; font-weight: bold; white-space: normal; max-width: 100%; border-color: rgb(216, 40, 33); text-align: justify; color: rgb(216, 40, 33); line-height: 28px; font-family: 微软雅黑; border-bottom-width: 2px; border-bottom-style: solid; min-height: 32px; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;扎克伯格夫妇宣布投入30亿美元研究疾病治疗&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;据新浪科技消息，Facebook CEO 马克-扎克伯格（Mark Zuckerberg）及其妻子普里西拉-陈（Priscilla Chan）承诺，将在未来 10 年中投入超过 30 亿美元，用于研究疾病的治疗。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;普里西拉-陈周三在旧金山的一次活动上表示：「我们能否合作，在我们孩子的一生时间里实现所有疾病的治疗、预防和管理？马克和我认为，这完全有可能。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;扎克伯格表示：「这是个远大的目标。在刚开始起步时，我们认为这过于激进。然而当你深入之后，令你吃惊的在于，药品成为现代科学才只有约一个世纪的时间。」在与专家交流之后，扎克伯格夫妇认为，治疗及预防所有疾病的目标是可以实现的。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他们的第一笔投资将是在未来 10 年里拿出 6 亿美元，资助一家名为 Biohub 的研究中心。在这里，不同领域的专家可以就科学问题展开合作。这一中心将与斯坦福大学、加州大学旧金山分校，以及加州大学伯克利分校合作建立。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在去年 12 月宣布这一计划时，他们持有的 Facebook 股份价值约为 450 亿美元。自那时以来，Facebook 股价已上涨超过 20%。今年早些时候，扎克伯格曾呼吁股东批准新的投票权架构，使他可以出售 Facebook 股份，同时不会失去对 Facebook 的控制权。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;扎克伯格夫妇已启动了教育方面的项目，并邀请了前美国教育部副部长吉姆-谢尔顿（Jim Shelton）来负责。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;微软联合创始人比尔-盖茨（Bill Gates）也出席了此次活动，他对扎克伯格夫妇的项目表示支持。盖茨已向比尔和梅琳达盖茨基金会捐出了超过 300 亿美元。该基金会的目标是解决饥饿、疾病和贫穷问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编辑整理，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 22 Sep 2016 15:54:20 +0800</pubDate>
    </item>
    <item>
      <title>重磅 | 量子计算大跃进？D-Wave将于明年推出2000量子比特芯片</title>
      <link>http://www.iwgc.cn/link/2777236</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自 Tech Republic&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Nick Health&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀、李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;要发掘出量子计算的真正潜力，我们可能还需要再等几十年，而 D-Wave 正在向着这个目标大步迈进，这家公司承诺将在明年推出其已经得到了大幅改进的量子处理器。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这家加拿大的公司表示将在明年初推出一款能够处理大约 2000 个量子比特（qubit）的新型量子芯片，这一数量差不多是现有的 D-Wave 2X 系统的处理器中量子比特数量的两倍，而且其将实现的计算速度也将达到前一代的 1000 倍以上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;D-Wava 的计算机造价数百万美元，其使用一种所谓的「量子晶体管（quantum transistor）」来进行计算——这种晶体管是一种利用液氦冷却至近乎绝对零度的微型铌线路。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前还仅有几家企业或组织在使用 D-Wave 的量子计算机，其中包括谷歌和大学空间研究协会（Universities Space Research Association）、洛克希德·马丁公司和洛斯阿拉莫斯国家实验室。不过，D-Wave 也在通过云服务来提供其量子计算机的使用权限。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;量子计算仍然很大程度上是一个理论研究的领域，这个领域研究的是如何利用物质在原子尺度上的怪诞和反直觉的行为来开发强大的机器。对于某些特定任务，量子计算机的速度有望指数级地超越现有的计算系统，而且同时其能效也将远远更高。目前还不存在通用型的量子计算机，而 D-Wave 的量子计算机是通过利用原子的多种行为（如纠缠和态叠加）来帮助解决一系列困难的计算问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我们已经进入了一个发展轨道，差不多每隔一年就能实现量子比特的数量的倍增。」D-Wave 业务发展和战略合作伙伴关系负责人 Colin Williams 说。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;D-Wave 处理器中量子比特数量的迅速增长让该系统可以进一步挑战传统计算机，而他们新的处理器还将支持一些能带来更高效计算的额外特性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「在内部测试中，这么做的效果看起来真的非常不错。通过利用这些能力所带来的 1000 倍提升，我们已经加快了解决某些问题的速度。」Williams 在剑桥的 CW TEC 会议上如是说道。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;D-Wave 系统并非如同今日的 PC 一样的通用型计算机。D-Wave 机器没有能力执行所有类型的计算任务，其只能解决一种被称为无约束二元优化（unconstrained binary optimization）的特定类型的任务及其相关的采样问题。这种类型的优化问题的一个非常简单的案例是：在你的预算范围内，拟定尽可能接近你的梦想规格的房屋规划。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;据 D-Wave 称，D-Wave 处理器处理的这些特定的任务可以在一些特定领域发挥巨大的作用，尤其是在训练机器学习模型上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是，要实现通用量子计算机还存在更大的难题，另外还有一些尚未解决的工程难题。伦敦大学学院纳米电子学和光子学教授 John Morton 根据过去的芯片发展趋势预测说第一个通用型量子处理器会在 2030 年代问世。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Morton 说就好像计算器不是计算机一样，D-Wave 系统也不是通用量子计算机。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「计算器可以解决一些非常具体的问题。很多人使用它，而且你可以跨许多行业使用计算器。」他说，「所以当 D-Wave 向你表示有许多行业都可以使用 D-Wave 机器时，也许确实有很多可以应用它的领域，但它仍然是一种专用设备。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尽管谷歌目前尚未使用 D-Wave 机器来增强其在机器学习方面的工作，但这家科技巨头在去年年底通过一次测试运行证实了 D-Wave 的处理器的可行性（其不断受到一些学者的质疑）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该实验发现在执行一个类似的运算时，D-Wave 2X 处理器的速度可以比传统处理器快 1 亿多倍，但 Williams 说，更重要的是这项实验展现了 D-Wave 的芯片的未来潜力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「其所带来的主要收获并不是在加速上的效果，因为还有一些其它算法可以做到更好。」他说，「这个实验表明 D-Wave 芯片中确实发生着量子隧穿（quantum tunnelling）。它表明即使隧穿的范围是有限的，它也仍是一种有用的计算工具。谷歌和我们一样理解这一点，随着我们对我们的芯片设计的改进，并实现更密集的连接，那么在这个问题上目前效果良好的传统算法就将完全落后。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;D-Wave 已经从多个投资者那里拿到了数百万美元的融资，其中包括投资银行高盛、In-Q-Tel（美国中央情报局的投资机构）、Bezos Expeditions（亚马逊创始人 Jeff Bezos 的投资机构）、BDC Capital、Harris &amp;amp; Harris Group、和 DFJ。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;像人类一样说话的机器&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对 D-Wave 芯片的另一个批评是其专用性限制其用途，Williams 反对这种说法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他说：「人们认为 D-Wave 芯片只能做一件事，我想说这是不对的，事实已经证明它所能做的一件事可以被用在许多不同的领域中。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尽管他并没有指明这样使用过 D-Wave 芯片的组织，但他说这种处理器已经在金融领域被用来进行交易轨迹优化、在生物科学领域被用来研究蛋白质折叠、被用来创造永远不会错过潜在匹配的列表过滤器——这可以用于检查恐怖分子监控列表的安全服务、人工智能二元分类器的开发和计算机视觉。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但这是无监督机器学习——训练数据被送入一个神经网络，机器通过识别模式进行学习；Williams 相信 D-Wave 处理器将在这一领域带来最大的影响，这也许还能够解释谷歌对这一技术的兴趣。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我们认为机器学习和人工智能从根本上来说是这种机器的最好的应用案例，尤其是它有望彻底变革无监督生成学习。」他说，「使用量子芯片，我们有望回到并解决机器学习的最初的也是最大的挑战——『我们怎么实现效果和人类一样好的无监督的生成式的机器学习？』如果你能做到这一点，你就可以使用机器学习做到很多惊人的事情。你可以让受过训练的机器生成新的、且与训练数据无法进行统计区分的新数据。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Williams 预测未来几代的 D-Wave 芯片可以训练机器生成类似于其接受训练的大师画作那样的新的让人信服的艺术作品，或有能力进行和人类一样的语音对话。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;D-Wave 已经开始在这种芯片上实验机器学习了，他们制作了一种随机循环神经网络——玻尔兹曼机，即「量子玻尔兹曼机（Quantum Boltzmann machine）」——Williams 称其「与之前的机器学习模型存在根本上的不同」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Williams 认为 D-Wave 芯片或其它量子处理器并不会取代传统计算机芯片，而是会一起协作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我们认识到量子计算并不会取代传统机器。量子计算改变世界的方式是增强传统系统。」他说，「比如说哦，你可以将量子计算的输出作为启发式搜索算法的输入。其中的思想是：量子算法可以让你接近很好的解决方案，而传统算法可以帮助你完成它。我们也可以看看预处理技术，对于一个非常大的问题，我们可以将其放进量子芯片中，然后将其分解成一个问题序列。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除了 2000 量子比特处理器之外，Williams 说 D-Wave 还有一种「下一代芯片」的新设计，其「基于我们所学到的经验教训，具有完全新式的拓扑结构」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;关于 D-Wave 新型芯片的更多细节&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对细节感兴趣的人来说，Williams 对 2000 量子比特芯片的能力也做了更深入的介绍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;每个 D-Wave 处理器被设计进行量子退火，使用量子物理发现最小的能态，这对解决优化和相关采样问题而言很有用。Williams 解释了新的芯片将如何提供对退火过程的更强大的控制。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他说，「不只是有了更多的量子比特，我们也改变了其他许多特征。在先前的 D-Wave 芯片上，我们只有观察一条退火路径的能力。我们也有一种单行道依次关闭初始哈密顿量以及打开最终哈密顿量。」他解释说，哈密顿量能够在给定系统状态的情况下输出系统内的能量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「这不久之后将会改变，有了 2000 量子比特芯片，我们将对参数有更强的控制，我们也打算对退火路径添加更多的控制。从内部的测试来看，做这些改变真的很好。通过利用这些能力，我们在一些问题上已经加速了 1000 倍。我们也有了终止退火的特征，然后加速将退火过程推向终点，你不需要再等速退火了。这很有趣，因为这使得你能在退火中探测量子态，从量子玻尔兹曼机的角度来说这是很重要的特征。我们也有一个更快速的退火过程，前一代系统的退火速度只能降低到 20 微秒，而新系统的速度可降到 5 微秒。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;来源：http://www.techrepublic.com/article/quantum-leap-d-waves-next-quantum-computing-chip-offers-a-1000x-speed-up/&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心经授权编译，机器之心系今日头条签约作者，本文首发于头条号，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 21 Sep 2016 15:09:24 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 机器学习的基本局限性：从一个数学脑筋急转弯说起</title>
      <link>http://www.iwgc.cn/link/2777237</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Nautilus&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;作者：JESSE DUNIETZ&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;参与：李亚洲、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数月之前，我阿姨给其同事发送了一封主题为「数学难题！答案是什么？」的邮件，邮件包含了一个谜题：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9cAyuhicHZ8WGB9WjkUv6RAo7W87tLwVfWRkiaX8jJvX450HVdsMZuY3vDUIic9S09sl5acFNhWapzQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;她认为自己的答案明显是正确的，她的同事们却认为他们自己的答案才是对的——但这两个答案却不一样。那是他们的答案有一个是错的呢？还是谜题本身有问题？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我阿姨和她的同事偶然间发现了机器学习中的一个基本问题。我们期望计算机做的所有学习以及我们人类自身的学习都是将信息归纳成基本的模式，然后再用其来推断未知。她的谜题也毫不例外。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;作为人类，我们面临的挑战是发现所有模式。当然，我们有直觉来限制自己的猜测。但计算机没有这样的直觉。从计算机的角度来看，模式识别中的难题是只采用一个模式：在多种模式实际上都可行的情况下，什么决定了哪个模式是「正确」的？其它模式都是「错误」的？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个问题在近期才成为人们实际考虑的问题。20 世纪 90 年代之前，人工智能系统几乎不做太多学习。例如，Deep Blue 的前身国际象棋系统 Deep Thought，通过从成功与失败对赛中学习却并没能很好掌握国际象棋。相反，国际象棋大师和编程人员谨慎的书写规则，教计算机哪个落子位置是好还是坏。这样庞大的人工工作是「专家系统」时代的典型方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了解决该谜题，专家系统的方法是需要一个人类来发现前三排问题的模式：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1 * (4 + 1) = 5&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2 * (5 + 1) = 12&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3 * (6 + 1) = 21&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然后，人们就可以命令计算机遵循 x * (y + 1) = z 模式。将该规则应用到最后一题，答案就是 96。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尽管早期专家系统很成功，但需要人工设计、调整、更新系统，这会使得它们变得很笨重。相反，研究人员将注意力转移到了设计能自己推断模式的机器上。也就是一个程序能够检查数千张图片或市场交易数据，并提取出表明一张脸或一个紧急价格峰值的统计信号。这种方法很快成为了主流，也从此增强了从自动邮件分拣到垃圾邮件过滤和信用卡诈骗检测等各种任务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如今，虽有有着如此多的成功，但这些机器学习系统仍需要工程师。再次回到上面的谜题，我们假设每个等式有 3 个相关组件（等式中的 3 个数值）。但也存在潜在的第四个元素：前面一个等式的结果。一个等式的属性，用机器学习的说法也就是特征，也考虑在内，那就生成了一个另外一种合理的模式：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;0 + 1 + 4 = 5&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;5 + 2 + 5 = 12&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;12 + 3 + 6 = 21&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;按此逻辑，最后的答案应该是 40。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以，哪种模式是正确的？两个都正确，当然或者两个都不正确。这完全由允许使用哪种模式所决定。你甚至还可以这么做：第一个数乘以第二个数，然后加上上一行答案加上 3 后的五分之一，然后取离结果最近的整数。（这很诡异，但却有效）而且，如果我们允许包含数值视觉形式的特征，我们可能还能得到一些关于字形和字体的模式。该模式匹配取决于观察者的假设。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在机器学习中这也是正确的。即使机器能自我学习，首要模式也由人来选择：面部识别软件应该推断明确的 if/then 规则吗？它应该将每个特征作为每个可能的人的附加证据吗？系统应该注意哪些特征？它是否应该关注每个像素？还是明亮区与暗区之间的锐利边缘？这些选择限制了系统认为像是甚至可能的模式。发现完美的结合成为了机器学习工程师的新工作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9cAyuhicHZ8WGB9WjkUv6RA1kOA9Zzt45FJP8MUia23bYiaQ0uylHIaXHfiahGDuhhTcHuT53CvicErlA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;叠层的蛋糕：在神经网络中，数据从一个「神经元」层传递到另一个「神经元」层，在每一步都经过一些简单的转换。中间层能学习更高层次的特征，这对最终输出很重要。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然而，自动化的过程在此并未结束。如同他们曾经厌倦了写规则一样，工程师开始更少设计这些特征。「如果计算机能够自己搞清楚内部特征不是更好吗？」所以，他们设计了深度神经网络，这是一种很显著的机器学习技术，能从更基础的信息中推断更高层次的特征。向神经网络输入一堆像素，它将学习边缘、曲线、甚至纹理这样的特征，都不需要明确的指令。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不，还不完美。神经网络仍不能完美适配所有问题。即使在最好的案例中，它们也需要少量的调整。神经网络包含带有「神经元」的层，每个层进行输入上的计算并将结果传向下一层。但应该有多少神经元？多少层呢？每个神经元应该从前一层的每个神经元中获取输入吗？还是选择一些神经元？每个神经元应该对输入采用什么转换，从而得到输出呢？等等一系列问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些问题限制了将神经网络应用到新问题；擅长面部识别的网络在自动翻译上却不合适。再一次的，人类选择的设计元素暗中影响了网络选择哪些模式、抛弃哪些模式。对博识的人类来说，不是所有的模式都是平等创造的。工程师还未失业。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当然，理论上发展的下一步是能自动搞清需要包含多少神经元、使用什么类型的连接等等这样的神经网络。探索这些主题的研究已经进行了数年了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;能发展到什么程度？机器能否依靠自己很好地学习，外部指导成为历史？理论上，你可以想下理想的通用学习器（Universal Learner），它能自我决定所有事情，而且总是选择针对手头任务的最佳模式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但在 1996 年，计算机科学家 David Wolpert 证明没有这样的学习器的存在。在其著名的「No Free Lunch」定理（参看：http://no-free-lunch.org/）中，他表示一个学习器善于学习某种模式，那就有其他该学习器不擅于学习的模式。这把我们带回了我阿姨的谜题——有无限的模式匹配无限量的数据。选择一个学习算法就意味着在选择了机器不擅长的模式。也就是说，可能所有的视觉模式识别任务将最终开始于一个包罗万象的算法。但没有学习算法能擅长所有学习。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这使得机器学习惊人地类似于人类大脑。像我们的思维那样智能，我们的大脑也不能完美地学习。大脑的每一部分通过进化而被精调，无论我们看到了、听到了什么，实体目标表现了什么行为，大脑各部分都能定位特定类型的模式。但当涉及到发现股票市场中的模式时，大脑不擅长；机器在这上面比我们强得多。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器学习的历史表明会有许多的模式。但最有可能的一种是：在接下来数年，我们将教授机器如何自我学习。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;来源：http://nautil.us/blog/the-fundamental-limits-of-machine-learning&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 21 Sep 2016 15:09:24 +0800</pubDate>
    </item>
  </channel>
</rss>
