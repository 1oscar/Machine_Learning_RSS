<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>机器之心</title>
    <link>http://www.iwgc.cn/list/670</link>
    <description>人与科技的美好关系</description>
    <item>
      <title>深度 | 谷歌新人李飞飞：击碎玻璃天花板的华裔女科学家</title>
      <link>http://www.iwgc.cn/link/3537501</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心原创&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：机器之心编辑部&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;本周二，谷歌宣布斯坦福大学教授&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720536&amp;amp;idx=4&amp;amp;sn=19fdaccf63daae29e72d2a738fd65e45&amp;amp;chksm=871b0d66b06c84708e3f803b2cec907365d5fd8a3d15401721a48bfaa4a49b5d37bded8e10a9&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720536&amp;amp;idx=4&amp;amp;sn=19fdaccf63daae29e72d2a738fd65e45&amp;amp;chksm=871b0d66b06c84708e3f803b2cec907365d5fd8a3d15401721a48bfaa4a49b5d37bded8e10a9&amp;amp;scene=21#wechat_redirect"&gt;李飞飞加入其云团队&lt;/a&gt;。作为第一代中国移民，这位图像识别领域的杰出学者是如何从普林斯顿进入斯坦福，最后成为谷歌人工智能团队新任领导者的？让我们来了解一下这名华裔学者的传奇经历吧。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;实现美国梦&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9xhznsLIp5sSbIiayEITWLFHvtX1ibmMyw0k4tVhyVwAnjbnr2Peh5hDfNWs6QguvNooRDlmG697HA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;1976 年，李飞飞出生于北京，后来在四川长大&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你真想做一件事，全世界都会来帮你。16 岁刚来美国的那两年，李飞飞却只能从依靠自己开始。在帕西悉尼的白人圈子中，这位亚裔姑娘显得有点孤独，她像所有极客一样过着简单的生活。那个时候打工与学习几乎占据了她所有的时间。李飞飞明白，这就是普通新移民的生活，需要点牺牲和决心。幸运的是她的同学和高中数学老师在这时给了她莫大鼓励和帮助。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1995 年，李飞飞进入普林斯顿大学攻读物理学，生活的大门终于渐渐为她打开。在周一到周五，她是普林斯顿物理系拿着高额奖学金的高材生，周末则必须回到 Parsippany 的洗衣房，置身于成堆的衣服中。她说「我爱普林斯顿。」因为这里有全世界最优秀的年轻天才。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然而生活的艰辛也在随着年龄增长，她见过斯坦福的优秀博士毕业生为一张绿卡四处奔波，那时的她不明白也无法想象一张绿卡，一个留在美国的机会能难倒全世界那么多优秀的人才。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有过移民经历的人对平等有着更加深刻的体会，李飞飞也如此，她坚持主张高科技产业性别平等，支持种族多样化，还有反对特朗普。她曾在 Twitter 上调侃特朗普是个不懂科学没有眼界的人。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;李飞飞说：「多样化的危机，也正是我们的社会正在应对的危机。『科技是没有灵魂的吗？』」她坦承自己对 AI 研究界的失望，因为这一领域不太欢迎不具代表性的少数群体。在她工作的部门里一共有 15 名全职人员，她是唯一的女性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;梦想与责任&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;并不是每个美国移民都能实现自己的梦想，但李飞飞做到了。当初她随父母举家搬到大洋彼岸。「他们来到这个国家是为了追求梦想。」李飞飞认为她也「应该能够追求自己的梦想。」这个「应该与能够」的选择做起来并不轻松。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1999 年，李飞飞从普林斯顿大学毕业，那时的华尔街一片辉煌，互联网泡沫的热潮接近顶峰，李飞飞接到了多家金融公司的工作邀请。然而她却没有从中选择任何一份工作来减轻家庭经济负担。她的父母支持她做出了最后选择，去西藏研究藏医。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然李飞飞知道自己终将回到学校，回到科研工作中来，读博士也是她的梦想，但西藏之行并非人生插曲。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在科学界藏医与中医一样存在很多争议，但这并不妨碍李飞飞对它的兴趣。她在媒体采访中提到，作为一个科学家，藏医可以在哲学和方法论层面上给她给多的理解。她非常看重具体科研项目在更大领域范围内的意义，每一项研究开始之前都要经过深思熟虑。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9xhznsLIp5sSbIiayEITWLFB67EIOFaYGTlRy1wfHpjtX2ktnf4FpicgwlxBGGyzgF5qRYVUpQH7icg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;她曾经放弃高盛的 offer，追随梦想来到西藏&amp;nbsp;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在李飞飞后来写给博士生们的信中可以看到她对科学探索的态度：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;每个领域的每一篇论文都应该以独特的新视角进行研究。所以当你在机械地开展你们的工作前，请扪心自问——『我的研究会重新定义这一领域的未来吗？』这意味着发表论文的意义不是『这个方向没有人写过』，或者『让我来解决这个小问题，它的成果会很容易展示』；研究意味着『如果我做了，这一重大问题就有了更好的解决方案』，『如果我做了，我就真正开拓了这一领域』。你的研究成果应该能被很多人和行业直接使用，换句话说，你的选题应该有很多『客户』，你的解决方案应该是他们想要的。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;西藏归来之后，李飞飞开始了加州理工的博士学业。博士期间母亲接连患上了癌症与中风，那是一段艰苦的日子，李飞飞说，「我们经历了很多困难，然后一起挺过来了。既要担起生活的责任，又要对得起自己的梦想」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;改变图像识别方向的人&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;是什么吸引谷歌一次性将李飞飞和她的门生李佳一齐请进公司，并委以重任的？显然是她的学术成就和影响力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;自 2009 年以来，李飞飞一直担任斯坦福人工智能实验室和斯坦福视觉实验室的负责人，并成为了终身副教授。在她 2014 年的简历上，有 95 篇在 Nature、PNAS、Journal of Neuroscience、CVPR、ICCV、NIPS 等顶级期刊与会议上发表的文章；联合发表的文章有 32 篇。从 2015 年到 2016 年，李飞飞署名发表的论文有 33 篇（斯坦福视觉实验室），还有一篇将在 2017 年发表在 CSCW 会议上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在不就之前，艾伦人工智能研究所推出了以人工智能为基础的免费学术搜索引擎&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720432&amp;amp;idx=1&amp;amp;sn=25c1224631a11ab1077fda9f2433e78e&amp;amp;chksm=871b0cceb06c85d840d98037614077761a0db0df6c75798d4fa2bc069c7380a02de81e0afed4&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720432&amp;amp;idx=1&amp;amp;sn=25c1224631a11ab1077fda9f2433e78e&amp;amp;chksm=871b0cceb06c85d840d98037614077761a0db0df6c75798d4fa2bc069c7380a02de81e0afed4&amp;amp;scene=21#wechat_redirect"&gt; Semantic Scholar&lt;/a&gt;。我们使用该引擎生成了李飞飞的论文引用量图解（注：搜索时请注意名字输入格式，Feifei Li 为另一位作者。），如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9xhznsLIp5sSbIiayEITWLFibLnDY6icE6E9f8ibWiaW4vn07NEGAibxoAE89BrePloAQWk9aRb4obxoSA/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9xhznsLIp5sSbIiayEITWLFophp9aM2mKJVXnxic179wsJHo0WydODiaibXsdbOL15hhSYhfbnibmYPNw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;过去 3 年，李飞飞论文的平均引用量为 6738。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9xhznsLIp5sSbIiayEITWLFDSftxppLcjibRovrPKLJFdIE9yMWLpnjjJ1iaHjSagIPPK2H7ibSzZ5LA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;基于可用数据，Semantic Scholar 估计李飞飞的引用量在 33215 到 44773 之间。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;回溯过去，李飞飞在计算机视觉上的研究已经花费了 15 年。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 2007 年，李飞飞和一位同事着手开始一项庞大的任务，为来自互联网的十亿张图片进行分类、打标签，从而为计算机提供样本。其中理论基础是如果机器观察到足够的事物，它们就能够在现实世界进行识别。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他们使用亚马逊 Mechanical Turk 这样的众包平台，邀请了来自 167 个国家的 5 万人帮助为其中的数百万张图像打标签。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最终，他们建立了 ImageNet 数据集。今天，这个数据集包含了使用日常英语标记的超过 1400 万张图像，跨越 21,800 个类别。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在我们用 Semantic Scholar 生成的图解中发现，李飞飞被引用最多的论文就是她于 2009 年在 CVPR 上发表的《ImageNet: A large-scale hierarchical image database》。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9xhznsLIp5sSbIiayEITWLFu7SJtX2Z8kgbviaSEKhle3O4cMuGO8NqwOeN4RtZHS8OYicic4JgUibCiaQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;iframe class="video_iframe" data-vidtype="1" style="   z-index:1; " height="375" width="500" frameborder="0" data-src="https://v.qq.com/iframe/preview.html?width=500&amp;amp;height=375&amp;amp;auto=0&amp;amp;vid=v0333il31b6" allowfullscreen=""&gt;&lt;/iframe&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;李飞飞Ted演讲&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;瓜分学界人才的科技巨头们&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谷歌的云业务负责人 Diane Greene 在新闻发布会上说，李飞飞和李佳的加入是谷歌正式将人工智能集团业务正式化的一部分。此后，该团队不会只专注于人工智能研究，而是致力于将尖端技术融入各种 Google Cloud 产品，例如让公司预测销售情况的软件。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而在宣布成立人工智能集团之前，谷歌还围绕着云服务部门产品路线图发布了一系列产品，介绍了他们如何扩大机器学习的使用。对于云计算来说，机器学习是一项关键的技术，它能训练大规模的 AI 网络，不断自我学习和提升。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Google Cloud 及其机器学习团队的产品经理 Rob Craft 也表示，这两名研究者将帮助谷歌「将机器学习的力量带入其他行业」，他们也将成为谷歌整合其研究单位及核心业务努力的一部分。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是，雇用具有机器学习和相关任务专业知识的人才并不便宜。这一行业内的激烈竞争导致谷歌这样的大公司经常会支付「NFL 球员签字费」级别的巨额资金，而越来越多的顶级学界研究人员也陆续加入了大公司的怀抱。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;近年来，学界内重所周知的大牛们基本被科技巨头筛了个遍，方式也是各种各样。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最初，谷歌先是收购了多伦多大学的一家初创公司 DNNResearch。但实际上，这家公司只有三个成员，Geoffrey Hinton 和他的两个刚毕业的、曾经赢得 2012 年的 ImageNet 大赛的学生——Alex Krizhevsky 和 Ilya Sutskever（现在加入了 OpenAI）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如今被称为谷歌最成功一笔收购的 DeepMind 也是竭尽全力的在挖空英国的人工智能人才。前几日 Business Insider 的一篇文章指出，牛津大学与剑桥大学最优秀的人工智能人才一直在被科技巨头收拢。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而且在文章中重点提到，虽然微软和 Facebook 这样的美国科技巨头也正在招募牛津大学的研究生和教授，但是 DeepMind 似乎比其他的公司挖到的人才更多。DeepMind 从被谷歌收购了之后就已经把它的团队规模从在国王十字路时的 100 人扩大到了大约 250 人。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不只是谷歌，以美国、中国为主力的科技巨头们正如同「风暴之眼」一般吸纳着一切尽可能的能量推动着公司在人工智能道路上的快速发展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;微软在人工智能研究中一直处于第一梯队，在 9 月底宣布组建 5000 人规模的专注人工智能的工程和研发团队 Microsoft AI and Research Group。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;之前我们觉得已然落后了的苹果，在 &lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719828&amp;amp;idx=3&amp;amp;sn=5f72f8b9bbd0078d483ad233e578081a&amp;amp;chksm=871b022ab06c8b3ce2ef881c941e1ea532e3f465bbc1109c74e0aa0a72b283a8408dca7b353f&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719828&amp;amp;idx=3&amp;amp;sn=5f72f8b9bbd0078d483ad233e578081a&amp;amp;chksm=871b022ab06c8b3ce2ef881c941e1ea532e3f465bbc1109c74e0aa0a72b283a8408dca7b353f&amp;amp;scene=21#wechat_redirect"&gt;10 月份拉拢到了 CMU 机器学习教授 Russ Salakhutdinov&lt;/a&gt; 作为该公司人工智能研究的负责人，开始招聘人才、组建团队。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;中国的 BAT 三巨头。百度因为有吴恩达，「声音」是最大的，我们对他们的人工智能研究也是了解最多的（开源深度学习框架 Paddle、硬件基准测算工具 DeepBench 等）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;阿里在今年的云栖大会上也「秀」了一把人工智能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;腾讯也在最近成立了腾讯 AI Lab，新一轮的招兵买马不可避免。虽然在&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720536&amp;amp;idx=1&amp;amp;sn=76e38d366841b567d38c4334df175eeb&amp;amp;chksm=871b0d66b06c8470d96d6faf9c636e0e0eed6d0e89e74abd3ecfe52c68f384a906c95efd1329&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720536&amp;amp;idx=1&amp;amp;sn=76e38d366841b567d38c4334df175eeb&amp;amp;chksm=871b0d66b06c8470d96d6faf9c636e0e0eed6d0e89e74abd3ecfe52c68f384a906c95efd1329&amp;amp;scene=21#wechat_redirect"&gt;机器之心的专访中&lt;/a&gt;他们对腾讯 AI Lab 没谈到太多内容，但隐隐可察觉出腾讯也要像谷歌一样在人工智能与自己的平台和产品结合上打通一条道路。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在接近尾声的 2016 年，我们已经明显感觉到人工智能、机器学习、深度学习等字眼成为了科技界的主流。从害怕 AlphaGo 之后因过度炒作而经历新一轮寒冬，到语音识别、神经机器翻译等的一个又一个的技术突破，再到越来越激烈的人才竞争，一个新的时代即将到来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心原创，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 17 Nov 2016 10:16:24 +0800</pubDate>
    </item>
    <item>
      <title>访谈 | CMU机器学习系负责人Manuela Veloso：人工智能与人类的未来是共生自主</title>
      <link>http://www.iwgc.cn/link/3537502</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自The Verge&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀、蒋思源&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 2021 年之前，我们日常所用的软件将会具有很大程度上的智能和能力，并将会在越来越多的任务中取代人类。难道我们就要就此落后了吗？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尽管有一些人预测会出现大规模的失业和人类与人工智能之间的全面战争，但其他人并不认为未来有那么糟糕。卡内基梅隆大学机器学习系负责人 Manuela Veloso 教授设想了一个人类与人工智能密不可分的未来，它们将同心协力持续不断地交换信息和目标，她将其称之为「共生自主（symbiotic autonomy）」。在 Veloso 眼中的未来里，我们将难以将人类代理和自动化助理区分开——但不管是人还是软件，如果没有彼此，就不会有很大的用处。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Veloso 已经在 CMU 的校园里面测试这个想法了。他们打造了可移动的、赛格威一样的机器人 cobot。它们可以自动将客人从一栋建筑护送到另一栋建筑，而且当它们短缺时它们会请求人类的帮助。这是一种新的思考人工智能的方式，并且可能会在未来五年里带来深远的影响。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;日前，The Verge 在匹兹堡对 Veloso 进行了一次专访，谈论了机器人、编程自发性（programming spontaneity）和人工智能给人类带来的挑战。下面是采访内容：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;问：自动化是过去五年里的一个大趋势。我们也看到有更多的智能被构建到了我们已经在使用的工具中，比如手机和计算机。你对未来五年的发展怎么看？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;在未来，我相信会出现人类与人工智能系统的共存，并有希望会造福于人类。这些人工智能系统将涉及到处理数字世界的软件系统，也将涉及到在物理空间中移动的系统，比如无人机、机器人和自动汽车，另外还会有处理物理空间的系统，比如物联网。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你也将在物理世界中有更多的智能系统——不只是你的手机和电脑，而是我们周围的各种物理存在，它们能处理和感知这个物理世界，并帮助我们进行涉及到大量物理世界的特征的决策。随着时间的推移，我们还将看到这些人工智能系统还将会对更广泛的社会问题产生影响：比如管理大城市的交通、做出关于气候的复杂预测、在人类进行重大决策时提供支持。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：目前，我们可以看到有一些系统并不好。当一个算法或机器人进行一项决策时，我们并不总是知道它们为什么要这样决策，这让它们难以得到我们的信任。技术可以如何解决这个问题？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：我正在研究的一件事是让这些机器能够解释它们自己——对它们做出的决定负责和透明。我们做的很多研究是让人类或用户询问该系统。当我的 Cobot 到我的办公室稍微迟到时，我可以说：「你为什么迟到了？」或「你选择了哪条路？」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以我们正在研究这些人工智能系统在学习和提升时解释自己的能力，以便提供不同详细程度的解释。我们想通过与这些机器人交互从而让人类能够更加信任这些机器人。你就可以问：「你为什么要那样说？」或「你为什么推荐这个？」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;提供那样的解释占到了我现在的研究的很大一部分，而且我相信能做到这一点的机器人能够为我们提供对于这些人工智能系统的更好的理解和信任。最终，通过这些交互，人类也将能够纠正这些人工智能系统。所以我们也在做尝试整合这些纠正的研究，让这些系统能够从指令中进行学习。我相信这会是我们与人工智能系统共存中的很大一部分。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：你认为为什么这些系统现在会提升这么快呢？在过去 50 年的人工智能研究中，你觉得是什么在拖我们的后腿？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：你必须理解，对于一个人工智能系统而言，要知道什么是手机、什么是杯子、一个人是否健康，它就需要知识（knowledge）。早期的人工智能研究实际上是获取知识。我们不得不求助于人类。要人类将信息收集起来并人工录入到计算机中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;神奇的是，在过去几年来，这些信息越来越数字化。看起来这个世界通过互联网显现了出来。所以现在人工智能就是关于可用的数据，以及处理这些数据和理解它的能力，我们仍然在寻找最好的做这些人物的方法。另一方面，我们很乐观，因为我们知道数据已经有了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在的问题变成了，我们如何从数据中学习？你怎么使用它？你怎么表征它？你怎么将这些碎片结合到一起？那就是你用深度学习和深度强化学习做自动翻译的系统和能玩足够的机器人的方式。所有这些系统之所以成为可能，是因为我们可以远远更加高效地处理所有这些数据。我们不再必须执行收集知识和表征知识这些大步骤了。就是这些。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：过去五年最大的发展之一是类似 Siri 和 Alexa 的个人助理，它们都是由机器学习驱动的。我想知道你怎么看待这些系统在过去五年内的变化？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;你知道，我是 Alexa 的大粉丝。我家里就有一个，大部分时间我与 Alexa 所谈论东西变得越来越广泛。在一开始的时候就是「天气怎样？」现在我会问「我的日历上有什么安排？」Alexa 在学习，我也在学习 Alexa 能做什么。它到底能够随时间变得多好，这会是很让我惊喜的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我告诉你一件有趣的事：当我离开家的时候，我告诉 Alexa：「Alexa, stop.」我想停止它正在播放的音乐，因为我要离开了。但如果我告诉 Alexa：「Alexa, I'm leaving」，它就无法理解「I'm leaving」意味着它应该停止了。我必须明确说出「stop」才行。所以我设想个人助理会越来越能明白这样的指令：「Alexa，当我离开时，意味着你应该停止播放音乐。」这样的指令应该被提到研究日程上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;问：你认为我们会达到这样的程度吗：我们可以问个人助理「我车子里的检查引擎指示灯亮了，我可以开这辆车吗？」或「谷歌，我刚拿到了一份工作邀约，我应该接受吗？」？&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我认为这是可能的。这种类型的问题是决策问题（decision-making questions）——假设你必须选择某个健康保险计划，但你被这些选择搞糊涂了。你可能会在你要睡觉的时候告诉 Alexa：「Alexa，你看看所有这些健康保险计划，还有那些我能够购买的汽车，或者我的孩子可以去哪些学校读书。」然后它就可以在晚上帮你编译一份报告出来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;大量的相关信息都是可以通过网络获取的。你可找到那些学校的所有特征，其他人对这些学校的评价。你能找到关于这些学校的博客和其它的选择。你可以有一个能收集这些学校的所有特征的人工智能系统——它们距离多远、得到了哪些评价……你可以进入一个关于你想从教育中得到什么的主页，而人工智能系统可以将这些信息聚集到一起。它们可以查看这些特征，它们可以从过去的经验中学习，它们可以处理所有的信息，根据你的指导和问题发送所有可用的消息，以一种你能更容易消化的方式呈现这些信息。因为网络上的这些信息非常繁杂，你根本不可能实时处理掉所有这些信息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，你可能也会想有一个能告诉你它这样建议的原因的助理。你可能会问：「为什么你说我应该买这辆车？我真的不喜欢那个品牌。」我认为这是非常重要的一步，让人工智能在决策中支持人类，尝试结合和学习所有的信息，并且整合你可能给出的反馈。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：除了个人决策之外，这些系统还能做什么？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：你可以想象这同样系统的一个版本可以用于科研论文。目前已经有很多的科研论文发表了，而且现在它们都在网上。你可以想象有一个人工智能系统能帮助研究者消化所有这些信息并找到他们感兴趣的东西。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个人工智能系统将仍然是网络上的信息的一个产物。很多人正在研究信息——文本信息、图片信息、流图表、表格——尝试理解网络上有什么并最终推理对这些信息的需求。比如，机器学习里有一个叫做「主动学习（active learning）」的领域，其中我们推理出其中一些过程的图像不够，而因此你可能会想要增加更多的图像。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我设想会有能够识别缺少什么的人工智能系统，从而能够将网络上的信息点连接起来，并在有需要时请求更多的数据。你可以想象它可以问研究者：「如果你告诉我更多有关这些细胞与这种化学品的交互方式，我就能有一个更好的关于当前情况的模型。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：你的共生自主思想的一部分已经体现到了 Cobot 中，对吗？这些机器人目前被放养在 CMU 的校园里，通过一套深度相机、WiFi 和 LIDAR 装置在计算机科学大楼里面导航。它们没有机器臂，所以对于很多简单的导航任务它们也会有麻烦，但你让它们很擅长寻求帮助。&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;是的，当我们意识到这些自动机器人也有限制时，我们也很吃惊。它们没法必须打开世界上所有的门，它们也不能理解世界上每一种口语。也许它们会随时间变得越来越好，但同样地，我相信人类也有限制——我说话有口音，我的网球打得没有其他人那么好——所以这些机器人也会有局限性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们很清楚这些机器人，这些人工智能系统最重要的一个特征就是识别它们不知道什么、不能做什么和不能理解什么，然后才向人类求救。你能按下电梯按钮吗？打开一扇门？或拿些东西放在我的篮子里，这就是我们所称呼的共生自主（symbiotic autonomy）。机器人能够对那些它不能做的、不知道的或不理解的问题自主地向人类寻求帮助。这是一种新的思路，我们将有一些围绕在我们周围并将寻求我们帮助作为它们部分任务的人工智能系统。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当这种系统实现规模化时，共生自主会以更复杂的方式发生。系统已经能用无线交流了，它在云端交流数据，或获得远程团队的协助。你可以认为人工智能系统能和其它所有事物永远成为一个共生系统，比如网络上的信息、其它人工智能系统和旁边的人类或远处的人类。它成为一个独立运行的人工智能系统也是完全没有问题的，但是一个人工智能系统要意识到什么时候它不知道、什么时候它需要信息、什么时候该用一些概率来思考问题都是不确定的。它不能预先解决所有问题，但它能依赖于周围其他的帮助来解决，这也就是我所设想的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：你怎样看待共生关系改变下已有的人工智能系统？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;所以让我们返回去设想向人工智能求教怎样决策上哪所学校或投哪种健康保险。我猜想这些人工智能系统将在某种情况下需要一些人类没有提供的信息。人工智能系统也将意识到如果它们知道那些额外的特征，这将会帮助我们更好地决策。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;真正有趣的是什么时候人工智能系统能自己认识到它们缺失了些什么信息。它们意识到是否能有更多的信息，是否能做一些明确的行为，例如它们是否能够预订那家网上订不到房间的旅馆、是否能给你订一个离开会地更近一些的旅店。我真的认为这种能力是很重要的，因为我不打算知道需要做某些决策的所有信息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在我们用的 Uber、谷歌地图或 Waze 通常对路线的的规划已经是做得很不错了，然而 Waze 会反过来问你「你现在饿了吗？我能给你一条最短路径吗？你喜欢走这条岔路看看更美的景色吗？」。如果智能助手知道我十分喜欢兰花、十分喜欢某种艺术那有怎么样？我只要稍稍地偏离路径，我就能看到更好的博物馆。它在路线规划中并不知道这些，如果知道这些，那么它一定会规划一条通过博物馆的路。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：许多现在的人工智能系统专门从事某一具体的任务，如对象识别或路径优化，但是这就导致了十分孤立的专家系统。我很好奇为什么你想的是带领我们返回一种软件中更为泛化的智能。&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：通用人工智能问题是极端困难的，我也确信深度学习就是其要求的技术基础，深度强化学习也会为通用人工智能加把料。我们也在做许多这种理解迁移学习概念的研究。我们是怎样有这些算法的——是因为它们能够从事特别的任务，但同样还能学习更多其它东西吗？我们并没有真正理解人工智能，我们还不知道做很多的事情。按照算法与技术、泛化的方法和提供解释的方法来看，我们的人工智能还真正处于婴儿期，关于很多这些事情我们还束手无策。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我真的认为通用人工智能有一天能从聚合人工智能专家系统中诞生出来，就像 Minsky 描述的那样合并他们就成为了一种心智社会（Society of Mind）。你也可以用一些特殊目的的算法来解决特别复杂的问题，就像 Simon 和 Allen Newell 在人工智能刚开始研究时预测的那样。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以通用人工智能是极其困难的，但因为现在这么多的数据它又是极其令人兴奋的。现在有很多人在使用电子设备并产生数据，而且越来越多的人在使用计算机、手机、Alexa 和 Uber，所有这些都给我们在研究通用人工智能铺平了道路。我们仍然还有很多研究要做，仍然不知道通用人工智能系统确切的样子，但是我们在一条正确的道路上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：你曾经担心过这种不确定性吗？有一些担忧是当人工智能超越人类的智能，那么人类也将会灭亡。&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我完全是一个乐观主义者，我认为我们所做的自主系统研究（包括自动驾驶汽车和自主机器人）都是要求对人类负责的。在某种意义上，这是和技术毫无关系的。技术会发展，但它是由我们由人类发明的。它不是从外星人那来的，而是我们自己的研究。它是人类智能构思的技术，它取决于人类思维也充分地利用人类思维才产生。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我很相信这将发生，之所以我很乐观是因为我看到人类已经意识到了他们需要很小心地研究这些技术，同样我也意识到了。但是最好还是投资于教育。把机器人扔在一边，它会持续变得更好，但是聚焦于教育，人们知道其他人、关照其他人、关心社会的进步、地球自然的发展和科学的进步。解决所有这些问题、治疗癌症、终结贫穷等。很多和人类相关的事都能使用这种我们正在发展的技术去解决。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在某种程度上，人工智能的人文主义将最终能将我们凝聚到一起，所以我是很乐观的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译文章，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 17 Nov 2016 10:16:24 +0800</pubDate>
    </item>
    <item>
      <title>业界 | CMU教授邢波创立公司Petuum，获1500万美元A轮融资</title>
      <link>http://www.iwgc.cn/link/3537503</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自CMU&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李泽南、杜夏德&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;卡耐基梅隆大学（CMU）教授邢波花费几年时间开发完善了一个平台 Petuum，利用工作站、分布式计算机、移动设备或嵌入式设备来解决大型机器学习的问题，现在这个平台已走出实验室，成为一家独立公司。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该公司的创始人兼首席执行官邢波表示，该公司已获得了 1500 万美元 A 轮融资，并预计明年年初将其首批产品投入市场。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器学习和人工智能技术是自动驾驶汽车、语音识别、计算机视觉、自然语言处理和电子医疗记录分析等许多科技公司在大数据分析应用和创新工作的关键。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「在十到二十年后，人工智能和机器学习程序将会接管计算设备中的大部分任务，」邢波说道「我们需要优化这些程序在设备中的设计，编程和运行效率，特别是在这些程序体量不断增大的情况下。在一些领域中，如自动驾驶汽车，目前仍然受到人工智能和机器学习——它们现在还是黑箱——的限制，无法快速发展。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「Petuum 有望成为转变这一现状的平台，让人工智能/机器学习程序能够轻松构建，并且使用标准化，透明和可重复的方法在不同的硬件平台上安装和运行，Petuum 平台允许程序快速、准确、规模化地运行，同时只需要耗费少量的计算资源，」邢波表示。「该公司的愿景是让他们的平台能够在任何硬件上运行。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我们的平台将使用不同的计算设备，从数据中心到移动设备，嵌入平台，让它们像个人电脑一样运行，」邢波说道。人工智能需要处理的大数据集通常已存在于这些设备中。Petuum 将允许机器学习系统在这些分布式计算设备中进行无缝操作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Petuum 寻求在分布式计算的更大规模上增强和扩展人工智能和机器学习的应用。计算设备之间的通信对于人工智能/机器学习来说可能是个棘手的问题，但邢波认为，他和他的同事们在 Sailing Lab 中开发的参数服务器具有高效管理通信和负载平衡的方法，在过去的以自年自动保持设备运行同步。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然一些其他团队也正在使用分布式设备解决机器学习问题，但邢波和他的团队的已经表明他们的方法为所有类型的机器学习任务提供了最佳，最有效的解决方案，不仅仅是某一方面，如深度学习。这一平台可以支持多种形式的应用，如自然语言处理，图像和视频的识别，以及交易数据中的异常检测。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了推动公司发展，「我们已经走到不得不融资的一步了」，邢波说道。未来 6 个月，他希望能招到 30 到 50 个人，需要受过高级研究训练的计算机科学家和工程师，把公司的水平维持在卡耐基梅陇大学的高度上。他补充道，「我们的目标是以匹兹堡为根据地，利用好这个城市和 CMU 的资源，帮助我们获得我们需要的顶尖人才。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;邢 &amp;nbsp;波&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;卡耐基梅隆大学计算机科学学院教授，卡耐基梅隆大学机器学习和医疗中心主任。美国新泽西州立大学分子生物学与生物化学博士；美国加州大学伯克利分校（UC，Berkeley）计算机科学博士。主要研究兴趣集中在机器学习和统计学习方法论及理论的发展，和大规模计算系统和架构的开发，以解决在复杂系统中的高维、多峰和动态的潜在世界中的自动化学习、推理以及决策问题。目前或曾经担任《美国统计协会期刊》(JASA)、《应用统计年鉴》(AOAS)、《IEEE模式分析与机器智能学报》(PAMI)和《PLoS计算生物学杂志》(the PLoS JournalofComputational Biology)的副主编，《机器学习杂志》(MLJ)和《机器学习研究杂志》(JMLR)的执行主编，还是美国国防部高级研究计划署(DARPA)信息科学与技术顾问组成员，曾获得美国国家科学基金会(NSF)事业奖、Alfred P. Sloan学者奖、美国空军青年学者奖以及IBM开放协作研究学者奖等，以及多次论文奖。曾于2014年担任国际机器学习大会（ICML）主席。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Petuum 公司简介&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Petuum, Inc. 正在开发一个服务各种人工智能和机器学习算法和应用的平台。它的产品让企业可以打造用于真实世界的人工智能和机器学习实现。&lt;br/&gt;Petuum, Inc. 有一个实力雄厚的顾问委员会，汇集了一些学界和产业界的重量级人士，包括：&lt;br/&gt;Michael I. Jordan：加州大学伯克利分校电气工程与计算机科学系和统计学系 Pehong Chen 杰出教授&lt;br/&gt;Stephen P. Boyd：斯坦福大学信息系统实验室电气工程教授和工程学院 Samsung 教授&lt;br/&gt;Kai Li（李凯）：Data Domain 创始人兼首席科学家；普林斯顿大学计算机科学系 Paul M. Wythes '55, P'86 and Marcia R. Wythes P'86 教授&lt;br/&gt;Harry Shum（沈向洋）：微软执行副总裁&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译文章，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 17 Nov 2016 10:16:24 +0800</pubDate>
    </item>
    <item>
      <title>专栏 | 第四范式先知平台的整体架构和实现细节</title>
      <link>http://www.iwgc.cn/link/3537504</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心专栏&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;Infoq授权转载&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：胡时伟、涂威威&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;在不久之前的一场演讲中，&lt;span&gt;第四范式联合创始人、研发副总裁胡时伟，以及「先知」平台的核心计算框架 GDBT 的开创者涂威威对先知平台的整体架构与实现细节进行了详细的介绍。在 12 月份，机器之心也将联合第四范式举办一场线下分享活动，感兴趣的读者可点击阅读原文报名。活动介绍附在文后。&lt;/span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717515&amp;amp;idx=1&amp;amp;sn=897ffd8a396d17ca4f785d499f7ae854&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717515&amp;amp;idx=1&amp;amp;sn=897ffd8a396d17ca4f785d499f7ae854&amp;amp;scene=21#wechat_redirect"&gt;第四范式·先知作为第四范式的核心产品，发布以来一直备受关注&lt;/a&gt;&lt;/span&gt;&lt;span&gt;。今年 10 月，先知荣获了中国智能科学界最高奖「2016 年吴文俊人工智能科学技术奖一等奖」。在正在举行的乌镇世界互联网大会上，先知将正式开放公有云版。定位于部署在公有云上的机器学习平台，先知公有云版有望帮助互联网公司零门槛地拥有人工智能技术，解决人工智能在不同行业企业、特别是互联网公司应用的问题。这也是第四范式为降低 AI 入场门槛而做出的较大突破。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;近期，先知主创团队在大数据杂谈上做了一个比较详细的系统介绍。主讲人是第四范式联合创始人、研发副总裁胡时伟，以及「先知」平台的核心计算框架 GDBT 的开创者涂威威。这也是第四范式团队首次对外披露设计、研发、部署先知过程中的一些经验，探讨机器学习从系统和工程方面的优化方向。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;具体分享内容如下，接下来主要从如下几个方面来讲述：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="list-style-type: decimal;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;为什么人工智能系统需要高维大规模机器学习模型&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;训练高维大规模机器学习模型算法的工程优化&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;机器学习产品的架构实践&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先先从人工智能发展说起，人工智能并不是一个最近出现的概念，早在 60 年代就有著名学者曾经预言二十年内机器将能够完成人能做到的一切工作。到今天我们又听到说 20 年之内，一大半的工作岗位将被机器人替代。那么 60 年代到今天发生的最大的区别是什么？这其中发生了两个重大的变化，第一个是计算能力的突飞猛进，今天的手机一个核的计算能力就足以秒杀当年的超级计算机。第二个是我们拥有了大数据，TB 级的数据存储、处理在今天已经不再困难，而 20 年前，GB 级的硬盘才刚刚兴起。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因此我们说今天人工智能=机器学习+大数据，那么什么样是好的人工智能呢？这里引入一个「VC 维」的概念。「VC」维是 1960 年代到 1990 年代由 Vapnik 及 Chervonenkis 建立的一套统计学习理论。VC 维反映了函数集的学习能力，VC 维越大则模型或函数越复杂，学习能力就越强。之前，统计建模曾经进入过一个误区，就是去追求经验风险最小化，什么意思呢？就是说我希望建立一个模型，在给定的样本上不要有误差，这样感觉非常好，但是往往这么一来，在实际的预测中非常糟糕，这是为什么呢？是因为采用了一些 VC 维很高的模型，虽然函数集学习能力是强了，但是由于数据不够，所以导致置信风险变大产生了一些类似过拟合的情况，最后这个模型还是不好用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是今天我们进入了大数据时代，样本的数量，包括样本的特征丰富程度有了极大提升，这就又带来了提升 VC 维的新机会。我们经常说经验主义害死人，过去的建模就是害怕经验主义，所以呢就把这个大脑变笨，降低 VC 维，使得模型更有效。但是今天的大数据情况下，可以通过补充更多的阅历（数据），来避免经验主义，那么一个阅历丰富的聪明的人，自然是要比一个笨的记不住东西的人要好的。因此我们说大数据人工智能时代，提升 VC 维变成了一个好的人工智能系统的关键因素。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;那么机器学习中的高维度从何而来？传统方法只能利用可以放在特征矩阵这个平面中的数据，对于立体的数据，多维度的数据，因为它们多不是数字，所以传统机器学习模型无法处理，只能选择舍弃。但在实际工业应用中，这类非数字化的数据所包含的信息，往往信息价值很高，比如它可能对个性化推荐很有影响，可能对泛化处理有帮助。为了能成分利用这些数据，我们对特征矩阵外的立体的数据通过切片等算法进行变换，使得变换后的数据成为特征矩阵的一部分，同时还对不同特征之间进行交叉组合等操作，这样特征矩阵的每一行的列数就从原始数据的列数，变成了每一行都是一个巨大（比如 2 的 64 次方）的向量，形成超高维度的模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;高维度模型真正的意义何在？通过对原来立体数据切片处理，可以使得某些过去只能有简单线性表达的数据，比如年龄等，获得更接近真实情况的细腻体现；此外，原来机器学习不能利用的非数字、没有排序关系的数据，比如姓名等，也可以发挥其价值所在。举个例子，在个性化推荐的场景中，体现个性化信息的数据之间通常是不可比的，比如，我们先只考虑热度、推荐序号和用户 ID 三个变量，其中用户 ID 这个变量就是传统机器学习模型所不能利用的，只有通过将这个数据切片处理，获得一个高维度模型，才可以真正将用户信息这个数据发挥出价值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;要获得一个成功的高维度模型，就需要好的机器学习系统，这个系统应当具备两个特征：横向可扩展的高计算性能和算法本身在收敛过程中的正确性。为此，我们的算法工程团队开发了一系列的基础设施组件，组成了大规模分布式机器学习框架 GDBT（General Distributed Brain Technology）。GDBT 是一个由 C++编写的，完全分布式的适合于机器学习计算场景的计算框架，可以运行在单机、MPI、Yarn、Mesos 等多个分布式环境。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;大规模分布式机器学习框架 GDBT&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器学习是一种数据驱动的实现人工智能的方式，机器学习在实际应用中的大数据、高维度背景导致需要一个高效计算的平台，同时，监督学习领域著名的 No Free Lunch 定理指出，没有一个机器学习模型能够对所有的问题都是最有效的。所以在不同的实际问题里，需要使用不同的机器学习算法或者对机器学习算法做适应性地调整，去达到更好的实际效果。因此在实际的应用中，需要能够非常容易地开发出适应实际问题的机器学习算法。相比于传统的 ETL 计算，机器学习算法的计算过程有很多自身的要求和特点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在框架设计上，没有普适的最好的框架，只有最适合自身应用场景的框架。GDBT 框架的设计初衷主要就是打造一个专门为分布式大规模机器学习设计的计算框架，兼顾开发效率和运行效率。GDBT 框架不是某一种算法，而是一种通用的机器学习算法计算框架，使算法工程师可以基于 GDBT 开发各种传统或者创新算法的分布式版本，而不用过多地关心分布式底层细节。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前比较流行的计算框架比如 Hadoop、Spark 其重点任务大多是 ETL 类的任务。前面提到机器学习计算任务相比于传统的 ETL 计算任务有很多自身的特点，时间有限这里可以简单地展开一下。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在计算方面：相比于 ETL 会做的一些相对「简单」的运算，机器学习算法会对数据做相对复杂的运算，一些非线性的模型，比如深度学习模型会需要比较密集的计算；在实际的应用中，需要考虑不同计算资源的特性；分布式计算中，由于分布式带来的通讯、同步、灾备等等的 overhead 需要调整计算模式来尽可能地降低。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在通讯方面：很多机器学习算法在计算过程中会频繁使用到全局或者其他节点的信息，对网络吞吐和通讯延迟的要求要远高于 ETL 任务。同时，很多机器学习任务对于一致性的要求要低于 ETL 任务，在系统的设计上可以使用放松的一致性要求。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在存储方面：ETL 需要处理来源不同的各种数据，比较少的反复迭代运算，很多机器学习算法会对数据做反复的迭代运算，可能会有大量的不断擦写的中间数据产生，对存储的使用效率、访问效率有着更高的需求。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在灾备和效率的权衡方面：容灾策略有两方面的额外开销，一方面来自于执行过程中为了容灾所需要做的额外的诸如状态保存之类的操作，另一方面来自于灾难恢复时所需要进行的额外重复计算开销。这两方面的开销是此消彼长的。与 ETL 计算任务不同，机器学习计算任务流程相对复杂，中间状态较多，在较细的粒度上进行容灾会增加执行过程中的额外开销。因此在容灾策略和容灾粒度上，机器学习计算任务和 ETL 计算任务之间的权衡点不一样。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;GDBT 计算框架针对机器学习任务在计算、通讯、存储、灾备等方面做了深入的优化。时间有限，这里可以简单的讲一点 GDBT 的工作，有兴趣了解更多的同学可以会后再和我们联系，或者加入第四范式一起解决这些有趣的问题：）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在计算方面，计算硬件发展到今天，提升计算能力的主要方式是堆积计算能力的分布式并行计算，比如现在做深度学习非常流行的 GPU 本身也是一种并行计算硬件，针对不同需求的计算硬件的种类也在变多，比如 FPGA 等等。对于大数据、高维度、复杂的机器学习计算任务，GDBT 框架充分考虑了分布式并行计算的特点，针对不同的硬件资源、不同的算法场景做了调度、计算模式、机器学习算法部件的抽象等的优化。GDBT 框架本身在设计上也刻意避免了现在一些框架设计容易走入的误区。比如：为了分布式而分布式，但是忘记了分布式带来的 overhead。GDBT 框架针对单机、分布式模式分别进行了优化，框架本身会对不同规模的计算任务、不同的计算环境做自适应的调整选择更高效的实现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然后在通讯方面，通信效率是分布式机器学习系统中至关重要的部分。首先, 相比于 ETL 任务, 很多机器学习算法在计算过程中会频繁使用到全局或者其他节点的信息, 对网络吞吐和通讯延迟的要求都很高。其次, 一些机器学习算法在通信时可能有很多可以合并处理的通讯需求。再次, 很多机器学习算法并不要 求在所有环节保证强一致性。最后, 对于不同的网络拓扑, 最优的通讯方式也会不一样。因为存在可能的合并处理、非强一致性需求、网络拓扑敏感等, 就会存在有别于传统通讯框架的优化。先知的 GDBT 计算框架内部, 针对机器学习计算任务单独开发了一套通信框架, 为机器学习任务提供了更高效、更易用的支持点对点异步、点对点同步、深入优化的组通讯 (比如类 MPI 的 Broadcast、 AllReduce、Gather、Scatter 等等) 的通信框架, 同时为应用层提供了简便易用的合并、本地缓存 等等功能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然后介绍下我们在参数服务器（Parameter Server）方面的工作，很多机器学习算法的学习过程都是在「学习」一组参数, 对于分布式机器学习任务, 不同的节点需要对「全局」的这组参数进行读取和更新, 由于是分布式并行的计算任务, 因此存在着一致性的问题, 不同的机器学习算法或者同一个机器学习算法的不同实现对一致性的要求会不尽相同, 不同的 一致性策略对整体算法的效率会产生很大的影响。参数服务器就是为了解决分布式并行机器学习任务中多机协同读取、更新同一组参数设计的, 设计上需要提供简单易操作的访问接口方便机器学习专家开发算法, 同时也需要提供可选择的一致性策略、灾备等等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外，由于是为机器学习任务设计，参数服务器的设计目标是高吞吐、低延迟。GDBT 中的参数服务器针对不同的应用场景做了更 加深入的优化, 结合高效缓存、智能合并等优化策略以及基于 GDBT 自带的高效异步通讯框架, 同 时, 还针对稀疏、稠密等不同的参数场景进行了针对性优化;内置提供了丰富的一致性策略可供用户选择或自定义一致性策略；GDBT 将参数服务器看成一种特殊的 Key-Value 存储系统, 对其进行了独立的灾备设计, 同时提供不同粒度的灾备选项, 便于在实际的部署中选择合适的灾备策略提升效率。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这次我主要讲计算框架方面的工作，以后有机会可以再详细分享我们在机器学习算法框架以及机器学习算法方面的设计工作。针对机器学习算法计算，GDBT 框架做了进一步的抽象，比如数据流、优化算子、多模型框架等等，这里简单介绍下数据流的设计。对于研究并实现机器学习算法的专家而言，算法的核心就是数据的各种变换和计算。GDBT 框架为了让机器学习专家更容易、更快速地开发出不同的机器学习算法提供了数据流的抽象，使得机器学习专家通过描述数据流 DAG 图的方式编写机器学习算法。机器学习专家只需要关注数据的核心变换和计算逻辑，GDBT 计算框架将机器学习专家描述的数据流图进行高效的分布式计算。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数据流计算框架的抽象一方面有助于降低机器学习专家的开发门槛、提升开发速度（他们不需要关注底层分布式、并行细节），另一方面也为 GDBT 框架提供了更大的空间去进行数据流执行优化，能够进一步提升执行效率（如果 GDBT 框架只在底层模块进行优化，将会非常乏力；但是数据流的抽象使得 GDBT 框架能够更全面地了解计算任务的 pattern，可以做更多的优化工作）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在存储、灾备设计等方面，GDBT 也做了深入的优化，比如多级缓存的设计、框架层面对存储读取写入、网络访问、计算过程等等的灾备设计，对不同计算规模采取不同的灾备粒度等等，这里时间有限，就不做过多介绍了。机器学习算法部分的工作以后有机会可以再一起交流。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;GDBT 定制的通信框架、算法框架以及参数服务器，为进行大规模机器学习训练提供了基石。当然 GDBT 还有一个很大的特性是算法开发者友好，对于算法开发来说，学术研究和工业应用之间存在一定的取舍。一些其他的算法框架比如 Tensorflow，比较注重研究上的易用性，从而在效率上有所舍弃，而一些注重于生产应用的算法框架特别是分布式框架，在算法二次开发和扩展上则捉襟见绌。GDBT 提供的是工业级的开发者易用性，从语言级别，GDBT 整体基于 C++ 14 标准，为算法的开发提供了更大的自由。从功能抽象上，GDBT 提供了对参数服务器和算子的良好包装，在 GDBT 上，只需要数百行代码就可以实现像逻辑回归、矩阵分解等算法的分布式版本。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;机器学习算法框架的语言选择问题&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;关于机器学习算法框架的语言选择问题，因为今天很多的大数据框架都是基于 Hadoop/Spark 这一套的，都是 JVM 上的东西，因此基于 JVM 从整体来说接入生态是比较容易的，但其实有三点理由让我们选择 C++而不是基于 JVM 去做这件事情。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先我们前面讲过，目前虽然计算能力对传统应用来说井喷，我们经常说 CPU 过剩、GPU 过剩。但是对于高维机器学习过程来说，依然是资源非常紧张的，这里面包括计算、网络、内存等多个方面，我们看 Spark 的 Project Tungsten 也做了大量堆外内存管理的工作以提升数据的处理效率，但是对机器学习来说，基本上整个过程都需要对内存和计算过程进行精细控制，以及避免不可控的 GC 过程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其次，C++的一些语言特性，比如运算符重载机制也可以使得框架上层的算法应用的语法比较简单优雅，不会变成巨大的一坨，而大规模机器学习很多时候和字符串组成的离散特征打交道，C++对字符串处理的效率也要高出 JVM-Based 语言非常多。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;再次，Spark 目前的机制和 Parameter Server 的结合很难做到优雅和完美，强行对接 PS 会破坏 Spark 自身的灾备、任务调度等特性。如果不对接，那么就基本上只能靠降低模型大小来确保效率，和高维度的目标南辕北辙。所以综合考虑，我们还是选择 C++来实现整个一套的系统，而将和大数据框架的对接以及开发门槛降低这个任务交给整个机器学习系统的架构。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;整体架构&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;上面讲了很多机器学习算法框架，但有过实践经验的朋友都知道，光有一个算法框架只相当于汽车有了发动机，离开起来还很远。我们总结一个完整的机器学习系统需要有如下部分：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;数据引入和预处理&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;特征工程&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;模型训练算法（支持参数灵活调整和二次开发）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;模型评估&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;模型上线（批量预估、实时 API 调用、线上特征实时计算）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;那么对于这所有的部分，我们开发了一个叫『先知』的整体平台产品，我们先看一下先知的整体架构图：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9xhznsLIp5sSbIiayEITWLFvJ7upAq9QqBb3WV36pNG7XMAPwQTtJxRHBZ2Y2VFmcsGiaicQxfnOpxQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;整体来说，先知平台由界面层、调度管理层、集群适配层、集群任务执行层，另外外加一个线上的预估服务云。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这套架构能够给我们带来如下几个优势：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 把整个机器学习过程作为一个整体来看待，做到各模块的深度整合。下面是我们产品的一个截图：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9xhznsLIp5sSbIiayEITWLFicrc99cjZz7gWibsAibIRbtvbz9kUPuZQllricSq1NGWBo8G4GFqiaXtzYQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;可以看到，通过一个 DAG 图的描述，可以将大数据的处理过程（SQL/PySpark/数据拆分）和机器学习的过程（特征工程、模型训练、模型评估）整体结合起来，用户不再需要去开发脚本去处理复杂的模块和模块之间的对接以及输入输出的各种判断。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;同时呢，这个 DAG 图的背后我们还做了很多工作，一个比较有意思的就是对存储的抽象和适配。我们有的客户是用 AWS 作为基础设施，而有的客户用阿里云做基础设施，有的客户则选择在 IDC 内构建自己的机房。这里面就有块存储、云盘、SSD、内存盘等多种存储服务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外，一个完整的机器学习过程，往往还要从数据库里面导入数据，最终要把数据导出到某个指定的位置。导数据在逻辑上的复杂性和由于某些开源模块不支持内存缓存和 SSD 导致的性能的低下都是困扰数据科学家的问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对此设计了一个两层的存储抽象层 API，第一层是一个开源项目 alluxio，就是以前的 tachyon，alluxio 这个东西是非常好的，好在哪里呢？他用一套解决方案一下子解决了几个问题，第一是可以支持很多分布式的文件系统，包括 S3、Ceph 等。第二还能够比较透明的解决内存和 SSD 加速的问题。针对 Alluxio 这个项目，我们将整个的数据处理、模型训练、预估体系，包括我们自己开发的 GDBT 框架都和 alluxio 做了深度的融合集成，也针对开源的产品在访问调度、吞吐、SSD 优化上做了一些增强和修补的工作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第二层是 DataManager，我们知道企业的应用，特别在意安全性，那么如果我们直接把底层的文件系统暴露给使用者，会导致权限隔离等个方面的隐患。Datamanager 提供了一个数据的逻辑沙箱，使得每个使用者在自己的 DAG 里面只能用一个唯一的名字来访问到自己安全容器内部的数据，这样不仅保证了安全，也避免了使用者直接去处理各种各样的长的数据文件的 URI。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 给开发者提供比较好的体验，相信使用大数据系统的朋友都有一个感受，就是在分布式时代，调试变得难了。一方面很多时候日志太过于复杂，不知道错误在哪里，另外一方面经常出现跑了几个小时报一个错前功尽弃的情况。先知平台从产品上做了很多工作，比如说 Schema 推断：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9xhznsLIp5sSbIiayEITWLF81jv2GXTaPrEtWSuSc9nIYwGdrCnTTLHhtpiakafHM0euW2g33ibcLicg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们可以在运行这个 SQL 之前就在界面上交互式的看到哪里出了错误，以便及时改正，而不需要整个 DAG 图跑了几个小时，运行到这个地方的时候，可能人都去睡觉了报个错，只能第二天再来。另外比如我们还提供了特征重要性评估的功能：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9xhznsLIp5sSbIiayEITWLFtlibsSn0p4UqSMSgKWmDI2WvBSglKT4vYyRe9VwttfeBBMTsicibwL3LQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个功能可以让使用者很快发现自己模型里面的问题，比如某个特征重要性极高，需要考虑自己的模型是不是有看答案（用结果去训练模型，再去评估结果，导致模型线下评估效果非常好，线上无效）的现象。值得一提的是，这个特征重要性评估的算法也是基于 GDBT 框架开发的，GDBT 不仅可以高效的支持各种模型算法开发，也能够快速的支持各种其他的大规模分布式计算逻辑。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3. 支持模型的上线，模型上线有几个技术上的难点，一是线上线下的一致性，而是性能。线上线下一致性为什么难，因为你看到训练过程是那么复杂一个 DAG 图，那么对应的线上多个数据源，也要经过一个组合、变换的过程，那如果每次都去手动开发，这个代价就不得了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;先知的架构支持从线下的 DAG 导出线上服务的核心部分，那么特征工程、模型计算就可以直接获得一个可用的 API，可以极大的节省开发者的代价。另外一个难题就是性能，因为线下批量的训练，可以花很长时间，而线上如果是实时预估，那么就要毫秒级的响应，也要求很高的 QPS。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们在线上有一个叫 Cannon 的分布式 KV 框架，可以支持到数十 T 分布式内存的模型高性能存储和查询。而模型计算的部分也可以复用 GDBT 的代码，既减少了开发量，又为一致性提供了保证。这里面也有很多有意思的工程优化，比如说如何解决机器数变大、网络条件变差情况下的可用性塌方式下降。今天时间有限就不展开说了，有机会可以再跟大家分享。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;小结&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;非常感谢大家耐心听我们分享了上面我们做的这些微小的工作。第四范式是一家人工智能技术与服务提供商，拥有大批顶尖的数据研究科学家，和追求极致匠人精神的工程师。各路 ACM 冠军选手每天在各个方向上进行深入的产品和工程优化工作，希望能够促进机器学习和 AI 在各行各业的发展，也希望能够给从业者们带来更好用的平台和工具。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当然做出好的机器学习解决方案，最关键的还是要和行业结合，工具和平台系统只是其中的一小部分，所以还希望能够向各位同仁多多学习。现在先知平台公有云版本已经向业务场景成熟的企业客户开放合作，如果有风控、内容推荐、客户经营等场景的朋友，我们也可以一起互相切磋，互相学习。谢谢大家。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Q&amp;amp;A&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Q1：请问先知平台用到深度学习框架了么？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;答：现有的开源的深度学习框架不能完全解决先知平台客户的问题，因为很多实际的问题，除了包含稠密的连续特征之外，还有大规模的稀疏离散特征，目前大部分的开源框架大多 focus 在稠密连续特征的深度学习问题上，对学术界比较关心的同学，可能可以发现 google 最近有一篇 wide&amp;amp;deep learning 的论文是做类似的事情的，这个解决方案和我们三年前在百度做的解决方案很类似，但是很可惜的是开源的 tensorflow 在这个问题上效率非常糟糕。实际问题的难点在于它是 IO 密集（大规模稀疏）且计算密集的（稠密），而且这样的模型是极其难调的，我们有很多新的算法在解决这方面的问题，不仅仅是深度学习。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Q2：是通过何种机制做到数百倍的加速的？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;答：从算法设计到 GDBT 平台设计和底层优化，都有很多工作，今天的讲座里面有涉及到一些，可以翻看记录；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Q3：有没有提出一些最优化框架，比如 SVRG 等来加速收敛？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;答：对于不同的问题，不同的场景，会对优化算法有不同的需求，比如收敛速度、稀疏性、稳定性、是否便于实现、是否便于分布式并行、是否访存友好等等，先知支持多种优化算法（batch/stochastic 的都有），比如 lbfgs、FOBOS、RDA、FTRL、SVRG、Frank-wolfe 等等都会有涉及，同时针对不同的应用场景也需要做一定的改进和调整。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Q4：超参数学习这块是通过 bayes 还是强化学习呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;答：目前产品中的是 bayesian 的，其他方式也正在尝试。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Q5：在何种情况下如何判定自动特征不能起作用而改为人工特征呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;答：有很多特征选择的算法和策略，同时，对于实际的问题，可以先用自动特征处理取得一个初步的效果，再从实际模型效果去看是否需要人工介入做进一步的优化，自动特征工程是一个很难的问题，目前其实是很难做到 100% 全自动的，我们平台期望能够尽最大可能的降低人力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Q6：先知在实现过程中用到参数服务器了没有？模型的训练，是采用异步 asp，还是同步 bsp，还是半异步的 ssp 这种？如果是异步，如何解决收敛困难的问题？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;答：前面有提到，我们用到了 parameter server。模型训练支持多种模式，对于不同的算法，不同的计算环境，会采用不同的同步方式。其实目前大部分情况下，如果数据切分 计算调度得当，异步和同步差别没有特别大，计算资源有较大差别的时候，还是建议带版本控制；更好的方式是采用类似的计算资源做好数据切分和计算调度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Q7: 第四范式的先知和谷歌的 Tensor flow 有什么区别？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;答： 从覆盖范围上，先知是一个机器学习应用全生命周期管理的平台，而 Tensorflow 对应的是先知的 GDBT 部分。而对于 GDBT 和 Tensorflow 的区别来说，前面也讲到，首先 Tensorflow 更多是为算法研究目的而存在的，已经有一些 benchmark 说明 tensorflow 比目前很多开源的深度机器学习框架都要慢。当然我个人觉得，因为 Tensorflow 本身不是为大规模工业应用设计的，只是现在好的框架的确太贫乏了。Tensorflow 的一些设计理念比如高兼容性，跨平台也是很好的。这方面 GDBT 也都有考虑和规划。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Q8：GDBT 有没有解决模型并行训练问题？还是只依靠数据并行？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;答：也分不同的算法，GDBT 同时支持模型分布式和数据分布式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Q9：GDBT 怎么能够同时支持连续、离散的这两种数据的融合训练？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;答：解决这个问题，一个是效率，首先框架底层上要能够支持很灵活的调度，能够根据连续和离散的数据的计算特性做针对性的设计，比如连续复杂模型是计算密集，可能需要调度到 GPU 运算，离散数据可能是 IO 密集，需要做好计算调度，资源异步调度；更重要的是在算法上做更多的新的改进，因为学术界大多情况下是分别考虑，我们有一系列自己重新设计的算法。对算法细节有兴趣的同学，可以考虑加入到第四范式，或者等我们的专利公开:)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Q10：请问 GDBT 对于异构计算的支持情况如何？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;答：GDBT 目前支持 CPU 和 GPU 的异构计算。在百度的时候，我们有过在模型预测时使用 FPGA，不过，最近 GPU 进展不错，比如 nvidia 有一些新的芯片比如 Tesla P4 的出现，可能会对 FPGA 有一定的冲击，对于 FPGA 的使用，目前我们研究上还是跟随状态，并没有集成到先知产品中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Q11：第四范式的人工智能平台先知可以直接替代 Spark 么？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;答： Prophet 诞生的原因是因为我们为各种行业提供服务，每个行业的差异化乍一看都不少，按照传统的方式，我们需要 case by case 的去应对，给出对应的方法，然后进行实施。但在这个 case by case 的过程中，大部分的精力是花在如何把对领域专有知识的理解（业务理解）转换为机器学习过程的具体操作（数据科学家的工作），对于端到端的两端，数据 和 服务，反而是比较通用的。那么如果能够利用技术和算法，解决专有知识到对应机器学习过程的映射问题，我们就可以建设一个通用的平台来使得 AI 应用到不同场景的代价变小，实现人工智能的傻瓜机。Prophet 就是这个目标的第一步。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先 Prophet 定位在一套完整的平台，包括核心机器学习算法框架 GDBT（没错不是 GBDT，这是个算法框架，其作者起名为 General Distributed Brilliant Technology），以及机器学习任务调度框架 TM，以及人机接口 Lamma，还有架设在整个框架上的一系列算子。当然这些都是内部名字无所谓，总的来说 Prophet 提供的是端到端的机器学习能力，进来是数据，出去是 Service。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然后关于 GDBT 和 Spark，应该说对比的是 基于 GDBT 的算法 以及 基于 Spark 的算法（MLLib 实现），由于计算架构的不同，所以简单的来说多少多少倍是没有太多的意义，因为如果特征纬度多到一定程度，MLLib 在不做数据采样的情况下是无法完成某些训练的。但是具体在几千万行，几十个核的场景下，快几百倍是实测结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外，我们在做的事情，算法框架是一个部分，性能也是很重要的，但是做这些的目的是为了降低机器学习应用于具体行业的门槛和先决要求。这个先决要求既包含硬件上的，也包含人在机器学习方面知识的要求。拥有更强大的计算能力和特征处理能力，意味着我们可以更少的让人输入信息，而更多的依靠计算机自身的学习和计算来找到机器学习算法在具体问题上应用的最佳结合点，这其中甚至还需要包括如何去利用计算资源的投入避免机器学习常见的一些缺陷。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因此 Prophet 不会替代 Spark，Prophet 里面的很多组件也是基于 Spark 的，Prophet 的目标是把 AI 的能力较为容易的带到各个应用场景，为了这个目标，我们会利用好 GDBT，也会极致的利用好 Spark，也会利用硬件技术的最新进展。一切为了 AI for everyone。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;简单的来说，先知的设计范围超出了 Spark，包含了 Spark，所以不能说是替代。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Q12：什么样的企业用得起机器学习来辅助运营？使用你们机器学习系统的门槛是什么?&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;答：从目前来看，需要有一个好的业务场景和足够的数据。互联网的 APP 或者非常大的传统行业里面的推荐、营销、定价等场景都比较适合。数据量小的就要看，通常来说 10 万多样本分布均匀就有这个可能。用这个机器学习系统目前的门槛是首先要能理解数据和业务，有一定的统计的背景和思路，然后就是能够导入导出数据，最后就是阅读一下先知的使用手册和培训视频。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Q13：电商推荐平台，怎么样能最快地应用机器学习的精准推荐？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;答：对于推荐场景，我们有相对比较成熟的接入方案，可以快速通过数据和 API 接入，通过公有云的 SaaS 服务享受到 GDBT 的能力以及先知的整体效果。有需求的朋友可以关注我们的官方网站和公众号（NextParadigm），我们会近期放出先知推荐的试用邀请。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Q14：机器学习目前哪些企业和行业应用比较广泛？国内有哪些成功案例。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;答：大规模机器学习，BAT 今日头条等，广告推荐为主。我们在银行最近的探索也有很多成功的例子，比如在营销和定价、反欺诈方面。另外风控一向是机器学习的主战场。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Q15：自动特征这套做法，跟百度凤巢的那套是一样的对吧？百度有公开论文，是 gradient boosting factorization machine，这个方法比深度学习那个自动特征相比如何？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;答：做法和夏粉老师的那套不一样；夏老师和张潼老师这篇文章和 nn-based 的各有优劣。其实 NN 没有大家想的那么万能，「人工」的很多 feature combination 是 NN 很难学出的，其中有很多有趣的问题，这里就不赘述了，可以再交流。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外：对于 FPGA 和 GPU 的未来我们有一段简单的思考，之前有准备过一段，之前没用上，现在贴这里：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;FPGA 是作为专用集成电路领域中的一种半定制电路而出现的，既解决了全定制电路的不足，又克服了原有可编程逻辑器件门电路数有限的缺点。机器学习尤其是深度学习是计算密集型的，比如深度学习里面有大量的浮点矩阵运算这种并行浮点运算需求，传统的 CPU 从设计上而言已经很难满足这种大规模浮点计算密集型任务。目前针对这种机器学习任务，CPU 主流的替代选择是 FPGA 和 GPU。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;GPU 是固定的计算架构的计算设备，有着良好的软件编程接口，但是对于特定的计算模式和模型结构不一定是最优的选择。FPGA 本身是一种可编程的硬件，对于有研发能力的厂商而言，深度优化过的 FPGA，相比 GPU，能够提供更专有的硬件加速，更重要的是 FPGA 在单位能耗上能提供的计算能力要高于 GPU。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外，企业级 FPGA 也比企业级 GPU 便宜很多。但是 FPGA 的缺点也非常明显，对相关专业人才的要求非常高，需要能够将复杂的机器学习算法映射到硬件逻辑上，同时提供高吞吐和低延迟，开发难度很大。对于中小公司而言，如果没有相应的 FPGA 研发能力，或者无法支撑高昂的研发成本，在机器学习尤其是深度学习的训练/预估硬件解决方案上可以选择架构固定的 GPU；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而对于有相应能力的大中型企业而言，FPGA 带来的硬件成本的大幅降低和能耗的大幅降低，能够轻易覆盖研发团队的费用，在机器学习尤其是深度学习预估的硬件解决方案上 FPGA 会是更合适的选择。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;同时，在制造工艺上，相比于 FPGA，GPU 是固定的专用计算架构且不提供可编程能力，可以通过不断的芯片优化，提供更强的计算能力，对于计算更加密集的深度学习训练任务，GPU 现在还是更合适的选择。随着 GPU 在芯片上不断优化提升和能耗的降低，以及 FPGA 不断提升芯片可提供的计算能力，两者的差距在不断缩小，未来两者的地位是否会有大的变革，值得期待。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;讲师介绍：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;胡时伟 第四范式联合创始人，研发副总裁&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;在大规模机器学习、广告、搜索、行业垂直应用、系统运维、研发团队管理等领域拥有丰富经验。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;曾主持架构了百度「知心」系统和链家网系统，在百度任职期间作为系统架构负责人，主持了百度商业客户运营、凤巢新兴变现、「商业知心」搜索、阿拉丁生态等多个核心系统的架构设计工作。在担任链家网研发负责人期间，从 0 开始完成了链家网新主站、经纪人新作业系统、绩效变革系统的整体架构设计以及研发团队的建设管理，参与规划及推动了链家系统和研发体系的互联网化转型。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;现任第四范式研发总工程师，负责产品技术团队以及第四范式核心产品『先知』机器学习平台的研发工作。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;涂威威 第四范式数据建模专家&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;在大规模分布式机器学习系统架构、大规模机器学习算法设计和应用、在线营销系统方面有深厚积累。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;百度最高奖 trinity 发起人之一。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;首次将 FPGA 应用于在线营销深度学习预估系统。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;设计开发百度机器学习计算框架 ELF。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;活动预告&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;12 月 3 日，机器之心将联合第四范式举办主题为「人工智能在工业应用上的技术突破和研究方向」的线下分享活动。第四范式的联合创始人陈雨强也将带来相关主题的分享，我们也将邀请知名人工智能专家共同研讨如何将机器学习用于互联网业务的提升以及机器学习未来在互联网场景中的应用与发展趋势等话题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;陈雨强个人简介&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;陈雨强，第四范式联合创始人，首席研究科学家，世界级深度学习、迁移学习专家。曾在多个国际顶级人工智能会议发表论文，其工作被全球著名科技杂志 MIT Technology Review 报道。陈雨强主持架构了世界上第一个商用深度学习系统「百度凤巢系统」，大幅提升了广告点击率并使变现能力；主持架构了中国用户量最多的新媒体人工智能推荐系统「今日头条」，以支持千亿特征、千亿数据的流式机器学习系统，实现今日头条新闻推荐的个性化、准确性与时效性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;参与人群：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;人工智能行业从业人员&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;互联网行业从业者&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;投资人&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;活动时间：2016 年 12 月 3 日 14：00-17：00&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;活动地点：北京市朝阳区酒仙桥电子城科技园 A2 楼一层 机器之心&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;点击阅读原文报名此次活动↓↓↓&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 17 Nov 2016 10:16:24 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 谷歌推出A.I. Experiments：让任何人都可以轻松实验人工智能</title>
      <link>http://www.iwgc.cn/link/3537505</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自AI Experients&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;iframe class="video_iframe" data-vidtype="2" style="   z-index:1; " height="375" width="500" frameborder="0" data-src="https://v.qq.com/iframe/preview.html?vid=a1310qakyx9&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0" allowfullscreen=""&gt;&lt;/iframe&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能正在飞速发展，但很多没有技&lt;/span&gt;&lt;span&gt;术背景但想试试机器学习的风采的人却没办法进入这一领域。作为人工智能和深度学习研究和应用的领军者，谷歌也正在尝试解决这个问题，从而让更多人能够了解和使用人工智能——不管你是有技术背景的工程师和爱好者，还是刚入门的学生，更或是仅仅对此感到好奇的吃瓜群众。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为此，谷歌创建了一个名叫人工智能实验（A.I. Experiments）的网站。该网站在线显示了一些简单的人工智能实验，让任何人只需一台联网的计算机就能轻松上手，甚至可以创建你自己的实验。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWic45jgIOq2OCuFlIgqdSFLkEJv7uM5xsFJia2y0tibAGCOZO3ROtx1iatMEBIuHaDoCRRmBdBETziaTnQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;A.I. Experiments 网址：http://aiexperiments.withgoogle.com/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该网站上的实验展示了机器学习理解各种事物（包括图像、绘画、语言、声音等等）的方式。这些项目是由各种各样背景的人创建的，他们有的是开发者、有的是音乐家、有的是游戏设计师，还有鸟鸣爱好者、数据可视化工作者……任何人都可以将他们自己的想法和机器学习结合起来进行实验！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这里列举两个可以在线试玩的项目：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Giorgio Cam：基于照片生成音乐&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Bird Sounds：使用机器学习可视化数千种鸟叫声&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谷歌在其开发者博客上表示：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们也希望能让开发者能够更轻松地进行他们自己的实验。我们给出的许多项目都是用任何人都能使用的工具开发的，比如 Cloud Vision API、Tensorflow 和其它来自机器学习社区的库。这个网站有创造者解释它们的工作方式的视频，并且还链接到了对应的开源代码让你能够快速开始。你也可在 A.I. Experiments 提交你自己的作品，或者把玩别人做出的东西。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在最后，谷歌还推荐了 Google Arts &amp;amp; Culture 团队的一些作品，戳这里：http://artsexperiments.withgoogle.com/，希望能够为你带来一些使用机器学习的灵感。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译文章，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 17 Nov 2016 10:16:24 +0800</pubDate>
    </item>
    <item>
      <title>独家专访 | 腾讯AI Lab公布首项研究：提出独特神经网络实现实时视频风格变换</title>
      <link>http://www.iwgc.cn/link/3522584</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心原创&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：老红、李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;em style="color: rgb(136, 136, 136); line-height: 1.75em; text-align: justify;"&gt;&lt;span&gt;风格变换一直是机器学习领域内的一项重要任务，很多研究机构和研究者都在努力打造速度更快、计算成本更低的风格变换机器学习系统，比如《&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719733&amp;amp;idx=3&amp;amp;sn=950a7adb4e93bca22e4ef975877482a9&amp;amp;chksm=871b018bb06c889ddc87bccaa0f35de5ca5a35c156cf1164d134d5010065d68dd06ba6e7cdfa&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719733&amp;amp;idx=3&amp;amp;sn=950a7adb4e93bca22e4ef975877482a9&amp;amp;chksm=871b018bb06c889ddc87bccaa0f35de5ca5a35c156cf1164d134d5010065d68dd06ba6e7cdfa&amp;amp;scene=21#wechat_redirect"&gt;怎么让你的照片带上艺术大师风格？李飞飞团队开源快速神经网络风格迁移代码&lt;/a&gt;》、《&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720113&amp;amp;idx=1&amp;amp;sn=b45bd28cef19a06c717717d3622d58de&amp;amp;chksm=871b030fb06c8a199334d745ad1be56b6b7aeb364596743be7215cc7c6a15a23053c8b60639f&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720113&amp;amp;idx=1&amp;amp;sn=b45bd28cef19a06c717717d3622d58de&amp;amp;chksm=871b030fb06c8a199334d745ad1be56b6b7aeb364596743be7215cc7c6a15a23053c8b60639f&amp;amp;scene=21#wechat_redirect"&gt;谷歌增强型风格迁移新算法：实现基于单个网络的多种风格实时迁移&lt;/a&gt;》。如今新成立的腾讯 AI Lab 也加入了此行列，在此文章中机器之心对腾讯 AI Lab 的视频风格变换的研究进行了独家报道。&lt;/span&gt;&lt;/em&gt;&lt;br/&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9xhznsLIp5sSbIiayEITWLFYNwvfZQmkM7jXypFBNfqVHdEqJeOPYKGLSsmw432bj0xoSm4OhJm6Q/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;几天前，Facebook 在其官方博客上宣布了一种可以用在移动设备实现实时风格的深度学习系统 Caffe2Go，称能在眨眼之间完成处理的任务，而且还能实现高质量的视频风格变换。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而鲜为人知的是，腾讯新成立的人工智能研究部门腾讯 AI Lab 也在做这方面的研究，技术团队告诉我们腾讯 AI Lab 早在 9 月中就已经研发出了实时的视频风格变换技术，并用此技术对一些电影进行了风格变化，制作了非常酷炫的艺术人工智能电影，在腾讯内部已经有过展示。腾讯 AI Lab 的研究表示，他们已通过首创深度网络学习视频的时空一致性，在很大程度上提高了视频风格变换的质量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;iframe class="video_iframe" data-vidtype="1" style="   z-index:1; " height="375" width="500" frameborder="0" data-src="https://v.qq.com/iframe/preview.html?width=500&amp;amp;height=375&amp;amp;auto=0&amp;amp;vid=w03451hmwnf" allowfullscreen=""&gt;&lt;/iframe&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;近日，机器之心对腾讯 AI Lab 的研究团队进行了独家专访，这也是腾讯 AI Lab 研究团队首次对外发声。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;风格变换简史&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;将一张图像的风格变换成另一种风格的技术已经存在了近 15 年。2001 年，当时加州大学伯克利分校的 Alexei A. Efros 联合另外一位作者在论文《Image Quilting for Texture Synthesis and Transfer》中介绍了一种简单的基于纹理合成的方法，通过「缝合」已有的小型图像块合成新的图像外貌。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但利用神经网络来做这件事是最近才出现的。在论文《A Neural Algorithm of Artistic Style》中，研究者 Gatys、Ecker 和 Bethge 介绍了一种使用深度卷积神经网络（CNN）的方法。他们的风格转换图像是通过优化（optimization）得到的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一方面，CNN 的高层特征描述了图像的主要的结构化信息。另一方面，基于 CNN 每一层的特征计算得到的 Gram matrix 又可以很好的捕捉图像的风格信息（笔触以及纹理等）。结合这两种信息定义损失函数，指导图像从某个起始点（如：随机噪声或内容图像本身）开始，不断迭代优化，逐渐转变为风格变换后的图像&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8DLuIlocGmG4BCQ8jCHJbeRTowcsFpCfs2Vnx0YUfj3aELV4rTu6mWbQEkS21RbLcNVqbpvicL3ibg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;内容+风格=另一种风格图像（图片来自：Google Reserch）&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该成果被认为是深度学习研究领域的一项突破，因为它首次提供了基于神经网络的风格变换的概念证明。不幸的是，这种为单张图像施加风格的方法对计算要求很高。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不过到了 2016 年，俄罗斯的 Dmitry Ulyanov [1] 等人以及斯坦福李飞飞团队 [2] 的研究都大大加速了这一过程。这些研究认识到可以将这个优化问题转变成图像变换问题（image transformation problem），也就是将单个固定的风格应用到任意一张内容图像（比如一张照片）上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然后该问题就可以这样被解决：训练一个前馈深度卷积神经网络来改变内容图像的语料库（corpus），从而使之匹配某画作的风格。这个训练出的网络有两重目的：保持原有图像的内容，同时匹配绘画的视觉风格。这样得到的最终结果是：以前花几分钟的图像风格转换现在通过前馈网络可以实时得到，进而应用于实时视频风格变换。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;风格变换技术如何由图像扩展到视频？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;视频是未来互联网上最多的流量载体。在图像风格变换引起爆发性关注之后，一系列的公司，譬如 Aristo，Prisma, Philm 等都开始聚焦短视频的风格变换，包括对人工智能一向深切关注的 Facebook 也将推出视频风格变换技术（智能手机移动端）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;将风格变换技术由图像向视频拓展最为直接的方式就是使用图像风格变换的技术逐帧完成视频的变换，但是这样很难保证视频帧间风格的一致性。为此 Ruder 等人提出了一种迭代式的做法 [3]，通过两帧像素之间的对应关系信息来约束视频的风格变换。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是，这种方法在生成风格化视频的时候复杂度很高，耗时很长。因此，如何构建有效的深度学习模型来学习视频的空间域以及时间域的特性以完成视频风格变换是学术界以及工业界一个重要的研究课题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为解决这种问题，这个深度学习模型需要：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="list-style-type: decimal;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;在空间域上可以将名画元素有效的提取出来并学习应用；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;在时间域上保持变换风格的时间一致性（temporal consistency）；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;保证计算的高效性以支持更多的实际应用场景。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这也是包括 Facebook 和斯坦福大学等业界领先的研究团队比较关注的研究课题。但是迄今，业界的研究团队仍然没有很好的深度学习模型和高效率（如实时）的解决方案。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;前向网络（Jonson et al.）主要应用于图像上。迭代式（Ruder et al.）的方法来处理视频的风格变换考虑了时间域的一致性，但是处理速度非常慢，处理一帧视频大约需要 3 分钟。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;斯坦福大学的 Justin Johnson（使用前向网络完成图像风格变换的作者 [2]）也谈到「将前向网络与基于光流的时间一致性结合是一个开放性的课题」，他本人认为这种结合是可能的，但是不清楚业界是否有人已经实现，而且也不太确定这种结合的正确方式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;针对视频风格变换的技术难点，腾讯 AI Lab 在业界率先构建了深度神经网络，将风格变换的前向网络与视频时空一致性结合起来，高效地完成高质量的视频风格变换。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先，腾讯 AI Lab 设计了独特的深度神经网络，该网络结合了最新的卷积层以及残差层，能够对图像和视频学习有效的表示。在训练的过程中使用大规模、多场景、多特点的视频数据（数千小时）以及相应的风格图像，一方面学习空间域的风格变换特点（在保持原有视频内容的基础上引入给定图像的风格），另一个方面捕捉视频帧之间极其复杂多变的时域特性，使得产生的风格视频相邻帧之间的时空内容与风格一致。因为是针对视频数据，定义的损失函数（Loss Function）也比做图像数据的损失函数更复杂。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;更重要的是，腾讯 AI Lab 还提出了一种针对视频数据的独特训练过程，使得他们的深度神经网络能够更好地捕捉视频时间域上的一致性信息。在风格视频生成阶段，不用做任何预处理和后处理，将输入视频在风格变换网络上进行一次前向传播，实时输出风格化的视频。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不仅如此，为了满足线上需要，腾讯 AI Lab 也挖掘了模型的深度、宽度对输出质量的影响，并基于此对模型进行压缩且输出质量没有肉眼可见损失。「我们有不同的网络模型精简策略和模型压缩算法。压缩后的模型小于 1M」。做此研究的人员说，「这里谈到的模型精简和压缩，是针对深度网络的精简以及相关的压缩策略。压缩会精简深度模型的操作并降低运算的复杂度，但是产生的图像/视频的质量（相比未压缩）不会显著性降低。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从图像的风格变换到视频的风格变化，数据量的增长是巨大的。在解决数据增长的问题上，研究人员在构建算法的时候考虑到了不同的解决方案。在云端处理时，可以通过并行化的操作来快速完成视频风格生成。在终端处理时，通过网络的精简和压缩，使得在终端上能够实时完成视频的风格变换。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，经过上述优化后的深度模型，可以在手机客户端做到针对摄像头数据的实时处理，将用户拍摄的视频画面实时进行风格变换。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除此之外，腾讯 AI Lab 内部也关注了谷歌的多种风格融合的图像风格变化工作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「整体来说，谷歌发现了不同风格的变换网络的参数之间的关系，因此使用一个基础网络以及另外一个参数变换表格来融合生成多种风格的网络。」腾讯 AI Lab 也正在研究如何将这一技术拓展到视频领域。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;手机客户端实时视频风格变换在产品上的应用&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;立足于腾讯的大数据与平台，AI Lab 作为腾讯新成立的研究部门也在探索人工智能技术的新应用和新业务，将人工智能技术融入产品，满足腾讯庞大用户的需求。这也和谷歌、Facebook、亚马逊、微软等巨头成立人工智能研究部门、开发新技术、融合新产品与业务的公司策略如出一辙。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;正如前文所言，腾讯 AI Lab 率先在业界探索了使用前向网络实现实时的视频风格变换，这是腾讯 AI Lab 在将人工智能技术与腾讯用户需求相结合的尝试。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「这使我们有理由相信更多的人工智能技术也能够应用到各类场景下的数据上面（图像/视频，文本，语音等）。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;类似之前朋友圈爆红的一款图像产品 Prisma，我们了解到腾讯 AI Lab 开发的图像滤镜技术已经在天天 P 图的 P 图实验室上线，产品名称是「潮爆艺术画」。目前他们们已经开发了上百款图像滤镜，会陆续在「潮爆艺术画」里登场。而对于视频风格变换技术，腾讯也有了一些产品上的计划。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;参考文献：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[1]Ulyanov, Dmitry, Vadim Lebedev, Andrea Vedaldi, and Victor Lempitsky. Texture Networks: Feed-forward Synthesis of Textures and Stylized Images (2016).&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[2]J. Johnson, A. Alahi, L. Fei-fei,「Perceptual Losses for Real-Time Style Transfer and Super-Resolution」, ECCV 2016.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[3]Ruder, Manuel, Alexey Dosovitskiy, and Thomas Brox. "Artistic style transfer for videos." arXiv preprint arXiv:1604.08610 (2016).&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心原创，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 16 Nov 2016 09:50:21 +0800</pubDate>
    </item>
    <item>
      <title>重磅 | 谷歌神经机器翻译再突破：实现高质量多语言翻译和zero-shot翻译（附论文）</title>
      <link>http://www.iwgc.cn/link/3522585</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Google Blog&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;9 月底，谷歌在 arXiv.org 上发表了论文《Google`s Neural Machine Translation System: Bridging the Gap between Human and Machine Translation》，介绍了谷歌的神经机器翻译系统（GNMT），该系统实现了机器翻译领域的重大突破，参见报道《&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719470&amp;amp;idx=1&amp;amp;sn=3368dea980517ea7d7942967da2740dc&amp;amp;chksm=871b0090b06c89863620be4e75c757940d03d8a43cd3c1d9a8309b6594c1bccd769cab193177&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719470&amp;amp;idx=1&amp;amp;sn=3368dea980517ea7d7942967da2740dc&amp;amp;chksm=871b0090b06c89863620be4e75c757940d03d8a43cd3c1d9a8309b6594c1bccd769cab193177&amp;amp;scene=21#wechat_redirect"&gt;重磅 | 谷歌翻译整合神经网络：机器翻译实现颠覆性突破&lt;/a&gt;》。昨日，谷歌再发论文宣布了其在多语言机器翻译上的突破：实现了 zero-shot 翻译！&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;昨天，谷歌在其官方博客上宣布其在谷歌翻译（Google Translate）上再次取得重大进展。这家搜索巨头表示现在已经将神经机器翻译（neural machine translation）集成到了其网页版和移动版的翻译应用之中，这意味着它可以一次性翻译一整段句子，而不只是像之前一样只能一个词一个词地翻译。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谷歌在其产品博客中表示，其产品的翻译结果现在变得更加自然，能够实现更好的句法和语法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Google Translate 产品负责人 Barak Turovsky 在谷歌旧金山的一次新闻发布会上说：「这一次的进步超过了过去十年积累的总和。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谷歌已经将自己的未来定义成了一家人工智能和机器学习公司——使用这些技术的计算机无需特定的编程就能自己学习执行任务。谷歌云部门（cloud division）的负责人 Diane Greene 总结说：「谷歌要将机器学习集成到每一种形式中，并将它带给这个世界。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谷歌在其博客中写道：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;今天我们宣布将神经机器翻译集成到了总共八种语言的相互翻译中，它们是：英语、法语、德语、西班牙语、葡萄牙语、汉语、日语、韩语和土耳其语。这些语言的母语总人口占到了世界总人口的三分之一，覆盖了谷歌翻译 35% 以上的请求。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;通过这一次更新，谷歌翻译一次性提升的性能超过了过去十年进步的总和。但这只是一个开始。尽管我们目前在谷歌搜索、谷歌翻译应用和网站上只有 8 种语言，但我们的目标是将神经机器翻译扩展到所有 103 种语言，并让你能随时随地都能接入到谷歌翻译。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除此之外，谷歌今天还宣布了提供机器学习 API 的公共云服务 Google Cloud Platform，「能让任何人都轻松地使用我们的机器学习技术」。今天，Google Cloud Platform 也使神经机器翻译背后的系统向谷歌的企业用户开放了——谷歌提供了 Cloud Translation API：https://cloud.google.com/translate/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;论文：谷歌的多语言神经机器翻译系统：实现 zero-shot 翻译（Google's Multilingual Neural Machine Translation System: Enabling Zero-Shot Translation）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9xhznsLIp5sSbIiayEITWLFHQTtiaZenO3xHgE4XgkKBPuDTzU1icn0yNhsWeOzCcmVOlfY39lX1zwQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们提出了一种使用单个神经机器翻译（NMT）模型在多种语言之间进行翻译的简洁优雅的解决方案。我们的解决方案不需要对我们的基础系统的模型架构进行修改，而是在输入句子的一开始引入了一个人工 token 来确定所需的目标语言（required target language）。模型的其它部分（包含了编码器、解码器和注意（attention））保持不变，而且可以在所有语言上共享使用。使用一个共享的词块词汇集（wordpiece vocabulary），我们方法能够使用单个模型实现多语言神经机器翻译（Multilingual NMT），而不需要增加参数，这比之前提出的 Multilingual NMT 方法简单多了。我们的方法往往能提升所有相关语言对的翻译质量，同时还能保持总的模型参数恒定。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 WMT' 14 基准上，单个多语言模型在英语→法语翻译上实现了与当前最佳表现媲美的结果，并在英语→德语翻译上实现了超越当前最佳表现的结果。类似地，单个多语言模型分别在 WMT'14 和 WMT'15 基准上实现了超越当前最佳表现的法语→英语和德语→英语翻译结果。在用于生产的语料库上，多达 12 个语言对的多语言模型能够实现比许多单独的语言对更好的表现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除了提升该模型训练所用的语言对的翻译质量之外，我们的模型还能执行在训练过程中没有明确遇见过的语言对之间的特定桥接（bridging），这表明用于神经翻译的迁移学习（transfer learning）和 zero-shot 翻译是可能的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，我们展示了对我们模型中的通用语言间表征（universal interlingua representation）的迹象的分析，还展示了一些将语言进行混合时的有趣案例。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9xhznsLIp5sSbIiayEITWLFMibJQia0bkqNZ1f9TNyhTQRs8OJJZkKlLHECvagl20DafAAsE4lJ5RhA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 1：该 Multilingual GNMT 系统的模型架构。除了论文《Google's neural machine translation system: Bridging the gap between human and machine translation》中描述的，我们的输入还有一个人工 token 来指示所需的目标语言。在这个例子中，token &amp;lt;2es&amp;gt; 表示目标句子是西班牙语的，而其源句子被逆向为一个处理步骤（processing step）。对于我们大部分的实验而言，我们还使用了编码器和解码器之间的直接连接，尽管我们后来发现这些连接的影响是可以忽略不计的（但是一旦你使用这些进行训练，它们也必须为了推理而存在）。该模型架构的其它部分与上述论文中的一样。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 16 Nov 2016 09:50:21 +0800</pubDate>
    </item>
    <item>
      <title>MXNet专栏 | 李沐：为什么强大的MXNet一直火不起来？</title>
      <link>http://www.iwgc.cn/link/3522586</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心授权转载&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：李沐&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;在机器之心今年 8 月份发布的文章《&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718160&amp;amp;idx=3&amp;amp;sn=a2114e3324f28740d2603da26fbbdfb4&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718160&amp;amp;idx=3&amp;amp;sn=a2114e3324f28740d2603da26fbbdfb4&amp;amp;scene=21#wechat_redirect"&gt;业界 | 五大主流深度学习框架比较分析：MXNET 是最好选择&lt;/a&gt;》中，微软数据科学家 Anusua Trivedi 对主流深度学习框架进行了比较分析。Trivedi 对 CNTK，MXNet，TensorFlow，Theano，Caffe 这 5 个框架进行对比之后，得出 MXNET 是最好的选择。但即使如此，TensorFlow、Torch 等框架的声音却「大」过了 MXNet。近日，MXNet 的打造者之一李沐在知乎上回答了「为什么强大的 MXNet 一直火不起来？」。本文为机器之心经授权转载文章，如若转载请联系作者获得授权。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;更多关于 MXNet 专栏系列的文章，可查看：&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719529&amp;amp;idx=3&amp;amp;sn=6992a6067c79349583762cb28eecda89&amp;amp;chksm=871b0157b06c8841587bdfb992c19290c8d66386a6f8accdf70998ce3f86b36330219c09672d&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719529&amp;amp;idx=3&amp;amp;sn=6992a6067c79349583762cb28eecda89&amp;amp;chksm=871b0157b06c8841587bdfb992c19290c8d66386a6f8accdf70998ce3f86b36330219c09672d&amp;amp;scene=21#wechat_redirect"&gt;MXNet专栏 | 陈天奇：NNVM打造模块化深度学习系统&lt;/a&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;简单来说就是我们没有足够的人手能够在短时间内同时技术上做出足够的深度而且大规模推广，所以我们前期是舍推广保技术。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;详细来说我稍微发散下，可以把当下的深度学习（DL）比作修真世界（传统武侠也类似）。学术界是各个门派，公司是世家，不过这个世界里世家比较强势。目前是盛世，各个流派之争，新人和技术层出不穷，各大擂台（例如 imagenet）和大会（据说今年 nips 8k 人参加，一个月前就把票卖光了）热火朝天。平台作为修真练级法宝，自然也是各家 PK 重要之地。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;各个平台是怎么「火」起来的&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;简单的来吧 DL 分三个阶段来看，前 DL 时代就是 Alexnet 没有刷出 imagenet 第一的时候，当时候主流算是 torch 和 theano，从上一个神经网络的时代的两大修正大门流传下来，还是有坚实的用户基础。之后魔界（kernel）入侵，神经网络衰败。但 10 年后 Alexnet 横空出世，借着大数据和 GPU 的重剑无锋，横扫三界。同时也促使了很多新的平台的出现，caffe 是之一，很多公司也有做自己的，例如百度的 paddle，G 的 distbelief，我们也有做一个类似的项目叫 cxxnet。大体上这些平台使用体验差不多，给一个 configure 就能跑。这里面 caffe 是最成功，我觉得重要两点是时间点很好，就是 dl 在 cv 爆发的那段时间，然后 caffe 有在 imagenet pretrain 的模型，这个很方便大家的研究。毕竟大部分工作要么是改改 operator 重新跑一下，要么是基于 pretrained 的模型来 finetune 一个别的任务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;之后出来的比较成功的平台主要是靠提供更加灵活的开发环境来吸引新人。例如 tensorflow 和 keras。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;tf 作为当下修真界最大门的平台，成功没有什么意外（1）G brain 在这个领域上耕耘了 5，6 年，做为第二代产品在质量确实很优秀。（2）在 jeff dean 的号召下 brain 网罗了一大帮人，跟他们团队接触过很多次，整体人员质量甩出其他家很远，以至于经常是好几个我觉得能独当一面的大牛一起在做一些很小的事情。例如我在 cmu 系统方向的老板 dave 在 brain 好长一段时间就是 debug 为什么 inception v3 从 distbelief 移植到 tf 老是跑不出想要的精度。（另，类似的坑我们也踩过，我还笑过 dave 你如果问我们一下可以省下你大笔时间，dave 回我们人多任性不求人。）（3）G 的宣传机器如果称第二，那业界估计没人敢说第一。这次 G 不遗余力的宣传 tf，连带推动了整个 DL 的火热。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;keras 比较有意思，基本是 François Chollet 一人之力做的，有点是散修自己折腾出来的（他人现在在 G，不过他去 G 之前就开始 keras 了）。它的优势就是简单，底层靠 theano 或者 tensorflow，上层提供一个非常简单的接口，非常适合新用户使用。修真界新人练气的不二法宝。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;MXNet 现状&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;mxnetet 是散修小团体一起合力做出来的平台。如果去看排名前 20 的开发者，基本都是出自不同的门派和世家。这个是 mxnet 最大的特色。我对此表示很自豪，这里汇聚了一大帮跑得出实验写得出代码的小伙伴。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不论是开始时间还是平台特性，mxnet 最靠近 tensorflow。有完整的多语言前端，后端类似编译器，做这种内存和执行优化。应用场景从分布式训练到移动端部署都覆盖。整个系统全部模块化，有极小的编译依赖，非常适合快速开发。相对于 tf 这种重量型的后端，mxnet 的轻量化路线使得可以我们在花费 G brain 1/10 的人力的情况下做到类似 tf 技术深度的系统。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从推广的角度来说，需要的是清晰的文档，大量的样例，媒体曝光，和客服。这个对于散修团体而说前期比较困难。不过最近也慢慢赶上了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;根据 keras 作者的平台排名，目前 mxnet 属于第四，前三分别是 tf，caffe，keras。因为 dl 也是刚兴起不久，目前的用户可能一大半是刚入门不久，选择 tf/keras 很符合情理。对于学术界而言，通常性能不是很关键，最重要是开发成本，如果前面的工作用了 caffe/torch，那基本会一直用下去。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们也回访过我们用户，很多都是工业界用户，基本都是属于有很强的技术能力，他们关心性能，开发和移植的便利性，和是不是能在开发社区里获得一定的话语权。事实上，mxnet 离人也很近，例如&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;某占有率很高手机利用 mx 处理图片&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;好几个常见的 app 云端利用 mx 处理数据&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;aws/azure 都写了好几篇 blog 普及在云上面运行 mxnet&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;国内几个技术能力很强的 ai 创业公司内部用 mx&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;整体而言，不管是 dl 技术，应用，还是平台，目前说什么都尚早。技术和潮流都是日新月异，修仙之路也刚开始。我觉得最核心的是，有一群有最求的人，一起合力做一件事情，不断往前。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;PS. 我在考虑要不要写一个关于 DL/ML 的修仙系列。例如「魔界小王子，誉为最有希望带领魔界重杀回来领袖的叛逃心路历程」，「我跟修真界第一门掌门的故事」，「如何利用入门道具组装小型阵法加速修炼」，「解析为什么大门长老屡屡逃奔世家」。。。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©机器之心经授权转载，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系作者获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 16 Nov 2016 09:50:21 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 李飞飞加入谷歌，负责云机器学习</title>
      <link>http://www.iwgc.cn/link/3522587</link>
      <description>&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自财富&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李泽南&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谷歌正将其云计算业务增加更多的人工智能成分。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这家搜索巨头在周二刚刚宣布其雇佣了两位人工智能领域的顶级研究者，这是 Google Cloud 业务改组的一部分。机器学习是人工智能的重要部分，通常指训练计算机在大量数据中学习概念。这两位谷歌新人是斯坦福大学人工智能实验室主任李飞飞，和前 Snapchat 研究主管李佳，这两位华裔女科学家是计算机视觉行业的专家。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谷歌的云业务负责人 Diane Greene 在本周二于旧金山举行的新闻发布会上说，两位新员工是谷歌正式将人工智能集团业务正式化的一部分。该团队不会只专注于人工智能研究，而是致力于将尖端技术融入各种 Google Cloud 产品，例如让公司预测销售情况的软件。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Greene 表示这两位新雇员是人工智能热点领域「世界领先的研究科学家，从业人员和领导者」像谷歌、Facebook 和 IBM 这样的科技巨头目前正在人工智能行业投资数百万美元进行相关技术的研发，深度学习是其中的重点。这些技术使计算机可以更快地处理大数据任务，如将文本翻译成多种语言。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最令人兴奋的是，这两位专家均为女性，人工智能行业过去一直因在大学和大公司缺乏女性领导角色而受到批评。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在今年夏天彭博的一篇文章中，李飞飞评论了人工智能领域界女性数量的问题，她说：「如果你是一台电脑，搜索所有的人工智能文献并查看作者，你会看到很少有女性的名字。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;李飞飞是 ImageNet 的创建者之一，这是一个巨大的、手动标注的图形数据集，为图像识别领域的研究奠定了基础。在 ImageNet 上，斯坦福大学每年都会邀请全世界图像识别研究者前来比赛，让计算机识别图片中的物体，这一数据集曾深刻改变了图像识别 领域的研究方向。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谷歌在发布会上称，李佳将在感恩节假期后开始在谷歌的工作，李飞飞则将于 2017 年初进入谷歌的研究部门。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Google Cloud 及其机器学习团队的产品经理 Rob Craft 表示，这两名研究者将帮助谷歌「将机器学习的力量带入其他行业」。他表示，新员工是谷歌整合其研究单位及核心业务努力的一部分。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;雇用具有机器学习和相关任务专业知识的人才并不便宜。这一行业内的激烈竞争导致谷歌这样的大公司经常会支付「NFL 球员签字费」级别的巨额资金，目前，谷歌仍未公开这两人的合同金额。人才竞争的很大一部分原因在于目前人工智能领域的研究者数量有限，无法满足行业需求。「大学输出的博士生数量不足。」Craft 说道。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 16 Nov 2016 09:50:21 +0800</pubDate>
    </item>
    <item>
      <title>报名 | 想和机器之心小伙伴来场考试吗？「人工智能研学社·入门班」招募</title>
      <link>http://www.iwgc.cn/link/3522588</link>
      <description>&lt;p&gt;&lt;span&gt;人工智能正在我们人类的生活中发挥越来越重要的价值——它们正在接管我们的工作、帮助我们更高效更安全地生产、甚至改变我们生存与存在的方式。对我们来说，理解这种前所未有的改变非常重要：人工智能是什么？将发挥什么作用？未来又将走向何方？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但缺乏技术背景的同学在学习过程中经常遇到如下问题：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="width: 528.188px; line-height: 25.6px; white-space: normal;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;找不到合适的学习资料。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;有学习动力，但无法坚持。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;学习效果无法评估。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;遇到问题缺乏讨论和解答的途径。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;没有系统性的学习方法和知识框架。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;对基本概念理解不准确。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因此，机器之心发起了「人工智能研学社·入门班」，通过优质资料分享、阅读研习、群组讨论、专家答疑、讲座与分享等形式加强对人工智能的理解和认知。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;人工智能研学社·入门班&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="width: 528.188px; line-height: 25.6px; white-space: normal;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;面向人群：非技术背景的人工智能爱好者和处于入门阶段的学习者。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;学习形式：学习资料推荐、统一进度学习、群组讨论、读书会、专家答疑、讲座等。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首次学习活动&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;阅读 M.I.Jordan 在 Science 的经典论文《Machine learning: Trends, perspectives, and prospects 》（点击阅读原文下载），特别适合入门者系统学习机器学习。为提升学习效果，机器之心将于本周六举办一次考试，除机器之心成员，拟邀请 10-20 位外部小伙伴参与。欢迎入群报名。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;答题语言：英语/中文&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;考题类型：名词解释、简答、图表、翻译&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;考试时间：本周六（11 月 19 日）下午 2 点&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;考试地点：酒仙桥东路电子城科技园 A2 一层 机器之心办公室&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;考试费用：免费&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;参与本次考试的小伙伴将获得：1）百度语音开放三周年庆门票；2）机器之心其他活动的优先参与权；3）机器之心周边。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;请添加微信 JuveAlex、zhaoyunfeng1984 、p_NizXdr 申请入群，入群时请提交以下资料：1）教育背景；2）从事行业和职务；3）人工智能学习经历。&lt;/span&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 16 Nov 2016 09:50:21 +0800</pubDate>
    </item>
  </channel>
</rss>
