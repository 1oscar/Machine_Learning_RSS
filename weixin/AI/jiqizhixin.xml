<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>机器之心</title>
    <link>http://www.iwgc.cn/list/670</link>
    <description>人与科技的美好关系</description>
    <item>
      <title>重磅 | Facebook贾扬清宣布新机器学习系统Caffe2Go：可在移动设备上实现实时风格迁移</title>
      <link>http://www.iwgc.cn/link/3428796</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Facebook Code&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：贾扬清、Peter Vajda&amp;nbsp;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李泽南、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;风格迁移一直是机器学习领域内的一项重要任务，很多研究机构和研究者都在努力打造速度更快、计算成本更低的风格迁移机器学习系统，比如《怎&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719733&amp;amp;idx=3&amp;amp;sn=950a7adb4e93bca22e4ef975877482a9&amp;amp;chksm=871b018bb06c889ddc87bccaa0f35de5ca5a35c156cf1164d134d5010065d68dd06ba6e7cdfa&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719733&amp;amp;idx=3&amp;amp;sn=950a7adb4e93bca22e4ef975877482a9&amp;amp;chksm=871b018bb06c889ddc87bccaa0f35de5ca5a35c156cf1164d134d5010065d68dd06ba6e7cdfa&amp;amp;scene=21#wechat_redirect"&gt;么让你的照片带上艺术大师风格？李飞飞团队开源快速神经网络风格迁移代码 &lt;/a&gt;》、《&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720113&amp;amp;idx=1&amp;amp;sn=b45bd28cef19a06c717717d3622d58de&amp;amp;chksm=871b030fb06c8a199334d745ad1be56b6b7aeb364596743be7215cc7c6a15a23053c8b60639f&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720113&amp;amp;idx=1&amp;amp;sn=b45bd28cef19a06c717717d3622d58de&amp;amp;chksm=871b030fb06c8a199334d745ad1be56b6b7aeb364596743be7215cc7c6a15a23053c8b60639f&amp;amp;scene=21#wechat_redirect"&gt;谷歌增强型风格迁移新算法：实现基于单个网络的多种风格实时迁移&lt;/a&gt; 》。今天，Facebook 又在其官方博客上宣布了一种可以用在移动设备实现实时风格的深度学习系统 Caffe2Go，自称能在眨眼之间完成处理的任务，而且还能实现高质量的视频风格迁移。Facebook 还表示该项目将会在未来几个月内进行部分开源。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;随着视频通话逐渐成为人们交流的主要方式，Facebook 希望创造最新的视频创意工具来帮助人们表达自我。最近，他们在手机 app 中测试了新的相机应用，实时在视频中添加艺术元素。这项技术被称为「风格转换」。它可以将一张图片中的艺术风格，例如梵高的画作，加入普通的图片或视频中去。这是以往技术上难以实现的事，通常这需要将参考图和要处理的数据发送到数据中心，通过大型服务器进行处理。Facebook 最新开发的移动端深度学习平台第一次摆脱了信号塔的束缚，可以实时捕捉、分析和处理图像，将最新技术放进人们的手中。这一新程序被称为 Caffe2Go，是一个完整的深度学习系统，它的架构已经嵌入手机 app 中。通过将处理图片和视频的人工智能模型压缩至百分之一大小，Facebook 现在已经可以在 iOS 和安卓系统中高效运行深度学习网络。最终，Facebook 公司的应用可以在部分手机中以不到 50 毫秒的速度完成人工智能任务的处理，而人眨眼需要的时间大约需要 300 毫秒。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相机风格转换工具是两种技术的结合：Caffe2Go 运行环境与风格转换模型。Facebook 的人工智能团队一直在处理算法与大规模系统，他们一直在致力于开发新模型，让风格转换更加快速稳定。于是，现在你拿起手机，开始摄像，梵高的绘画风格变得无处不在了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Caffe2Go 项目在三个月前开始，目前没有其他公司的产品能够做到这样的效果：让人工智能风格转换变成创作工具。不仅如此，Facebook 做到了更多，他们让这种应用可以在手机中实时处理图像。该项目的研究者跨越产品、技术和研究者。FAIR 团队的 Justin Johnson 是一篇描述该项目技术基础论文（Perceptual Losses for Real-Time Style Transfer and Super-Resolution (https://arxiv.org/abs/1603.08155)）的作者，他们在前人的努力基础之上开发了新的技术；应用机器学习团队则通过努力将 AI 引擎塞进手机设备中；相机团队负责满足用户需求；正是因为所有人的努力，这些团队构建了运行在移动设备上的高效神经网络。我们将解释如何思考和开发这一应用技术的，从 Caffe2Go 开始。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Caffe2Go&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;轻量快速&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能对计算机科学产生了深远的影响，但它的应用一直被局限在大型数据中心里，距离普通用户存在很长一段距离。大多数时候，人工智能「实时处理」应用将数据发送到远端数据中心，通过那里的 GPU 来处理，物理距离造成了不可避免的延迟。我们认为使用超级计算机进行实时处理是不实际的，于是我们转换思路，努力让人工智能在移动设备的 CPU 中运行。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWicBG77tp9SKiarHJ2pM2xSVRFzrf9IxLuhRIyBh3WSekv0WDp13rxgbdicXco4icLjAIqmHPLyNjFiaWQ/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;没人想拖着一台超级计算机出门&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;手机可以拍照，通话，也可以实时理解用户所需，不需要连接远端服务器，但它们的性能有限。尽管近年来硬件设备的发展让移动设备的计算能力有了很大改进，手机 CPU 现在已经可以在一秒钟内进行数十亿次运算，但智能软件在设计中还要面对诸如功率，存储器和计算能力的各种资源限制。因此，移动设备环境对机器学习系统提出了机遇和挑战。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;面对这些挑战，我们的解决方案是设计超轻量级模块化框架。为此，我们以开源的 Caffe2 项目为基础，遵循 Unix 理念开发了 Caffe2Go。我们确保了用于声明和连接组件的核心架构的轻量化，允许多种组件与其连接——包括对于移动设备的专用优化。我们保留了一个精巧的算法框架，允许工程人员将抽象概念描述成有向无环图（DAG），同时确保没有约束被强加在图中执行节点的输入和输出上。这允许我们的工程团队能够在不同平台上实现和优化模块，同时可以轻松地连接各种模块。当图像实时输入时，通过硬件功能进行自我实例化可以达到最大处理速度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;速度是计算密集型移动应用的关键，特别是对于图像和视频处理而言，框架的轻量级设计允许我们为特定的运算符执行平台进行特定的优化。NNPack 库是其中一个例子，Caffe2 集成在移动运行环境中时，通过使用移动 CPU 中被称为 NEON 的功能，可以显著提高运算速度。在 iOS 设备上，我们也正在着手集成加速功能如 Metal 语言。所有这些都是通过模块化设计完成的，无需改变一般模型定义。因此，算法端和运行环境可以互相依靠，不必担心兼容性的问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;面向开发者&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Caffe2 是我们的第一个产业级深度学习平台，它可以在服务器 CPU、GPU、iOS 和安卓四种平台上运行，使用同一种代码。因为我们的模块化设计，这种架构在不同平台上都使用同一种语言，但对每个平台都有优化。这是一个开发人员不必担心的细节；例如，可以在移动端 NNPack（iOS 和安卓）和服务器 GPU 的 CUDNN 中进行选择。在 Caffe2 中，算法开发者可以专注于算法，无需考虑如何运行卷积。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;快速的部署设计也能使开发者受益。从开发者的角度看，调试移动设备的运行时间可能是一项挑战，因为移动端工具链（toolchain）并不如桌面的和服务器的工具链那么先进。我们通过从硬件上抽象神经网络的数学而解决了这个问题——一个 Caffe2go 中的串行化网络（serialized network）在被应用于移动手机和服务器时可以得到相同的数值输出。其结果是，我们可以将大部分工作（模型训练、性能评估、用户体验研究）移动到服务器环境中进行；当结果看起来不错了之后，就可以实现在移动环境中的一键式部署了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;训练风格迁移模型&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;风格迁移（style transfer）并不是什么新概念。它最早是由研究人员在发表于 2015 年 8 月的一篇题为《A Neural Algorithm for Artistic Style》的论文中引入的。但是，当时这项技术的速度还很慢，而且需要强大的服务器。后面的几个月，研究社区改进了这项技术，将其速度提升了几个数量级，但也还是需要依赖服务器上的大量计算能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Caffe2go 成功使人工智能实现了高速处理，并且可以集成到你手上的移动设备中。但该风格迁移模型仍然还需要优化，这样才能在确保实时体验的同时还能保证得到高质量、高分辨率的图像。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;优化成有效的模型大小&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;传统的风格迁移研究得到的模型（甚至只是前馈变量）是很大（在参数的数量方面）很慢的。我们的目标是创造能够运行新的、更小的、更高效的模型的风格迁移应用——能够在 iPhone 6s 或以上的手机上不掉帧地提供 20 FPS 的高质量视频。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了减小该模型的尺寸，我们应用了 3 种主要的方法：优化了卷积层的数量（这是处理中最耗时间的部分）、优化了每一层的宽度、以及调整了处理过程中的空间分辨率（spatial resolution）。卷积层的数量和宽度是可用于调整处理时间的单独指标——即调整图像有哪些方面需要处理，或调整一个单独的处理过程需要多少时间。对于空间分辨率，我们可以调整中间层中图像实际被处理的大小。通过较早地使用池化（pooling，缩小正被处理的图像的大小），我们可以加速处理时间，因为系统不再需要处理那么多的数据了。我们还发现，使用这些技术，我们可以极大地减少该网络的宽度和深度，同时还能保持合理的质量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;提升质量&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图像质量是主观的，非常难以测量——尤其是对于风格迁移这样的东西。因此我们打造了一些可视化工具，其中包括 A/B tests；并训练了不同的模型以确保我们可以得到最高质量的图像结果。我们的大型 GPU 集群由 FBLearner Flow 驱动，让我们可以快速扫描大范围的超参数（比如模型架构、内容/风格权重、和下采样），从而找到满足我们的性能目标同时能保持和提升质量的训练良好的前向风格（feedforward style）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在提升质量方面还有很多其它的技巧——比如，应用实例规范化（instance normalizatio）而不是常用的批规范化（batch normalization）能有助于多种风格，同样避免卷积层中的零填充（zero padding）可以减少伪像，也可以将不同的预处理或后处理过滤器应用到风格或内容图像上。但在我们的测试中，我们发现这些方法往往在一些风格上效果良好，在另一些风格上则效果不佳。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;凭借在这项风格迁移技术上的速度和质量优化，使用 Caffe 2 框架，我们就可以将一种实时图像处理系统应用到移动设备上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;展望下一步&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Caffe2go，加上 Torch 这样的研究工具链，是 Facebook 的机器学习产品的核心。因为其在大小、速度和灵活性上的优势，我们正在将 Caffe2go 推广到整个 Facebook 的 stack 中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们还在致力于和社区分享我们的软件和设计，从而让我们可以学习更好地利用多种硬件平台和算法设计的特性，这在跨平台机器学习系统中是尤其重要的。在未来的几个月，我们将会部分开源该人工智能框架。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;随着我们的进步，你可以想象出设备上实时运行的人工智能可以如何帮助世界更加开放、人们更加互连。我们手中的智能设备将继续颠覆我们对「智能（intelligence）」的认知方式。有了像 Caffe2go 这样精巧的机器学习系统，我们将致力于为人们带来更赞的人工智能和增强现实体验——让你在拍视频的时候，设备里还有一把梵高的画刷。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译文章，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 09 Nov 2016 11:22:16 +0800</pubDate>
    </item>
    <item>
      <title>对话 | 关于开源，我们和谷歌开源奖获得者、DMLC成员唐源聊了聊</title>
      <link>http://www.iwgc.cn/link/3428797</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心原创&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;记者：之乎&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;TensorFlow 和 DMLC（分布式深度机器学习社区）这两个开源社区在今天围绕人工智能的计算机行业享有极大声誉。作为这两个开源项目的成员、目前任职 Uptake 数据科学家的唐源（Terry Tang）正在带领团队研发用于多个物联网垂直领域的数据科学引擎；同时，他也是开源软件社区内一位非常活跃的贡献者，是 TensorFlow、XGBoost、MXNet 等软件的 committer, 也是 Scikit Flow、ggfortify、metric-learn 等软件的作者。他曾因自己对开源社区的贡献而获得过谷歌 Open Source Peer Bonus，此外还获得过多项高校和企业编程竞赛的奖项。日前，机器之心对这位开源社区的活跃参与者进行了一次交流。他分享了自己在开源上的人生经历和经验，同时也呼吁大家能够更多地参与到开源项目的发展和建设中来。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;唐源的 GitHub 主页：https://github.com/terrytangyuan&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8g4RL7srjDrnlKGuexhib3lh90c4gY4TGCwOufSjx9trNcrv5oTDSn286KQ49WyMHDeia1xmdfJnPQ/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;唐源&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;关于开源的一些想法&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：你参与过 TensorFlow, XGBoost, MXNet 等软项目，同时也是 Scikit Flow, ggfortify, metric-learn 的作者，可以为大家在其中挑选几个你觉得最喜爱的项目，为大家介绍一下？为什么偏爱这几个项目？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;唐源&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：我对自己参与过的项目都挺喜欢的，从中都学到特别多的东西，也认识了特别多的人。在这里我想简单谈谈我最近在做的 Scikit Flow，也就是现在被放在 TensorFlow.contrib 里面的 TF.Learn 模块，这是一开始我和谷歌的 Illia Polosukhin 一起建立的，现在由于被放在 TensorFlow 里面，谷歌的 TensorFlow 团队开始重视这个模块，也参与了它的发展，这个模块的目的是降低大家使用分布式机器学习和深度学习的门槛，让大家可以像使用 Python 里面的 Scikit-learn 那样很快地建立自己的机器学习和深度学习模型，比如说仅仅几行代码就能使用随机深林、深度神经网络等算法，而且可以很方便地部署到分布式的集群中，从而真正地使用到 TensorFlow 的分布式的优势。这些都是需要对低阶的 TensorFlow API 有深度的理解才能实现的一些功能。数据科学从事者没有必要为了使用最新的算法和技术又花许多时间来学习这些实现的细节，他们可以很快地直接将这些使用在工作和研究中。最近倾向于做这种能够简单易用，统一的界面，像 TensorFlow 这样的软件，有着自己独特的语法和使用方法，这迫使大家花时间学习，我觉得好的东西就应该有简单易用的使用方法。ggfortify 的构建初衷也比较类似，我们当时有太多的重复的代码来一遍又一遍实现同样的功能，比如说给聚类算法的结果用椭圆圈出集群的结果，又比如说对使用不同的 R 包生成的时间序列的分析结果进行可视化。ggfortify 达到的目的就是对比较常用的一些 R 数据分析包的结果进行可视化，避免用户花太多时间学习怎样用 ggplot2 的特殊语法来实现一个常见的可视化。我希望以后这样的软件包越来越多，让研究者和工作者能够不用担心太多实现细节，能够集中精力在他们的主要研究当中，从而在科学和技术上有着更快的实质性突破。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：可以为大家讲讲的你是从什么样的机缘巧合开始成为一位开源社区的积极贡献者吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;唐源&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;： 大四的时候在一家创业公司实习，公司对开源的政策特别开放，我们用到了各种各样的开源软件，用的过程中发现各种问题以及对用户体验度有着各种不满，Github 上面有地方可以提交建议，但是项目的管理者太忙，我就干脆自己对源代码进行研究然后提交修改，这样养成了一种习惯，遇到问题的第一反应是自己研究研究代码，然后直接自己去解决问题，自己独立阅读代码的能力也就这样慢慢培养出来了。很多时候由于对于某个开源软件特别熟悉，经常在做项目中会想到一些有趣的点子来对项目的性能进行改进和功能进行延伸。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：是什么让你对开源社区这么有热情？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;唐源&lt;/strong&gt;：我从参与开源软件这个过程中获得了许多帮助，学到了很多，认识了许多志同道合的人，我也希望通过我的贡献来报答社区对我的帮助。我相信给予越多，获得的回报也越多。一开始因为只是工作需要对经常使用的软件进行各种修修补补，逐渐也养成了一种看源代码的习惯，对软件的架构好奇心也越来越强，老是主动去了解某个功能是如何具体实现的，这个过程让我受益良多。比如说我一开始自学了 Python 的基础，没有任何的项目实战经验，数据科学这一行对各种开源软件需要特别熟悉，因为不可能自己有时间把需要的功能自己实现一遍，通常你需要的功能其实都已经在开源软件里面实现了，然而随着对软件的熟悉，我就开始好奇以及研读具体的实现细节，这也让我打下了很好的对编程以及软件架构的基础，对一个编程语言的了解也逐渐深入了。比较大的开源项目比如说 pandas，有许多开发者在维护以及审阅新的贡献的代码，他们很认真的审阅了我提交的每一行代码，给予了很多很好的改进建议，这让我养成了许多写软件的好习惯。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：你在 Github 上非常活跃，Github 也是现在最流行的开源项目平台，在国外使用已经很普遍，一些学习相关专业地同学甚至都会习惯把学过的课程的作业代码保存在 github 上；但对于国内一些听过开源概念，下载过开源包，却从来没有尝试过参与开源项目的同学来说，还是比较陌生的，甚至他们对于 Git 的 workflow 都不是很了解，可以为这些同学简单讲讲 Github 开源项目的参与流程，以及开源社区的文化吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;唐源&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;： 大部分的开源软件的发展都是在 Github 上完成的，大家需要去自己熟悉和实践一下 Git 的用法，Github 的开源项目里面一般大家都在 issues 里面讨论一的中会想到一些有趣的点子来对项目的性能进行改进和功能进行延伸。大家可以根据自己的兴趣爱好和需求选择自己想贡献的开源项目，fork 这个项目，对项目进行改进和修改，然后提交 pull request 来让项目管理者进行代码审阅。我最先开始参与的开源软件是 Python 的 pandas 库，它有着特别活跃的贡献者社区，也有着特别有耐心有帮助的项目管理者，每个 issue 都会被标上难易程度以及是否欢迎第一次贡献者，这样大家就可以先选择简单的 issue 来下手，开始熟悉这个贡献的流程。我的第一次代码贡献花了一周才被接受，项目管理者特别细心地对我写的每一行代码进行审阅和评论，保证我的改动不会影响现有用户以及要求新的代码必须有新的单元测试。我在这个过程中养成了很多很好的开发习惯也认识了世界各地的朋友，也希望我的这些建议能帮助到大家。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：你一方面在 Uptake 带领团队，另一方面又是开源社区的活跃贡献者，从公司以及社区成员的两个不同的角度看，将项目开源的优势和劣势分别是什么呢？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;唐源&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：在参与这些开源项目的过程中，我深刻地体会到这个社区的活跃度以及创新能力。拿 XGBoost 举个例子，一旦有人在竞赛中使用 XGBoost 取得好的名字，这个项目也就得到大家的认可，更多的人就愿意尝试使用，甚至使用在公司核心的软件当中，这样一来，广大的社区能够很好的测试这个产品，我们也能够通过 Bug report 和 Feature request 来更好的理解用户的需求和改进产品，这个过程中几乎所有的对话都是公开透明的，大家都可以参与到这个过程当中，有时候一些小小的代码错误能够被广大开源社区发现，软件的性能甚至突然得到成倍的提升。对公司来说，开源代码也意味着大家都知道你的公司在用什么样的算法，其它公司也可以模仿使用，这样公司间的竞争更大。由于代码都是开放的，很多时候甚至有安全隐患，不过我相信公司开源代码前都是对这些隐患有深刻的理解和应对方式的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：一般什么样的项目会被开源？一个项目被开源意味着什么？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;唐源&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：这个有很多情况，比如说有些在公司使用了很多年的代码突然决定开源，这有可能是这个项目的某些员工离开了或者是算法过时了，没必要再保密了，公司决定不再花时间维护，而将维护和测试的责任交给广大的社区用户。也有可能是很新的项目，为了减少自己维护的成本，将项目开源，这样大家可以更全面的测试，也能够及早得到用户的反馈意见，打造更加满足用户需求的产品。也有公司的开源是战略性的，想让大家知道自己在这方面是专家，等等。不同的公司有着不同的开源软件维护方式，政策，和原因。一旦项目被开源，这也代表着所有的代码，算法，以及实现细节都是透明的，这意味着所有的竞争者都知道这个公司使用的技术以及在某个细节上的实现，这有一定的安全隐患，但是我相信在开源前这些都是考虑透彻了的。对员工来说，一个项目被开源意味着自己多年来在公司的心血和贡献都能够被大家知道，也让自己的工作更有动力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;机器之心：很多人无法理解开源的理念，认为开源就是免费，和商业利益是相冲突的，你怎么看待这个问题？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;唐源&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：开源往往是战略上的决定，往往是和商业利益上是没有冲突的，我之前也提到过，开源一个项目可以为这个项目节省不少成本，也可以给这个公司节省招聘合适人才所需要的开支，因为你可以招到已经熟悉公司所使用技术的员工，当员工加入公司时，不需要再花时间和精力来进行培训了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：另外一些人认为公司如 Google、Facebook 和微软做开源的目的是为了垄断行业，你觉得这些担忧是有必要的吗？我们应该如何应对呢？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;唐源&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：我觉得这个没有必要担心，技术的更新换代太快了，可能今天比较火的技术和开源项目，明天就因为某个原因停止维护以及失去竞争力了，比如说以前比较火的 DeepLearning4J，因为有着比如像 MXNet 的 Scala 接口这样的竞争者，有着更好的性能也有着更了解用户需求的 DMLC 成员的维护，相信现在已经很难再有竞争力了。我们不应该担心这些，我之前也稍微提到的一点就是大家喜欢比较不同的框架，从而不断学习这些不同来改进自己的产品让它更有竞争力，互相竞争是很好的一种现象。我们能做到的就是使用自己喜欢的软件，来达到自己的研究和工作的需求，与时俱进。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：谷歌、Facebook 还有 OpenAI 这些组织做了很多开源，你们也在做，你们认为开源对人工智能技术和社区的发展有怎样的作用？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;唐源&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：开源可以让人工智能的研究的结果更有重现性然后能够更方便地让研究学者们分享研究结果。比如说我之前谈到的 TF.Learn，谷歌最近甚至最近的一篇论文是使用它来实现的，算法的实现也成为了 TF.Learn 里面的一个 Estimator，这样其它的业界人士也能直接使用到他们的工作研究当中，论文的结果也能很容易地再次得到。这些公司的开源项目都让大家有更多的学习资源，让大家有更好的工具来帮助自己的学习，工作，以及研究。这些开源项目也给了全世界各地的朋友互相交流，学习，以及一起开发产品的机会，我觉得是特别宝贵的，在芝加哥我们经常举行线下的见面会来进行交流，这样可以极大地扩展自己的视野，也认识到了一群志同道合的朋友。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：谷歌给你颁发了 Open Source Peer 奖，能给大家介绍一下这个奖对你的意义吗？你接下来打算做什么？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;唐源&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：这个奖首先是由谷歌内部员工提名推荐，然后再经过内部审核和讨论得到最后的获奖人名单的，我通过持续的贡献得到了他们的注意以及肯定，这是对我的一个很大的鼓励以及对我的贡献的认可。首先我会继续活跃在这个社区中，维护和继续贡献参与的软件，帮助大家解答使用软件时遇到的各种问题。很多时候在 Github Issues 和 StackOverflow 上会发现许多有趣的主意或者是某个人的问题和回答会激发新的灵感。然后我也一直在观察这一行的需求，其实有很多东西都是可以做的。我比较感兴趣的是那种能够让大家工作更有效率，让工作更不那么重复和繁琐的项目。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;关于 DMLC&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8g4RL7srjDrnlKGuexhib3ljI1xfO61Vs9fh9nnia90fq7Dtsku69AMibTFcibibk7QDMllick0sp2ThXA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：在你眼中，DMLC 是一个什么样的组织？是什么样的契机加入了 DMLC？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;唐源：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt; 简单来说，DMLC 是为了帮助大家更方便使用一些最新的算法和技术，降低大家进入这一行的门槛。我们想把最先进的技术带给大家，这样感兴趣的朋友可以不必再花费时间来重新实现这些技术，从而可以直接应用这些技术到他们的研究和工作当中，集中精力在已有的技术上进行突破。我们觉得好的东西应该要分享给大家，这样可以提高大家的效率，也可以加快研究领域上的突破。我最先开始是一直在改进和延伸 DMLC 的 XGBoost 项目，比如说给 Python 包做了许多小的功能上的延伸，其中有不少的需求都是来自现在比较火的数据科学竞赛 Kaggle 用户，一些 DMLC 成员经常参加 Kaggle 里面的论坛，来帮助大家更好的使用 XGBoost 来满足他们各种创新的建模需求。在天奇的邀请下，我成为 XGBoost 的 committer，然后也就自然而然地花更多的时间在维护这个项目，后来又参与了 MXNet 的 Scala 接口的建设。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：知乎上有人提到 dmlc 的初衷好像是提供一套比较简单易用的 python 的接口，这种说法对吗？那么你们设计 mxnet 的初衷是什么？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;唐源&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;： 我觉得 Python 接口只是让好的技术能够让更多人使用的一个很好的开始，Python 在数据科学和机器学习领域是非常火的，用户特别多，开源社区也比较活跃，是个很好的选择，大部分的深度学习领域的研究者都是 Python 用户，尤其是设计到图像处理，文本处理等领域。但是仅仅有 Python 接口是满足不了需求的，很多社会科学和生命科学领域经常使用 R,、Julia，在产业界最广泛使用的语言是 JVM 类的，比如说 Java 和 Scala，这也是我们后来为什么又把许多精力放在了其它语言上，比如说我花时间最多的 Scala 接口。我觉得一个好的产品不能一次性实现各种语言以及各种需求，我们首先用 Python 接口来做实验，看看需要满足用户的哪些需求，看看我们的方法能不能行得通，会不会受大众喜欢，接下来的其它的接口也都是看需求来的，这样我们能够更有效地利用时间。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：随着深度学习越来越受关注，最近对几大框架的比较是越来越多，这种现象是好是坏呢？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;唐源&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：我觉得这是非常好的现象，有竞争更能推进进步，大家都开源自己的独特框架，这更有助于学习、研究以及交流。&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719529&amp;amp;idx=3&amp;amp;sn=6992a6067c79349583762cb28eecda89&amp;amp;chksm=871b0157b06c8841587bdfb992c19290c8d66386a6f8accdf70998ce3f86b36330219c09672d&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719529&amp;amp;idx=3&amp;amp;sn=6992a6067c79349583762cb28eecda89&amp;amp;chksm=871b0157b06c8841587bdfb992c19290c8d66386a6f8accdf70998ce3f86b36330219c09672d&amp;amp;scene=21#wechat_redirect"&gt;DMLC 的天奇做的 nnvm&lt;/a&gt; 就很有学习价值，这是一个很轻量级的模块，实现了许多在深度学习系统比如说 TensorFlow 和 MXNet 中存在的对计算图进行优化，以及处理前后端，等等的一些需求。我非常开心能看到大家这样愿意将自己的研究成果开源，这样让后来的学习者少走了不少弯路。比较是好的，这样大家能看到自己的框架的优缺点，但是与此同时，因为各种条件的限制和变化，往往我们很难进行比较公平的比较。有些人喜欢拿自己框架擅长的方面来定制自己的衡量标准，希望大家能够全面的进行比较，不要以争取用户为目的来比较框架。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：谷歌、Facebook 作为大公司，他们的 TensorFlow、Torch7 好像更受欢迎，这是不是资源优势造成的呢？你如何看待现在业界的反 TensorFlow 呼声以及支持 TensorFlow 的呼声？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;唐源&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：资源优势确实影响到了受欢迎程度，但也不是绝对的，因为最终的受欢迎程度是需要经过时间的考验的，最终的决定权还是在用户手上，有着不同需求的用户群体可以更好地全面地测试不同的框架，不管是大公司支持的还是草根阶级的，都会有着竞争的机会，不会被完全垄断的。我觉得不用太在意这些，自己了解自己项目的需求，然后考虑一下学习成本，看看哪个框架更适合自己就好。比如说很多人就不太喜欢学新的编程语言就仅仅为了使用 Torch7，很多统计学家熟悉 R 的话可以直接使用 MXNet 的 R 接口，等等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心原创，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 09 Nov 2016 11:22:16 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 机器人有了新皮肤，可像人类那样感知温度</title>
      <link>http://www.iwgc.cn/link/3428798</link>
      <description>&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自IEEE Spectum&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;作者：Evan Ackerman&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：蒋思源、杜夏德&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;与他人握手时能感觉到掌心的温暖，但与机器人握手就像是抓住一块生铁？现在佐治亚理工学院的研究人员发明一种由多种织物组成的「紫杉醇」皮肤，用在机器人身上。这种技术不但可以让机器人摸起来暖暖的，还能让它在触摸其他物体时收集与温度有关的物体性质的数据，比如通过感知物体的导热系数来判定物体是木质还铝质的，其准确性可达 96%。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通常情况下，如果你的机器人摸起来暖暖的，那多半可能是它的冷却系统出了问题的症状。在大多数人眼中，机器人就不可能是热的——它们就应该是冷冰冰的钢铁人，它们的体温顶多和室温持平。机器人身上热一般都是运行的产生的副产品，是需要处理的。人类和很多其他非爬行动物都会消耗大量能量来维持一个近乎的恒温。事实证明，维持温暖的温度是有好处的，比如让我们通过触摸事物收集有用的信息的能力。现在机器人也有了这种能力了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器人使用的大多数触觉传感器都是力探测器。他们可以区分一个物体表面的硬度，有时还能分辨出它的质地。你可以在其中加上温度传感器，让它告诉你这个表面是冷的还是热的。但是，通常情况下，你周围的物体不是冷的也不是热的，而是室温的，也就是说它们总是与环境温度的持平。佐治亚理工学院的触觉的机器人皮肤使用了一个「紫杉醇（taxels）」阵列，是研究人员用压阻式织物、热敏电阻和一个加热条叠在一起组装成的。他们说力和热传感的结合效果显着优于单独的力传感。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当人类触摸到室温的物体时，我们通常的感觉是它比真实的温度要冷一点或热一点。原因有两个：第一是我们的皮肤是暖的，所以我感觉皮肤与其他物体的存在温差。第二个原因是当我们触摸物体是总是感觉它吸收我们多少的热量。换句话说，我们在测量它的导热系数。试一下：一些金属的导热性更好，能从你的手上快速吸收热量。这样一来我们就有了通过触摸收集金属的其他数据的能力，因为我们的手指是温暖的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;佐治亚理工学院的 Joshua Wade, Tapomayukh Bhattacharjee 和 Charlie Kemp 教授上月在 IROS 的 workshop 上宣讲了一篇论文，介绍了一种新的机器人皮肤，这种皮肤能主动加热。当它与传统的力传感结合起来时，就能形成一个多模态的触摸传感器，帮助确定物体的组成。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicBG77tp9SKiarHJ2pM2xSVRXmkWZWwwB67vJQeiaHIdrajrR5bUt2gWbg2DMEx4zKDpxLPjEMRiarUA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;佐治亚理工学院的基于多模态织物的触觉传感皮肤原型&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;好吧，虽然它外表看起来不怎么样，但是由力觉感应和热敏感应组成的系统相比较于单由力觉感应组成的系统要运行得好得多。织物是由大量「紫杉醇（taxels）」做成的，每一块都是电阻织物夹在处于炭纤维电阻加热条上的两层导电织物，两层被动热敏电阻（passive thermistors），两层主动热敏电阻（active thermistors）之间。这三种传感模态的结合使用能让每一个都发挥效用，如此一来研究人员就能用它通过按压来识别识别物体是木质还是铝质，准确率达 96%。而当其滑过物体时识别物体性质的准确率为 86%。我们需要强调的是这个并不是第一个主动热敏电阻传感器，Syn Touch 的 BioTac 传感器同样也集成了一个加热器，只是在指尖上使用。而佐治亚理工学院在做的是全臂使用触觉皮肤。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Tapo Bhattacharjee 告诉我们像这样的传感器在很多方面是有应用潜力的。「机器人就能使用这种传感器在复杂情况或人类环境下工作，通过了解对象的触觉属性的方式，机器人能够帮助人类设计操作的方法，例如机器人会说挤压一个软物体要比挤压一个坚硬的物体容易，或者是如果机器人知道他是在触摸人类，那么用力就会小得多。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译文章，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 09 Nov 2016 11:22:16 +0800</pubDate>
    </item>
    <item>
      <title>学界 | Google Brain与OpenAI合作论文：规模化的对抗机器学习</title>
      <link>http://www.iwgc.cn/link/3428799</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自arXiv.org&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李亚洲、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;近日在 arXiv 上发表的论文中，Ian Goodfellow 等人对对抗机器学习进行了进一步的研究。点击阅读原文可下载此论文。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicBG77tp9SKiarHJ2pM2xSVRyBDA270OBHBn8a7pHw8Wo6M2MnvMNwu1smk5iaaIUnuiblB7lzU3JuCQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;摘要&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对抗样本（adversarial examples）是被设计用来愚弄机器学习模型的恶意输入。它们总是从一种模型迁移到另一个，让 attackers 在不知道目标模型的参数的情况下进行黑箱攻击。对抗训练（adversarial training）是在对抗样本上明确地训练模型的过程，从而使它可在面临攻击时更稳健或可减少它在干净输入上的测试错误率。目前，对抗训练主要被用于一些小问题。在此研究中，我们将对抗训练应用到了 ImageNet。我们的贡献包括：（1）推荐如何将对抗训练成功地规模化到大型模型和数据集上。（2）观察对抗训练对单步 attack 方法的稳健性。（3）发现多步 attack 方法要比单步 attack 方法有较小的可迁移性，所以单步 attack 对进行黑箱 attack 更好。（4）分辨出是「lable leaking」效应造成对抗训练的模型在对抗样本上的表现比在干净样本上的表现更好，因为对抗样本构造流程使用真实标签（true label），所以该模型能学习利用构造流程中的规律。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译文章，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 09 Nov 2016 11:22:16 +0800</pubDate>
    </item>
    <item>
      <title>深度 | Yann LeCun提交ICLR 2017论文汇总：从生成对抗网络到循环实体网络等</title>
      <link>http://www.iwgc.cn/link/3414016</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自OpenReview&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李泽南、杜夏德、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;em style="color: rgb(136, 136, 136);"&gt;&lt;span&gt;国际学习表征会议 ICLR 2017 的论文提交已经于近日结束。作为机器学习领域的顶级会议之一，ICLR 自然也得到了很多重量级研究者和机构的亲睐。据大概统计，ICLR 2017 已经收到了大约 500 篇论文，这些论文都已经开放 open review，任何人都可以在&lt;span&gt; http://openreview.net/group?id=ICLR.cc/2017/conference &lt;/span&gt;看到所有提交的论文。机器之心之前已经整理过了几篇重要的提交给 ICLR 2017 的论文&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720367&amp;amp;idx=3&amp;amp;sn=15551131dbd1d1fad15d2752dd78fe83&amp;amp;chksm=871b0c11b06c8507b17d846e7d09b8fc4f0f12267d2f7dd019afa3d0ca3345a8774041ef5c84&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720367&amp;amp;idx=3&amp;amp;sn=15551131dbd1d1fad15d2752dd78fe83&amp;amp;chksm=871b0c11b06c8507b17d846e7d09b8fc4f0f12267d2f7dd019afa3d0ca3345a8774041ef5c84&amp;amp;scene=21#wechat_redirect"&gt;《谷歌 ICLR 2017 论文提出超大规模的神经网络：稀疏门控专家混合层》&lt;/a&gt;、&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720285&amp;amp;idx=5&amp;amp;sn=583751084a6855b35f684f582afd7976&amp;amp;chksm=871b0c63b06c857523341e94380cd6b87e84502854886f7aa8fa40ff665166db4ffda8a5ea1b&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720285&amp;amp;idx=5&amp;amp;sn=583751084a6855b35f684f582afd7976&amp;amp;chksm=871b0c63b06c857523341e94380cd6b87e84502854886f7aa8fa40ff665166db4ffda8a5ea1b&amp;amp;scene=21#wechat_redirect"&gt;《Vicarious 在 ICLR 2017 提交无监督学习论文，提出层级组合特征学习》&lt;/a&gt;、&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720257&amp;amp;idx=3&amp;amp;sn=4dfc480bfc70691f5baa44a75a0c1b82&amp;amp;chksm=871b0c7fb06c85696574d7f15d160afd3f45aa669bad4d1589f908c2fe0f56a3f34946bb6e73&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720257&amp;amp;idx=3&amp;amp;sn=4dfc480bfc70691f5baa44a75a0c1b82&amp;amp;chksm=871b0c7fb06c85696574d7f15d160afd3f45aa669bad4d1589f908c2fe0f56a3f34946bb6e73&amp;amp;scene=21#wechat_redirect"&gt;《OpenAI 最新论文：神经 GPU 的扩展和限制》&lt;/a&gt;。这篇文章将介绍 Yann LeCun 参与的在 ICLR2017上提交的所有论文（共 5 篇）。点击文末「阅读原文」可下载这 5 篇论文。&lt;/span&gt;&lt;/em&gt;&lt;br/&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8g4RL7srjDrnlKGuexhib3l4pdq1zWQzsMJiaTATvtvzy9qr7eI96dpC06tDAibCwNoEcgPIPEWUu6Q/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;论文：基于能量的生成对抗网络&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8g4RL7srjDrnlKGuexhib3l6V2OY9vJuHHsHHfI4hqhceMpJ5puDsCIHl5jcdyK5nQumRZ4X0b7ug/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：&lt;/span&gt;&lt;span&gt;我们在这里介绍「基于能量的生成对抗网络（Energy-based Generative Adversarial Network，简称 EBGAN）」模型，该网络将 GAN 框架中的鉴别器（discriminator）视为与数据流形（data manifold）和其它所有更高能量的区域的低能量区域相关联的能量函数（energy function）。和概率 GAN 类似，需要训练一个生成器（generator）来产生具有最小能量的对比样本，同时还要训练该能量函数将高能量分配给那些生成的样本。将鉴别器视为能量函数让我们可以在通常的二元判别网络之外还能使用范围广泛的架构和损失函数。在 EBGAN 的所有实例中，其中之一是沿着作为重构误差（reconstruction error）的能量使用一个自动编码器（auto-encoder）。我们研究表明这种形式的 EBGAN 能在训练过程中得到比通常的 GAN 更稳定的表现。我们也表明只需训练一个单尺度（single-scale）的架构就能生成高分辨率的图像。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;论文：用循环实体网络跟踪世界状态&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8g4RL7srjDrnlKGuexhib3lmBicX7xNtlg0hPIfrYF7mKiaHa9VtXZrrNeU5QTwEicEjx2xDGKwp7j9w/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：我们提出一个新的模型，循环实体网络（Recurrent Entity Network (EntNet)）。它配备了一个动态的长期记忆，能让它随着接收新数据来维持和更新世界的状态的表征。在语言理解任务中，它能一边读取数据一边运行推理，不像 Sukhbaatar 等人在 2015 年提出的记忆网络（Memory Network）(Sukhbaatar et al., 2015) 需要要求它回答或回应某个问题。它很像 Graves 等人分别在 2014 和 2016 年提出的神经图灵机器（Neural Turing Machine）或者可微神经计算机（Differentiable Neural Computer），可以保持一个固定大小的记忆并能学习去定位，基于内容读取数据，写下操作过程。然而，和这些模型不一样的是，它有一个简单的并行架构，能够同时更新若干个记忆位置。该 EntNet 在 bAbI 任务上实现了目前最佳的水平，并且是第一个能在 10000 个训练样本场景中解决所有任务的方法。我们证明了它能在大量事实支持的条件下解决推理任务，这是其他方法无法办到的。它还可以概括过去的训练水平。在实践中，它还能被使用到大规模的数据集中，比如 Children』s Book Test，在这个数据集处理任务中，该模型的表现极具竞争力，它能一次读取儿童书的故事。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;论文：深度学习中 Hessian 的奇异性&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8g4RL7srjDrnlKGuexhib3lFDKDp8CdtWLo4lCibsJkXmwu7EW0h24vDbU0SNibs8lDp2YXgDKFOc5A/0?wx_fmt=png"/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们分别在训练前后检查了一个损失函数的 Hessian 特征值。观察到的特征值分为两部分：主体部分集中在 0 附近，边缘值散落在 0 周边较远的位置。我们的实验证据显示主体部分的特征值过于参数化，而边缘区域的特征值指示了输入数据的复杂性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;论文：Entropy-SGD：偏压梯度进入宽河谷&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本论文提出了一种训练深度神经网络的优化算法：Entropy-SGD。这种方法的灵感来自于能量图景（energy landscape）局部几何关系的解决方案，这种方案在梯度下降中发现。具有低泛化误差（generalization error）的局部极值在 Hessian 中具有很大比例的几乎为零的特征值，正特征值或负特征值则非常少。我们利用这一观察来构建基于局部熵的目标，其有利于位于能量图景的平坦区域中的良好可概括的解，同时避免位于尖锐山谷（sharp valleys）中的不可概括的解。我们的算法类似于 SGD 的两个嵌套循环，其中我们使用 Langevin dynamics 来在每次更新权重时计算局部熵的梯度。本研究证明了将局部熵并入目标函数中可形成更为平滑的能量图景，同时它均衡的稳定性展示了比 SGD 更好的泛化边界。在竞争性基线中的的实验结果表明，Entropy-SGD 可以提升泛化性能，有增加训练准确性的潜力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;论文：停止时间中的普遍性&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8g4RL7srjDrnlKGuexhib3l6IStkbBsw1cDicjYfBypKXTu3Pm3P7Z2r2AajdpzicB2jCtfiaF8kk3YA/0?wx_fmt=png"/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：作者提出了应用于 spin glasses 和深度学习这两种随机系统的优化算法的停止时间（通过达到给定精度的迭代次数测量）经验分布。对于一个我们采用了优化流程（optimization routine）和随机图景（random landscape）形式的算法，停止时间（halting time）的波动遵循一个分布，该分布能在输入彻底变化后仍然不变。我们观察两个主要类：在谷歌搜索、人类做决策时、QR 因式分解和 spin glasses 中出现的 Gumbel 形式的分布；以及出现在共轭梯度方法、带有 MNIST 数据输入的深度网络和带有随机数据输入的深度网络的高斯形式的分布。对于其的实验表明：存在一类分布——其停止时间在某些条件下与底层分布无关。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译文章，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号或作者获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 08 Nov 2016 12:13:40 +0800</pubDate>
    </item>
    <item>
      <title>专栏 | 2016年欧洲计算机视觉大会纪要（ECCV’16 Recap）</title>
      <link>http://www.iwgc.cn/link/3414017</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心专栏&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;作者：魏秀参&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;计算机视觉（Computer Vision, CV）是人工智能领域的一个重要研究子领域。随着近年来 CV 学界研究成果在业界产生的巨大产业影响，计算机视觉受到越来越多的关注。机器之心曾整理报道过&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719772&amp;amp;idx=2&amp;amp;sn=9540989a7862ef93d1e5146a7b5641c9&amp;amp;chksm=871b0262b06c8b74bcd961a7bfe45076a92c1d9456af235f8e84a4bce6e15d120f295cab5576&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719772&amp;amp;idx=2&amp;amp;sn=9540989a7862ef93d1e5146a7b5641c9&amp;amp;chksm=871b0262b06c8b74bcd961a7bfe45076a92c1d9456af235f8e84a4bce6e15d120f295cab5576&amp;amp;scene=21#wechat_redirect"&gt;ECCV‘2016的各项最佳论文奖&lt;/a&gt;。本文为机器之心专栏作者魏秀参记录下的大会纪要。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;同计算机其他研究领域一样，CV 依然有着较浓厚的「会议情节」，其中每年一届的 Computer Vision and Pattern Recognition (CVPR)、两年一届的 International Conference on Computer Vision (ICCV) 和同样两年一届的 European Conference on Computer Vision (ECCV) 并称 CV 领域的三大顶会，其中 ICCV 和 ECCV 奇偶年交替召开。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;笔者有幸参加了 2016 年欧洲计算机视觉大会（ECCV 2016），在此将大会纪要同大家分享。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8g4RL7srjDrnlKGuexhib3l2CTrtnnOiaibrXRwSIB6hmEYoAeym2fdiaf3NnF28ib9bn24etow74EWcQ/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本次 ECCV 在素有「北方威尼斯」之称的荷兰迷幻浪漫都市阿姆斯特丹举办，会议历时九天（10 月 8 日至 10 月 16 日），可谓「饕餮盛宴」，其中主会从 11 日到 14 日持续四天，其余时间为 workshop 日程。值得一提的是，多媒体领域顶会 ACM Multimedia（ACM MM）于 15 日至 19 日接续 ECCV，同样在阿姆斯特丹举办，真是让人过足了 AI 瘾。此外，城市中不时弥漫开来的大麻气味无疑给这两大会徒添了一种别样的神秘气息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;ECCV 主会&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8g4RL7srjDrnlKGuexhib3l3ZvykRl6XLcXSkWyPI1xoA3r8zQLtb5LsQVWKqsZ8ic8z6N9Q5Uojtw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本次 ECCV 主会在始建于 1887 年的皇家剧场 Carré举行，注册参会人数约 1700 人。有效投稿数为 1561 篇，共 74 位 Area Chairs 和 1163 位审稿人（Reviewers），录用论文 415 篇，录用比例 26.6％，其中 28 篇为 Oral（占 1.8%），45 篇为 Spotlight（2.9%）。收录论文的主题仍然延续传统，覆盖了计算机视觉和模式识别的各个方向，包括：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;3D computer vision&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Computational photography, sensing and display&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Face and gesture&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Low-level vision and image processing&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Motion and tracking&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Optimization methods&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Physics-based vision, photometry and shape-from-X&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Recognition: detection, categorization, indexing, matching&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Segmentation, grouping and shape representation&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Statistical methods and learning&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Video: events, activities and surveillance&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Applications&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其中，深度学习（DL）、3D、视频相关等为热门方向。而审稿人方面，也是 DL、3D 等方向审稿人居多，特别是深度学习，异军突起。（PS：但是审稿人多并不一定是好事。由于不同研究背景的研究人员都进入 DL 领域，导致 DL 审稿人给出的审稿意见参差不齐，不同意见间的「方差」很大。）相比之下，审稿人最少的 Sensors 领域人数只是 DL 的七分之一。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8g4RL7srjDrnlKGuexhib3lgkOsYqQ8wibAznnfN1mibXcUqI6JSaed9ibH9HETE3oAD4Tic9owrXg33A/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8g4RL7srjDrnlKGuexhib3l1ib4ZjvWic9OLnKMuBa3y3OsSRY6EmUfXTScukNYlDibLNQJ5Yv7uicSBA/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;主会日程基本半天一个单元，每个单元中前场分别是 Oral 和 Spotlight 报告，接下来则是 Poster 环节。有关 Oral、Spotlight 和 Poster paper 具体内容可参见 ECCV 2016 主页。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;ECCV Workshops&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本次依托 ECCV 举办的 workshop 共有 26 个，一些在当地酒店举办，一些在阿姆斯特丹大学举办。Workshop 中比较吸引人眼球的还属「Joint ImageNet and MS COCO Visual Recognition Challenge」了。这次 ImageNet 竞赛比较显著的一个特征即今年的获胜者基本是华人团队，如商汤（SenseTime）、海康威视（HIK Vision）、360 AI，公安部三所等。另外，比赛结果中并未见 Google、微软、百度等公司的身影。在此也祝贺在各项比赛细类中取得名次的队伍！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外，笔者也有幸作为 team director 参加了 Apparent Personality Analysis 竞赛，历时两个多月，我们的参赛队（NJU-LAMDA）在 86 个参赛者，其中包括有印度「科学皇冠上的瑰宝」之称的 Indian Institutes of Technology（IIT）和荷兰名校 Radboud University 等劲旅中脱引而出，斩获第一。关于竞赛细节，可参看近期我们发布在「深度学习大讲堂」的竞赛经验分享。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;晚宴和颁奖&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;由于阿姆斯特丹是运河城市且沿海，ECCV 晚宴特地选定在「Ocean Diva 号」游轮上举行。各国人工智能研究者济济一堂，好不热闹！只是「晚宴」并不如我们想象中的中式会议晚宴那么丰富甚至奢华，国外会议晚宴一般都是以啤酒、饮料穿插以小吃、汉堡为主。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8g4RL7srjDrnlKGuexhib3l36E5D8QYibeclDOZUiaAdydPUlSCmpGckfAzIItWuYgjnJa6Rs5m2PIA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;晚宴的重要时刻即大会颁奖，本次的最佳论文及提名，和最佳学生论文均授予了传统计算机视觉研究问题，而非深度学习。一则可以看出深度学习相关研究目前难度日益加大，欲做出有突破性进展的工作不易；二则可以看出 CV 大佬有意扶持传统研究问题，维护 CV 生态平衡，不致 DL 一家独大。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8g4RL7srjDrnlKGuexhib3liasrc5eUM3icDWAJ8lxlxQT1GwO5Uq5Sha08lWN556Tgb1gQNGbYl9qQ/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外，Koenderink Prize（ECCV「十年最佳论文」）授予了著名的 SURF: Speeded up robust features (ECCV 2006) (Herbert Bay, Tinne Tuytelaars and Luc Van Gool) 和 Machine learning for high-speed corner detection (ECCV 2006) (Edward Rosten and Tom Drummond)。值得一提的是，在宣布 SURF 获奖之际当即引来一片欢呼，可见其工作深入人心之甚。PAMI Everingham Prize（CV 领域的最佳贡献奖）分别授予了 ImageNet 数据集团队和 Ramin Zabih 以表彰其在开源数据集，和服务 Computer Vision Foundation 上的卓越贡献。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;干货时间&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;开会数日，笔者有心记录了一些会议观察，在此与君共享。不过受个人研究兴趣影响，以上内容不免有所偏颇，望诸君选择性参考。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 这次会上大佬们如 Jitendra, Cordelia 在力推 self-supervised learning（基于 robot 反馈机制，例如，机械手臂戳一下物体，从 sensor 或视频中获得反馈，可以看作是用 robot 来探知世界吧），最近 arxiv 也有一篇类似的 https://arxiv.org/abs/1605.07157；另外，很多利用 side information，如利用声音辅助视觉，这样的工作在本次 ECCV 上也屡见不鲜；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 冠名弱监督学习（Weakly supervised learning）的工作非常多了，但是「弱监督」的内涵却是个圆其说，不像机器学习中有明确的定义；因此，以后基于弱监督设定的计算机视觉问题还应该有做的空间；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3. 底层视觉（Low-level vision）问题／任务极少，几乎没有，不像 ICCV 2015 还有若干篇的样子；而且一些工作开始用 DL 去做 low-level vision 的东西，比如 Ming-Hsuan Yang 在这次会上的两篇利用 DL 技术学习底层视觉中的滤波器（Filters）。（http://faculty.ucmerced.edu/mhyang/papers/eccv16_joint_filter.pdf 和 http://faculty.ucmerced.edu/mhyang/papers/eccv16_rnn_filter.pdf）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4. 传统细粒度图像相关工作几乎没有，只有一篇做细粒度图像任务的新问题，即细粒度场景图像分类（Fine-grained scene classification）（https://arxiv.org/abs/1607.07614）；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;5. 有两篇 image colorization 作为 oral paper，不知是否是巧合；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;6. Question answering 这类问题相比 ICCV 少了很多，但隐式做 visual-text 的工作还是占了一定比例；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;7. 下面几篇文章做的问题比较有趣：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;a) Amodal instance segmentation, Ke Li and Jitendra Malik.（构造新数据集，做了新问题）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;b) Automatic Attribute Discovery with Neural Activations, Sirion Vittayakorn, University of North Carolina at Chapel Hill; Takayuki Umeda, NTT; Kazuhiko Murasaki, NTT; Kyoko Sudo, NTT; Takayuki Okatani, Tohoku University; Kota Yamaguchi, Tohoku University&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;c) Pixel-Level Domain Transfer, Donggeun Yoo, KAIST; Namil Kim, KAIST; Sunggyun Park, KAIST; Anthony Paek, Lunit Inc.; In So Kweon, KAIST (根据衣服生成买家秀，或反过来，在真实场景下，从模特照片中生成产品照片)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，总结来说，这次参会最明显也是最微妙的一个感受就是，多数工作在开会前都没有看过。而不像前两年参加顶会时发现绝大多数文章已经是 arxiv 上读过很久的工作，甚至已经跑过源码，去开会也只是和作者当面聊聊天，甚至当时还有一种顶会更新速度落后于 arxiv 的感受。ECCV'16 这一现象恰恰说明深度学习研究的发展慢慢从当初的白炽化走向正常化，从着急忙慌的在 arxiv 上占坑走向踏踏实实的顶会发表。另外也从侧面显示了深度学习研究难度的提升，就拿 arxiv 举例，一年前几乎每天都能看到有令人 exciting 的文章更新出来，而近期不仅发布文章的数量有所下降，重要的是有趣的文章更是难得一见。这次会上也与众多老友把酒言欢，同时也认识了很多新朋友，期待下次的 CV 大趴，我们 CVPR'17 再见。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;10 月 30 日于澳大利亚阿德莱德&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（题图为笔者摄于 Zaandam 风车村）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;作者简介：&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;魏秀参：南京大学计算机系机器学习与数据挖掘所（LAMDA）博士生，研究方向为计算机视觉和机器学习。曾在国际顶级期刊和会议发表多篇学术论文，并多次获得国际计算机视觉相关竞赛冠亚军，另撰写的「Must Know Tips/Tricks in Deep Neural Networks」受邀发布于国际知名数据挖掘论坛 KDnuggets 等. 微博 ID：Wilson_NJUer&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心专栏文章，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号或作者获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 08 Nov 2016 12:13:40 +0800</pubDate>
    </item>
    <item>
      <title>资源 | 斯坦福自然语言工具CoreNLP更新，下载3.7.0版本</title>
      <link>http://www.iwgc.cn/link/3414018</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Stanfordnlp&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;著名的斯坦福自然语言工具 CoreNLP 有了最新的更新，此次更新的 CoreNLP 下载包大小为 536MB，包括 CoreNLP code jar、CoreNLP &amp;nbsp;model jar、运行 CoreNLP 所需的库、该项目的文档/源代码。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;项目地址：&lt;/span&gt;&lt;span&gt;http://stanfordnlp.github.io/CoreNLP/&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;斯坦福 CoreNLP 提供一系列自然语言分析工具。它能给出单词的基础形式，单词在语言中的成分，单词是否是公司、人的名字，规范化日期、时间、数量词等，根据短语和单词的依存关系组成语句结构，表明哪些名词短语指代同一实体，指明情感成分，提取这些内容之间的开放性关系，等等一系列用途。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你有以下需求，就可以使用斯坦福 CoreNLP：&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;需要一个有宽泛范围语法分析工具的融合型工具包；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;对任意文本进行快速、可靠的分析；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;总体而言最高质量的文本分析；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;支持一系列主要的（人类）语言；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;可与多种主要的编程语言对接；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;可作为简单的网页服务来运行；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;斯坦福 CoreNLP 是一个融合框架。其目标是能最简单的将语言学分析工具应用到文本中。一个 CoreNLP 工具管道通过两行代码就能在一些简单文本上运行。其设计高度灵活、可延展。你可以改变其中无效的工具，加入有效的工具。斯坦福 CoreNLP 融合了斯坦福多种 NLP 工具，包括 part-of-speech（POS）tagger、命名实体识别器（NER）、解析器、conference resolution 系统、情感分析、bootstrapped 模式学习和开放信息提取工具。它的分析能为高层次的、特定领域的文本理解应用提供基础构造。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8g4RL7srjDrnlKGuexhib3lQKjcYvyPbnWa7eiaeXp8wFBMSE73icpWL4Q82I3RcDDiaiboVbB9lGtpLg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此次更新的 CoreNLP 下载包大小为 536MB，包括 CoreNLP code jar、CoreNLP model jar、运行 CoreNLP 所需的库、该项目的文档/源代码。此外该项目还提供了早期版本的下载。下图是 3.7.0（beta）支持下载的语言：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8g4RL7srjDrnlKGuexhib3lPwJW2XeuoQk0wjSHPjcORXruZegyUnutleS6eqkkqYxegsyeDicIQ0Q/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;工具包的基础分布能为较好剪辑英语的分析提供模型文件夹，但该引擎能兼容其他语言模型。我们提供了阿拉伯语、汉语、法语、德语、西班牙语的打包模型。我们也提供了一个包含斯坦福所有英语模型的 jar，它包含各种变体模型，尤其是有一个处理非常规英语（例如，大部分或全部单词都是大写或小写的形式）的优化模型。该工具包也支持其他语言的第三方。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在编程语言上，斯坦福 CoreNLP 使用 Java 编写。从命令行使用斯坦福 CoreNLP 的方式有很多，通过 Java 编程 API、大部分编程语言的第三方 API 或者通过 CoreNLP Server。它能在 Linux、OS X 和 Windows 上运行。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 08 Nov 2016 12:13:40 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 东芝宣布时域神经网络技术：要让低功率物联网设备也能深度学习</title>
      <link>http://www.iwgc.cn/link/3414019</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自phys.org&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8g4RL7srjDrnlKGuexhib3luNnEFMIf3BcT03KicbUpNXG33LULDoshnYxnByISqltxQjs5hQ3gLmA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 1：时域神经网络（Time Domain Neural Network）&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了追求其在物联网和大数据分析领域的未来，东芝公司正在开发一种时域神经网络（TDNN/Time Domain Neural Network），采用了超低功耗的神经形态半导体电路，可用于执行深度学习的运算。TDNN 由大量使用了东芝自家的模拟技术的微型处理单元构成，这让它和传统的数字处理器不一样。TDNN 在 11 月 8 日的 A-SSCC 2016（2016 年亚洲固态电路会议）上报告了出来——这是由 IEEE 赞助的一个在日本举办的国际性半导体电路技术会议。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;深度学习需要大量的计算，所以通常需要在高功率的高性能处理上运行。但是，如果要将深度学习和物联网边缘设备（IoT edge device）（如传感器和智能手机）结合起来，就需要非常高能效的 IC（集成电路）——它可以执行大量所需的运算，同时仅需消耗极少的能量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在冯诺依曼型的计算机架构中，大部分能量都消耗在了将数据在片上或片外存储设备与处理单元之间的传递之中。减少数据移动的一种最有效的方式是使用大量处理单元，其中每一个都仅处理与其接近的一个数据。这些数据点在将输入信号（比如猫的照片）转换成输出信号（比如识别照片中有猫）的过程中会有一个权重。数据点离目标输出越近，其获得的权重就越高。该权重是自动化引导深度学习过程的一个参数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;生物大脑也有相似的架构。在生物大脑中，神经元之间的耦合强度（权重数据）内建于突触（处理单元）之中。在大脑里面，突触是神经元之间的连接，每一个都有不同的强度。这些强度（权重）决定了通过该连接的信号。突触可以通过这种方式执行某种形式的计算处理。这种架构被称作是完全空间展开架构（fully spatially unrolled architecture）；它很有吸引力，但也有一个明显的缺点——将其复制到芯片上需要大量的算术电路（arithmetic circuits），而且会很快变大到难以承受的程度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;东芝的 TDNN 从 2013 年开始开发，使用了时域的模拟和数字混合的信号处理（TDAMS/time-domain analog and digital mixed signal processing）技术，可以实现处理单元的小型化。在 TDAMS 中，比如加法这样的算术运算可以通过使用像模拟信号一样的数字信号通过逻辑门的延迟时间来有效地执行。使用这项技术，用于深度学习的处理单元可以仅有完全空间展开架构的 3 个逻辑门和 1 bit 内存即可。东芝已经制造出了一款用于概念验证的芯片，其使用了 SRAM（静态随机存取存储器）单元作为内存，并且已经证明能够用来识别手写数字。其每条指令的能量消耗是 20.6 fJ，仅有之前一场顶级会议上报道的成绩的 1/6.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;东芝计划将 TDNN 开发成一种电阻式随机存取存储器（ReRAM/resistive random access memory），以进一步提升能量和数据的效率。其目标是得到一款能够在边缘设备上实现高性能深度学习技术的 IC。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;原文链接：http://phys.org/news/2016-11-toshiba-advances-deep-extremely-power.html&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，机器之心系今日头条签约作者，本文首发于头条号，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 08 Nov 2016 12:13:40 +0800</pubDate>
    </item>
    <item>
      <title>深度 | 数据和算法像人一样有偏见，你还愿意让人工智能帮你投票吗？</title>
      <link>http://www.iwgc.cn/link/3399371</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自World Economic Forum&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李泽南、曹瑞&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;em style="text-align: justify; color: rgb(136, 136, 136);"&gt;&lt;span&gt;2016 美国大选将至，一些研究者和从业者也趁着这股热潮推出了一些基于数据预测大选结果的人工智能程序，但就像人类自己一样，它们所支持的总统候选人也都不一样（一些俄罗斯人开发的一个人工智能程序会选择特朗普当总统 :O）。未来，如果算法成为了我们日常生活的管家，我们可以让算法来帮助我们选出总统吗？&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;想象一下 2020 年的普通一天，人工智能助手唤你起床，为你端上已准备好的早餐，都是你最喜欢的食物。在晨跑中，播放器会自动播放符合你喜好的最新歌曲。上班路上，电子助手会根据你过去的阅读品味，自动向你推送新闻以供阅读。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你阅览着新闻，注意到总统选举马上就要来了，人工智能参考了你过去的政治看法和本州其他选民的意见，向你推荐了一位民主党候选人。你的手机上，一条弹出信息询问你是否需要 AI 助手帮你准备投票所需文件，你点击「同意」，然后关掉屏幕，继续自己的生活。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;人工智能：呆板的数据机器&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;AI 个人助手在几年前已经走进现实，对于我们来说，把履行公民义务的重任交与它们还是显得有些不合适——即使人工智能几乎总是知道在特定的时刻给我们最好的建议。通过足量的数据学习，人工智能可以为每个人提供准确的，个性化的建议，甚至比你最亲密朋友的建议更完美。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Alphabet 董事长埃里克·施密特坚信，人工智能的发展会让每个人都会变得更聪明，更有能力，更为成功。人工智能已经展现出了巨大潜力，有希望帮助解决人类社会面临的各种复杂挑战，如气候变暖，人口增长和人类发展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然而机器展现出的潜力也带来了担忧。有调查显示，34% 的人表示自己害怕人工智能，而 24% 的人认为人工智能会对社会造成负面影响。相比较未知的恐惧，人工智能对于数据的依赖带来了现实的隐患，GWI 的研究表明，63% 的民众担心他们的个人信息被科技公司滥用。最近 Oxford Internet Institute 的研究显示，人们对于让人工智能助手打理自己生活的方式持谨慎态度，特别是当这些助理提出自己的建议，却又不告诉你它推理过程的时候。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这里，我们没有必要混淆数学与魔法。人工智能并不是在你手机里生活的神秘生物。但我们往往会忘记，人工智能一直在读取我们的个人资料，通过复杂的数学模型，自动推断我们的兴趣、位置、习惯、财务和健康。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;开发者的角色&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当前关于算法与人类的很多讨论都围绕着设计者在算法中的作用——人工智能创造者的潜在意识和偏差是否会被编码进帮我们做出决定的算法中。很多人担心开发者的个人偏见会被带入算法，其中一点点微妙的歧视就会让部分人群的利益受到侵害——也许还有更坏的结果，科技平台会演变成弱势群体难以逾越的门槛。即使算法和写算法的人没有偏见，没有人能够保证训练算法的数据中一切都是平等的，现实世界本身存在着偏见，数据集中的内容也会对人工智能框架产生影响。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;持这一观点的决策者和专家们经常误解人工智能算法出错的原因。他们不断指责开发者，却忽略了自我学习系统的局限性。将错误推给别人是一种自然反应，特别是在你无法理解这些技术时。算法的偏差很少来自于开发它们的工程师。事实上，在大部分情况下，问题的根源出自训练算法的数据，这才是构建未来人工智能社会所要担心的真正危险。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;算法决定论&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;回想一下机器学习到底是怎么工作的，通过应用统计学技术，我们可以开发自动识别数据中特征的算法。为了达到这个目的，系统需要经过巨大数据集的训练，训练模型的数据越多，预测准确率越高。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在个性化数字应用中，这些统计学习技术被用来建立算法，为用户提供个性化服务，计算机阅读了我们的使用模式、品味、偏好、人格特征和社交图谱，随后建立起对于人类的数字观感。计算机形成的社交身份并不基于你的个性或选择，相反，这种虚拟身份来自于你的可统计数据点，和它们的机器解释。这种代替，无论多么复杂，都是人工智能对人类的不完美数字表达。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能只能查找历史数据，为用户所需做出建议。这就是为什么今年 8 月，一个视觉识别神经网络通过 1400 万张照片的训练后预测唐纳德·特朗普将会赢得本届美国总统大选。鉴于这个数据集中并没有女性美国总统，AI 可能判断性别是识别模型的相关特征。但即使排除这一点，如果让这个俄罗斯人训练的人工智能投票的话，它肯定会投特朗普。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicsPeIvLZsUJgazZo1ias2IuJNEAvGv5NRwWHicibDZweMHAlvrox2VYj1kckWjNETR3GXk45A1eKMcg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这样的推论会导致越来越僵化的推荐系统，它倾向于不断强化现有的看法，就像社交网络中的反射效应一般。「个性化」使每个人都被贴上了标签，让现实生活和网络世界互相割裂。计算机不断地推荐「你喜欢的」内容，用户获得的信息在不知不觉中被算法误导，人类或许在人工智能真正觉醒之前就已深陷其中了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;动态的人生&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们的身份是动态的，复杂而充满矛盾的。根据我们的社会背景，我们总会拥有者几个不同的身份，这意味着我们需要用到几种不同的 AI 助理——在学校或工作中的，在酒吧或教堂里的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除了通常的自我介绍，我们在网络中可能也需要以不同的身份展现自我，和不同的群体展开互动。我们不希望自己在社交网络中被随意查看，我们也不希望自己在寻找新奇事物时，还要担心朋友和家人的窥视。如果我们想要试试不同的社会身份，会发生什么？4Chan 创始人 Chris Poole 说道：「这不是你在和谁分享的问题，这有关你与他人分享什么样的内容。身份就像一个棱镜，别人通过它来看你会呈现无数不同的面貌。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;区分不同的自我表达阶层，绘制不同社交环境下的身份，对于人工智能而言是一个巨大挑战。很多时候，人类面临的问题不在于算法设计——我们连自己是什么都还没弄清楚。但人工智能助手总会给我们一个答案：关于过去的我们。身份的变化在这样的环境中变得越来越难，我们的生活习惯和信念被自我强化的循环锁定，算法构建的《土拨鼠日》出现了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们在日常生活中越依赖于个性化算法，我们的个性就会越被计算所磨灭，我们所读，我们所见，我们生活的方式都将被机器所决定。通过专注于现状，接管探索信息和偶遇陌生人的渠道，用过去发生过的事情试图再一次讨好自己，这就是算法决定论的世界。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当过去照进未来，人类赖以生存的自发性，开放与进取变得逐渐稀缺。温斯顿·丘吉尔曾经的话变成了这样：我们塑造了算法，然后，算法塑造了我们。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicsPeIvLZsUJgazZo1ias2IuYJGwhR0KoMia0kGcPp8GEIz7ueE3Lsaic7iamj2ib8UgXbfiajpibtbG8p2A/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;如何阻止未来&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在今天，现实世界中的人工智能应用已经融入到了日常生活的方方面面——而人们对这一科技的兴趣也是越发浓厚。但是有两个主要的挑战正让未来变得难以触及。从科技进步的角度来讲，不同应用之间的数据交换上缺乏互通性标准，而具备这一点能够防止彻底的个性化。要是想要真正有用的话，机器学习系统需要更多的个人数据——而这些数据现在都被孤立地分散在一些有竞争力的科技公司的专业数据库当中。那些掌握数据的公司就掌握了权利。一些公司，最著名的比如说像 Apple 和 Viv，已经开始通过与第三方服务结合的实验来扩大自己的势力范围。最近，一些最大的科技公司宣布了与人工智能研究的主要合作，这样就可以将益处带给大多数人，而不仅仅是少数人。这将会对今后建立对人工智能的普遍信任至关重要。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从社会的角度来看，人类似乎对人工智能的急速发展有一种莫名的反感。人们担心会失去对人工智能助手的控制。信任是我们控制能力的一种直接表现。试图对生产力进行一些微小的改进，却要赌上关系和名誉，大多数人都不愿意这样做。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当然，在早期，人工智能助手的行为方式可能并不是它的人类制造者所期望的。有先例证明，一些失败的人工智能实验会减少对弱人工智能（narrow AI）解决方案和聊天机器人（conversational bots）的信任。Facebook、微软和谷歌纷纷在 2016 年建立了它们的机器人平台，但过早呈现在人们面前的人工智能科技，因其有限的功能、应用和定制化让用户大失所望。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一直困扰我们的恐惧——人工智能科技的后果，也因为很多科幻小说中所描述的有意识、暴戾的人工智能统治世界的反乌托邦场景而加剧。但是我们所面对的未来，既不会像是人工智慧网络「天网」（Skynet），也不会像乔治·奥威尔的《1984》里一样：而更可能会像是《美丽新世界》（A Brave New World）中所描述的一个享乐主义的社会，在那里，科技的地位仍然是需要为普遍的幸福和自我放纵所服务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicsPeIvLZsUJgazZo1ias2Iu2HNia0xTsL27niczVuXYIDgHaaAvL8coPibtn5TXRLUhbHwH8GksVYDJw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;未来导向型机制&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;科技发展的脚步从未停滞，但希望仍在。2016 年全球杰出青年社区（Global Shapers Community）的年度调查显示，在年轻人眼中，人工智能已经成为了主要的科技发展趋势。此外，21% 的调查对象表示他们支持人形机器人的权利，而且在东南亚，支持的呼声尤为高涨。年轻人们似乎对于人工智能在我们日常生活中所扮演的角色持非常乐观的态度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在欧洲，欧盟的《一般数据保护条例》（General Data Protection Regulation，简称 GDPR）让用户有机会要求对基于分析的算法决策进行解释，限制了绝对形式的算法决策。该条例有望于 2018 年 5 月之前在所有欧盟国家实施。这样的机制能够限制资料搜集，强调了人类可解释性（human Interpretability）在算法设计中不容忽视的重要性。但是，这是否会对一些大型科技公司现行的算法实践带来主要的变化，还尤未可知。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;每天都有关于我们每个人的成千上万个算法决策——从 Netflix 的电影推荐、Facebook 上的好友建议，到保险风险评估和信用评分。就各方面而言，人们自己应该有责任对关于自己的算法决策进行跟踪和仔细审查，或者说我们可能需要将此编码到他们使用的数字平台设计当中？责任是非常重要的一点，准确来说是因为在大范围内进行估量和实施是非常困难的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因此，在一头栽进这个未知的领域之前，我们需要回答一个问题：我们想让人类和人工智能之间的关系成为什么样子？反思这些问题，我们才会设计出非决策性的、透明并且有责任感的算法，这些算法能够辨别出个体当中复杂、发展和多方面的本质。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Mon, 07 Nov 2016 14:44:05 +0800</pubDate>
    </item>
    <item>
      <title>基础 | 机器学习入门必备：如何用Python从头实现感知器算法</title>
      <link>http://www.iwgc.cn/link/3399372</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自machinelearningmastery&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：Terrence L、武竞、Xavier Massa&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;br/&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;感知器算法是最简单的人工神经网络形式之一。感知器是一个单神经元的模型，可以用于两个类别的分类问题，也能为以后开发更大的神经网络奠定基础。在本教程中，你将了解到如何利用 Python 从头开始实现感知器算法。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在完成本教程后，你将学会：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如何训练感知器的网络权重&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如何利用感知器做出预测&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如何对于现实世界的分类问题实现感知器算法&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;让我们开始吧。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;概述&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本节简要介绍了感知器算法和 Sonar 数据集，我们将会在后面应用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;感知器算法&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;感知器的灵感来自于被称为神经元的单个神经细胞的信息处理过程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;神经元通过其树突接受输入信号，并将电信号向下传递到细胞体内。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过类似的方式，感知器从训练数据的样本中接受输入信号，训练数据被加权并在称为激活（activation）的线性方程中进行组合。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicsPeIvLZsUJgazZo1ias2IuR58uk06pl1hs3qIsAAqyAXl4jJS9TUgu9XqAy9jQ0S7cNUGkuhLGUQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然后，使用诸如阶跃传递函数（step transfer function）的传递函数将激活变换为输出值或预测。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicsPeIvLZsUJgazZo1ias2Iu2cXKNFv1vfsAtD4syvAIKOYHBnn6d0m00jAS9oz8LlBOZYKsWRg8Zg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以这种方式，感知器是用于具有两个类（0 和 1）的问题的分类算法，其中可以使用线性方程来分离这两个类。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;它与以类似方式进行预测的线性回归和 logistic 回归密切相关（例如输入的加权和）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;感知器算法的权重必须使用随机梯度下降算法从训练数据中估计。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;随机梯度下降&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;梯度下降是通过跟随成本函数（cost function）的梯度来最小化函数的过程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这涉及了解成本的形式以及导数，使得从给定的点你可以知道梯度并且可以在该方向上移动，比如下坡到最小值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在机器学习中，我们可以使用一种技术来评估和更新称为随机梯度下降的每次迭代的权重，以最小化我们的训练数据模型的误差。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这种优化算法的工作方式是每次向模型显示每个训练实例。模型对训练实例进行预测，计算误差并更新模型以便减少下一预测的误差。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该过程可以用于在模型中找到能使训练数据上模型误差最小的权重集合。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于感知器算法，每次迭代，权重（w）使用以下等式更新：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicsPeIvLZsUJgazZo1ias2IuCR15qgicJ3zgQ2CzAgmSkoK19p5ssuTGnsLwNnSukqJCtLHG52meDOQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其中w是正在被优化的权重，learning_rate是必须配置的学习速率（例如 0.01），（expected - predicted）是在归因于权重的训练数据上的模型的预测误差，x是输入值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;S&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;onar 数据集&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们将在本教程中使用的数据集是 Sonar 数据集。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是一个描述了声呐啾啾叫声并返回不同服务的试探的数据集。60 个输入变量是在不同角度的返回强度。这是一个二元分类问题，需要一个模型来区分金属圆柱体和岩石。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;它是一个很好理解的数据集。所有的变量是连续的，通常在 0 到 1 的范围内。因此，我们不必对输入数据进行归一化，这通常是使用感知器算法的一个好地方。输出变量是字符串「M」（表示矿 mine）和「R」（表示岩石 rock），我们需要将其转换为整数 1 和 0。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过在数据集（M 或 Mines）中预测具有最多观测值的类，零规则算法（Zero Rule Algorithm）可以实现 53％的精度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你可以在 UCI Machine Learning repository：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://archive.ics.uci.edu/ml/datasets/Connectionist+Bench+(Sonar,+Mines+vs.+Rocks)）&lt;/span&gt;&lt;span&gt;中了解有关此数据集的更多信息。你也可以免费下载数据集，并将其放在工作目录中，文件名为 sonar.all-data.csv。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;教程&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个教程分为三个部分：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1.作出预测&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2.训练网络权重&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3.将 Sonar 数据集建模&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些步骤将带给你实现和应用感知器算法到你自己的分类预测建模问题的基础。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1. 作预测&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一步是开发一个可以进行预测的函数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这将会需要在随机梯度下降中的候选权重值的评估以及在模型被最终确定之后，我们希望开始对测试数据或新数据进行预测。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面是一个名为 predict() 的函数，用于预测给定一组权重的行的输出值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一个权重始终是偏差，因为它是独立的，不负责特定的输入值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicsPeIvLZsUJgazZo1ias2IuMrXeLicnjIkPD4dweYXbr8a7jz0tRU6JQtZzSPJM45hlE1axSzznqNw/0?wx_fmt=png"/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们可以设计一个小数据集来测试我们的预测函数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicsPeIvLZsUJgazZo1ias2IucnkwaNuPyMzA1etI2PQuQq2bS27VanfQ2VbGX4Th2crFRJ3FuKialSw/0?wx_fmt=png"/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们也可以使用之前准备好的权重来为这个数据集做预测。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;将所有这些集中起来，我们就可以测试我们的 predict() 函数了，如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicsPeIvLZsUJgazZo1ias2Iu6YiaMuicXM9pSxLIZ4KAscevJicrCNgMA34sBzpBjnz5rxicyib0FmEA6Ng/0?wx_fmt=png"/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该函数有两个输入值 X1、X2 和三个权重参数 bias、w1 及 w2。该问题的激活函数有如下的形式：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicsPeIvLZsUJgazZo1ias2IuzBpTY21RHjUKGjw27bFc9mdjnct7qtFdERT6FVm9I5XSDggdm1XxTA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;或者，我们能够手动地选择权重值：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicsPeIvLZsUJgazZo1ias2Iuj6OicNIlSzibiaJ4gNfCb6nFqb16SMkJQdf9K667f8pR7JNQzpQdEjpBw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;运行这个函数，我们将会得到与期望输出值 (**y**) 相符合的预测值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicsPeIvLZsUJgazZo1ias2Iu26ylV03nTicsSeIibHqv7iaiaY8pgSLk3kuAXKVuqbPysqYJjEqicPL04Dg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在，我们已经准备好使用随机梯度下降法（SGD）来最优化我们的权重值。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2. 训练神经权重&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们可以使用 SGD，来估计出对于训练集的权重值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;SGD 有两个参数：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;学习率（Learning Rate）：用来限制每次更新中权重项修正值的大小。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;迭代次数（Epochs）：在训练集上训练同时更新权重项的次数。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这两个参数，和训练集一起，都将会是预测函数的输入参数。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这个函数中，我们需要运行三个循环：&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 对于每次迭代进行循环；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 对于一次迭代中，训练集的每一行进行循环；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3. 对于每一行中，每一个值进行循环。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如你所见，我们在每一次迭代中，对训练集每一行中每一个权值都进行更新。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们基于现有情况模型预测的「误差」，来对权重值进行更新。误差，是由候选权值计算出来的预测值与（数据集中的）期望值的差。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对每一个输入属性，都有一个权重值，并且这些权_重值都连续更新_。如：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicsPeIvLZsUJgazZo1ias2IuAUaJJPicgMicUkWX5MF8ibzp4ich0J9nMRdY5p5sBS8wZrq6lhHkxHjGdw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;偏差项以一种相似的方式更新，不过因为它本身就不与特定的输入值有关，因而在式子中没有输入值的项。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicsPeIvLZsUJgazZo1ias2Iu63iarVI5iaR7MVP9IQN2mhhSuc0ribCoQR9YlJ6lOSfREJQaViboGpsfzg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在，我们把所有的内容组合到一起。如下所示，在 train_weights() 函数中，它使用 SGD 方法，计算对于给定训练集的权重值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicsPeIvLZsUJgazZo1ias2IunAMYCGjib2ru5eSHzTRib6zBsGDdlf6LMnx5pzCqDY4xSbvIGsD5BZLw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如你所见，我们也在每次迭代中，记录下了平方误差之和（这始终是一个正值）。因而我们能在外循环的每次迭代中，print 一些有用的信息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们也可以在我们上面创建的小规模数据集上，对该函数进行测试。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicsPeIvLZsUJgazZo1ias2IueN9D4GWkC01Xht9OicCCR62qlGUkYQsSswrgFiaPOs9e4TT8m3RgOjdA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们将使用 0.1 的学习率和 5 次迭代，也就是把参数在训练集上更新五次，来训练这个模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;运行这个案例，它将会在每一次迭代结束后，显示出该次迭代后的平方误差和，并在完成所有迭代后，显示最后的权重集。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicsPeIvLZsUJgazZo1ias2IuiaPeXF9F8yEg9KQ79AQObDNwmsn4h46icGh3xnGwWaM8XP4S8gnjUqkQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你可以看到，这个算法很快学会了「解决」这个问题。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在我们来试试看，如何在一个实际的数据集上应用这个算法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3. 对声纳数据集进行建模&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这一节中，我们将使用 SGD 方法，对一个声纳数据集，训练一个感知器模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在该例子中，我们假定，在当前的工作目录下，有一名为&lt;strong&gt;sonar.all-data.csv&lt;/strong&gt; 的文件，存储着该数据集。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先该数据集被载入。数据集中字符串格式的数据被转换为数值型，同时输出值从字符串被转换了 0 或 1 的两个整数值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过&lt;strong&gt; load_csv(), str_column_to_float()及str_column_to_int() &lt;/strong&gt;三个函数，我们实现了对数据集的读取及预处理。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们使用「k 倍交叉验证法」（k-fold cross validation）来对学习后的模型在未知数据集上的表现进行评估。也就是说，我们需要建立 k 个模型并估计各模型的平均误差。分类准确性将被用于模型的评估工作中。这些工作在 &lt;strong&gt;cross_validation_split(), accuracy_metric() 及 evaluate_algorithm() &lt;/strong&gt;函数中被完成。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们将会使用上面设置的&lt;strong&gt; predict()&lt;/strong&gt; 和&lt;strong&gt; train_weights()&lt;/strong&gt;函数来训练该模型。同时，我们将会用一个新函数&lt;strong&gt; perceptron() &lt;/strong&gt;来将它们组合在一起。如下是完整的例子。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicsPeIvLZsUJgazZo1ias2IuBsLw6loicYRnj1tu2icZsicHpzNzkOg8UQMiaXHIRjZjMDwm7ZfickCa2jQ/0?wx_fmt=png"/&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicsPeIvLZsUJgazZo1ias2IuuaXykSWI0a7wmb1ch9xpLmqnog2icNTv1mFeicZJYuDJZ95siaP0zVUbw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicsPeIvLZsUJgazZo1ias2IupcDG0JWt0OcqaEK0DP12o6gUU1AY05amW7V5DJnGxBG5jJQrCTzUDg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在交叉验证中，我们取 k 为 3——也就是对每一块数据，都有 208/3 约 70 个记录，会在每次迭代中被用于计算。我们取 0.1 的学习率及 500 的训练迭代次数，来训练模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你可以尝试你自己的参数，并且看看你的结果能否战胜我的分数。运行这个例子，将会显示对 3 倍交叉验证中每一块的分数，以及平均的分类正确率。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们可以看到，这个正确率约为 73%，高于由仅考虑主要类的零规则算法（Zero Rule Algorithm）得到的 50% 的正确率基准值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicsPeIvLZsUJgazZo1ias2Iu66FVpT5THHaNaPYibpuT0p7bQp98MlESvqBiby0FFKVrR256ZfMxAx8g/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;拓展&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这一节列举了关于该入门指导的拓展内容，你可以考虑深入探究其中的一些内容。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;调试样例参数。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;尝试着去调整包括学习率、迭代次数乃至于数据预处理的方法，以使模型在该数据集上，得到更高的分数。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;批量化进行随机梯度下降。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;修改随机梯度下降的算法，使得我们能记录下每一次迭代的更新值，并且在迭代结束的时候再基于记录的更新值来更新权重值。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;额外的分类问题。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;将文中提到的技巧，应用于 UCI 机器学习数据集中其他数据。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;回顾&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在该教程中，你学习了如何从零开始，用 Python 实现，基于随机梯度下降的感知器算法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你学会了：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如何对一个二元分类问题进行预测。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如何使用随机梯度下降，对一系列的权重值进行最优化。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如何将这个技巧，应用到一个实际的分类预测模型。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Mon, 07 Nov 2016 14:44:05 +0800</pubDate>
    </item>
  </channel>
</rss>
