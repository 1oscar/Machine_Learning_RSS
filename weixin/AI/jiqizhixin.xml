<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>机器之心</title>
    <link>http://www.iwgc.cn/list/670</link>
    <description>人与科技的美好关系</description>
    <item>
      <title>专访 | 顶级语音专家、MSR首席研究员俞栋：语音识别的四大前沿研究</title>
      <link>http://www.iwgc.cn/link/3299917</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心原创&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;记者：老红&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;编辑：吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;9 月中旬，微软报告了在语音识别方面取得的新里程碑：&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719135&amp;amp;idx=1&amp;amp;sn=012d179f83a6c3b38c6e58b4ac9ba82f&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719135&amp;amp;idx=1&amp;amp;sn=012d179f83a6c3b38c6e58b4ac9ba82f&amp;amp;scene=21#wechat_redirect"&gt;新系统的识别词错率降至 6.3%&lt;/a&gt;；一个月后，微软又公布了在这一领域成功实现了历史性突破：&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719843&amp;amp;idx=1&amp;amp;sn=0c6387d422cf9765b9b10c178d160680&amp;amp;chksm=871b021db06c8b0b0b0447124c5c07818f53a17ba470305049af1d7d49806c87e07307a93811&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719843&amp;amp;idx=1&amp;amp;sn=0c6387d422cf9765b9b10c178d160680&amp;amp;chksm=871b021db06c8b0b0b0447124c5c07818f53a17ba470305049af1d7d49806c87e07307a93811&amp;amp;scene=21#wechat_redirect"&gt;他们的语音识别系统实现了和专业转录员相当甚至更低的词错率（WER），达到了 5.9%&lt;/a&gt;！机器之心在此期间曾对&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719843&amp;amp;idx=2&amp;amp;sn=4611f810734df8a72286567e90c65a92&amp;amp;chksm=871b021db06c8b0b283ac93f267d95365392be02b3cde5d2fe6df85b359aa96368f25318e2f5&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719843&amp;amp;idx=2&amp;amp;sn=4611f810734df8a72286567e90c65a92&amp;amp;chksm=871b021db06c8b0b283ac93f267d95365392be02b3cde5d2fe6df85b359aa96368f25318e2f5&amp;amp;scene=21#wechat_redirect"&gt;微软首席语音科学家黄学东进行了专访&lt;/a&gt;，探讨了这一连串突破性背后的技术和语音识别领域未来的可能性。近日，机器之心又对微软研究院首席研究员俞栋进行了一次独家专访，谈论了深度学习与语音识别相辅相成的发展以及相关领域的现状和未来。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;俞栋简介&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：1998 年加入微软公司，现任微软研究院首席研究员，兼任浙江大学兼职教授和中科大客座教授。语音识别和深度学习方向的资深专家，出版了两本专著，发表了 160 多篇论文，是 60 余项专利的发明人及深度学习开源软件 CNTK 的发起人和主要作者之一。曾获 2013 年 IEEE 信号处理协会最佳论文奖。现担任 IEEE 语音语言处理专业委员会委员，曾担任 IEEE/ACM 音频、语音及语言处理汇刊、IEEE 信号处理杂志等期刊的编委。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;以下是此次专访的内容：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：请俞老师先给我们的读者介绍一下目前语音识别方面最值得关注的一些方向。&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;俞栋&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：在安静环境下并使用近距麦克风的场合，语音识别的识别率已越过了实用的门槛；但是在某些场景下效果还不是那么好，这就是我们这个领域的 frontier。现在大家主攻几点：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;首先，是不是能够进一步提升在远场识别尤其是有人声干扰情况下的识别率&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。目前一般远场识别的错误率是近场识别错误率的两倍左右，所以在很多情况下语音识别系统还不尽如人意。远场识别至少目前还不能单靠后端的模型加强来解决。现在大家的研究集中在结合多通道信号处理（例如麦克风阵列）和后端处理从拾音源头到识别系统全程优化来增强整个系统的 表现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;另外，大家还在研究更好的识别算法&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。这个「更好」有几个方面：一个方面是能不能更简单。现在的模型训练过程还是比较复杂的，需要经过很多步骤。如果没有 HTK 和 Kaldi 这样的开源软件和 recipe 的话，很多团队都要用很长时间才能搭建一个还 OK 的系统即使 DNN 的使用已经大幅降低了门槛。现在因为有了开源软件和 recipe，包括像 CNTK 这样的深度学习工具包，事情已经容易多了，但还有继续简化的空间。这方面有很多的工作正在做，包括如何才能不需要 alignment 、或者不需要 dictionary。现在的研究主要还是基于 end-to-end 的方法，就是把中间的一些以前需要人工做的步骤或者需要预处理的部分去掉。虽然目前效果还不能超越传统的 hybrid system，但是已经接近 hybrid system 的 performance 了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;另外一个方面，最近的几年里大家已经从一开始使用简单的 DNN 发展到了后来相对复杂的 LSTM 和 Deep CNN 这样的模型&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。但在很多情况下这些模型表现得还不够好。所以一个研究方向是寻找一些特殊的网络结构能够把我们想要 model 的那些东西都放在里面。我们之前做过一些尝试，比如说人在跟另外一个人对话的过程中，他会一直做 prediction，这个 prediction 包括很多东西，不单是包括你下一句想要说什么话，还包括根据你的口音来判断你下面说的话会是怎样等等。我们曾尝试把这些现象建在模型里以期提升识别性能。很多的研究人员也在往这个方向走。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;还有一个方向是快速自适应的方法—就是快速的不需要人工干预的自适应方法（unsupervised adaptation）&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。现在虽然已经有一些自适应的算法了，但是它们相对来说自适应的速度比较慢，或者需要较多的数据。有没有办法做到更快的自适应？就好像第一次跟一个口音很重的人说话的时候，你可能开始听不懂，但两三句话后你就可以听懂了。大家也在寻找像这种非常快还能够保证良好性能的自适应方法。快速自适应从实用的角度来讲还是蛮重要的。因为自适应确实在很多情况下能够提升识别率。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从识别来讲，我觉得目前主要是这些方向。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：Google DeepMind 最近提出了一种通过学习合成波形的方式生成语音的技术 WaveNet，据说可以生成感觉更自然的语音，微软在这方面有什么研究项目？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;俞栋&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：微软也在做类似的工作，但是因为合成的研究团队和工程团队都在中国，我对他们具体到哪个地步不是特别清楚。有一些信息我也不能直接披露，所以就不详细讲了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：深度学习已经在语音识别得到了非常出色的表现，您觉得未来语音识别还能在深度学习的哪些方面实现突破？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;俞栋&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：刚才我讲了，其中的一个可能性就是通过各种类型的 prediction 和 adaptation 使得深度学习模型表现更出色，这是有可能继续提升的地方。另外就是 end-to-end 建模。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;还有，像我们最近也在做一些特殊环境中的语音识别，比如说在高噪音环境下、或者你说话的时候有背景的音乐、或者是会议室里面有多个人同时说话——这些情况下现在的语音识别效果是很差的。所以我们也在研究如何用深度学习的方法在比如多说话人的情况下做得比原来传统的方法好。我们现在已经在 arXiv 上面发布了一个早期结果的预印本（Permutation Invariant Training of Deep Models for Speaker-Independent Multi-talker Speech Separation），含有更多实验结果的正式版本现在正在审稿中。我们的这一称为 Permutation Invariant Training 的方法主要用于语音分离。用这种方法整个 process 比较简单而效果很好。在这些方面深度学习都能带来一定的突破。当然，我前面也讲了，完全解决这些问题需要软硬结合，从拾音到前端和后端需要系统性优化。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：在类似汉语这种多音字、多音词比较多的语言中，语音识别方面有什么和英语这样的拼音语言不一样的地方？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;俞栋&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：从语音识别的技术角度来讲，没有太大的区别。因为你最终都是将语音信号，即 waveform sequence，变成字或者词的 sequence。多音字和多音词只是词表里对应的字或词有多个发音规则而已，这在其他语言比如英语中也很常见。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不过中文是一个有音调的语言，音调对字和词的识别是有影响的。音调信息如果用好的话，就有可能提升识别率。不过大家发现 deep learning 模型有很强的非线性映射功能，很多音调里的信息可以被模型自动学到，不需要特别处理。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;唯一可能不一样的地方是如果你用 end-to-end system，建模单元会不一样。因为在英语里面你一般会选用字母、音素、或音节 作为建模单元，而不会选用词作为建模单元。但在中文里面你可以直接用汉字作为建模单元。所以建模单元的选择上可能会不太一样。除此之外，基本上没有太大区别。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：技术上没有太大区别？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;俞栋&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：没有太大区别。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：具体来说，您觉得自然语言处理能够给语音识别带来哪些帮助？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;俞栋&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：目前来讲，自然语言处理对语音识别本身的帮助还不是很大。要说帮助比较大的方面——如果语言模型（language model）算做自然语言处理的话，语言模型还是起到了很大作用的，尤其是在有噪音的环境下，如果没有语言模型来做约束，效果一般来说都比较差。但是除此之外，现在的 NLP 技术对语音识别没有起到很大的作用。大家尝试过很多用自然语言处理技术提升识别率的方法，但效果都不理想。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是理论上来讲它应该是可以起到作用的。因为我们理解句子含义，我们能发现有一些语音识别结果是不 make sense 的，比如说前面的主语跟后面的宾语根本就不搭，在这种情况下识别系统应该选择其他的 hypothesis，对话系统则应该寻求澄清，但是现有系统没有这么做。没有这么做的原因在于它其实不理解到底用户说了什么，也没能充分利用远距离的 dependency 信息。这样的错误，有可能通过自然语言处理的技术发现并得到更正。但是语义分析是个很困难的问题，如何做还是一个未知数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：刚才我们讲到在噪音环境下，包括远距离环境下的识别，除了这个，还有多个说话人一起说话的情况下的语音识别。在这三个方面，您觉得现在和未来可以通过什么样的方式来解决这个问题？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;俞栋&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：前面提到过，解决远距离识别很重要的一点是需要硬件的支持。至少以目前的技术，仅仅通过后端处理效果还不够好。因为信号在传输的过程中衰减很厉害，距离越远衰减越厉害，信噪比就越差。所以远距离识别一般都需要做增强。比较好的增强需要硬件支持，比如说麦克风阵列。深度学习方法也能提供一些帮助。当你有多通道信息的时候，深度学习方法还可以做自动的信息融合以提升远距离语音识别的性能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;多通道信号处理，比如麦克风阵列，对分离含噪语音和多人混合语音也至关重要。另外，深度学习方法比如我刚才提到的 Permutation Invariant 训练方法也可以解决一部分语音分离问题，是整体解决方案中的重要一环。分离后的结果可以送到后端做识别。后端的识别结果反馈回来也能帮助提升分离和说话人跟踪的效果。所以最终的系统应该是前端的分离跟后端的识别融合互助的系统。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：从您和邓力老师的那本书《Automatic Speech Recognition： A Deep Learning Approach》出版到现在，您认为期间深度学习有了什么新的研究成果? 哪些研究成果您认为是很重大的？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;俞栋&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：我们写这本书的时候，LSTM 这样的模型才刚刚开始成功应用于语音识别。当时大家对其中的很多 技巧 还没有很好的了解。所以训练出来的模型效果还不是那么好。最近，我的同事 Jasha Droppo 博士花了很多时间在 LSTM 模型上面，提出了一种很有意思的基于 smoothing 的 regularization 方法使得 LSTM 模型的性能有了很大的提升。他的 smoothing 方法的基本思想在我们的 human parity 文章中有介绍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外一个比较大的进展是 Deep CNN。最近两年里，很多研究组都发现或证实使用小 Kernel 的 Deep CNN 比我们之前在书里面提到的使用大 kernel 的 CNN 方法效果更好。Deep CNN 跟 LSTM 比有一个好处。用 LSTM 的话，一般你需要用双向的 LSTM 效果才比较好。但是双向 LSTM 会引入很长的时延，因为必须要在整个句子说完之后，识别才能开始。而 Deep CNN 的时延相对短很多，所以在实时系统里面我们会更倾向于用 Deep CNN 而不是双向 LSTM。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;还有就是端到端的训练方式也是在我们的书完成后才取得进展的。这方面现在大家的研究工作主要集中在两类模型上。一类就是 CTC 模型，包括 Johns Hopkins 大学的 Dan Povey 博士从 CTC 发展出来的 lattice-free MMI；还有一类是 attention-based sequence to sequence model。这些模型在我们的书里面都没有描述，因为当时还没有做成功。即便今天它们的表现也还是比 hybrid model 逊色，训练的稳定性也更差，但是这些模型有比较大的 potential。如果继续研究有可能取得突破。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外一个进展是单通道语音分离，尤其是多人混合语音的分离。这方面有两项有趣的工作。一个是 MERL 的 John Hershey 博士提出的 Deep Clustering 方法，另外一个是我们提出的 Permutation Invariant Training。实现上，Permutation Invariant Training 更简单。John Hershey 认为有迹象表明 deep clustering 是 permutation invariant training 的一个特例。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些都是在我们完书之后最近两年里比较有意义的进展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：也是在这个月，Google 发了神经网络翻译系统（GNMT），您对这个系统有什么看法？微软在这方面有没有这样的研究？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;俞栋&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：微软很早以前就在做类似的工作了。你可能知道微软有个基于文本的翻译系统，在 Skype 上也有一个 speech to speech translation system。在这些系统里我们已经用到了 neural machine translation 的一些东西。不过翻译主要是由另外的团队在做，我在这里面涉及比较少。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：语音特征参数提取与鲁棒性语音识别与合成的关键因素，特征参数在不利的噪声环境下，鲁棒性都会急剧下降。目前有什么新的研究可以在特征提取中保持语音信号的最重要参数吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;俞栋&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：目前，一个方法是用信号处理技术对输入信号进行分离和增强。另一个方法是用 deep learning 取代人工从 waveform 直接提取特征。只要训练数据的 coverage 足够大，各种各样场景的训练数据都有，模型的结构设计合理，那么模型的泛化能力和鲁棒性就能得到提升。两种方式结合可以得到更好结果。不过，泛化是机器学习的一个未解决的基本问题，更好的解决方案有待于机器学习理论的进展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：微软在语音识别上如何解决方言带来的口音问题，比如说「le」和「ne」？针对方言，微软的语料库是从何而来的？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;俞栋&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：一个简单的方法是增加带口音的训练语料。如何有效利用这些语料有些讲究。大概 3、4 年前，我们发过一篇文章，研究怎么样在 deep learning model 上做自适应。带口音的识别问题可以看作一个自适应的问题。假设你已经有标准语音的模型，带口音的语音可以看成标准语音的某种偏离。所以我们的解决方法是做自适应。做自适应的时候，我们可以把有类似口音的语料聚合在一起以增加训练数据。我们发现这样做效果挺不错。如果已经有系统上线，收集带口音的语料并不困难。如果你用过 Windows Phone，你就知道 Windows Phone 的 Cortana 里面有个选项——你想用标准的识别模型还是想用含口音的模型？用户可以选择。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：今年，微软发布了 CNTK。您能说一下 CNTK 跟 Theano、TensorFlow、Torch、Caffe 这些工具的区别吗？以及在微软语音系统上是怎么样应用 CNTK 的？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;俞栋&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：所有的这些开源工具现在都做得相当好了，都能够满足一般的研究或者是工程的需要。但是每一个开源工具都有自己的长处和弱点。CNTK 是唯一一个对 Windows 和 Linux 都有比较好的支持的深度学习工具。相比较其他工具，CNTK 对多 GPU 并行训练有更好的支持, 不仅并行效率高，而且简单易用。CNTK 对 C++的支持也是最全面的，你可以完全使用 C++来构建、训练、修改、和解码模型。CNTK 版本 1 对 Python binding 支持比较弱。但是刚刚发布的版本 2.0 提供了非常强大的 Python binding。另外，CNTK 提供了许多运行效率很高的并行文件阅读模块，大大提升了并行效率。这里我想提一下，我的很多同事都对 CNTK 2.0 有很大贡献。尤其值得一提的是 Amit Agarwal，他是我见过的非常难得的优秀软件工程师和架构师，他主导设计了 CNTK2.0 的主要 API。我在他身上学到很多东西，我非常享受与他讨论的时间。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我和几个同事刚开始写 CNTK1.0 的时候，主要用户是语音识别研究员和工程师，所以 CNTK 对语音相关的模型、数据结构、和文件格式支持得相对比较好。因为语音识别系统训练数据很大，我们很早就在 CNTK 中实现了并行训练的算法。目前，微软产品线所有的语音识别模型都是用 CNTK 训练的。最近我们的语音识别系统在 SWB 数据集上能做到比专业转录员错误率还低，CNTK 对缩短我们达到这一里程碑所需的时间有很大贡献。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：您曾说过，人工智能的成功在于将多种方法的整合到一个系统。在你们最近发表的论文中，我们看到目前最新的语音识别的研究用到了多任务优化（Multitask Joint learning）以及多种模型混合（ensembles of models）的方法，能谈谈他们的优势吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;俞栋：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;语音识别相对来说是一个任务比较单一而非通用的人工智能系统。语音识别的问题定义得也比较清晰。在这样的系统里面，把深度学习模型与其他模型进行整合的重要性相对来说比较小。这也就是为什么只要你有足够的数据和运算能力，即便是完全的 deep learning end-to-end system 表现也不错。不过目前来讲，深度学习和 HMM 相结合的混合模型在大多数场景下仍然表现最佳。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;语音识别中使用多任务优化的主要目的是增加模型的泛化能力或利用一些不能直接利用的辅助信息。而多种模型混合（ensembles of models）的主要目的是利用模型间的差异来增强混合后模型的表现。值得指出的是，由于深度学习模型是非线性非凸的优化问题，当初始模型不同时，最后的模型也不同。尽管这些模型的平均表现很接近，但因为他们收敛到的点不一样，模型之间仍有差异，融合这些模型也能提升一些性能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是更通用的人工智能系统还需要能做决策（decision-making）、要做推理、要能理解。对于这样的系统来说，单靠深度学习方法远远不够。而需要结合过去几十年里人工智能其他分支取得的一些进展，比如说增强学习、逻辑推理、知识表达、以及最优和次优搜索。还有如果我们想让一群人工智能系统自己从与环境的交互中快速寻找答案，那么诸如蚁群算法和遗传算法一类的算法就变得很重要了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：今年您觉得在语音识别方面有哪些比较重量级的论文值得去读，能否推荐几个给我们的读者？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;俞栋&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：除了前面提到的 LF-MMI 、 Deep CNN（包括我们最近发表的 LACE 模型）、和 Permutation Invariant Training，另外一个比较有意思的论文是 MERL 在 arXiv 上发表的一篇文章。他们结合了 CTC 和 attention-based model，利用这两个模型各自的长处来克服对方的弱点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;	&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：您是怎么看待监督学习、半监督学习和无监督学习这三个学习方式呢？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;俞栋&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：监督学习是比较 well-defined，有比较明确的任务。目前来讲，深度学习对这一类问题 效果比较好。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;无监督学习的目的是要寻找数据中的潜在规律。很多情况下，它试图寻找某种特征变换和相对应的生成模型来表达原始数据。但无监督学习不仅本身困难，对无监督学习系统的评价也很难。原因是通过无监督学习找到的规律不一定对你将来的任务有帮助，或者它对某一任务有帮助，换一个 任务就没有帮助了。当然，如果你的目标仅仅是数据压缩，评价还是容易的，但我们使用无监督学习压缩本身往往不是主要目的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：那半监督学习呢？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;俞栋&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：半监督学习介于两者中间。因为你已经有一部分标注信息了，所以你 的任务是明确的，不存在不知如何评估的问题。半监督学习在实用系统里还是有一定作用的。比如说我们需要标注大量数据来训练语音识别系统，但人工标注既花时间又花钱，所以你往往有比标注数据多得多的未标注数据。没有标注过的数据，也有很多可以利用的信息，虽然它们的价值远远小于标注的数据。半监督学习对我们的系统性能有一定的提升。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：最后一个问题，在整个人工智能的布局上，您认为语音识别是一个怎样的定位？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;俞栋：在很多应用场合，语音识别是一个入口。没有这个入口的话，大家都会觉得这个智能机器不够智能或者与这个智能机器交互会有困难。人机交互中语音识别是第一步。如果语音识别做得不够好，那后期的自然语言理解等的错误率就会大幅上升。这也是为什么语音到语音的翻译要比文本到文本的翻译难很多，因为在语音对语音的翻译系统里语音识别产生的错误会在后面翻译的过程中放大。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;历史上，语音识别也为机器学习和人工智能提供了很多新的方法和解决方案。比如语音识别里的关键模型 Hidden Markov Model 对后来机器学习的很多分支都有帮助。深度学习也是先在语音识别上取得成功，然后才在图像识别和其他领域取得成功的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8G2Aqj8cfARvWSIzEs1ZXZgT6VrNdsVA4icyCrL6lqQtv3wPx1Ij2rZn8odibiaN7LBAPnqsPNXxteg/0?wx_fmt=jpeg"/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;专访 | 微软人物志 &lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650714822&amp;amp;idx=1&amp;amp;sn=e56ee226cdacab228e1ad9fc40646adf&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650714822&amp;amp;idx=1&amp;amp;sn=e56ee226cdacab228e1ad9fc40646adf&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;微软研究院人工智能首席科学家 | &lt;/span&gt;&lt;span&gt;邓力&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719843&amp;amp;idx=2&amp;amp;sn=4611f810734df8a72286567e90c65a92&amp;amp;chksm=871b021db06c8b0b283ac93f267d95365392be02b3cde5d2fe6df85b359aa96368f25318e2f5&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719843&amp;amp;idx=2&amp;amp;sn=4611f810734df8a72286567e90c65a92&amp;amp;chksm=871b021db06c8b0b283ac93f267d95365392be02b3cde5d2fe6df85b359aa96368f25318e2f5&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;&lt;span&gt;微软首席语音科学家 | &lt;/span&gt;黄学东&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=400579280&amp;amp;idx=1&amp;amp;sn=b13556c48c2937593ee833e8284f2c89&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=400579280&amp;amp;idx=1&amp;amp;sn=b13556c48c2937593ee833e8284f2c89&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;微软亚洲研究院院长 | 洪小文&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=401882267&amp;amp;idx=1&amp;amp;sn=eb5a4cf6e10b6dc3787303f421a8f77b&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=401882267&amp;amp;idx=1&amp;amp;sn=eb5a4cf6e10b6dc3787303f421a8f77b&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;微软（亚洲）互联网工程院院长 | 王永东&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650714905&amp;amp;idx=2&amp;amp;sn=ad19a7e003ecdb48b0ffc524e8c2c94b&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650714905&amp;amp;idx=2&amp;amp;sn=ad19a7e003ecdb48b0ffc524e8c2c94b&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;微软亚洲研究院首席研究员 | 霍强&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;strong&gt;机器之心&lt;/strong&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8G2Aqj8cfARvWSIzEs1ZXZ248wIRLFyLjemC1oeWWd1em6qPOfHVREYUvcibiamyGHjAkDJH7mOC4w/0?wx_fmt=jpeg"/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;</description>
      <pubDate>Mon, 31 Oct 2016 12:46:20 +0800</pubDate>
    </item>
    <item>
      <title>学界 | CMU全新编码器解-码器框架：一种用于描述生成的Review Network（附项目地址）</title>
      <link>http://www.iwgc.cn/link/3299918</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;选自GitHub&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：杜夏德&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;卡耐基梅隆大学提出了一种新的编码器-解码器框架 —— review network，该框架在提升图像和源代码描述的任务上超过了现有其他最先进的系统。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们提出了一种编码器-解码器框架的新扩展，叫review network。这种 review network是通用的，能够增强任意现有的编码器-解码器模型：在这篇论文中，我们探讨了带有CNN和RNN编码器的RNN解码器。该review network在编码器隐藏状态下执行一些review步骤，并在每一次review后输出一个 thought vector；这些 thought vectors 在解码器中被用作注意力机制（attention machine）的输入。我们发现在我们的框架中，卷积的编码-解码器是一个特例。经过实证，我们发现我们的框架在提升图像和源代码描述的任务上超过了目前所有最先进的编码器-解码器系统。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;项目地址：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt; https://github.com/kimiyoung/review_net&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;用于描述生成的 R&lt;span&gt;eview Network&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;在 MSCOCO 上给图像添加描述&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你可以在这个 repo 中使用这个代码来生成一个 MSCOCO 评估服务器（CIDE.r=0.96+), 这个过程需要几个小时。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;无需微调，没有花哨的技巧。仅训练三个端到端的 &lt;span&gt;review network&lt;/span&gt;，然后做一个集成：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;特征提取：并行 2 小时&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;单一模型训练：6 小时&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;集成模型训练：30 分钟&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;描述生成的波束搜索：并行 3 小时&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面是我们的系统在 MSCOCO 评估服务器上与其他先进系统的比较（根据已发表的论文）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;th&gt;Model&lt;/th&gt;&lt;th&gt;BLEU-4&lt;/th&gt;&lt;th&gt;METEOR&lt;/th&gt;&lt;th&gt;ROUGE-L&lt;/th&gt;&lt;th&gt;CIDEr&lt;/th&gt;&lt;th&gt;Fine-tuned&lt;/th&gt;&lt;th width="79"&gt;Task specific features&lt;/th&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;Attention&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.537&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.322&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.654&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.893&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;No&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="79"&gt;No&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;MS Research&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.567&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.331&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.662&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.925&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;No&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="79"&gt;Yes&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;Google NIC&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.587&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.346&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.682&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.946&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;Yes&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="79"&gt;No&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;Semantic Attention&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.599&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.335&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.682&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.958&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;No&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="79"&gt;Yes&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;Review Net&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.597&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.347&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.686&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.969&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;No&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="79"&gt;No&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 image_caption_online 目录下，你可以使用里面的代码重现我们的评估服务器的结果。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 image_caption_offline 目录下，你可以使用离线评估重新运行我们论文中的实验。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;添加代码描述&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一个有趣的任务是预测一条源代码的注释。在这个 repo 中，除了一个&lt;span&gt;review network&lt;/span&gt;的代码外，我们也开放了一个带有 train/dev/test 分类的数据集。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;查看 code_caption 目录。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面是我们的框架系统在代码描述数据集上与基线的比较。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;th&gt;Model&lt;/th&gt;&lt;th&gt;LLH&lt;/th&gt;&lt;th&gt;CS-1&lt;/th&gt;&lt;th&gt;CS-2&lt;/th&gt;&lt;th&gt;CS-3&lt;/th&gt;&lt;th&gt;CS-4&lt;/th&gt;&lt;th&gt;CS-5&lt;/th&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;LSTM Language Model&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;-5.34&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.234&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.2763&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.3&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.3153&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.329&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;Encoder-Decoder&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;-5.25&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.2535&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.2976&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.3201&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.3367&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.3507&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;Encoder-Decoder (Bidir)&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;-5.19&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.2632&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.3068&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.329&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.3442&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.357&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;Attentive Encoder-Decoder (Bidir)&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;-5.14&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.2716&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.3152&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.3364&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.3523&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.3651&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;Review Net&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;-5.06&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.2889&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.3361&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.3579&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.3731&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.384&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;参考文献：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;用于描述生成的review networks（Review Networks for Caption Generation），&lt;/span&gt;&lt;span&gt;这个 repo 中包含的代码和数据可在这篇论文中找到。（点击「阅读原文」下载论文）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Mon, 31 Oct 2016 12:46:20 +0800</pubDate>
    </item>
    <item>
      <title>学界 | Yoshua Bengio最新论文：一种用于训练循环网络的新算法Professor Forcing（附论文）</title>
      <link>http://www.iwgc.cn/link/3299919</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;选自arXiv&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9I0lJy7h7Z6eSXUB9HJUgibXwlVb7BOrFvyibhww67kZd61G4ptL1icZ5htQ9Ako7VJI7CmVSP6M35A/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：&lt;/span&gt;&lt;span&gt;Teacher Forcing 算法通过将被观察到的序列值作为训练过程中的输入和使用该网络自己的提前一步的预测（one-step-ahead predictions）来进行多步采样（multi-step sampling）。我们在这里介绍 Professor Forcing 算法，其使用了对抗域适应（adversarial domain adaptation）来促进训练网络的动态（dynamics）在训练网络时和从网络中进行多个时间步骤的采样时一样。我们将 Professor Forcing 应用到了语言建模、在原始波形的声音合成、手写生成和图像生成上。我们的实验表明 Professor Forcing 可用作正则化器（regularizer），其能提升在字符级 Penn Treebank 和序列的 MNIST 上的测试似然（test likelihood）。我们还发现该模型可以定性地改进样本，尤其是当要进行大量时间步骤的采样时。这也得到了人类对样本质量的评估的支持。我们讨论了 Professor Forcing 和 Scheduled Sampling 之间的权衡。我们产生了 T-SNE，表明 Professor Forcing 能成功使训练过程和采样过程中的网络动态更为相似。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9I0lJy7h7Z6eSXUB9HJUgib5mmYZBS2bWmK8KVDBwggWibz0OwMILCsJq2Bpq61d64FWdIkgsfZ4dQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 ：Teacher Forcing（左）和 Professor Forcing（右）的样本&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Mon, 31 Oct 2016 12:46:20 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 智能技术+电力驱动：曾被巨头们垄断的汽车业正迎来变革</title>
      <link>http://www.iwgc.cn/link/3299920</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;选自TechCrunch&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李泽南、吴攀、蒋思源&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;法国 Mulhouse 的汽车城（Cité de l’ Automobile）是一个神奇的地方。这里有全世界最大的汽车收藏，瑞士兄弟 Hans Schlumpf 与 Fritz Schlumpf 为这里提供了大量藏品。他们将生意赚来的钱用于购买各种汽车，这对兄弟拥有一家纺织厂。有趣的是，他们的姓「Schlumpf」在德语中的意思是蓝精灵，如果你记得《蓝精灵》，在这里你也许会惊呼「Smurftastic!（真是蓝精灵的风格！）」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;由于他们的疯狂收集——以及纺织业中心在 20 世纪 70 年代转向亚洲——兄弟们的债务变得难以偿还，他们最终被迫离开了法国，回到瑞士。在那个时候，他们的汽车收藏已经价值连城，法国政府甚至发布了历史保护法令，让这些收藏免于被毁、拆解或出口，最终在 1978 年，这里被法国国务院认定为历史遗产加以保护。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9I0lJy7h7Z6eSXUB9HJUgibK2HewhPRGjoheEj5NtHm3P8OBanGW8HBmGYKJGmTut3aFKbtjCckvg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Cité de l’Automobile中的汽车长廊&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;几年前，我有幸来到这里参观，这里现在已是世界最大的汽车博物馆了，就像汽车时代的时间胶囊。当你漫步在博物馆的大厅里，身边数百辆各个时代的汽车依次排开，你会发现这些品牌都是由一个「初创」（是的，我想你可以把这个词语用在过去的公司上）阶段开始制造汽车、创立品牌、在市场竞争中获得立足之地。在汽车发展的过程中，马匹再也不是最好的交通工具了，它们最终变成了有钱人的玩具。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一次汽车行业繁荣是由工业革命带来的新技术推动的，这给当时的初创公司提供了机会，以有限的资金来设计和制造他们的第一辆车。举个例子：在二十世纪二十年代，汽车主要是框架车身，这种结构允许不同的供应商分别制造汽车的每一个部分，最终在生产线上将汽车拼装在一起。后来，一体化车身出现了，汽车的制造门槛开始提高，行业开始高度集成——这让大规模的公司变得越来越有竞争力。现在的电动汽车让我们想起了那个框架车身的年代，就像 BMW i3，它拥有固定框架容纳传动系统和电池。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以下这些名字只是 Mulhouse 博物馆馆藏的一部分，如果你认识其中三个以上名字的话，你就是一个汽车专家了：ABC,Amilcar, Arzens, Aster, Ballot, Bardon, Barraco, Barré, Baudier, B.N.C, Bollée, Brasier, Charron, Cisitalia, Clément de Dion, Clément-Bayard, Clément-Panhard, Corre La Licorne, Darracq, Decauville, De Dietrich……&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些上古时代的优秀初创企业并没有遇到其后阻止一切新来者的技术壁垒——内燃式发动机。这是一个被通用、福特、奔驰、丰田、宝马和大众等巨头占据超过 40 年的领域。它的出现让大小厂商之间出现了一道难以逾越的鸿沟，如今，迈凯伦、布加迪和 Lotus 早已无力向这些巨头发起挑战。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当然，现在也有像 DeLorean、Fisker 和 Artega 这样的汽车创业公司，但是提到普通汽车的制造和销售，更不用说维持经销渠道和资金链，大多数人认为这是一个由大规模和纯粹的金融力量主导的游戏。成功地在汽车行业中创建一个新的品牌难度颇大。每个获得资金少于 1 亿美元的企业迟早都会失败。特别是对于投资者来说，这个行业被认为是一个禁区，因为涉及的风险很大、成功率低。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;「我们看到了数量巨大的轿车，商用汽车和其他交通工具的初创企业。」&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这一切都在 2004 年台湾的一个路演中被改变了。有一个人带着他的汽车模型，试图为他的产品募集资金：Tesla Roadster。这辆新车的大多数零件都来自于这个两千三百万人口的岛屿，台湾以提供世界 80% 的 PC 与笔记本电脑闻名于世，提供 iPhone 和其他手机的几乎所有芯片。这些制造商里不乏知名企业，包括富士康、和硕联科和纬创。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 2006 年初代特斯拉发布的时候，它的发动机就是在台湾生产的。伊隆 ·马斯克在所有人之前认识到，科技和汽车世界中，初创阶段没有区别。他获得了初始投资并开始大胆展望——没有听从那些专家的意见。特斯拉在 2009 年之间实现融资 1.8 亿美元，卖出了 147 辆汽车。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9I0lJy7h7Z6eSXUB9HJUgibR75lEFCwjt86FS7ffScZTmbQgfcJxRPUqaHK3IHWcC9ODzklxY7zpg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;em&gt;&lt;span&gt;特斯拉 Roadster，第一辆可以跑上公路的锂电池纯电动汽车&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;几年以后，数十亿美元的资金涌入特斯拉，世界看到了特斯拉能够做到其他公司想都不敢想的——向汽车工业发起进攻。因为计算机的力量，革新开始出现，故事进入了「创业者困境」的又一个章节，这一阶段就像哈佛大学教授 Clayton Chrstensen 说到的，新技术会让旧的巨头分崩离析。更重要的是，奥迪、宝马、丰田和奔驰等现在的大公司们已经开始紧张起来，认真对待电动汽车及其技术了。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;金融和技术上的壁垒已被打破。风险资本的世界对这些机遇感到兴奋，并且已经开始向这一行业投资。过去五年里，这一领域内的并购交易已经增长了超过 2200 亿美元。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;基于高度复杂生产技术（例如内燃机）的进入壁垒将会被抹平。电动机开始成为主流。比如说，电动传动现在可以外包给 Magna 这样的公司，它也许最终会成为这一领域的富士康。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但更重要的是特斯拉在机器学习上的独特优势，而且其在传统技术（内燃技术、未连接的汽车）的根基缺乏反倒让它能够先于对手进入这个规模更大、增长更快的市场。这种做法将会将没有连接和计算机的传统模式转变成拥有自主性、共享交通、乃至最终的按需用车的自主交通（Autopia-on-demand autonomous mobility）的模式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们正看到有很多想要创造新式汽车、商用载具和其它交通方式的创业公司涌现出来，其中包括：NextEV, Atieva, ThunderPower, Gogoro, Navya, Borgward, Local Motors, ZMP, Faraday Future, Starship, Varden Labs, Easy Mile, Auro Robotics, Gaius, LeEco（乐视超级汽车）, Dyson, Mission Motors, Boosted, Lit Motors,Renovo Motors, Inboard Technology, Future Motion, GLM, Dubuc Motors, Dagmy Motors, Newton Vehicles, ALTe Technologies, Lumen Motors, Barham Motors, Highlands Power, Myers Motors , Tratus, Virtus Motors, AC Motors, Scalar Automotive, Fenix Vehicles, Marfil, Esco Motors, Lithos Motors。我预计在未来几年内，还会有另外几百家公司出现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;如果不久的将来你看到有红牛牌汽车在路上行驶，不要感到惊讶。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;即使最创新的交通概念也会需要载具。和今天的载具相比，它们可能会有不同的构成因素，即是由不同的材料制成的、有不同的驱动方式和不同的控制方式。但总有人要去开发、制造、销售、维护和保护这些载具。如果一些参数像我们描述的那样发生了改变，现有的汽车制造商仍然还有随时间进行调整的能力。它们有获得利润的知识和流程，仍然能生产出复杂的、持久的和以安全为重的产品，而且它们知道怎么将其规模化。除此之外，它们已经有自己的品牌、声望和客户忠诚度了，这些都将能持续一段时间。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在特定一段时间内，主要的品牌将具有优势。动作快和资金充裕的新进入者也是如此。我们还有可能会看到专注于某些特定交通领域的品牌和公司出现。未来的许多进展都将基于现在尚没有答案的问题，比如新载具将会如何使用、城市和农村地区的交通如何分离、电动载具和自动化技术发展会有多快、人们会怎样接受、监管会帮助推进发展还是会拖后腿。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在汽车领域，消费者仍然会看重一些品牌的价值。保时捷这样的高端品牌就能够从这种价值受益，因此很可能不会受到像大众市场品牌那样大的影响。汽车的品牌将会有新有旧，就像大众甲壳虫的 Fender、Mini 的 Paul Smith、菲亚特 500 的 Gucci 等等。如果不久的将来你看到有红牛牌汽车在路上行驶，不要感到惊讶。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此外，即使汽车交通变得更加智能和更廉价，品牌也仍有它们的一席之地。即使 easyJet、维珍和瑞安等一些低成本的航空公司也具有自己的定位品牌。在航空业，旅客所选择的受欢迎的品牌是服务提供商（航空公司），而非载具（飞机）的制造商。我们可以想象在汽车行业和航空业之间存在一定的相似性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;还记得在 Cité de l’ Automobile 上展出的汽车公司列表吗？创业公司来了又去，只在博物馆里留下了一点遗迹。同样地，显然未来几年后前面所提到的一些汽车公司可能就已经不在了——但其中一些肯定会成为我们日常出行的主要装置。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现如今有很多新的品牌和新的想法进入这个庞大的交通运载市场（麦肯锡估值 6.4 万亿美元），并且它们并不仅仅是在制造汽车，更是在发展一个实现交通互联的新方式，这个新方式将能减少交通事故、加强道路安全、等等更多的提升。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一段时间之后，像 Schlumpf 兄弟那样的博物馆将陈列的是我们今天所熟知的汽车品牌。我很期待能有收藏者将这些新型汽车（最终的载具）都搜集到一起，并创建一个博物馆。这并不简单，但会给我们的后代带来很大的乐趣。历史总会不断重复。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Mon, 31 Oct 2016 12:46:20 +0800</pubDate>
    </item>
    <item>
      <title>思想 | 智能的终极命题：宇宙级的融合心智即是上帝本身</title>
      <link>http://www.iwgc.cn/link/3299921</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;选自科学美国人&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：&lt;span&gt; Freeman Dyson&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：曹瑞&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;「科学神学」思考的是心智的最终目的。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;科学神学家 Freeman Dyson 在评论智能的长远发展时说道：「我并没有在心智（mind）和上帝（God）之间划出明显的界限。心智在超出我们理解的范围之外时就会成为上帝。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9I0lJy7h7Z6eSXUB9HJUgibuJoMUp2lzw7aIRPDrV7D61qWXibuIWibRds6UEaCibJAGk0bzTmzJXnWQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这到底是好是坏呢？作为一个头发花白的科学迷，新的事物对我来说都像是老掉牙的了。比如说，在最近的一次人工智能大会上，听着那些聪明人们谈论、思考那些超级智能会想要什么，而对我来说，我一直在思考一些我曾经听过、看过和读过的东西。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;正如一些演讲者所认为的，无数科学幻想中都曾经想象过人工心智想要什么。电影中一些常见的答案有能量（比如说像《2001 太空漫游》、《终结者》、《黑客帝国》）、自由（像是《我，机器人》、《机械姬》），还有爱（斯蒂芬·斯皮尔伯格的《人工智能》、斯派克·琼斯的《她》）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是要是机器既具备能量，又拥有自由（可以说是同等的），还有它们需要的爱，会怎么样呢？或者说如果所有的机器都融合成一个庞大的心智呢？在这个时候，自由、能量和爱这些社会目标就会变得无关紧要。这些宇宙级的计算机到底想要什么呢？它们会做些什么来打发时间呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在《科学的终结》（The End of Science）一书中，我把这种推测叫做「科学神学（scientific theology）」。物理学家 Freeman Dyson 是我最喜欢的实践者。1979 年，他发表了一篇名叫「Time Without End: Physics and Biology in an Open Universe」的论文，对现代物理学进行了评论。Dyson 写这篇论文的目的就是为了反驳另一位物理学家 Steven Weinberg 臭名昭著的观点：「宇宙越难以理解，它就似乎越毫无意义」。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Dyson 反驳道，「没有智能的宇宙是没有意义的」。他试图向大家展示，即使是在一个不断膨胀的宇宙当中，通过精确地能量守恒，智能几乎能够永远坚持下去，防止热寂（heat death）。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在他 1988 年的文集Infinite in All Directions当中，Dyson 展望了智能充满整个宇宙并转化为巨大的宇宙级心智的情景，并问道：「在心智可以知会并且控制宇宙之后会选择做什么呢？」他认为我们不能确切地回答这个问题。因为这个问题涉及的是神学而不是科学：「我没有在心智和上帝之间划分明显的界限，心智在超出我们理解的范围之外时就会成为上帝。上帝可以被认为是一个世界灵魂，或者说是世界灵魂的集合。我们是当前这个星球上神的最主要入口，我们会随着神的成长而成长，要不然我们就会落后」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Dyson 的想法是受到了科幻小说作家（和哲学家）Olaf Stapledon 的影响，Olaf Stapledon 在 1950 年就去世了。在他的两部作品*Last and First Men*和*Starmaker*当中，Stapledon 想象了心智在上百万甚至是上亿年之后会变成怎么样？他假设宇宙心智想要创造。然后它就会成为一个艺术家，它的作品就是整个宇宙。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个想法很酷（这也意味着我们就生活在某个艺术作品当中），但是我还是更喜欢 Dyson 的假设。他猜想，一个宇宙心智不是一个艺术家，而是一个科学家，一个探索知识的人。我在 1993 年采访 Dyson 的时候，他非常有信心地说道对知识的追求的没有尽头的，因为知识是无穷无尽的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他的这种积极的态度部分是从哥德尔定理衍生而来的，每一个公理系统提出的问题都无法用这些公理解答。这条定理也暗示着数学是没有限制的，所以可以永远延续下去。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Dyson 对我说，「因为我们已经知道了物理定律其实是数学上的，而我们也知道数学是一个不相容的系统，所以说我们似乎有理由相信物理也是不相容的」，而且没有限制的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我在最后想象终极宇宙计算机——也就是「上帝」——的时候经历了非常艰难的时期，因为数学和物理问题让我想破了头。我的想法是（诚然是由于毒品的启发）它可以基于自己的来源思考问题。元问题是：它会解决这些玄之又玄的问题吗，还是说会永远被它难住？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;后记：另外还有两位神学家值得一提：物理学家 Frank Tipler，在他 1994 年出版的作品 The Physics of Immortality 中，他认为最终，像上帝一样的机器可以让在网络天堂（cyber-paradise）中幸福生活的每一个生物都能复活。另外一位是 Stanislaw Lem，他在 1961 年的小说《索拉里斯星》（Solaris）当中想象了人类和一个有感知的星球相遇的场景。他认为超智能是难以预测的。他的观点是否定的神学，因为他认为上帝永远都是在我们的理解范围之外的。Lem 非常聪明的一点是，他认为普通的人类心智也是非常难以预测的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Mon, 31 Oct 2016 12:46:20 +0800</pubDate>
    </item>
    <item>
      <title>深度 | 一篇文章带你进入无监督学习：从基本概念到四种实现模型（附论文）</title>
      <link>http://www.iwgc.cn/link/3288864</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Eugenio Culurciello's blog&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Eugenio Culurciello&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李亚洲、武竞&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em style="font-size: 12px;"&gt;这是今年 6 月份普渡大学副教授 Eugenio Culurciello 写的一篇关于无监督学习的概述性文章。除了基本概念，本文还介绍了无监督学习的四种实现模型：&lt;em style="color: rgb(136, 136, 136); text-align: justify; white-space: pre-wrap; font-size: 12px;"&gt;聚类学习、自动编码器、生成模型、PredNet。&lt;/em&gt;前几日，Culurciello 教授根据最近无监督学习的发展对此篇文章进行了更新与调整，机器之心对此进行了编译。文中提到的论文可点击「阅读原文」下载。&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;注：刘帝伟（译者）、刘翔宇（审校）两位老师对 6 月份的版本进行了编译并发布到了 CSDN 极客头条上，此篇编译文章借用了两位老师之前的翻译（有部分调整），如有不允，请联系机器之心，谢谢！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;无监督学习可谓是深度学习的圣杯，其目标是建立可兼容小数据集进行训练的通用系统，即便是很少的数据。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如今深度学习模型往往在大型监督型数据集上训练。所谓监督型数据集，即每条数据都有一个对应的标签。比如流行的 ImageNet 数据集，有一百万张人为标记的图像。一共有 1000 个类，每个类有 1000 张图像。创建这样的数据集需要花费大量的精力，同时也需要很多的时间。现在想象创建一个有 1M 个类的数据集。试想一下，对有 100M 数据帧的视频数据集的每一帧进行分类。该任务量简直不可估量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在，回想一下你在小时候是如何进行学习的。是的，那时候会有人指导你，你的父母会告诉你这是一个「猫」，但是他们不会在你余生的每一分每一秒都告诉你这是一只「猫」！如今的监督学习也是这样：我一次一次地告诉你，什么是「猫」，也许高达 100 万次。然后你的深度学习模型就学会了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;理想情况下，我们希望有一个模型，它的表现与我们的大脑非常相似。只需少量的标签便可理解这个多类的世界。这里所说的类，主要是指对象类、动作类、环境类、对象组成类等等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;基本概念&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;无监督学习研究的主要目标是预训练一个模型（称作「识别」或「编码」）网络，供其他任务使用。编码特征通常能够用到分类任务中：例如在 ImageNet 上训练会表现出很好的结果，这与监督模型非常接近。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;迄今为止，监督模型总是比无监督的预训练模型表现的要好。其主要原因是监督模型对数据集的特性编码的更好。但如果模型运用到其他任务，监督工作是可以减少的。在这方面，希望达到的目标是无监督训练可以提供更一般的特征，用于学习并实现其它任务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;自动编码器（auto-encoders）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该理论主要源于 1996 年 Bruno Olshausen 和 David Field（参见论文：Sparse Coding with an Overcomplete Basis Set：A Strategy Employed by V1）发表的文章。此文表明，编码理论可应用于视觉皮层感受野。他们发现，我们大脑的主要视觉皮层（V1）使用稀疏原理来创建可以用来重建输入图像的最小基函数子集。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;YannLeCun 团队在该领域也做了很多工作。在余下的文章中，你将看到一个很好的例子来解释类似 V1 的稀疏滤波器是如何学习的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;栈式自动编码器也会被用到，以贪婪式的方式逐层重复训练。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;自动编码器方法也被称为「直接映射」方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;自编码器/稀疏编码/堆栈自编码器的优点与缺点&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;优点：&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;简单技术：重建输入&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;可堆栈多层&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;直觉型，且基于神经科学研究&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;缺点：&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;贪婪训练每一层&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;没有全局优化&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;比不上监督学习的表现&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;层一多会失效&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;输入的重建可能不是学习通用表征的理想度量（metric）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;聚类学习（Clustering Learning）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一种技术是使用 K-均值聚类来学习多层的 filters。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们团队将这种技术命名为：聚类学习（参见论文：Clustering Learning for Robotic Vision）、聚类联结（参见论文：An Analysis of the Connections Between Layers of Deep Neural Networks）和卷积聚类（参见论文：Convolutional Clustering for Unsupervised Learning），最近它们在 STL-10 无监督数据集上取得了非常好的结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们在此领域的研究独立于 Adam Coates 和吴恩达（参见论文：Learning Feature Representations with K-means）的研究。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;众所周知，受限玻尔兹曼机（RBMs）、深度玻尔兹曼机（DBMs）、深度信念网络（DBNs）难以训练，因为解决其配分函数（partition function）的数值难题。因此它们还未被普遍用来解决问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;聚类学习的优缺点&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;优点：&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;简单技术：聚类相似输出&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;可被多层堆栈&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;直觉型，且基于神经科学研究&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;缺点：&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;贪婪训练每一层&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;没有全局优化&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;在一些情况下，比不上监督学习的表现&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;层数增加时会失效，收益递减&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;生成模型（generative models）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;生成模型，尝试在同一时间创建一个分类（识别器或编码器）网络和一个生成图像（生成模型）模型。这种方法起源于 Ian Goodfellow 和 Yoshua Bengio（参见论文：Generative Adversarial Networks）的开创性工作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Alec Radford、Luke Metz 和 Soumith Chintala 的 DCGAN（参见论文：Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks）是一种生成对抗模型，实例化这种模型，能够得到很好的结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面是系统框架图：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8G2Aqj8cfARvWSIzEs1ZXZRpNLOtd8REOOanicgibxl0UmwicOicztTk0Liban0BiaVfVEtQTYHkbODnYg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;DCGAN 识别器的目的是识别输入图像是否真实，或来自数据集，或是生成器生成的伪图。该生成器需要一个随机噪声向量（用 1024 个数值表示）作为输入，并产生一个图像。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 DCGAN 中，生成器网络如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8G2Aqj8cfARvWSIzEs1ZXZKjUOHvVzexib3jYSR0CjhrLwsghgOWNdQ1dKwbJljUp08VTiabdjWhTg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;识别器是一个标准的神经网络。详情请见下文。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;关键是以并行的方式训练两个网络而不是完全地过度拟合，从而复制数据集。学习特征需要推广到未知的实例，因此用于学习的数据集将不能再用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Torch7 提供了 DCGAN 训练代码（代码地址&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt;https://github.com/soumith/dcgan.torch），&lt;/span&gt;&lt;span&gt;可用于实验中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在生成器和识别器网络训练好之后，两者便可使用了。主要目标是为其它任务训练一个很好的识别器网络，例如对其它数据集进行分类。生成器则可用于生成随机向量的图像。这些图像有着非常有趣的特性。首先，他们提供了输入空间的平滑转换。看下面这个例子，它展示了在 9 个随机输入向量之间进行移动产出的图像：&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8G2Aqj8cfARvWSIzEs1ZXZS5iaKUk5uicxeGwsubOW4tbq3Hvt5pTUOrADcmicfxa4yJy7Dn6n28XTQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;输入向量空间还提供数学特性，表明学习特征是根据相似性进行组织的：&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8G2Aqj8cfARvWSIzEs1ZXZ1bRVtQfTicNCiasae8JMkNpBsMbA2SScmLsVicGp0OXd7bacU37RkHG3A/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;由生成器学到的光滑空间表明识别器也具有类似的性质，使它成为图像编码出色的特征提取器。这在不连续图像数据集训练 CNN 网络的经典问题上很有帮助，在这些数据集，对抗性噪声往往致使其走向失败（参见论文：Intriguing properties of neural networks）。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;近期对 GAN 训练的一次更新（参见论文：Improved Techniques for Training GANs）取得了在 CIFAR-10（只有 1000 个标记样本）上的 21% 错误率。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最近关于 infoGAN（参见论文：InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets）的一篇论文能够产生带有可被松解（disentangled）和有更多尤其意义的图片特征的非常锐利的图像。然而他们没有报告在任务或数据集上学习特征的表现，从而作为对比。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一个有趣的例子是作者使用生成式对抗训练来学习如何产生图像的文本描述。如下图：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8G2Aqj8cfARvWSIzEs1ZXZ3iaIiblro6j5BDR9yYeQVvibV4rwzamrcFJPfspicuTTZ488rEaaQibjtiaw/0?wx_fmt=png"/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我对此工作的赞赏之处在于它使用文本描述作为生成器的输入，这与随机向量完全不同，因此能够准确控制生成器的输出。如下图：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8G2Aqj8cfARvWSIzEs1ZXZsNvQcV5QnWZJVqHFM10IBQWia02lB6nfqppOAdjDulPqEyaibwtkwO2g/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;优点：&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;整个网络的全局训练（global training）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;代码和应用简单明了&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;缺点：&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;难以训练和转化（conversion）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;在某些情况下，与有监督学习的表现相似&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;需论证展示方法（representation）的可用性（这是所有无监督算法面临的问题）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过设定不需要标签的无监督学习任务，并设立训练目标解决任务，这些模型直接从无标签的数据学习。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;解决拼图谜题的无监督学习的视觉展示是一个很好的例子。作者将图像拆分，并以拼图谜题的形式呈现，最后通过训练一个深度神经网络来解决这个谜题。训练得到的网络是产生最好结果的预训练网络之一。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图像块（patch）和局部（locality）的无监督学习的视觉展示的也是一个很好的例子。这里，他们使用同一张图像上的两个位置相近的图像块。从统计数据来看，这 2 个图像块反映的是同一个对象。第 3 个图像块是随机从图片的任意位置获取的，从统计数据来看，与其它 2 个图像块反映的不是同一个对象。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然后，将这 3 种图像块传入一个深度神经网络进行训练，以区分相同对象和不同对象。训练得到的网络是产生最好结果的预训练网络之一。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;立体图像重建的无监督学习的视觉展示，例如通过左视图重建右视图。虽然这不是无监督学习的特有工作，但它可以使用无监督学习！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;使用替代类别（surrogate category）的无监督学习的视觉展示，使用图像块来创建大量的替代类别。增强这些图像块，然后用于训练基于增强替代类别的有监督网络。这给出了无监督特征学习的最好结果之一。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;使用视频的无监督学习的视觉展示，使用 LSTM 作为编码/解码器。LSTM 编码器通过运行一组视频帧（video frame）序列，来生成内部图像。这个内部图像然后通过另一个 LSTM 解码器，来产生一组目标序列。为了达到无监督学习，一种方法是预测与输入序列相同的序列。另一种方式是预测未来的视频帧。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一篇论文（MIT：Vondrick 和 Torralba）的视频有令人非常信服的结果。这项工作从 2015 年 4 月就开始了！这个思路的亮点是从视频输入来预测未来帧的图像。它使用的模型如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;PredNet&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;PredNet 是一个用于预测视频未来帧的网络。这个网址有很好的例子：https://coxlab.github.io/prednet/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;PredNet 是一个非常聪明的神经网络模型，在我们看来，它将在未来的神经网络中的发挥重要的作用。PredNet 的神经网络架构超越了单个有监督的 CNN 框架。PredNet 结合了生物启发和生物导向模型 [ 模拟人类大脑模型 ]（参见论文 https://papers.nips.cc/paper/1083-unsupervised-pixel-prediction.pdf）。它使用预测编码和使用 [ 神经模型中的反馈连接 ]（参见论文 http://arxiv.org/abs/1608.03425）。以下是 PredNet 模型和 2 个堆叠层（stacked layer）的示例：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该模型还具有以下优点：&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;使用无标签数据训练！&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;每层纳入损失函数（loss function）计算误差&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;通过监视错误信号来在线学习（online-learning）：当它不能正确预测输出时，它知道模型需要学习更新了&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;未来&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;未来由你创造。&lt;/span&gt;&lt;span&gt;无监督学习是一个非常开放的主题，你可以通过以下方式做出巨大贡献：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;创建一个新的无监督任务来训练神经网络，例如：解决一个谜题，对比图像块，生成图像，等等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;思考创建更好的无监督特征训练任务，例如：什么是对象以及什么是背景，立体图像的相同物体识别，视频帧的相同物体识别…… 这与人类的视觉系统的进化相似。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Sun, 30 Oct 2016 14:06:07 +0800</pubDate>
    </item>
    <item>
      <title>入门 | 初学者必读：解读14个深度学习关键词</title>
      <link>http://www.iwgc.cn/link/3288865</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自KDnuggets&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Matthew Mayo&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：Xuwen Wang、Chen Chen&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;本文介绍了包括 LSTM、ANNS、生物神经元、反向传播、多元感知机等 14 个深度学习关键概念，对初学者来说，搞清楚这些关键词的含义对理解深度学习至关重要。机器之心曾在九月的&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719393&amp;amp;idx=1&amp;amp;sn=41ed306d26dd209acfd61ee70efc8cf6&amp;amp;chksm=871b00dfb06c89c9dc8d5da87a0be1b3666c439909b41559097e952b7ccec29bae09823521bf&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719393&amp;amp;idx=1&amp;amp;sn=41ed306d26dd209acfd61ee70efc8cf6&amp;amp;chksm=871b00dfb06c89c9dc8d5da87a0be1b3666c439909b41559097e952b7ccec29bae09823521bf&amp;amp;scene=21#wechat_redirect"&gt;一篇文章&lt;/a&gt;中介绍过有关深度学习的其他专业术语。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尽管在最近的在线搜索中已经占据高的搜索量，深度学习仍然是一个相对较新的概念。由于在各个不同的领域都获得了巨大的成功，机器学习在研究和生产领域中大量涌现。机器学习是应用深度神经网络技术的一个过程——也就是有着多个隐藏层的神经网络构架——去解决问题。像数据挖掘一样，深度学习也是一个进程，它采用了神经网络构架——一种特定的机器学习算法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8G2Aqj8cfARvWSIzEs1ZXZkm7ldwgwskx5gtyYNapwckbJavmDQibiakAGEN4Hr5WzMPK2AFSticic8w/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;近段时间来深度学习已经积累了可观的研究成果。据此，在我看来，将以下下几点牢记在心对机器学习十分重要：&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;机器学习不是万灵药——它不能够解决所有的问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;它并不是一个传说中的大师级的算法——深度学习不能够替代其他机器学习的算法和数据科学的技术，或者说，至少它至今还未被证明可以&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;我们需要对它持以平和的期待——尽管最近各种分类问题，特别是计算机视觉和自然语言处理，强化学习以及其他领域都已取得显著进步，深度学习目前还没有到达可以解决诸如「实现世界和平」这种复杂问题的水平。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;深度学习和人工智能并非同义词。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;深度学习可以通过向一大堆数据提供附加的操作和工具从而解决问题。由此，深度学习在数据科学领域是一个十分有用的辅助。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8G2Aqj8cfARvWSIzEs1ZXZt5fLFq97EgAcdSnG6CMKgkFKpjFIA8WIicKiakicxmOanI6pRNdW8LpAw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;就像上图所示，深度学习深度学习之于数据挖掘，就像（深度）神经网络之于机器学习（进程 VS 构架）。同时我们也可以看到深度神经网络绝大程度属于当前人工智能的情况。两者概念相互交织几乎已经到了相同意思的程度（但实际上这两者并非相同的事物，人工智能除了神经网络还含有大量其他的算法和技术）同时，在深度学习过程和神经网络技术的带领下，近几年来在相关领域有了卓越的跨越。其中起重要作用的，深度学习／深度神经网络和计算机视觉，自然语言处理，生成模型之间的联系值得关注。由此，让我们通过简明扼要的定义，来了解深度学习和相关术语。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1. 深度学习&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;就像上述定义的一样，深度学习是应用神经网络解决问题的过程。深度神经网络是有着至少一个隐藏层的神经网络（如下图）。像数据挖掘一样，深度学习所指的是一个特定的过程。其中采用了深度神经网络-一种特定的机器学习算法的框架。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2. 人工神经网络（ANNs）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器学习构架最早的灵感来源于生物大脑（尤其是神经元）深度学习就运用到了神经元的概念。事实上，单一的人工神经网络（并非深度神经网络）在很早之前就被发现，在过去已经能解决一些特定的问题。然而，相较于现在，目前的神经网络构架都被设计为包含数个隐藏层（除了简单的输入和输出层）。层数的增加提高了网络的复杂度，使得网络能够进行深度学习，成为一种更强大的问题解决工具。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;实际上，人工神经网络 ANN 一族结构差别很大，因此，目前没有一个确切的神经网络定义。目前两个主流的适用于所有 ANN 的特征，一个是拥有一个可调整的权重集合，另一个是具有模拟输入信号到神经元的非线性功能的能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3. 生物神经元&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在生物和人工神经网络之间的关系已经有了明确的定义。大量传播开的出版物渲染出这样一个概念：ANN 是某种对发生在人（或其他生物）大脑的过程的完全复制。这种观念显然是不准确的。充其量我们只能说早期的人工神经网络是受到生物学的启发。两者间抽象的关系不比原子的组成和功能与太阳系间的抽象关系明确。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;也就是说，如果仅仅了解是什么启发了 ANN，这提供了一种高层次的解读，可帮助我们去理解生物神经是如何工作的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8G2Aqj8cfARvWSIzEs1ZXZsnwIm3J7xKWWFiasuOVdJY6KROfoqGT1iaG47EsXkRMCT7GvGeibE8yicg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以下是我们对生物神经元的最感兴趣的部分，包括：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;携带着遗传信息的细胞核（如 DNA）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;处理输入刺激并转化为输出刺激的细胞体。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;从其他神经元接受刺激的树突。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;信息传给其他神经的轴突。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;轴突末端，和相邻树突之间形成的突触结构。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在轴突末端与相邻树突形成的突出间隙中，扩散着一种叫做神经传递素的化学物质，他实现了神经传递。神经中最关键的部分，是神经通过树突接收到刺激，处理后，通过轴突末梢传输出去。在末梢处会经过突触间隙，然后到达许多接受神经的树突。该过程将重复进行。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;4. 感知机&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;感知机是一个简单的线形二进制分类器。它接收输入和与其相连的权重（表示输入变量的相对重要性），将它们结合来产生输出。输出接下来被用于分类。感知机已经存在很长一段时间了，最早的使用可追溯到 1950 年代，其中一个也是应用到早期的人工神经网络中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;5. 多层感知机&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一个多层感知机（MLP）是由几个含有全邻接层的感知机组成，形成一个简单的前馈神经网络（见下）。这个多层感知器在非线性激活函数上有许多好处，这些都是单层感知器不具备的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;6. 前馈神经网络&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在非周期性连接的神经网络结构中，前馈神经网络是最简单的形式。最初的人工神经网络中，前馈网络中的信息从输入节点单方向前进，而后通过所有隐藏层，到达输出节点，不存在任何周期。前馈网络不同于之后的连接构成有向循环的周期性网络架构（见下文）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;7. 循环神经网络&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;和上文所提到的前馈神经网络不同，循环神经网络的连接构成有向循环。这种双向流动允许内部时间状态表示，继而允许序列处理。并且值得注意的是，它提供了用于识别语音和手写的必要能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;8. 激活函数&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在神经网络中，激活函数通过组合网络的加权输入来产生判定边界输出结果。激活函数的范围从标识（线性）到 Sigmoid 函数（逻辑或软步长），双曲线（正切）和超越。为了采用反向传播（见下文），神经网络必须使用可微的激活函数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;9. 反向传播&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我所见过的对反向传播的定义中，最基本、简洁的定义是数据科学家 Mikio L. Braun 在 Quora(&lt;em&gt;&lt;span&gt;https://www.quora.com/How-do-you-explain-back-propagation-algorithm-to-a-beginner-in-neural-network/answer/Mikio-L-Braun&lt;/span&gt;&lt;/em&gt;) 上给出的答案。我在此列出原文，以防破坏这份答案简洁的完美。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8G2Aqj8cfARvWSIzEs1ZXZwwzljuoGlYctrPFgL0GZhogS3o573QQ58ibCxTvpZ4oueGoDlba6UFg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;反向传播只是在个别错误上进行梯度下降。通过比较对神经网络预期输出的预测，而后计算相对于神经网络的权重的误差梯度。然后得出了权值空间中减小误差的方向。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我将它列在这里。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;10. 成本函数&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在训练神经网络时，必须评估网络输出的正确性。众所周知，预期上正确的训练输出数据和实际的训练输出是可比拟的。成本函数便能测量实际和训练输出之间的差异。实际和预期输出之间的零成本将意味着训练神经网络成为可能。但这显然是理想化的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;所以，通过什么机制来调整成本函数，以实现将其最小化的目标呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;11. 梯度下降&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;梯度下降法是求函数局部极小值的一个优化算法。虽然它不能保证全定义域内的最小值，但梯度下降对于难以通过分析（例如通过将导数取 0 获得最优解）求得精确解的问题十分有用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8G2Aqj8cfARvWSIzEs1ZXZxbYrvua6Q28QclHHHyCCuPRDMRpAxDsJ5wHsUHjfMWhDehsDh5AgfQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;正如上文所述，在神经网络的情况中，随机梯度下降用于对网络参数做出知情调整，以达到使成本函数最小化的目标，从而使网络的实际输出迭代性地愈加接近在培训期间的预期输出。这种迭代最小化采用微积分，即微分。在训练步骤之后，网络权重根据成本函数的梯度和网络的当前权重接收更新，使得下一个训练步骤的结果可以更加接近正确值（通过更小的成本函数测量）。反向传播（关于错误的反向传播）便用于将这些更新以小份的形式送到网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;12. 梯度消失问题&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;由于反向传播使用链式规则来计算梯度（通过微分），朝向 n 层神经网络的「前」（输入）层将使其修改的梯度以一个较小的值乘以 n 次方，然后再更新之前的固定值。这意味着梯度将指数性减小。n 越大，网络将需要越来越多的时间来有效地训练。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;13. 卷积神经网络&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;卷积神经网络（CNN）通常与计算机视觉和图像识别相关联，并采用卷积的数学概念来模仿生物视觉皮层的神经连接网格。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先，正如 Denny Britz 所描述一样(&lt;em&gt;&lt;span&gt;http://www.kdnuggets.com/2015/11/understanding-convolutional-neural-networks-nlp.html&lt;/span&gt;&lt;/em&gt;)，卷积可以被认为是在图像的矩阵表示之上的滑动窗口（见下文）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8G2Aqj8cfARvWSIzEs1ZXZNK4X0miarAkFRt9VXicxcEXYCiczbW6fFS7rgvVufsRDibYQicMuNwkribqQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;来源：斯坦福&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在神经网络结构中，至少在计算机视觉实现该概念将导致专用于处理局部图像的神经元的集合。当在某些例如自然语言处理的其他领域中使用时，鉴于输入（字，句子等）可以置于矩阵中并以类似的方式处理，故可以采取同样的方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;14. 长短期记忆网络（LSTM）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8G2Aqj8cfARvWSIzEs1ZXZf9m2yutVjOawAw0rC4KGHI51s3fKgyICtHY6w8PJ0gJ52mA5vxVgKA/0?wx_fmt=png"/&gt;&lt;/strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;来源：Christopher Olah(&lt;span&gt;http://colah.github.io/posts/2015-08-Understanding-LSTMs/&lt;/span&gt;)&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;长短期记忆网络（LSTM）是经优化以用于从时间相关数据中学习和作用的循环神经网络，而这些数据可能在相关事件之间具有未定义的或未知的时间长度。它们的特定架构给予 ANN「内存」并允许其持久性。最近手写识别和自动语音识别的突破便得益于 LSTM 网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这显然只是深度学习术语的一个小部分以及许多衍生的从基础到高级的概念。若欲了解更多关于机器学习研究当前领先的领域，您需要自行探索。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Sun, 30 Oct 2016 14:06:07 +0800</pubDate>
    </item>
    <item>
      <title>学界 | MIT论文SoundNet：从未标记的视频中学习声音表征（附开源代码）</title>
      <link>http://www.iwgc.cn/link/3288866</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自MIT&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;MIT 之前发过一篇从未标记视频中学习声音表征的论文（SoundNet），近期他们开源了 SoundNet 的实现代码。相关论文可点击「阅读原文」下载。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;SoundNet 代码地址：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;https://github.com/cvondrick/soundnet&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8G2Aqj8cfARvWSIzEs1ZXZmIc3MdFcQW0Jb8Wiba2ibL0hibANkDAB4eTUvF3w9YXIcPGArqUOL4R2Q/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：通过有效利用大量从野外收集的未标记声音数据，我们学习了丰富 的自然声音表征。使用两百万未标记的视频，我们利用时间和声音的自然同步来学习声学表征。未标记视频的优势是在经济有限情况下也能获得大规模的、包含有用信号的数据。我们提出一种 student-teacher 训练流程，使用未标记视频作为桥梁，能将来自好的视觉识别模型的有识别力的视觉知识迁移到声音形态。在声学场景/识别分类基准上，我们的声音表征对前沿表现有了极大的改进。可视化数据表明一些高层次语义可在该声音网络中自动生成，即使它是在没有 ground truth 标记的情况下训练的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8G2Aqj8cfARvWSIzEs1ZXZ7TibNLed6EI8RBFiaSUO0yFqEicEVndsUTpuqCb6ibZicT0tUje7Ar7dqoA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Sun, 30 Oct 2016 14:06:07 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 人工智能开发者的入门指南</title>
      <link>http://www.iwgc.cn/link/3288867</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Intel&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Niven S&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：杜夏德&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;自上世纪 50 年代以来，人类对人工智能前景的想象从未停止过，计算机科学家创造出更加复杂的新技术，也为普通消费者打造出一个令人向往的未来。虽然对人工智能的理解几十年来一直在变化，但我们也有理由相信人工智能时代最终会到来。那么想要成为一名人工智能开发者，怎样才能踏入这一领域呢？&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;首先要搞清楚，人工智能到底是什么？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;感知——在大量数据中鉴定和识别有意义的物体或概念。比如说前方的物体是红绿灯吗？或者它是肿瘤还是普通的身体组织？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;推理——理解更大的语境，然后做出计划以达到目标。如果目标是避免碰撞，那么自动驾驶车就必须基于汽车的行为、车距、速度和交通状况计算出撞车的可能性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;执行——推荐或者直接启用最佳的行动程序。基于汽车和交通状况分析，它可以做到刹车、加速或者进入安全模式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;自我调试（adapt）——最终，我们一定能在每一阶段基于经验来调试算法，让它们越来越智能。自动驾驶算法需要重复训练来识别更多的盲点，将新的变量纳入语境中作为参考因素，并在基于之前的事故来调试行动。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;今天的人工智能达到了什么程度？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当下，人工智能是一个总称，可以表示任何一种能感知、推理、行动、自我调试（adapt）的程序。开发者可以通过机器学习和深度学习两种方式来实现机器的上述行为。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8G2Aqj8cfARvWSIzEs1ZXZjMBJZQicBHsAH0icoZebEL4R9ibLzzSs359F3kwXtZIdsvgBxQib9sg6yg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在机器学习中，从数据中学习算法来建立一个模型，并且随着时间的推移接触到的数据越来越多，算法也会不断提升。现在四种主要类型的机器学习：监督学习、无监督式学习、半监督学习和强化学习。在监督学习中，算法学习通过处理和分类大量经过标签的数据来识别数据。在无监督学习中，算法识别的是模式并对大量无标签的数据进行分类，往往比人脑要快得多。你可以阅读这篇文章（（https://software.intel.com/en-us/articles/why-should-you-care-about-machine-learning）(https://software.intel.com/en-us/articles/why-should-you-care-about-machine-learning%EF%BC%89)）了解更多机器学习的知识。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;人工智能的运行：机器学习的工作流程&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;上文讨论过，人工智能可以基于经验来感知、推理和行动。但是，它们是怎么做到的呢？下面是机器学习的一般流程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 数据获取——首先需要大量数据，可以从任意数量的数据源中收集，包括可穿戴设备上的传感器和其他物体、云以及网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 数据聚合与策展——数据收集过后，就可以进行聚合和打标签工作（监督学习）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3. 模型开发——下一步，用这些数据来开发模型，利用数据训练出到达某种精确度的模型并优化其性能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4. 模型部署和评分——模型被部署进应用中，然后基于新的数据进行预测。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;人工智能开发者的机遇&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能最令人激动的地方就是具备变革我们生活触及的每个产业的潜力，不仅仅是计算和软件产业。它会像工业革命、技术革命、数字革命那样改造社会颠覆我们的日常生活。对于开发者来说，人工智能领域的扩张意味着你可以将人工智能的专业知识应用到你感兴趣的领域中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8G2Aqj8cfARvWSIzEs1ZXZSMKib5HbicWmf8gv9ssg0U9pto5LnYey0EY36DwCvcwMsVGYem2VdjIw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8G2Aqj8cfARvWSIzEs1ZXZVApYW9nCibMiaVzbm2jH5VfxhXrvSmGpmWVwCS7j5yrBt8ibf6HAibv2YQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Sun, 30 Oct 2016 14:06:07 +0800</pubDate>
    </item>
    <item>
      <title>深度 | MIT开发新型神经网络训练技术，让模型决策不再黑箱(附论文)</title>
      <link>http://www.iwgc.cn/link/3277436</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自MIT&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：Terrence L、李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;来自MIT计算机与人工智能实验室的研究者设计了一种新的神经网络训练方法，利用这种方法训练过的神经网络不仅可以预测和分类还能给出决策理由。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最近几年，人工智能研究领域表现最好的系统都来自于神经网络，它能够寻找训练数据中的模式，产生有用的预测或分类。例如，神经网络经过训练可识别数字图像中的某些目标或者推断文本的主题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是神经网络是黑箱子。在训练之后，神经网络或许能非常好地分类数据，但即使其创建者也不知道为什么。通过可视化数据，有时有可能自动操作那些决定神经网络响应哪些视觉特性的实验。但是文本处理系统往往更加不透明。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在计算语言学会自然语言处理实证方法会议（Association for Computational Linguistics』 Conference on Empirical Methods in Natural Language Processing）上，MIT 计算机科学与人工智能实验室（CSAIL）的研究人员将提出一种新的训练神经网络的方法，使他们不仅提供预测和分类，而且为他们的决策提供理论依据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;MIT 电气工程和计算机科学研究生、论文第一作者 Tao Lei 说道：「在现实应用中，有时人们真的想知道为什么模型做出这种预测。医生不相信机器学习方法的一个主要原因是没有证据。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;MIT 电子工程与计算机科学系教授、Tao Lei 的论文导师 Regina Barzilay 补充说：「不仅仅是医学领域。在任何领域，错误预测的成本都是非常高的。你需要证明你为什么这样做。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;论文第三作者 Tommi Jaakkola 说，「这项工作还有更广泛的影响，你可能不想只是验证模型是以正确的方式进行预测；你可能还想对它应该做出的预测类型施加一些影响。外行人如何与一个复杂的、他们所不知道的算法训练出的模型进行交流？他们可能有能力告诉你做出特定预测的理由。在这个意义上，它打开了一种与模型交流的不同方式。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;虚拟大脑&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;神经网络的得名是因为它们大致模仿了大脑的结构。它们由大量的处理节点组成，像单个神经元一样只能进行非常简单的计算，但是在密集网络中彼此连接。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在被称为「深度学习」的方法中，训练数据被馈送到网络的输入节点，网络的输入节点对其进行修改（modify）并将其馈送到其它节点，其它节点修改并将其馈送到另外的节点，并重复该过程。然后存储在网络输出节点中的值与网络尝试学习的分类类别相关联——例如图像中的目标或文章的主题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在网络训练的过程中，由各个节点执行的操作被连续地修改，从而在整个训练样本集合上产生一致的良好结果。在过程结束时，编程网络的计算机科学家通常不知道节点的设置是什么。即使他们明白，也很难将低级信息转换回系统决策过程的可理解性描述。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在新论文中，Tao Lei、Barzilay 和 Jaakkola 专门描述了在文本数据上训练的神经网络。为了能够解释神经网络的决定，CSAIL 研究人员将网络分为两个模块。第一模块从训练数据中提取文本段，并且根据它们的长度和它们的相干性来对分段进行评分：分段越短，并且从连续单词串中提取的越多，其分数越高。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然后将由第一模块选择的文本段传递给执行预测或分类任务的第二模块。两个 模块一起训练，训练的目标是最大化所提取文本段的分数以及预测或分类的准确性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;研究人员测试他们的系统的数据集之一是来自用户评价不同啤酒的网站的一组评论。数据集包括评论的原始文本和相应的评级，评级使用五星级系统在三个属性上评定：色（appearance）、香（aroma）、味（palate）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该数据集对自然语言处理研究者有吸引力的原因是它也被手动注释过，指示评论中哪些句子对应于哪些分数。例如，评论可以包括八个或九个句子，并且注释可以突出显示指示啤酒的「大约半英寸厚的棕褐色泡沫」，「显著爱尔兰啤酒气味」和「缺乏碳酸化」等等。每个句子与不同的属性等级相关联。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;验证&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因此，数据集为 CSAIL 研究人员的系统提供了一个很好的测试。如果第一模块已经提取了这三个短语，并且第二模块将它们与正确的评级相关联，则系统已经识别了人类注释器所做的判断的相同基础。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在实验中，系统与人类对于色和香评级的一致性分别为 96％和 95％，对于更浑浊的味觉概念则是 80％。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在论文中，研究人员还报告了在自由形式技术问答的数据库上测试他们的系统，其中任务是确定给定问题是否之前就已经被回答。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在未发表的成果中，他们已经将该系统应用于数千份关于乳腺活检的病理报告，在那里它已经学会提取文本来为病理学家作解释以提供诊断基础。他们甚至使用它来分析乳房的 X 线照片，其中第一个模块提取图像的部分而不是文本的部分。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;东北大学计算机与信息科学助理教授 Byron Wallace 说：「现在关于深入学习有很多炒作，特别是用于自然语言处理的深度学习。」「但这些模型的一个很大缺点是，它们通常是黑箱。拥有一个不仅可以做出非常准确的预测，还可以告诉你为什么做这些预测的模型是一个非常重要的目标。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「实现这一目标后，我们在同一会议上会提交一份主旨相似的论文，」Wallace 补充说。「我当时不知道 Regina 正在做这个，实际上我认为她的更好。我们的方法在培训过程中，当有人告诉我们，例如，某个电影评论是非常积极的，我们假设他们会标记一个句子并给你理由。我们利用这种方式来训练深度学习模型去提取这些理由。但他们不做这个假设，所以他们的模型运行时没有使用带有标记的直接注释，这是一个非常好的方式。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;论文：Rationalizing Neural Predictions&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Ik2rVaj7QnMX8iavbkiaBj4oVJqFxefuKYEbJdV00AECicSeecFibiciasxwoRl99Fh6HcAZ8kicnALoLw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：没有根据（justification）的预测往往限制了其应用。作为补救，我们学习提取输入文本的碎片作为根据（或者说论据，rationales），裁剪出的文本要短却具有相干性，而且足够做出同样的预测。我们的方法是结合两个模块，也就是生成器和编码器，训练后的模块要很好的协同运行。生成器指定在文本段上的一组分布作为候选论据，然后将这堆论据输入编码器进行预测。论据不是在训练过程中给出的。该模型通过渴求论据而被正则化。除了手动注释的测试案例，我们在多方面情感分析上评估该方法。我们的方法以显著的优势超过了基于注意力的基线，我们也成功的在问题检索任务上解释了该方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Sat, 29 Oct 2016 11:11:23 +0800</pubDate>
    </item>
  </channel>
</rss>
