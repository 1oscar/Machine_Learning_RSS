<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>机器之心</title>
    <link>http://www.iwgc.cn/list/670</link>
    <description>人与科技的美好关系</description>
    <item>
      <title>重磅 | Nature评论白宫发布的最新报告：人工智能研究中的一个盲点</title>
      <link>http://www.iwgc.cn/link/3066147</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Nature&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Kate Crawford 、Ryan Calo&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李泽南、李亚洲、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;对于人工智能未来影响的担忧正在分散研究人员部署目前系统的注意力。──Kate Crawford，Ryan Calo&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW92ia2VwicvjoPDiaEn4mqfPpmtEgtcYxlicHlxSXsHsX3IQ6fLGbiaxomWMmmp9hTtEiclgbxvYqEN9tbQ/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;芝加哥警察使用算法系统来预测哪些人在枪击案中存在最大嫌疑，但这种方式被证明效率很低。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本周，美国白宫发表了一篇有关人工智能的报告──这份报告是今年五月、七月分别于西雅图，匹兹堡，华盛顿和纽约举行的四次研讨会的成果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这些形成报告的活动中，来自世界各地不同行业的思想家汇聚到一起，讨论人工智能将怎样改变我们的生活；许多发布会展示了使用机器学习和其他人工智能技术解决各种生活中复杂问题的前景。这些技术包括了识别皮肤的变化预警早期癌症的风险、减少数据中心的能源消耗等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些研讨会着重提出了关于目前人工智能研究的盲点。目前自动系统已经被部署在大多数重要的社会机构中，从医院到法庭。但还未出现一个人们普遍认同的方式来评估这些应用对于人类的持续影响。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;近年来，人工智能的技术有了长足的进步。在这样的发展中，各学科研究人员和设计者需要建立一种所谓人工智能的社会制度分析。他们需要评价技术对于社会，文化和政治环境的影响。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;社会制度的分析可以探究例如：AiCure──一种提醒病人按时用药，同时传输数据给医生的应用──是如何改变医患关系的。这样的研究同时也可以探索使用历史记录预测犯罪发生的方式，是否会导致边缘化社区警力使用过度。或者，它可以研究为什么高级投资者有权使用人力和算法来做出投资决策，而低收入的贷款者还在纳闷为什么他们的贷款申请被不断拒绝。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;奇点问题&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「人们担心计算机会变得过于聪明，最终控制这个世界，但是真正的问题是它们仍然不够聪明，却已经控制了整个世界。」这是计算机科学家 Pedro Domingos 在他 2015 年的著作「The Master Algorithm」中的总结语。尽管很多研究者拒绝接受「技术奇点」的概念，认为这一领域还有待发展，但他们仍然支持将未经受检验的人工智能系统直接引入社会框架。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;由于人工智能研究者的热情，一些智能系统已经被使用在了医生的指导诊断中。它们被应用在律师事务所，向委托人估算打赢官司的成功率，告诉金融机构应该接受哪些借贷申请，同时也告诉雇主应该雇佣谁。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;分析师期待人工智能系统不断进入这些领域。目前市场分析者将人工智能应用估值为 10 亿美元级别，IBM 的首席执行官 Ginni Rometty 曾说她预计人工智能系统在未来十年中存在 20000 亿美元的机会。当然，未来难以预测，部分原因是没有形成关于「什么是人工智能」的共识。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW92ia2VwicvjoPDiaEn4mqfPpmAHFe0gLjElnDKjUlvVjsOgz4I4DwKwwqYULFRXP7MbxoC8CIPptdxA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在未来，人工智能在进行预测和做出决定方面将不会弱于人工操作的系统。但目前，工程师们还在优化人工智能，使得它们能够发现和消除人类中存在的偏见。研究表明在目前一些环境中，人工智能的缺点正在不成比例地增加已受种族，性别，社会经济背景影响的弱势人群的压力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 2013 年的一份报告中，谷歌的研究者发现通常被用于黑人的名字相比「白人名字」有更高（25%）的几率被标记以投放犯罪记录搜索的广告。在 ProPublica 在 2016 年 5 月的另一项有关种族的研究中，他们发现用于判断再次犯罪危险的专用算法错误地把黑人的危险性估计为白人的两倍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;三个工具&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如何能够避免这样的情况？目前，有三种主要模型可以回答有关人工智能对于社会和伦理影响的问题：服从，「设计值」和思维实验。所有三种模型都很有价值，它们不能单独使用，而且仅仅这三个工具也不够。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;部署和服从。通常，公司在运作过程中会以遵守行业标准和法律义务为准则，这可以减少政府，媒体和其他监督机构的调查。这种方式在短期内有效，以谷歌为例，他们在 2015 年系统将一对非裔夫妇贴上黑猩猩标签的事件后改进了图像识别算法。公司被建议在人工智能系统中添加「红色按钮」，用以在系统失控后有能力作出反应。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;同样的，Facebook 在用户关于普利策将照片被系统删除的抗议后添加了豁免规则，让儿童裸体的照片不再被屏蔽，那是一张越战中一名女孩在凝固汽油弹袭击中哭喊逃亡的著名照片。在上个月，很多人工智能的领导者，包括微软，亚马逊和 IBM，形成了合作关系来促进公众理解，开发共同标准。所以，「部署和服从」方式可以临时做出改变，如果行业准则缺乏独立性，没有得到充分地讨论，它可能会被认为是不适当的。新的人工智能合作体系邀请了伦理学家和公民社会组织加入。但目前仍有顾虑存在，科技公司仍可以完全自由地公开测试他们的人工智能系统，在此之前并不用进行中期甚至早期的持续性研究。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;设计中的价值观。在包括 Batya Friedman，Helen Nissenbaum 等早期设计者提出技术的伦理之后，研究者和公司以此为基础，不断发展自己的敏感值设计或进行「负责任地创新」来保证可能的利益相关者和他们的利益。目标人群或其他的技术被用来建立人们关于个人隐私，环境等议题的广泛观点。关于潜在用户的价值观被代入了技术产品的设计中，不论是手机应用还是自动驾驶汽车。在这种情况下，人工智能系统的开发者需要更加遵循这些准则。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然而，这些工具总是在建立系统的假设上工作。机器根本不能告诉设计者，政策制定者和整个社会系统会被如何建立，也不会告诉人们它所遵循的准则过于老旧或不可靠，不能被医院，法庭这样的重要基础设施采用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW92ia2VwicvjoPDiaEn4mqfPpmeUGhARYgUg4IBExOCLk6jzwWusGX0WXyOHtVMhaoZd7fSyXOR5Qmicg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;em style="color: rgb(136, 136, 136); text-align: justify;"&gt;&lt;span&gt;在预测肺炎时，一位病人被人工智能系统错误的评定为低风险。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;思维实验。过去几年中，假想的情形已经主导了围绕人工智能的社会影响的公众议题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人类将会创造出将最终统治我们或毁灭我们的高智能系统的可能性已经得到了非常广泛的讨论。另外，来自 1967 年的一个相关的思维实验——电车难题（The Trolley Problem）——已经焕发出了新的生机。这种情形引发了关于责任和罪责的问题。在电车难题中，一个人要么让奔驰中的电车碾过有五个人正在上面施工的轨道，要么需要调整方向让电车驶向另一个只会给一个人带来危险的轨道。许多评论者将这个假想的情形应用到了自动驾驶汽车上——他们认为自动驾驶汽车将不得不做出事关道德伦理的自动决策。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然而和机器人末日一样，自动驾驶汽车权衡「杀人决策」的可能性只提供了一个关于道德推理的狭隘框架。电车难题对于我们目前所面临的更广泛的社会问题仅具有一点点指导性——我们面临的问题是：对自动驾驶汽车而非公共交通进行大规模投资的价值；在自动驾驶汽车上路运营之前需要达到怎样的安全程度（以及应该使用什么工具来决定这个程度）；以及自动化载具对交通拥堵、环境和就业的潜在影响。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;社会系统分析&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们认为需要第四种方法，一个实际的、普遍可用的社会系统分析（social-systems analysis），彻底搞清人工智能系统对所有方面的所有可能的影响。在每一阶段它都伴随着社会影响——从概念，到设计，到部署和管理。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一步，跨学科、政府部门和产业的研究人员需要开始调查不同社区接触信息的方式有何不同，财富和基础服务塑造人训练人工智能系统所需的数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;比如，在芝加哥和伊利诺伊，算法生成的热点图正被用于识别与枪击事件最相关的人。上个月发布的一项研究表明这样的热点图效率低下：它们增加了应该被警察视为目标的人的可能性，但并未减少犯罪。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而社会系统方法会将热点图基于的社会和政治历史数据考虑在内。这可能需要需要咨询社区成员，并根据其反馈来权衡关于周边警务的警务数据，无论这些反馈是正面的还是负面的。这也意味着将监督社区和法律机构所发现的数据计算在内。社会系统分析也会询问系统给出的风险与奖励是否被均衡的应用，所以在此案例中，也就是警方是否使用类似的技术识别哪个警官更可能有不当行为，比如说暴力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有另外一项例子：2015 年的一项研究展示了机器学习技术被用于预测在大部分情景下哪些病人会发展成肺炎并发症。但该研究犯了一项严重错误：即使有的病人是高风险的哮喘病人，它也建议医生将这种病人放回家。因为医院会自动地将哮喘病人放到重症护理，在系统被训练的数据中，这些病人很少有「进一步治疗」的记录。有了社会系统分析，就能查看底层的医院指南以及其他的保险政策等构成病人记录的因素。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;类似地，社会系统分析会问人们是否以及何时会受到人工智能系统的影响，这样的分析也需要提出关于这些系统的工作方式的问题。金融分析师一直被限制他们利用机器学习的方式，因为客户期望他们剖析、解释所做的决策。而如今，已经使用人工智能决策的人无法做出这样的解释。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;社会系统的分析需要用到哲学、法律学、社会学、人类学和科学技术研究等许多学科。它必然也会需要对社会、政治和文化价值与技术变革和科学研究的相互影响进行研究。只有通过提出关于人工智能的影响的更为宽泛的问题，我们才能得到对人工智能的更为全面和综合的理解——这比单独通过计算机科学或犯罪学进行分析好多了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;也存在一些希望。像下个月将在纽约举办的「Fairness, Accountability, and Transparency in Machine Learning meeting」这样的研讨会就是一个很好的例子。但是资助者（政府、基金会和企业）应该在实现我们描述的人工智能上进行更多的投资。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能既会带来技术上的变革，也会带来文化上的变革。这类似于过去发生过的技术拐点——如印刷机和铁路的出现。自动化系统正在改变工作场所、街道和学校。我们需要确保这些改变是有益的，然后才能将它们进一步地构建到我们日常生活的基础设施中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Fri, 14 Oct 2016 12:13:00 +0800</pubDate>
    </item>
    <item>
      <title>开源| Keras.js可以让你使用浏览器在GPU上运行Keras模型</title>
      <link>http://www.iwgc.cn/link/3066148</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自GitHub&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;本项目可以让你使用 WebGL 在 GPU 驱动的、你的浏览器上运行训练好的 Keras 模型。模型直接根据 Keras JSON 格式配置文件和关联的 HDF5 权重而序列化（serialized）。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;项目地址：&lt;span&gt;https://github.com/transcranial/keras-js&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;互动演示&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;用于 MNIST 的基本卷积网络&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;在 MNIST 上训练的卷积变自编码器（Convolutional Variational Autoencoder）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;在 ImageNet 上训练的 50 层的残差网络（Residual Network）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;在 ImageNet 上训练的 Inception V3&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;用于 IMDB 情绪分类的双向 LSTM&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW92ia2VwicvjoPDiaEn4mqfPpmKdc0yqtuSxdTwGwrBzicn9R6Xu4rAWzWTpAQu6PmQMsIC5HrkBReic2A/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW92ia2VwicvjoPDiaEn4mqfPpmLzOm2sMaNlxEUjKFyNnCakicc3SOm0T3ia81TDmfpv8ASV7WRfIgWuibA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW92ia2VwicvjoPDiaEn4mqfPpmaXQJHb5HOZXlNSY7a3DX2lvG7iaPn4N3y04jb0PrKmclADIEYkOjk5A/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW92ia2VwicvjoPDiaEn4mqfPpmaqNnDPVmdO54UpkuD8kecfIRRuUH6o3LyTE2iap5tgGhdyqjicCOaFqA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;为什么要做这个项目？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;消除对后端基础设施或 API 调用的需求&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;完全将计算卸载到客户端浏览器&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;互动应用程序&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;使用方法&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;查看&lt;span&gt;&lt;em&gt; demos/src/&lt;/em&gt;&lt;/span&gt; 获取真实案例的源代码。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 对&lt;span&gt;&lt;em&gt; Model&lt;/em&gt;&lt;/span&gt; 和&lt;em&gt;&lt;span&gt; Sequential &lt;/span&gt;&lt;/em&gt;都适用&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;model = Sequential()&lt;/span&gt;&lt;br/&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;model.add(...)&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;...&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;...&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;model = Model(input=..., output=...)&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一旦训练完成，保存权重和导出模型架构配置：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;model.save_weights('model.hdf5')&lt;/span&gt;&lt;br/&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;with open('model.json', 'w') as f:&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;f.write(model.to_json())&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;参见演示的 jupyter notebooks 了解详情：&lt;span&gt;&lt;em&gt;demos/notebooks/&lt;/em&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 在 HDF5 权重文件上运行编码器脚本：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;$ python encoder.py /path/to/model.hdf5&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这将在同一个文件夹中产生两个用作 HDF5 权重的文件：&lt;em&gt;&lt;span&gt;model_weights.buf &lt;/span&gt;&lt;/em&gt;和 &lt;span&gt;&lt;em&gt;model_metadata.json&lt;/em&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3.Keras.js 所需的三个文件：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: circle;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;模型文件：&lt;em&gt;&lt;span&gt;model.json&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;权重文件：&lt;span&gt;&lt;em&gt;model_weights.buf&lt;/em&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;权重元数据文件：&lt;span&gt;&lt;em&gt;model_metadata.json&lt;/em&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4.GPU 支持由 weblas(https://github.com/waylonflinn/weblas) 驱动。将 Keras.js 和 Weblas 库包含进去：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;lt;script src="lib/weblas.js"&amp;gt;&amp;lt;/script&amp;gt;&lt;/span&gt;&lt;/em&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;lt;script src="dist/keras.js"&amp;gt;&amp;lt;/script&amp;gt;&lt;/span&gt;&lt;/em&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;5. 创建新模型&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;实例化时，数据通过 XHR（相同域或要求 CORS）加载，层被初始化为有向无环图。当这些步骤完成之后，类方法 ready() 返回一个解决问题的 Promise。然后，使用 perdict() 让数据通过模型，这也会返回一个 Promise。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;const model = new KerasJS.Model({&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;filepaths: {&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;model: 'url/path/to/model.json',&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;weights: 'url/path/to/model_weights.buf',&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;metadata: 'url/path/to/model_metadata.json'&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;}&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;gpu: true&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;})&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;model.ready().then(() =&amp;gt; {&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;// input data object keyed by names of the input layers&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;// or `input` for Sequential models&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;// values are the flattened Float32Array data&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;// (input tensor shapes are specified in the model config)&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;const inputData = {&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;'input_1': new Float32Array(data)&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;}&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;// make predictions&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;// outputData is an object keyed by names of the output layers&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;// or `output` for Sequential models&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;model.predict(inputData).then(outputData =&amp;gt; {&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;// e.g.,&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;// outputData['fc1000']&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;})&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;})&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;可用的层&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;高级激活: &lt;span&gt;&lt;em&gt;LeakyReLU, PReLU, ELU, ParametricSoftplus, ThresholdedReLU, SReLU&lt;/em&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;卷积: &lt;span&gt;&lt;em&gt;Convolution1D, Convolution2D, AtrousConvolution2D, SeparableConvolution2D, Deconvolution2D, Convolution3D, UpSampling1D, UpSampling2D, UpSampling3D, ZeroPadding1D, ZeroPadding2D, ZeroPadding3D&lt;/em&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;内核: &lt;span&gt;&lt;em&gt;Dense, Activation, Dropout, SpatialDropout2D, SpatialDropout3D, Flatten, Reshape, Permute, RepeatVector, Merge, Highway, MaxoutDense&lt;/em&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;嵌入: &lt;em&gt;&lt;span&gt;Embedding&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;归一化: &lt;em&gt;BatchNormalization&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;池化: &lt;em&gt;&lt;span&gt;MaxPooling1D, MaxPooling2D, MaxPooling3D, AveragePooling1D, AveragePooling2D, AveragePooling3D, GlobalMaxPooling1D, GlobalAveragePooling1D, GlobalMaxPooling2D, GlobalAveragePooling2D&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;循环: &lt;span&gt;&lt;em&gt;SimpleRNN, LSTM, GRU&lt;/em&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;包装器:&lt;span&gt;&lt;em&gt; Bidirectional, TimeDistributed&lt;/em&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;还没有实现的层&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前还不能直接实现 Lambda，但最终会创建一个通过 JavaScript 定义计算逻辑的机制。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;内核:&lt;span&gt;&lt;em&gt; Lambda&lt;/em&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;卷积: &lt;span&gt;&lt;em&gt;Cropping1D, Cropping2D, Cropping3D&lt;/em&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;本地连接: &lt;span&gt;&lt;em&gt;LocallyConnected1D, LocallyConnected2D&lt;/em&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;噪声&lt;em&gt;:&lt;span&gt;GaussianNoise, GaussianDropout&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;备注&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;WebWorker 及其限制&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Keras.js 可以与主线程分开单独运行在 WebWorker 中。因为 Keras.js 会执行大量同步计算，这可以防止该 UI 受到影响。但是，WebWorker 的最大限制之一是缺乏 &amp;lt;canvas&amp;gt; 访问（所以要用 WebGL）。所以在单独的线程中运行 Keras.js 的好处被必须运行在 CPU 模式中的要求抵消了。换句话说，在 GPU 模式中运行的 Keras.js 只能运行在主线程上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;WebGL MAX_TEXTURE_SIZE&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 GPU 模式中，张量对象被编码成了计算之前的 WebGL textures。这些张量的大小由 &lt;span&gt;&lt;em&gt;gl.getParameter(gl.MAX_TEXTURE_SIZE) &lt;/em&gt;&lt;/span&gt;限定，这会根据硬件或平台的状况而有所不同。参考 http://webglstats.com/ 了解典型的预期值。在 im2col 之后，卷积层中可能会有一个问题。比如在 Inception V3 网络演示中，第一层卷积层中 im2col 创造了一个 22201 x 27 的矩阵，并在第二层和第三层卷积层中创造 21609 x 288 的矩阵。第一个维度上的大小超过了&lt;em&gt;&lt;span&gt; MAX_TEXTURE_SIZE &lt;/span&gt;&lt;/em&gt;的最大值 16384，所以必须被分割开。根据权重为每一个分割开的张量执行矩阵乘法，然后再组合起来。在这个案例中，当&lt;span&gt;&lt;em&gt; createWeblasTensor() &lt;/em&gt;&lt;/span&gt;被调用时，Tensor 对象上会提供一个 &lt;span&gt;&lt;em&gt;weblasTensorsSplit&lt;/em&gt;&lt;/span&gt; 属性。了解其使用的例子可查看 &lt;em&gt;&lt;span&gt;src/layers/convolutional/Convolution2D.js&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;开发/测试&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于每一个实现的层都存在广泛的测试。查看 notebooks/ 获取为所有这些测试生成数据的 jupyter notebooks。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;$ npm install&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;要运行所有测试，执行&lt;span&gt;&lt;em&gt; npm run server&lt;/em&gt;&lt;/span&gt; 并访问 http://localhost:3000/test/。所有的测试都会自动运行。打开你的浏览器的开发工具获取额外的测试数据信息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于开发，请运行：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;$ npm run watch&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;编辑 src/ 中的任意文件都会触发 webpack 来更新 &lt;span&gt;&lt;em&gt;dist/keras.js&lt;/em&gt;&lt;/span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;要创建生产型的 UMD webpack 版本，输出到&lt;span&gt;&lt;em&gt; dist/keras.js&lt;/em&gt;&lt;/span&gt;，运行：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;$ npm run build&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;证书&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;MIT：&lt;span&gt;https://github.com/transcranial/keras-js/blob/master/LICENSE&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Fri, 14 Oct 2016 12:13:00 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 全球机器人创投状况：中国成长最为迅猛</title>
      <link>http://www.iwgc.cn/link/3066149</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自 CB Insights&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：杜夏德&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;CB Insights 统计分析了自 2015 年 1 月以来非美国的机器人创业公司的发展状况，单轮融资额最高的前四家创业公司都来自中国。中国、法国、印度和英国是其中发展速度最快的 4 个国家。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;过去五年对机器人创业公司的大部分投资交易都来发生在美国，而美国本土外的机器人投资也正在崛起。2012 年，美国之外机器人创业公司投资占到了全球份额的 26%，五年来，这一数据一直在波动增长，2016 年达到了 43%（截止于 2016 年 10 月 5 日）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW92ia2VwicvjoPDiaEn4mqfPpmKLv5eg2GBeVm2KfVQBv7otlk1nOTCEcfEickhPwChr5dGfb0wsaYpyQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;注意：我们的机器人分类不包括只专注于开发无人机软件的公司，并根据我们的数据排除了债务融资的公司。这张图并不涵盖这一领域的所有公司。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面是投资亮点：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;中国：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;2015 年，全球大约 8% 的机器人创业公司投资都发生在中国。英特尔资本（Intel Capital）去年投资了两家创业公司：个人运输机器人 Ninebot 和无人机初创公司 Yuneec；加速合伙公司（Accel Partners）B 轮 7500 万美元投资了大疆创新（DJI innovations）；红杉资本（Sequoia Capital China）A 轮 500 万美元投资了工业机器人创业公司 Quotient Kinematics。今年到目前，共有 7 家创业公司募集到了投资。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;法国：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;2016 年，全球机器人创业投资中，法国的交易份额超过了 6%。工业机器人创业公司 Delair -Tech 获得法国投资公司 Andromede1415 万美元的投资，创下今年单轮最高投资金额。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;印度：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;2016 年，印度机器人创业公司投资交易占全球的 5% 多。Accel Partners India 在 2016 年第一季度投资了班加罗尔的工业机器人创业公司 Systemantics。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;英国：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;2016 年截止第三季度，英国占去了超过 4% 的全球机器人创业公司投资交易。上一季度就有三家公司获得了投资：剑桥医疗机器人（Cambridge Medical Robotics）从 ABB Technology 和 Escala Capital 那里获得了 A 轮 2000 万美元的投资；社会化机器人 Olly 从 Lightning Capital 和 Alliance Capital Ventures 那里获得了 A 轮 1000 万美元的投资；正在筹建的教育机器人创业公司 tio 从 Kickstarter Accelerator 那里获得了种子资金。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Smart Money VCs：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;今年第二季度，CRV 以 2850 万美元在系列 A 轮 B 轮中投资了以色列自动无人机初创公司 Airobotics。Battery Ventures 投资了另一家以色列自动无人机创业公司 Dronomy。Accel Partners 和 红杉资本投资了大疆创新。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;单轮融资最高：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;自 2015 年一月以来（排除美国），单轮融资最高的前四家创业公司都来自中国。仿人机器人创业公司 UBTECH 获得了 B 轮 一亿美元的投资并与今年第三季度跻身独角兽俱乐部。Ninebot 从小米和红杉资本那里获得了 8000 万美元的投资。大疆创新 B 轮融资 7500 万美元，Yuneec 获得了英特尔资本的 6000 万美元投资。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心经授权编译，机器之心系今日头条签约作者，本文首发于头条号，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Fri, 14 Oct 2016 12:13:00 +0800</pubDate>
    </item>
    <item>
      <title>活动 | 11月3-5日，机器之心带你躁动今秋第一场跨界大会GIC</title>
      <link>http://www.iwgc.cn/link/3066150</link>
      <description>&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;11月3日-5日由Y星人社区主办、机器之心作为前沿科技合作媒体的全球创新者大会（GIC）将在京召开，届时，来自全球20多个国家的100多位重量级嘉宾，&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;em style="color: rgb(136, 136, 136); line-height: 1.75em;"&gt;&lt;span&gt;共同跨界探讨科技、自然、文化和商业。这是一篇福利贴，Y小星为大家送上了价值399美元的GIC门票。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2016全球创新者大会（GIC）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;将在11月3日-5日如约而至，&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;等待，是美丽的，当然也是有福利滴。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;今天，Y小星就为大家送上——&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;价值399美元的超级福利&lt;/span&gt;！&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/Uqve8RQtb7nqfEA9KFdASCatmnxmeMlicfYsODlxvrssyQ9rX3JYMibZMFia0uceicfOIPY0WdxExbVia9n8iapNgoYw/640?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/pWm1O3dq2vUPiaicdib9GCWCjJ2Ria64ACbJLUfv7S3Dia4CVNZic0wyQnkt6bjibbUfgp0ic2ha5ZPwWV3ibQicQOMvdrVw/640?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;span&gt;所以&lt;span&gt;&lt;strong&gt;&lt;span&gt;价值399美元的GIC门票&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;，&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;可以让乃们听到美国国家航空航天局、Airbnb、&lt;span&gt;无印良品、&lt;/span&gt;奇点大学、麻省理工大学、&lt;span&gt;故宫博物院、&lt;/span&gt;Pitango&lt;/span&gt;&lt;span&gt;（以色列最大的风投机构）&lt;/span&gt;&lt;span&gt;、&lt;span&gt;百度、&lt;/span&gt;乐视、&lt;span&gt;蚂蚁金服、&lt;/span&gt;联想等大牌公司或机构的故事。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了低调，Y小星是不会告诉你还有美国通用人工智能协会、世界超人协会、日本二期俱乐部、FMC、法国城市建设、卡地亚珠宝等机构也会齐聚全球创新者大会（厉害了word GIC）......好吧！&lt;span&gt;&lt;strong&gt;实际上，嘉宾来自20多个国家，共有100多位；议题涉及科技、文化、自然、商业四大领域。来啊，造作吧！&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;点击下方&lt;/span&gt;&lt;span&gt;&lt;strong&gt;【阅读原文】&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;，&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;你即可了解2016 GIC的嘉宾与议题！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;注意！&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;这仅是GIC超级嘉宾的第一弹，&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;后续将有神秘大咖登陆GIC，&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;敬请关注！&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;福利领取方法&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;点击&lt;strong&gt;&lt;span&gt;【阅读原文】&lt;/span&gt;&lt;/strong&gt;后&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;将H5页面转发至朋友圈并截图&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;将截图发送至&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;『GIC全球创新者大会&lt;span&gt;』&lt;/span&gt;&lt;/span&gt;&lt;span&gt;微信公众帐号&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;即有机会领取福利！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;可以扫码下方二维码关注哦！&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;共计赠出30张门票，赠完即止。&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;特别鸣谢！&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;无所不能的《腾讯科技》，&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;宇宙时间间隙中的《不存在日报》，&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以及回到未来的《机器之心》，&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/Uqve8RQtb7nqfEA9KFdASCatmnxmeMlic2I7XSGQDbCSMWJicfJpichHtqMoAFSercmich2PmeRWWicsGHrnETqOxzg/640?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/pWm1O3dq2vVZo4rPufpLaaplCtw6E2tj0u75s7QGYeehoicibCsgZ9R79xtVUYibahxXgoibL2yOA2QTiaPOiakZg4KA/640?wx_fmt=jpeg"/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Fri, 14 Oct 2016 12:13:00 +0800</pubDate>
    </item>
    <item>
      <title>重磅 | 奥巴马再谈人工智能：我们的经济模型需要适应新技术</title>
      <link>http://www.iwgc.cn/link/3052016</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;选自连线&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;参与：李泽南、杜夏德&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;em style="color: rgb(136, 136, 136); font-size: 14px;"&gt;&lt;span&gt;本周四白宫发布了两份重磅报告，《为未来人工智能做好准备》以及《美国国家人工智能研究与发展策略规划》，详细阐述了美国未来的人工智能发展规划以及人工智能给政府工作带来的挑战与机遇。对此，连线专访奥巴马，畅谈了美国未来的人工智能计划，以及智能机器给美国社会所带来的问题。在访谈中，奥巴马提到需要重新设计新的社会契约来适应技术给人类社会带来的变革。&lt;/span&gt;&lt;/em&gt;&lt;br/&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;很难想象有什么比人工智能更能塑造未来 50 年中我们的世界了。机器学习使得计算机可以自我训练，从医疗诊断到自动驾驶汽车，各种技术突破近在眼前。与此同时，担忧也开始出现，谁来掌控新技术？它们会抢走我们的工作吗？人工智能是否危险？美国总统奥巴马也正在考虑这些问题。对此，他与企业家和麻省理工媒体实验室主管伊藤穰一（Joi Ito）展开了对话。我也加入了这场在白宫里有关希望，谣言，恐惧之于人工智能的讨论。当然，还有关于电影「星际迷航」的一些小问题。──「连线」主编 Scott Dadich&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;SCOTT DADICH（以下为 DADICH）:感谢各位的到来。总统先生，最近过得怎么样？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;奥巴马：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;忙碌而富有成效。你知道，世界各地还有很多危机需要解决。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;DADICH：我把这次会谈的主题定为人工智能，它将会从科幻小说中走出，来到我们的现实生活中。以你所知，真正的人工智能何时会来到我们身边？&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;奥巴马：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;在我看来，人工智能已经通过很多方式逐渐渗透进我们的生活了──只是没有被注意到；一部分原因是因为我们以人类自己的样子想象人工智能。在广义和狭义的人工智能之间有很大的区别，但很多人不会去搞清楚。在科幻小说里，你们所看到的人工智能是广义的。计算机开始变得比人类聪明，它们开始思考，认为我们不再有存在的意义，然后它们要么让我们保持肥胖和开心，要么把我们丢进虚拟世界中。我的观点是，基于我和我的顶尖科学顾问的讨论，目前的情况和小说里的情节还相距甚远。但这种担忧值得思考，因为它能让我们展开思路，去考虑在狭义的人工智能发展中有关选择和自由的宏观课题，它们现在还只是在利用算法的计算机来帮助我们完成越来越复杂的任务。人工智能的影子已在我们的生活中不断出现了，从医疗到交通到电力调配，它有希望创造更高效的经济环境。如果监管得力，人工智能的发展将会带来广泛的繁荣和机会。但它也许会使得工作机会减少，增加不平等，压缩人们的工资。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;伊藤穰一（JOI ITO，以下为 ITO）&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：这也许会让我在麻省理工学院的一些学生感到担心，我的一个担忧是：现在有不少的男性，大多数是白人──他们是开发人工智能计算机科学的核心力量──他们在更多地关注计算机，而不是人类本身。他们其中很多人觉得只需要像科幻小说里一样，随心所欲地发展广义的人工智能，而不需要担心任何政治与社会的「琐事」。他们觉得机器会帮我们解决这些问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;奥巴马&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：是的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;ITO：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;但是他们低估了这些问题，我觉得今年是让人工智能变得不再仅仅是计算机科学问题的一年。所有人都需要知道人工智能的价值观十分重要。在麻省理工媒体实验室里，我们用术语「延展智能（extended intelligence）」来表达这个问题。因为问题是，如何将社会价值观注入人工智能？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;奥巴马：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;当我们在午餐后回来时，Joi 用自动驾驶汽车作为例子。人工智能的技术实际上已经到来了。我们拥有可以做出大量快速决策的机器，可以显著减少交通事故的数量，显著增加目前交通网络的运行效率，同时还能帮助解决碳排放和全球变暖等环境问题。但 Joi 同时点出了问题，我们正在放进汽车的东西，它们的价值观是什么？还有大量问题必须解决，比如最经典的问题：如果你在开车，你需要急转弯避让行人，但这样你有可能撞墙害死你自己。这是一个道德上的抉择，但由谁来制定规则呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;ITO：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;谈到有轨电车难题，我们会发现大多数人希望驾驶员和乘客能够牺牲自我，拯救更多的人。他们还说他们永远不会购买自动驾驶汽车（笑）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;DADICH：我们正在讨论的是伦理问题，政府在其中扮演什么样的角色？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;奥巴马：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我考虑这个问题的通常框架是，人工智能的出现，在技术的早期，会百花齐放。政府在这个时期需要做相对很少的管控，提供大量投资来帮助研究，同时让基础研究和应用研究之间交流畅通。随着技术进入成熟期，找出如何让新出现的问题在已有框架中解决的方法是一个棘手的问题，政府需要在此阶段参与更多。不必总是强迫新技术进入已有框架中，但是需要保证新的规则能够反映广泛的基础价值。另外，新规则也许会损害某些人或某些群体的利益。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;ITO：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我不知道你们是否了解多元神经（Neurodiversity）运动，但电影「自闭历程」（Temple Grandin）中存在很多有关情节，女主角在片中说莫扎特，爱因斯坦和特斯拉假如生活在今天，可能都会被认为是有自闭倾向的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;奥巴马：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;他们是有可能得过自闭症。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;ITO：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;是的，得了自闭症。而如果我们有能力彻底消灭自闭症，让所有人都神经正常，我敢打赌很多麻省理工学院的学生都会变得大有不同。其中一个问题，无论我们在讨论自闭倾向还是广泛的多样性，这些问题只有我们让市场自由选择后才会出现。即便如此你可能也不会愿意让爱因斯坦成为你的孩子，你会说：「好吧，我只想要一个普通的孩子」这不会是使社会受益最大的选择。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;奥巴马：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;这会是我们围绕人工智能展开的主要伦理争论。其中的一部分会让人类变得扭曲。事物的发展过程中总会存在突变，异常，瑕疵，而往往这些才是新创造的灵感，对不对？我们一直假设，假如系统是完美的，它会是静态的。而让我们成就自己的那部分，让我们生存至今的那部分，是动态和令人惊讶的。我们必须思考，在什么时间，什么地点，这样的事情会发生，我们能否欣然接受。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;DADICH：当我们在讨论智能的发展时，它的研究同时存在于政府，私人企业和学术界，但其中谁来扮演核心角色，是否存在一个中心？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;ITO：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我相信麻省理工学院会说这个中心是我们（笑）。历史上同样的技术发展大多基于被政府资助的各类学院。但现在科技公司的许多大型研究机构成为了主流。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;奥巴马：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我们知道是谁在资助这些机构，如果你在说拉里·佩奇或者其他人，他们的看法，可以想象是：「我们最不想看到的就是在寻找独角兽的过程中有一帮官僚在拖我们后腿。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;问题的一部分是，我们正在目睹旨在为社会服务的基础研究在逐渐衰退。我们的雄心正被意识形态或各种争议逐渐冷却。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最好的例子就是：今天，我们仍在从 50 年前登月计划这一巨大成就中受益。有人告诉过我，太空探索计划在那时的花费只占 GDP 的 0.5%。这听起来不像一个很大的数字，相当于在如今每年投入 800 亿美元。在人工智能方面，现在我们每年的投入不到 10 亿美元，这个数字无疑需要增加，但我们需要明白的是，如果我们想要在这些突破性技术中代表的多元化的价值观，政府资助必须身在其中。而如果政府并没有资助这些研究，那么 Joi 刚才谈到的那些有关人工智能的价值观的所有问题有可能会导致失败，至少不会获得适当的讨论。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;DADICH：你的观点让 Joi 曾写到的事情变得更加令人不安了：人工智能和太空计划发展历程中的差异。我们如何来确保这些想法被所有人知道？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;奥巴马：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我一直试图强调这些，因为政府正在资助人工智能的发展，帮助收集数据，这不意味着我们在囤积数据，或者仅仅将其用于军事目的。有一个很好的例子：我们精密医疗计划的一部分已经收集了足够的人类基因组数据，多样性覆盖到了所有的美国人。在这件事上我们并没有向斯坦福或哈佛大学注资──他们仍在囤积样本──我们现在的基因数据库非常完整，同时所有人都有权访问。政府有最完整的价值体系，结构，去保证研究结果得到分享，不会让某个团体单独受益。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Dadich：但是风险肯定是&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;有的。我们已经听说埃隆·马斯克和 Nick Bostrom 担心人工智能的潜在能力会超过我们对它的理解。当我们前进时，我们该如何考虑这些忧虑，不仅是为了保护我们自己还有整个人类？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;奥巴马&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：我来说说现在更让我担心的事——这是目前人工智能领域里的一个可以解决的问题，我必须注意到它。如果你有一台能下围棋的计算机，这是一种变化复杂的游戏，以此开发出一种能让你从纽约证券交易所最大获利的算法是显而易见的事情。而且，如果一个人或组织能率先开发出这个算法，他们就能很快弄垮交易所，最起码他们可以破坏金融市场的完整性。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;之后可能又会有一个算法说，「去搞定核代码，搞定某些导弹的发射。」如果算法的工作只是这些，如果它能自我教导，那它还真是一个效率挺高的算法，但是你们可能就会有麻烦了。我想我对我的国家安全局的建议应该是，不要过于担心机器会占领整个世界。要担心的是非国家势力或敌对势力渗入系统的能力，在这个意义上，它与我们做的很多事情在概念上没什么不同。仅仅意味着我们必须得做到更好，因为那些能会破坏我们系统的人现在已经做的比我们好了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;ITO：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我大体同意你的说法。唯一需要注意的是还有一些人相信广义人工智能 10 年后出现的几率相当高。但是依我看要实现这个理想，还有一二十个需要突破的地方。所以当你认为这些突破会要出现时，你可以监控它们。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;奥巴马：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;你只需要在它们的核心部位安插个线人就可以了（大笑）。是的，当你知道它快出现时，就赶紧收线。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;ITO：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;重要的是找到那些想用人工智能造福人类的人——群体或领导人——想好怎么帮他们使用人工智能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;奥巴马：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;传统上看，当我们考虑到安全和自我保护时，我们想到的是武器和筑墙。逐渐地，我发现自己开始转向药物，并开始考虑使用病毒、抗体。网络安全一直很难做好的部分原因是你面临的威胁不是一批开向你的坦克，而是一整套可能马上会受到蠕虫病毒侵害的系统。也就是说我们得换种思维考虑安全问题，做出不同的投资，有些可能看起来不那么诱人，但可能最终会成为举足轻重的东西。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我常常担心像流行病这种问题。因为你不可能建一堵墙来防止有人登陆海岸后，从空中播撒致命流感病毒。所以我们需要的是一个系统，在世界的每块地方创建公共健康体系，点击按钮就能告诉我们发现新情况，确保我们有快速的协议和系统能让我们可以快速制造出更好的疫苗。如果你有了一个公共健康模型，你就考虑一下我们该如何应对网络安全问题，这些最终都会对应对人工智能的威胁很有帮助。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;ITO：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;还有一件事我觉的很有趣，当我开始观察微生物时。很多证据显示引进好的细菌来对抗坏的细菌（不是消毒）是一个不错的策略。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;奥巴马：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;完全同意。不过我还是不会让 Sunny 和 Bo 舔到我，因为每次遛它们去草坪时，看到它们用嘴叼着或者啃咬什么东西时，我就很不舒服。（哈哈哈）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;ITO&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：我们不得不重新思考什么才是干净的东西，类似于你们谈论的网络安全或者国家安全。我认为，对于一个国家，你可以设定边界，也可以消除每一个可能的病菌，但是搞清楚什么是网络安全什么是国家安全却不是件容易的事情。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Dadich：这也会引发一场新型的军备竞赛吗？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;奥巴马：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我认为一定会有一套通用的国际网络安全规范、协议和验证机制，但是这套国际机制出现还为时尚早，尤其在人工智能方面。有趣的是在这个问题上，进攻和防守的界线非常模糊。当对政府的不信任逐渐增多时，事情就会变得困难起来。不要等到有别的国家将美国视为超级网络霸权，现在我们就可以说，「我们愿意克制自己，只要你也愿意克制自己。」这个挑战来自于最复杂的国家——俄罗斯、中国、伊朗——它们并不总是遵循那些我们拥有的共同价值观和准则。我们必须要把这国际议题提上表面，以便高效地处理它。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;ITO：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我想我们正处于一个人们想要交流讨论的黄金时期。如果我们能确保资金和能源可以持续公开共享，一定会有很多好处。相互隔绝的环境没有好处，而且现在已经是国际化社区时代了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;奥巴马：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我觉得 Joi 说的非常对，而且那也是我们为什么不断召开一系列的会议让每个对此感兴趣人都参与进来的原因。有一件事我们还没有讨论太多，那就是我们确实得考虑一下经济影响。因为大多数人现在不会花时间去担心奇点（singularity）的问题，他们担心的是「好吧，我的工作是不是要被机器取代了。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我更倾向于乐观的态度——从历史上看，我们已经接纳了很多新技术，而且人们发现也会有新的工作出现，他们不断迁移，我们的生活水准也大体上升了。我确实认为我们所处的时代有点不同，仅仅是因为遍地都是人工智能和其他技术的应用。掌握高技能的人在这个环境中如鱼得水。他们可以利用自己的才华，他们可以借助机器来延伸他们市场，他们的销售，他们的产品和服务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;廉价低技术的人会越来越不受市场欢迎，他们的工作或许不会被替代，但是薪水会压得很低。而且如果我们想要成功完成这个过渡，我就必须要发起一次社会讨论。如果我们正在生产的更多成果，而且这些成果越来越多地集聚到社会顶层群体的手上，我们又将如何培养并确保经济的包容性呢？我们如何确保普通人能有一份稳定的收入呢？这对于我们支持的那些艺术、文化或者保证退伍军人获得保障的事情又意味着什么呢？社会契约必须适应这些新技术，我们的经济模型也必须适应它们。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;ITO：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;不仅仅是工作被取代这类直观的现象，因为我敢打赌只要你有一台能理解医疗系统的计算机，而且擅长诊断，那么医生被替代的可能性要比护士和药剂师大，因为后者的薪水更低。还有一些高层次的工作，如律师和审计师也可能会消失。但是还有很多服务业务、艺术和计算机无法胜任的工作不会被替代。我不知道你们怎么看待普遍的基本收入，但是当我们看到人们的工作被取代时，我们还可以考虑一下其他的模型，比如学术界或艺术界，这些人的目标并不直接指向金钱。我认为其中的一个问题是：普遍的观念是如果你没钱，你怎么能变得更聪明呢？在学术界，我见过很多没有钱的聪明人。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;奥巴马：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;你说对很对，我说的重新设计社会契约就是这个意思。现在，普遍的收入是不是适当的模型，它有没有广阔的民众基础？也是我们未来 10 到 20 年要辩论的问题。还有你说的人工智能不仅会取代低技能工作也对；那些高技术但重复性的工作以及计算机能胜任的工作都将被取代。还有一个不争情况是随着人工智能不断整合，社会越来越富裕，产品与分配之间的联系，你干了多少工作与你挣了多少钱之间的关系都会变得越来越弱。计算机干了很多工作，它却不拿一分钱。结果我们就必须作出一些更艰难的决定。我付给教师的工资会很少，尽管那是一份艰巨的工作，计算机想要做好这份工作也不容易。所以对于我们来说，重新审视我们看重的东西，我共同愿意付出的是什么，不论是教师、护士、护工、母亲还是居家父亲、艺术家，所有这些现在对我们来说都非常重要但其薪水处于低端的人，我们需要在一起对话。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Dadich：总统先生，您在政府中发现了什么可以解决这个最大挑战的技术？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;奥巴马&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：我们还有大量工作要做，要让政府变得更加亲民，让纳税想订披萨、机票一样便捷。无论是鼓励民众参与选举还是释放大数据让人们使用起来更加便利，或者让数据在网上处理起来更加简单。这些问题都随着联邦政府、州政府和地方政府进入了 21 世纪。联邦政府里的人才与私人公司里的人才一样有能力，尽管技术上的差距依然巨大。当我第一次来这里，我总是想象情报室是最酷的地方，就像汤姆·克鲁斯在《少数派报告》中演的一样。但实际一点也不一样。（哈哈哈）尤其是在追捕地球另一边的恐怖分子时，电影展现的是我们掌握了全局。但是真实情况并非如此，资金缺口很大，设计上也有错误。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从技术上更宽泛的问题来说，我坚信如果我们能恰当改变气候，如果我们能启动制动系统，找出避免海平面上升 6 英尺的方法，那就是人类要解决的问题。我非常乐观。而且我们做了很多有益的工作，但路还很长。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;要找出一种可负担起的、透明的、安全的方式来规范网络连接性，能让我们发现不法分子，但同时确保政府不对我们的生活掌握过多的权力，以至于出现压迫。我们一直在努力做这些事情。有些问题解决起来需要技术，比如加密。我已经与公民自由主义人士和国家安全局的人会面过很多次了。这确实是个棘手的问题，因为在这些议题上，没人能给我一个真正的好答案。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因为这是一个前沿问题，最后我还要提醒你我是一个宇宙科幻迷，认为下一代太空旅行方式的研究正严重缺乏资金支持。目前私人企业对此有一些不错的成果，因为事实上它是政府投资的真空区域，他们正在探索一些疯狂的点子「见鬼，为什么不呢？」。当我们想到太空飞行，我们仍然只有和五十年前阿波罗计划中一样的化学推进系统。我觉得我们现在需要──比如「星际迷航」里的 dilithium 晶体──但是你知道，这还需要很多方面的技术突破。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;DADICH：我知道你是「星际迷航」的粉丝。那是一部灵感来自科技的电影──你心中的未来是什么样的？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;奥巴马：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;在我小的时候，我为「星际迷航」而着迷。这个系列总是非常有趣。让它长盛不衰的不仅仅是其中的科幻成分，更在于其中关于价值和友情的探讨。因此，旧版的低特效并没有影响我们的观感，不是吗？在剧中，他们在一个星球上着陆，那里覆盖着纸做的岩石（笑）。但这都无所谓，因为「星际迷航」其实是在讲述有关人性和勇敢的故事。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有一部最近的电影也在表现同样的精神──火星救援。不是因为它有着宏大复杂的情节，而是因为他在讲述一个很多不同的人共同解决一个问题的故事。通过展现创造性，坚韧不拔和努力工作，同时保持自信，我们可以战胜巨大的困难。这就是为什么我如此热爱美国，它那种面对挑战说：「哦，我们可以做到。」的精神至今仍在吸引着全世界的人们不断前来。我最看重科学的地方也在于这一点，我们可以做到。我们可以试试这个──如果这样不行，我们来看看它为什么不行，然后我们再试试别的方法。我们会陶醉于我们的错误中，因为失败是成功之母。而如果我们失去了这种精神的话，我们就脱离了美国人的本质，我认为这也是人类的本质。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;ITO：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我完全同意──我喜欢「星际迷航」中的乐观主义。但我同时也认为其中的星际联邦有着惊人的多样性，进取号的船员也有着多样性，而那些反派也不是完全的邪恶──他们往往只是误入歧途。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;奥巴马：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;「星际迷航」，就像所有好故事一样，告诉我们所有人都是复杂的，我们都有一点史波克，一点柯克（笑）和一点史考特，也许还有一点克林贡，不是吗？但这就是我在说可以做到的意思。一部分是跨越隔阂与差异排除万难。我们对理性抱有谨慎的信心。这在艺术和科学中都是对的。我们目前拥有的这些难以置信的感觉，仅仅还是表面，我们不应狂妄自大。我们需要时刻提醒自己，有很多的事物还有待探索。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em style="color: rgb(136, 136, 136); font-size: 12px;"&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em style="color: rgb(136, 136, 136); font-size: 12px;"&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibZF0R7M7A97iajltKvGkDSInKKEDFI9lOMRvmAEDX0ZOCpZSia2o1u5TBRSBYoKBKygYpywbYgnKOw/0?wx_fmt=jpeg"/&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;em&gt;点击&lt;/em&gt;&lt;/span&gt;&lt;span&gt;&lt;em&gt;「阅读原文」&lt;/em&gt;&lt;/span&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;报名机器之心西雅图分享活动&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;span&gt;&lt;em&gt;。&lt;/em&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 13 Oct 2016 15:04:09 +0800</pubDate>
    </item>
    <item>
      <title>业界 | DeepMind深度解读Nature论文：可微神经计算机</title>
      <link>http://www.iwgc.cn/link/3052017</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;选自DeepMind&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;DeepMind 最近发表于 Nature 的一篇论文《Hybrid computing using a neural network with dynamic external memory》介绍了一种记忆增强式的神经网络（memory-augmented neural network）形式，其被称为可微神经计算机（differentiable neural computer），研究表明其可以学习使用它的记忆来回答有关复杂的结构化数据的问题，其中包括人工生成的故事、家族树、甚至伦敦地铁的地图。研究还表明它还能使用强化学习解决块拼图游戏（block puzzle game）问题。本文是 Google DeepMind 对这项新公开的成果的官方解读。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;柏拉图将记忆（memory）比作是一块蜡片——一旦在其上留下了一个印象（impression），那个印象就会凝固下来。他的这个比喻表达了现代的可塑性（plasticity）的概念，即我们的心智可以被经历所塑造和重塑。但我们的记忆之蜡不仅能够塑造印象，还能塑造一个记忆到另一个记忆的连接（connection）。John Locke（注：知识论上英国经验主义的三位代表人物之一）这样的哲学家认为当记忆在临近的时间和空间被塑造时，它们就会连接起来。表达这一观点的最有效的比喻不再是蜡片，而是 Marcel Proust（注：20 世纪法国最伟大的小说家之一，意识流文学的先驱与大师）的马德琳蛋糕（madeleine cake）；在 Proust 看来，这是一种在他成年之后释放童年记忆的甜品的味道。我们现在已经知道这些情景记忆（也叫事件记忆）依赖于人脑之中的海马体。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今天，我们对记忆的比喻已经得到了更精细的锤炼。我们不再将记忆看作是蜡片了，而看作是一个重新构建的过程（reconstructive process），其中经验可以使用其组成部件进行重组。而且也已经不再是刺激（stimuli）和行为响应（behavioural responses）之间的简单关联，记忆和行为之间的关系可以根据背景和优先级的状况而发生改变。一个简单的记忆中的知识，比如对伦敦地铁布局的记忆，可以被用于回答「从 Piccadilly Circus 到 Moorgate 该怎么走？」以及「那条线可以直达 Moorgate，坐 Northern Line 向北走？」这样的问题。这完全依赖于问题是什么；记忆的内容和记忆的使用可以分开。另一种观点认为记忆可以被组织起来以执行计算。比起蜡片，这更类似于乐高积木——记忆可以根据当前的问题而重新组合。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;神经网络擅长模式识别和快速反应的决策，但我们现在才刚刚开始造出只能缓慢思考——即用知识进行权衡或推理——的神经网络。比如说，神经网络可以如何存储有关事实的记忆（比如一个交通网中的连接），然后使用其知识片段进行合乎逻辑的推理以回答问题？在最近的一篇论文（doi:10.1038/nature20101）中，我们展示了神经网络和记忆系统（memory system）可以如何结合起来以得到可以快速存储知识并用其灵活进行推理的学习机器。我们将这些模型称为可微神经计算机（DNC: differentiable neural computer），它们可以和神经网络一样从样本中学习，但它们也能和计算机一样存储复杂的数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在普通的计算机中，处理器可以从随机存取存储器（RAM）中读写信息。RAM 为处理器提供了远远更多的空间来组织计算的中间结果。用于信息的临时占位符被称为变量（variable），它们被存储在内存（memory，注：和「记忆」的英语词一样）中。在计算机中，构建一个保存数值的变量是很简单的操作。构建数据结构（data structure）同样也很简单——数据结构是指可以跟随内存中包含链接（link）的变量获取其它变量的结构。一种最简单的数据结构被称为表单（list）——可以逐项读取的变量序列。比如：可以存储一个运动员团队的运动员名字列表然后逐一读取每个名字。树（tree）是一种更复杂的数据结构。比如，在一个家族树中，可以根据子代和亲代之间的链接读取出祖系情况。而图（graph）是一种最复杂又最常见的数据结构，比如伦敦地铁网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当我们设计 DNC 时，我们想要机器能够学习自己构建和引导复杂的数据结构。DNC 的核心是一个被称为控制器（controller）的神经网络，其类似于计算机中的处理器。控制器的作用是获取输入、读取和写入记忆、以及生成可以被解读为答案的输出。而其记忆（memory）则是一个位置（location）的集合，其中每个位置都存储了一个信息向量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;控制器可以在记忆上执行多种操作。在每一个时钟，它都会选择是否写入记忆。如果它选择写入记忆，它可以选择将信息存储在一个新的、未经使用过的位置或已经包含了该控制器正在搜索的信息的位置。这让控制器可以更新一个位置所存储的内容。如果记忆中所有的位置都用尽了，该存储器可以决定释放一些位置，这就像计算机可以重新分配不再需要的存储空间一样。当该控制器执行写入时，它会发送一个信息向量到记忆中被选中的位置。每一次写入信息时，这些位置都会被关联链接（links of association）连接起来，这代表了信息被存储的顺序。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除了写入，控制器也可以从记忆中的多个位置读取信息。它可以基于每个位置的内容对记忆进行搜索，即可以通过关联时间链接（associative temporal links）向前和向后回调以顺序或反序写入的信息。其读取出的信息可被用于生成问题的答案或在某个环境中要采取的行动。总的来说，这些操作让 DNC 可以选择如何重新分配记忆、在记忆中存储信息、以及轻松地找到存储在记忆中的信息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibZF0R7M7A97iajltKvGkDSIMgD1TIMrOf5PiasGalLwooZFuSHbjBuBWhjCQflXrmRF1N2JJGGZf2Q/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;DNC 架构的图示。其神经网络控制器可接收外部输入，并基于这些输入通过读取和写入操作（这些操作被称为 head）与记忆进行交互。为了帮助控制器引导记忆，DNC 会存储「时间链接（temporal links）」以追踪内容被写入的顺序，DNC 还会记录每个记忆位置的当前「使用（usage）」水平。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;没有技术背景的读者可能对我们不断重复使用的「该控制器可以……」或「可微神经计算机……做出选择」这些短语会感到一些奇怪。我们这样表述是因为可微神经计算机可以完全从头开始学习如何使用记忆和如何得出答案。它们使用优化（optimisation）的魔力学习做到了这一点：当一个 DNC 生成一个答案时，我们会将这个答案与我们想要的正确答案进行比较。随着时间的推移，该控制器可以学会生成越来越接近正确答案的答案。在这个过程中，它会搞清楚如何使用它的记忆。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们想在涉及构建数据结构的问题上测试 DNC 以及使用这些数据结果来回答问题。在表征任意连接的构成路径和循环的数据项方面，图（graph）数据结构是非常重要的。在这篇论文中，我们的研究表明 DNC 可以自己学习写出关于任意一个图的描述并回答有关的问题。当我们描述伦敦地铁的站点和线路时，我们可以问 DNC 这样的问题：「从 Bond 街出发，乘坐 Central 线往一个方向走一个站，再乘坐 Circle 线往一个方向走四个站，然后再乘坐 Jubilee 线往一个方向走两个站，你会到达哪个站？」或者，该 DNC 可以为「从 Moorgate 到 Piccadilly Circus 该怎么走？」这样的问题规划路径。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibZF0R7M7A97iajltKvGkDSInib85iak4pTTy101n4APt9C6HLqEYD3efCP9nJZ2YYzcQ2skan5Nd7Qg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;使用随机生成的图（graph）训练 DNC（左图）。训练之后对其进行测试，看其能否导航伦敦地铁（右图）。其三元组（出发、路径、到达）被用于定义下面所示网络的图，另外还带有两类任务的样本：「遍历」（其被要求从一个站点开始并沿一定的路线序列规划）和「最短路径」（其被要求找到两个站点之间的最快路径）。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们的研究表明，DNC 可在一个家族树中回答需要复杂推演的问题。比如，即使我们仅给该网络描述了亲代、子代和兄弟姐妹关系，我们仍然可以提出「谁是 Freya 的大舅舅？」这样的问题。我们还发现可能能够通过可视化控制器读取了记忆中的哪些位置以生成答案来分析 DNC 使用它们的记忆的方式。我们用作对比的卷积神经网络要么不能存储信息，要么就不能以一种可以泛化到新样本的方式学习推理。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;iframe class="video_iframe" data-vidtype="1" style="   z-index:1; " height="375" width="500" frameborder="0" data-src="https://v.qq.com/iframe/preview.html?vid=n0336x3u41g&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0" allowfullscreen=""&gt;&lt;/iframe&gt;&lt;br/&gt;&lt;/span&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;DNC 回答一个有关家族树的问题&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们还能通过强化学习训练 DNC。在这个框架中，我们让 DNC 生成行为但绝不向其展示答案。而是当其生成了一个良好的动作序列后给其打分（类似于小孩子的游戏 hot or cold）。我们将一个 DNC 连接到了一个带有以堆积形式排列的彩色块的简单环境中。我们给了它要实现的目标的指令：「将淡蓝色块放到绿色块下面；橙色块放到红色块左边；紫色放到橙色下面；淡蓝色在深蓝色右边；绿色在红色下面；紫色在绿色左边」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;iframe class="video_iframe" data-vidtype="1" style="   z-index:1; " height="375" width="500" frameborder="0" data-src="https://v.qq.com/iframe/preview.html?vid=b0336txiqq1&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0" allowfullscreen=""&gt;&lt;/iframe&gt;&lt;br/&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;DNC 解决一个移动块问题&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们可以设立大量类似的可能的目标，然后让该网络执行行动，这些行动能够依据命令产生一个或另一个目标状态。在这个案例中，还是和计算机类似，该 DNC 可以在记忆中存储多个子路径，一个可能的目标存储一个，然后执行一个或另一个。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人类记忆的工作方式的问题由来已久，而我们的理解仍在发展之中。我们希望 DNC 既能为计算机科学提供一种新工具，也能为认知科学和神经科学提供一个新的比喻：这是一个不需要预先编程就能将信息组织成互连的事实并能使用这些事实解决问题的学习机器。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;论文：使用带有动态外部记忆的神经网络的混合计算（Hybrid computing using a neural network with dynamic external memory）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：&lt;/span&gt;&lt;span&gt;人工神经网络非常擅长感官信号处理、序列学习和强化学习，但由于缺乏外部记忆（external memory），它们在表征变量和数据结构以及长时间存储数据上的能力却很有限。这里我们介绍一种名叫可微神经计算机（DNC: differentiable neural computer）的机器学习模型，该模型由一个可以读写外部记忆矩阵（external memory matrix）的神经网络构成，这类似于传统计算机中的随机存取存储器（RAM）。它既可以和传统计算机一样使用它的记忆（memory，注：对应于传统计算机的「内存」）表征和操作复杂的数据结构，也能和神经网络一样从数据中学习这么做的方法。当使用监督学习进行训练时，我们发现 DNC 可以成功回答设计用来模仿自然语言中的推理和推断问题的合成问题。我们表明 DNC 可以学习寻找特定点之间的最短路径和推断随机生成的图中所缺少的链接等任务，然后还能将这些任务泛化到交通网和家族树等特定的图上。当使用强化学习进行训练时，DNC 可以完成移动块拼图任务，其中变化的目标又符号的序列指定。总而言之，我们的结果表明 DNC 有能力解决对没有外部读写记忆的神经网络而言难以解决的复杂的结构化任务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em style="color: rgb(136, 136, 136); font-size: 12px; text-align: justify; white-space: pre-wrap;"&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibZF0R7M7A97iajltKvGkDSInKKEDFI9lOMRvmAEDX0ZOCpZSia2o1u5TBRSBYoKBKygYpywbYgnKOw/0?wx_fmt=jpeg"/&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;em&gt;点击&lt;/em&gt;&lt;/span&gt;&lt;span&gt;&lt;em&gt;「阅读原文」&lt;/em&gt;&lt;/span&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;报名机器之心西雅图分享活动&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;span&gt;&lt;em&gt;。&lt;/em&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 13 Oct 2016 15:04:09 +0800</pubDate>
    </item>
    <item>
      <title>专访 | Orbeus 夏威：「嵌入式」和「云」是计算机视觉未来发展的两大方向</title>
      <link>http://www.iwgc.cn/link/3052018</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心原创&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;机器之心团队&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;2012 年，Orbeus 的两位来自波士顿大学的联合创始人中止了原定的博士项目并拒绝了来自 Google 的 offer，毅然走向了创业的道路。2014 年，他们推出了一款手机终端图片搜索与管理软件 PhotoTime，早于 Google 发布的同类产品 Google Photos，甫一首发就被苹果商店选为当季最佳新应用。创业三年后，这家硅谷的明星创业公司被亚马逊所收购，开始了一段新的征程。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在本次机器之心北美系列分享活动的西雅图站中，我们请到了原 Orbeus 的 Chief Scientist、现亚马逊公司的 Senior Scientist 夏威来进行技术分享并对他进行了独家专访。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以下为专访实录：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;机器之心：简单介绍一下 Orbeus 的发展历史？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;夏威：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;Orbeus 成立于 2012 年，主打人脸识别和场景识别的图像识别技术。最早由 Boston 的几个华人学生创立，创始人是王盟和刘天强。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;公司于 2012 年 7 月率先发布 Rekognition 云端图像识别服务的 API，方便开发者在自己的应用中整合图像识别功能。成功开拓近 7000 多家商业客户，遍布北美，欧洲和亚洲。2014 年推出了一款手机终端图片搜索与管理软件 PhotoTime，早于 Google 发布的同类产品 Google Photos。当时首发就被苹果商店选为当季最佳新应用，并被多家媒体报道。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;PhotoTime 利用云端的智能照片识别系统，可以从用户手机和云端（如 facebook，instagram，flickr，dropbox）上存储的所有照片中自动识别出人脸和关键的物体还有场景，并打上相应的标签关键词，使得照片的搜索和整理变的非常容易。PhotoTime 能识别出超过 3000 类的物体和场景，并允许用户一键分享图片给好友或者分享到主流社交网站。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2015 年底 Orbeus 被 Amazon 收购。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：Orbeus 两位来自波士顿大学的联合创始人当初为何中止原定的博士项目，甚至拒 Google 的 offer 来走上创业这条路？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;夏威：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;王盟当时在 Google 工作，有十余项美国和全球专利。当时在 Youtube 组工作的他发现 Youtube 上大部分的视频都没有标注，于是他萌生了用计算机视觉技术来对视频进行标注的想法，当然由于早期视频的运算量太大，于是就决定先从图像开始。在决定创业后，他们获得了哈佛 Harvard Pitch Competition 的第一名，而后进入了位于芝加哥的著名孵化器 Excelerate Labs (现在叫 TechStar)。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;之后搬到硅谷，先后获得真格基金，丰元创投等知名天使投资的青睐，开始进入快速发展期。公司于 2012 年 7 月率先发布 Rekognition 云端图像识别服务的 API，方便开发者在自己的应用中整合图像识别功能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我个人读 PHD 期间一直对 AI 方面的技术创业有着浓厚的兴趣，经常关注硅谷这块的动向，自己也曾在新加坡尝试过一些创业计划。偶然的机会通过朋友介绍认识了王盟，非常欣赏 Orbeus 的创业方向和愿景，于是一时冲动来到了硅谷，加入 Orbeus，任 Chief Scientist。我加入时，公司还只有几个核心成员。比较有意思的是，等我到了才发现，公司除了 CTO 王盟，只有我一个 Research Scientist，我这才明白了 Title 里 Chief 其实是 Only 的意思。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;之后公司拿到下一轮融资后团队也开始慢慢扩展，到被收购时有了十几个正式员工外加一些实习生。虽然团队一直不大，但成员单兵素质很强，各个都能独当一面。比如 PhotoTime 这款 APP 的实际开发团队只有包括陈毓珊博士在内的四五个人，而后来 Google 的同类产品 Photos 背后的开发团队是数百人。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：早期产品开发最难的部分在哪？是如何解决的？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;夏威：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;众所周知，大部分有监督的视觉识别算法都非常依赖庞大的计算资源和高质量的训练数据。早期最难的点我认为也主要在计算资源的成本控制和数据的获取上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;早在 Boston 刚开始创业的时候，王盟像捡破烂似的从学校实验室淘汰的机子里东拼西凑出了公司最早的服务器群。拿到融资后仍然秉持着节约至上的准则，从 eBay 淘了一堆二手零件来组装服务器，分别放置在公司机房和一个 Facebook 曾经的数据中心。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当然后期随着业务的扩展，慢慢的也开始在 AWS 上架设服务器群。另外一个很重要的方面是 GPU 训练集群的搭建，我们用 Nvidia 赞助的几块显卡搭建了最早的几台 training server，我们除了搞 research 外，也花了不少时间当硬件组装工程师。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2014 年的时候，我们自己 DIY 了一台配备了水冷系统 8xGPU 的服务器，之后又 DIY 了一台 14xGPU 的大杀器。这应该是当时我们知道的第一个支持 8xGPU 以上的单机训练系统，Nvidia 的 4xGPU 的 DIGIT BOX 已经是差不多一年之后的事情了。还记得当时晚上跑完实验，我们俩就在那锯管子，装水冷器，调试的时候噪音巨大到像飞机发动机，把几个员工逼的 work from home。在很长一段时间内，公司在计算资源这块的平均成本只有 AWS 的 1/10。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;早期这种极低的 burning rate 使得公司可以把有限的资金投入到产品研发。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数据这一块，除了收集各种公开的数据集外，早期我们通过免费授权我们的 API 给开发者使用换得对他们的数据的使用权（仅限于训练），之后慢慢谈了几个 Stock Image Website 的客户之后，就可以从他们那获得大量优质数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，因为这几年深度学习的井喷式发展，如何使得你的技术永远保持前沿是另外一个难点，我们必须得时刻关注领域的最新动态，并快速测试和迭代，不断的打磨产品。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibZF0R7M7A97iajltKvGkDSI8GhftKC4h8VONC8ZbdZgIOnEG0cvbpeNkNqiaJw7TlcUyXibicmwE1gKg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：从事 CV 领域创业的公司很多，你觉得你们能够快速发展、顺利拿到融资并被亚马逊收购的原因是什么？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;夏威：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我认为主要有三点：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;时机： Orbeus 成立于 2012 年，那一年 Alex 在 ImageNet 横空出世，正式开启了深度学习这几年火热发展的序幕。能够在当时开始创业，无疑是取得了一定的先机，使得早期可以更安心的打磨技术和产品，不至于陷入残酷的竞争。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;成本控制：如上面介绍的，硬件成本，对于公司规模的谨慎扩张。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;勇于跳出舒适区，快速迭代和创新：比如 14 年开始决定基于 rekognition API 开发一款 2C 的图片 APP 到 photoTime 的正式发布只用了半年多的时间。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：简述一下你们产品的识别过程是如何实现的？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;夏威：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;简而言之，就是在云端结合传统的 feature based network 和深度神经网络对图片进行分析，通过不同的网络来实现不同的功能，比如人脸检测，关键点定位，属性（表情，年龄，颜值），物体和场景识别等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：Google、Facebook 和微软等公司都有从事着 CV 方面的研究，你觉得你们和他们比有哪些优势？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;夏威：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;这其实基本就是创业公司和巨头相比的优缺点，相对巨头来说，创业公司在资源和 PR 方面有着巨大的劣势，比如 Google photos 的开发团队规模是 Phototime 的几百倍，广告预算更是高出 n 个数量级。但是相对巨头来说，创业公司的主要优势在于灵活性，快速迭代性，以及小团队之间沟通的高效性。比如，PhotoTime 早于 Google Photos 大半年发布；在 Microsoft 那个风靡朋友圈 how old.net 之前接近一年，我们就开发出了趣味测年龄和颜值的 Magic Mirror。哪怕在 how old.net 开发出来之后，还有开发者利用我们的 API 开发过恶搞版的 how dude.net 来判断一个人有多 man。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外一个不同点在于巨头往往有他的战略侧重，还是以照片管理这个应用为例，比如 Google photos 就基本只支持本地和上传到 Google 云端的照片，但从用户的角度来说，他的照片是散布在 Facebook，Instagram，Dropbox，Google 或者 Amazon 等各种云端的。这样为了使用 google photos，用户就得牺牲掉一定的便利性，而创业公司出身的 Phototime 就不存在这种战略考量，可以从用户出发，提供一个所有本地和云端相册的接口，通过视觉识别技术来达到全面智能检索和管理。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;机器之心：为何选择做开放平台？&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;夏威：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;可以服务更多的客户？哈哈，当然当时还有计算资源的制约，很多识别算法所需要的计算量在当时只有云端能提供。当时希望做 AWS 那样的技术提供商，我们提供 API，把图像识别技术嵌入到任何可以让它发光发热的领域，社交网络，电子商务，市场营销，图片视频整理等等。图像识别的可应用领域太多，光靠我们当然难以穷尽，我们期待跟各领域的开发者一起开拓这些可能性，所以决定做开放平台。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：如何看待亚马逊的 AI 研究与其他大公司的区别？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;夏威：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;相对 Google 和 Facebook 长期占据科技新闻头条，Amazon 的 AI 研究显得更为低调和务实，这可能和 Bezos 商人出身有关，而 Google 和 Facebook 的创始人都是技术出身。比如，语音识别方面，相对 Google 和 Microsoft 在 research 上的突破，反而是 Amazon 发布了第一款真正卖座的语音智能产品——Echo，Google 反而成了跟随者，今年才刚刚发了一款同类产品，Google Home。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;机器之心：为什么最终会选择接受亚马逊的投资？&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;夏威：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;最终选择 Amazon，也主要是战略愿景比较吻合吧，如前面所说，我们最早是想做成最好的云端视觉识别平台，而 AWS 恰好又是最大的云平台。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：怎么看待海外华人创投圈以及谷歌的 CV 创业圈？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;夏威：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;这两年，VC 资本爆发式增长，中国和美国科技圈的融合越来越频繁和紧密。以前都是硅谷海龟回国创业，现在也有越来越多的华人在硅谷创业，比如我们。这背后当然离不开资本和人才这两个因素，海外华人创投圈给这些在海外创业的创业者提供了巨大的资金帮助，同时也能帮助这些公司了解国内市场，我觉得是一个双赢的局面。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当然，相对美国本土 VC 很多都有技术背景外，华人 VC 对技术的理解相对差一点，所以当一个颠覆性的新技术出现的时候，会出现『看不懂』从而出现误判或者盲目跟风的现象。当然，我相信随着创业者和 VC 之间的交流逐渐深入，这种局面会逐渐得到改善。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;至于 Google 的 AI 创业圈, 我觉得还是因为 Google 投入 AI 研究的时间比较早，加上 Google 之前注重创新的文化基因，培养了大批掌握了前沿 AI 技术的人才，而这些人意识到行业的爆发迹象而纷纷出来创业也就成了顺理成章的事情。比如我们 CTO 王盟，出门问问的李志飞，格灵深瞳的赵勇都是这方面的典范，而他们都出自 Google。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibZF0R7M7A97iajltKvGkDSIuuVhtfibNtzHlnaoVy4T9XibnAmoUlRyBJHYwkTONycR8zAzX00SGWGQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：你觉得目前在 CV 的研究有哪些难点？产品在技术上亟待解决的问题有哪些？未来的发展方向是？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;夏威：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;研究方面的话我觉得无监督学习或者弱监督学习就是一个很大的难点。具体到产品中经常遇到的问题是如何获取高质量的训练数据，以及如何用更少的数据或者在噪音很大的数据库中用最快的速度训练出足够好的模型，同时也涉及到大规模 GPU 训练。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;未来我觉得 CV 技术本身主要会有两个大的方向，一个是朝云端发展，一个是朝嵌入式发展。复杂计算会在云端实现，而本地的嵌入式系统也能快速处理大量的简单计算，二者的结合能实现很多应用对于及时性和复杂性的双重要求。至于应用的话，我个人比较看好的一个方向是 ADAS，还有智能家居。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;如果你对亚马逊、Orbeus 或是夏威老师的研究感兴趣，你也可以在&lt;span&gt;当地时间 10 月 13 日 7pm - 9:30pm&lt;/span&gt; 来到 Husky Union Building（University of Washington Campus）参加我们的活动。点击&lt;/em&gt;&lt;/span&gt;&lt;span&gt;&lt;em&gt;「阅读原文」&lt;/em&gt;&lt;/span&gt;&lt;span&gt;&lt;em&gt;即可报名。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;br/&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibZF0R7M7A97iajltKvGkDSInKKEDFI9lOMRvmAEDX0ZOCpZSia2o1u5TBRSBYoKBKygYpywbYgnKOw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 13 Oct 2016 15:04:09 +0800</pubDate>
    </item>
    <item>
      <title>Nature | 瑞士研究者开发出新型量子加密技术：信息安全延迟时间延长500万倍</title>
      <link>http://www.iwgc.cn/link/3052019</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;选自Nature&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;em style="color: rgb(136, 136, 136);"&gt;&lt;span&gt;一些信息可以在被加密 24 小时后才被显示出来——这比之前的记录长了 500 万倍！&lt;/span&gt;&lt;/em&gt;&lt;br/&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;量子加密（quantum cryptography）可以防范窃听者，但在安全投票和密封投标拍卖中，信息必须要一直保持不可读取和被保护一定长度的时间。在发送方和接收方之间将信息传递通过一些可信的「朋友」可以实现该信息的延迟和加密，但如果要让信息的延迟达到几毫秒之上，那么这些朋友就要位于离发送方和接收方非常远的距离。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;瑞士日内瓦大学的 Anthony Martin 及其同事开发了一种可以让这种交换发生 50 亿次的协议，其中每一轮都进行的加密都构建于之前所创造的轮之上。这让这篇论文的作者可以将发送方和接收方计算机与它们的「朋友」之间的距离压缩至仅仅 7 千米，同时能够实现 24 小时的信息安全。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;论文：24 小时的相对位承诺（24-Hour Relativistic Bit Commitment）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：位承诺（Bit Commitment）是一种基本的加密原语（cryptographic primitive），其中一方希望向另一方承诺一个秘密位（secret bit）。不幸的是，不可信多方之间通过经典和量子信息的异步交换实现完美的安全是不可能的。尽管如此，如果每一方都分成两个满足严格的相对论约束（relativistic constraints）的在时间和位置上交换经典信息的代理（agent），那么完美安全也是可以实现的。一种实现这一目标的相对论多轮协议（relativistic multiround protocol）之前已被提出，并被用来实现了一个 2 毫秒的承诺时间（commitment time）。最初人们认为更长的持续时间是不安全的，但近来的理论进展表明事实并非如此。在这篇文章中，我们报告了长达 24 小时的位承诺的实现，该实现仅基于定时高速光通信和快速信息处理，而且其所有的代理都位于日内瓦市内。这个持续时间比之前实现的时间长 6 个数量级，而且我们认为它可以被扩展到一年并实现远远更为灵活的代理位置。我们的实现为数字签名、安全投票和诚信保持拍卖（honesty-preserving auctions）等应用提供了一种实用且可行的解决方案。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;论文地址：&lt;span&gt;http://journals.aps.org/prl/abstract/10.1103/PhysRevLett.117.140506&lt;/span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em style="color: rgb(136, 136, 136); font-size: 12px;"&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibZF0R7M7A97iajltKvGkDSInKKEDFI9lOMRvmAEDX0ZOCpZSia2o1u5TBRSBYoKBKygYpywbYgnKOw/0?wx_fmt=jpeg"/&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;em&gt;点击&lt;/em&gt;&lt;/span&gt;&lt;span&gt;&lt;em&gt;「阅读原文」&lt;/em&gt;&lt;/span&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;报名机器之心西雅图分享活动&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;span&gt;&lt;em&gt;。&lt;/em&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 13 Oct 2016 15:04:09 +0800</pubDate>
    </item>
    <item>
      <title>深度 | 全面整理30个重要的深度学习库：按Python和C++等10种语言分类</title>
      <link>http://www.iwgc.cn/link/3035706</link>
      <description>&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自 datasciencecentral&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Emmanuelle Rieuf&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李泽南、杜夏德、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;本文介绍了包括 Python、Java、Haskell等在内的一系列编程语言的深度学习库。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Python&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;Theano 是一种用于使用数列来定义和评估数学表达的 Python 库。它可以让 Python 中深度学习算法的编写更为简单。很多其他的库是以 Theano 为基础开发的：&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;ol class=" list-paddingleft-2" style="list-style-type: lower-alpha;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Keras 是类似 Torch 的一个精简的，高度模块化的神经网络库。Theano 在底层帮助其优化 CPU 和 GPU 运行中的张量操作。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Pylearn2 是一个引用大量如随机梯度（Stochastic Gradient）这样的模型和训练算法的库。它在深度学习中被广泛采用，这个库也是以 Theano 为基础的。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Lasagne 是一个轻量级的库，它可以在 Theano 中建立和训练神经网络。它简单、透明、模块化、实用、专一而克制。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Blocks 是一种帮助你在 Theano 之上建立神经网络模型的框架。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Caffe 是一种以表达清晰、高速和模块化为理念建立起来的深度学习框架。它是由伯克利视觉和学习中心（BVLC）和网上社区贡献者共同开发的。谷歌的 DeepDream 人工智能图像处理程序正是建立在 Caffe 框架之上。这个框架是一个 BSD 许可的带有 Python 接口的 C++库。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;nolearn 包含大量其他神经网络库中的包装器和抽象（wrappers and abstractions），其中最值得注意的是 Lasagne，其中也包含一些机器学习的实用模块。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Genism 是一个部署在 Python 编程语言中的深度学习工具包，用于通过高效的算法处理大型文本集。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Chainer 连接深度学习中的算法与实现，它强劲、灵活而敏锐，是一种用于深度学习的灵活的框架。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;deepnet 是一种基于 GPU 的深度学习算法的 Python 实现，比如：前馈神经网络、受限玻尔兹曼机、深度信念网络、自编码器、深度玻尔兹曼机和卷积神经网络。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Hebel 是一个在 Python 中用于带有神经网络的深度学习的库，它通过 PyCUDA 使用带有 CUDA 的 GPU 加速。它可实现大多数目前最重要的神经网络模型，提供了多种不同的激活函数和训练方式，如动量，Nesterov 动量，退出（dropout）和 前期停止（early stopping）。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;CXXNET 是一种快速，简明的分布式深度学习框架，它以 MShadow 为基础。它是轻量级可扩展的 C++/CUDA 神经网络工具包，同时拥有友好的 Python/Matlab 界面，可供机器学习的训练和预测使用。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;DeepPy 是一种建立在 Mumpy 之上的 Python 化的深度学习框架。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;DeepLearning 是一个用 C++和 Python 开发的深度学习库。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Neon 是 Nervana 公司基于 Python 开发的深度学习框架。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;C++&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;eblearn 是一个机器学习的开源 C++库，由纽约大学机器学习实验室的 Yann LeCun 牵头研发。尤其是，按照 GUI、演示和教程来部署的带有基于能量的模型的卷积神经网络。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;SINGA 被设计用来进行已有系统中分布式训练算法的普通实现。它由 Apache Software Foundation 提供支持。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;NVIDIA DIGITS 是一个新的用于开发、训练和可视化神经网络系统。它把深度学习放进了基于浏览器的界面中，让数据分析师和研究人员可以快速设计最好的深度学习神经网络（DNN）来获取实时的网络行为可视化数据。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Intel® Deep Learning Framework 为英特尔的平台提供了统一的框架来加速深度卷积神经网络。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Java&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;N-Dimensional Arrays for Java (ND4J) 是一种为 JVM 设计的科学计算库。它们被应用在生产环境中，这就意味着路径被设计成可以最小的 RAM 内存需求来快速运行。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;Deeplearning4j 是第一个为 Java 和 Scala 编写的消费级开元分布式深度学习库。它被设计成在商业环境中使用，而非研究工具。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Encog 是一种先进的机器学习框架，支持支持向量机（Support Vector Machines），人工神经网络（Artificial Neural Networks），基因编程（Genetic Programming），贝叶斯网络（Bayesian Networks），隐马尔科夫模型（Hidden Markov Models）和 遗传算法（Genetic Algorithms）。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;JavaScript&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Convent.js 是一种 Javascript 中用于深度学习模型（主要是神经网络）的库。完全在浏览器中使用，不需要开发工具，不需要编译器，不需要安装，也不需要 GPU 的支持，简单易用。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Lua&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Torch 是一种科学计算框架，可支持多种计算机学习算法。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Julia&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Mocha 用于 Julia 的一种深度学习框架，其灵感来源于 C++框架 Caffe。在 Mocha 中通用的随机梯度求解器和公共层的有效实现可以被用于训练深度/浅层（卷积）神经网络，其带有通过（堆叠的）自动解码器的（可选的）无监督的预训练。其最大特点包括：带有模块化架构、 高层面的接口、便携性与速度、兼容性等等。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Lisp&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Lush（Lisp Universal Shell）是一种为研究人员、试验者以及对大规模数值和图形应用感兴趣的工程师设计的、面向对象的编程语言。它带有丰富的作为机器学习库一部分的深度学习库。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Haskell&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;DNNGraph 是一个用 Haskell 编写的深度神经网络生成 DSL。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;.NET&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Accord.NET 是一种.NET 机器学习框架，包含声音和图像处理库，它完全由 C# 编写。它是一种为开发生产级的计算机视觉、计算机听觉、信号处理和统计应用而设计的完整框架。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;R&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;darch 包可以用于建立多层神经网络（深层结构）。其中的训练方式包括使用对比发散法进行提前训练，或使用通常的训练方法（如反向传播和共轭梯度）进行一些微调。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;deepnet 实现了一些深度学习架构和神经网络算法，包括 BP、RBM、DBN、深度自编码器等等。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 12 Oct 2016 13:45:51 +0800</pubDate>
    </item>
    <item>
      <title>开源| 怎么让你的照片带上艺术大师风格？李飞飞团队开源快速神经网络风格迁移代码</title>
      <link>http://www.iwgc.cn/link/3035707</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自 GitHub&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;这是来自 Justin Johnson、Alexandre Alahi 和李飞飞的论文《Perceptual Losses for Real-Time Style Transfer and Super-Resolution》的代码，该论文已被 ECCV 2016 接收。本论文和文中提到的其它论文可点击文末「阅读原文」下载。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该论文基于 Leon A. Gatys、Alexander S. Ecker 和 Matthias Bethge 的论文《A Neural Algorithm of Artistic Style》，即训练将艺术风格应用于图像的前馈网络。在训练之后，我们的前馈网络能以比 Gatys 等人提出的基于优化的方法（optimization-based method）快数百倍的速度为图像改变风格。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个 repository 还包含一个实例归一化（instance normalization）的实现，其在 Dmitry Ulyanov、Andrea Vedaldi 和 Victor Lempitsky 的论文《Instance Normalization: The Missing Ingredient for Fast Stylization》中得到了描述。这种简单的技巧能极大地提升前馈风格迁移模型（feedforward style transfer models）的质量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;项目地址：&lt;span&gt;https://github.com/jcjohnson/fast-neural-style&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在一个 Pascal Titan X 上只用 50 毫秒就能实现这张分辨率为 1200x630 的斯坦福校园照片的风格迁移：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWic25JBMVLrowCdDa5MMQyMAJlmWcqVMBDhwsjATzGzFEeOd80PVp5S9nCOxctsNdvl1ruiat2n2uXQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这个 repository 中，我们提供了：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;我们的论文中所使用的风格迁移模型&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;额外的使用了实例归一化的模型&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;用于在新图像上运行模型的代码&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;在一个网络摄像机上实时运行模型的演示&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;一种 Gatys 等人描述的基于优化的风格迁移方法的实现&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你觉得这些代码有用，请加上引用信息：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;@inproceedings{Johnson2016Perceptual,&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;title={Perceptual losses for real-time style transfer and super-resolution},&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;author={Johnson, Justin and Alahi, Alexandre and Fei-Fei, Li},&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;booktitle={European Conference on Computer Vision},&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;year={2016}&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;}&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;设置&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所有的代码都在 Torch 中实现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先安装 Torch，然后更新或安装以下软件包：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;luarocks install torch&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;luarocks install nn&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;luarocks install image&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;luarocks install lua-cjson&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;GPU 加速（可选）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你有一个 NVIDIA GPU，你可以通过 CUDA 加速所有的运算。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先安装 CUDA，然后更新或安装以下软件包：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;luarocks install cutorch&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;luarocks install cunn&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;cuDNN（可选）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当使用 CUDA 时，你可以使用 cuDNN 加速卷积运算。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先下载 cuDNN（https://developer.nvidia.com/cudnn），然后将该库复制到&lt;span&gt;&lt;em&gt; /usr/local/cuda/lib64/&lt;/em&gt;&lt;/span&gt;。然后安装用于 cuDNN 的捆绑组件：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;luarocks install cudnn&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;预训练模型&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过运行以下脚本可下载所有的预训练的风格迁移模型：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;bash models/download_style_transfer_models.sh&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这会将 10 个模型文件（约 200 MB）下载到文件夹 &lt;span&gt;&lt;em&gt;models/ &lt;/em&gt;&lt;/span&gt;中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;论文中的模型&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们在我们的论文中使用的风格迁移模型可以在文件夹 models/eccv16 中找到。下面是一些我们使用这些模型给大小为 512 的芝加哥楼群照片施加风格的例子：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWic25JBMVLrowCdDa5MMQyMAmKYqaCwibU9fjImkDUunbeKVSSA5iaeHOicQx6XcKEFUa2RJNtTRFiadfw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;带有实例归一化的模型&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;正如 Dmitry Ulyanov、Andrea Vedaldi 和 Victor Lempitsky 的论文《Instance Normalization: The Missing Ingredient for Fast Stylization》中讨论的那样，使用实例归一化替代批归一化（batch normalization）能够显著提升前馈的风格迁移模型的质量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们使用实例归一化训练了多个模型；在下载了预训练模型之后，你可以在&lt;em&gt;&lt;span&gt; models/instance_norm &lt;/span&gt;&lt;/em&gt;文件夹中找到它们。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些模型使用了我们在论文中所使用的一样的架构，除了其每一层的过滤器（filter）只有一半，而且使用的是实例归一化而非批归一化。使用更窄的层可以让模型更小和更快，且不会牺牲模型的质量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面是这些模型的一些输出案例，图像大小为 1024：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWic25JBMVLrowCdDa5MMQyMAT0mrLEcKsLg5tPnNhqYQlzU69hwOCVibpibL8nR3Y66AzTicplAu1lFTw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;在新图像上运行&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;脚本 fast_neural_style.lua 让你可以使用一个预训练的模型给新的图像施加风格：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;th fast_neural_style.lua \&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;-model models/eccv16/starry_night.t7 \&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;-input_image images/content/chicago.jpg \&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;-output_image out.png&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你可以在一个完全不同的图像目录上运行同样的模型，如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;th fast_neural_style.lua \&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;-model models/eccv16/starry_night.t7 \&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;-input_dir images/content/ \&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;-output_dir out/&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你可以使用 -image_size 标签控制输出图像的大小。该脚本是默认运行在 CPU 上；要在 GPU 上运行，应增加 -gpu 标签特定所运行的 GPU。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该脚本的完整选项介绍参见：https://github.com/jcjohnson/fast-neural-style/blob/master/doc/flags.md#fast_neural_stylelua&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;网络摄像头演示&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;您可以使用脚本&lt;span&gt;&lt;em&gt; webcam_demo.lua&lt;/em&gt;&lt;/span&gt; 从网络摄像头视频流中实时运行一个或多个模型。要运行这个演示，你需要使用 qlua 而不是 th：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;qlua webcam_demo.lua -models models/instance_norm/candy.t7 -gpu 0&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过给 -models 标签添加逗号分隔的列表，你可以同时运行多个模型：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;qlua webcam_demo.lua \&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;-models models/instance_norm/candy.t7,models/instance_norm/udnie.t7 \&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;-gpu 0&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;使用一个 Pascal Titan X，你可以轻松地实时地在 640x480 大小下运行 4 个模型：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWic25JBMVLrowCdDa5MMQyMAY9BiayiacRX0rnhXEdhmyLcvYghw6gICcgrpoPt8zB3eicOzvZddzVq1w/0?wx_fmt=gif"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该网络摄像头的演示依赖于几个额外的 Lua 包：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;clementfarabet/lua---camera：https://github.com/clementfarabet/lua---camera&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;torch/qtlua：https://github.com/torch/qtlua&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;要安装这些包，运行：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;luarocks install camera&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;luarocks install qtlua&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;关于该脚本的完整描述参见：https://github.com/jcjohnson/fast-neural-style/blob/master/doc/flags.md#webcam_demolua&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;训练新模型&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你可以在这里找到训练新模型的说明：https://github.com/jcjohnson/fast-neural-style/blob/master/doc/training.md&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;基于优化的风格迁移&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;脚本&lt;span&gt;&lt;em&gt; slow_neural_style.lua &lt;/em&gt;&lt;/span&gt;类似于原来的 neural-style（https://github.com/jcjohnson/neural-style），并且使用了 Gatys 等人描述的基于优化的风格迁移方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该脚本使用了和前馈训练脚本一样的计算损失的代码，允许前馈的风格迁移网络和基于优化的风格迁移之间进行公平的比较。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;和原来的 neural-style 相比，这个脚本有如下的改进：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;移除了对 protobuf 和 loadcaffe 的依赖&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;支持远远更多 CNN 架构，包括 ResNets&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该脚本的完整选项集合参见：https://github.com/jcjohnson/fast-neural-style/blob/master/doc/flags.md#slow_neural_stylelua&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;证书&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;个人或研究可免费使用；商业用途请与我联系。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;论文：实时风格迁移和超分辨率的感知损失（Perceptual Losses for Real-Time Style Transfer and Super-Resolution）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWic25JBMVLrowCdDa5MMQyMAhm17vyMQxHIy4lOziagLmBiaKWxXLJ06E86ESQy8U5eMAlYVutxzp6BA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：&lt;/span&gt;&lt;span&gt;我们思考了图像转换问题，即一个输入图像被转换成一个输出图像的问题。近来针对这类问题的方法通常是使用输出图像和 ground-truth 图像之间的 \emph{per-pixel} 损失来训练前馈卷积神经网络（feed-forward convolutional neural networks）。另一些研究已经表明高质量的图像可以基于从预训练的网络中提取的高层次特征，定义和优化 \emph{perceptual} 损失函数来生成。我们将这两种方法的优势结合了起来，提出使用感知损失函数（perceptual loss functions）来训练用于图像转换任务的前馈网络。我们给出了在图像风格迁移上的结果，其中我们训练出了一种前馈网络来实时解决由 Gatys 等人提出的优化问题。与基于优化的方法（optimization-based method）相比，我们的网络在给出类似定性结果的同时速度能快上三个数量级。我们还实验了单图像超分辨率（single-image super-resolution），其中用感知损失替代每像素损失（per-pixel loss）的做法得到了视觉上让人满意的结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 12 Oct 2016 13:45:51 +0800</pubDate>
    </item>
  </channel>
</rss>
