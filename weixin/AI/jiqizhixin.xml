<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>机器之心</title>
    <link>http://www.iwgc.cn/list/670</link>
    <description>人与科技的美好关系</description>
    <item>
      <title>Quora问答 |《Python机器学习》作者Sebastian Raschka：从Python的学习经验到计算生物学的最前沿</title>
      <link>http://www.iwgc.cn/link/3331426</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Quora&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：杜夏德、李泽南、蒋思源、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;昨日机器之心编译的一篇文章（参见：&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720220&amp;amp;idx=3&amp;amp;sn=c3b8b65ec118d6fdef3f55e5f29e89ff&amp;amp;chksm=871b03a2b06c8ab4b0a0c87a3b3647372578b129ad5f420fddc5a1a84138a7db51911e143980&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720220&amp;amp;idx=3&amp;amp;sn=c3b8b65ec118d6fdef3f55e5f29e89ff&amp;amp;chksm=871b03a2b06c8ab4b0a0c87a3b3647372578b129ad5f420fddc5a1a84138a7db51911e143980&amp;amp;scene=21#wechat_redirect"&gt;业界 | 超越R，Python成为最受欢迎的机器学习语言&lt;/a&gt;）显示Python已经逐渐成为最受欢迎的机器学习语言。在今日的 Quora 专题上， 《Python机器学习》一书的作者 Sebastian Raschka 回答了有关 Python、机器学习、计算生物学方面的许多问题。让我们通过这个专题看看这个机器学习界的明星（他被列为Github中最有影响力的数据科学家之一）是如何完成从生物到计算机的传奇跨界经历的。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;1. 你用过什么让你工作效率提升的工具？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从较高的层面来说，我把「计算编程语言和算法」视为最重要的生产工具，它能处理所有类型的问题。然而，从软件应用层面来说，我喜欢 Atom Editor（我仍在使用 VIM 进行远程工作）。每天我都需要编写很多不同类型的文件：Python 脚本、.cpp 文件、HTML 文件、Markdown、.tex 、纯文本文件、蛋白质结构文件等等。Atom Editor 支持跨平台（macOS 和 Linux）并带有丰富的插件系统。自从有了 VIM 后，我逐渐习惯使用这个小工具了。当然，我的大部分数据分析工作都在 Jupyter Notebook 上做。我不会用 Jupyter 来「开发」代码，但是对我来说，它为我提供一个记录研究轨迹的环境，就像一本「笔记本」，把所有的事情都集中在一处：执行代码，不同的 notation 和 comment，inline plots，以及 LaTeX 等式，不仅节约了时间，在我回顾某个项目写报告赶 deadline 时，它还是我的救命武器，哈哈。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对了，差点忘了「git」（和 GitHub）和一个强大的笔记类应用程序 Quiver（只能在 Mac 上用）。笔记类应用太多了，但我只喜欢 Quiver，它能输出所有格式的数据，有了它你永远不会觉得你会陷入某个特定的程序或格式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;2. 对一个刚入行的、有点手忙脚乱的机器学习/数据科学家，你有什么建议？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我认为手上握有太多的可用资源既有好处又有坏处。好的是我们有很多可选的工具和信息资源，但是为了利用好时间充分使用它们，做好「选择」和保持「关注」才是真正重要的事情。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我不想说很多资源都是「冗余的」，因为「冗余」这个词用在这里有点负面。然而，市面上有很多看似不同的书、工具、教程，内容实际上都差不多，可能在范围和风格上有些差别。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以，不要想贪多，我们总是被长长的阅读清单拖后腿，更重要的是先想清楚个人的目标（「我需要学习那些技能来解决 X 问题？」「我真的要学这个流行的 X 工具而不是 Y 工具吗？」）。资料和工具太多了，我们需要更加精心地挑选。当然有时候我们会感觉是不是错过了什么，但是我觉得习惯这种感觉会帮你把注意力集中在某一件事情上，取得稳定的进步。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;例如，我认为「机器学习简介」的书一本就足够了，没必要每本都读，除非你真的感觉到内容不完整需要补充。就像 Cathy O'Neil 和 Rachel Schutt 解释的那样，没有「完美」的数据科学家，因为没有时间去学每样东西。每个人掌握属于自己的一套技能，擅长某一领域就可以了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我认为不知道所有的事情不一定是件坏事。因为（如下图所示）我们能通过团队合作来弥补各自的缺陷。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibNsuVzdAtufgY2lKIlMXzHTpnKodp1RkiaPtwibCfaCyYNLxrnSsSZHKkUUSCNNyI79nkuJ4jfySKw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;3.2016 年机器学习领域发生的哪件事让你最兴奋？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我对如何将解决特定问题的技术比如卷积神经网络和循环神经网络应用到除图像识别和神经语言处理外的其他问题上极度感兴趣。我认为现在这些技术应用上的一个关键挑战是找到合适的「表征」（除了有足够的 数据外）。这里有个例子（比较旧），&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Lusci, Alessandro, Gianluca Pollastri, 和 Pierre Baldi。「化学信息学中的深度架构和深度学习：药物类分子的水溶性预测」Journal of chemical information and modeling 53.7（2013）：1563-1575.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;研究者们用有向非循环图呈现分子（通常来说，结构是无向循环图）作为递归神经网络的输入，来预测这些分子的水溶性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最近的一个例子是：&lt;/span&gt;&lt;span&gt;Gómez-Bombarelli, Rafael 等人「使用数据驱动的连续分子表达进行自动化学设计（Automatic chemical design using a data-driven continuous representation of molecules）」arXiv：https://arxiv.org/abs/1610.02415&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;简而言之，研究者们训练了一个自动解码器来生成现实的、合成分子。这里，他们的神经网络将 SMILES 串转换成潜在的表达（经过压缩后仅包含统计上的显著信息的向量）并以最小的（或者没有）误差回到 SMILE 串。SMILE 串是一个分子的一维表达；例如，阿司匹林的 SMILES 串是 CC(=O)OC1=CC=CC=C1C(=O)O 对应的是下面的二维结构：&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibNsuVzdAtufgY2lKIlMXzHicf8UwpHYkOCOZHDdplwzh0RODU6HySH0m654XBPc6M7H9IRUwicRo0A/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;阿司匹林（2 -（乙酰氧基）苯甲酸）&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，这些年出现了很多非常棒的工具，从 scikit-learn 到 Theano、 TensorFlow 和 Keras，使得进入机器学习的门槛降低，这也让我很兴奋。这些工具带来的便利让我们不用太担心技术上的部署问题，还让我们集中关注我们想解决的实际问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;4. 你是如何在紧张的工作中挤出时间做那些小项目的？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个问题问的好，说实话，我没有什么秘密可以分享。我觉得这个问题就像是：人们总是说要控制体重，但最终问题还是会归结于每日的热量摄入与消耗。而且，每天只有 24 小时，没人可以延长这个数字。我认为挤出时间的秘诀是你需要对这些小项目感兴趣，这样我就会自然地减少其他业余活动的时间，如看比赛，读小说等等。当然，你的关注点也是很重要的。我觉得对大多数有趣的东西说「不」是其中的关键。我没有说我们必须全天无休止地工作，我想表达的是：如果你有一个绝妙的想法，你通常会挤出时间来实现它。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;5. 解决机器学习问题时最适用的数学是什么？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;统计、概率论、线性代数 和微积分。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;统计和概率论，因为首要任务之一通常是在区别生成模型之间选择一个，来定义性能指标，并评估结果。线性代数是机器学习部署中主要支柱之一，因为它让我们能持续高效地记录和部署。我想说微积分在纯机器学习应用中显得不太重要，但是如果你想理解我们使用或部署的算法，多元微积分和优化理论就显得非常重要，如果你想研究机器学习，那就更不必说了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;6. 我是一位生物物理学专业的学生，对 Python 在自然科学中的应用很感兴趣。对于初学者，你能推荐一本学习 Python 的最好的书吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不幸的是，在学习 Python 上，我个人没有什么推荐的书，因为我是通过 Codecademy 以及后面参加的一个大学课程（CS Programming I）学会 Python 的；与此同时，我还大概在 2011 年 12 月份学习了 Udacity 的「计算机科学入门」课程。所以我倒是愿意推荐 Codecadamy 和 Udacity 的计算机科学入门课程，它们都是很好的资源（而且就我所知它们是免费的）。推荐书的话，我觉得最受欢迎的两本书是《Hitchhiker's Guide to Python》和《Learn Python the Hard Way》。但是我个人从来没有读过这两本书，也就不能为它们做担保了——但这不是说它们并不够好 :)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外，我认为这还要看你在其它编程语言上的经验如何。如果你之前曾经使用过另一种动态语言（例如 Ruby 或甚至 R），那么我觉得你只需要读一下 Python Pocket Guide（甚至只需要网页文档）就可以很快掌握 Python 了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尽管我相信上面列出的所有资源都对入门很有帮助，但你应该通过应用这门语言来解决你领域内的问题的方式来自动地学习这门语言。或者换句话说，一旦你通过入门的门槛，你就可以快速地在网上找到相关的或更特定的概念实现（比如通过 StackOverflow）。另外，写代码的时候进行合作也是有帮助的，因为你可以通过阅读其他人的代码获得很多有用的想法，而且其他人也能为你的实现提供有用的指点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;参考：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;计算机科学入门：https://www.udacity.com/course/intro-to-computer-science--cs101&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Hitchhiker's Guide to Python：http://docs.python-guide.org/en/latest/&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Learn Python the Hard Way：https://learnpythonthehardway.org/&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;7. 在生物学和机器学习的尖端，最激动人心的问题是什么？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在计算生物学领域（computational biology），我们常常有丰富的无标签的数据（有标签的数据有时候可能会有些棘手，这要看具体的项目）。我认为主要的难题之一实际上是我们应该如何呈现数据以使之能够被机器学习算法处理（即：特征表征（feature representation））。现在我看到了很多有潜力的想法和方法；碰巧的是，我刚刚在上面还回答了这个问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;8. 我喜欢你的《Python Machine Learning》这本书，你有计划再写一本吗？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我很高兴听到你喜欢我的《Python Machine Learning》。是的，我正计划写另一本书！在 2015 年我上一本书之后，我在学术界度过了非常忙碌的一年，我在教书、写论文、参加会议……上花掉了大量的时间，而且在写作新书之前我还需要休息一下 :)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但长话短说：我正计划写一本关于模型评估（model evaluation）的书。我收到过关于这个主题的很多问题，而且其往往只在介绍性的书里面有一些简短的介绍。因此，我今年开始写作关于「机器学习中模型评估、模型选择和算法选择的博客」（http://sebastianraschka.com/blog/2016/model-evaluation-selection-part1.html），但关于它的更多内容我想在一本书（Model Evaluation and Selection in Machine Learning：https://leanpub.com/meval）中扩展——通过使用 Python/scikit-learn/Tensorflow 的说明性的和实用的代码例子来增强这些概念。（另外，我相当确定未来某天我还会写一本关于深度学习的书。）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;9. 我可以如何在 10 天之内学会机器学习？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;10 天？嗯，这绝对很有难度 :)。但是，我也认为 10 天是一个你需要用来很好地整体了解机器学习领域的时间框架，也许还能开始将一些技术应用到你的问题上了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在阅读了机器学习三个不同的子领域（监督学习、无监督学习和强化学习）的介绍之后。我可能会花时间了解一下这些领域内代表性的简单（但有用的）算法（可能要把强化学习放到后面一点）。比如：用于回归分析的简单线性回归和 Ridge 回归、用于分类的 logistic 回归和 k-最近邻、以及用于聚类任务的 k-均值聚类和分层聚类。一旦你了解了每种算法的目标和它们解决特定问题的方式，你就能轻松地为你的知识库增加更多算法和方法。但是除了算法之外，你还要清楚如何准备你的数据（特征选择、变换和压缩）以及如何评估你的模型。也许，作为初学者，你可以查看我们在 SciPy 2016 上的 scikit-learn 机器学习教程。它大概有 6 小时长，并总结了大部分基础，还介绍了 scikit-learn 库，这些库可被用于实现和进一步的学习。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;教程地址：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;https://www.youtube.com/watch?v=OB1reY6IX-o&amp;amp;feature=youtu.be&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;https://www.youtube.com/watch?v=Cte8FYCpylk&amp;amp;feature=youtu.be&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;10. 人工智能会颠覆设计行业吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当然，我肯定这么想。人工智能或机器学习已经在很多设计相关的领域得到了应用。从提升图像质量到 Stitch Fix 的个人造型（https://www.stitchfix.com/）和自动驾驶汽车。另一个将自动算法整合到设计里面的例子是 NASA 用在太空船上面的「进化天线（evolved antenna）」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibNsuVzdAtufgY2lKIlMXzHzhLbGTSMfxiad5S7xCW14plbibuIwLJWvZia07ic0WwDPwTFNzD9IR1KHA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能和机器学习可能并不会完全取代设计师，但我认为它将成为设计师的工作流程中「机械性的（mechanical）」部分中不可缺少的部分。或者换句话说，我认为这是一种增强而非完全的替代。但我预计「设计（design）」将随时间变得越来越好，因为特定的人工智能驱动的流程将能帮助缺乏人力或资源的公司或行业实现「好」的设计。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;11. 你如何鉴定机器学习是否对一个项目有用？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一步需要考虑这个项目的主要目的以及完成目标的需要那些步骤。一旦我确定了某个问题可以用一个预测模型（一个分类器或回归器）来处理，或一个聚类算法（clustering algorithm），我会问自己这些数据是否适用于这个任务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果这是一个监督学习任务，我能访问这些标签/目标变量吗？如果不能，我能不能从别的地方获取？是否有足够的可用样本？在一个机器学习算法中，我能不能以某种适当的格式（也许是表格）表达这些输入数据？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;还有，如果我有一个可以轻易可视化或手绘的简单的一维或二维数据，用机器学习处理可能会有点过。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;例如，我或许不会为预测分子重量拟合一个回归模型，因为它是输入的结构。举个例子，给定一个乙酰水杨酸分子，它的分子结构是：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibNsuVzdAtufgY2lKIlMXzHicf8UwpHYkOCOZHDdplwzh0RODU6HySH0m654XBPc6M7H9IRUwicRo0A/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们得到了包含 9 个碳原子、8 个氢原子和 4 个氧原子的化合物；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;C ~ 12 g/mol&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;H ~ 1 g/mol&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;O ~ 16 g/mol&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以我们可以轻松计算出它的重量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;思考一些我们想要解决的问题十分重要，无论我们是否能轻松手动推倒出规则或者，无是够需要机器学习。大体上说，机器学习就是把手动推倒规则和假设或逼近函数的工程自动化。另一个例子是 Joel Grus 写的： Fizz Buzz in Tensorflow（http://joelgrus.com/2016/05/23/fizz-buzz-in-tensorflow/）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;12. 从分子生物学学士到 Python 机器学习，你转行进入数据科学领域的想法是因何而起？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我得承认，在本科学分子生物的时候，我确实对其中的统计和数据分析最感兴趣，而不是那些「实际」的实验室工作，仅仅为了一篇老式的，无名的论文就花了我本科学习的大部分时间。顺便说一句，我在这篇论文中，用实验数据画结论中的图表用了一两天时间，做实验却用了一个多月。所以我不是那么地不喜欢分子生物学，但我很快发现潮湿的实验室不是我的归宿：我视它为：「必要的邪恶」——项目中繁琐的数据收集部分。希望我说完以后，实验室的同僚们不要对我发火，我很感谢他们的辛勤工作（笑）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然我的博士学位是纯计算机领域的，我觉得我对数据科学和机器学习的热情来源于我在研究生学习期间的统计识别课程。学习这些技术非常有意思，而且效果立竿见影，我很快就能在生物学问题上用到它们。那段时间，我得说我对于算法和技术有点过于感兴趣了，而生物学被放在了第二位。今天，我对通用领域解决问题的过程最感兴趣，而生物学恰好是一个有很多数据的学科，恰好有很多问题需要解决。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;13. 你认为机器学习和数据科学会对医疗领域产生什么样的影响？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我的工作并不涉及医疗领域，但是我遇到了几个在机器学习和医疗交叉领域工作的人。例如在我们学院的 Mias 实验室（G.Mias Lab）就专注于收集来自于各种在线数据库和数据源的基本数据，用以预测患上特定疾病的风险。《Why》的作者 Samantha Kleinberg 正在做着非凡的研究，她应用和开发了各种用于医疗行业的统计学建模技术。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;看看那些生物医学的文献，我觉得描述特定蛋白质或基因的功能的经典方法是孤立地看待它们，然后分类至特定的表型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这种自下而上的方法当然也是医疗领域中的关键。然而，基因或蛋白质其实只是更大，更复杂系统中的一小部分。我相信汇集实验和设备的信息能对我们理解这个复杂系统提供有用的信息，并且能使医疗进步。特别是，我希望监测随着时间推移不同风险因素的变化。&lt;/span&gt;&lt;span&gt;如果这能够被高效地完成，那么我相信医疗界将会因此受益。我想说的是我们的目标是尽早获知健康隐患，最好是在这些隐患成为真正的问题之前。比如在一个人真正地患了糖尿病之前跟踪那些有患糖尿病风险的因素。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;发展更好的糖尿病治疗方法是很重要的，但是如果我们更好地理解哪种外界环境的组合会提高患糖尿病的风险，我们就能帮助许多人避免患上这种疾病。我认为不需要在这方面做任何研究，只需要整合如家庭历史、基因表达水平、年龄、购物行为、锻炼等信息就能帮助我们尽早发现患病的风险。我们收集越来越多的数据在一定程度上可以是以匿名形式研究的，因为这样才可以更容易地把它加入到机器学习算法中来建立一个预测模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然而，主要的挑战就是这些数据是高度异质，原始的，并且结合不同的数据库也是也是一个瓶颈，当然，出于隐私方面的担忧——数据是匿名的，这种方式很难链接不同的数据集。然而，苹果等公司正在研究如智能手机这类电子设备上的匿名追踪数据的解决方案。现如今，我认为找到一个将个人资料通过匿名方式提供给研究者的可行方法是建立一个更好的健康问题检测系统的第一步。我相信一旦解决这个问题，我们就为个人预警系统铺平了道路，这个系统是结合数据, 如购物行为, 日常锻炼和饮食信息, 也许个人基因组和偶尔的血液测试。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;14. 你在计算生物学中参与过哪些有趣的项目？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我的大多数其他项目都专注于虚拟筛选的应用：我们一直与实验生物学的实验室合作，开发和使用各种方式，在不存在或存在蛋白质晶体结构的情况下预测单独抑制的（或活性的，取决于哪个项目）候选分子。最有趣的地方是预测与反馈之间的关系：我需要预测（在某些时候），得到实验结果，然后再看看我的尝试对不对，分析我的方式为什么比其他方式更好。这些项目的另外一个挑战在于研究者需要让所有算法在计算上可行——如果你有 1500 万个分子，想在其中选取 100 个候选分子有点像在大海捞针。通常在这种情况下我们会预先进行「过滤」步骤让计算变得简单一些，因为研究总是有时间限制的。我的项目需要所有人充分发挥自己的创造力和技术，但最终，我们的研究成果也需要对合作方产生价值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除了虚拟筛选的应用（其中的一些已经完成了，我现在正在撰写论文，同时准备发布工具包），我同时正在参与蛋白质——配体相互作用等一般概念的研究，我们最近发现了一个蛋白质——配体相互作用的有趣现象，我们正在寻找数据点以确认它不是一个特例。今年夏天刚刚结束的一个项目则有关计算蛋白质——配体结合袋的局部刚性，用以预测近天然蛋白质——配体的结合模式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我觉得这是一个有趣的想法，因为近天然捆绑模式通常需要通过不同的能量项求和来进行预测。使用刚性理论，计算结构中的自由度更多是关于相互作用的协同性，而不是它们的相加和。换句话说，如果特定的非共价相互作用不从复合体中去除额外的自由度（如果复合体已经是刚性的），则其不被「计数」到相互作用分数。在实践中，使用局部刚性蛋白质——配体符合体似乎比其他方式或基于知识的评分方式一样好。而且，除了除了作为「独立」评分函数之外，我认为它是一个有趣的新的「信号」或「特征」，可以用于整体评分。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;15. 使用 Octave 作为机器学习语言到底有多高效？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我认为 Octave 是一种原型设计的高效环境，同时它也是（和 MATLAB 一起）计算机科学（学术领域）中的流行语言。我在很多地方必须使用它，而且我得说它确实是在机器学习上的好选择。但是，看起来现实世界中不趋向于使用 Octave/MATLAB，我得说像 Python 这样的语言也很容易学习——而且功能更多一点（但请注意这是我的个人喜好）。简而言之：如果你的研究需要大量使用，或者你的实验室/团队已经再用了，Octave 是一个不错的选择，否则我会考虑 Python 和 R 语言。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你有兴趣，可以看我去年写的一篇关于「语言战争」的文章：http://sebastianraschka.com/blog/2015/why-python.html&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;16. 对于有一些机器学习知识的程序员来说，学习计算生物学有什么好的方法？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是一个好问题！计算生物学是一个广阔的领域，有很多不同的子领域和方向可以研究：蛋白质折叠，同源性蛋白质建模，蛋白质配体对接和评分、分子动力学模拟、序列比对、基因组装配、微生物组研究、进化生物学和系统发育等等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;生物学的入门可以从分子生物学和基因开始，首先了解「大局」，然后再开始进入你所感兴趣的分区。关于生物计算方面的学习，我主要通过阅读论文——这一领域的变化很快，一本十年前的教科书可能已经过时了。我听说 Edx 和 Coursera 这样的网站已经在提供计算生物学和生物信息学的专门课程了，我没有接触过这些课程，但我觉得这也是不错的入门方式。有一个内容我想要特别分享一下，Greg Caporaso 的「应用生物信息学概论（Introduction to Applied Bioinformatics：http://readiab.org/）」，一本免费的在线图书。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;17. 你对数据科学的初学者有什么好建议？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我的建议是选择你个人感兴趣的问题或项目，而不是从复制一个问题的解决方案入手。如果你对一个问题感兴趣，自然会急于去解决它，并在此过程中开发新的工具和技术。首先，你需要以你能够熟练使用的技术和工具入手，看看能做到什么程度。如果使用现有的工具包不能够解决问题，我会尝试在线搜索类似问题的解决方案，或者问问别人。举个例子，如果你对某种预测感兴趣，在一开始你会将键值对储存在 Python 字典中。随着你的数据集不断增长，你可能会开始需要其他的存储方式，如 SQLite，然后你会开始学习 SQLite。同样的，假如你会使用 NumPy 数组处理很多问题，在收集异构数据时，你可能会转而寻求 Pandas 来处理；如果你的系统内存有限，你会尝试使用其他工具，例如 Blaze。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我建议的方法是你需要学习使用你认为可以解决问题的工具，假如合适就使用它们。第二步是看看你目前工具的潜在替代者，看看它们有什么额外的功能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我发现为了学习工具而学习工具很快就会变得无聊，所以我的方式是在实践中学习工具。如果方向正确，你自然会花时间来学习新的工具。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;18. 您怎么找到时间来掌握机器学习，获得另一个博士学位，并且还对这个学科出了本书的？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我认为计算生物学和机器学习在解决问题的时候是有很大的相似之处的。在计算生物学中，我们通常通过各种数据挖掘来解决计算问题，机器学习中，数据挖掘也占大头。我一直很喜欢统计学，在研究生的阶段我就上过一门「类统计模式识别」，我真的认为这门课点燃了我对预测建模还有机器学习的热情。最开始的时候，我感到「哇，这真是太不可思议了，它帮我解决了计算生物学各种各样的问题」，后来，我真是感觉到「哇，机器学习是那么重要，他几乎能帮我解决所有问题，我要学到更多。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在课程中，我发展出了对机器学习真正的热情，这使我有动力在晚上花一些额外的时间去努力钻研。说实话，有很多机器学习的方面我都没有深入研究，还有很多文件资料我都没有来得及读。然而当我被要求写本书的时候，我发现先前的研究正好与此有关。虽然我在每个周末晚上花上几个小时来写书，我的社交生活在这几个月里也遭受些磨难，但是这也是我激情的来源：我十分高兴能够分享那些使我兴奋的的知识，这也使整个写书的过程变得充满了乐趣。所以，我认为抓紧所有时间在已经足够疯狂的博士期间写一本书是一个很棒的体验（因为他直接有助于解决计算生物学的问题），所以我也愿意花费一些我的「空闲」时间。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;19. 我能在哪找到可以用来学习的 Python 机器学习项目？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我的建议是关注一些数据科学的博客，因为有很多人的博客都在分享他们所爱好的 Python 机器学习方面的东西。现在这边有一个较为全面的数据科学家博客列表，不过这并不是全都关于机器学习的，所以你得做一些手动搜索：rushter/data-science-blogs 你也可以看看 Kaggle（https://www.kaggle.com/）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;例如：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;「通过 100 万条酒店评论发现一些有趣的见解」：https://blog.monkeylearn.com/machine-learning-1m-hotel-reviews-finds-interesting-insights/&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;在 Python 中的机器学习训练，第一部分：http://www.johnwittenauer.net/machine-learning-exercises-in-python-part-1/&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不幸的是，他的博客似乎不常更新了（或者有了个新的站点），但还是可以看看通过了 Kaggle 比赛的解决方案（http://www.chioka.in/kaggle-competition-solutions/）。同样的，我也认为 Kaggle 比赛和论坛是学习的良好平台。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 02 Nov 2016 14:58:26 +0800</pubDate>
    </item>
    <item>
      <title>深度 | 专访《西部世界》科学顾问：机器人可能会进化为有意识的物种</title>
      <link>http://www.iwgc.cn/link/3331427</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;选自Flick&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：曹瑞、李泽南&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;HBO 雄心勃勃的新剧《西部世界》——描述了一个十九世纪牛仔风格的未来主题公园，其中遍布人工智能的角色「接待员」，自开播以来已经播出了五集，每周一更新。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在前几集中，我们已经看到了制片人乔纳森·诺兰和 Lisa Joy（他们是一对夫妻）如何在每个星期一用剧情戏弄观众的感受。通过五集的刻画，未来人工智能的行为方式跃然呈现在现代人的眼前。在第一季剧情进入高潮之前，Flick网站对本剧的科学顾问，奥克兰理工大学人工智能教授 Wai Kiang（Albert）Yeap 进行了一次有关人工智能的专访。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibNsuVzdAtufgY2lKIlMXzHNRiclDniafUveCJ6pnagTwLakUHia5odMZ67ava0C9DEFqKibGDZbEjcSA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;正如我们所见，《西部世界》展示了小诺兰的深厚功力，那么它是如何写成的？让我们看看 Yeap 是怎么说的&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：看到目前的剧情，我们不知道「西部世界」是如何创作的，你觉得科学对剧情的设计有什么样的影响？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：我得说从科学的角度来说，这是很有趣的。《西部世界》对于一个不研究人工智能的高学历人士而言——比如物理学家和化学家——是很有趣的。对于研究智能的人们来说，一些明显的 bug 会让他们有点出戏，我想。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：那当然啦。作为一名专业人士，你可以评价一下接待员在「西部世界」里的设定符合你心中人工智能的未来吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：他们干得不错（笑），接待员也很不错。一切都是人类的错（笑）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：我觉得我们未来会看到更多这种类型的剧作，顺着这个思路。你觉得《西部世界》中的人工智能是什么级别的存在？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：对于《西部世界》中的人工智能，表现力是核心——这就是说必须通过图灵测试。我认为对于大多数人而言最重要的是需要让你觉得它就是真实的人类，这样的接待员才能让来客们满意。当然，我们不知道剧中客人是如何分清谁是机器人，谁是其他客人的，我漏掉了一点剧情。但剧中的接待员举止得体，而且它们遵从阿西莫夫的经典定律「机器人不能伤害人类」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：如果你是这部剧中的人物，你会发现什么能区分出人类和机器人的东西？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：我觉得如果我在其中，或者任何其他人，在《西部世界》中如果没有被事先告知，那我们是看不出来的。所以我说机器人的表现很好嘛，它们让人真假难辨。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：你看到剧中对机器人的能力，功能和权限的设定了吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：是的，所以我说它们的表现很好，但对于一个故事而言，人类部分的描写就显得有些薄弱了。我认为目前剧中人物正在试图通过与接待员对话来控制他们。如果他们可以控制机器人，剧情就变得有点过头了。你不能用这种方法检查和分析性能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：这是因为通过图灵测试的机器人具有欺骗性吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：不，只是因为这太复杂了。剧中机器人的程序非常复杂，你不可以简单地询问公园中的角色「你为什么要这么做？」然后期待它们可以给你一个可以理解的答案。其中的原因会非常复杂，它们不会遵循简单的逻辑。想象一下一些程序可以为这些机器人加入一点阴险的特征，让它们变得更加危险，同时也变得更加像人类（甚至最终变成人类）。这样，就变成了有一个超人正在创造和控制这些机器人。一旦你创造了西部世界，你就难以分析其中的人造角色了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：当你在设计一个和《西部世界》中的人物一样复杂的物体，你认为创造者会在其中加入一些人类的特质吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：你能说的就是在程序当中可能会出现一些出乎意料的行为。如果你允许它们学习新的信息，学习怎样在不同的情境下表现的话，确实是这样。这也就是危险的所在。机器人可以在人类没有意识到的情况下进行学习，并且表现出很多不同的行为。它们很快就可以有能力做到这样的事情，它们选择怎样表现也就变得无法预料。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：如果在《西部世界》中，一个进化程序被故意设定开始运行，这会让你感到不不安吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：在回答这个问题之前，弄清楚设定「一个程序的进化过程」（an evolutionary process in motion）是什么意思非常重要。简单地说就是允许这些机器人自己接受（无限制的）信息，并且选择它们认为合适方式来改变自己的行为。这样一来，进化的就是它们的行为。潜在的过程基本上是一样的。机器人所进行的就是我们所说的符号到符号的处理（symbol to symbol manipulations）。如果是这样的话，我会觉得非常不安。如果它们来控制我们，想一想我们居然被机器统治。这部电视剧中对这一过程的描述从科学的角度来讲是非常薄弱的。在电视剧中，这些机器人慢慢发现了自己是谁，并且认识到人类正在尝试修复它们。而我认为，这不可能发生。如果机器真的这样做，它们可能会立刻展现出一些「疯狂的」行为，一个个被「消灭」。那个用石头砸自己头的流浪机器人可能就是感到迷惑的一个，我喜欢那一幕。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：似乎在这部电视剧当中，不只有一位人类科学家想要赋予这些机器人高级的意识。如果人类这样做的话，我们应该感到担忧吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：再次说明，当你说到他们正在尝试要去做什么的时候，事实上他们并没有那样去做。剧中科学家们正在做的事情是让它们可以「进化」，产生一些更加有趣和让人意想不到的行为。正如我之前说到的，如果这些科学家真的按照你说的方式去做，他们能够控制这些人工智能的时间也就不会太久了。这种行为很危险，也不是什么好事儿。也就会成为像我之前说到的一样，被机器所统治。可是尽管它们能够展现出复杂的行为，它们仍然还是机器。可惜的是，大多数电影描绘的都是人工智能的这一方面，让人工智能看上去很邪恶。另外一种可能，也是更加复杂的一种可能就是让机器加速人类的进化过程。这样，我们就会跨越物种，从生物进化为机器。但是我们首先需要要去认清我们是谁，我们是怎样从原始物种进化到现在的状态的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：考虑到这一点，你有没有猜想过，或者说你有没有一些想法认为哪些故事情节可能会在这里上演？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：最有可能的是，机器人会开始学习成为一种「有意识」的物种，之后他们有可能会取得控制权，或者是在人类和机器人之间创造出一种复杂的相互作用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;问：你认为人工智能拥有一定程度的能力已经是一种必然了，是这样吗？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：是的，但是就像我之前所说，虽然它们的行为和人类一样复杂，但它们也仍然只是机器。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：那么对我们来说，对待人工智能最好的方式是怎样的呢？从一方面来讲，我们是不是不应该让它们的能力超出某一限度？或者还是说我们应该继续追求那些只能在实验室环境下研究的高度受限的人工智能？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：对于我来说，最好的方式就是使用人工智能科技来帮助我们将心智神秘的面纱一层一层地揭开。如果我们继续使用人工智能科技创造拥有复杂行为的机器，那么它们就会像霍金教授所预言的那样摧毁我们。像《西部世界》这样的游戏太危险了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：如果要和一个自己拥有人工智能的机器人或是一个被远程人工智能控制的机器人互动，你认为在这种情境之下，人类的生命会面临危险吗？你会怎样去尝试控制这些风险？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：同样，这取决于你对机器人的警惕放松到了多大程度。如果你控制了他们的学习能力，那就不会出现什么问题。问题的源头就在于它们是否拥有自我学习的能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：在这部电视剧当中，有一个编程策略是让每一台机器都可以在一个狭窄的框架之中在白天完全自主，控制自己。这样让它们自己运行，但是又给它们设定了一些限制的方式，你怎么看？从一个非专业人员的角度来看的话，这让我感到有点不安。&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：如果说你为它们设定了一系列的行为，让他们从中选择的话也是可以的。如果我们对此进行限制的话，你会很安全，但是就没有那么有趣了。确实在现实世界当中，一些公司出于盈利的目的，会放松对人工智能的限制，让它们可以展现出更多有趣的行为。可这样的话，我们可能就会面临大麻烦了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：我在看电视剧的时候，想到其中一件最危险的事情就是人类用对待同类的方式来对待机器人。所以说，如果你可以谋杀或是强奸机器人，这会改变我们人类互相之间的关系吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：是的，当然。因为它们太过于真实，这会影响我们与机器人的关系以及对它们的感觉。我们会越来越觉得它们像人类——因为就像我所说的，从机器人层面来说，我们无法对它们进行区分。另外，你问到人与人之间的关系，我只能说我不太了解。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;问：如果你有反社会的冲动或是行为，在人工智能方面付诸实践是不是一个好主意？这样的行为应该受到鼓励吗？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：我认为我可能还没有资格来回答这个问题，但是如果你让我做一个猜想的话，我的回答应该是否定的！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：那我们换种方式来说吧。假设你是一个机器人研制方面的工程师，看到它们被对待的方式，你会喜欢吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：我认为这取决于你创造机器人的用途是什么。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：对于这个节目，你还有什么特别想要讨论的东西吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：是的。我一直在想这些接待员是怎么具备原始意图/意识的。在《西部世界》当中展示的是这些接待员是怎么突然有了「知觉」，但是否确实有一些「特别瞬间」让我们意识到它们是谁。这和处理其他情况或是产生一些反应有什么不同呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：对于说这样的改变会最终成为现实的说法，你怎么看？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：很困难，对于人工智能来说明白它是怎么来的是关键，就像圣杯一样。我们是怎样具备原初意向性（original intentionality），或者是一些宗教人士所说的人类灵魂。像我之前所说的，我相信使用人工智能科技能够揭开思维运作的秘密。或许之后我们就能够了解真相。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：如果看到这样的科技被用到了游乐园而不是一些科学领域，你会感到惊讶吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：不会，一点儿都不惊讶。事实上，我也有一个问题想要问你，我想问一下《西部世界》的地址。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：我们都想尽快去那儿，是吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：你也想去吗？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：当然了。你不会感觉不舒服吧？你确定是 100% 安全的吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：是的，当然。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：你在追求知识的过程中也花了很大功夫，是吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：肯定，那是当然。我一直在进行观察，尽力想要找到这个迷宫。「笑声」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 02 Nov 2016 14:58:26 +0800</pubDate>
    </item>
    <item>
      <title>学界 | 谷歌新论文提出神经符号机：使用弱监督在Freebase上学习语义解析器</title>
      <link>http://www.iwgc.cn/link/3331429</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;选自arXiv.org&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibNsuVzdAtufgY2lKIlMXzHFxvXVaGgOfLKibbsluO2raHFCtjiaI8HaQ4Ka8gP7WBlYib1grjkvlDrw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;摘要&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;将深度神经网络的成功扩展到自然语言理解和符号推理上需要复杂的运算和外部的记忆。最近的神经程序诱导方法（neural program induction approaches）已经在尝试解决这个问题了，但这种方法通常受限于可微分的记忆（differentiable memory），因此只能执行一些小型的合成任务，不能进一步扩展。在这项成果中，我们提出了 Manager-Programmer-Computer（管理器-编程器-计算机）框架，其整合了神经网络和不可微分记忆（non-differentiable memory）以支持通过一个友好的神经计算机接口执行抽象的、可扩展的和精准的运算。具体来说，我们引入了一种神经符号机（NSM：Neural Symbolic Machine），其包含了一个序列到序列（seq2seq）神经「编程器（programmer）」和一个不可微分的「计算机（computer）」——该计算机是一个带有代码协助（code assist）的 Lisp 解释器。为了成功将 REINFORCE 用于训练，我们通过使用一个迭代式的最大似然训练过程（iterative maximum likelihood training process）所找到的近似黄金程序（approximate gold programs）来增强它。NSM 可以通过弱监督（weak supervision）的方式在大型知识库上训练语义解析器（semantic parser）。其通过弱监督的方式在很有挑战性的语义解析数据集 WebQuestionsSP 上实现了新的当前最佳的表现。和之前的方法相比，NSM 是端到端的（end-to-end），因此无需依赖特征工程或特定领域的知识。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibNsuVzdAtufgY2lKIlMXzHzm1qH1jqh5PciaD1fkzHISL63tbVnkaK2wO4W3gpRh8vWxbP4jGS5Ig/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 3：使用 NSM 的语义解析。其密钥-变量记忆（key-variable memory）的密钥嵌入（key embedding）是该序列模型在特定编码或解码步骤的输出。为了说明，我们也在括号中显示了这些变量的值，但该序列模型永远不会看到这些值，而且只能通过变量名（如 R1）引用它们。特殊的 token「GO」表示解码的开始，而「RETURN」则表示解码的结束。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibNsuVzdAtufgY2lKIlMXzH60RQt9KicvhJyobNB4zeX5WO5RNpbnfR2rEYRT3bSMzIttcpZiaU57pg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 4：系统架构。100 个解码器、50 个 KG 服务器（KG server）和 1 个训练器（trainer）。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;论文下载地址：https://arxiv.org/pdf/1611.00020v1.pdf&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 02 Nov 2016 14:58:26 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 企业应用机器学习的主要障碍有哪些？</title>
      <link>http://www.iwgc.cn/link/3331430</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自The Next Platform&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李亚洲、杜夏德&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;如今机器学习的应用虽然越来越普遍，但如同其他新兴应用领域一样，一定会有一些障碍。对于企业来说，官僚化的批准流程、隐私保护、部门壁垒、价值周期长是其在部署机器学习时的主要障碍。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;即使在分析工作复杂的组织中，机器学习也存在「专业孤立性」问题。例如，银行中的反金融犯罪部门可能使用先进的技术进行反洗钱；而信用风险团队使用完全不同的、不兼容的工具来预测贷款违约，并基于风险设定价位；而财政部门却又使用另一工具预测现金流。同时，消费服务和分行运作根本就不用机器学习，因为缺乏专业知识和软件。这些部门经常不彼此合作，使得难以为成员、流程和技术建立标准。这种软件的拼接集合提高了全公司应用机器学习的总体拥有成本（TCO）。从外，团队的孤立也使得高层难以开始机器学习。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了支持数字化转型，机器学习必须要做三件事：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;彻底的转换企业商业流程：市场、销售、财务、人力资源、供应链等等；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;在全企业支持数据、用户和负载；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;融合企业技术堆栈；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Carolina Healthcare System、Cisco 和 PayPal 的例子说明了机器学习转换业务流程的潜力。在许多企业中，这种转换仍处于早期阶段。从平台架构的角度来看，机器学习需要与支撑业务流程的软件平台融合，支持不同背景的众多用户，以及支持不同的项目。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;扩展到企业级数据意味着许多不同的事。对支持全公司分析的数据仓库的看法迷惑着大部分公司。从实际来看，机器学习软件必须要能与不同的数据平台对接；消化不同格式的数据：有结构的、半结构的和无结构的；它必须能利用「高」（众多记录）和「宽」（许多列）的数据，并且能使用流数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，机器学习软件必须要与公司优选的技术堆栈融合。这意味着遵守安全协议；在优选的数据平台上的可操作性；符合操作系统的标准；虚拟化技术等等其他技术。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;数据科学家的短缺&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有一个普遍的认知就是企业缺乏数据科学家。麦肯锡的一份报告指出这种缺乏将会持续到 2018 年；Venture Beat、华尔街日报等多家媒体都曾报道过数据科学家的缺乏；哈佛商业评论表示要么不找要么降低对数据科学家的标准，因为真正的数据科学家都是独角兽。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;招聘难的问题不只是简单的供应与需求的问题。麦肯锡几年前的报告预测缺乏理解大数据的管理层，只不过比数据科学家缺失的差额小而已。学位课程和 MOOC 公开课每年产出数千新鲜的数据科学家。公司可以将机器学习项目推送到中国和印度等国家，因为在其他国家中，咨询公司就掌握了大量的有先进水平的分析师团队。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;缺乏专业标准和专业证书造成最大的招聘挑战。如今正在为数据科学家建立专业标准，却没有被普遍接受的标准。每个人都可以自称数据科学家。在 O'Reilly Media 发布的 2016 数据科学薪资调查报告中，29% 的调查对象自称数据科学家，但却说他们花费较少或不花费时间做机器学习项目，也不使用标准的机器学习工具。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对数据科学家合适的角色也不确定。在招聘经理找到带有机器学习技术和经验的人后，实际的工作可能完全不同。在许多公司中，带有数据科学家 title 的人的实际角色是信息检索：使用查询工具保证数据平台的数据安全，从而让用户能在 Tableau 或 Excel 上浏览（O'Reilly 的调查显示 SQL 是最流行的工具）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这样的误解损害了团队的积极性和激励机制。Stack Overflow 最近的一项调查显示创新和「建立有极大意义的东西」是机器学习专业人士的关键动力，要比其他条例更有激励性。因为一个机器学习人员知道如何使用 SQL 就把他放到「data broker」的角色，这是一种人力资源的误用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;价值的体现需要长久时间&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;根据 Gartner 的调查，负责高级分析的管理层说建立一个预测模型大约花费 52 天。（Gartner 对高级分析的定义包括统计、描述、预测数据挖掘、模拟和优化。）报告时间线从几天到几月各有不同。管理层都把「开发模型的速度」作为选择高级分析平台的顶级标准，仅次于使用方便度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;管理层想知道：为什么建立且部署预测模型需要这么久的时间？其实有许多原因：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: square;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;数据难以获得；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;数据污染；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;传统的机器学习工具不能扩展到大数据；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;管理部门批准部署模型的速度太慢，充满官僚主义；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;公司对模型部署缺乏明确的流程或技术标准；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;大部分数据科学家花费较少的时间训练机器学习模型。在 2014 年，纽约时报报道根据采访和专业评测，数据科学家花费 50-80% 的时间收集并准备数据。今年早些时候，Gil Press 在 Forbes 上发表的文章称 CrowdFlower 的一份数据科学家的报告称调查对象花费 80% 的时间收集、清理和组织数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;考虑到在企业数据仓库的投资，数据科学家需要花费如此多宝贵的时间来清洁数据是一件很惊人的事。有两个主要原因，首先，企业数据仓库注重对商业智能和性能管理使用案例的支持。这些使用案例是最容易获取的成果；他们有稳定的数据需求和大量的目标用户。然而，机器学习项目却要频繁处理企业数据库不支持的源数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第二，数据对机器学习项目的成果非常重要——「垃圾进入/垃圾清除」。有偏见或无效的数据产生有偏见或错误的预测。数据科学家的工作职责是高质量的输出，不能不理会数据问题说是「其他人的问题」。随着社会对算法中偏见的忧虑越来越多，我们期待对数据采集分析过程的可见性会成为普遍采用机器学习的重要因素。这种对责任的需求说明了数据科学家想要掌控数据的流程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器学习极其依赖计算基础设施，尤其是大数据。模型开发需要迭代测试和重复测试。2010 年之前，大部分基于机器学习软件的服务器都是单线程的，少有产品支持单机多核并行处理。（例如，SAS/STAT 中有超过 300 个程序，其中只有 22 个支持多线程处理。）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所有的这些顶级数据仓库提供商都在他们的分布式数据集中囊括机器学习引擎。Teradata 在 1989 年就引入了这一能力，IBM 在 1992 年做到这一点，微软 2000 年，Oracle 2003 年，Netezza 在 2006 年加入了机器学习。Greenplum 如今的品牌是 Apache MaDlib。2007 年独立的软件供应商 Fuzzy Logix 在多数据库平台上引入了机器学习库。嵌入 MPP 数据集中的机器学习引擎提供一些潜在的收益，包括减少数据移动，简化部署和一个 MPP 平台的性能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然而，在实际中，少有数据科学家使用数据库内的机器学习工具。主要有几个原因：第一，减少数据移动意味着一个机器学习项目所需的所有数据就只能是数据库里面的，这很少出现；第二，如果该分析数据集支持消费者喜好的应用我们只能加快部署；MPP 数据仓库中的机器学习库也缺少可用特征，要么强制用户妥协，要么依赖自定义代码。最后，机器学习工作量会分散数据库管理员的注意力，因为它是一些粗笨的、难以预测的工作。许多公司降低数据库内机器学习的部署或者严格的将使用缩减到商业智能的精调上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然关于公司审查模型的时间和通过流程的数据较少，但有证据显示机器学习很重要。负责的管理层要求将影响他们业务的机器学习透明化；没有银行会在不理解模型行为、测试并验证模型的情况下，冒险使用信用风险模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在受到监管的产业中，比如银行、保险、医疗中，法律审查是批准流程的一部分。例如在银行中，法律团队会评估信用风险模型从而保证模型没有显性或隐性的歧视效果，当然还有其他的合规问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器学习经验较少的公司可能缺乏模型部署的明确流程。没有明确流程的情况下，每个项目就是一个自定义项目，所以每个 contributor 必须从头开始完成每个人物，缺少最佳实践和标准模块提供的指导。这会花费很长的时间，在一些公司中，不是一个预测模型可能要花费 6 个月或更长的时间。在如今快速前进的商业环境中，这是很长的一段时间。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;企业机器学习的挑战&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;打破机器学习的各种「专业孤立性」是企业机器学习的关键目标。部门之间孤立行事会提高成本，阻碍投资，阻碍数字改革。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;技术人员的短缺是管理者们普遍关心的首要问题，因为这阻碍了更广泛的机器学习部署。技术差距部分归因于对于数据科学家，缺少一个专业的标准，机器学习项目 contributor 的角色不清晰。这个技术差距在组织中产生了一个恶循环，因为招聘经理在之前成功案例的情况下可能会无法判断某个人是否胜任机器学习的工作。管理人员的报告中提到，机器学习项目的周期太长是一个关键问题。机器学习项目需要花很长的时间才能产生价值，因为数据中有很多杂乱的东西，而且很难获取；因为传统的机器学习工具无法升级；因为部署模型的批准过程可能很复杂很官僚化；还因为很多组织缺少确定的模型部署程序和标准。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，机器之心系今日头条签约作者，本文首发于头条号，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 02 Nov 2016 14:58:26 +0800</pubDate>
    </item>
    <item>
      <title>独家 | Hinton、Bengio、Sutton等巨头聚首多伦多：通过不同路径实现人工智能的下一个目标</title>
      <link>http://www.iwgc.cn/link/3316956</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心原创&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：机器之心编辑部&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;技术顾问：Yuxi Li&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote style="max-width: 100%; color: rgb(62, 62, 62); font-size: 16px; white-space: normal; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p&gt;&lt;em style="color: rgb(136, 136, 136); font-size: 12px;"&gt;当地时间 10 月 27 日，Creative Destruction Lab 在多伦多举办了 2016 机器学习与智能市场（2016 Machine Learning and the Market for Intelligence）会议。会议云集了人工智能投资及科研界众多世界级明星。在下午的科研分论坛上 Yoshua Bengio、Geoffrey Hinton、Richard Sutton 和 Ruslan Salakhutdinov 等机器学习领域的巨星人物聚首于此，以接下来 1-5 年的人工智能方面的前沿科研方向为主题进行了公开探讨，并分享了很多有价值的知识和经验。机器之心现场观摩了这些大师级人物对机器学习技术、应用和未来的探讨。未来一段时间，机器之心将陆续发布对本次会议内容的独家整理报道。&lt;/em&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;整理内容如有疏漏之处，请不吝指正：留言或发送邮件到 editors@jiqizhixin.com。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以下为机器之心的分论坛现场整理。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Yoshua Bengio、Geoffrey Hinton、Richard Sutton 和 Ruslan Salakhutdinov 同台共同探讨人工智能这一研究领域的接下来 1-5 年的人工智能方面的前沿科研方向。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个明星小组论坛的主持人是科技领域的明星风投公司 DJF（Draper Fisher Juvetson）的合伙人 Steve Jurvetson。Steve 曾经投资过 Hotmail、Tradex、SpaceX、Nervana、D-Wave 和特斯拉等众多明星科技创业公司，他还拥有世界上第一辆 Tesla model S 和第二辆 Tesla model X（第一辆在 Elon Musk 手里）。但是，即使是 Steve，主持这场大师云集的小组论坛还是很有压力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibQiblzyVh1Iicfga2kY36K3YGI5wKK58sSznVpJlW9BSP1b8Qv3sHbzNwdxaryxwL3p7y49xo85ia6g/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本次小组论坛的主题是「What's Next?The Research Frontier（接下来是什么？研究前沿）」。论坛开始，Steve 先请每位小组成员分别讨论自己对人工智能领域，其是机器学习领域下一阶段的科研方向的看法。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;下一步，去向何方？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在未来的一年里 Bengio、Hinton、Sutton 和 Salakhutdinov 教授认为都有哪些问题需要解决？我们会在哪些方向取得进展？&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Yoshua Bengio&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Yoshua Bengio 教授与 Hinton 教授和 LeCun 教授是深度学习崛起背后的领军人物。从 20 世纪 80 年代到 90 年代再到 21 世纪前几年，在那段很少有其他人看到深度学习的发展潜力的时间里，他们三位一直在培养和孕育深度学习。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibQiblzyVh1Iicfga2kY36K3YZcg4d1Oa4VW6b7dxFyo1aFe7cZjLXgu5Edl6C8ZCrlG91zmLYhiagqg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Bengio 教授列出了两个方向：&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1. 解释性的无监督学习（Explanatory Unsupervised Learning）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&amp;nbsp;&lt;strong&gt;&amp;nbsp;&amp;nbsp;1）当前的模型通过提取表面的规律来解决表面的问题。&lt;/strong&gt;Bengio 教授给出了一个图像识别系统的例子。该系统可以被各种各样的色调愚弄，比如背景绿化仍会增加物体被识别成野生动物的可能性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;strong&gt;2）机器无法做到人类非常擅长的无监督学习。&lt;/strong&gt;即使两岁孩童也能理解直观的物理过程，比如丢出的物体会下落。人类并不需要有意识地知道任何物理学就能预测这些物理过程。但机器做不到这一点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;strong&gt;&amp;nbsp;3）处理罕见的危险状态所需要的带有隐变量（latent variable）的预测 (（predictive）,，因果（causal）和解释性（explanatory）模型&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;a. 研究和开发带有隐变量的模型非常重要&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;b. 为什么带有隐变量的模型很重要？因为在可观察到的事物与观察不到的事物之间存在因果关系&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;c. 除了要有更好的模型，处理无标签数据也很重要。无标签意味着没有进行人类解读。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;d. Bengio 教授给出了一个关于开发安全的自动汽车的例子：自动汽车应该要能搞清楚其在训练过程中从未见过的危险状况。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;strong&gt;4）基于模型的强化学习、域适应（domain adaptation）、半监督学习、多任务学习等的应用&lt;/strong&gt;。Steve 问 Bengio 教授因果模型（causal model）是否能以一种无监督的方式衍生出来。Bengio 教授认为无监督将会是一个关键的组成元素，但我们必须使用所有的信息源。我们既应该使用有标签数据，也需要无标签数据。事实上，我们遇到的数据大多是无标签的，也就是说没有提供人类的注解。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibQiblzyVh1Iicfga2kY36K3YKGS6libsLlia8DNVgnXCibf4laibF6jJT5Ma1LiahUx6I9c9nLPOV2ic5ibPg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2. 记忆（Memory）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Bengio 教授还提到未来几年记忆（memory）将成为一个热门的研究领域。为什么记忆会在这个领域如此重要呢？因为记忆与推理存在紧密的联系。从本质上讲，推理就是各种信息的组合过程。为了能够得出能够准确预测未来的结果，你需要有合理的预测步骤。这个过程会在很大程度涉及到记忆。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;Geoffrey Hinton&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Hinton 教授是第一批使用反向传播算法来训练多层神经网络的研究者之一，他也是深度学习社区的一位重要大师。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibQiblzyVh1Iicfga2kY36K3YnSibD2Aj8VIWKpANov2HibqjicV41h70gsMMavFJqX5hgtWWXXm2mvYjg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Hinton 教授用一个他常开的玩笑开场。他对医学院学生说不要去当放射科医生，因为这个工作在未来 5 年内就会被深度学习应用取代。Hinton 教授指出，通常而言，如果你有大量数据和高速的计算芯片，并且需要解决预测问题，深度学习基本上都能派上用场。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibQiblzyVh1Iicfga2kY36K3YiaJfxgJCGIpoibTF0lIW14aUcSJmuQZBG1dwuxoAxUOwQiavG4ByPDbOQ/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Hinton 教授认为未来可能会实现的两件事：&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1. 发现比 ReLU 效果更好的「神经元（neurons）」模型&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;发现比我们的标准 logistic 单元或修正线性单元（ReLU）效果更好的「神经元（neurons）」模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了解释这个问题，Hinton 教授首先简要谈论了自 50 年代以来人工神经元（artificial neuron）的定义的发展史。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;50 年代的时候，人们认为神经元是逻辑门，是确定性的和二进制形式的。然后人们发现它实际上是随机的二进制（stochastic binary）。然后到了 80 年代，Hinton 教授那一代人对神经元的理解从确定性的逻辑门转变成了 S 型的 logistic 单元（sigmoid logistic units）。此后 30 年来，人们一直在使用 logistic 单元；直到 2011 年，修正线性单元随 AlexNet 被引入，进而带来了革命性的影响。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2. 在相对较小的数据集上训练带有大量参数的神经网络。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相较于探索无监督学习，Hinton 教授相信监督学习领域仍然还有一些工作要做。计算能力将越来越便宜，数据集将越来越大，这是如今的趋势。Hinton 教授认为计算能力降价的速度将会超过数据集增长的速度。也就是说，更多的参数可能将不再是噩梦。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数周前，在 Hinton 教授为多伦多大学研究生做的一次讲演中，他表达了自己关于如何做出好成果的观点，他认为可以在网络中利用我们拥有的计算能力并注入尽可能多的参数来获取数据的规律（包括可靠的与不可靠的），并结合所有这些意见来做出预测。这个观点已经在许多任务的完成中得到了成功的证明。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了解释更多的参数能打造更好的模型，他举了一个关于人类的例子：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们每个人都有 100,000,000,000,000 个突触。一个人在一生中大概要进行 1000 万次注视（fixation）。以每 5 秒一次计算，就是 200 万秒。如果我们将每次注视都看作是一个数据点，那么参数的数量和数据的数量之间就存在大约 10,000 倍的差异。如果你一次处理一个数据，那么当你有更多的参数时，你所得到的模型的效果就越好。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于这个例子，Hinton 教授继续指出人脑处理的数据比注视过程中接收的数据多 10,000 倍，但仍然可以处理。而我们的计算机能力不足的原因很可能是因为我们还没有提出一种用于 dropout 的规范化的方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Steve 提出对是否可以使用机器学习来优化参数，同时是什么让 Hinton 相信参数是解决问题的关键的疑问。对于 Steve 的这个问题，Hinton 表示赞同可以将其转变成一个机器学习问题，而且这能给科学研究带来很大的裨益。但同时，Hinton 也并未过多深入探讨参数的问题，反而指出人们实际上仍然不知道神经元实际的工作方式，但在研究上我们甚至有避免将我们在生物神经元上观察到的基本性质应用到人工神经元上的趋势。当前的人工神经元仍然还存在诸多限制，还只能计算一些非常简单的问题。为了解决更复杂的问题，我们还需要继续改变基本的神经元。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Richard Sutton&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Richard Sutton 教授被认为是现代计算强化学习之父，他在该领域有几个重要贡献，包括时间差分学习（temporal difference learning）、策略梯度方法（policy gradient methods）和 Dyna 架构。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibQiblzyVh1Iicfga2kY36K3YWdITSrnub5KicXYC7gZ8L4k2raOpRA3DStQ4HAykc6u7qNa2dgbChqg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Sutton 教授的兴趣点在于智能本身，以及学习的本质。Sutton 教授并没有探讨接下来一年什么会帮助公司企业获得利益，而是探讨了接下来一年里，他认为机器学习最重要的进展。主要有以下三个方面：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1. 从普通经历中规模化学习的能力&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2. 将机器学习扩展到下一阶段&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3. 使用深度强化学习进行长期预测，（可能）进行无监督学习&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibQiblzyVh1Iicfga2kY36K3YZzU0XqFWcupibw1ZJoicCUZiaK6iaIQ6ic1W07aicukXnQ7XILKVXxDRkiajw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在的机器学习过程和人类学习的方式并不相同。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Sutton 教授提到了经验学习法，比如人类和动物会通过生活经验来学习知识。在最近的深度学习方法种借鉴了这种经验法，我们用经验构建起巨大的训练集。能像人类那样学习是件非常重要的事情。不过在机器学习中，这种经验学习的方法还关涉到训练集的可扩展性和限制。这就是为什么现在的系统只能「被动学习（learned）」无法「主动学习（learning）」的原因。一个被动学习的系统建立在训练数据之上，而在主动学习系统中，系统能随时能通过新的经验不断提高。对于未来一年机器学习领域的发展，Sutton 总结道：了解世界的运行规律、可扩展的深度学习方法、用于长期预测的深度强化学习以及无监督学习。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 Sutton 教授看来，学习应该源自与世界交互的过程，而不需要使用有标签的数据集进行训练。它应该是一种更加自然的方式，就像人类小孩与动物的方式一样。它应该有关世界的运行规律和因果规律。Sutton 教授认为他和 Bengio 是在用不同的术语和方法讨论同一个问题。他在用强化学习的方法，而 Bengio 则用的是无监督学习。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他最后说，人工智能目前还有很长一段路要走，我们还仅仅出于旅程的起点，我们将会找到一个稳定的方式赶上甚至超越摩尔定律。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当 Steve 问到这和人类与大脑连接的类比时，Sutton 只是微笑着把问题让给了 Bengio 教授。Bengio 提到 logistic 单位模型受神经元科学假说的影响很大。我们还需要探索更多，才能消除神经科学与机器学习之间的差距。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Ruslan Salakhutdinov&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Ruslan Salakhutdinov 教授是卡耐基梅隆大学计算机科学院机器学习系的副教授，之前是多伦多大学的教授，也是 Hinton 的博士生。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibQiblzyVh1Iicfga2kY36K3YRaWHNxOSaXNkiadR7t9rAibAJ3BaT93DNYy49OQG5L9fmXHclJat0pKQ/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibQiblzyVh1Iicfga2kY36K3Yx0Oh4zL3HibwsP72vKKSnCbswewAvzicd7iaSVN7XShhvib5UPg3fMXZHg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719828&amp;amp;idx=3&amp;amp;sn=5f72f8b9bbd0078d483ad233e578081a&amp;amp;chksm=871b022ab06c8b3ce2ef881c941e1ea532e3f465bbc1109c74e0aa0a72b283a8408dca7b353f&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719828&amp;amp;idx=3&amp;amp;sn=5f72f8b9bbd0078d483ad233e578081a&amp;amp;chksm=871b022ab06c8b3ce2ef881c941e1ea532e3f465bbc1109c74e0aa0a72b283a8408dca7b353f&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;Salakhutdinov 教授最近作为机器学习研究的负责人加入了苹果&lt;/span&gt;&lt;/a&gt;&lt;span&gt;。他说他们正在组建一个顶级科学家团队。有很多棘手的项目和研究要做。他的工作是确保他们能开发出新的优秀算法。因为机器学习正在被应用到苹果内部的每个角落。他很高兴能够兼顾到所有的地方。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Salakhutdinov 教授说，人工智能与机器学习在未来一到三年内存在四大挑战：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1. 无监督学习/一次性学习（One-Shot Learning）/迁移学习&lt;/span&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Salakhutdinov 教授表示他在卡内基梅隆大学的实验室里已经利用数据进行了大量研究，已经可以使用监督学习从数据中提取结构，这是一个新进展，但计算机距离无监督学习还很远。他还提到了一次性学习，Bengio 和 Hinton 也提到过这种方法。只是目前的机器还不能像人类一样从少数例子中学到新的知识与概念。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2. 推理、注意和记忆&lt;/span&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Salakhutdinov 教授没有深入探讨这一部分，但他提出了一个问题：如何让系统具有内建记忆，帮助我们进行决策。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3. 自然语言理解/对话与提问/自动应答系统&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;即使我们在自然语言的推理中取得了很大的进展，但我们距离人机自然交互仍然有很长的一段距离。Salakhutdinov 在被问及建立嵌入记忆是否是让自然语言理解语境和长对话的关键时回答说：需要有正式的记忆网络，能在神经网络中进行读取和存储。建立和设计新的神经网络架构是我们要探索的问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Steve 还问到了人机交互自然对话界面建立的时间表，Salakhutdinov 则说，我们仍需在有限的环境中做很多工作，而不是在通用人工智能上。Bengio 则开了个玩笑：「严肃的科学家从不给出时间表。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;4. 深度增强学习&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Salakhutdinov 推荐对这一话题感兴趣的人们阅读 Sutton 的著作。他认为认真总结上个世纪 80 到 90 年代增强学习的成就之后，人们将会取得更伟大的进步。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;讨论花絮&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除了讨论这一个领域未来的展望，教授们还探讨了很多有趣的想法，互相开了开玩笑，与 Steve 进行问答，下面是从讨论中摘录的部分有意思的花絮。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Hinton 教授的灵感之源：「它（大脑）是如何工作的？」&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;待四位教授说完自己对未来科研风向的观点后，Steve 问了一个问题，是什么让教授们坚信，并且在不知道什么时间才会出成果的情况下，全身心将事业投入于此？（在会议中 Bengio 教授曾笑言：「（对科研态度）严肃的教授是不会给你（出成果的）时间线的。」）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;Hinton 教授谈到自己的坚持是希望探索出大脑是如何工作的。Steve 追问，「这个强烈的兴趣就在于我们对大脑真实工作情况理解的越多，模拟就能做的越好。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Hinton 教授：「不，我不关心这个。我只关心大脑如何工作。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibQiblzyVh1Iicfga2kY36K3YJVV8ic5ORMlBmpxskjpkq0dIuI1Ip72uC3SV0LtYTPL1bzcgic8Pfu4A/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;关于智能，存在一个简单的解释吗？&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在讨论到自由意志这个主题时，Bengio 教授还聊了聊自己正在思考怎样才能简单的解释智能。他提到 Pedro Domingos 教授在书中写过，很多机器学习（和深度学习）都有基础假设。有一些可以理解的简单原理能解释我们的智能以及我们大脑理解世界的能力。如果这个方法复杂到我们无法理解，那就不好玩了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Geoffrey Hinton 最近的工作&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;讨论中，Hinton 教授提到谷歌正全力支持他探索新型人工神经元及其工作原理，谷歌对他基础研究的支持非常有效，有了些突破性进展。他开玩笑说实际上谷歌是比 NSERC（加拿大自然科学与工程技术研究理事会）更好的资金来源。但由于这些讨论的内容本身很难，再加上 Hinton 浓重的英国口音就更加晦涩难懂。Bengio 教授则建议大家可以阅读他们最近发表的论文（论文点击「&lt;span&gt;阅读原文&lt;/span&gt;」下载，这是 Geoffrey Hinton之前的论文：&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719971&amp;amp;idx=3&amp;amp;sn=c23aa4b6172bd4ccea042d139ffa5daf&amp;amp;chksm=871b029db06c8b8b939ba2e0eb256db1d5fdd5ce2b229139cb31e7e54e5bdd2772761ce01c19&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719971&amp;amp;idx=3&amp;amp;sn=c23aa4b6172bd4ccea042d139ffa5daf&amp;amp;chksm=871b029db06c8b8b939ba2e0eb256db1d5fdd5ce2b229139cb31e7e54e5bdd2772761ce01c19&amp;amp;scene=21#wechat_redirect"&gt;&lt;em&gt;使用快速权重处理最近的过去&lt;/em&gt;&lt;/a&gt;的修订版）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Yoshua Bengio 教授 :「自由意志是一种错觉！」&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当 Steve 问 Bengio 教授他如何看待自由意志和计算决定论时，Bengio 教授并没有正面回答，而是给出了一个引人深思观点：「自由意志是一种错觉！」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;深度增强学习渐热&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Sutton 教授和 Salakhutdinov 教授都在强调深度强化学习。这种方法会催生通用人工智能吗？我们还不知道。但我们明白目前还有很多工作要做，而在这条路上我们将会有很多收获。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibQiblzyVh1Iicfga2kY36K3YGzHjcXzUmkcfc4r7QdVrzbZ3kNiajoCA2hHibodlkT6QUzA81f9RRcEw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;我们需要知道大脑的运作机制&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在会议和讨论中，Hinton 教授不断地讲述他关于神经、突触、脉搏、电流和其他工作的进展。他同时提到了图灵对神经网络的观点，并多次强调我们其实还是不明白它（人工神经网络以及大脑）的具体机制。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Bengio 教授与 Hinton 分享了类似的观点，他认为将大脑运作机制研究清楚是非常重要的——「如果我们不这么做一定是疯了」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Hinton：「我们不知道它的工作机制。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Bengio：「或者说，我们不知道我们大脑的工作机制！」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibQiblzyVh1Iicfga2kY36K3YCuQ3PeSXu78IpCFINp4jAf44LQcKoBIcbjRJl4PtT9aX7UfIf0zIyg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;本文是机器之心对 2016 机器学习和人工智能市场会议的第一篇小组论坛要点报道。该会议由多伦多 Creative Destruction Lab 于 2016 年 10 月 27 日在多伦多举办。我们希望本篇总结可以让大家从这些研究者的观点中受益。随后的一段时间里，机器之心将会陆续发出该会议的其他精彩小组论坛总结报道。请锁定机器之心，第一时间获得感兴趣的小组论坛总结报道。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心原创，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 01 Nov 2016 16:26:34 +0800</pubDate>
    </item>
    <item>
      <title>学界 | 微软重磅论文提出LightRNN：高效利用内存和计算的循环神经网络</title>
      <link>http://www.iwgc.cn/link/3316957</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;选自arXiv.org&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李泽南、吴攀、蒋思源&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQiblzyVh1Iicfga2kY36K3YNNKLJ7BbGrq6rTRLpKjpnHsdFPhHZxtVsxDKojEMntPibyc9IdUD9ibQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;摘要&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;循环神经网络（RNN）已经在许多自然语言处理任务上取得了最出色的表现，比如语言建模和机器翻译。然而当词汇量很大时，RNN 模型会变得很大（可能超过 GPU 最大的内存能力），这样训练将变得很低效。在这项工作中，我们提出一种全新的方法来解决这一挑战。其中的关键思想是使用二分量（2-Component(2C)）共享的词表征的嵌入（embedding for word representations）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们将词汇表中的每一个词都分配到一个表格中，其中每一行都关联了一个向量，每一列则关联了另一个向量。根据一个词在表中的位置，该词可由行向量和列向量两个维度联合表示。因为该表中同一行具有相同的行向量，同一列具有相同的列向量，所以我们仅仅需要 2p|V|个向量来表示带有|V|个词的词汇表，这远远少于现有的方法所需要的向量数|V|。基于二分量（2-Component）共享嵌入的方法，我们设计了一种新的 RNN 算法，并且使用几个基准数据集上的语言建模任务对其进行了评估。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;结果表明，我们的算法可以显著地减少模型的大小，并且能在不牺牲精度的情况下加快训练速度（它实现了与当前最佳的语言模型相近或更好的困惑度（perplexity））。值得注意的是，在 One-Billion-Word 基准数据集上，我们的算法实现了和以前语言模型差不多的困惑度，同时却将模型的大小减小了 40 到 100 倍、训练过程也加快了 2 倍。我们将我们提出来的算法命名为 LightRNN, 这主要是反应它在模型大小上的精简和很快的训练速度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQiblzyVh1Iicfga2kY36K3Ykw75jfcsfYRZu7VArMce4A8zh3TUFoicA8cEfDx45EibK8hZyXJttjBQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;训练 ACLW-French 时的困惑度对比&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;引言&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最近，循环神经网络（RNN）已被用于处理多种自然语言处理（NLP）任务，例如语言建模、机器翻译、情绪分析和问答。有一种流行的 RNN 架构是长短期记忆网络（LSTM），其可以通过记忆单元（memory cell）和门函数（gating function）建模长期依赖性和解决梯度消失问题。因为这些元素，LSTM 循环神经网络在当前许多自然语言处理任务中都实现了最佳的表现，尽管它的方式几乎是从头开始学习。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然 RNN 越来越受欢迎，但它也存在一个局限性：当应用于大词汇的文本语料库时，模型的体量将变得非常大。比如说，当使用 RNN 进行语言建模时，词首先需要通过输入嵌入矩阵（input-embedding matrix）从 one-hot 向量（其维度与词汇尺寸相同）映射到嵌入向量。然后为了预测下一词的概率，通过输出嵌入矩阵（output-embedding matrix）将顶部隐藏层投射成词汇表中所有词的概率分布。当该词汇库包含数千万个不同的词时（这在 Web 语料库中很常见），这两个嵌入矩阵就会包含数百亿个不同的元素，这会使得 RNN 模型变得过大，从而无法装进 GPU 设备的内存。以 ClueWeb 数据集为例，其词汇集包含超过 1000 万词。如果嵌入向量具有 1024 个维度并且每个维度由 32 位浮点表示，则输入嵌入矩阵的大小将为大约 40GB。进一步考虑输出嵌入矩阵和隐藏层之间的权重，RNN 模型将大于 80GB，这一数字远远超出了市面上最好的 GPU 的能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;即使 GPU 的内存可以扩容，用于训练这样体量模型的计算复杂度也将高到难以承受。在 RNN 语言模型中，最耗时的运算是计算词汇表中所有词的概率分布，这需要叠乘序列每个位置处的输出嵌入矩阵和隐藏状态。简单计算一下就可以知道，需要使用目前最好的单 GPU 设备计算数十年才能完成 ClueWeb 数据集语言模型的训练。此外，除了训练阶段的难题，即使我们最终训练出了这样的模型，我们也几乎不可能将其装进移动设备让它进入应用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了应对这些挑战，在本研究中我们提出了将二分量（2-Component）共享的嵌入用于循环神经网络中词表征的方法。我们将词汇表中的所有词放入一个表中，每一行都与一个向量关联，每一列都与另一个向量关联。这样我们就能够通过两个组件来表示一个词：对应的行向量和列向量。因为该表中同一行具有相同的行向量，同一列具有相同的列向量，所以我们仅仅需要 2p|V|个向量来表示带有|V|个词的词汇表，这样可以大幅度减少模型体积（相比而言，vanilla 方法需要|V|个不同的向量）。同时，由于模型尺寸的减小，RNN 模型的训练速度将会显著加快。因此，我们将这一新算法称为 LightRNN，以表示模型的小尺寸和极高的训练速度。这种方法的最大技术难题是如何将词合适地分配到表中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmsns.qpic.cn/mmsns/KmXPKA19gWibQiblzyVh1Iicfga2kY36K3YfrIj0081O9ruFYI5JuZibEQ/0"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;LightRNN（左）对比常规 RNN（右）&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了这个目的，我们提出一个引导框架：（1）首先随机初始化词分配（word allocation），并训练 LightRNN 模型。（2）解决训练了的嵌入向量（对应为表格中的行和列向量），然后细化分配来最小化训练损失（training loss），这是图论（graph theory）最小权重完美匹配问题，我们能够有效地解决。（3）重复第二步，直到满足确切的终止标准。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们使用在多个基准数据集进行语言建模任务来评价 LightRNN。实验表明，在困惑度（perplexity）上面，LightRNN 实现了可与最先进的语言模型媲美或更好的准确度。同时还减少了模型大小高达百倍，加快了训练过程两倍。请注意，对于高度紧凑的模型来说这个可预见的（没有准确性下降）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先，这使得将 RNN 模型运用到 GPU 甚至是移动设备成为了可能。其次，如果训练数据很大，需要执行分布式数据平行训练时，聚合本地工作器（worker）的模型所需要的交流成本会很低。通过这种方式，我们的方法使先前昂贵的 RNN 算法变得非常经济且规模化了。因此，它将会对用于人工自然语言处理（NLP）任务的深度学习有深远的影响。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;结论和未来的方向&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在本研究中，我们提出了一个全新的算法 LightRNN，该算法可用于自然语言处理任务。通过用于词表征的二分量共享的嵌入（2-Component shared embedding for word representations），LightRNN 在模型尺寸和运行时间上都取得了高效的表现，特别是在具有大词汇量的语料库中。在未来，这种算法有很多方向可以进一步研究。首先，我们计划将 LightRNN 应用于更大的语料库中，如 ClueWeb 数据集——传统的 RNN 模型还不能将其装进一个现代的 GPU 中。第二，我们会将 LightRNN 应用于机器翻译和问答等其它自然语言处理任务中。第三，我们会探索 k-分量分享嵌入（k&amp;gt;2）并研究 k 在权衡效率和有效性之间的作用。最后，我们将会整理我们的代码，以便在近期通过 CNTK 将其发布出来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;论文下载：https://arxiv.org/pdf/1610.09893v1.pdf&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 01 Nov 2016 16:26:34 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 超越R，Python成为最受欢迎的机器学习语言</title>
      <link>http://www.iwgc.cn/link/3316958</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;选自Machine Learning Mastery&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Jason Brownlee&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你应该挑选正确的工具做机器学习。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你正在做的特定预测模型问题要求特定的编程语言、库、甚至是机器学习算法。但如果你只是刚开始呢？还在找一个平台学习并实践机器学习呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在此文章中，你会发现 Python 正在成为做机器学习逐渐流行的平台，在采用率与能力上极可能超过并推翻 R 语言。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;读完该文章后，你将会明白：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;对 Python 机器学习的搜索量增长迅速，已经超越了 R 语言机器学习的搜索量；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Python 机器学习招聘的比例正在增长，已经超越了 R 语言；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;调查中，近 50% 的调查对象使用 Python，而且正在增长；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;用 Python 做机器学习的趋势在增长&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;让我们看一下以下三个领域，从此三方面都能看到使用 Python 进行机器学习的趋势正在增长：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;搜索量&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;招聘广告&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;专业工具使用&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;搜索量&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;搜索量可能表明学生、工程师和其他从业者搜索信息开始或者深入这一主题的趋势。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谷歌提供了一个名为 Google Trends 的工具，能让我们观察关键字随时间变化的搜索量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们能够调查 2014 年至 2016 年「Python 机器学习」的增长趋势，如下图所示：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQiblzyVh1Iicfga2kY36K3Y7PiajCxjGs2sXQTcxTIUUvcK0lG6icEupxqq6UA5TqXyEwqgAXfyqj8g/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们能够看到在 2012 年趋势开始上涨，在 2015 年急剧上涨，这可能是因为 TensorFlow 这样的 Python 深度学习工具。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们也可与 R 机器学习的搜索量进行对比，我们可以看到在 2015 年中期，Python 机器学习已经超过 R 机器学习：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQiblzyVh1Iicfga2kY36K3YPX5QfPn106tKPrDoMPA4HM3tnkO9hAAfFURGAiaUHuDmQSYfEpY6eVQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;蓝色代表「Python 机器学习」，红色代表「R 机器学习」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Python 机器学习招聘增长&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Indeed 是一个招聘搜索网站，像 Googel Trends 一样，它可提供匹配关键词的招聘广告量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们能够调查过去 4 年的「Python 机器学习职位」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQiblzyVh1Iicfga2kY36K3Y5r5ruliaQmDoS0gH1Q2LErbtU45zibticsqOJZibmoOoOIWjPTYBPlJLGQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们能够看到 X 轴上的时间和匹配关键词的招聘比例。该图显示从 2012 年至 2015 年几乎呈现线性增长，在 2016 年有曲棍球式的增长。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们也可以对比 Python 和 R 的招聘广告。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQiblzyVh1Iicfga2kY36K3YXvHhOtwp1CYZKK7PCP8ibtq4OicInuweVoKxUofqn512JPPldKAhCfCg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;蓝色表示 Python 机器学习，橙色表示 R 机器学习&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;与谷歌搜索量有显著的对比。从 Indeed 网站获得的招聘广告的比率显示从 2012 年开始，对 Python 机器学习技能的需求一直高于对 R 机器学习技能的需求，差距在近几年逐渐拉大。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;KDnuggets 调查结果：更多人使用 Python 进行机器学习&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过回顾 KDnuggets Software Poll Results 我们能够观察机器学习从业者使用的工具：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面就引自 2016 年的结果：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;R 语言仍然主导工具，占有 49% 的份额，但 Python 增长迅速，几乎赶超 R 语言。——Gregory Piatetsky。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该调查追踪了机器学习和数据科学从业人士使用的工具，在调查中，从业者可以选择多种工具。以下是过去 4 年 Python 机器学习的增长比例：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQiblzyVh1Iicfga2kY36K3Y7PR3P1hokzicjZ6IvkpSibnofXdF2KOVNsPdwVfnAlibSIVNIbSTOYwdw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面是一张增强趋势图：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQiblzyVh1Iicfga2kY36K3YtDwUtdlBib5vwElQ39kBgENfS9HsZTtqcUgHlCEicDUiaefx2wUIJCPPg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们可以看到几乎呈现线性增长趋势，在 2016 年刚好低于 50%&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;值得注意的是，近几年的调查中参与调查的对象也从几百增加到了几千人，参与者是自选择的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;O'Reilly 调查结果：更多人使用 Python 进行机器学习&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;O'Reilly 展示了年度数据科学薪水调查结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他们收集了大量数据科学家和机器学习从业者的数据，并展示了调查结果。该调查追踪了从业人员对工具的使用情况。从下面这段话中，我们可以看到 Python 如今在数据科学薪资中扮演重要角色：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Python 和 Spark 是最对薪资有贡献的工具。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;回顾此调查结果，我们可以看到类似的增长趋势：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQiblzyVh1Iicfga2kY36K3YjsiaZMHrZRnbca4t66cmuWDZo6sPaExGLQZT6SYhDktEUAOyMiaaXQEA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图形展示如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQiblzyVh1Iicfga2kY36K3Y4A9VQBTDC9ic4CuuVWE3eIkN1jwOWMXdXHfqh2VJiaW99PHDScUjholg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有趣的是 O'Reilly 的调查结果非常类似于 KDNuggeets 的结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 01 Nov 2016 16:26:34 +0800</pubDate>
    </item>
    <item>
      <title>学界 | DeepMind最新论文：线性时间的神经机器翻译</title>
      <link>http://www.iwgc.cn/link/3316959</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自arXiv.org&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQiblzyVh1Iicfga2kY36K3YQPuwgqiawCVMAo5jghfuzpnPruESfCdQnNCq5W8fuuicp3vbMZ5kicgtQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;摘要&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们提出了一种用于序列处理（sequence processing）的神经架构。ByteNet 是一种两个扩张的卷积神经网络（dilated convolutional neural networks）的堆叠；其中一个网络用于编码源序列（source sequence），另一个网络用于解码目标序列（target sequence）——这个过程中目标网络动态展开从而生成可变长度输出。ByteNet 有两个核心特性：它在与序列长度成线性的时间上运行；它能保留序列的时间分辨率（temporal resolution）。ByteNet 解码器在字符级的语言建模上获得了顶尖水平，并超越了之前循环神经网络取得的最好结果。ByteNet 也在原始的字符级机器翻译（raw character-level machine translation）上获得了接近最好的神经翻译模型（运行在二次时间（quadratic time）中）所能取得的顶尖表现。由 ByteNet 学习到的隐含架构能反映出序列之间的预期对应。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;论文下载：https://arxiv.org/pdf/1610.10099v1.pdf&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 01 Nov 2016 16:26:34 +0800</pubDate>
    </item>
    <item>
      <title>专访 | 顶级语音专家、MSR首席研究员俞栋：语音识别的四大前沿研究</title>
      <link>http://www.iwgc.cn/link/3299917</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心原创&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;记者：老红&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;编辑：吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;9 月中旬，微软报告了在语音识别方面取得的新里程碑：&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719135&amp;amp;idx=1&amp;amp;sn=012d179f83a6c3b38c6e58b4ac9ba82f&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719135&amp;amp;idx=1&amp;amp;sn=012d179f83a6c3b38c6e58b4ac9ba82f&amp;amp;scene=21#wechat_redirect"&gt;新系统的识别词错率降至 6.3%&lt;/a&gt;；一个月后，微软又公布了在这一领域成功实现了历史性突破：&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719843&amp;amp;idx=1&amp;amp;sn=0c6387d422cf9765b9b10c178d160680&amp;amp;chksm=871b021db06c8b0b0b0447124c5c07818f53a17ba470305049af1d7d49806c87e07307a93811&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719843&amp;amp;idx=1&amp;amp;sn=0c6387d422cf9765b9b10c178d160680&amp;amp;chksm=871b021db06c8b0b0b0447124c5c07818f53a17ba470305049af1d7d49806c87e07307a93811&amp;amp;scene=21#wechat_redirect"&gt;他们的语音识别系统实现了和专业转录员相当甚至更低的词错率（WER），达到了 5.9%&lt;/a&gt;！机器之心在此期间曾对&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719843&amp;amp;idx=2&amp;amp;sn=4611f810734df8a72286567e90c65a92&amp;amp;chksm=871b021db06c8b0b283ac93f267d95365392be02b3cde5d2fe6df85b359aa96368f25318e2f5&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719843&amp;amp;idx=2&amp;amp;sn=4611f810734df8a72286567e90c65a92&amp;amp;chksm=871b021db06c8b0b283ac93f267d95365392be02b3cde5d2fe6df85b359aa96368f25318e2f5&amp;amp;scene=21#wechat_redirect"&gt;微软首席语音科学家黄学东进行了专访&lt;/a&gt;，探讨了这一连串突破性背后的技术和语音识别领域未来的可能性。近日，机器之心又对微软研究院首席研究员俞栋进行了一次独家专访，谈论了深度学习与语音识别相辅相成的发展以及相关领域的现状和未来。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;俞栋简介&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：1998 年加入微软公司，现任微软研究院首席研究员，兼任浙江大学兼职教授和中科大客座教授。语音识别和深度学习方向的资深专家，出版了两本专著，发表了 160 多篇论文，是 60 余项专利的发明人及深度学习开源软件 CNTK 的发起人和主要作者之一。曾获 2013 年 IEEE 信号处理协会最佳论文奖。现担任 IEEE 语音语言处理专业委员会委员，曾担任 IEEE/ACM 音频、语音及语言处理汇刊、IEEE 信号处理杂志等期刊的编委。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;以下是此次专访的内容：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：请俞老师先给我们的读者介绍一下目前语音识别方面最值得关注的一些方向。&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;俞栋&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：在安静环境下并使用近距麦克风的场合，语音识别的识别率已越过了实用的门槛；但是在某些场景下效果还不是那么好，这就是我们这个领域的 frontier。现在大家主攻几点：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;首先，是不是能够进一步提升在远场识别尤其是有人声干扰情况下的识别率&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。目前一般远场识别的错误率是近场识别错误率的两倍左右，所以在很多情况下语音识别系统还不尽如人意。远场识别至少目前还不能单靠后端的模型加强来解决。现在大家的研究集中在结合多通道信号处理（例如麦克风阵列）和后端处理从拾音源头到识别系统全程优化来增强整个系统的 表现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;另外，大家还在研究更好的识别算法&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。这个「更好」有几个方面：一个方面是能不能更简单。现在的模型训练过程还是比较复杂的，需要经过很多步骤。如果没有 HTK 和 Kaldi 这样的开源软件和 recipe 的话，很多团队都要用很长时间才能搭建一个还 OK 的系统即使 DNN 的使用已经大幅降低了门槛。现在因为有了开源软件和 recipe，包括像 CNTK 这样的深度学习工具包，事情已经容易多了，但还有继续简化的空间。这方面有很多的工作正在做，包括如何才能不需要 alignment 、或者不需要 dictionary。现在的研究主要还是基于 end-to-end 的方法，就是把中间的一些以前需要人工做的步骤或者需要预处理的部分去掉。虽然目前效果还不能超越传统的 hybrid system，但是已经接近 hybrid system 的 performance 了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;另外一个方面，最近的几年里大家已经从一开始使用简单的 DNN 发展到了后来相对复杂的 LSTM 和 Deep CNN 这样的模型&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。但在很多情况下这些模型表现得还不够好。所以一个研究方向是寻找一些特殊的网络结构能够把我们想要 model 的那些东西都放在里面。我们之前做过一些尝试，比如说人在跟另外一个人对话的过程中，他会一直做 prediction，这个 prediction 包括很多东西，不单是包括你下一句想要说什么话，还包括根据你的口音来判断你下面说的话会是怎样等等。我们曾尝试把这些现象建在模型里以期提升识别性能。很多的研究人员也在往这个方向走。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;还有一个方向是快速自适应的方法—就是快速的不需要人工干预的自适应方法（unsupervised adaptation）&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。现在虽然已经有一些自适应的算法了，但是它们相对来说自适应的速度比较慢，或者需要较多的数据。有没有办法做到更快的自适应？就好像第一次跟一个口音很重的人说话的时候，你可能开始听不懂，但两三句话后你就可以听懂了。大家也在寻找像这种非常快还能够保证良好性能的自适应方法。快速自适应从实用的角度来讲还是蛮重要的。因为自适应确实在很多情况下能够提升识别率。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从识别来讲，我觉得目前主要是这些方向。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：Google DeepMind 最近提出了一种通过学习合成波形的方式生成语音的技术 WaveNet，据说可以生成感觉更自然的语音，微软在这方面有什么研究项目？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;俞栋&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：微软也在做类似的工作，但是因为合成的研究团队和工程团队都在中国，我对他们具体到哪个地步不是特别清楚。有一些信息我也不能直接披露，所以就不详细讲了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：深度学习已经在语音识别得到了非常出色的表现，您觉得未来语音识别还能在深度学习的哪些方面实现突破？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;俞栋&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：刚才我讲了，其中的一个可能性就是通过各种类型的 prediction 和 adaptation 使得深度学习模型表现更出色，这是有可能继续提升的地方。另外就是 end-to-end 建模。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;还有，像我们最近也在做一些特殊环境中的语音识别，比如说在高噪音环境下、或者你说话的时候有背景的音乐、或者是会议室里面有多个人同时说话——这些情况下现在的语音识别效果是很差的。所以我们也在研究如何用深度学习的方法在比如多说话人的情况下做得比原来传统的方法好。我们现在已经在 arXiv 上面发布了一个早期结果的预印本（Permutation Invariant Training of Deep Models for Speaker-Independent Multi-talker Speech Separation），含有更多实验结果的正式版本现在正在审稿中。我们的这一称为 Permutation Invariant Training 的方法主要用于语音分离。用这种方法整个 process 比较简单而效果很好。在这些方面深度学习都能带来一定的突破。当然，我前面也讲了，完全解决这些问题需要软硬结合，从拾音到前端和后端需要系统性优化。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：在类似汉语这种多音字、多音词比较多的语言中，语音识别方面有什么和英语这样的拼音语言不一样的地方？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;俞栋&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：从语音识别的技术角度来讲，没有太大的区别。因为你最终都是将语音信号，即 waveform sequence，变成字或者词的 sequence。多音字和多音词只是词表里对应的字或词有多个发音规则而已，这在其他语言比如英语中也很常见。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不过中文是一个有音调的语言，音调对字和词的识别是有影响的。音调信息如果用好的话，就有可能提升识别率。不过大家发现 deep learning 模型有很强的非线性映射功能，很多音调里的信息可以被模型自动学到，不需要特别处理。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;唯一可能不一样的地方是如果你用 end-to-end system，建模单元会不一样。因为在英语里面你一般会选用字母、音素、或音节 作为建模单元，而不会选用词作为建模单元。但在中文里面你可以直接用汉字作为建模单元。所以建模单元的选择上可能会不太一样。除此之外，基本上没有太大区别。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：技术上没有太大区别？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;俞栋&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：没有太大区别。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：具体来说，您觉得自然语言处理能够给语音识别带来哪些帮助？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;俞栋&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：目前来讲，自然语言处理对语音识别本身的帮助还不是很大。要说帮助比较大的方面——如果语言模型（language model）算做自然语言处理的话，语言模型还是起到了很大作用的，尤其是在有噪音的环境下，如果没有语言模型来做约束，效果一般来说都比较差。但是除此之外，现在的 NLP 技术对语音识别没有起到很大的作用。大家尝试过很多用自然语言处理技术提升识别率的方法，但效果都不理想。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是理论上来讲它应该是可以起到作用的。因为我们理解句子含义，我们能发现有一些语音识别结果是不 make sense 的，比如说前面的主语跟后面的宾语根本就不搭，在这种情况下识别系统应该选择其他的 hypothesis，对话系统则应该寻求澄清，但是现有系统没有这么做。没有这么做的原因在于它其实不理解到底用户说了什么，也没能充分利用远距离的 dependency 信息。这样的错误，有可能通过自然语言处理的技术发现并得到更正。但是语义分析是个很困难的问题，如何做还是一个未知数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：刚才我们讲到在噪音环境下，包括远距离环境下的识别，除了这个，还有多个说话人一起说话的情况下的语音识别。在这三个方面，您觉得现在和未来可以通过什么样的方式来解决这个问题？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;俞栋&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：前面提到过，解决远距离识别很重要的一点是需要硬件的支持。至少以目前的技术，仅仅通过后端处理效果还不够好。因为信号在传输的过程中衰减很厉害，距离越远衰减越厉害，信噪比就越差。所以远距离识别一般都需要做增强。比较好的增强需要硬件支持，比如说麦克风阵列。深度学习方法也能提供一些帮助。当你有多通道信息的时候，深度学习方法还可以做自动的信息融合以提升远距离语音识别的性能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;多通道信号处理，比如麦克风阵列，对分离含噪语音和多人混合语音也至关重要。另外，深度学习方法比如我刚才提到的 Permutation Invariant 训练方法也可以解决一部分语音分离问题，是整体解决方案中的重要一环。分离后的结果可以送到后端做识别。后端的识别结果反馈回来也能帮助提升分离和说话人跟踪的效果。所以最终的系统应该是前端的分离跟后端的识别融合互助的系统。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：从您和邓力老师的那本书《Automatic Speech Recognition： A Deep Learning Approach》出版到现在，您认为期间深度学习有了什么新的研究成果? 哪些研究成果您认为是很重大的？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;俞栋&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：我们写这本书的时候，LSTM 这样的模型才刚刚开始成功应用于语音识别。当时大家对其中的很多 技巧 还没有很好的了解。所以训练出来的模型效果还不是那么好。最近，我的同事 Jasha Droppo 博士花了很多时间在 LSTM 模型上面，提出了一种很有意思的基于 smoothing 的 regularization 方法使得 LSTM 模型的性能有了很大的提升。他的 smoothing 方法的基本思想在我们的 human parity 文章中有介绍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外一个比较大的进展是 Deep CNN。最近两年里，很多研究组都发现或证实使用小 Kernel 的 Deep CNN 比我们之前在书里面提到的使用大 kernel 的 CNN 方法效果更好。Deep CNN 跟 LSTM 比有一个好处。用 LSTM 的话，一般你需要用双向的 LSTM 效果才比较好。但是双向 LSTM 会引入很长的时延，因为必须要在整个句子说完之后，识别才能开始。而 Deep CNN 的时延相对短很多，所以在实时系统里面我们会更倾向于用 Deep CNN 而不是双向 LSTM。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;还有就是端到端的训练方式也是在我们的书完成后才取得进展的。这方面现在大家的研究工作主要集中在两类模型上。一类就是 CTC 模型，包括 Johns Hopkins 大学的 Dan Povey 博士从 CTC 发展出来的 lattice-free MMI；还有一类是 attention-based sequence to sequence model。这些模型在我们的书里面都没有描述，因为当时还没有做成功。即便今天它们的表现也还是比 hybrid model 逊色，训练的稳定性也更差，但是这些模型有比较大的 potential。如果继续研究有可能取得突破。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外一个进展是单通道语音分离，尤其是多人混合语音的分离。这方面有两项有趣的工作。一个是 MERL 的 John Hershey 博士提出的 Deep Clustering 方法，另外一个是我们提出的 Permutation Invariant Training。实现上，Permutation Invariant Training 更简单。John Hershey 认为有迹象表明 deep clustering 是 permutation invariant training 的一个特例。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些都是在我们完书之后最近两年里比较有意义的进展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：也是在这个月，Google 发了神经网络翻译系统（GNMT），您对这个系统有什么看法？微软在这方面有没有这样的研究？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;俞栋&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：微软很早以前就在做类似的工作了。你可能知道微软有个基于文本的翻译系统，在 Skype 上也有一个 speech to speech translation system。在这些系统里我们已经用到了 neural machine translation 的一些东西。不过翻译主要是由另外的团队在做，我在这里面涉及比较少。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：语音特征参数提取与鲁棒性语音识别与合成的关键因素，特征参数在不利的噪声环境下，鲁棒性都会急剧下降。目前有什么新的研究可以在特征提取中保持语音信号的最重要参数吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;俞栋&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：目前，一个方法是用信号处理技术对输入信号进行分离和增强。另一个方法是用 deep learning 取代人工从 waveform 直接提取特征。只要训练数据的 coverage 足够大，各种各样场景的训练数据都有，模型的结构设计合理，那么模型的泛化能力和鲁棒性就能得到提升。两种方式结合可以得到更好结果。不过，泛化是机器学习的一个未解决的基本问题，更好的解决方案有待于机器学习理论的进展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：微软在语音识别上如何解决方言带来的口音问题，比如说「le」和「ne」？针对方言，微软的语料库是从何而来的？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;俞栋&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：一个简单的方法是增加带口音的训练语料。如何有效利用这些语料有些讲究。大概 3、4 年前，我们发过一篇文章，研究怎么样在 deep learning model 上做自适应。带口音的识别问题可以看作一个自适应的问题。假设你已经有标准语音的模型，带口音的语音可以看成标准语音的某种偏离。所以我们的解决方法是做自适应。做自适应的时候，我们可以把有类似口音的语料聚合在一起以增加训练数据。我们发现这样做效果挺不错。如果已经有系统上线，收集带口音的语料并不困难。如果你用过 Windows Phone，你就知道 Windows Phone 的 Cortana 里面有个选项——你想用标准的识别模型还是想用含口音的模型？用户可以选择。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：今年，微软发布了 CNTK。您能说一下 CNTK 跟 Theano、TensorFlow、Torch、Caffe 这些工具的区别吗？以及在微软语音系统上是怎么样应用 CNTK 的？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;俞栋&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：所有的这些开源工具现在都做得相当好了，都能够满足一般的研究或者是工程的需要。但是每一个开源工具都有自己的长处和弱点。CNTK 是唯一一个对 Windows 和 Linux 都有比较好的支持的深度学习工具。相比较其他工具，CNTK 对多 GPU 并行训练有更好的支持, 不仅并行效率高，而且简单易用。CNTK 对 C++的支持也是最全面的，你可以完全使用 C++来构建、训练、修改、和解码模型。CNTK 版本 1 对 Python binding 支持比较弱。但是刚刚发布的版本 2.0 提供了非常强大的 Python binding。另外，CNTK 提供了许多运行效率很高的并行文件阅读模块，大大提升了并行效率。这里我想提一下，我的很多同事都对 CNTK 2.0 有很大贡献。尤其值得一提的是 Amit Agarwal，他是我见过的非常难得的优秀软件工程师和架构师，他主导设计了 CNTK2.0 的主要 API。我在他身上学到很多东西，我非常享受与他讨论的时间。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我和几个同事刚开始写 CNTK1.0 的时候，主要用户是语音识别研究员和工程师，所以 CNTK 对语音相关的模型、数据结构、和文件格式支持得相对比较好。因为语音识别系统训练数据很大，我们很早就在 CNTK 中实现了并行训练的算法。目前，微软产品线所有的语音识别模型都是用 CNTK 训练的。最近我们的语音识别系统在 SWB 数据集上能做到比专业转录员错误率还低，CNTK 对缩短我们达到这一里程碑所需的时间有很大贡献。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：您曾说过，人工智能的成功在于将多种方法的整合到一个系统。在你们最近发表的论文中，我们看到目前最新的语音识别的研究用到了多任务优化（Multitask Joint learning）以及多种模型混合（ensembles of models）的方法，能谈谈他们的优势吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;俞栋：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;语音识别相对来说是一个任务比较单一而非通用的人工智能系统。语音识别的问题定义得也比较清晰。在这样的系统里面，把深度学习模型与其他模型进行整合的重要性相对来说比较小。这也就是为什么只要你有足够的数据和运算能力，即便是完全的 deep learning end-to-end system 表现也不错。不过目前来讲，深度学习和 HMM 相结合的混合模型在大多数场景下仍然表现最佳。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;语音识别中使用多任务优化的主要目的是增加模型的泛化能力或利用一些不能直接利用的辅助信息。而多种模型混合（ensembles of models）的主要目的是利用模型间的差异来增强混合后模型的表现。值得指出的是，由于深度学习模型是非线性非凸的优化问题，当初始模型不同时，最后的模型也不同。尽管这些模型的平均表现很接近，但因为他们收敛到的点不一样，模型之间仍有差异，融合这些模型也能提升一些性能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是更通用的人工智能系统还需要能做决策（decision-making）、要做推理、要能理解。对于这样的系统来说，单靠深度学习方法远远不够。而需要结合过去几十年里人工智能其他分支取得的一些进展，比如说增强学习、逻辑推理、知识表达、以及最优和次优搜索。还有如果我们想让一群人工智能系统自己从与环境的交互中快速寻找答案，那么诸如蚁群算法和遗传算法一类的算法就变得很重要了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：今年您觉得在语音识别方面有哪些比较重量级的论文值得去读，能否推荐几个给我们的读者？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;俞栋&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：除了前面提到的 LF-MMI 、 Deep CNN（包括我们最近发表的 LACE 模型）、和 Permutation Invariant Training，另外一个比较有意思的论文是 MERL 在 arXiv 上发表的一篇文章。他们结合了 CTC 和 attention-based model，利用这两个模型各自的长处来克服对方的弱点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;	&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：您是怎么看待监督学习、半监督学习和无监督学习这三个学习方式呢？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;俞栋&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：监督学习是比较 well-defined，有比较明确的任务。目前来讲，深度学习对这一类问题 效果比较好。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;无监督学习的目的是要寻找数据中的潜在规律。很多情况下，它试图寻找某种特征变换和相对应的生成模型来表达原始数据。但无监督学习不仅本身困难，对无监督学习系统的评价也很难。原因是通过无监督学习找到的规律不一定对你将来的任务有帮助，或者它对某一任务有帮助，换一个 任务就没有帮助了。当然，如果你的目标仅仅是数据压缩，评价还是容易的，但我们使用无监督学习压缩本身往往不是主要目的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：那半监督学习呢？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;俞栋&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：半监督学习介于两者中间。因为你已经有一部分标注信息了，所以你 的任务是明确的，不存在不知如何评估的问题。半监督学习在实用系统里还是有一定作用的。比如说我们需要标注大量数据来训练语音识别系统，但人工标注既花时间又花钱，所以你往往有比标注数据多得多的未标注数据。没有标注过的数据，也有很多可以利用的信息，虽然它们的价值远远小于标注的数据。半监督学习对我们的系统性能有一定的提升。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：最后一个问题，在整个人工智能的布局上，您认为语音识别是一个怎样的定位？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;俞栋：在很多应用场合，语音识别是一个入口。没有这个入口的话，大家都会觉得这个智能机器不够智能或者与这个智能机器交互会有困难。人机交互中语音识别是第一步。如果语音识别做得不够好，那后期的自然语言理解等的错误率就会大幅上升。这也是为什么语音到语音的翻译要比文本到文本的翻译难很多，因为在语音对语音的翻译系统里语音识别产生的错误会在后面翻译的过程中放大。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;历史上，语音识别也为机器学习和人工智能提供了很多新的方法和解决方案。比如语音识别里的关键模型 Hidden Markov Model 对后来机器学习的很多分支都有帮助。深度学习也是先在语音识别上取得成功，然后才在图像识别和其他领域取得成功的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8G2Aqj8cfARvWSIzEs1ZXZgT6VrNdsVA4icyCrL6lqQtv3wPx1Ij2rZn8odibiaN7LBAPnqsPNXxteg/0?wx_fmt=jpeg"/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;专访 | 微软人物志 &lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650714822&amp;amp;idx=1&amp;amp;sn=e56ee226cdacab228e1ad9fc40646adf&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650714822&amp;amp;idx=1&amp;amp;sn=e56ee226cdacab228e1ad9fc40646adf&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;微软研究院人工智能首席科学家 | &lt;/span&gt;&lt;span&gt;邓力&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719843&amp;amp;idx=2&amp;amp;sn=4611f810734df8a72286567e90c65a92&amp;amp;chksm=871b021db06c8b0b283ac93f267d95365392be02b3cde5d2fe6df85b359aa96368f25318e2f5&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719843&amp;amp;idx=2&amp;amp;sn=4611f810734df8a72286567e90c65a92&amp;amp;chksm=871b021db06c8b0b283ac93f267d95365392be02b3cde5d2fe6df85b359aa96368f25318e2f5&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;&lt;span&gt;微软首席语音科学家 | &lt;/span&gt;黄学东&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=400579280&amp;amp;idx=1&amp;amp;sn=b13556c48c2937593ee833e8284f2c89&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=400579280&amp;amp;idx=1&amp;amp;sn=b13556c48c2937593ee833e8284f2c89&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;微软亚洲研究院院长 | 洪小文&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=401882267&amp;amp;idx=1&amp;amp;sn=eb5a4cf6e10b6dc3787303f421a8f77b&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=401882267&amp;amp;idx=1&amp;amp;sn=eb5a4cf6e10b6dc3787303f421a8f77b&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;微软（亚洲）互联网工程院院长 | 王永东&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650714905&amp;amp;idx=2&amp;amp;sn=ad19a7e003ecdb48b0ffc524e8c2c94b&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650714905&amp;amp;idx=2&amp;amp;sn=ad19a7e003ecdb48b0ffc524e8c2c94b&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;微软亚洲研究院首席研究员 | 霍强&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;strong&gt;机器之心&lt;/strong&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8G2Aqj8cfARvWSIzEs1ZXZ248wIRLFyLjemC1oeWWd1em6qPOfHVREYUvcibiamyGHjAkDJH7mOC4w/0?wx_fmt=jpeg"/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;</description>
      <pubDate>Mon, 31 Oct 2016 12:46:20 +0800</pubDate>
    </item>
    <item>
      <title>学界 | CMU全新编码器解-码器框架：一种用于描述生成的Review Network（附项目地址）</title>
      <link>http://www.iwgc.cn/link/3299918</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;选自GitHub&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：杜夏德&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;卡耐基梅隆大学提出了一种新的编码器-解码器框架 —— review network，该框架在提升图像和源代码描述的任务上超过了现有其他最先进的系统。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们提出了一种编码器-解码器框架的新扩展，叫review network。这种 review network是通用的，能够增强任意现有的编码器-解码器模型：在这篇论文中，我们探讨了带有CNN和RNN编码器的RNN解码器。该review network在编码器隐藏状态下执行一些review步骤，并在每一次review后输出一个 thought vector；这些 thought vectors 在解码器中被用作注意力机制（attention machine）的输入。我们发现在我们的框架中，卷积的编码-解码器是一个特例。经过实证，我们发现我们的框架在提升图像和源代码描述的任务上超过了目前所有最先进的编码器-解码器系统。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;项目地址：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt; https://github.com/kimiyoung/review_net&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;用于描述生成的 R&lt;span&gt;eview Network&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;在 MSCOCO 上给图像添加描述&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你可以在这个 repo 中使用这个代码来生成一个 MSCOCO 评估服务器（CIDE.r=0.96+), 这个过程需要几个小时。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;无需微调，没有花哨的技巧。仅训练三个端到端的 &lt;span&gt;review network&lt;/span&gt;，然后做一个集成：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;特征提取：并行 2 小时&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;单一模型训练：6 小时&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;集成模型训练：30 分钟&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;描述生成的波束搜索：并行 3 小时&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面是我们的系统在 MSCOCO 评估服务器上与其他先进系统的比较（根据已发表的论文）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;th&gt;Model&lt;/th&gt;&lt;th&gt;BLEU-4&lt;/th&gt;&lt;th&gt;METEOR&lt;/th&gt;&lt;th&gt;ROUGE-L&lt;/th&gt;&lt;th&gt;CIDEr&lt;/th&gt;&lt;th&gt;Fine-tuned&lt;/th&gt;&lt;th width="79"&gt;Task specific features&lt;/th&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;Attention&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.537&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.322&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.654&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.893&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;No&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="79"&gt;No&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;MS Research&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.567&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.331&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.662&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.925&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;No&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="79"&gt;Yes&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;Google NIC&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.587&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.346&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.682&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.946&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;Yes&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="79"&gt;No&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;Semantic Attention&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.599&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.335&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.682&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.958&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;No&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="79"&gt;Yes&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;Review Net&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.597&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.347&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.686&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.969&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;No&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="79"&gt;No&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 image_caption_online 目录下，你可以使用里面的代码重现我们的评估服务器的结果。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 image_caption_offline 目录下，你可以使用离线评估重新运行我们论文中的实验。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;添加代码描述&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一个有趣的任务是预测一条源代码的注释。在这个 repo 中，除了一个&lt;span&gt;review network&lt;/span&gt;的代码外，我们也开放了一个带有 train/dev/test 分类的数据集。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;查看 code_caption 目录。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面是我们的框架系统在代码描述数据集上与基线的比较。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;th&gt;Model&lt;/th&gt;&lt;th&gt;LLH&lt;/th&gt;&lt;th&gt;CS-1&lt;/th&gt;&lt;th&gt;CS-2&lt;/th&gt;&lt;th&gt;CS-3&lt;/th&gt;&lt;th&gt;CS-4&lt;/th&gt;&lt;th&gt;CS-5&lt;/th&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;LSTM Language Model&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;-5.34&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.234&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.2763&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.3&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.3153&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.329&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;Encoder-Decoder&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;-5.25&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.2535&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.2976&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.3201&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.3367&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.3507&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;Encoder-Decoder (Bidir)&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;-5.19&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.2632&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.3068&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.329&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.3442&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.357&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;Attentive Encoder-Decoder (Bidir)&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;-5.14&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.2716&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.3152&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.3364&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.3523&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.3651&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;Review Net&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;-5.06&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.2889&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.3361&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.3579&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.3731&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.384&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;参考文献：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;用于描述生成的review networks（Review Networks for Caption Generation），&lt;/span&gt;&lt;span&gt;这个 repo 中包含的代码和数据可在这篇论文中找到。（点击「阅读原文」下载论文）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Mon, 31 Oct 2016 12:46:20 +0800</pubDate>
    </item>
  </channel>
</rss>
