<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>机器之心</title>
    <link>http://www.iwgc.cn/list/670</link>
    <description>人与科技的美好关系</description>
    <item>
      <title>深度 | 为何最强人工智能比不上婴儿大脑？</title>
      <link>http://www.iwgc.cn/link/3579156</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自IBTimes&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：王宇欣、候韵楚&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器可以理解语音、识别面部和安全驾驶汽车。这让人们十分讶异于近期的技术方面的进步。但是，如果人工智能领域想要实现革命性的跨越，从而建造出类人式的机器，它首先将要掌握婴儿的学习方式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「在相对最近的人工智能中，人们从想直接设计一个可以完成成人做的事情的系统转变成一种认识——即如果想要有一个灵活和强大的系统来完成成人做的事情，这个系统需要能够学习婴儿和孩子做事情的方式。」加州大学伯克利分校的发展心理学家 Alison Gopnik 说，「如果你将现在计算机可以完成的事情与 10 年前可以完成的事情相比较，它们已经取得了很大的进步，但是如果你将这些事情与一个 4 岁儿童可以做的事相比较，仍然有相当大的差距。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;婴儿和孩子使用一种和科学家用来构建科学理论的相同的方法来构建关于他们的周围的世界的理论。他们以一种系统的和实验性的努力来探索和测试他们周围的环境以及环境中的人，这对于学习至关重要。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Gopnik 最近和一组研究人员一起研究揭示了 15 个月大的孩子相比年龄更大的孩子是如何使用统计数据来更好地学习因果关系的。婴幼儿也许是更好的学习者，因为他们的大脑更加灵活或者「可塑性」更强 ；他们较少地被背景知识所影响，这也让他们有着更加开放的头脑。大脑并非是不变的，而是随着每一次学习的经验而改变。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过将发展心理学家和计算学家的专业知识相结合，人们可以揭示出世界上最好的学习型大脑是如何工作的，并且将其计算能力转化到机器的身上。最近，人工智能需要大量的数据来提取模式和结论，但那些对周围世界有相对较少数据的婴儿使用的是一种被称为贝叶斯学习（Bayesian learning）的统计评估方法（参阅机器之心文章《&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=401831226&amp;amp;idx=1&amp;amp;sn=daa0f6faa0e13a9e2c857d24d7784318&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=401831226&amp;amp;idx=1&amp;amp;sn=daa0f6faa0e13a9e2c857d24d7784318&amp;amp;scene=21#wechat_redirect"&gt;深度 | 大脑认知机制是贝叶斯式的吗？&lt;/a&gt;》）。也就是说，这种理解并非是基于一个结果的已知频率（婴儿所没有的信息），而是基于当前的知识推断出的事情发生的可能性，其随着新接收到的信息而连续调整。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「令人震惊的是，婴儿可以只看到一次或听到一个新单词的时候，他们就已经对这个新词的可能意思和可能的使用方法等有了一个很好的认识了；」Gopnik 说。「所以这些贝叶斯方法很好地解释了在没有充足数据的情况下，这些孩子为什么如此擅长于学习。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;婴儿们使用概率模型通过组合概率和可能性（probabilities and possibilities）来得出结论，从而创造出各种假设。随着大脑的成熟，它变得更加专业化以便执行复杂的功能，因此也变得不那么灵活，越来越难以随着时间而改变。年长的学习者发展出了有偏见的观点，因为他们更多地了解世界并且加强某些神经连接，这阻碍了他们基于很少的信息来形成具有创新性的假设和抽象理论的能力。这种能力使得 5 岁以下的婴儿和儿童茁壮成长。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「这种权衡关系就是，你知道的越多，你就越难以考虑新的可能性，」Gopnik 说。「你知道的越多，你就越依赖于你知道的东西，而对新的东西则不能保持一个开放的态度。从进化的角度来看，婴儿的整体情况就是他们不知道那么多，所以他们可以更好地学习新的东西。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在婴儿刚出生的几年，每一秒都有 700 个新神经连接生成，这是让一个灵活的大脑处理快速积累的来自环境和社交的信息所必需的部分。比起在成年时期重新组合大脑回路，生命早期的可塑性使得从零建立大脑的架构更加容易。贝叶斯学习已经被证明是儿童发展中的一个强大工具，计算机科学家正在使用该模型设计智能学习机。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;麻省理工学院大脑和认知科学系的教授、计算认识科学家 Joshua Tenenbaum 说：「贝叶斯算法正在试图捕捉婴儿的学习模式，」他正在与 Gopnik 合作进一步研究其计算机和心理学的混合领域。「当这些孩子进入了真实的世界时，就已经有准备好的基本的构建模块来让他们理解一些最复杂的概念。然后，他们有学习机制——即以这些最初的构建模块来尝试从稀疏数据推理，并创造因果理论。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人类的大脑，不管处在哪一个发展阶段，都是被设计通过一系列的感觉系统，包括视觉、听觉、嗅觉、味觉、触觉、空间取向和平衡从而进入物理世界。当一个人只有有限的数据时，大脑就会填补空白，这是一种被称为「退化（degeneracy）」的神经结构现象。尽管婴儿的大脑缺乏一个或多个感知，但是他们还是尤其擅长处理信息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Tenenbaum 说：「为了理解世界，孩子们会像科学家一样学习，这包括形成理论、进行试验、玩耍并且看看到他们可有所发现的东西，积极思考什么是正确的方法来测试他们的理论或者应对一些他们没有想到的东西，并试图找出什么是错，什么是对。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;采取孩子的措施&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Tenenbaum 和来自纽约大学和多伦多大学的研究人员团队合作设计了一种能够以更有效和更复杂的方式捕获新知识的人工智能软件。在 2015 年 12 月，他们的研究论文《Human-level concept learning through probabilistic program induction》指出用于创建计算机的机器学习算法接近我们所处理信息的方式；该论文已发表在 Science 杂志上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;新的人工智能程序可以在看到一个样本之后就像人类一样准确地识别手写字符。使用贝叶斯程式学习框架，软件能够为每个至少看到一次的手写字符生成一个独特的指令。但是，当机器面临一个不熟悉的特性的时候，这种算法的独特功能就发挥了作用。它从数据搜索转换到寻找匹配，使用概率程序并通过组合已经见过的字符的部分和子部分来创建一个新的字符以此检测其假设——即当婴儿面对他们从未见过的角色和对象时，他们如何从有限的数据中学习到丰富的概念。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然而，软件仍然无法通过形成原始假设自主学习方式模仿孩子学习的方式。当研究人员能够设计具有原始假设和真实的目标的软件时（例如产生识别字符的愿望而非遵循研究者的指令），人工智能系统的潜力将会有里程碑式的转变。没有自我驱动的目标，人工智能系统就限制了他们自主运作的潜力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Tenenbaum 说：「使用越来越多的数据进行的持续性学习是任何人工智能系统都想要做到的，但自主学习却是棘手的，因为总会有人来操控整件事情，数据的数量与类型也由他们给出。婴儿是自主选择的，但是要让人工智能系统能够更自主地构建自己学习过程仍旧是一个众所周知的挑战。目前的人工智能系统并没有建立任何目标，应此它们也无法为自己的学习负责。当一个机器人按指示拿起一个盒子时，看着它们做着和人类一样的事情是非常令人欣喜的，然而它们并不会拥有像孩子那样复杂的思维水平。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Tenenbaum 和他的同事采用了在神经元的虚拟网络上建模的深度学习算法。它建造了一个非常初步模仿人脑的工作方式。当机器处理一个对象时，它搜索其巨大的数据库来获取与机器匹配的像素以进行识别。而人类依赖于更高形式的认知功能来解释对象的内容。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我们正在试图编写像大脑的软件一样的计算机程序，这通常被称之为思维。思维是程序且运行于大脑这个硬件上，我们就是试图在对准软件层面。神经网络在人工智能中就像计算机程序的软件层面一样。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 2013 年，美国国家科学基金会拨款 2500 万美元资助了麻省理工学院一项为期五年的项目，用于建立脑、思维和机器中心。为了解大脑如何执行复杂计算，不同领域的科学家和工程师共同合作，希望构建更类似于人类智能的智能机器。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Tenenbaum 说：「近期我们才建立出一个能够做到这一点的数学与计算机模型，我们将需要更多的资源、人才、公司、技术和公司的利益以及更快的计算机。我们可能需要等待或依靠其他工程进展，然后才能赶上即使是非常幼小孩子的智力。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;构建第一个婴儿大脑&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;新西兰的奥克兰大学生物工程研究所正在试图通过一个动画制作的可互动的婴儿来弥合大脑和机器之间的差距。Mark Sagar 是该研究所动画技术实验室的导演和创始人，其动画作品《阿凡达》和《金刚》获多项奥斯卡奖。他在实验室和一个叫做 BabyX 的 3D 电脑屏幕上的金发碧眼宝宝玩躲猫猫，这个 BabyX 是一个能够学习、思考并可以产生面部表情，能够自己做出反应的实时系统。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过在麻省理工学院建立身体部位的医学模拟，Sagar 开始了他的职业生涯。在那里他致力于实现数字面孔，并使用这些技能开发 BabyX。动画人工智能能够模仿他的面部表情、朗读简单的字、识别对象和播放经典的视频游戏 Pong，这使它每天都变得更聪明。BabyX 不仅是 Sagar 的「大脑宝宝」，也是在他的女儿 Francesca 在不同年龄阶段的模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了构建 BabyX，Sagar 在他的女儿 6 个月、12 个月、18 个月和 24 个月时进行了扫描，并将数据上传到了系统中。他选择通过动画技术来复制他女儿的行为、面部表情和声音，作为人工智能初生的隐喻。Sagar 亲切地将 BabyX 称为「她」，并解释她如何使用光纤电缆：由她的模拟神经活动所驱动，如同脊髓连接到大脑。与之前的系统不同，由于 BabyX 是一个具有人工智能的交互式化身，故它具有学习和保留信息的能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我们不以大多数人所想的方式开发人工智能，」Sagar 说，「在神经科学和认知科学中存在许多有争议的理论，现有知识可能仅代表冰山一角。而最困难但也最深刻有趣的部分是：生物学启发的方法如何从不同规模过程的相互作用中出现更高的认知水平。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Sagar 和他的团队测试了 BabyX 与人类的互动。BabyX 能够处理人类的情绪、理解他们的行动背后的意义、并根据她过去与 Sagar 的互动中所学的东西做出回应。BabyX 的屏幕之后是一个大脑的实时模拟，使它能够提示面部模拟眨眼和观众报以微笑。Sagar 认为脸部是发展是有效交互式人工智能的关键，因为它是大脑的反映，并揭示了有意识思维的内在运作。例如，一个简单的微笑是脑内连接的复杂、交织系统运行的结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「BabyX 通过使用者的行为和宝宝的行为之间的关联来学习，」Sagar 说道，「在一种学习形式中，咿呀声会使 BabyX 探索她的运动空间、移动她的脸或手臂。如果使用者的响应类似，则表示 BabyX 的动作神经元开始通过称之为 Hebbian 学习的过程与响应使用者动作的神经元相联系，共同发挥作用的神经元会聚在一起。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在重复过程之后，新的神经连接开始在 BabyX 的模拟大脑中创建一个映射，将其动作与使用者的动作相匹配，为更高级的模仿打基础。人类大脑的工作方式大同小异——即通过完成一个动作，大脑形成新的连接并通过重复这个动作而加强。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最终，这个模拟的婴儿通过她大脑处理的环境信息来做出自己的反应。本质上，BabyX 通过不断改进代码进行学习。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;BabyX 的学习能力是基于生物学似乎可信的学习模型中，这种算法模拟和翻译人类大脑如何处理信息和释放大脑中的化学反应，例如多巴胺或催产素水平。当她不明白一个单词或动作时，BabyX 显示困惑的表情，但当她正确地读一个单词时，她会快乐地笑起来，并释放更高水平的「快乐激素」多巴胺。每个算法都控制神经系统从而令她能够模仿、建立反馈系统还有通过互动和演示学习新的信息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我想探索如何将基于生物学的行为、情绪和认知的计算模型集成到动画中，特别是面部，」Sagar 说道，「面部表情是人类经验许多方面的纽带。这对探索学习和心理发展的基础，甚至可能对我们未来与更复杂、自主技术的相互作用和使用都至关重要。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;由于面部是沟通的一个首要手段，Sagar 希望他的实验可以为未来的健康和教育应用奠定基础，例如旨在与自闭症或其它社交障碍疾病儿童患者进行互动的方案。一个可以感受到人的情绪、处理并了解他们的感受的系统是驱动人工智能研究的目标，这就像我们人生中最初的光阴一样——建立一个可以自己思考的大脑。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译文章，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Sun, 20 Nov 2016 11:17:41 +0800</pubDate>
    </item>
    <item>
      <title>技术 | 斯坦福大学副教授Reza Zadeh：神经网络越深就越难优化</title>
      <link>http://www.iwgc.cn/link/3579157</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自O'Reilly&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：武竞、吴攀、蒋思源&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;本文作者 Reza Zadeh 是斯坦福大学副教授及 Matroid 公司创始人兼 CEO。他的研究工作主要涉及机器学习、分布式计算和离散应用数学。他同时也是微软和 Databricks 的技术顾问委员会的成员。对于这篇文章，他总结说：「神经网络越深，往往就越难优化。」&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9YibFeykBDgdvOUNVxn0L44aVibqcbWobPqyhOicLFRpYpibh6S1n3ChhiawRFDUcfaJS9Qn8JpO4sIUg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Rastrigin 函数&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;优化是非常困难的一类问题，而这正是深度学习的核心。优化问题是如此困难，以至于在神经网络引入几十年后，深度神经网络的优化问题仍阻碍着它们的推广，并导致了其 20 世纪 90 年代到 21 世纪初的衰落。自那以后，我们解决了这个问题。在这篇文章中，我会探讨优化神经网络的「困难度（hardness）」，并发掘其背后的理论。简而言之：网络越深，优化问题就越难。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最简单的神经网络是单节点感知器，其优化问题是凸优化的。凸优化问题的好处是其所有的局部最小值也是全局最小值。现在有各种各样的优化算法来处理凸优化问题，且每隔几年就有更好用于凸优化理论的多项式时间算法（polynomial-time algorithms）出现。运用凸优化很容易得到单个神经元的优化权重（见下图）。从单个神经元开始，让我们看看会发生什么。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9YibFeykBDgdvOUNVxn0L44OXV1TB7eFu5IDrdDhWEC84ojcs3eyfJS9jQIHvvpfesLJZiaaOibpVsw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 1。左：凸函数。右：非凸函数。沿着函数表面，凸函数比非凸函数更容易找到表面的最小值。（来源： Reza Zadeh）&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下一步是保持单层网络下添加多个神经元。对于单层、n 节点的感知机神经网络，如果存在一组边权重使得网络可以正确地分类给定的训练集，则这样的权重可以通过线性规划用 n 的多项式时间找到，这也是凸优化的特殊例子。所以下个问题是：对于更深的多层神经网络，我们是否可以类似地使用这种多项式时间方法？不幸的是，我们无法保证。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;能够有效解决两层或多层的广义神经网络的优化问题并不容易，这些算法将会涉及计算机科学中的一些最棘手的开放性问题。因此，要想机器学习研究人员找到可靠的深度网络最佳优化算法可能性十分渺茫。因为该问题是 NP-hard（非确定性多项式困难 non-deterministic polynomial hard）的，也就意味着如果可以在多项式时间的计算复杂度中解决它，也将解决数十年来悬而未决的几千个开放性问题。事实上，1988 年 J.Stephen Judd 阐述的以下问题就是 NP-hard：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;给定一个广义神经网络和一组训练集样本，是否存在一组网络边权重（edge weight），使网络能够为所有的训练样本产生正确的输出结果？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Judd 还表明，即使只需要神经网络正确输出三分之二的训练样本，但还是 NP-hard 的，这意味着即使在最坏的情况下，训练一个不精确的神经网络在本质上也是困难的。1993 年，Blum 和 Rivest 证明了更坏的消息：即使训练一个只有两层和三个节点的简单神经网络也是 NP-hard！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;理论上，对比深度学习与机器学习中的许多更简单的模型（例如支持向量机和逻辑回归），这些模型可以在数学上保证优化能在多项式时间中执行。对于这些更简单的模型，我们能够保证优化算法在多项式时间内就会找到最佳模型。但是，对于深度神经网络的优化算法，并没有这样的保证。根据你的设置来看，你不知道你训练的深度神经网络是否是你可以找到的最好的模型。所以你也并不知道如果继续训练是否能得到更好的模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;幸运的是，实践中我们可以非常有效地解决这些「困难」结果：运用典型梯度下降（gradient descent）优化方法可以给出足够好的局部最小值，让我们在许多问题上取得了巨大进步，例如图像识别、语音识别和机器翻译。我们只是忽略困难的部分，在时间允许下尽可能多地运用梯度下降迭代。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;似乎最优化问题的传统理论结果是很笨拙的，我们很大程度上可以通过工程和数学技巧、启发式方法、增加更多的机器或使用新的硬件（如 GPU）来解决它们。有意思的是，仍有很多人研究为什么典型的优化算法如此有用，当然除了那些困难的部分。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;深度学习流行的原因远远不止是解决了优化问题。深度学习在许多机器学习任务中获得领先，它的网络的架构、训练的数据量、损失函数和正则化都起着关键作用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译文章，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Sun, 20 Nov 2016 11:17:41 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 特斯拉全自动驾驶第一视角体验：轻松应对十字路口和城市街道</title>
      <link>http://www.iwgc.cn/link/3579159</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自TechCrunch&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;日前，特斯拉曾透露正在研发一款全新的硬件，以满足他们未来实现完全自动驾驶汽车的需求；同时该公司还曾公布了一段工作中的原型软件的视频。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今天早些时候，特斯拉又发布了一段第一视角的自动驾驶体验视频，在视频中，特斯拉的自动驾驶汽车在完全没有人类干涉的情况下穿过了交通繁忙的城市街区和一些十字路口。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;iframe class="video_iframe" data-vidtype="2" style="   z-index:1; " height="375" width="500" frameborder="0" data-src="https://v.qq.com/iframe/preview.html?vid=y13111xxgof&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0" allowfullscreen=""&gt;&lt;/iframe&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;视频中我们可以看到驾驶座位上坐着一位工作人员，但他并没有进行任何操作（因为法律规范他必须坐在那里）——没有碰方向盘，也没有踩刹车或加油门。除了主画面的体验视角之外，画面右侧还显示了这辆特斯拉上面所安装的 3 个光学相机在驾驶过程中捕获的实时画面，其上的色块是汽车上的计算机所检测出的行人、汽车、道路标志等等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，工作人员下车，这辆特斯拉自动完成了泊车。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个 Autopilot 的完全自动驾驶版本看起来真是令人印象深刻。特斯拉 CEO Elon Musk 曾经说过要在明年进行一次穿越整个美国的无人驾驶测试，看起来似乎真的是很有可能如期完成目标了！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外，我就知道你要问这段视频的背景音乐是什么——滚石乐队的《Paint it Black》。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;扩展阅读：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719875&amp;amp;idx=2&amp;amp;sn=1d70df4cefc830ce8a40f322052ecc90&amp;amp;chksm=871b02fdb06c8beb61da80d688b37874e324c00ad0e953dca84747e842a841e7331db2239c9c&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719875&amp;amp;idx=2&amp;amp;sn=1d70df4cefc830ce8a40f322052ecc90&amp;amp;chksm=871b02fdb06c8beb61da80d688b37874e324c00ad0e953dca84747e842a841e7331db2239c9c&amp;amp;scene=21#wechat_redirect"&gt;Tesla 推出「完全自动驾驶」功能，这是彻底解放人类还是又一次「大跃进」？&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718688&amp;amp;idx=3&amp;amp;sn=45f0864bc58f08cf7fcb17c842e05d91&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718688&amp;amp;idx=3&amp;amp;sn=45f0864bc58f08cf7fcb17c842e05d91&amp;amp;scene=21#wechat_redirect"&gt;从特斯拉到计算机视觉之「图像语义分割」&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716988&amp;amp;idx=1&amp;amp;sn=65ad0b7c47c2b6c3f1b0b89e6fab1ff5&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716988&amp;amp;idx=1&amp;amp;sn=65ad0b7c47c2b6c3f1b0b89e6fab1ff5&amp;amp;scene=21#wechat_redirect"&gt;特斯拉巡航系统供应商Mobileye创始人详解自动驾驶三大支柱&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译文章，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Sun, 20 Nov 2016 11:17:41 +0800</pubDate>
    </item>
    <item>
      <title>独家 | MIT-CHIEF 2016年会回顾：站在自动驾驶与人工智能的风口</title>
      <link>http://www.iwgc.cn/link/3579161</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心原创&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;作者：&amp;nbsp;孙睿，张晨卉，李九喻&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2016 年 11 月 12-13 日，麻省理工学院中国创业与创新论坛（MIT-CHIEF）第六届年会在波士顿举行，旨在搭建中美商界与学界对话的平台，其中嘉宾包括：麻省理工学院斯隆管理学院副院长黄亚生教授，搜狐总裁张朝阳，斯坦福教授兼丹华资本创始人张首晟教授，MIT 机械系主任陈刚教授，真格基金兼新东方创始人王强，瑞银集团执行副总裁 Eric Gan 等。机器之心则带着对智能驾驶与人工智趋势的关注，参加了本次大会。两天的会议虽未对技术细节作出深入的讨论，但仍在技术的商业应用，市场推出，中美交流上提供了很强参考价值。提醒各位创新者仅掌握技术的局限性，创业——尤其是颠覆性创新——需要导航复杂的商业环境，面对甚至尚未形成的市场，从中平衡长短期利益。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Pannel／Plenary 亮点回顾&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不少嘉宾以自身科研成果或创业历程为切入点发表讲话，也有投资人从大趋势上分析人工智能等产业的走势。例如，创新工场的合伙人 Chris Evdemon 指出，人工智能将是继互联网先驱，产品经理，O2O 热潮后的下一个大趋势。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前，国内市场面临着资本过剩，人才缺失，大公司垄断等问题，亟需建立更明确的分期成果，吸引多方面人才，搭建长远目标，实际地考虑创业公司与大公司竞争的利弊与发展前景。Chris 认为，海外的技术人才出路很多，可以考虑为美国本地公司／美国本地公司的华人市场部／华人公司，或中国外资企业／中国公司／中国公司的海外部工作，几种选择各有利弊，不过介于这几年经济形势的变化以及国内的高速发展，中国境内的外资企业或已失去竞争优势。海外创业公司若打算开发国内市场，亦需要考虑「本土化」。从投资人的角度来看，这背后的多重顾虑与独特商机算是一把双刃剑。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW81aVM2Gdgrxfsa0vR4YVib22qLBbfqUiaqu6cOsvLb1iat5eaFopJbZ2ibxXdzHvk0RIVDQa3C0MxwPw/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW81aVM2Gdgrxfsa0vR4YVib27a0EPkOdZyhModTeQT3zkKBuLRYQ0flvh38sq95gI9bA7LA6qSaibHQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本篇文章将带您回顾：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;智能驾驶论坛（Autonomous Driving Panel）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;机器学习（Machine Learning Panel）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;张首晟演讲&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;张朝阳演讲&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;智能驾驶商业化中未知的风险与商机&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;智能驾驶&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2016 年是全球智能驾驶热度空前的一年。谷歌、福特、特斯拉、丰田、通用、百度、法拉第、Uber 等公司纷纷入局，以不同方式展开对智能驾驶的实验研究及产业落地。智能驾驶为汽车产业带来了发展的新机遇，但同时其在当下也面临着相关法律缺失、技术尚不完善以及消费接受度不高的现实挑战。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此次 MIT CHIEF 智能驾驶论坛（Autonomous Driving Panel）汇聚了来自智能驾驶产业生态圈各个环节的「代表」，阵容豪华：由普林斯顿大学教授转型投身产业的肖健雄第一位发言，现场展示了他近期创立并任 CEO 的 AutoX 公司的产品演示；来自麻省理工媒体实验室的 Iyad Rahwan 副教授，则分享了正在创建的「驾驶道德」（Moral Driving）网站－通过数据收集分析不同情境下的驾驶决策；技术驱动型创业公司图森互联的联合创始人兼 CTO 侯晓迪，介绍了图森互联及其基于计算机视觉和深度学习算法的公司策略和发展方向；最后来自云启创投的黄榆镔，代表了 VC 方对智能驾驶产业做出了点评。随后，在「麻省理工科技评论」（MIT Technology Review）杂志资深编辑 Will Knight 主持的座谈环节中，肖健雄、Iyad Rahwan、侯晓迪和黄榆镔对智能驾驶技术及产业现状展开了讨论，并分别从各自的专业角度分享了他们对智能驾驶的思考。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当谈及自动驾驶汽车的商用时，来自产业链不同环节的嘉宾们的发言见仁见智。研究「驾驶道德」的 Iyad Rahwan 关注更多的是自动驾驶汽车的安全性，他表示大众对于自动驾驶汽车是否接受很大程度取决于是否安全。云启创投的黄榆镔则认为资本的注入是自动驾驶汽车真正上路的先决条件。正在研发自动驾驶汽车产品的肖健雄提出，在兴建新城市的过程中为自动驾驶汽车设计专用车道，作为推进商用的解决办法；同为技术创业「代表」的侯晓迪则解释了图森互联的定位，他们认为自动驾驶可以细分为自动卡车和自动汽车两部分，两者区别很大，其中自动卡车会更加可控，也正是图森互联先下的研究方向。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;会后肖健雄与侯晓迪特别面对机器之心，对此次论坛发言进行了补充。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;肖健雄&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然 AutoX 仍处于「地下模式」，作为创始人的肖健雄并不吝于展露自己的雄心。在解释公司标语「Democratizing Autonomy」时，他表示推动自动化的普及是他们的使命，并自比微软希望自动化像计算机一样覆盖到社会的方方面面，其中自动驾驶只是他们目前专注的第一步，AutoX 的「X」代表着未知，也代表着一切。同时他也阐述了自己从学术界普林斯顿大学教授，投身到工业界创立 AutoX 的始末：「我认为这可以为社会带来更多的价值。实验室关注更多的是理论上的推导。在学术圈做研究产出论文的模式是必要的，但是相应每个项目规模很不会很大，缺少多人合作也很难系统化地解决问题。我觉得自动驾驶的研究到了这样一个阶段，需要多人合作长期系统地来攻克。创业是唯一的解决办法，也只有工业界才能够实现。」此外肖先生还表达了以技术为先的态度和对深度学习的关注，特别是如何将深度学习作为一种工具来使用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;侯晓迪&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;计算机视觉和认知科学领域专家侯晓迪先生也从图森互联 CTO 的身份出发，很详细地解释了他对于业界一些看法及图森现阶段的发展状态。与机器之心的对话如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Synced：自动驾驶汽车的发展阶段被学界分为五级，从部分自动化一直到完全自动化。您觉得图森的研究现在位于哪个级别？5 年内计划实现到哪个级别？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;侯晓迪：我觉得这个分级体系其实不够准确，其中一个原因就是，从它定义的第三级到第四级其实是一个很大的跳跃。在第三级，驾驶员虽然不操作，但是还需要观察路况，但是在第四级，驾驶员就可以完全不看路了。这中间其实跳过了很多东西。我们将我们的产品定位在「三加四减」的阶段，也就是说，卡车不需要随时有人看着，但是也不排除在一些非常规情况（比如轮胎故障），需要人介入进行调整。对于大部分公司来说，特别是创业公司，一下子达到五级都是不太可能的。我认为所有的技术都需要且行且看吧，没有一个技术能够在初期就满足所有人的所有幻想。作为一个创业公司，我们一定是先有商业上的需求，在可得资源和可等待的时间范围内实现一个技术上可行的产品。所以我们目前的计划是定在「三加」阶段。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;Synced：图森为什么选择自动化卡车作为第一个进入市场的产品？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;侯晓迪：第一个原因是成本和价格的问题。对于普通的消费者来说，目前自动化汽车改造的价格是很高的，因为本身我们的成本就很高，而大部分人也不会长时间频繁使用汽车；而对于产品生产者来说，卡车运输是不可或缺的一部分，在被大量使用的基础上，产品公司对价格的承受能力会更高。所以我们的第一步，是让自动驾驶汽车作为生产工具进入市场。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;Synced：自动卡车在市场接受程度上可能会遇到什么阻碍？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;侯晓迪：市场接受的程度主要还是取决于最终的产品形态，包括功能、价格、可靠性等等。如果一开始功能定的虚高，算法达不到，最后产品出来不是贵就是可靠性差，就肯定会在市场上碰一鼻子灰。其实有很多技术上无法绕过的难题，是完全可以通过功能设计来回避的。创业公司有一个优势就是，算法设计者和产品功能设计者的沟通成本很低，大家可以坐在一起，持续地沟通和妥协，来达成共识，最后迭代出来一个功能上有价值、价格上可接受、可靠性上足够在使用场景内让大家放心的东西。在风险控制上，我们最开始一定是需要自己承担相关的风险，这样大家的信任程度会更高一些。同时，只要我们的模拟测试能够将出错频率控制在极低的范围内，我认为这个产品就是可以被接受的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Synced：政府对自动卡车投入市场的态度是什么样的？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;侯晓迪：政府对这件事是非常支持的，因为现在的卡车运输其实存在很多问题，比如超载、危险驾驶、司机行为监管等等，要将这些管理好，要比管理几个自动卡车公司要复杂得多的，所以我们的产品其实也是在帮政府解决这些管理上的问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Synced：智能驾驶产业现在话题度热度居高不下，您对产业现状怎么看？是否存在泡沫呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;侯晓迪：泡沫是肯定存在的，因为市场包括投资人很难鉴别技术创业者是否真正具有算法研究能力。我们也见识过一些技术领域的「李鬼」，这些人其实是在消费整个 AI 创业圈的公信力。但是无论怎样，想要实车上路，哪怕只是在开放环境下跑几公里，稍微拐个弯避个障，就已经不是纯靠嘴皮子就能吹出来的了。何况是关乎人命的产品，所以整体来说大家对于风险管控意识很强。而且确实存在不少比无人车泡沫更大的领域。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Synced：中国现在有接近 1600 万长途卡车司机。随着自动驾驶系统的应用，卡车司机群体失业是不可避免的结果，对此您怎么看？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;侯晓迪：一方面，新的职业一定会出现，社会会提供给这些人新的就业机会，比如说，自动汽车不需要人来驾驶了，这些人就可以借着物流成本降低的东风来做生意；另一方面，现代社会学习新知识、新技术的门槛越来越低，这些人群完全有可能成为技术工人甚至程序员。最后，自动驾驶系统的换代升级肯定不会是一夜之间完成的事情，市场的转变会是以年为单位的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Synced：图森在大量使用 labelled data，那么也就意味着还是需要人对数据进行解读，之后进行 supervised learning。这样对于历史数据无法覆盖的危险情况，我们如何保证安全？图森是否在进行 supervised learning 之外的尝试？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;侯晓迪：所有的测试数据肯定都是「历史训练数据」无法涵盖的。如何增强模型的泛化能力是机器学习一直以来最核心的问题。近年来深度学习大行其道，确实存在一些急于求成的创业者，一知半解的情况下就拿深度学习说话，给社会一种不靠谱的感觉。但是我们对于纯深度学习的局限性一直很清醒，并且在 end-to-end learning 之外做了很多尝试。比如，我们一直很强调传统的 Bayesian statistics 和深度学习并重的视角来看问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器学习试水商业应用，「曾经训练出来的数据集，可能根本没用。&lt;span&gt;」&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器学习&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW81aVM2Gdgrxfsa0vR4YVib2hOibdqwVbanf0kPpZu18PUQUkruy33tIa3MmicSHbA9ddqtVpTQDjZEA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从年初的围棋大战开始，「机器学习」就注定将成为 2016 年最受关注的话题之一。与此同时，机器学习也从实验室走出来，作为一种更强大的数据分析工具，被快速应用在许多公司的商业决策上。在此次 MIT CHIEF 机器学习论坛（Machine Learning Panel）中，嘉宾们都给出了自己对这一波商业浪潮的独到见解。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;微软 Azure 机器学习工作室的高级数据科学家 Wu Tao 首先点出了应用机器学习工具这一趋势的动因：数据的快速增长、计算能力的大幅提升、以及应用门槛的大幅降低。同时，他认为在这一大环境下，小型的公司反而能有更大的优势，因为大公司整合新技术的过程更加烦琐，一定程度上影响商业效率。数据分析解决方案提供者 Tamr 公司的 CEO，Andy Palmer，也分享了他创立 Tamr 的经历和心得，并强调了机器学习工具对商业决策的重要性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;来自麻省理工大学信息与决策系统实验室（LIDS）的高级研究员 Kalyan Veeramachaneni 认为，目前，机器学习预测模型的商业应用，仍有很大的进步空间，因为目前的落地时间慢、行政冗余长。在技术方面，大部分学术上的研究模型都没有在真实的环境下训练过，导致其实际价值非常有限。在会谈过程中，他向台下的观众问道：「在座有多少人训练过数据集？」台下约几十人举手。他随后追问道：「谁训练的模型最终被上线使用？」只有寥寥无几的人响应。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于提供数据分析服务的初创企业，论坛的建议是：专精于某一个领域，能够帮助公司更快找到客户群。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;结束后，Kalyan Veeramachaneni 特别面对机器之心，对此次论坛发言进行了补充。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW81aVM2Gdgrxfsa0vR4YVib2cALqGerSsSk4OyvmEYLS8wqgYOwKjRLxic0mDZiagjia8a73cxicez8JhA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Kalyan Veeramachaneni&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Synced：与大部分学术研究不同，您的许多研究项目都更加实际、偏重应用，比如您 2015 年对 MOOC 网站退课率的预测模型研究。是什么让您选择了这些课题？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Kalyan：我一直认为，学术界的许多研究灵感都是来源于商业：当旧的技术不能满足市场的时候，学术界就能够把握机会创造新的技术，计算机视觉、机器学习等都是这样的例子。同时，我也觉得，拥有应用价值的研究项目才是更有意义的项目。虽然学术界一直不太强调研究的实际应用，但我觉得这是有价值的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Synced：您觉得学术研究与商业应用存在脱节的现象吗，对此您有什么看法？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Kalyan：我确实认为存在一定程度的脱节，而这种脱节是可以缩小的。比如在麻省理工学院，学术圈与商业的交流非常频繁，我们能够很快地了解到商业企业的最近进展和技术需求，研究成果也能快速地投入商业中使用。所以，第三方机构，比如大学，在缩小这以差距上扮演了很重要的角色。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;张首晟——物理学家人工智能风投，当斯坦福与硅谷遇上中国&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;张首晟&amp;nbsp;&lt;/span&gt;&lt;span&gt;(斯坦福大学教授，丹华资本创始人)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW81aVM2Gdgrxfsa0vR4YVib28TtySOfu0d9rNrhzLicNXWQLtrpKo5IFNOARQJ0taEWv6qX4csfEJiag/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;张首晟教授在演说中提到硅谷的发源地，回溯在新泽西的贝尔实验室，肖克莱博士、巴丁博士和布菜顿博士发现晶体管，并借由此发现荣获诺贝尔奖的这段历史。他指出，信息技术依赖于摩尔定律的效应，如果摩尔定律停止应验，将无法继续发展。张教授与他的团队在量子自旋霍尔 (Quantum spin Hall effect) 与拓扑绝缘体 (Topological Insulators) 的研究上对芯片的升级有着重大贡献。在「量子自旋霍尔效应」下，芯片中的电子可以像高速公路的汽车一样正反流动，将「信息高速公路」拓建到芯片层次。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不过，张首晟此次主要以投资人亮相。他于 2013 年成立丹华资本，「丹」取之于斯坦福的音译，「华」取之于中华，试图搭建硅谷，斯坦福大学，与中国之间的技术创新桥梁。在讲到自己作为著名物理学家和新进投资人之间的身份转变时，张教授认为两者之间并无太大区别。像特斯拉 CEO 埃隆·马斯克，张教授也提到要从物理的「第一原理」开始思维，认清事物与事物之间的本质联系，强调理工思维在商业投资里起到的重要作用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;演说后，张教授对机器之心阐述了更多关于人工智能的看法和投资理念。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Synced：您的丹华投资在硅谷投了非常多的人工智能公司，是什么样的契机让您开始关注这一领域呢？&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;张首晟：人工智能是一个必然的趋势，这个趋势有三个重要的模块：优良的算法，大量的数据，还有我今天在演讲时提到的「摩尔定律」——计算能力势必以指数增长。人工智能是在 50，60 年代提出的概念，不过把以上三个模块整合在一起是近期才做到的。在这个意义下下，我们处于一个非常激动人心的时代，它会改变人类生活的每个角落。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Synced: 能讲讲您在硅谷投的公司吗？它们分别有什么样的特点？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;张首晟：我先讲我们投的人工智能公司吧。人工智能有两个，一个是做平台性的，比如像 DeepMind，MetaMind 等，像我们去年看到 AlphaGo 的成功。另外人工智能会改变垂直领域，在这个意义下，它能带来更多的机会。平台性的，大公司可能已经掌握了技术，它也有大量的数据和计算能力。但是有的时候在无人机上或者自动驾驶汽车上，你不可能用到云端的计算能力。该如何在局限的情况下把人工智能做好？我们投的一家公司叫 pilot.ai，它就找到了类似的初创公司生存空间。另外我们投的一家公司叫 Trustlook，它使用人工智能来识别安卓手机系统里的病毒。在以前，这是人工来做得事情，现在都会慢慢被机器取代。另外一个很大的领域是医药，比如说 radiology 的图片和 pathology 的图片，我们都可以用机器读取，机器在很多时候比人工更精准。相比较于人，机器大脑可以不休息地运作，一旦有了足够的训练集，我们就能够把它教得越来越成功。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Synced: 您如何看待国内的人工智能创业公司？这些公司的机遇与相对优势又在哪里？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;张首晟：国内真正原创的公司还是不够多，不过我相信在某些垂直的领域，技术虽然不一定是全球领先，但是它已经是有一定领先的应用，这样的话也是有竞争空间。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;张朝阳——立志返回互联网舞台中心的搜狐，在人工智能时代何去何从？&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;张朝阳&amp;nbsp;&lt;/span&gt;&lt;span&gt;(搜狐总裁，创始人兼 CEO)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW81aVM2Gdgrxfsa0vR4YVib2z4MekjY53t2W1EQXxbRicwk1XiaZz90saw7cN2BOcFvXL0F4z81qIRCQ/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;搜狐总裁张朝阳是此次 MIT-CHIEF 的最后一个嘉宾。面对 MIT 的观众，他轻松说起多年前的创业经历——从 MIT 毕业后的少年成功——其中不乏对搜狐倚重宣传，错失开发产品良机等历程的一些反思。作为总结语，张朝阳表示将尽力在未来几年将搜狐带回互联网中心，从内容娱乐，语音搜索等切入口更新整个平台。这位互联网界的大佬对机器之心给出了关于创新接地气的看法，其中包括人工智能在搜索，新闻，娱乐等方面的应用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Synced: 今年上半年，搜狗投资了 1.8 亿与清华联合成立了天工只能计算研究院，双方基于「清华搜狗搜搜索技术联合实验室」的研究向人工智能领域的前沿技术深入拓展。那么搜狐是否有计划进行全线业务的人工智能化呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;张朝阳: 这是一个持续一直在发展的事情。我们一直在投资人工智能，主要集中在搜狗方面。人工智能在新闻方面的应用据我所知，用机器学习的算法，深度学习的构架来处理编辑好的文章特征。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Synced: 那会不会有搜狐员工被自动化掉的危险？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;张朝阳：没有，因为将需要更多的人来写更好的软件。其实不是说会减少人，而是说工种变了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Synced: 那么编辑部的员工还安全吗？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;张朝阳：编辑部现在基本上是越来越少了，现在很多是公众号的东西写好，再由机器来筛选。打头阵的编辑部的团队需要更精炼地提选内容。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心原创文章，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Sun, 20 Nov 2016 11:17:41 +0800</pubDate>
    </item>
    <item>
      <title>C Talk | Face++产品体验：能不能借钱，机器说了算</title>
      <link>http://www.iwgc.cn/link/3579163</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;C Talk 专栏&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;公司：用钱宝&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;从最初作为学界内的研究，到企业战略部署的科技领域，再一点一点的实现商业化，人工智能已经离我们越来越近。业内众多创业公司的产品也得到了越来越多的客户的认可。为了从产品层次了解业内的众多公司，机器之心推出了 C Talk 专栏（客户说），让客户介绍如何用人工智能技术提升自己的效率，评价自己所用的人工智能产品。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;本文为该系列专栏的第一篇，&lt;span&gt;用钱宝的 CTO 齐鹏对 Face++人脸活体检测的感知。&lt;strong&gt;欢迎已经使用人工智能产品的用户向我们投稿，介绍经验和体验，邮箱：editor@almosthuman.cn&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;用钱宝目前已在年轻白领和蓝领中被熟知，它是为消费缺乏计划性、短期内需要小额资金周转的年轻人而设计的一款生活服务类的 APP。用钱宝使用以人工智能为核心的风控系统，所以用户填写信息、提交申请都在手机上搞定，风控评估到放款则都是由机器完成。对于用户来说，这意味着可以随时随地使用用钱宝，且方便快捷。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;据小编了解，用钱宝上线 16 个月的时间，就已经可以实现单月放款笔数超过 55 万笔。在这么短的时间内获得迅猛稳健的成长，不仅因为用钱宝极强的市场洞察力和贴心的产品设计，更因为它是一家以「技术基因」而闻名的公司——核心团队均是技术出身，CEO 焦可和 CTO 齐鹏都来自于百度，所以我们发现整个技术团队中相当于 T6 级别（技术总监或创业公司技术合伙人级别）的技术大拿就有十多个。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;那么这套以人工智能为核心的风控，是如何服务这些缺失银行数据的年轻人呢？小编采访了用钱宝的 CTO 齐鹏之后，才恍然大悟。传统银行对于人群的风险评估系统是建立在被称为「强特征」的基础上，比如有无房产、工资流水、社保征信等；然而年轻人大多却只拥有移动互联网时代下产生的海量「弱特征」。通过对于「弱特征」的挖掘、评估和使用，用钱宝建立了独有的专业风控体系，尽可能为更多的年轻人提供服务。Face++的人脸活体监测，就在这套风控体系中验真的环节，扮演了重要角色。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这套新型风控系统究竟如何运作，让我们来听听 CTO 齐鹏怎么说。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;齐鹏部分采访实录：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 用钱宝是针对都市白领跟蓝领的一款小额个贷的产品，可否透露都在使用哪些弱特征来做风控体系？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;传统金融是通过用户的还款能力来进行判断，这个比较容易理解。但是我们则是针对还款意愿来进行判断，因为理论上来说，只存在用户是不是有意愿进行偿还。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以，我们通过柯南特征工程、D-AI 机器学习模型以及 Anubis 大数据计算架构等人工智能技术，从海量弱特征中提取 500+有效特征，对用户进行建模，并借助快速积累的用户还款样本来进行系统优化，从而保证较高的通过率和较低的逾期率。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 怎么看媒体的评价，「用科技做智慧的金融」？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们的公司叫智融时代，从创立初期就一直秉持「让每个人享受智慧的金融」这一宗旨。「每个人」就是我们所服务的对象是银行所不能覆盖的人群，而智慧的金融就是我们以人工智能为核心的新金融技术。我们深信只有通过新金融技术，才能在未来的某一天，实现让每个人享受金融的魅力这一美好目标。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3. 所以，拥有科技团队的公司喜欢启用同类型的公司，face++的刷脸认证？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们使用 face++是基于两方面的考虑，一个是验真，一个是提升审核效率。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先我们要保证贷款个人是本人来申请，不是别人来冒名顶替，我们发现人脸核对身份是比较好的方式，另外人来核查跟机器相比还是慢很多，「face++的稳定性好，识别准确度高，使用很流畅，服务能力还不错」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4. 目前用户增长量？续贷率如何？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;增长量很快，从上线第一个月的 93 单到 10 月份增长到 55 万单，呈现指数级的发展态势。传统金融需求属于低频、决策时间长、流程久，而我们则是中高频需求，并且整个决策过程和业务流程都比较高效。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;5、1.56 亿元融资后的战略布局是？将围绕着「人工智能」为核心研发更多的新金融技术？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们会一直坚持两件事情，一个是让「每个人」享受金融服务的魅力，这说明我们服务的人群会一直不变；另一个则是智慧的金融，也就是新金融技术。在这样的基础上，我们可能会设计更多的产品线，来实现这一目标。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;C Talk：机器之心推出的文章系列，让客户介绍如何用人工智能技术提升自己的效率，评价自己所用的人工智能产品。&lt;strong&gt;欢迎已经使用人工智能产品的用户向我们投稿，介绍经验和体验，邮箱：editor@almosthuman.cn&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心C Talk系列文章，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Sun, 20 Nov 2016 11:17:41 +0800</pubDate>
    </item>
    <item>
      <title>重磅 | 世界首个光子神经网络诞生：比传统方法快1960倍</title>
      <link>http://www.iwgc.cn/link/3568914</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自arXiv.org&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;日前，来自普林斯顿大学的 Alexander N. Tait 等科学家在 arXiv 上发表了一篇题为《神经形态硅光子学（Neuromorphic Silicon Photonics）》的论文，介绍了世界上首个「光子神经网络（Photonic Neural Network）」。点击阅读原文可下载此论文。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以机器学习神经网络为代表的人工智能技术正在改变我们生活的许多方面，对支撑这些技术所需的数据处理能力的需求也越来越强。而针对神经网络的结构开发出神经形态芯片（neuromorphic chip）有望能大幅提升神经网络的性能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;日前，来自普林斯顿大学的 Alexander N. Tait 等科学家在 arXiv 上发表了一篇题为《神经形态硅光子学（Neuromorphic Silicon Photonics）》的论文，介绍了世界上首个「光子神经网络（Photonic Neural Network）」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;和我们目前主流的基于电子的处理方式相比，光子的方式的速度可以达到更快、也能实现更高的带宽。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;据 MIT Technology Review 的报道介绍，开发光子神经网络这个难题的核心是生产一种每个节点都有相同的响应特征的装置以用作神经元。这些节点采用了微型的环形波导（tiny circular waveguides）的形式，这些波导被蚀刻在硅衬底中，光可以在其中循环。当释放这个光并调制在阈值处工作的一个激光的输出时，该环境中输入光的一点微小的改变就会给该激光的输出带来巨大的影响。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其中的关键在于，该系统中的每个节点都工作在一定的光波长长——这是一种被称为波分复用（wave division multiplexing）的技术。在来自各个节点的光被送入该激光之前会被总功率检测求和。然后该激光输出会被反馈回节点以创造出一个带有非线性特征的反馈回路。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;那么这种非线性能在多大程度上模拟神经行为呢。研究表明其输出在数学上等效于一种被称为连续时间循环神经网络（continuous-time recurrent neural network）的输出。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些研究者为进行概念验证开发了一个 49 节点的硅光子神经网络——实验表明在一个实验性的差分系统仿真任务中比传统方法快了 1960 倍！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当然，验证性的实验不一定能够适用于实际的应用场景，但毫无疑问，这一研究为基于光子的神经网络的发展提供了重要的推动力。在带宽和速度需求日渐高涨的今天，这有望能为我们提供一种我们所需的解决方案。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;论文：神经形态硅光子学（Neuromorphic Silicon Photonics）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW81aVM2Gdgrxfsa0vR4YVib2oHGXtMueBWJRd0aIL6Ql79jc7sOibaWCAdGicsvZ0z8eTrG1lo7OZNMA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们报告首次观察到了集成模拟光子网络（integrated analog photonic network），其中的连接（connection）是通过 microring weight banks 和首次被用作光子神经元（photonic neurons）的电光调制器（electro-optic modulators）配置而成。这种硅光子电路和连续神经模型之间的数学同构（mathematical isomorphism）通过动态分叉分析（dynamical bifurcation analysis）而得到了证明。已有的神经工程工具可以利用这种同构性来适应硅光子信息处理系统。我们使用一种「神经编译器（neural compiler）」编程了一个的 49 节点的硅光子神经网络，它模拟了传统的神经网络，并且预计其表现在一个实验性的差分系统仿真任务中超过了传统方法 1960 倍。利用了硅光子平台的光子神经网络可以接入用于无线电、控制和科学计算的超快信息处理环境。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW81aVM2Gdgrxfsa0vR4YVib23nicicxz6UtbDfjEmKthoNVBPYaFFkI2WlnexOxFmppQCic9FSI7zMjhA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 1：带有用作神经元的调制器的 STAR broadcast-and-weight network。MRR: microring resonator, BPD: balanced photodiode, LD: laser diode, MZM: 马赫-曾德尔调制器 (Mach-Zehnder modulator), WDM: 波分复用器（wavelength-division multiplexer）。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW81aVM2Gdgrxfsa0vR4YVib2IqJRPVMib08b6ToIWLew9uSicvngjcbR4UTCiaia0DvRRTNiaMqHolcd4JA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 2：带有 2 个 MZM 神经元和一个外部输入的实验配置，阵列波导光栅（AWG）中进行波长复用，并耦合到一个片上 broadcastand-weight network。这个 2×2 的循环网络是由 MRR 权重配置的，w11，w12 等等。神经元状态由低通滤波跨阻抗放大器（low-pass filtered transimpedance amplifiers）的电压 s1 和 s2 表示。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译文章，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Sat, 19 Nov 2016 11:34:50 +0800</pubDate>
    </item>
    <item>
      <title>深度 | 逐层剖析，谷歌机器翻译突破背后的神经网络架构是怎样的？</title>
      <link>http://www.iwgc.cn/link/3568915</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自SMERITY&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谷歌神经机器翻译（GNMT）论文《Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation》描述了一种将深度学习融入产品的有趣方法。该论文和架构是不标准的，在很多情况下偏离学术论文中的架构。通过典型但计算密集型的调整，谷歌这个系统的重点是保证系统的实用性而并非追求顶尖结果。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;架构&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了理解 GNMT 中使用的模型，我们将从传统的编码器-解码器机器翻译模型开始，持续变化该模型直到匹配 GNMT 中的模型。看起来，GNMT 进化的东西是改进准确率，同时维持实际产品化时的训练与预测速度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;V1：编码器-解码器&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;编码器-解码器架构开始了近期的神经机器翻译趋势，出现于数年前。如同名字中的含义，该架构包含两个组件：一个解码器和一个编码器。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一个词级的编码器-解码器机器翻译系统，如同下面所描述的：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;采用一个循环神经网络，通常是 LSTM 来编码用语言 A（英语）写出的语句。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;该 RNN 吐出一个隐态（hidden state），我们称之为 S。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;该隐态有希望表征前面编码出的语句的所有内容。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;然后 S 被应用到解码器，一个单词一个单词的生成 B 语言（德语）句子。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW81aVM2Gdgrxfsa0vR4YVib2wCIHNabCic1Hr144r4PAuSDMLNMHGgWz12GtibYdgF1jTvHtuniauHYSw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;编码器-解码器展示了基于神经的机器翻译可能提供的潜力。即使有了如今复杂的神经机器翻译架构，大部分还是根据解码器-编码器架构分解出的产物。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该架构有两个主要的缺点，都和长度有关。第一个，像人类一样，该架构记忆有限。LSTM 最后的隐态，也就是 S，要死记硬背需要翻译的句子的全部内容。S 通常只有数百个 unit（读取：浮点数），你越是尝试挤入固定维数向量，该神经网络也被迫有更多损失。可以将神经网络的这个过程看作是一种有损压缩，有时候这是很有用的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第二，根据经验法则，神经网络越深，越难以训练。对循环神经网络而言，序列越长，神经网络随着时间维度越深。这造成了梯度的消失，也就是随着反向传输，循环神经网络学到的目标的梯度信号会消失。即使 RNN 是专门用来帮助防止梯度消失的，比如 LSTM，这仍然是个根本性的问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW81aVM2Gdgrxfsa0vR4YVib2tARonBxE8fnibMhvcrk1L6wIBReEbpBmXTnpp9S6MmvNAaQgbnTiaKyQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图：来自 Bahdanau 等人的论文 "Neural Machine Translation by Jointly Learning to Align and Translate" (2014)，展示了在翻译得分（评分形式为 BLEU 得分）随着语句变长后的影响。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然它在短句上有效，但当句子变得更长时就开始失效了。记忆问题的一种解决方案是增加 LSTM 隐态的大小。不幸的是，如果我们这么做训练速度也变得不够现实了。随着增加 LSTM 的隐藏大小，参数的数量也次方数的增加。你会耗尽 GPU 的存储或训练时间过长。这种方法也无法解决梯度消失问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;V2：基于注意力的编码解码器&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们如何解决上面那些问题？或许会尝试一个人类天生会使用的技能——反复关注源句的相关部分。如果你在翻译一条长句子，你可能会回头看一看源句，确定你捕捉到了所有细节信息。我们能让神经网络也做到这些。我们可以通过存储和指定 LSTM 之前的输出来增加神经网络的存储，同时不用改变 LSTM 的操作。此外如果我们知道对句子的某个特定部分感兴趣，那么注意力机制就会做一个「shortcut」，因此我们就能提供出一个无需遍历大量时间步的监督信号，而遍历时间步会导致梯度消失。这就类似于一个人在读完指环王所有的书后可能会回答的一个问题。如果我想问一个关于这本书开头的特定问题，比如夏尔袋底洞（Bag End），这个人就知道在这部系列小说的第一本中的哪一一页能找到答案。系列小说的长度不会影响你查找答案的能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW81aVM2Gdgrxfsa0vR4YVib2OppsZdcu4PCf4hvVtJic9KjWgud9ZSQJlFPNPsDYWDOtFTUjYAzUCPQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;简单来说（由于注意力机制已经很好地覆盖到其他地方）这个想法就是，一旦你有了从存储的编码器获取的 LSTM 输出，你就可以通过问询它们是如何与解码器端的电流计算相关的来查询每一条输出。编码器的每一条输出后面都会获得一个相关性得分，我们可以将这个相关性得分转换成一个概率分布，再通过 softmax 激活来归一。然后我们可以提取一个语境向量（context vector），这是一个编码器输出的加权求和，其结果取决于我们认为它们是如何相关的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;注意力机制的一个缺点是我们现在必须为每一个解码器的输出执行所有经过编码的源句的计算。虽然这有利于句子之间的翻译，但可能给长输出带来问题。在计算术语中，如果你的源句与 NN 的长度相当，同时你的目标句与 MM 的长度相当，我们就可以将编码器-解码器架构中的 O(M)O(M) 的解码器带入注意力架构中的 O(MN) O(MN) 中。虽然不是最好的方法，但至少在这个任务上，注意力机制优点远远大于缺点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;注：你或许会注意到编码器和解码器（之前架构中的 S）之间的直接连接已经消失了。虽然很多标准的编码器-解码器结构维持了这个直接连接，但是 GNMT 架构会消除这个连接。GNMT 架构会以信息能从编码器端转移到解码器端的方式来形成注意机制。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW81aVM2Gdgrxfsa0vR4YVib2P6q80G9EvAqFBYWib6LtQiahiaJMWoPMelvyIJbeW9HDXR5nfoklV93IQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图：Bahdanau 等人的论文「Neural Machine Translation by Jointly Learning to Align and Translate"(2014) 中的图像。显示了使用注意力对翻译成绩的影响（以 BLEU 得分的形式）。RNN 搜索是带有注意力的架构，后面的数字指的是训练样本的长度。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;V3：双向编码器层（BI-DIRECTIONAL ENCODER LAYER）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然注意力机制允许根据解码上下文检索句子的不同部分，但还是有一个问题。注意机制基本上会问这个编码器的存储输出「你是不是跟这个相关？」并用答案来决定提取什么样的信息。如果编码器输出自己没有充分的语境，它们就不太可能给出一个好答案。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;加上后面的单词的相关信息，例如编码器输出由左右两边的词决定，显然是有益的。如果有一个完整的句子可用，人类几乎肯定会用完整的语境来决定一个词的意思和语境。那为什么我们要强迫计算机不去使用所有的信息呢？而且这对它们真的是一个障碍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW81aVM2Gdgrxfsa0vR4YVib2UpIe20Ect8iaDA9qaKdkM4eP05DMwCichHV0AXehMrhVH9LDgr3o0dew/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;加上这个双向性的最简单的方法是运行两个 RNN，一个在句子中前进，一个在句子中后退。然后，对每一个词，我们连接（concatenate）或者添加所产生的向量输出，从两边产生一个带有语境的向量。在你翻译一种有不同排序（例如从左向右）的语言时（例如无论用另外一种语言翻译这个语言，还是把这个语言翻译成另一种语言），双向的编码器就会变得更重要。GNMT 架构连接（concatenate）它们，潜在的优势是向前和向后的 RNN 的结果只有一半大小。由于双向层最终会成为 GNMT 中的一个瓶颈，同时 RNN 中的参数数量也会几何增长，所以这不是一个不重要的节省。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;V4：「为深度学习增加深度」&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于许多神经机器翻译的架构而言，增加深度是精确模型中的关键组成部分。GNMT 架构也通过添加大量的层来增加模型的精度——研究者们使用了 8 层编码器与 8 层解码器的 16 层结构，令目前大多数最好的机器翻译系统望尘莫及。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;在编码器中，谷歌的模型具有一个双向的 RNN 层，随后是七个单向的 RNN 层。解码器则是八个单向 RNN 层。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在大多数文章的翻译中，全部层都是双向的可以增加准确性。具有全部双向层的模型可以获得相同或更好的结果，谷歌并没有这么做，我们将在下一部分解释 GNMT 这么做的理由。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW81aVM2Gdgrxfsa0vR4YVib2U8XMnUWnDhaYs8NsfB5c14ng9wHe1CFWuOPiaMIwwicQ8SWBD36d1sow/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;循环神经网络在训练中有很多不确定性。事实上，这种深度的标准神经网络需要进行大量的训练，和其他类型的系统不同，它相对简单，不会出现许多时间步。我们会在未来的尝试解决这个问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;V5：并行&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;GNMT 构架最主要的动力就是它的实用性。这个令其在和标准编码器（解码器架构 decoder architectures）相比较的时候显得有些局限和奇怪。为了将像 GNMT 那样的系统转化为产品，并行化就是必要的了。它不仅仅训练地更快、允许更多的试验，同时也让产品部署得更快。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们现在看到的这幅图表不仅仅是机器翻译模型的构架，它更是个相关图（dependency graph）。在一个结点开始计算，所有接近你的结点都需要是已经计算过了的。即使你有无限的计算量，但仍然需要符合相关图表流。同样的，你想最小化相关性就可能相比于相似层级需要更多的计算量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW81aVM2Gdgrxfsa0vR4YVib2Zq2n8g1YS2zRezpttcKwicXnlpB45tHouic19zTb9xbRrWb2STLnwUVw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;注：无遮盖结点（Unshaded nodes）还没有完成的时候，白遮盖节点（nodes shaded white）已经完成了它的计算。蓝遮盖层（Layers shaded blue）也处于计算的过程或已经完成了计算。这也就是为什么只使用了单一双向的循环神经网络（RNN）。双向层是两个循环神经网络组成的，一个从左至右另一个从右至左。这意味着计算第一个输出需要等待从右边到你现在位置共 N 个计算量（N 是序列的长度）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果层级是双向的，全部这一层就会在任何后面的相关性层开始计算前完成计算。但是如果使用的是单向层级，我们的计算就能有够多的灵活性与并行性。在上面的例子中，仅仅关注编码部分，最前面的四层网络全都是同时计算结点。这是上层神经网络不依赖于所有下层网络节点唯一可能性，只要是直属下层的。如果是双向神经网络，那就不可能了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW81aVM2Gdgrxfsa0vR4YVib25rcl2a2yTxzYYpmbh10kXFWibQzcmB6YnQzTqhgKfcUQkAwiaada0bwg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;并行（解码器侧）&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：由于使用解码器侧的所有输出的注意机制，解码器侧必须等待，直到所有编码器完成处理。但在编码器完成时，解码器能以和编码器侧相同的并行方式执行任务。通常，注意机制将使用解码器的最顶部输出来查询注意机制，但 GNMT 架构使用最低的解码器层来查询注意机制以最小化依赖图，并且允许最大并行化。在上面的例子中，如果我们使用最高的解码器层作为注意（attention），我们将无法开始计算解码器的第二输出，因为解码器的第一个输出仍在进行中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;旁注（强制教育和训练对生产）&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：在训练期间，我们已经知道英语句子需要翻译成什么。这允许我们具有比在预测时更高的并行性水平。由于我们已经有了所有正确的词（在右下角的「已知」翻译），我们可以强迫系统使用它。强制教育是你给神经网络下一个词的正确答案，即使它实际上已经预测出错误的词。这种方式是有效的，训练将继续迫使神经网络输出正确的词，系统最终会输出正确的结果。这种方式允许你在计算第一个输出字的过程中「作弊」并计算第二个输出字。在原有情况下，我们需要等待系统逐词输出，而且不能加入「已知」的翻译。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;旁注（多 GPU）&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：这种并行化只有在多 GPU 情况下才有效率。在 GNMT 论文中，他们的图示实际上是根据 GPU 的数量来标记每个图层的。对于编码器和解码器而言，谷歌的方法使用了八个 GPU——每层一个。它对单 GPU 有没有意义？通常，在计算给定图层时，GPU 应该达到高利用率（假设你能够设置合理的批量大小，网络大小和序列长度）。这项工作有关重新排序的依赖性，重新排序允许立即进行更多的计算，允许更好地利用更多的设备。在 GPU 情况下，并行计算并不会提高效率，而在多 GPU 的情况下，这种重新排序能够显著加快速度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;V6：残差是新的热点&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;八层神经网络至少对循环神经网络已经是很深了，从一般经验法则来看，除了一些异常情况或特定结构外，更深的神经网络是更难以训练的。当然这有许多原因，最直观的就是有更深的梯度需要计算路径，它消失或爆炸（vanishing or exploding）的风险就越高。幸运的是，现在有很多很有潜力的方式来解决这一问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一个解决梯度消失（vanishing gradients）的方法就是使用残差网络（residual networks），著名的卷积神经网络（CNN）就是训练数百层深度残差网络组成神经网络。&lt;/span&gt;&lt;span&gt;想法是相当简单的，通过默认一层神经网络计算一个恒等函数（identity function）。这是很有道理的，如果你在一层上面做得挺好，就不会期望二或三层运行得差。最坏的情况也是第二层和第三层只会不加修改地「复制」第一层输出。所以每层只需要学习一个恒等函数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不幸的是，学习这样的恒等函数（identity function）好像对多数神经网络不算太麻烦。更糟的是后面的的层级作为监督信号会打乱前面层级的训练，也就是它打算要去方向是持续改变的。同样地，第一层在有很多层级在它下面的情况下也就根本不会训练地很好。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW81aVM2Gdgrxfsa0vR4YVib2JT19TfibiaUhDufRv6GnlrQcf0OjRLarcWbnN04Gxglnicw7RUlbVB9ow/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;为了解决这个问题，我们侧重构建这些层级在表达恒等函数时不同权重的表现。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW81aVM2Gdgrxfsa0vR4YVib2OibLor06lub0wZ4yqs0RYlCRe6dqvM8icNj4HefxuUYRBFeqjasDR0UA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;集众家所长的谷歌神经机器翻译&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;GNMT 文章中所描述的架构建立在之前算法的迭代之上。尽管十分复杂，它仍然遵循编码器-解码器的流程。它看起来可能让人望而生畏，但每个变化都是由一个简单的想法驱动的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW81aVM2Gdgrxfsa0vR4YVib2sQZECAlicnfk3WeBwkoXqiaGBFiakC6G3VPABoRj7ov2axIbMRo1Lya7w/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;总结&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谷歌神经网络翻译的架构非常有趣，它在算法上没有太多创新，真正精妙的地方在于架构设计。如果把它比作一条船，它的船型是如此的完美，能快速穿过充斥波浪的水域而不受一点阻力。以上我们已经讨论了执行各种任务的架构——有关翻译和自然语言生成，它们完全可以应用到其他大计算量的密集型任务中。我们希望很快就会见到这些方式的更多应用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本文是谷歌新论文的一小部分介绍，没有详细讨论 BLEU 的细节，词汇级粒度（granularity）如何改进词级别的翻译效果，BLEU 的优缺点，在快速部署中量化模型，在各种优化算法中选择以获得更好收敛，以及在数据集过大情况下不要使用 dropout 等话题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译文章，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Sat, 19 Nov 2016 11:34:50 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 体验百度无人车，系统性人工智能技术让自动驾驶越来越近</title>
      <link>http://www.iwgc.cn/link/3568916</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;机器之心原创&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：赵云峰&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;iframe class="video_iframe" data-vidtype="1" style="   z-index:1; " height="375" width="500" frameborder="0" data-src="https://v.qq.com/iframe/preview.html?width=500&amp;amp;height=375&amp;amp;auto=0&amp;amp;vid=h0346g9f437" allowfullscreen=""&gt;&lt;/iframe&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第三届世界互联网大会在乌镇召开，人工智能成为热门话题，而真正能让大众切身体验到人工智能便是已经从「测试」走向「试乘」的无人车，百度无人车邀请了多位嘉宾进行了体验，李彦宏竟然也发朋友圈「吐槽」自己不是第一批体验的，同时这也标志着桐乡市子夜路智能汽车和智慧交通示范区内开始测试和试运营，这成为百度继 2013 年启动无人车项目、2015 年底完成多种路段测试、今年 9 月和 10 月分别获得美国加州自动驾驶汽车道路测试许可证和完成加州首次公共道路测试，无人车项目的有一个重大进展。&lt;/span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibtpcdWV11ysdQEicbIfwqaiaTEbFPUtng1O7EGAP4zteYuTYO9Sz4zeNb4EuwJfQgxcOcjSIacvia4g/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是国内首次第四级别的自动驾驶汽车全程无干预的在全开放城市道路上行驶，投入乌镇运营无人车 15 辆，3 天内超过 200 位乘客规模化试乘，应付了多时段的复杂气象条件。更加重要的是，这是支持 5 款车型的跨平台无人驾驶技术。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2015 年底，在百度宣布正式成立自动驾驶事业部且表示「计划三年实现自动驾驶汽车的商用化，五年实现量产。」时，很多人会持观望态度。也有人在谷歌和特斯拉的自动驾驶汽车出现事故（后者为辅助驾驶）后去质疑自动驾驶的发展方向。但就像斯坦福「人工智能百年研究」的首份报告中所提到的那样：就像现在还不明确的一点是，自动驾驶汽车需要发展到何种程度才能引起大众的广泛接受。解决这个问题一方面是需要技术的持续进步和产品的不断成熟；另一方面是需要大众和自动驾驶汽车在生活中进行持续和良性的互动，感知到每一次自动驾驶技术的进步给自己生活带来的影响。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibtpcdWV11ysdQEicbIfwqaiaeSbV0icgrN6FeTbUWo0ddHCqT8NicEDtNiaR6vnYojicUfnvE8Dm6VZfjA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而我们通过一次次的真实体验，逐渐感知到，梦想中的完全自动驾驶和决策精确的汽车以及随之而来的更加智能的城市已经离我们越来越近。波士顿咨询做了一项调查，58% 的调查对象表示他们愿意乘坐自动驾驶汽车。例如，印度和中国消费者的意愿很高：分别有 85% 和 75% 的调查对象表示准备乘坐自动驾驶汽车。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;城市是自动驾驶汽车最有可能给人们的生活、工作和出行带来更好的彻底变革的场景。因为城市既是我们最大的，也是我们增长最快的人口中心。现在全世界已有一半的人类——35 亿人——生活在城市里；而到 2030 年，全世界将有三分之二的人是城市居民。城市占据了 60%——80% 的能源消耗和全世界 70% 的温室气体排放。这也是此次桐乡市子夜路智能汽车和智慧交通示范区内开始运营的意义，它的重要性要远远超过一条供自动驾驶汽车测试的道路，因为这是一个智慧系统。对于我们生活的城市来说，我们可以预计到的好处包括：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1）更为安全的驾驶和更少的事故&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先，人工智能使机器在很多任务的决策速度上都超过了人类，在驾驶决策，尤其是紧急情况下的应变能力更是如此。驾驶员遇到突发情况，他从视觉感知、到肢体决策再到汽车的执行大约需要 1.2 秒，而自动驾驶汽车仅需要 0.2 秒。其次，驾驶员的安全视距一般在50米左右，而自动驾驶汽车安装有多种中远距雷达、摄像头等传感器，能实现200米以上的超视距扫描观测。第三，人类驾驶员会受疲劳、酒驾、醉驾、情绪等问题影响，而计算机系统却不存在这样的问题。因此，更好的「视力」、更快的「驾驶决策」和更加稳定的「驾驶表现」会使自动驾驶汽车成为比人类更加出色的驾驶员，从而降低事故发生率，甚至是提高我们的平均寿命。据麦肯锡咨询预测，自动驾驶可将制动距离及反应时间的大幅降低，车辆碰撞事故发生率减少九成。而根据波士顿咨询的数据，自动驾驶汽车的广泛应用能够让美国每年减少约3万起公路死亡事故。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「让一个有驾照的司机代替电脑驾驶，实际上增加了事故的可能性，因为人类没有那么可靠。」谷歌自动驾驶汽车项目总监 Chris Urmson 曾表示。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2）资源的利用更加高效和环保&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先从车辆来说，目前的车辆利用率较低，而无人车将通过全局优化、共享经济、实时调度、智能派单、动态定价等方式来提高汽车使用率。其次，麻省理工学院MIT研究发现，如果采用自动驾驶汽车，路口通行效率可以提升一倍；IBM研究发现，30%的城市交通流量因找车位而产生。自动驾驶会减轻对道路和停车场需求的压力。BCG 的研究表明，SDV 和「自动驾驶出租车（robo-taxi）」（尤其是共享自动驾驶出租车）在市区的广泛使用可以让城市街道上的汽车数量下降 60%，尾气排放下降 80% 或更多，这会带来公共资源的更好利用和更好的环境。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3）提高生活质量&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这出现表现在出行成本的下降和时间利用效率的提升。据百度自动驾驶事业部总经理王劲介绍，未来，80%的汽车将是共享的，百度经过建模测算得出：如果居民采用完全自动驾驶模式的电动无人驾驶出租车方式出行，其成本仅为当前有人驾驶出租车出行成本的44%。甚至，如果该电动无人驾驶出租车采用分时共享方式运营的话，其出行成本将进一步降到目前出租车方式的1/3。美国一个通勤者的单程平均驾驶时间是 25 分钟，中国大城的通勤时间更长，当有了自动驾驶技术之后，人们可以在通勤中有更多的时间来工作和休闲。同时，自动驾驶汽车还可以为我们「跑腿」去处理一些任务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因此，自动驾驶将大幅提升我们的生活效率，并且会创造出一种全新的智能城市形态。带来的影响不可估量，因此也成为众多科技巨头纷纷加入进来的原因。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从 20 世纪 80 年代卡耐基梅隆大学的 Navlab 计划，到谷歌自动驾驶项目，再到如今所有相关公司的强势布局，众多参与者都走在追求这个终极目标的路上，每个参与者都会基于自己的优势规划发展路径。各个领域的参与者从不同角度向自动驾驶这个目标进发，特斯拉上个月刚刚发布了完全自动驾驶硬件，包括 8 个环绕摄像机、12 个升级版的超声波传感器、具有增强功能的前视雷达、基于 GPU 的更强大的车载计算系统和特斯拉自己开发的神经网络；创业公司 Drive.ai 另辟蹊径选择了与自动驾驶汽车与周围环境（主要是人类）进行通信的发展方向；英伟达则将端到端学习应用到了自动驾驶中；牛津大学和Udacity刚刚开放了各自的自动驾驶数据集。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以谷歌和特斯拉为例，两家公司都使用了多种相似的传感器、地图技术以及汽车的「学习」软件技术，但各自有一些不同的考量。但就像人类一样，无人驾驶汽车也需要一双「眼睛」去「看」到路上的人、车、物，以安全为前提做出决策。而在这项技术方面，谷歌和特斯拉有不同的考量。 谷歌激光测距系统 LIDAR，通过向目标发射探测信号(激光束)，然后将接收到的从目标反射回来的信号(目标回波)与发射信号进行比较，来计算目标的相关信息，比如距离、方位、高度、速度、姿态、甚至形状等参数。由于该技术可高度精确地计算汽车与周遭环境的位置关系，因此激光测距系统 LIDAR 是目前无人驾驶技术最优的选择之一。而特斯拉则完全不买 LIDAR 的帐，而是采用高速摄像头让汽车「看见」周遭的一切。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在数据方面，特斯拉在去年 10 月通过软件升级增加了辅助驾驶功能，这个功能在研发时使用了特斯拉车主过去 18 个月积累的 7.8 亿英里行驶数据。在该功能上线后的短短六个月内就积累了 4,700 万英里数据，远远超过谷歌历时 6 年积累的 150 万英里，而近期特斯拉的这个数据已经增加到 1 亿英里。特斯拉在收集数据上有着垄断性的巨大优势，所以能够利用现有深度学习做自动驾驶，在与大多数同行竞争中已然遥遥领先。但特斯拉并没有满足这一状态，Elon Musk 同时通过成立 Open AI 在本质上寻求能够实现第四级别自动驾驶的下一代的深度学习算法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在通往自动驾驶之路上，各家科技公司各显神通，百度无人车的体验让我们意识到自动驾驶已经离我们的生活越来越近，而现在我们需要探寻的就是谁将先到达那里。自动驾驶涉及的技术非常复杂，现在下结论还为时过早，但唯一明确的一点是，自动驾驶是一项系统工程，需要各种技术相结合。BCG报告中指出，传感器和传感器整合技术在自动化驾驶中至关重要。但除此之外，自动驾驶还需要有精确到10厘米以内的高清地图，满足其对周围环境进行预判。传感器和地图的结合可以保证数据的连贯性，准确定位、导航，不止这些，高清地图可以对传感器进行交叉检查，帮助自动驾驶车辆对周围环境进行实际的测试。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;百度无人车的这次试乘不仅可以让我们更加自信的畅想自动驾驶给我们带来的未来，同时也更好的让我们感知到系统性自动驾驶技术的进展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibtpcdWV11ysdQEicbIfwqaiaVGYj2rmQNKQNyrVfB9fFLH1b6WkiaGSg2gTj4nC9bDhqHSvqJibfibMmw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「百度汽车大脑」是百度自动驾驶的核心，包括高精度地图、定位、感知、智能决策与控制四大模块。底层为高精度地图、中间层为感知/定位，最高层为智能决策与控制。目前汽车大脑已经可为汽车提供高精度地图、高精定位、智能感知、智能控制的自动驾驶整体解决方案。其中，百度自主采集和制作的高精度地图记录完整的三维道路信息，能在厘米级精度实现车辆定位，相比于GPS定位精度提升了两个数量级。百度无人驾驶车依托国际领先的交通场景物体识别技术和环境感知技术，实现高精度车辆探测识别、跟踪、距离和速度估计、路面分割、车道线检测，为自动驾驶的智能决策提供依据。百度无人驾驶使用了64线激光雷达、毫米波雷达、视频等感应器。GPS定位系统等，随时采集车辆周边数据，精确识别路面交通线、红绿灯、各种交通标识，可准确接收车辆的定位信息。在国际通用的KITTI测试车辆检测项目中，百度的车辆识别准确率达到89.32%。在计算能力方面，百度无人车还拥有CPU+GPU+FPGA的异构车载计算平台，计算能力比去年提升8倍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibtpcdWV11ysdQEicbIfwqaiaLgn9ZhnKD4g7ibnPUDoanOLld0icMeibjD7K0CDI48FmCa0dfI9gomyhQ/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然完全自动驾驶在技术上是一个极其困难的问题，我们需要在这方面持续加速，但 自动驾驶汽车的出现还会带来社会、法律和监管上的问题，这就需要决策者、规划者、企业和作为世界各地城市一份子的普通居民等城市市民都将要参与进来，让大家感知和接受它慢慢渗透进我们生活的完成过程。人工智能为大众所知需要一个载体，令人惊艳的 AlphaGo 取得了伟大成就，但是除了我们见证了技术之外没有从本质上改变我们的生活。从目前看来，自动驾驶就是人工智能的最佳呈现方式之一，自动驾驶不能仅仅提留在高校和科技公司的实验室里，也不能一直在工程师进行封闭的测试，而是应该通过一次次公开体验让大众感知到自动驾驶技术的逐渐进步。只有这样，我们才能拥有 BCG 在报告《Revolution in the Driver’s Seat: The Road to Autonomous Vehicles》中「问题不再是 SDV（自动驾驶汽车） 是否会上路，而是会何时上路。」那种状态和自信。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心原创文章，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Sat, 19 Nov 2016 11:34:50 +0800</pubDate>
    </item>
    <item>
      <title>演讲|首席研究员童欣：从交互到智能的网络图形</title>
      <link>http://www.iwgc.cn/link/3568917</link>
      <description>&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/HkPvwCuFwNMgrGtHlAqSolGAFJOjlguic6E2KicGL1jsTEuYncmBwoZMIeo2kh583rErYY0v1YNL8h7s9l4asQAA/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;11月14日，微软亚洲研究院院友会成立，下午举行了“让世界充满AI：人工智能研讨会”，新老院友同台分享来自各自领域的洞见。以下是第一篇，来自微软亚洲研究院网络图形组首席研究员童欣。有关院友会报道请戳：&lt;a href="http://mp.weixin.qq.com/s?__biz=MzAwMTA3MzM4Nw==&amp;amp;mid=2649439445&amp;amp;idx=1&amp;amp;sn=8ddc5f54a313909ce0bbbf126a2a61ac&amp;amp;chksm=82c0d551b5b75c4716e733a2687a4bafaf737728be2a2de5a9b40ca966c195e297aaa0bf3e15&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzAwMTA3MzM4Nw==&amp;amp;mid=2649439445&amp;amp;idx=1&amp;amp;sn=8ddc5f54a313909ce0bbbf126a2a61ac&amp;amp;chksm=82c0d551b5b75c4716e733a2687a4bafaf737728be2a2de5a9b40ca966c195e297aaa0bf3e15&amp;amp;scene=21#wechat_redirect"&gt;这里是你们永远的家——写在微软亚洲研究院院友会成立日。&lt;/a&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;主持人马歆&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：各位院友好。我现在的身份是微软亚洲研究院院友会常务副秘书长。正式开始今天下午让世界充满&lt;span&gt;AI&lt;/span&gt;：人工智能研讨会。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面请我的同事童欣，他是&lt;span&gt;1999&lt;/span&gt;年毕业直接加入微软亚洲研究院，目前担任微软亚洲研究院网络图形组首席研究员。他主要研究方向为计算机图形学和计算机视觉。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;童欣&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：谢谢马歆的介绍，&lt;/span&gt;&lt;span&gt;谢谢各位院友。几天前我得到通知要在这里做一个报告，我非常焦虑和紧张。上次这么紧张还是第一次在&lt;span&gt;SIGGRAPH&lt;/span&gt;报告论文的时候。我想了很久，决定了这个题目，&lt;span&gt;“&lt;/span&gt;网络图形：从交互到智能&lt;span&gt;”&lt;/span&gt;，我想把过去几年来的一些想法作一个思想汇报，请各位院友指正、批评、提出建议。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;事情要从&lt;span&gt;15&lt;/span&gt;年前说起，&lt;span&gt;2001&lt;/span&gt;年的时候，&lt;span&gt;Har&lt;/span&gt;&lt;/span&gt;&lt;span&gt;ry（沈向洋）和百&lt;/span&gt;&lt;span&gt;宁（郭百宁）决定要成立一个新的图形组，那么就需要有一个很酷的组名，于是他们决定叫做&lt;span&gt;“&lt;/span&gt;互联网图形组&lt;span&gt;”&lt;/span&gt;。名字起得很好，问题也马上来了：基本上每个见到我们的人都问什么是&lt;span&gt;Internet&amp;nbsp; Graphics&lt;/span&gt;。为了回&lt;ins cite="mailto:Ershan%20Wang" datetime="2016-11-17T12:07" style="box-sizing: border-box;"&gt;答&lt;/ins&gt;这个问题，在&lt;span&gt;2001&lt;/span&gt;年的时候我们集中全组的力量做了第一个项目，&lt;span&gt;Game&amp;nbsp; Download &amp;amp; Play&lt;/span&gt;，这项目我们想把游戏图形的数据、几何、纹理做一些压缩，那么通过互联网下载的时候，大家就不用等那么长的下载时间了，很快把一部分数据下载到本地之后，大家就可以开始玩游戏了。这项目可以说非常成功。这之后我们顺利地开始做&lt;span&gt;SIGGRAPH……&lt;/span&gt;转眼到了&lt;span&gt;2010&lt;/span&gt;年，百宁把接力棒交给我，让我慢慢开始负责整个图形组，那么我要怎样激励大家、我们组里应该有什么样的愿景。我也开始思考这些问题，重新在问自己到底什么是互联网图形？&lt;span&gt;&lt;ins cite="mailto:Ershan%20Wang" datetime="2016-11-17T13:40" style="box-sizing: border-box;"&gt;&lt;/ins&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/HkPvwCuFwNMgrGtHlAqSolGAFJOjlguicmZWuZFo1cXxwQAP65S6z8W97QGSbg0kWjpnib29HZUNOzoynNVsdjfw/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果我们看看周围，可以看到很多成功的例子。互联网加文字，有网络文学、微博，维基百科。加图片就有美图秀秀、&lt;span&gt;Instgram&lt;/span&gt;等等。互联网加视频也很好，有&lt;span&gt;Youtube&lt;/span&gt;、爱奇艺等很多国内网站，还有网络直播，还有了网红。回头再看看&lt;span&gt;Graphics&lt;/span&gt;，却好像什么都没发生，就这样过了十年，那么到底出了什么问题呢？&lt;span&gt;——&lt;/span&gt;有传言说，如果你站在风口，就算你是一头猪也能飞起来。可是我这么瘦的一个人，站了这么久，怎么还没飞起来，这到底出了什么问题？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我做了一些粗浅的研究，认真想了一想。我发现，飞起来这件事，不是什么都可以，要满足两个条件：第一，要&lt;span&gt;Everyone&lt;/span&gt;，就是内容最好是每一个人都能产生、都能创造，那么有了网络大家就可以互相交流，你的内容就会有海量增长。第二，要&lt;span&gt;Everywhere&lt;/span&gt;，随着移动平台的发展，如果你这个内容的产生和消费能互联到每一个平台上，让大家在任何地方都能生产消费，这时候你就真的飞起来了。&lt;span&gt;&lt;ins cite="mailto:Ershan%20Wang" datetime="2016-11-17T13:42" style="box-sizing: border-box;"&gt;&lt;/ins&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;ins cite="mailto:Ershan%20Wang" datetime="2016-11-17T13:42" style="box-sizing: border-box;"&gt;&lt;/ins&gt;&lt;/span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/HkPvwCuFwNMgrGtHlAqSolGAFJOjlguicrAaFXnKGROAQVGcb1oKY8ACDqhmAOtNzENicn7ZKgEXGiamzpOOeOB5g/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;那么我们看看图形学到底是个什么状况？答案很悲惨：在&lt;span&gt;Everyone&lt;/span&gt;方面，三维内容的生产，对普通用户而言还是非常难的任务。最左边大家可以看到传统的造型动画软件，界面很复杂，即使是艺术家也需要好几年的学习才能做好一个模型。另一方面，虽然我们有一些设备帮助大家来做三维内容的捕捉，比如三维扫描仪、&lt;/span&gt;&lt;span&gt;光穹、动&lt;/span&gt;&lt;span&gt;捕等等，但这些设备都非常昂贵，每个要几百万，还需要专门的场地和专业的操作，普通用户享受不到。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;ins cite="mailto:Ershan%20Wang" datetime="2016-11-17T13:40" style="box-sizing: border-box;"&gt;&lt;/ins&gt;&lt;/span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/HkPvwCuFwNMgrGtHlAqSolGAFJOjlguicicxnyTZmMbBRW6Tdhk2xUTAlsZsY1nkxCQ8OPdgqlSVwd0EC2d5pFMg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/HkPvwCuFwNMgrGtHlAqSolGAFJOjlguicwFiaiaGnEAtQDwug7w7gWbv7kmOziasqpbibsHibt81DXhY8FsfUcgouUjw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们再看看&lt;span&gt;Everywhere&lt;/span&gt;，发展了这么多年，所有三维图形的内容都是通过一个二维的屏幕来传递给大家的&lt;span&gt;——&lt;/span&gt;某种意义上来讲，我们的内容和&lt;span&gt;2D&lt;/span&gt;的视频就没有太大的区别。我们的交互就不用提了，我们还得通过鼠标、键盘或者&lt;span&gt;gamepad&lt;/span&gt;进行交互，这些交互&lt;ins cite="mailto:Ershan%20Wang" datetime="2016-11-17T12:08" style="box-sizing: border-box;"&gt;跟&lt;/ins&gt;我们在真实三维世界中所做的交互是非常不同的。由于这些限制，大家就会发现，&lt;/span&gt;&lt;span&gt;到现在为止，图形的生产和消费基本和互联网无关，基本的方式还是少数的艺术家，他们组织在一起，经过艰苦的奋斗，做了一些游戏、电影，然后把东西通过市场分发给成千上万的消费者进行消费。一切还是停留在传统的模式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;ins cite="mailto:Ershan%20Wang" datetime="2016-11-17T13:43" style="box-sizing: border-box;"&gt;&lt;/ins&gt;&lt;/span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/HkPvwCuFwNMgrGtHlAqSolGAFJOjlguicHNgZjL9AjXT0zLFXEicpxB7ic2zpd1LgbJnkqEomNOSMLFGQyWeaFPRg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;基于这样的想法，我们就提出了我们互联网图形组的愿景，这就是，我们希望做一些图形学的工具和系统，能帮助每个人很方便地产生、观看和分享一些三维内容。同时，我们希望能在自然世界和虚拟世界间提供更自然的界面和交互的方式，另外我们还想在可视的和不可视的抽象信息之间提供一些自然的界面，把抽象的信息变成可视的展现出来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/HkPvwCuFwNMgrGtHlAqSolGAFJOjlguic9qv289w6ara2jjp6LERESIwA0htjBWISO8uAIYjevpf3Nk0Eicp41gw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;过去五年我们为了这一愿景做了很多不同方面的研究，慢慢意识到也许基于智能或者数据的方法是个很好的解决方案。原因有下面几个：第一，我们已经有了一些昂贵的设备，这些设备帮助我们捕捉了大量高质量的数据。第二，我们也有了比较便宜的设备，这些设备可以为我们的系统提供一个初始的输入，不用从零开始了。最后，是一些关于机器学习方面的技术进展可以让我们把这些技术用到图形学的问题里。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/HkPvwCuFwNMgrGtHlAqSolGAFJOjlguicMkuFNHJuGVoGr11JWZVqj2XGttYg0FN6Dnty6Dc6kwIdAJyicyCyW6A/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;那么也许一个比较好的解决方案是通过低价普及的设备，比如普通相机和深度相机，加上智能的算法，再有些时候需要一些简单的用户输入，来方便&lt;/span&gt;&lt;span&gt;地产&lt;/span&gt;&lt;span&gt;生三维的内容。关于智能算法，我们希望它能做两件事，一是希望能够利用到所有三维数据的本征特性，用这些帮助我们产生内容&lt;span&gt;; &lt;/span&gt;二是可以用机器学习来进行端到端的学习，在输入和输出之间直接建立一些联系。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面我用我们组研究的一个研究课题三维物体的数字化来进一步说明举例。&lt;span&gt;&lt;ins cite="mailto:Ershan%20Wang" datetime="2016-11-17T12:09" style="box-sizing: border-box;"&gt;&lt;/ins&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;三维物体数字化的目标是希望将一个真实世界的三维物体，完美地传递扫描进一个虚拟世界。为做到这一点，我们不仅仅要捕捉三维物体的几何形状，还要重现它的材质信息。注意&lt;/span&gt;&lt;span&gt;，有了几何信息虽然可以知&lt;/span&gt;&lt;span&gt;道物体形状，却不知道这个物体是什么，只有有了物体材质表面反射属性以后，我们才能在三维世界中真正栩栩如生地体现出来，大家就会&lt;span&gt;的&lt;/span&gt;清楚知道这是真实世界的一个啤酒瓶，上面&lt;ins cite="mailto:Ershan%20Wang" datetime="2016-11-17T12:10" style="box-sizing: border-box;"&gt;有&lt;/ins&gt;一个纸标签，标签上有烫金字&lt;span&gt;……&lt;/span&gt;我想我不需要再说明这样一个工具对&lt;span&gt;VR/AR&lt;/span&gt;内容的产生、或者对虚拟购物等应用是多么重要。&lt;span&gt;&lt;ins cite="mailto:Ershan%20Wang" datetime="2016-11-17T13:44" style="box-sizing: border-box;"&gt;&lt;/ins&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/HkPvwCuFwNMgrGtHlAqSolGAFJOjlguicY7Kh5Cat9FdLN9PhhL4dtcYy8kf7hcQgd635IyKIuu3NRd2XHx61Kw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;那么我们看看现在的解决方案是什么。基本上我们可以&lt;/span&gt;&lt;span&gt;发现这&lt;/span&gt;&lt;span&gt;流水线还是非常长的，首先用设备扫描三维几何形状，但是扫描得到的这些几何形状&lt;/span&gt;&lt;span&gt;在&lt;/span&gt;&lt;span&gt;大部分情况下非常糟糕，需要大量人工交互工作来去除噪&lt;/span&gt;&lt;span&gt;声、平&lt;/span&gt;&lt;span&gt;滑三维模型。材质捕捉就更麻烦了，我们需要把物体挪到专用的捕捉室，放在专用的设备上，捕捉物体在各种光照、各种视点下的外观，有了这些才能采集出真正的物体形状和材质。大家可以发现这样一个基本的任务还是有很多障碍，首先去噪方面需要很多手工交互工作，其次材质捕捉设备很昂贵，另外这个流水线很长，需要分开的步骤去先捕捉几何，再用另外的设备捕捉材质。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/HkPvwCuFwNMgrGtHlAqSolGAFJOjlguicPVLCtAmxjgyn8qa9z5pDE7lnQ947zhXicgVhIibck2w3d6wNq8J1ZGsg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;那么我们看看我们用一些智能的算法能帮我们做什么事情：第一个要介绍给大家的是我们去年研发出来的一个数据驱动的模型去噪算法。这里要做的是希望有个自动的算法，帮我们除去扫描模型上的噪音，同时保留模型上面所有的几何细节，并且算法对不同设备扫描出来的模型都能很好的处理。我们的算法通过收集带噪声的扫描模型和对应的基本没有噪声的高质量模型，先去学习训练这些几何之间的对&lt;/span&gt;&lt;span&gt;应关系。基于这个对应关系，我们就可以将一个带有噪声的扫描模型直接对应生成它的没有噪声的&lt;/span&gt;&lt;span&gt;模型，从而实现去噪的效果。这是我们组的刘洋研究员带领实习生完成的工作&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/HkPvwCuFwNMgrGtHlAqSolGAFJOjlguicyybeOia462a8607uTlpACFJICSOAooXR7fFktITncxHEibgodCO0tCwA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们这个算法在训练好了以后，用户在用的时候是全自动的。更了不起的是，我们的算法在我们所有的测试模型上去噪效果都超过了所有目前已有的模型去噪算法。同时我们的算法还比所有已知算法都要快。我们很快会把我们的算法源代码和数据公布在网上，希望其他研究人员都可以在基础上继续研究，同时很多用户也可以直接使用我们的算法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面我们来看一些实验结果。左边是输入一个扫描模型，有很多的噪声，右边是&lt;span&gt;Ground&amp;nbsp; Truth&lt;/span&gt;，右边第二个是我们算法得到的结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/HkPvwCuFwNMgrGtHlAqSolGAFJOjlguicoSt5A0MP1E9tMoxgKzQ00mjqLo0JtyTlOKw0LmBj8icNsbiatl83AmPw/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是另一个例子，扫描模型的噪音非常大，以前的算法只能除掉一些噪音，或者会抹去很多模型上的集合细节。我们的算法可以比较好地去掉模型上的噪声，同时比较好地保留它的几何细节。&lt;span&gt;&lt;ins cite="mailto:Ershan%20Wang" datetime="2016-11-17T13:45" style="box-sizing: border-box;"&gt;&lt;/ins&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/HkPvwCuFwNMgrGtHlAqSolGAFJOjlguic9GDbU97ytx4uXvwkxuWQhyUZA2CzhygdbXiaAaZ9KEQIMCM6fTOaeSw/0?wx_fmt=jpeg"/&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们再看看材质捕捉方面，刚才我们说材质捕捉设备很昂贵，捕捉过程很麻烦。有什么更好的做法来做呢？我们在两年前做了世界上第一个不需要任何特殊设备和光照，只从自然未知光照下拍摄的物体视频出发进行材质捕捉的算法。这是我们团队的董悦研究员带领实习生完成的工作。输入就是大家看到的左边的视频序列，右边是输出的材质捕捉的结果，最后我们把它放在一个新的光照下，物体可以栩栩如生地再现出来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/HkPvwCuFwNMgrGtHlAqSolGAFJOjlguicOc1UWZmVONlrZNnxrR4vLqMS2BysUWDKmfa9GQZlIkf7SVoEYF9gvQ/0?wx_fmt=jpeg"/&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个算法的关键是我们要从视频中同时估计物体的光照和材质属性。我们发现自然环境中的光照和材质本身具有不同的属性，可以用这些属性很巧妙地从观察的数据最终把二者分分离开来。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这里显示了我们算法所恢复的物体的材质效果，不论是啤酒瓶上印刷的标签，还是光滑的瓷器，还是带有铁锈的金属，我们的算法都能自动地从一些视频序列中把高质量的材质重构出来。&lt;span&gt;&lt;ins cite="mailto:Ershan%20Wang" datetime="2016-11-17T13:47" style="box-sizing: border-box;"&gt;&lt;/ins&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/HkPvwCuFwNMgrGtHlAqSolGAFJOjlguic3pV31p6rwyaMbQZKU3BHexOoGI88x3WNGTBInNIibWGdomMXibRXvKVQ/0?wx_fmt=jpeg"/&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有了这些工作，上面的流水线变得简单自动了很多，但还是要经过两步。有没有可能一步就把所有事情搞定？去年我们在这方面做了一些研究，做了世界上第一个从视频中同时恢复物体的几何形状和表面材质的算法。这个方法只是用了视频而不再需要任何的深度相机捕捉的数据。同样，我们的算法不需要知道光照信息。左边是我们算法输入的视频，右边是捕捉的物体和材质在新的光照环境下绘制的结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/HkPvwCuFwNMgrGtHlAqSolGAFJOjlguicEVM2ibp5dfcWpLX0B4nrF2wvXR8a6D2tmVibsBfa6FUXALU9NcVKAgZg/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是我们捕捉到的几何和材质和真实照片的对比，你可以看到所有的几何细节、表面反光和材质属性都被很好的重建出来了。在不同的光照下看，所有物体都像真实物体一样得到真实再现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/HkPvwCuFwNMgrGtHlAqSolGAFJOjlguicuB46Y6YSKmEicEESNiciaRQX6xX25ib3Diaiajicf483uuDSpN1FRwVE4ykDA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;基于这一结果，我们把做的结果放到&lt;span&gt;HoloLens&lt;/span&gt;，并和我们周围的真实光照结合在一起，可以生成非常真实的效果。&lt;span&gt;&lt;ins cite="mailto:Ershan%20Wang" datetime="2016-11-17T13:48" style="box-sizing: border-box;"&gt;&lt;/ins&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/HkPvwCuFwNMgrGtHlAqSolGAFJOjlguic5en9lbHKmyjFfThZICGmI2qKLRMTXIZ7LKtzVauX3NMSK7nZq6lZ2w/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;刚才我们以物体的数字化为例说明了如何采用智能的算法帮助我们简化建模过程，方便普通用户捕捉三维内容。总结一下，在过去几年中我们在智能算法方面做了很多努力，我们逐渐认识到&lt;/span&gt;&lt;span&gt;，&lt;/span&gt;&lt;span&gt;智能算法也许是能够实现普通用户产生三维内容的一个最终解决方案。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，我也想分享一下我在这个过程中所得到的经验或者教训：我总结为三个&lt;span&gt;D&lt;/span&gt;。首先是&lt;span&gt;Open-minded&lt;/span&gt;。我们要积极地学习借鉴&lt;/span&gt;&lt;span&gt;其他&lt;/span&gt;&lt;span&gt;领域的方法算法，比如现在我们也在学习和深度学习相关的东西。第二是&lt;span&gt;Concentrated&lt;/span&gt;。第一条就像吸星大法，把别人的东西都吸过来了，但还不够，还要易筋经，把东西化成自己的，要知道自己拿到这个工具是要解决自己的问题的，聚焦于自己的问题，把那些东西为你所用。最后是&lt;span&gt;End&amp;nbsp; to&amp;nbsp; end&lt;/span&gt;，我们并不想发了一篇论文&lt;/span&gt;&lt;span&gt;然后&lt;/span&gt;&lt;span&gt;研究就结束了，论文更多的是一个交流表达的手段，关键是把问题真正给解决掉，最后给用户提供一个真正的端到端的解决方案。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;展望未来，可以说我们才刚刚起步，前面还有很长的路要走。这也许是个坏消息，但对我来说这其实也是好消息。因为这意味着前面还有很多不确定性、很多挑战。作为一个研究人员来说，这些困难、挑战也正是我们最终的乐趣所在，虽千万人，吾往矣。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谢谢大家。&lt;span&gt;&lt;ins cite="mailto:Ershan%20Wang" datetime="2016-11-17T13:49" style="box-sizing: border-box;"&gt;&lt;/ins&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;ins cite="mailto:Ershan%20Wang" datetime="2016-11-17T13:49" style="box-sizing: border-box;"&gt;&lt;/ins&gt;&lt;/span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/HkPvwCuFwNMgrGtHlAqSolGAFJOjlguicNtT72ssZY0Oia4bwibricTicHeSITZoFHwyYoznSIg1ZBXY0IPD3Ysasug/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;你也许还想看：&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="max-width: 100%; width: 527.778px; line-height: 28.4444px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;li&gt;&lt;p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzAwMTA3MzM4Nw==&amp;amp;mid=2649439247&amp;amp;idx=1&amp;amp;sn=49e2b25ceab322c938049a082a3e6e1c&amp;amp;chksm=82c0d58bb5b75c9d6bca10b8b3f647498dd8de3f238cca6012a5c249bf8528387ba30ce85aff&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzAwMTA3MzM4Nw==&amp;amp;mid=2649439247&amp;amp;idx=1&amp;amp;sn=49e2b25ceab322c938049a082a3e6e1c&amp;amp;chksm=82c0d58bb5b75c9d6bca10b8b3f647498dd8de3f238cca6012a5c249bf8528387ba30ce85aff&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;对话|首席研究员童欣：从长远看，AR的应用范围远比VR广泛&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;/p&gt;&lt;/pre&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzAwMTA3MzM4Nw==&amp;amp;mid=401773681&amp;amp;idx=2&amp;amp;sn=5d4a33fae7b5dc90b425c646ef77dfbb&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzAwMTA3MzM4Nw==&amp;amp;mid=401773681&amp;amp;idx=2&amp;amp;sn=5d4a33fae7b5dc90b425c646ef77dfbb&amp;amp;scene=21#wechat_redirect" style="font-size: 15px; text-decoration: none;"&gt;&lt;span&gt;【将电影变成现实】用HoloLens玩虚拟传送&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;/p&gt;&lt;/pre&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzAwMTA3MzM4Nw==&amp;amp;mid=400607098&amp;amp;idx=1&amp;amp;sn=933c7328221cfec90e358314be8602e3&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzAwMTA3MzM4Nw==&amp;amp;mid=400607098&amp;amp;idx=1&amp;amp;sn=933c7328221cfec90e358314be8602e3&amp;amp;scene=21#wechat_redirect" style="font-size: 15px; text-decoration: none;"&gt;&lt;span&gt;刷新神经网络新深度：ImageNet计算机视觉挑战赛微软中国研究员夺冠&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;/p&gt;&lt;/pre&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 style="margin-bottom: 14px; padding-bottom: 11px; max-width: 100%; border: none; line-height: normal; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;感谢你关注“微软研究院AI头条”，我们期待你的留言和投稿，共建交流平台。来稿请寄：msraai@microsoft.com。&lt;/span&gt;&lt;br/&gt;&lt;/h2&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNOiadOWXokcRPb57xdGSTVyicYWXylxhcJ1WZhXVOBwuWvLMoWcWzm9OxKc6PaiaBk1nIf1tfGQAgjSQ/640?"/&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;微软小冰&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;进驻微软研究院微信啦！快去主页和她聊聊天吧。&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/HkPvwCuFwNNibWT4MnMcgUQJEZLVyb5ZFPDia4l7FaIVk2q7lSlRBLibUdkydGuaStIS5NSPso2ek1NmMdAHGtakg/640?wx_fmt=jpeg"/&gt;&lt;/span&gt;&lt;/p&gt;</description>
      <pubDate>Sat, 19 Nov 2016 11:34:50 +0800</pubDate>
    </item>
    <item>
      <title>一周论文 | TTIC在QA任务上的研究进展</title>
      <link>http://www.iwgc.cn/link/3568918</link>
      <description>&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;span&gt;&lt;strong&gt;引言&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;PaperWeekly已经介绍过不少Question Answering的相关工作。主要有DeepMind Attentive Reader，FAIR Memory Networks，Danqi’s Stanford Reader, Attention Sum Reader, Gated Attention Sum Reader, Attention Over Attention Reader, etc. 这些模型关联性很大，或多或少存在相似之处。本文给大家介绍一下Toyota Technological Institute at Chicago (TTIC)在Question Answering方面的相关工作，共有3篇paper：&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;1、Who did What: A Large-Scale Person-Centered Cloze Dataset, 2016&lt;br/&gt;2、Broad Context Language Modeling as Reading Comprehension, 2016&lt;br/&gt;3、Emergent Logical Structure in Vector Representations of Neural Readers, 2016&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;span&gt;&lt;strong&gt;Who did What: A Large-Scale Person-Centered Cloze Dataset&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="作者" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;作者&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Takeshi Onishi, Hai Wang, Mohit Bansal, Kevin Gimpel, David McAllester&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="文章来源" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;文章来源&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;EMNLP 2016&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="问题" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;问题&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;文章构建了一个新的Question Answering dataset，”Who did What”。&lt;/p&gt;&lt;p&gt;sample instance如下图所示。&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnA1Oia1MHKMzFs1Fy1NnogMvKibKh36a2NNib7nOZelL6SJLm9gdSwARmDDxoT9zh0OlZSwHq8P1t5A/640?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;问题的句子总是挖掉了一些named entities，然后给出在文中出现过的别的named entities作为选项。这一个dataset的难度要高于之前的CNN/DM dataset，可以作为创建新模型的参考数据集。&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="模型" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;模型&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;构建此数据集的方法与CNN/DM不同，问题并不是context passge的一个summary。问题与context均来自Gigaword Corpus，他们是两篇非常相关的文章。&lt;/p&gt;&lt;p&gt;具体来说，我们先找到一篇文章，作为question文章。然后提取出文中第一句话的named entities，删除其中的一个named entity作为将要被预测的答案。然后利用这一句question sentence，我们可以利用一些Information Retrieval系统从Gigaword Corpus找到一篇相关的文章作为passage。这篇文章与question文章不同，但是包含着与question sentence非常类似的信息。&lt;/p&gt;&lt;p&gt;有了passage之后，我们再从passage中找出named entities作为candidate answers。&lt;/p&gt;&lt;p&gt;为了使任务难度更大，我们用一些简单的baseline (First person in passage, etc) 将一些很容易做出的问题删掉，只留下比较困难的instances。这样构建的数据比CNN/DM会困难不少。&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="简评" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;简评&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;相信作者创建的新数据集会给Machine comprehension带来一些新的问题与挑战，是很有价值的资源。文章采用的baseline suppresion方法可以用比较小的代价加大问题的难度，值得参考。&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;span&gt;&lt;strong&gt;Broad Context Language Modeling as Reading Comprehension&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="作者" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;作者&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Zewei Chu, Hai Wang, Kevin Gimpel, David McAllester&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="文章来源" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;文章来源&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;arXiv&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="问题" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;问题&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;不久前发布的&lt;a target="_blank" rel="external" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;LAMBADA dataset&lt;/a&gt;中，作者尝试的各种baseline models都给出了比较差的结果。&lt;/p&gt;&lt;p&gt;每一个LAMBADA instance如下图所示。&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnA1Oia1MHKMzFs1Fy1NnogMmkOuheREhVedFhMtZTvibBkibY90UvlLPeH4swDIxZEEeHTWR2s48Uow/640?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="模型" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;模型&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;在观察了LAMBADA dataset之后，我们认为可以利用Reading comprehension models来提升准确率，而不必使用传统的language model。&lt;/p&gt;&lt;p&gt;由于state of the art reading comprehension models需要给出candidate answers，然后从中选出一个作为预测的答案，我们就将所有在context中出现过的单词都作为一个candidate answer。&lt;/p&gt;&lt;p&gt;LAMBADA给出的训练集是一些小说的文本。为了使训练集与测试集的数据类型保持一致，我们构建了一个biased training set。具体的做法是，我们将training set划分成4-5句话的context，然后保证target word在context passage中出现，只保留这样的训练数据。我们在新构建的training set上训练各种attention based models,得到了比原作者好得多的测试结果。&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnA1Oia1MHKMzFs1Fy1NnogMLnWdq0hSAagXkPvoU4tsCcuukP2NZfkQE6RrPaJWumc8oxEqMVdeFw/640?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="简评" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;简评&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;这篇文章中，作者利用了简单的方法和模型将LAMBADA dataset的准确率从7.3%提高到45.4%，非常简单有效。&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;span&gt;&lt;strong&gt;Emergent Logical Structure in Vector Representations of Neural Readers&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="作者" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;作者&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Hai Wang, Takeshi Onishi, Kevin Gimpel, David McAllester&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="文章来源" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;文章来源&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;ICLR 2017 Submission&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="问题" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;问题&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;最近提出的各种各样的attention based reader models,本文作者做了一个比较全面的总结和分析，并且通过数学分析和实验展示了模型之间的相关性。&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="模型" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;模型&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;本文作者认为，当前的attention based models可以分为两类，aggregation readers(包括attentive readers和stanford readers)以及explicit reference readers(包括attention sum reader和gated attention sum reader)。&lt;/p&gt;&lt;p&gt;这两种reader可以用如下的公式联系在一起。&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnA1Oia1MHKMzFs1Fy1NnogMQFhTTx6uXEUEK5eqhqezwSe3y3Uib8xjURURTJ2GWoV2wbkIKWMqIibg/640?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;要满足上述等式，只需要满足下面的公式。&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnA1Oia1MHKMzFs1Fy1NnogMLVdCyxMmRicdGmw6JsGmbJHcErIjgke95z2EkOrW3iaHWmhqe0t1huuw/640?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;也就是说，只有正确答案所在的hidden vector和question vector得到的inner product才能给出不为零的常数。以下实验结论支持了这一假设。&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnA1Oia1MHKMzFs1Fy1NnogMhkSVQydMibUiate8BcAVeNIgI06iawmIPvr1AB1T8w3Al1eUswaGF4Z5g/640?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;由于CNN/DM在训练和测试中经过了anonymization，作者认为此inner product其实可以分为两部分，一部分与anonymized token ID有关，另一部分与ID无关。与ID相关的那一部分在inner product应该直接给出0的答案。如下述公式所示。&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnA1Oia1MHKMzFs1Fy1NnogME0UEcbYD2TyMgTYDgnibGrweUccspkXrjeCsCCmia7QmzwMvbDCEOkwg/640?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;本文的另一部分工作是在attention readers上加入一些linguistic features提升各个数据集的准确读，这里不仔细描述。&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="简评" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;简评&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;本文是对于各个attetion based neural reader models很好的总结，它很好地连接了各个不同的model，说明了为何看似不同的model能够给出非常类似的结果。&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="总结" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;span&gt;&lt;strong&gt;总结&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;问答系统是一类大的问题，也是目前NLP应用的研究热点之一。本文作者介绍了TTIC在QA研究中的一些成果，其中第二篇是本文作者近期的paper。感谢来自芝加哥大学的@Zewei Chu童鞋辛勤的劳动。&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;关于PaperWeekly&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;PaperWeekly是一个分享知识和交流学问的学术组织，关注的领域是NLP的各个方向。如果你也经常读paper，也喜欢分享知识，也喜欢和大家一起讨论和学习的话，请速速来加入我们吧。&lt;/p&gt;&lt;p&gt;微信公众号：PaperWeekly&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgkSMlEJFo90NY8rCXr3mJMBibduVHxMKSHzQtVkHz8kNwpjCKBiccGuqLE0WpPuAbdtEs6cTF5iabpAQ/640?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;微博账号：PaperWeekly（&lt;a target="_blank" rel="external" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;http://weibo.com/u/2678093863&lt;/a&gt;&amp;nbsp;）&lt;br/&gt;微信交流群：微信+ zhangjun168305（请备注：加群交流或参与写papernote）&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;</description>
      <pubDate>Sat, 19 Nov 2016 11:34:50 +0800</pubDate>
    </item>
  </channel>
</rss>
