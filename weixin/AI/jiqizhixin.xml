<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>机器之心</title>
    <link>http://www.iwgc.cn/list/670</link>
    <description>人与科技的美好关系</description>
    <item>
      <title>深度 | 伯克利教授Stuart Russell：人工智能基础概念与34个误区</title>
      <link>http://www.iwgc.cn/link/3592114</link>
      <description>&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自UC Berkely&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote style="max-width: 100%; color: rgb(62, 62, 62); font-size: 16px; line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;/blockquote&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Russell 是加州大学伯克利分校人工智能系统中心创始人兼计算机科学专业教授，同时还是人工智能领域里「标准教科书」《人工智能：一种现代方法》作者（谷歌研究主管 Peter Norvig 也是该书作者）。在这篇文章中，他以 Q&amp;amp;A 的方式讲解了人工智能的未来以及常见的误解。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1. 什么是人工智能？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;是对让计算机展现出智慧的方法的研究。计算机在获得正确方向后可以高效工作，在这里，正确的方向意味着最有可能实现目标的方向，用术语来说就是最大化效果预期。人工智能需要处理的任务包括学习、推理、规划、感知、语言识别和机器人控制等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;常见误解&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;「它是一个特定技术」。例如在二十世纪八十年代到九十年代，人们经常会看到新闻报道中人工智能与基于规则的专家系统被混为一谈。现在，人工智能经常会与多层卷积神经网络混淆。这有点像把物理和蒸汽机的概念搞混了。人工智能探究如何在机器中创造智能意识，它不是在研究中产生的任何一个特定的技术。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;「这是一个特定类别的技术方法」。例如，经常有人用符号化或逻辑化的方法将人工智能与「其他方法」相互比较，如神经网络和遗传编程。人工智能不是一种方法，它是一个课题。所有这些方法都是在对人工智能进行研究的产物。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;「这是一小群研究者的方向」。这个误解与前几个错误有关。一些作者使用「计算智能」指代几个特定的研究者群体，如研究神经网络，模糊逻辑和遗传算法的研究者。这是非常片面的，因为这种分类让人工智能的研究陷入孤立的境地，让研究成果不能得到广泛的讨论。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;「人工智能只是算法」。严格说来不算是误解，人工智能的确包含算法（也可粗略定义为程序），它也包含计算机中其他的应用。当然，人工智能系统需要处理的任务相比传统算法任务（比如排序、算平方根）复杂得多。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2. 人工智能将如何造福人类？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;文明的一切都是人类智慧的产物。在未来，人工智能会将会扩展人类的智力，这就像起重机让我们能够举起几百吨的重物，飞机让我们很快飞到地球的另一端，电话让我们在任何角落实时交流一样。如果人工智能被适当地设计，它可以创造更多价值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;常见误解&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;「人工智能没有人性」。在很多反乌托邦幻想中，人工智能会被用来控制大部分人类，无论是通过监视，机器人执法，法律判决甚至控制经济。这都是未来可能出现的情况，但首先它不会被大多数人接受。人们往往忽视人工智能可以让人类接触更多的知识，消除人与人之间的语言隔阂，解决无意义和重复的繁重任务。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;「人工智能将造成不平等」。毫无疑问，自动化程度的提升将使财富集中到越来越少的人手里。但是现在，如何使用人工智能的选择权在我们手里。例如，人工智能可以促进协作，让生产者与客户有更多交流，它可以让个人和小组织在全球化的经济环境下独立运作，摆脱对于特定大公司订单的依赖。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3. 什么是机器学习？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;它是人工智能的一个分支，探索如何让计算机通过经验学习提高性能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;常见误解&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;「机器学习是一个新的领域，它已经代替了人工智能的地位」。这种误解是最近机器学习热潮产生的副作用，大量学生在之前没有接触过人工智能的情况下学习了机器学习课程。机器学习一直是人工智能的核心话题：阿兰·图灵在二十世纪五十年代的论文中已经认为学习是通向人工智能最可行的途径。这一观点似乎是正确的，人工智能最突出的早期成果，Arthur Samuel 的跳棋程序就是使用机器学习构建的。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;「机器不能学习，它们只能做程序员告诉它的事情」。这显然是错的，程序员能够告诉机器如何学习。Samuel 是一个优秀的跳棋玩家，但他的程序很快就通过学习超过了他。近年来，机器学习的很多应用都需要大量数据来进行训练。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;4. 什么是神经网络？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;神经网络是受生物神经元启发构建的计算系统。神经网络由许多独立的单元组成，每个单元接收来自上一层单元的输入，并将输出发送到下个单元（「单元」不一定是单独的物理存在；它们可以被认为是计算机程序的不同组成部分）。单元的输出通常通过取输入的加权和并通过某种简单的非线性转型，神经网络的关键特性是基于经验修改与单元之间的链接比较相关权重。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;常见误解&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;「神经网络是一种新型计算机」。在实践中，几乎所有的神经网络都运行在普通的计算机架构上。一些公司正在设计专用机器，它们有时会被称作是「神经计算机」，可以有效地运行神经网络，但目前为止，这类机器无法提供足够的优势，值得花费大量时间去开发。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;「神经网络像大脑一样工作」。事实上，生物神经元的工作方式比神经网络复杂得多，自然界存在很多种不同的神经元，神经元的连接可以随时间进行改变，大脑中也存在其他的机制，可以影响动物的行为。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;5. 什么是深度学习？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;深度学习是一种特定形式的机器学习，训练多层神经网络。深度学习近年来非常流行，引领了图像识别和语音识别等领域的突破性进展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;常见误解&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;「深度学习是一个新领域，已经代替了机器学习的地位」。事实上，深度学习在神经网络研究者中间已经被讨论了超过二十年。最近深度学习的发展是由相对较小的算法改进以及大数据集模型和计算机硬件发展驱动的。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;6. 什么是强人工智能和弱人工智能？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「强人工智能」和「弱人工智能」概念是由 John Searle 最先提出的，是他对人工智能研究方向的两个假设。弱人工智能假设机器可以通过编程展现出人类智能的水平。强人工智能则假设机器出现意识，或者说机器思考和认知的方式可以用以前形容人类的方式来形容。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;常见误解&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;「强人工智能是人类智力级别通用人工智能研究的方向」。这个解释具有代表性，但这不是强/弱人工智能概念被提出时的本来意义。同样，「弱人工智能」被认为是针对特定领域，执行特定任务的人工智能研究，如语音识别和推荐系统（也称工具 AI）。虽然没有人具有最终解释权，但这种语义的转换可能会造成不必要的混乱。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;7. 什么是 AGI，ASI 和超级智能？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;AGI 代表的是通用人工智能，这个术语意在强调建立通用目的智能系统的雄心目标，其应用的宽度至少能覆盖人类能解决任务。ASI 指的是人工超级智能：远远超越人类智能的人工智能。更具体地说，一个超级智能系统高质量决策能力要比人类强，它能考虑更多的信息和进一步深入未来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;常见误解&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;「主流的人工智能研究者并不关心通用人工智能。」像语音识别这种细分领域的某些研究者主要关心的是其所在领域的具体目标，其他一些研究者比较关心找到现有技术的商业应用。在我的影像里，如学习、推理、和计划等细分领域的大多数人工智能研究者认为他们目前的研究工作有助于解决通用人工智能的子问题。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;「人类的智能是一种通用智能」。这种观点常被认为是显而易见，不值得讨论，但它却几乎回避了关于 AGI 的所有讨论。持有这种观点的人通常会认为通用智能就是人类能做到所有任务的能力。然而当然不存在人工不能做的人类工作，所以人类能做已经存在的人类工作也没什么好惊讶的。难的是怎么定义那种完全独立于以人类为中心的价值观和偏见的宽度。所以我们只能说人类智能是某种程度上的通用智能，人类能做人类能做的所有事情。另一种更有意义的说法是人类能做很多事情，但目前为止这个问题 还没有确切的答案。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;8. 什么是摩尔定律？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「摩尔定律」指的是多个相关的观察和预测能影响电路性能和密度。现代理解的「摩尔定律」是每一秒的操作次数以及每一美元所能买到的电脑性能，将每隔 N 个月翻一倍以上，N 大约是 18，这一表述有些背离「摩尔定律」最初的定义。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;常见误解&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;「摩尔定律是物理定律」。事实上，摩尔定律只是一种关于技术进步的经验观察。没有什么规定摩尔定律会持续下去，当然它也不可能无限持续下去。时钟速度的增加已经达到了顶峰，目前价格/性能上的提升也来自于单个芯片上内核（处理单元）数量的上升。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;9. 摩尔定律能让我们预测出超级人工智能的到来吗？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不能。人工智能系统不能做的事情很多，比如理解复杂的自然语言文本；加速意味着在很多情况下得到的错误答案的速度也越快。超级智能需要在主要的概念突破。这些很难预测，即便我们有了速度更快的机器也没啥用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;常见误解&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;「让机器更强大的意思是提升它们的智能」。这是人工智能的未来的讨论中的一个常见主题，这个主题似乎建立在一个混乱的概念上，我们使用「强大」来描述人类智力，但是在描述计算机时用的「强大」的含义更加简单，就是每秒操作的次数。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;10. 什么是机器 IQ？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;没有机器 IQ 这种说法。某种程度上一个人在多个任务上的多种智慧能力是高度相关的，人类可以说有 IQ，但是研究者们对任意单一维度上的 IQ 定义有争议。另一方面，任意给定的机器的各种能力之间都是不相关的：一台机器能打败世界象棋冠军，并不意味着它能玩的好别的棋类游戏。能赢得猜谜比赛的机器也无法回答「你叫什么名字？」这样简单的问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;常见误解&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;「&lt;/span&gt;根据摩尔定律，机器 IQ 会不断上升&lt;span&gt;」&lt;/span&gt;。既然根本不存在什么机器 IQ，它也就不可能增长；摩尔定律描述的仅仅是原始的计算吞吐量，与是有存在执行任意特定任务的算法没有关系。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;11. 什么是智能爆炸？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「智能爆炸」这个术语是 I.J.Good 于 1965 年在其文章「Speculations Concerning the First Ultraintelligent Machine」中创造的。它指的是足够智能的机器能重复设计它自己的硬件和软件来创造出一个更加智能的机器的可能性，这个过程会一直重复下去，直到「人的智能被远远的甩在后面」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;常见误解&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;「&lt;/span&gt;一旦机器达到人类水平的智能，智能爆炸就在所难免&lt;span&gt;」&lt;/span&gt;。反过来：虽然逻辑上是可行的，但是让 N 代的机器设计出 N+1 代的机器太难了。同样的道理，我们造的机器可能在一些重要的方面成为超过人类，但是在其他方面可能会落后于人类。在解决贫困、治疗癌症等重要问题上，机器的能力肯定会比人类强，而且不需要在人工智能研究上有大突破就能实现。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;12. 人工智能系统何时才能超过人类智力？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是一个难以回答的问题。因为首先它假定这件事必然发生，事实上它具有选择性：假如人类选择不去发展这样的人工智能，这件事就不太可能发生。第二，「超过」假定智力是线性的，而这不是真实情况，机器在某些任务的处理上比人类更快，而在更多放面则很糟糕。第三，如果我们认为「通用的」智能是有用的，我们就可以开发这样的机器，但目前我们不知道它是不是有用的。宽泛地说，实现这样的人工智能还需要很多技术突破，而这些都是难以预测的，大多数科学家认为这件事会在本世纪内发生。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;常见误解&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;「它永远不会发生」。对技术突破进行预测是很难的。1933 年 9 月 11 日，Rutherford，也许是那个时代最著名的核物理学家，在英国科学促进年会上向人们宣布：「任何想从原子变形过程中获取能源的努力都是徒劳的。」（他在各种场合发表过许多类似言论，大意都是表达使用原子能是不可能的）结果第二天早上，Leo Szilard 发现了中子诱导链式反应，并很快对核反应堆申请了专利。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;13. 人工智能系统现在能做什么？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能的应用范围已经比几年前大很多了。从围棋、纸牌、简单的问答、从新闻中抓取信息、组合复杂的对象、翻译文字、识别语音、识别图像中的概念、到在「普通」交通条件下驾驶汽车，不一而足。在很多情况下，人工智能在你不知道的情况下发挥着作用，如检测信用卡欺诈，评估信用，甚至在复杂的电子商务拍卖中投标。搜索引擎中的部分功能也是人工智能的简单形式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;常见误解&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;「像『下棋』这样的任务对机器来说和对人类来说是一样的」。这是一个错误的假设：机器「掌握」一项技能的程度超过了人类。人类通过阅读和理解学会游戏规则，通过观看棋局和下棋来提高水平。但典型的下棋程序没有这样的能力——将下棋规则编程，让机器算法直接给出所有可能的下一步。机器无法「知道」人类所谓的规则（目前新兴的强化学习方式改变了这一点）。DeepMind 的人工智能系统可以学会很多种游戏，它不知道自己在学习什么，看起来也不太可能学会这些游戏的规则。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;「机器执行任务的方式和人类一样」。我们不知道人类思考问题的机制，但这种机制与人工智能系统处理任务的方式看起来大不相同。例如，下棋程序通过考虑当前棋局状态和下一步可能的序列比较结果考虑下一步，而人类经常是先发现可能获得的优势，然后继续考虑如何找到一系列方式来实现它。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;「如果机器可以做到任务 X，那么它就可以做类似的所有任务了」。参见有关机器 IQ 的问题，机器目前还不能形成通用化的智能，它们的功能通常局限于某一领域。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;14. 人工智能会对社会造成什么样的影响？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在可预见的未来中，人工智能的各种应用将会改变社会形式。自动驾驶汽车现在已经在路上进行测试，至少有一家公司承诺将在 2016 年内交货（考虑到目前遇到的困难，其他公司的态度则更为谨慎）随着计算机视觉和机械腿设计的进化，机器人非结构化环境正在变得更为实用——可能的应用范围包括农业和服务领域（特别是对于老人和残疾人而言）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，随着机器能够理解人类语言，搜索引擎和手机上的「个人助理」将会改变现有的人机交互方式，它们可以回答问题，整合信息，提供建议，并促进交流。人工智能还可能会对科学领域（如系统生物学）产生重大影响，这些学科中信息的复杂性和数量一直令人望而却步。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;常见误解&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;「机器人正在接管一切」。参见《人工智能的智力何时才能超过人类》，人工智能中的绝大多数进步是基于任务处理的改进。当然，从长远来看，维持人类的控制很重要。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;15. 人工智能与机器人的发展会取代大量人类的工作吗？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一些研究（比如 Frey 和 Osborne 在 2013 年的调查）表明在未来美国将近一半的工作在自动化面前会变得很脆弱。其他作者，比如 Bryjolfsson 和麦肯锡在 2011 年的工作表明这一变化已经开始了：2008 年经济萧条之后就业率的缓慢恢复，生产率与停滞不前的工资之间的差异化增加了自动化的进程。随着人工智能与机器人的持续发展，更多的工作将受到影响看起来不可避免。大量的失业并不是必然的，但这可能会造成经济结构的巨大转变，需要想出组织工作与酬劳的新思路。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;常见误解&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;「机器人的工作越多意味着人类工作越少」。工作不是零和（zero-sum）的：由一对机器人协助的工人可能更具工作效率，也因此需要更多这样的工人。没有机器人的帮助，一些领域的工作由人类完成可能不具备经济效益，或者一些工作单独的人或机器无法完成。同样，就像涂刷匠的刷子与滚筒：如果使用针尖大小的刷子一点一点的涂刷，我们就雇不起涂刷匠来涂刷一整间屋子了。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;16. 什么是无人机，自动武器，杀人机器人？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;无人机是由人远程控制的飞行器；有些无人机可以携带武器（通常是导弹），这些武器的释放也是由人远程控制的。自动武器是可以自主选择和吸引攻击对象的装置。目前这类装置包括韩国非军事化区里的自动瞄准机枪和一些不同类型的船载反导弹系统。目前在技术上可以实现将无人飞机的控制员替换成完全自动的计算机系统，以达到致命自主武器系统的要求。致命自主武器系统是日内瓦会议裁减军备议题的讨论主题。杀人机器人是对具有轮动能力和行走能力的武器的统称，包括：船，飞行器以及人工智能的昆虫飞行器。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;常见误解&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;「&lt;/span&gt;完全自主武器的出现还需要 20-30 年的研发&lt;span&gt;」&lt;/span&gt;。得出这个预估时间的依据无从知晓，但是 20-30 年的时间跨度有点夸大所需的研发时间长度。目前自主武器的研发已经在全世界内大范围的开展，英国国防部已经宣称，对于一些简单对抗如海上战役，完全自动武器现在已经可以实施。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;17. 我们需要担心杀人机器人胡作非为或接管世界吗？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果部署了自动化武器，它们也会有士兵那样的难题：有时难以分别朋友与敌人、平民与敌军。而且可能会有军事事故造成平民伤亡，或者机器人受到干扰与网络攻击。也因为后者，一些军事专家预测自动化武器可能需要封闭操作系统，没有电子通讯。如果系统行为不准确的话，这样做能防止有人凌驾于自动化控制器之上。但在可预见的未来，自动化武器可能会变得很常见，在有限的任务中被使用。但在全局规模上，它们很难自己编程出计划。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;常见误解&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;我们可以按下「关闭」按钮。「关闭」按钮会使得自动化武器在网络攻击面前变得很脆弱。这样的通信频道在战争中也是如此。此外，通用智能系统会被赋予一项任务，防止自己的「关闭」按钮被按下。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;18. 人工智能的「存在风险」是什么？它是真的吗？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;关于人工智能风险的早期警告曾是非常模糊的。I.J.Good 对于人工智能的可行性提出了自己的观点：「只要机器能够聪明到告诉我们如何保持对它的控制。」人们普遍意识到，在我们的星球上如果存在一个超级智能实体，可能会出现恐慌；但另一方面，我们也都清楚更加聪明的机器会更加有用，而且更加聪明不一定意味着邪恶。事实上，论据很简单。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;假设超智能系统被设计成实现由人类设计者指定的某一目标，并假设这一目标不完全符合人类的价值观，人工智能形成的价值观（如果有）是非常难以确定的。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;任何充分有能力的智能系统将倾向于确保其自身的持续存在并且获取物理和计算资源——不是为了他们自己的目的，而是为了更好地执行人类为它设定的任务。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在我们问题的本质是你所要求的不是你所得到的。Norbert Wiener 是自动化和控制理论的先驱者，他在 1960 年写道：「如果我们使用——为达到某些目的——一些机器来代替我们做某些工作，我们最好能够清楚它们的确在按我们的想法工作。」Marvin Minsky 举了让机器计算 pi 这个例子，Nick Bostrom 则举了回形针的例子。对于人类而言，这些目标是根据人类视角提出的，这意味着计算机服务器或回形针覆盖整个银河系不是好的解决方案。一个具有能力的决策者——特别是能够通过互联网连接全球每块屏幕的智能——可能会对人类产生不可逆转的影响。幸运的是，这个问题相对比较明确，所以现在就可以开始解决。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;常见误解&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;超智能机器将变得自发地产生意识、本能地变得邪恶或伤害人类。科幻小说作者通常假定上面这些一个或多个问题来设定机器与人类的对立面，这样的假设完全是不必要的。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;我们人类发展人工智能系统，那么为什么我们要制造出来毁灭自己呢？有一些人类工智能「捍卫者」常常争辩道因为人类建立了人工智能系统，那么完全没有理由来支持这样的假设，即我们是在制造一个旨在毁灭人类的机器。这个没有抓住辩论要点，即哪个是邪恶意图，在设计者这一边还是代中间者这一边，这是存在存亡威胁的先决条件，这个问题也就是错误设定了对象。这将永远不会发生。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;19. 为什么人们会突然对人工智能如此担心？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从 2014 年开始，媒体就定期地报道如 Stephen Hawking、 Elon Musk、 Steve Wozniak and Bill Gates 那样名人的对人工智能的担忧。这些报道通常引用那些最绝望话语并省略实质担心的深层原因，通常就像「什么是人工智能现存风险」那样的问题。在许多情况下，担忧就是在阅读 Nick Bostrom 的书籍超智能（*Superintelligence*）之后产生的。另外一些当下关心这个问题的潮流也是因为人工智能的发展正在加速。这种加速可能是很多因素的集合，包括逐步完善的理论基础，它连接了很多的人工智能领域成为一个统一的整体。还有学术实验室能产出达到能够应用并解决现实世界的实际问题在人工智能方向商业投资的急剧增加也作为。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;常见误解&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如果人们是担心超人工智能就在某个角落，那么基本上人工智能研究者很少认为超智能机器就在我们周围某个角落。这并不暗示着我们应该等着，直到这个问题变得很严重！如果我们发现直径 10 英里的小行星将于 50 年后撞向地球，我们难道能够不消灭它并声称「我们会在五年的时候去关注它」？&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;20. 人工智能在接下来的几十年里会取得怎样的进步？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个领域好像并不要求人类级的通用人工智能能够达到成熟，而制造一些可信赖的高质量的产品也许在下个十年内有能实现。这就包括了语音识别、从简单的实际材料中提炼信息、对物体和行为的视觉识别、日常事物的机器人操作和自动驾驶。努力提升质量和扩展文本与视频的理解系统能制造更强劲的家用机器人，产生更为广泛有用的机器人，它能展示常识知识系统，一起学习并在遍历所有形式后表现得更好。还存在获取和组织科学知识的专业系统，它能管理复杂假说并可能对分子生物学、系统生物学和制药方面产生重大的影响。我们也许也会看到它在社会科学和政策制定有相同的影响，特别是在给它关于人类活动巨量的机器可读性数据之后，并如果机器是很可靠有用的，那么人们同样也需要机器去理解人类价值。公共和私人知识源，也就是知道和推理真实世界的系统，它不仅仅是数据的仓库，它会成为社会的组成部分。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;21. 什么是「价值定位（value alignment）」？它有什么要紧的？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;价值定位（Value alignment）就是校准人机关系具体目标价值的任务，所以机器最优选择大概来说就是无论做什么都是最大化人类的幸福感。如果没有价值定位，那么超脱人类掌控的超智能机器的出现就是不可忽视的风险。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;常见误解&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;「&lt;/span&gt;我们所有需要的就是阿西莫夫定律（Asimov's laws）&lt;span&gt;」&lt;/span&gt;。阿西莫夫定律本质上就是一些条款：它们给人类创造出各种故事情节提供灵感，但是基本对约束机器人没有什么有用的信息，因为它没有更多具体的细节。它们的基本结构为一组规则而不是效用函数，这是很有问题的：它们的词典式结构（例如任何对人类的伤害是比所有机器人的损害还要严格重要地多）意味着没有给不确定性或权衡留下空间。也许机器人只为了拍死一只在以后可能叮咬人类的蚊子会跳出悬崖毁灭了自己。另外，它也许会锁上人类汽车的门，因为坐车会提高人类受伤的可能性。最后，基于最大化人类效用的方法，对于第三条法则是没有必要的（机器人自我保护），因为机器人不保证自身的存在是不能为人类效用做出贡献的，还会令其拥有者十分失望。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;22. 对于存在主义风险（existential risk），人工智能社区做了什么？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;许多关于人工智能的存在主义风险的讨论都是处于人工智能社区主流之外的，它们是从人工智能研究最初到最主要的反动力。在 2008 年的时候，AAAI（美国人工智能学会）就举行了个座谈会来讨论这个问题。座谈会中期报告就指出了存在的一些长期问题，并降低了一些人工智能对人类社会风险的想法。最近，在 2015 年 1 月 Puerto Rico 由 Future of Life Institute 主办的会议上，参会者和随后参加者共六千多人共同签署了一份公开信，强烈呼吁应该有关注这些风险问题的研究和提出一个更加详细的研究议程。随后，Elon Musk 为支持这方面的研究而拿出了 1000 万美元。另外，Eric Horvitz 已经建立个期望追踪风险问题并在需要时给出政策建议的长期研究。最后还有 AAAI 也已经建立了一个关注人工智能影响和伦理问题（Impact of AI and Ethical Issues）的常务委员会。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;常见误解&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;「&lt;/span&gt;规约或控制研究是不可能的&lt;span&gt;」&lt;/span&gt;。有些人辩称没办法避免消极后果，因为研究进展是无法停止和规约的。实际上这种声称本身就是错误的：在 1975 年关于基因重组的阿西洛马会议（Asilomar Conference）就成功地发起自愿活动中止了设计制造人类遗传性基因修饰，并一直持续成为了国际准则。另外，如果实现人类级的人工智能研究未加抑制（这个是很可能出现的），那么在方法上开始谨慎地研究确保人工智能系统在我们掌控下是十分重要的。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;23. 我能提供什么帮助吗？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你是一个人工智能研究者（或对这方面感兴趣的经济学家、伦理学家、政治学者、未来主义者和律师），从 2015 年波多黎各会议（Puerto Rico conference）在研究议程中就已经兴起了一个主题，即在主要的人工智能会议上会举行相应的研讨会，比如说 AAAI Fall 和 Spring Symposium series 等等。FHI、CSER、 FLI 和 MIRI 网站都有更多的信息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;常见误解&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;「&lt;/span&gt;完成这些是没什么困难的&lt;span&gt;」。&lt;/span&gt;我们不管做什么都无法改变未来，这些事都终将发生。也没有什么能离真相更近一点的，我们不能预测未来，因为我们正在创造未来，这是我们集体的选择。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译文章，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Mon, 21 Nov 2016 14:24:11 +0800</pubDate>
    </item>
    <item>
      <title>视频 | Yann LeCun CMU 演讲：人工智能的下一个前沿——无监督学习</title>
      <link>http://www.iwgc.cn/link/3592115</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自CMU&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;上个月 Yann LeCun 在 CMU 做了一场讲座，讲解了人工智能中的下一个发展前沿：无监督学习。几天前，CMU 官方放出了此次讲座的视频，共计 1 小时 15 分钟。机器之心对此视频内容进行了摘要概述，希望对读者了解无监督学习有所帮助。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8gsdO8GAUKvdwVZiaUXzb3FNoIsxEETia9zH4TRXHwLsPTb2BR1m0RcgMiab11LviaXzticf9rE3icvcmg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在观看视频前，小编先为大家出一道题。这张图包含了如今人工智能领域的众多大牛：Hinton、Michael Jordan、LeCun 都在内，你能发现他们吗？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;iframe class="video_iframe" data-vidtype="1" style="   z-index:1; " height="375" width="500" frameborder="0" data-src="https://v.qq.com/iframe/preview.html?width=500&amp;amp;height=375&amp;amp;auto=0&amp;amp;vid=y0348sofhrw" allowfullscreen=""&gt;&lt;/iframe&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;视频摘要：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;过去几年，人工智能领域的快速发展得益于深度学习和神经网络的发展，再加上大型数据集和高速 GPU 的可用性。我们如今已经有了能与人类相媲美的图像识别系统，它们将变革自动驾驶交通和医疗图像理解在内的众多领域。但目前，大部分系统都是使用监督学习，机器在人工标注的输入上进行训练。接下来几年的一项挑战是让机器从原始的、无标记数据中学习，比如视频或文本。这也就是无监督学习。如今的人工智能系统不能处理人类或动物通过观察世界而获得的「常识」。人工智能领域内的一些人将无监督学习视为通往机器拥有常识道路上的关键。在此视频中，Yann LeCun 回顾了无监督学习方法，讲解了深度学习的一些基础概念。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;PPT 目录：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="list-style-type: decimal;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;神经网络简述&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;记忆增强网络（微分计算）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;人工智能的障碍&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;智能系统的架构&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;学习预测世界的 Forward Models&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;对抗训练&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;视频预测&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;一、神经网络简述&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8gsdO8GAUKvdwVZiaUXzb3FJKht7KTfhTfloYonE3vORNO8NfNSFOP6a7RbibibP1jHQyUHIUd0xotg/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;神经科学激发了早期在人工智能与机器学习中的研究&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8gsdO8GAUKvdwVZiaUXzb3FCxJhjGf1tW5UzDL7mg4gGbAT0ibyuu8wdnLlvc2iaicTIicoDCBib2tbRwQ/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;监督学习&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8gsdO8GAUKvdwVZiaUXzb3FWoYxJYbvlxDYkicGugF89b2csPQvMMiajYoVQTTAKSGKKYKZnQ8YJ4ZA/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;多层神经网络&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8gsdO8GAUKvdwVZiaUXzb3F5GC79zMcms714dYsN850aVzWtclEkUvQ8PIYHWKPW8OEiaSr80nQibvw/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过反向传播计算梯度&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8gsdO8GAUKvdwVZiaUXzb3FddqkicNgj0oBzXMt0qwbibLNpCYMWBdIHXaku7vmM25icmu1YPvm9wnLg/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;卷积神经网络架构&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8gsdO8GAUKvdwVZiaUXzb3FEfibRKMGSUg0p3rkE6XRoSMw43ftp6H8a39ZBasfIXa5FVe4fHQBMnA/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;深度卷积网络进行物体识别&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8gsdO8GAUKvdwVZiaUXzb3FWLA1vm7icr8raVpxyFlib8tS8kMF5icjqRZKpyxspBxHZicviaPCibcvew5A/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;深度学习=学习层级表征&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8gsdO8GAUKvdwVZiaUXzb3FskJiavIbQuichWesQVekuJfibYudbqlHl7ENocMZWzasPfdaUSicERSicYg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;视觉皮层中的层级架构&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8gsdO8GAUKvdwVZiaUXzb3FHxrkJGgqeluTT4hDwxcwIgEETN92lHVf5DLiaxLwwsU8WiansboGiaHPA/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;监督卷积网络&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8gsdO8GAUKvdwVZiaUXzb3Fnic9Elib1aiaCkUVzCLyMUGF5jOhJSBuEAOtMfVeTR6KBNRicOnvL0mTww/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;汽车中的卷积网络&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8gsdO8GAUKvdwVZiaUXzb3FAByIdY1UlmdfibV4CAC1AXBBQ26fHicEf2brmprBxcVB1XZ8oD0iaZmibQ/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718597&amp;amp;idx=1&amp;amp;sn=56aa4e5deff99620fe6ed42000903849&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718597&amp;amp;idx=1&amp;amp;sn=56aa4e5deff99620fe6ed42000903849&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;"&gt;&lt;span&gt;DeepMask：ConvNet Locates 和识别物体&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;二、记忆增强网络（微分计算）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8gsdO8GAUKvdwVZiaUXzb3F5RkMAybJSnXC94K2crFJcEzPicMGYtGU41wQTsuCQHCF3QBew54nx5Q/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8gsdO8GAUKvdwVZiaUXzb3FF8STZ7aQOF7ZGJgQVnCVY3JQgH0ibNGTKjOQ0Uo8jB6DlaoeLnuDdhw/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;用记忆模块增强神经网络&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8gsdO8GAUKvdwVZiaUXzb3FRcHsY4CvgLw8icQxMAMGPWDfbs0iczXwibSeEiaOjOictMxRwO3m3DCLetw/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;实体循环神经网络&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;三、人工智能的障碍&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8gsdO8GAUKvdwVZiaUXzb3FHGHvtZ3yMv0tQBD4vy3CyvmfFrnTy9l2N4muRHvpYLpkJwEsnKPVDg/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8gsdO8GAUKvdwVZiaUXzb3F2MSkbsQ9Yz78DjfcpSgPwFEYc09rfGgGic64MewxMtBX6ZDAqJxvR1Q/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能进展中的障碍&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8gsdO8GAUKvdwVZiaUXzb3FW8uU19BReWzltawia3pmf06NjUiaKlibCicGVibr0Xmib30qcEv7RpFCbiaVg/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器需要预测多少信息？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;四：智能系统的架构&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8gsdO8GAUKvdwVZiaUXzb3F7md737vdofAT9XGTJXbqacykYicjFl6thiclibBdJQOF4m4Jg3k8icVB1w/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8gsdO8GAUKvdwVZiaUXzb3FnxbdNHEadMKsEyXaXD39xKG3sr2708UzP0zjkRJY8zFogMpicRHCWCQ/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能系统：学习代理+不便的目标&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8gsdO8GAUKvdwVZiaUXzb3F1qDIK5Xqy3pVy7G1EerkevHveyMS5ib7BqwU0PXmKQlbuT1I4icY8zqQ/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能系统：预测+规划=推理&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;五、学习预测世界的 Forward Models&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8gsdO8GAUKvdwVZiaUXzb3F7Cj9858VicmL4YKYRia6BiaicGSzVrm6Mw2M2zv6zUNMAqg3jNBDnDribFw/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8gsdO8GAUKvdwVZiaUXzb3FN5ia9kcV61lLxdVt3a8hr1Cc9OGXOjEQSyC63GCcRZdcErlQicicMOWkA/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8gsdO8GAUKvdwVZiaUXzb3Fhou9LNhscqN0HibkHaibt923OrWicPrQUOFWicjUULMWA2VXJugxbbwtZQ/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;基于能量的无监督学习&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8gsdO8GAUKvdwVZiaUXzb3Fpleq7rkpawOibHcbgtXTDY9fWcVTj0DAs1MxcicAib5fyyyalC8aKJbCQ/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;建立能量函数的7个策略&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;六：对抗训练&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8gsdO8GAUKvdwVZiaUXzb3Fvvr2ic88ibEVibShyrUQKlOY28hITiaDlRBpAgJ6krMBASA8fyHax16Vzg/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8gsdO8GAUKvdwVZiaUXzb3FhmYv8ujOv6AyicUicOJCVjjhibk5TrEz9SW5KJDEAQ25PHMWyVDGmfBcQ/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8gsdO8GAUKvdwVZiaUXzb3F0VpM4Qib7wo7Dxe1biaLgUISjc3HcUv6yGTSMErHGVo52J4FeibHH6GYg/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8gsdO8GAUKvdwVZiaUXzb3FVxqP76xbJCsEtEvX4xRPvTC6HukXGPapHAI2l11jfkW8DuV7wiakaTw/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 ImageNet 128×128 像素图像上基于能量的 GAN 训练&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;七：视频预测&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8gsdO8GAUKvdwVZiaUXzb3FlTPr2jugXILbLalTHfJq5HddqVNkferve8dSRJ2dxqxicjJoJZwNO3Q/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8gsdO8GAUKvdwVZiaUXzb3FH0XmNTT0HBsnccoo0yZIbycs5WzzKry2pcl9v5FomoMsRflTyloIKw/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;进行视频预测的多尺度卷积&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8gsdO8GAUKvdwVZiaUXzb3FbN9SEFgyFVJklKVFMJ9cqK28pkbrJxGhtSW2oRsdOtR4KELT00sKicQ/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;预测式无监督学习&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;视频中在演讲完之后，LeCun 还与 CMU 的学生进行了长时间的互动，感兴趣的同学可以观看视频。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译文章，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Mon, 21 Nov 2016 14:24:11 +0800</pubDate>
    </item>
    <item>
      <title>技术 | 深度解读最流行的优化算法：梯度下降</title>
      <link>http://www.iwgc.cn/link/3592116</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自sebastianruder&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：沈泽江&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;梯度下降法，是当今最流行的优化（optimization）算法，亦是至今最常用的优化神经网络的方法。本文旨在让你对不同的优化梯度下降法的算法有一个直观认识，以帮助你使用这些算法。我们首先会考察梯度下降法的各种变体，然后会简要地总结在训练（神经网络或是机器学习算法）的过程中可能遇到的挑战。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目录：&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;梯度下降的各种变体&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="list-style-type: decimal;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;批量梯度下降（Batch gradient descent）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;随机梯度下降（Stochastic gradient descent）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;小批量梯度下降（Mini-batch gradient descent）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;面临的挑战&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;梯度下降的优化算法&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="list-style-type: decimal;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Momentum法&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Nesterov加速梯度法&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Adagrad法&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Adadelta法&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;RMSprop法&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;适应性动量估计法（Adam）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;几种算法的可视化&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;该选择哪种优化器&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;对SGD进行平行或分布式运算&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="list-style-type: decimal;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Hogwild!&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Downpour SGD&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;容忍延迟的SGD算法&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;TensorFlow&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;弹性平均梯度下降法（Elastic Averaging SGD）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;优化SGD的其他手段&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="list-style-type: decimal;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;重排（Shuffling ）和递进学习（Curriculum Learning）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;批量标准化（Batch normalization）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;早停（Early Stopping）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;梯度噪声（Gradient noise）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;结论&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;参考资料&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;梯度下降法，是当今最流行的优化（optimization）算法，亦是至今最常用的优化神经网络的方法。与此同时，最新的深度学习程序库都包含了各种优化梯度下降的算法（可以参见如 lasagne、caffe 及 Kera 等程序库的说明文档）。但它们的算法则不被公开，都作为黑箱优化器被使用，这也就是为什么它们的优势和劣势往往难以被实际地解释。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本文旨在让你对不同的优化梯度下降法的算法有一个直观认识，以帮助你使用这些算法。我们首先会考察梯度下降法的各种变体，然后会简要地总结在训练（神经网络或是机器学习算法）的过程中可能遇到的挑战。接着，我们将会讨论一些最常见的优化算法，研究它们的解决这些挑战的动机及推导出更新规律（update rules）的过程。我们还会简要探讨一下，在平行计算或是分布式处理情况下优化梯度下降法的算法和架构。最后，我们会考虑一下其他有助于优化梯度下降法的策略。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;梯度下降法的核心，是最小化目标函数 J(θ)，其中θ是模型的参数，θ∈Rd。它的方法是，在每次迭代中，对每个变量，按照目标函数在该变量梯度的相反方向，更新对应的参数值。其中，学习率η决定了函数到达（局部）最小值的迭代次数。换句话说，我们在目标函数的超平面上，沿着斜率下降的方向前进，直到我们遇到了超平面构成的「谷底」。如果你不熟悉梯度下降法的话，你可以在这里找到一个很好的关于优化神经网络的介绍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;梯度下降法变体&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本文讨论了三种梯度下降法的变体——它们的不同之处在于，一次性使用多少数据来计算目标函数的梯度。对于不同的数据量，我们需要在参数更新准确性和参数更新花费时间两方面做出权衡。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;批量梯度下降法（Batch Gradient Descent）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Vanilla 梯度下降法（译者注：Vanilla 是早期机器学习算法相关的名词，也是如今一个机器学习 python 程序库的名字，在该处指的是后者，参见：https://github.com/vinhkhuc/VanillaML），也就是大家所熟知的批量梯度下降法，在整个数据集上（求出罚函数 J(θ 并）对每个参数 θ 求目标函数 J(θ) 的偏导数：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8gsdO8GAUKvdwVZiaUXzb3FY3Shw8qiaw7cnaZjZgibXUSibsWE6yMmUibbVgqa9K7sneHdZ0I5OFEAibg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在该方法中，每次更新我们都需要在整个数据集上求出所有的偏导数。因此批量梯度下降法的速度会比较慢，甚至对于较大的、内存无法容纳的数据集，该方法都无法被使用。同时，梯度下降法不能以「在线」的形式更新我们的模型，也就是不能再运行中加入新的样本进行运算。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;批量梯度下降法的实现代码，如下所示：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;code class=" language-python" style=" font-style: inherit; font-variant: inherit; font-weight: inherit; font-stretch: inherit; line-height: 1.5; ; ; ; ; ; ; ; ; ; ; ; ; "&gt;&lt;span&gt;for&lt;/span&gt; i &lt;span&gt;in&lt;/span&gt; range&lt;span&gt;(&lt;/span&gt;nb_epochs&lt;span&gt;):&lt;/span&gt;
 &amp;nbsp;params_grad &lt;span&gt;=&lt;/span&gt; evaluate_gradient&lt;span&gt;(&lt;/span&gt;loss_function&lt;span&gt;,&lt;/span&gt; data&lt;span&gt;,&lt;/span&gt; params&lt;span&gt;)&lt;/span&gt;
 &amp;nbsp;params &lt;span&gt;=&lt;/span&gt; params &lt;span&gt;-&lt;/span&gt; learning_rate &lt;span&gt;*&lt;/span&gt; params_grad&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于给定的迭代次数，我们首先基于输入的罚函数 loss_function 对输入的参数向量 params 计算梯度向量 params_grad。注意，最新的深度学习程序库中，提供了自动求导的功能，能够高效、快速地求给定函数对于特定参数的导数。如果你希望自己写代码求出梯度值，那么「梯度检查」会是一个不错的注意。（你可以参考这里，了解关于如何检查梯度的相关建议。）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然后，我们对参数减去梯度值乘学习率的值，也就是在反梯度方向，更新我们参数。当目标函数 J(θ) 是一凸函数时，则批量梯度下降法必然会在全局最小值处收敛；否则，目标函数则可能会局部极小值处收敛。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;随机梯度下降法（Stochastic Gradient Descent）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相比批量梯度下降法，随机梯度下降法的每次更新，是对数据集中的一个样本（x，y）求出罚函数，然后对其求相应的偏导数：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8gsdO8GAUKvdwVZiaUXzb3Fjv3r6W8AicUHibnaDPJwCFl5VzaIoFbqYtmCkn4rSLaDawrtHxPEsG0A/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因为批量梯度下降法在每次更新前，会对相似的样本求算梯度值，因而它在较大的数据集上的计算会有些冗余（redundant）。而随机梯度下降法通过每次更新仅对一个样本求梯度，去除了这种冗余的情况。因而，它的运行速度被大大加快，同时也能够「在线」学习。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;随机梯度下降法更新值的方差很大，在频繁的更新之下，它的目标函数有着如下图所示的剧烈波动。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8gsdO8GAUKvdwVZiaUXzb3FQic5YJX97yics5iaK2DuMeyiat9HjUfcfWKnrHqvqCpBfbdCOGBptrDvAA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;—image—SGD 函数波动，来源：Wikipedia&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相比批量梯度下降法的收敛会使目标函数落入一个局部极小值，SGD 收敛过程中的波动，会帮助目标函数跳入另一个可能的更小的极小值。另一方面，这最终会让收敛到特定最小值的过程复杂化，因为该方法可能持续的波动而不停止。但是，当我们慢慢降低学习率的时候，SGD 表现出了与批量梯度下降法相似的收敛过程，也就是说，对非凸函数和凸函数，必然会分别收敛到它们的极小值和最小值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相比批量梯度下降法的代码，在如下的代码中，我们仅仅加入了一个循环，用以遍历所有的训练样本并求出相应的梯度值。注意，如这里所说，在每次迭代中，我们会打乱训练数据集。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;code class=" language-python" style=" font-style: inherit; font-variant: inherit; font-weight: inherit; font-stretch: inherit; line-height: 1.5; ; ; ; ; ; ; ; ; ; ; ; ; "&gt;&lt;span&gt;for&lt;/span&gt; i &lt;span&gt;in&lt;/span&gt; range&lt;span&gt;(&lt;/span&gt;nb_epochs&lt;span&gt;):&lt;/span&gt;
 &amp;nbsp;np&lt;span&gt;.&lt;/span&gt;random&lt;span&gt;.&lt;/span&gt;shuffle&lt;span&gt;(&lt;/span&gt;data&lt;span&gt;)&lt;/span&gt;
 &amp;nbsp;&lt;span&gt;for&lt;/span&gt; example &lt;span&gt;in&lt;/span&gt; data&lt;span&gt;:&lt;/span&gt;
 &amp;nbsp; &amp;nbsp;params_grad &lt;span&gt;=&lt;/span&gt; evaluate_gradient&lt;span&gt;(&lt;/span&gt;loss_function&lt;span&gt;,&lt;/span&gt; example&lt;span&gt;,&lt;/span&gt; params&lt;span&gt;)&lt;/span&gt;
 &amp;nbsp; &amp;nbsp;params &lt;span&gt;=&lt;/span&gt; params &lt;span&gt;-&lt;/span&gt; learning_rate &lt;span&gt;*&lt;/span&gt; params_grad&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;小批量梯度下降法（Mini-Batch Gradient Descent）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;小批量梯度下降法集合了上述两种方法的优势，在每次更新中，对 n 个样本构成的一批数据，计算罚函数 J(θ)，并对相应的参数求导：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8gsdO8GAUKvdwVZiaUXzb3Fohh6D6A1dibYskXr8ibtKuUo09XBPMXn9HuXY5ULS5bOf2EysVpfmG1g/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这种方法，(a) 降低了更新参数的方差（variance），使得收敛过程更为稳定；(b) 能够利用最新的深度学习程序库中高度优化的矩阵运算器，能够高效地求出每小批数据的梯度。通常一小批数据含有的样本数量在 50 至 256 之间，但对于不同的用途也会有所变化。小批量梯度下降法，通常是我们训练神经网络的首选算法。同时，有时候我们也会使用随机梯度下降法，来称呼小批量梯度下降法（译者注：在下文中，我们就用 SGD 代替随机梯度下降法）。注意：在下文对于随机梯度法优化的介绍中，为方便起见，我们会省略式子中的参数 x(i:i+n),y(i:i+n)。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如下的代码所示，我们不再对每个样本进行循环，而是对每批带有 50 个样本的小批数据进行循环：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;code class=" language-python" style=" font-style: inherit; font-variant: inherit; font-weight: inherit; font-stretch: inherit; line-height: 1.5; ; ; ; ; ; ; ; ; ; ; ; ; "&gt;&lt;span&gt;for&lt;/span&gt; i &lt;span&gt;in&lt;/span&gt; range&lt;span&gt;(&lt;/span&gt;nb_epochs&lt;span&gt;):&lt;/span&gt;
 &amp;nbsp;np&lt;span&gt;.&lt;/span&gt;random&lt;span&gt;.&lt;/span&gt;shuffle&lt;span&gt;(&lt;/span&gt;data&lt;span&gt;)&lt;/span&gt;
 &amp;nbsp;&lt;span&gt;for&lt;/span&gt; batch &lt;span&gt;in&lt;/span&gt; get_batches&lt;span&gt;(&lt;/span&gt;data&lt;span&gt;,&lt;/span&gt; batch_size&lt;span&gt;=&lt;/span&gt;&lt;span&gt;50&lt;/span&gt;&lt;span&gt;):&lt;/span&gt;
 &amp;nbsp; &amp;nbsp;params_grad &lt;span&gt;=&lt;/span&gt; evaluate_gradient&lt;span&gt;(&lt;/span&gt;loss_function&lt;span&gt;,&lt;/span&gt; batch&lt;span&gt;,&lt;/span&gt; params&lt;span&gt;)&lt;/span&gt;
 &amp;nbsp; &amp;nbsp;params &lt;span&gt;=&lt;/span&gt; params &lt;span&gt;-&lt;/span&gt; learning_rate &lt;span&gt;*&lt;/span&gt; params_grad&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;面临的挑战&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;由于 Vanilla 小批量梯度下降法并不能保证良好地收敛，这给我们留下了如下待解决的挑战：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;选择适当的学习率是一个难题。太小的学习率会导致较慢的收敛速度，而太大的学习率则会阻碍收敛，并会引起罚函数在最小值处震荡，甚至有可能导致结果发散；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;我们可以设置一个关于学习率地列表，通过如退火的方法，在学习过程中调整学习率——按照一个预先定义的列表、或是当每次迭代中目标函数的变化小于一定阈值时来降低学习率。但这些列表或阈值，需要根据数据集地特性，被提前定义。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;此外，我们对所有的参数都采用了相同的学习率。但如果我们的数据比较稀疏，同时特征有着不同的出现频率，那么我们不希望以相同的学习率来更新这些变量，我们希望对较少出现的特征有更大的学习率。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在对神经网络最优化非凸的罚函数时，另一个通常面临的挑战，是如何避免目标函数被困在无数的局部最小值中，以导致的未完全优化的情况。Dauphin 及其他人 [19] 认为，这个困难并不来自于局部最小值，而是来自于「鞍点」，也就是在一个方向上斜率是正的、在一个方向上斜率是负的点。这些鞍点通常由一些函数值相同的面环绕，它们在各个方向的梯度值都为 0，所以 SGD 很难从这些鞍点中脱开。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;梯度下降的优化算法&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在如下的讨论中，我们将会列举一些应对上述问题的算法，它们被广泛应用于深度学习社区。同时，我们不会讨论那些不能应用于高维数据集的方法，例如牛顿法等针对二阶问题的方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;动量法&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;SGD 很难在陡谷——一种在一个方向的弯曲程度远大于其他方向的表面弯曲情况——中找到正确更新方向。而这种陡谷，经常在局部极值中出现。在这种情况下，如图 2 所示，SGD 在陡谷的周围震荡，向局部极值处缓慢地前进。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8gsdO8GAUKvdwVZiaUXzb3Fgj4nFAhmBe5GwJYxdlhwQEHdd1k8bPpMxleh5wkAZo9leVnpntIBRQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;动量法 [2]，如图 3 所示，则帮助 SGD 在相关方向加速前进，并减少它的震荡。他通过修改公式中，在原有项前增加一个折损系数γ，来实现这样的功能：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8gsdO8GAUKvdwVZiaUXzb3FIfZcxibLVG01xq25K1h04A8Y2KLMCXAgRVPYnr033mve5R2KbiaAkp4Q/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;注意：在其他的一些算法实现中，公式中的符号也许有所不同。动量项 γ 往往被设置为 0.9 或为其他差不多的值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从本质上说，动量法，就仿佛我们从高坡上推下一个球，小球在向下滚动的过程中积累了动量，在途中他变得越来越快（直到它达到了峰值速度，如果有空气阻力的话，γ&amp;lt;1）。在我们的算法中，相同的事情发生在我们的参数更新上：动量项在梯度指向方向相同的方向逐渐增大，对梯度指向改变的方向逐渐减小。由此，我们得到了更快的收敛速度以及减弱的震荡。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Nesterov 加速梯度法&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但当一个小球从山谷上滚下的时候，盲目的沿着斜率方向前行，其效果并不令人满意。我们需要有一个更「聪明」的小球，它能够知道它再往哪里前行，并在知道斜率再度上升的时候减速。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Nesterov 加速梯度法（NAG）是一种能给予梯度项上述「预测」功能的方法。我们知道，我们使用动量项γvt-1 来「移动」参数项θ。通过计算θ-γvt-1，我们能够得到一个下次参数位置的近似值——也就是能告诉我们参数大致会变为多少。那么，通过基于未来参数的近似值而非当前的参数值计算相得应罚函数 J(θ-γvt-1) 并求偏导数，我们能让优化器高效地「前进」并收敛：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8gsdO8GAUKvdwVZiaUXzb3F3ExjXIYfgHI39lQ1eqoEHKia0jL9aUZs30zekCslkD3P3qxXLd9vodw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在该情况下，我们依然设定动量系数γ 在 0.9 左右。如下图 4 所示，动量法首先计算当前的梯度值（小蓝色向量），然后在更新的积累向量（大蓝色向量）方向前进一大步。但 NAG 法则首先（试探性地）在之前积累的梯度方向（棕色向量）前进一大步，再根据当前地情况修正，以得到最终的前进方向（绿色向量）。这种基于预测的更新方法，使我们避免过快地前进，并提高了算法地响应能力（responsiveness），大大改进了 RNN 在一些任务上的表现 [8]。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8gsdO8GAUKvdwVZiaUXzb3FIn5Py92O1T7QGE52bYibURplrMOIibCjfGibfXzdGXqlI9N0xXa2XEXIw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;--image4: Nesterov Update 法，来源：G. Hinton's lecture 6c--&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;参考这里，以查看 Ilya Sutskever 在它博士论文中，对 NAG 机理的更为详尽的解释 [9]。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因为我们现在能根据我们罚函数的梯度值来调整我们的更新，并能相应地加速 SGD，我们也希望能够对罚函数中的每个参数调整我们的更新值，基于它们的重要性以进行或大或小的更新。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Adagrad 法&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Adagrad[3] 是一个基于梯度的优化算法，它的主要功能是：它对不同的参数调整学习率，具体而言，对低频出现的参数进行大的更新，对高频出现的参数进行小的更新。因此，他很适合于处理稀疏数据。Dean 等人 [14] 发现，Adagrad 法大大提升了 SGD 的鲁棒性，并在谷歌使用它训练大规模的神经网络，其诸多功能包括识别 Youtube 视频中的猫。此外，Pennington 等人 [5] 使用它训练 GloVe 单词向量映射（Word Embedding），在其中不频繁出现的词语需要比频繁出现的更大的更新值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这之前，我们对于所有的参数使用相同的学习率进行更新。但 Adagrad 则不然，对不同的训练迭代次数 t，adagrad 对每个参数都有一个不同的学习率。我们首先考察 adagrad 每个参数的的更新过程，然后我们再使之向量化。为简洁起见，我们记在迭代次数 t 下，对参数θi 求目标函数梯度的结果为 gt,i：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8gsdO8GAUKvdwVZiaUXzb3FzmdChz7rmz0aQKiaj8c5MUkcW4iaNMndYxk874X4J83XfOCVgO8N9MCw/0?wx_fmt=png"/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;那么普通 SGD 的更新规则为：&lt;/span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8gsdO8GAUKvdwVZiaUXzb3FPr2dLchbeibCiaSB8TdRHocx0R2dibtg2HBKDZqZ3PuibstjoOH2UtAaoQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而 adagrad 将学习率η进行了修正，对迭代次数 t，基于每个参数之前计算的梯度值，将每个参数的学习率η按如下方式修正：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8gsdO8GAUKvdwVZiaUXzb3FOTnL5YKb855xeue5ghyRSkzwEuQz6RCibEDia1CP6jj7tEHujovgicxrQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其中 是一个对角阵，其中对角线上的元素是从一开始到 时刻目标函数对于参数 梯度的平方和。是一个平滑项，以避免分母为 0 的情况，它的数量级通常在。有趣的是，如果不开方的话，这个算法的表现会变得很糟。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因为 在其对角线上，含有过去目标函数对于参数 梯度的平方和，我们可以利用一个元素对元素的向量乘法，将我们的表达式向量化：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8gsdO8GAUKvdwVZiaUXzb3F8ZjrDWiciaOdx4NT3D92EgSgjvKrBOOZnu0VS4SQV4dQV8jvUmjcJXeA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Adagrad 主要优势之一，是它不需要对每个学习率手工地调节。而大多数算法，只是简单地使用一个相同地默认值如 0.1，来避免这样地情况。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Adagrad 地主要劣势，是他在分母上的项中积累了平方梯度和。因为每次加入的项总是一个正值，所以累积的和将会随着训练过程而增大。因而，这会导致学习率不断缩小，并最终变为一个无限小值——此时，这个算法已经不能从数据中学到额外的信息。而下面的算法，则旨在解决这个问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Adadelta 法&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Adadelta 法 [6] 是 Adagrad 法的一个延伸，它旨在解决它学习率不断单调下降的问题。相比计算之前所有梯度值的平方和，Adadelta 法仅计算在一个大小为 的时间区间内梯度值的累积和。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但该方法并不会存储之前 个梯度的平方值，而是将梯度值累积值按如下的方式递归地定义：它被定义为关于过去梯度值的衰减均值（decade average），当前时间的梯度均值是基于过去梯度均值和当前梯度值平方的加权平均，其中是类似上述动量项的权值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8gsdO8GAUKvdwVZiaUXzb3FLRfdrkPHMDkQXT5gRkx8KkmC31ibc0U8xUpm0B5rRyEU7mmxxP6C9ug/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;与动量项的设定类似，我们设定 为以 0.9 左右的值。为明确起见，我们将我们的 SGD 更新规则写为关于参数更新向量 的形式：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8gsdO8GAUKvdwVZiaUXzb3FFiataS8tuVIMBlfbsTt5CnVzz0vaVd3EvZWxvUWPMyuAYJgo2F40b1w/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;由此，我们刚刚在 Adagrad 法中推导的的参数更新规则的向量表示，变为如下形式：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8gsdO8GAUKvdwVZiaUXzb3FygCF0qc0WGLC9wXXGibCTzpLop78BNU685QTnrBCfSJErsE5tEDAYwA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们现在将其中的对角矩阵 用上述定义的基于过去梯度平方和的衰减均值 替换：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8gsdO8GAUKvdwVZiaUXzb3FB0JA2TsibQrxsTaPnMqSnmvzNLorkgXWkYiaZgVNzIezesicLfGcYlrlA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因为分母表达式的形式与梯度值的方均根（root mean squared,RMS）形式类似，因而我们使用相应的简写来替换：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8gsdO8GAUKvdwVZiaUXzb3FRoYhWOPlXic4FMxFOc9LEo9JqN3eEbft0yf7eKia5tRkW4EkkQyoEZnw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;作者还注意到，在该更新中（在 SGD、动量法或者 Adagrad 也类似）的单位并不一致，也就是说，更新值的量纲与参数值的假设量纲并不一致。为改进这个问题，他们定义了另外一种指数衰减的衰减均值，他是基于参数更新的平方而非梯度的平方来定义的：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8gsdO8GAUKvdwVZiaUXzb3FGrkh5fZR95UvJxDWVicwe9HibhJwthmfkolficnyE3AqfOKFvFK3KEDbA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因此，对该问题的方均根为：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8gsdO8GAUKvdwVZiaUXzb3FpryZzWAvsUZsVfia3dLSaJwXnBD9enIIFHeGXyiaSt7ZkzkqEKxy7Ixg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因为 值未知，所以我们使用 时刻的方均根来近似。将前述规则中的学习率 替换为，我们最终得到了 Adadelta 法的更新规则：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8gsdO8GAUKvdwVZiaUXzb3F63EQXZgttGOYDeXyiaXpUbItv89ib86ibNia93UFiaiasSrFO9hqXX6UlrTg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;借助 Adadelta 法，我们甚至不需要预设一个默认学习率，因为它已经从我们的更新规则中被删除了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;RMSprop 法&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;RMSprop 是由 Geoff Hinton 在他 Coursera 课程中提出的一种适应性学习率方法，至今仍未被公开发表。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;RMSprop 法和 Adadelta 法几乎同时被发展出来。他们 解决 Adagrad 激进的学习率缩减问题。实际上，RMSprop 和我们推导出的 Adadelta 法第一个更规则相同：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8gsdO8GAUKvdwVZiaUXzb3FzwydLk7Hpiab7Dhq8hibzb7QwBP5URysD18QO2gPARWBWAaRkIqqgBxA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;RMSprop 也将学习率除以了一个指数衰减的衰减均值。Hinton 建议设定 为 0.9，对 而言，0.001 是一个较好的默认值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Adam&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;适应性动量估计法（Adam）[15] 是另一种能对不同参数计算适应性学习率的方法。除了存储类似 Adadelta 法或 RMSprop 中指数衰减的过去梯度平方均值 外，Adam 法也存储像动量法中的指数衰减的过去梯度值均值 ：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8gsdO8GAUKvdwVZiaUXzb3FKm4QoT3f16NXK4ciceKBlY0ib3SYc92ricC0rxLU1IP6lVP8MpmpKSfMw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;和 分别是梯度的一阶矩（均值）和二阶矩（表示不确定度的方差），这也就是该方法名字的来源。因为当 和 一开始被初始化为 0 向量时，Adam 的作者观察到，该方法会有趋向 0 的偏差，尤其是在最初的几步或是在衰减率很小（即 和 接近 1）的情况下。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他们使用偏差纠正系数，来修正一阶矩和二阶矩的偏差：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8gsdO8GAUKvdwVZiaUXzb3FAB8MeBXp3WvJwj89CfJMXbRpFURuxtojku8csx98TDdKiaWBunaAyww/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他们使用这些来更新参数，更新规则很我们在 Adadelta 和 RMSprop 法中看到的一样，服从 Adam 的更新规则：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8gsdO8GAUKvdwVZiaUXzb3FCaRO3Yt8zUd2TUccKoL10yh3WhnIpOXc0vO2qZk9wMNibeeR5Q3SVibg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;作者认为参数的默认值应设为：&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8gsdO8GAUKvdwVZiaUXzb3FvDpI83nP2F92ibr5KticHRKczjibQLwxBn3hXMQ5Y6w2CIZs8zdEaI0ng/0?wx_fmt=png"/&gt;&lt;br/&gt;。他们的经验表明，Adam 在实践中表现很好，和其他适应性学习算法相比也比较不错。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;算法可视化&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如下的两个动画（图像版权：Alec Radford）给了我们关于特定优化算法在优化过程中行为的直观感受。你可以参见这里，以获取 Karpathy 对相同图像的一些描述，及另关于一些相关算法的细致讨论。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在图 5 中，我们可以看到，在罚函数的等高线图中，优化器的位置随时间的变化情况。注意到，Adagrad、 Adadelta 及 RMSprop 法几乎立刻就找到了正确前进方向并以相似的速度很快收敛。而动量法和 NAG 法，则找错了方向，如图所示，让小球沿着梯度下降的方向前进。但 NAG 法能够很快改正它的方向向最小指出前进，因为他能够往前看并对前面的情况做出响应。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图 6 展现了各算法在鞍点附近的表现。如上面所说，这对对于 SGD 法、动量法及 NAG 法制造了一个难题。他们很难打破」对称性「带来的壁垒，尽管最后两者设法逃脱了鞍点。而 Adagrad 法、RMSprop 法及 Adadelta 法都能快速的沿着负斜率的方向前进。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8gsdO8GAUKvdwVZiaUXzb3FL7lSCHlvWIeCQyATDgl4Jaz6zJYAY2QqSSq6wlpicTw1zd5BUVc1Crg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如我们所见，适应性学习率方法，也就是 Adagrad 法、Adadelta 法 、RMSprop 法及 Adam 法最适合处理上述情况，并有最好的收敛效果&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;如何选择优化器？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;那么，我们该如何选择优化器呢？如果你的输入数据较为稀疏（sparse），那么使用适应性学习率类型的算法会有助于你得到好的结果。此外，使用该方法的另一好处是，你在不调参、直接使用默认值的情况下，就能得到最好的结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;总的来说，RMSprop 法是一种基于 Adagrad 法的拓展，他从根本上解决学习率骤缩的问题。Adadelta 法于 RMSprop 法大致相同，除了前者使用了。而 Adam 法，则基于 RMSprop 法添加了偏差修正项和动量项。在我们地讨论范围中，RMSprop、Adadelta 及 Adam 法都是非常相似地算法，在相似地情况下都能做的很好。Kingma 及其他人 [15] 展示了他们的偏差修正项帮助 Adam 法，在最优化过程快要结束、梯度变得越发稀疏的时候，表现略微优于 RMSprop 法。总的来说，Adam 也许是总体来说最好的选择。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有趣的是，很多最新的论文，都直接使用了（不带动量项的）Vanilla SGD 法，配合一个简单的学习率（退火）列表。如论文所示，这些 SGD 最终都能帮助他们找到一个最小值，但会花费远多于上述方法的时间。并且这些方法非常依赖于鲁棒的初始化值及退火列表。因此，如果你非常在你的模型能快速收敛，或是你需要训练一个深度或复杂模型，你可能需要选择上述的适应性模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;对 SGD 进行平行计算或分布式计算&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现如今，大规模数据集随处可见、小型计算机集群也易于获得。因而，使用分布式方法进一步加速 SGD 是一个惯常的选择。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;SGD 它本事是序列化的：通过一步一步的迭代，我们最终求到了最小值。运行它能够得到不错的收敛结果，但是特别是对于大规模的数据集，它的运行速度很慢。相比而言，异步 SGD 的运行速度相对较快，但在不同的工作机之间的关于非完全优化的沟通可能会导致较差的收敛结果。此外，我们能够对 SGD 进行平行运算而不需要一个计算机集群。下文讨论了相关的算法或架构，它们或关于平行计算或者对其进行了分布式优化。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Hogwild!&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Niu 等人提出了一种叫做 Hogwild! 的更新规则，它允许在平行 GPU 上进行 SGD 更新。处理器。这仅能在输入数据集是稀疏的时起效，在每次更新过程中仅会修正一部分的参数值。他们展示了，在这种情况下，这个更新规则达到了最优化的收敛速度，因为处理器不太会覆盖有用的信息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Downpour SGD&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Downpour SGD 是一个异步的 SGD 法变体，它被 Dean 等人 [4] 用在了谷歌的 DistBelief 架构中（它是 TensorFlow 的前身）。他对训练集地子集同步地运行模型的多个副本。这些模型将它们的更新值发送到参数服务器，服务器被分为了许多台主机。每一台主机都负责存储和上载模型的一部分参数。但是，副本之间却没有相互的通信——例如，共享权重值或者更新值——其参数面临着发散的风险，会阻止收敛。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;容忍延迟的 SGD 算法&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;McMahan 和 Streeter [12] 改良了 AdaGrad 法使之能够用于平行运算的场景。通过实现延迟容忍的算法，它不仅能能够适应于过去的梯度，还能够适应于更新的延迟。在实践中，它的表现很好。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;TensorFlow&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;TensorFlow[13] 是谷歌最近开源的一个实现和部署大规模机器学习模型的架构。它基于他们之前对于使用 DistBelief 的经验，并已在内部被部署在一系列的移动设备及大规模的分布式系统上进行计算。为了分布式执行，一个计算图被分为了许多子图给不同的设备，设备之间的通信使用了发送和接受节点对。2016 年 4 月 13 日更新：一个分布式 TensorFlow 的版本已经被发布。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;弹性平均梯度下降法（Elastic Averaging SGD）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;张等人 [14] 提出了弹性平均梯度下降法（EASGD），他使不同工作机之间不同的 SGD 以一个「弹性力」连接，也就是一个储存于参数服务器的中心变量。这允许局部变量比中心变量更大地波动，理论上允许了对参数空间更多的探索。他们的经验表明，提高的探索能力有助于在寻找新的局部极值中提升（优化器的）表现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;优化 SGD 的其他手段&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，我们将讨论一些其他手段，他们可以与前述的方法搭配使用，并能进一步提升 SGD 的效果。你可以参考 [22]，以了解一些其他常用策略。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;重排法（Shuffling）和递进学习（Curriculum Learning）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;总体而言，我们希望避免训练样本以某种特定顺序传入到我们的学习模型中，因为这会向我们的算法引入偏差。因此，在每次迭代后，对训练数据集中的样本进行重排（shuffling），会是一个不错的注意。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一方面，在某些情况下，我们会需要解决难度逐步提升的问题。那么，按照一定的顺序遍历训练样本，会有助于改进学习效果及加快收敛速度。这种构建特定遍历顺序的方法，叫做递进学习（Curriculum Learning）[16]。*这个词目前没有标准翻译，我根据表意和意义翻译成这个。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Zaremba 和 Sutskever [17] 仅使用了递进学习法训练 LSTMs 来学习简单的项目，但结果表明，递进学习法使用的混合策略的表现好于朴素策略——后者不断地重排数据，反而增加了学习过程的难度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;批量标准化（Batch Normalization）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们通常设置我们参数初值的均值和方差分别为 0 和单位值，以帮助模型进行学习。随着学习过程的进行，每个参数被不同程度地更新，相应地，参数的正则化特征也随之失去了。因此，随着训练网络的越来越深，训练的速度会越来越慢，变化值也会被放大。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;批量标准化 [18] 对每小批数据都重新进行标准化，并也会在操作中逆传播（back-propgate）变化量。在模型中加入批量标准化后，我们能使用更高的学习率且不要那么在意初始化参数。此外，批量正则化还可以看作是一种正则化手段，能够减少（甚至去除）留出法的使用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;早停（Early Stopping）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;诚如 Geoff Hinton 所言：「Early stopping (is) beautiful free lunch（早停是美妙的免费午餐，又简单效果又好）」（NIPS 2015 Tutorial Sildes, Slide 63）。在训练过程中，你应该时刻关注模型在验证集上的误差情况，并且在改误差没有明显改进的时候停止训练。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;梯度噪声（Gradient Noise）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Neelakentan 等人 [21] 在每次梯度的更新中，向其中加入一个服从合高斯分布 N(0,σ^2) 的噪声值：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8gsdO8GAUKvdwVZiaUXzb3FYT6H8dH0J0rkCS6MeibYbIicqPckYoOWD4Enx7APg1EE8JINysfvbH8A/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;并按照如下的方式修正方差：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8gsdO8GAUKvdwVZiaUXzb3FAr17OWWQ17aibiacxFxem2YGVuUgyunF4xognv0KvVvmwXnpWDz7MOaA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他们指出，这种方式能够提升神经网络在不良初始化前提下的鲁棒性，并能帮助训练特别是深层、复杂的神经网络。他们发现，加入噪声项之后，模型更有可能发现并跳出在深度网络中频繁出现的局部最小值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;结论&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在本文中，我们首先分析了梯度下降法的三个变体，在其中小批量梯度下降法最受欢迎。接着，我们研究了常用的优化 SGD 的算法，包括：动量法、Nesterov accelerated gradient 法、Adagrad 法、Adadelta 法、RMSprop 法、Adam 法及其他优化异步 SGD 的算法。最终，我们讨论了另外一些改进 SGD 的策略，包括样本重排法（shuffling）、递进学习（curriculum learning）、批量标准化（Batch Normali·zation）及早停（early stopping）等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我希望本文能增进读者关于这些优化算法的认识，能对这些算法的行为与动机有一个了解。也许我遗漏了一些常用的优化 SGD 的算法，或是你有一些自己使用 SGD 训练的技巧。如果有的话，请在下方留言区留言让我知道。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;原文连接查看参考文献：http://sebastianruder.com/optimizing-gradient-descent/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译文章，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Mon, 21 Nov 2016 14:24:11 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 为什么自然界是我们理解人工智能的最优导师？</title>
      <link>http://www.iwgc.cn/link/3592118</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自TechCrunch&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：朱思颖&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对生物体而言，进化是一个多代累积的基因改变过程，在每一代的进化过程中会有基因的剔除和基因的增加。在每一次的基因改变后，只有那些拥有适宜于生存环境基因的变异生物能够存活，而那些拥有不适宜生存环境基因的变异生物则无情的被环境淘汰。这个过程就是一次自然选择的过程。在自然选择中，生物的适应能力固然重要，但能恰到好处的拥有适宜于当前环境的特征才是关键，就像在洪水爆发的时候，能够用鳃呼吸的鱼才可以生存。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相比而言，工程设计则是一个严谨规划的过程，尽力确保过程中每一步达到预计目标。然而，随着人工智能的出现，机器学习算法的迭代具有类似生物进化的功效，使得生物进化和工程设计过程的融合成为可能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;具体细看自然进化的过程和机器学习的过程，我们可以把机器学习所需的数据（data）及其规格化处理类比为生物进化过程中的「环境」，把机器学习过程类比为「自然选择」。机器学习在训练的时候分为监督式学习、非监督式学习、增强学习、聚类、决策树以及深度学习的其他方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在自然进化过程中，虽然不同的生物在遇到相同的生存难题时会进化出各自不同的特征，但最终它们将进化出类似的特征来解决其所遇到的生存难题。鲨鱼和海豚从不同的原始生物种类进化而来，却具备相似的伤口愈合机制。在人工智能领域，我们同样能看到与此类似的现象。例如：K-均值聚类算法常被用来处理图像分割问题，通过对原始无标签的输入数据（通常是图像）进行聚类直至相似特征的数据被合理的聚分至各族群内。如果你把这个问题交给 10 个机器学习工程师，并且是处理同样输入数据集，很可能他们 每个人使用的算法都不相同，但并不妨碍最终的聚类结果。从这个维度来比较自然选择和机器学习过程，两者何其相似。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8gsdO8GAUKvdwVZiaUXzb3F5CvOSC45mPWAXcgjIrW4S94W8CFtg58EEvqGDP3ESPDxJOweCPaLdw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;那么，这与商业有何相关呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因为机器学习技术已经有了商业化的应用，目前机器学习在商业化应用上遇到的难题是如何安全稳妥并富有效率的运用机器学习技术。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;回顾科技的发展历史，大自然给了工程师们很多启发。这里，我将给出一些在商业上运用进化理论来理解人工智能潜在影响的范例。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;趋异进化：人工智能下的趋异进化，是指在这个过程中很难将同一个数据集来处理数据集类型相似的问题。就如：你用 ImageNet 数据集来处理一个目标识别的问题，最后的识别结果非常好，但这并不能够保证你在处理视频识别和面部识别时依旧可以有非常好的识别结果。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;趋同进化：人工智能的趋同进化是指一些看似不同类型的数据集处理过程，其实是同一类问题。例如：Google 借助搜索关键词来优化检索时的拼写检查功能。Google 通过跟踪用户的检索词，当你检索词的拼写和大部分人有差异时，将会出现检索词推荐，这个优化过程很人性化。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;捕食者和被捕食者或者寄生和宿主共同进化：在人工智能里，如果两个人工智能算法一起迭代，会出现很多意想不到的结果。网络安全公司（如 Cylance 和 Bromium）正在开发如何运用机器学习算法来实现不间断的系统训练，从而可以第一时间识别新的网络安全隐患。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前，只有少量的 AI 公司在帮助我们更高效的工作（X.ai 可以帮助我们规划繁忙的工作生活，Diffbot 能帮助我们更智能的管理网站等等），但这些应用还只是处于起步阶段，能够成熟到用户可以方便使用的程度，仍需极大的提升。或者说这也是它们的「进化」过程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;AI 领域还有待开垦，而生物界自然选择的过程为我们提供了一个很好的框架来理解机器学习的进化发展，并为之到来做好准备。与此同时，公司的领导层需要着重考虑如何借助 AI 来提升公司业务，并且招募相关的人才来研发出具有创新性的解决方案。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译文章，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Mon, 21 Nov 2016 14:24:11 +0800</pubDate>
    </item>
    <item>
      <title>深度 | 为何最强人工智能比不上婴儿大脑？</title>
      <link>http://www.iwgc.cn/link/3579156</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自IBTimes&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：王宇欣、候韵楚&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器可以理解语音、识别面部和安全驾驶汽车。这让人们十分讶异于近期的技术方面的进步。但是，如果人工智能领域想要实现革命性的跨越，从而建造出类人式的机器，它首先将要掌握婴儿的学习方式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「在相对最近的人工智能中，人们从想直接设计一个可以完成成人做的事情的系统转变成一种认识——即如果想要有一个灵活和强大的系统来完成成人做的事情，这个系统需要能够学习婴儿和孩子做事情的方式。」加州大学伯克利分校的发展心理学家 Alison Gopnik 说，「如果你将现在计算机可以完成的事情与 10 年前可以完成的事情相比较，它们已经取得了很大的进步，但是如果你将这些事情与一个 4 岁儿童可以做的事相比较，仍然有相当大的差距。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;婴儿和孩子使用一种和科学家用来构建科学理论的相同的方法来构建关于他们的周围的世界的理论。他们以一种系统的和实验性的努力来探索和测试他们周围的环境以及环境中的人，这对于学习至关重要。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Gopnik 最近和一组研究人员一起研究揭示了 15 个月大的孩子相比年龄更大的孩子是如何使用统计数据来更好地学习因果关系的。婴幼儿也许是更好的学习者，因为他们的大脑更加灵活或者「可塑性」更强 ；他们较少地被背景知识所影响，这也让他们有着更加开放的头脑。大脑并非是不变的，而是随着每一次学习的经验而改变。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过将发展心理学家和计算学家的专业知识相结合，人们可以揭示出世界上最好的学习型大脑是如何工作的，并且将其计算能力转化到机器的身上。最近，人工智能需要大量的数据来提取模式和结论，但那些对周围世界有相对较少数据的婴儿使用的是一种被称为贝叶斯学习（Bayesian learning）的统计评估方法（参阅机器之心文章《&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=401831226&amp;amp;idx=1&amp;amp;sn=daa0f6faa0e13a9e2c857d24d7784318&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=401831226&amp;amp;idx=1&amp;amp;sn=daa0f6faa0e13a9e2c857d24d7784318&amp;amp;scene=21#wechat_redirect"&gt;深度 | 大脑认知机制是贝叶斯式的吗？&lt;/a&gt;》）。也就是说，这种理解并非是基于一个结果的已知频率（婴儿所没有的信息），而是基于当前的知识推断出的事情发生的可能性，其随着新接收到的信息而连续调整。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「令人震惊的是，婴儿可以只看到一次或听到一个新单词的时候，他们就已经对这个新词的可能意思和可能的使用方法等有了一个很好的认识了；」Gopnik 说。「所以这些贝叶斯方法很好地解释了在没有充足数据的情况下，这些孩子为什么如此擅长于学习。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;婴儿们使用概率模型通过组合概率和可能性（probabilities and possibilities）来得出结论，从而创造出各种假设。随着大脑的成熟，它变得更加专业化以便执行复杂的功能，因此也变得不那么灵活，越来越难以随着时间而改变。年长的学习者发展出了有偏见的观点，因为他们更多地了解世界并且加强某些神经连接，这阻碍了他们基于很少的信息来形成具有创新性的假设和抽象理论的能力。这种能力使得 5 岁以下的婴儿和儿童茁壮成长。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「这种权衡关系就是，你知道的越多，你就越难以考虑新的可能性，」Gopnik 说。「你知道的越多，你就越依赖于你知道的东西，而对新的东西则不能保持一个开放的态度。从进化的角度来看，婴儿的整体情况就是他们不知道那么多，所以他们可以更好地学习新的东西。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在婴儿刚出生的几年，每一秒都有 700 个新神经连接生成，这是让一个灵活的大脑处理快速积累的来自环境和社交的信息所必需的部分。比起在成年时期重新组合大脑回路，生命早期的可塑性使得从零建立大脑的架构更加容易。贝叶斯学习已经被证明是儿童发展中的一个强大工具，计算机科学家正在使用该模型设计智能学习机。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;麻省理工学院大脑和认知科学系的教授、计算认识科学家 Joshua Tenenbaum 说：「贝叶斯算法正在试图捕捉婴儿的学习模式，」他正在与 Gopnik 合作进一步研究其计算机和心理学的混合领域。「当这些孩子进入了真实的世界时，就已经有准备好的基本的构建模块来让他们理解一些最复杂的概念。然后，他们有学习机制——即以这些最初的构建模块来尝试从稀疏数据推理，并创造因果理论。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人类的大脑，不管处在哪一个发展阶段，都是被设计通过一系列的感觉系统，包括视觉、听觉、嗅觉、味觉、触觉、空间取向和平衡从而进入物理世界。当一个人只有有限的数据时，大脑就会填补空白，这是一种被称为「退化（degeneracy）」的神经结构现象。尽管婴儿的大脑缺乏一个或多个感知，但是他们还是尤其擅长处理信息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Tenenbaum 说：「为了理解世界，孩子们会像科学家一样学习，这包括形成理论、进行试验、玩耍并且看看到他们可有所发现的东西，积极思考什么是正确的方法来测试他们的理论或者应对一些他们没有想到的东西，并试图找出什么是错，什么是对。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;采取孩子的措施&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Tenenbaum 和来自纽约大学和多伦多大学的研究人员团队合作设计了一种能够以更有效和更复杂的方式捕获新知识的人工智能软件。在 2015 年 12 月，他们的研究论文《Human-level concept learning through probabilistic program induction》指出用于创建计算机的机器学习算法接近我们所处理信息的方式；该论文已发表在 Science 杂志上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;新的人工智能程序可以在看到一个样本之后就像人类一样准确地识别手写字符。使用贝叶斯程式学习框架，软件能够为每个至少看到一次的手写字符生成一个独特的指令。但是，当机器面临一个不熟悉的特性的时候，这种算法的独特功能就发挥了作用。它从数据搜索转换到寻找匹配，使用概率程序并通过组合已经见过的字符的部分和子部分来创建一个新的字符以此检测其假设——即当婴儿面对他们从未见过的角色和对象时，他们如何从有限的数据中学习到丰富的概念。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然而，软件仍然无法通过形成原始假设自主学习方式模仿孩子学习的方式。当研究人员能够设计具有原始假设和真实的目标的软件时（例如产生识别字符的愿望而非遵循研究者的指令），人工智能系统的潜力将会有里程碑式的转变。没有自我驱动的目标，人工智能系统就限制了他们自主运作的潜力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Tenenbaum 说：「使用越来越多的数据进行的持续性学习是任何人工智能系统都想要做到的，但自主学习却是棘手的，因为总会有人来操控整件事情，数据的数量与类型也由他们给出。婴儿是自主选择的，但是要让人工智能系统能够更自主地构建自己学习过程仍旧是一个众所周知的挑战。目前的人工智能系统并没有建立任何目标，应此它们也无法为自己的学习负责。当一个机器人按指示拿起一个盒子时，看着它们做着和人类一样的事情是非常令人欣喜的，然而它们并不会拥有像孩子那样复杂的思维水平。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Tenenbaum 和他的同事采用了在神经元的虚拟网络上建模的深度学习算法。它建造了一个非常初步模仿人脑的工作方式。当机器处理一个对象时，它搜索其巨大的数据库来获取与机器匹配的像素以进行识别。而人类依赖于更高形式的认知功能来解释对象的内容。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我们正在试图编写像大脑的软件一样的计算机程序，这通常被称之为思维。思维是程序且运行于大脑这个硬件上，我们就是试图在对准软件层面。神经网络在人工智能中就像计算机程序的软件层面一样。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 2013 年，美国国家科学基金会拨款 2500 万美元资助了麻省理工学院一项为期五年的项目，用于建立脑、思维和机器中心。为了解大脑如何执行复杂计算，不同领域的科学家和工程师共同合作，希望构建更类似于人类智能的智能机器。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Tenenbaum 说：「近期我们才建立出一个能够做到这一点的数学与计算机模型，我们将需要更多的资源、人才、公司、技术和公司的利益以及更快的计算机。我们可能需要等待或依靠其他工程进展，然后才能赶上即使是非常幼小孩子的智力。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;构建第一个婴儿大脑&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;新西兰的奥克兰大学生物工程研究所正在试图通过一个动画制作的可互动的婴儿来弥合大脑和机器之间的差距。Mark Sagar 是该研究所动画技术实验室的导演和创始人，其动画作品《阿凡达》和《金刚》获多项奥斯卡奖。他在实验室和一个叫做 BabyX 的 3D 电脑屏幕上的金发碧眼宝宝玩躲猫猫，这个 BabyX 是一个能够学习、思考并可以产生面部表情，能够自己做出反应的实时系统。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过在麻省理工学院建立身体部位的医学模拟，Sagar 开始了他的职业生涯。在那里他致力于实现数字面孔，并使用这些技能开发 BabyX。动画人工智能能够模仿他的面部表情、朗读简单的字、识别对象和播放经典的视频游戏 Pong，这使它每天都变得更聪明。BabyX 不仅是 Sagar 的「大脑宝宝」，也是在他的女儿 Francesca 在不同年龄阶段的模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了构建 BabyX，Sagar 在他的女儿 6 个月、12 个月、18 个月和 24 个月时进行了扫描，并将数据上传到了系统中。他选择通过动画技术来复制他女儿的行为、面部表情和声音，作为人工智能初生的隐喻。Sagar 亲切地将 BabyX 称为「她」，并解释她如何使用光纤电缆：由她的模拟神经活动所驱动，如同脊髓连接到大脑。与之前的系统不同，由于 BabyX 是一个具有人工智能的交互式化身，故它具有学习和保留信息的能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我们不以大多数人所想的方式开发人工智能，」Sagar 说，「在神经科学和认知科学中存在许多有争议的理论，现有知识可能仅代表冰山一角。而最困难但也最深刻有趣的部分是：生物学启发的方法如何从不同规模过程的相互作用中出现更高的认知水平。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Sagar 和他的团队测试了 BabyX 与人类的互动。BabyX 能够处理人类的情绪、理解他们的行动背后的意义、并根据她过去与 Sagar 的互动中所学的东西做出回应。BabyX 的屏幕之后是一个大脑的实时模拟，使它能够提示面部模拟眨眼和观众报以微笑。Sagar 认为脸部是发展是有效交互式人工智能的关键，因为它是大脑的反映，并揭示了有意识思维的内在运作。例如，一个简单的微笑是脑内连接的复杂、交织系统运行的结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「BabyX 通过使用者的行为和宝宝的行为之间的关联来学习，」Sagar 说道，「在一种学习形式中，咿呀声会使 BabyX 探索她的运动空间、移动她的脸或手臂。如果使用者的响应类似，则表示 BabyX 的动作神经元开始通过称之为 Hebbian 学习的过程与响应使用者动作的神经元相联系，共同发挥作用的神经元会聚在一起。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在重复过程之后，新的神经连接开始在 BabyX 的模拟大脑中创建一个映射，将其动作与使用者的动作相匹配，为更高级的模仿打基础。人类大脑的工作方式大同小异——即通过完成一个动作，大脑形成新的连接并通过重复这个动作而加强。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最终，这个模拟的婴儿通过她大脑处理的环境信息来做出自己的反应。本质上，BabyX 通过不断改进代码进行学习。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;BabyX 的学习能力是基于生物学似乎可信的学习模型中，这种算法模拟和翻译人类大脑如何处理信息和释放大脑中的化学反应，例如多巴胺或催产素水平。当她不明白一个单词或动作时，BabyX 显示困惑的表情，但当她正确地读一个单词时，她会快乐地笑起来，并释放更高水平的「快乐激素」多巴胺。每个算法都控制神经系统从而令她能够模仿、建立反馈系统还有通过互动和演示学习新的信息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我想探索如何将基于生物学的行为、情绪和认知的计算模型集成到动画中，特别是面部，」Sagar 说道，「面部表情是人类经验许多方面的纽带。这对探索学习和心理发展的基础，甚至可能对我们未来与更复杂、自主技术的相互作用和使用都至关重要。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;由于面部是沟通的一个首要手段，Sagar 希望他的实验可以为未来的健康和教育应用奠定基础，例如旨在与自闭症或其它社交障碍疾病儿童患者进行互动的方案。一个可以感受到人的情绪、处理并了解他们的感受的系统是驱动人工智能研究的目标，这就像我们人生中最初的光阴一样——建立一个可以自己思考的大脑。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译文章，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Sun, 20 Nov 2016 11:17:41 +0800</pubDate>
    </item>
    <item>
      <title>技术 | 斯坦福大学副教授Reza Zadeh：神经网络越深就越难优化</title>
      <link>http://www.iwgc.cn/link/3579157</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自O'Reilly&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：武竞、吴攀、蒋思源&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;本文作者 Reza Zadeh 是斯坦福大学副教授及 Matroid 公司创始人兼 CEO。他的研究工作主要涉及机器学习、分布式计算和离散应用数学。他同时也是微软和 Databricks 的技术顾问委员会的成员。对于这篇文章，他总结说：「神经网络越深，往往就越难优化。」&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9YibFeykBDgdvOUNVxn0L44aVibqcbWobPqyhOicLFRpYpibh6S1n3ChhiawRFDUcfaJS9Qn8JpO4sIUg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Rastrigin 函数&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;优化是非常困难的一类问题，而这正是深度学习的核心。优化问题是如此困难，以至于在神经网络引入几十年后，深度神经网络的优化问题仍阻碍着它们的推广，并导致了其 20 世纪 90 年代到 21 世纪初的衰落。自那以后，我们解决了这个问题。在这篇文章中，我会探讨优化神经网络的「困难度（hardness）」，并发掘其背后的理论。简而言之：网络越深，优化问题就越难。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最简单的神经网络是单节点感知器，其优化问题是凸优化的。凸优化问题的好处是其所有的局部最小值也是全局最小值。现在有各种各样的优化算法来处理凸优化问题，且每隔几年就有更好用于凸优化理论的多项式时间算法（polynomial-time algorithms）出现。运用凸优化很容易得到单个神经元的优化权重（见下图）。从单个神经元开始，让我们看看会发生什么。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9YibFeykBDgdvOUNVxn0L44OXV1TB7eFu5IDrdDhWEC84ojcs3eyfJS9jQIHvvpfesLJZiaaOibpVsw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 1。左：凸函数。右：非凸函数。沿着函数表面，凸函数比非凸函数更容易找到表面的最小值。（来源： Reza Zadeh）&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下一步是保持单层网络下添加多个神经元。对于单层、n 节点的感知机神经网络，如果存在一组边权重使得网络可以正确地分类给定的训练集，则这样的权重可以通过线性规划用 n 的多项式时间找到，这也是凸优化的特殊例子。所以下个问题是：对于更深的多层神经网络，我们是否可以类似地使用这种多项式时间方法？不幸的是，我们无法保证。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;能够有效解决两层或多层的广义神经网络的优化问题并不容易，这些算法将会涉及计算机科学中的一些最棘手的开放性问题。因此，要想机器学习研究人员找到可靠的深度网络最佳优化算法可能性十分渺茫。因为该问题是 NP-hard（非确定性多项式困难 non-deterministic polynomial hard）的，也就意味着如果可以在多项式时间的计算复杂度中解决它，也将解决数十年来悬而未决的几千个开放性问题。事实上，1988 年 J.Stephen Judd 阐述的以下问题就是 NP-hard：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;给定一个广义神经网络和一组训练集样本，是否存在一组网络边权重（edge weight），使网络能够为所有的训练样本产生正确的输出结果？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Judd 还表明，即使只需要神经网络正确输出三分之二的训练样本，但还是 NP-hard 的，这意味着即使在最坏的情况下，训练一个不精确的神经网络在本质上也是困难的。1993 年，Blum 和 Rivest 证明了更坏的消息：即使训练一个只有两层和三个节点的简单神经网络也是 NP-hard！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;理论上，对比深度学习与机器学习中的许多更简单的模型（例如支持向量机和逻辑回归），这些模型可以在数学上保证优化能在多项式时间中执行。对于这些更简单的模型，我们能够保证优化算法在多项式时间内就会找到最佳模型。但是，对于深度神经网络的优化算法，并没有这样的保证。根据你的设置来看，你不知道你训练的深度神经网络是否是你可以找到的最好的模型。所以你也并不知道如果继续训练是否能得到更好的模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;幸运的是，实践中我们可以非常有效地解决这些「困难」结果：运用典型梯度下降（gradient descent）优化方法可以给出足够好的局部最小值，让我们在许多问题上取得了巨大进步，例如图像识别、语音识别和机器翻译。我们只是忽略困难的部分，在时间允许下尽可能多地运用梯度下降迭代。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;似乎最优化问题的传统理论结果是很笨拙的，我们很大程度上可以通过工程和数学技巧、启发式方法、增加更多的机器或使用新的硬件（如 GPU）来解决它们。有意思的是，仍有很多人研究为什么典型的优化算法如此有用，当然除了那些困难的部分。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;深度学习流行的原因远远不止是解决了优化问题。深度学习在许多机器学习任务中获得领先，它的网络的架构、训练的数据量、损失函数和正则化都起着关键作用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译文章，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Sun, 20 Nov 2016 11:17:41 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 特斯拉全自动驾驶第一视角体验：轻松应对十字路口和城市街道</title>
      <link>http://www.iwgc.cn/link/3579159</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自TechCrunch&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;日前，特斯拉曾透露正在研发一款全新的硬件，以满足他们未来实现完全自动驾驶汽车的需求；同时该公司还曾公布了一段工作中的原型软件的视频。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今天早些时候，特斯拉又发布了一段第一视角的自动驾驶体验视频，在视频中，特斯拉的自动驾驶汽车在完全没有人类干涉的情况下穿过了交通繁忙的城市街区和一些十字路口。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;iframe class="video_iframe" data-vidtype="2" style="   z-index:1; " height="375" width="500" frameborder="0" data-src="https://v.qq.com/iframe/preview.html?vid=y13111xxgof&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0" allowfullscreen=""&gt;&lt;/iframe&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;视频中我们可以看到驾驶座位上坐着一位工作人员，但他并没有进行任何操作（因为法律规范他必须坐在那里）——没有碰方向盘，也没有踩刹车或加油门。除了主画面的体验视角之外，画面右侧还显示了这辆特斯拉上面所安装的 3 个光学相机在驾驶过程中捕获的实时画面，其上的色块是汽车上的计算机所检测出的行人、汽车、道路标志等等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，工作人员下车，这辆特斯拉自动完成了泊车。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个 Autopilot 的完全自动驾驶版本看起来真是令人印象深刻。特斯拉 CEO Elon Musk 曾经说过要在明年进行一次穿越整个美国的无人驾驶测试，看起来似乎真的是很有可能如期完成目标了！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外，我就知道你要问这段视频的背景音乐是什么——滚石乐队的《Paint it Black》。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;扩展阅读：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719875&amp;amp;idx=2&amp;amp;sn=1d70df4cefc830ce8a40f322052ecc90&amp;amp;chksm=871b02fdb06c8beb61da80d688b37874e324c00ad0e953dca84747e842a841e7331db2239c9c&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719875&amp;amp;idx=2&amp;amp;sn=1d70df4cefc830ce8a40f322052ecc90&amp;amp;chksm=871b02fdb06c8beb61da80d688b37874e324c00ad0e953dca84747e842a841e7331db2239c9c&amp;amp;scene=21#wechat_redirect"&gt;Tesla 推出「完全自动驾驶」功能，这是彻底解放人类还是又一次「大跃进」？&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718688&amp;amp;idx=3&amp;amp;sn=45f0864bc58f08cf7fcb17c842e05d91&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718688&amp;amp;idx=3&amp;amp;sn=45f0864bc58f08cf7fcb17c842e05d91&amp;amp;scene=21#wechat_redirect"&gt;从特斯拉到计算机视觉之「图像语义分割」&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716988&amp;amp;idx=1&amp;amp;sn=65ad0b7c47c2b6c3f1b0b89e6fab1ff5&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716988&amp;amp;idx=1&amp;amp;sn=65ad0b7c47c2b6c3f1b0b89e6fab1ff5&amp;amp;scene=21#wechat_redirect"&gt;特斯拉巡航系统供应商Mobileye创始人详解自动驾驶三大支柱&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译文章，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Sun, 20 Nov 2016 11:17:41 +0800</pubDate>
    </item>
    <item>
      <title>独家 | MIT-CHIEF 2016年会回顾：站在自动驾驶与人工智能的风口</title>
      <link>http://www.iwgc.cn/link/3579161</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心原创&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;作者：&amp;nbsp;孙睿，张晨卉，李九喻&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2016 年 11 月 12-13 日，麻省理工学院中国创业与创新论坛（MIT-CHIEF）第六届年会在波士顿举行，旨在搭建中美商界与学界对话的平台，其中嘉宾包括：麻省理工学院斯隆管理学院副院长黄亚生教授，搜狐总裁张朝阳，斯坦福教授兼丹华资本创始人张首晟教授，MIT 机械系主任陈刚教授，真格基金兼新东方创始人王强，瑞银集团执行副总裁 Eric Gan 等。机器之心则带着对智能驾驶与人工智趋势的关注，参加了本次大会。两天的会议虽未对技术细节作出深入的讨论，但仍在技术的商业应用，市场推出，中美交流上提供了很强参考价值。提醒各位创新者仅掌握技术的局限性，创业——尤其是颠覆性创新——需要导航复杂的商业环境，面对甚至尚未形成的市场，从中平衡长短期利益。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Pannel／Plenary 亮点回顾&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不少嘉宾以自身科研成果或创业历程为切入点发表讲话，也有投资人从大趋势上分析人工智能等产业的走势。例如，创新工场的合伙人 Chris Evdemon 指出，人工智能将是继互联网先驱，产品经理，O2O 热潮后的下一个大趋势。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前，国内市场面临着资本过剩，人才缺失，大公司垄断等问题，亟需建立更明确的分期成果，吸引多方面人才，搭建长远目标，实际地考虑创业公司与大公司竞争的利弊与发展前景。Chris 认为，海外的技术人才出路很多，可以考虑为美国本地公司／美国本地公司的华人市场部／华人公司，或中国外资企业／中国公司／中国公司的海外部工作，几种选择各有利弊，不过介于这几年经济形势的变化以及国内的高速发展，中国境内的外资企业或已失去竞争优势。海外创业公司若打算开发国内市场，亦需要考虑「本土化」。从投资人的角度来看，这背后的多重顾虑与独特商机算是一把双刃剑。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW81aVM2Gdgrxfsa0vR4YVib22qLBbfqUiaqu6cOsvLb1iat5eaFopJbZ2ibxXdzHvk0RIVDQa3C0MxwPw/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW81aVM2Gdgrxfsa0vR4YVib27a0EPkOdZyhModTeQT3zkKBuLRYQ0flvh38sq95gI9bA7LA6qSaibHQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本篇文章将带您回顾：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;智能驾驶论坛（Autonomous Driving Panel）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;机器学习（Machine Learning Panel）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;张首晟演讲&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;张朝阳演讲&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;智能驾驶商业化中未知的风险与商机&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;智能驾驶&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2016 年是全球智能驾驶热度空前的一年。谷歌、福特、特斯拉、丰田、通用、百度、法拉第、Uber 等公司纷纷入局，以不同方式展开对智能驾驶的实验研究及产业落地。智能驾驶为汽车产业带来了发展的新机遇，但同时其在当下也面临着相关法律缺失、技术尚不完善以及消费接受度不高的现实挑战。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此次 MIT CHIEF 智能驾驶论坛（Autonomous Driving Panel）汇聚了来自智能驾驶产业生态圈各个环节的「代表」，阵容豪华：由普林斯顿大学教授转型投身产业的肖健雄第一位发言，现场展示了他近期创立并任 CEO 的 AutoX 公司的产品演示；来自麻省理工媒体实验室的 Iyad Rahwan 副教授，则分享了正在创建的「驾驶道德」（Moral Driving）网站－通过数据收集分析不同情境下的驾驶决策；技术驱动型创业公司图森互联的联合创始人兼 CTO 侯晓迪，介绍了图森互联及其基于计算机视觉和深度学习算法的公司策略和发展方向；最后来自云启创投的黄榆镔，代表了 VC 方对智能驾驶产业做出了点评。随后，在「麻省理工科技评论」（MIT Technology Review）杂志资深编辑 Will Knight 主持的座谈环节中，肖健雄、Iyad Rahwan、侯晓迪和黄榆镔对智能驾驶技术及产业现状展开了讨论，并分别从各自的专业角度分享了他们对智能驾驶的思考。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当谈及自动驾驶汽车的商用时，来自产业链不同环节的嘉宾们的发言见仁见智。研究「驾驶道德」的 Iyad Rahwan 关注更多的是自动驾驶汽车的安全性，他表示大众对于自动驾驶汽车是否接受很大程度取决于是否安全。云启创投的黄榆镔则认为资本的注入是自动驾驶汽车真正上路的先决条件。正在研发自动驾驶汽车产品的肖健雄提出，在兴建新城市的过程中为自动驾驶汽车设计专用车道，作为推进商用的解决办法；同为技术创业「代表」的侯晓迪则解释了图森互联的定位，他们认为自动驾驶可以细分为自动卡车和自动汽车两部分，两者区别很大，其中自动卡车会更加可控，也正是图森互联先下的研究方向。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;会后肖健雄与侯晓迪特别面对机器之心，对此次论坛发言进行了补充。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;肖健雄&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然 AutoX 仍处于「地下模式」，作为创始人的肖健雄并不吝于展露自己的雄心。在解释公司标语「Democratizing Autonomy」时，他表示推动自动化的普及是他们的使命，并自比微软希望自动化像计算机一样覆盖到社会的方方面面，其中自动驾驶只是他们目前专注的第一步，AutoX 的「X」代表着未知，也代表着一切。同时他也阐述了自己从学术界普林斯顿大学教授，投身到工业界创立 AutoX 的始末：「我认为这可以为社会带来更多的价值。实验室关注更多的是理论上的推导。在学术圈做研究产出论文的模式是必要的，但是相应每个项目规模很不会很大，缺少多人合作也很难系统化地解决问题。我觉得自动驾驶的研究到了这样一个阶段，需要多人合作长期系统地来攻克。创业是唯一的解决办法，也只有工业界才能够实现。」此外肖先生还表达了以技术为先的态度和对深度学习的关注，特别是如何将深度学习作为一种工具来使用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;侯晓迪&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;计算机视觉和认知科学领域专家侯晓迪先生也从图森互联 CTO 的身份出发，很详细地解释了他对于业界一些看法及图森现阶段的发展状态。与机器之心的对话如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Synced：自动驾驶汽车的发展阶段被学界分为五级，从部分自动化一直到完全自动化。您觉得图森的研究现在位于哪个级别？5 年内计划实现到哪个级别？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;侯晓迪：我觉得这个分级体系其实不够准确，其中一个原因就是，从它定义的第三级到第四级其实是一个很大的跳跃。在第三级，驾驶员虽然不操作，但是还需要观察路况，但是在第四级，驾驶员就可以完全不看路了。这中间其实跳过了很多东西。我们将我们的产品定位在「三加四减」的阶段，也就是说，卡车不需要随时有人看着，但是也不排除在一些非常规情况（比如轮胎故障），需要人介入进行调整。对于大部分公司来说，特别是创业公司，一下子达到五级都是不太可能的。我认为所有的技术都需要且行且看吧，没有一个技术能够在初期就满足所有人的所有幻想。作为一个创业公司，我们一定是先有商业上的需求，在可得资源和可等待的时间范围内实现一个技术上可行的产品。所以我们目前的计划是定在「三加」阶段。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;Synced：图森为什么选择自动化卡车作为第一个进入市场的产品？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;侯晓迪：第一个原因是成本和价格的问题。对于普通的消费者来说，目前自动化汽车改造的价格是很高的，因为本身我们的成本就很高，而大部分人也不会长时间频繁使用汽车；而对于产品生产者来说，卡车运输是不可或缺的一部分，在被大量使用的基础上，产品公司对价格的承受能力会更高。所以我们的第一步，是让自动驾驶汽车作为生产工具进入市场。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;Synced：自动卡车在市场接受程度上可能会遇到什么阻碍？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;侯晓迪：市场接受的程度主要还是取决于最终的产品形态，包括功能、价格、可靠性等等。如果一开始功能定的虚高，算法达不到，最后产品出来不是贵就是可靠性差，就肯定会在市场上碰一鼻子灰。其实有很多技术上无法绕过的难题，是完全可以通过功能设计来回避的。创业公司有一个优势就是，算法设计者和产品功能设计者的沟通成本很低，大家可以坐在一起，持续地沟通和妥协，来达成共识，最后迭代出来一个功能上有价值、价格上可接受、可靠性上足够在使用场景内让大家放心的东西。在风险控制上，我们最开始一定是需要自己承担相关的风险，这样大家的信任程度会更高一些。同时，只要我们的模拟测试能够将出错频率控制在极低的范围内，我认为这个产品就是可以被接受的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Synced：政府对自动卡车投入市场的态度是什么样的？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;侯晓迪：政府对这件事是非常支持的，因为现在的卡车运输其实存在很多问题，比如超载、危险驾驶、司机行为监管等等，要将这些管理好，要比管理几个自动卡车公司要复杂得多的，所以我们的产品其实也是在帮政府解决这些管理上的问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Synced：智能驾驶产业现在话题度热度居高不下，您对产业现状怎么看？是否存在泡沫呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;侯晓迪：泡沫是肯定存在的，因为市场包括投资人很难鉴别技术创业者是否真正具有算法研究能力。我们也见识过一些技术领域的「李鬼」，这些人其实是在消费整个 AI 创业圈的公信力。但是无论怎样，想要实车上路，哪怕只是在开放环境下跑几公里，稍微拐个弯避个障，就已经不是纯靠嘴皮子就能吹出来的了。何况是关乎人命的产品，所以整体来说大家对于风险管控意识很强。而且确实存在不少比无人车泡沫更大的领域。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Synced：中国现在有接近 1600 万长途卡车司机。随着自动驾驶系统的应用，卡车司机群体失业是不可避免的结果，对此您怎么看？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;侯晓迪：一方面，新的职业一定会出现，社会会提供给这些人新的就业机会，比如说，自动汽车不需要人来驾驶了，这些人就可以借着物流成本降低的东风来做生意；另一方面，现代社会学习新知识、新技术的门槛越来越低，这些人群完全有可能成为技术工人甚至程序员。最后，自动驾驶系统的换代升级肯定不会是一夜之间完成的事情，市场的转变会是以年为单位的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Synced：图森在大量使用 labelled data，那么也就意味着还是需要人对数据进行解读，之后进行 supervised learning。这样对于历史数据无法覆盖的危险情况，我们如何保证安全？图森是否在进行 supervised learning 之外的尝试？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;侯晓迪：所有的测试数据肯定都是「历史训练数据」无法涵盖的。如何增强模型的泛化能力是机器学习一直以来最核心的问题。近年来深度学习大行其道，确实存在一些急于求成的创业者，一知半解的情况下就拿深度学习说话，给社会一种不靠谱的感觉。但是我们对于纯深度学习的局限性一直很清醒，并且在 end-to-end learning 之外做了很多尝试。比如，我们一直很强调传统的 Bayesian statistics 和深度学习并重的视角来看问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器学习试水商业应用，「曾经训练出来的数据集，可能根本没用。&lt;span&gt;」&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器学习&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW81aVM2Gdgrxfsa0vR4YVib2hOibdqwVbanf0kPpZu18PUQUkruy33tIa3MmicSHbA9ddqtVpTQDjZEA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从年初的围棋大战开始，「机器学习」就注定将成为 2016 年最受关注的话题之一。与此同时，机器学习也从实验室走出来，作为一种更强大的数据分析工具，被快速应用在许多公司的商业决策上。在此次 MIT CHIEF 机器学习论坛（Machine Learning Panel）中，嘉宾们都给出了自己对这一波商业浪潮的独到见解。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;微软 Azure 机器学习工作室的高级数据科学家 Wu Tao 首先点出了应用机器学习工具这一趋势的动因：数据的快速增长、计算能力的大幅提升、以及应用门槛的大幅降低。同时，他认为在这一大环境下，小型的公司反而能有更大的优势，因为大公司整合新技术的过程更加烦琐，一定程度上影响商业效率。数据分析解决方案提供者 Tamr 公司的 CEO，Andy Palmer，也分享了他创立 Tamr 的经历和心得，并强调了机器学习工具对商业决策的重要性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;来自麻省理工大学信息与决策系统实验室（LIDS）的高级研究员 Kalyan Veeramachaneni 认为，目前，机器学习预测模型的商业应用，仍有很大的进步空间，因为目前的落地时间慢、行政冗余长。在技术方面，大部分学术上的研究模型都没有在真实的环境下训练过，导致其实际价值非常有限。在会谈过程中，他向台下的观众问道：「在座有多少人训练过数据集？」台下约几十人举手。他随后追问道：「谁训练的模型最终被上线使用？」只有寥寥无几的人响应。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于提供数据分析服务的初创企业，论坛的建议是：专精于某一个领域，能够帮助公司更快找到客户群。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;结束后，Kalyan Veeramachaneni 特别面对机器之心，对此次论坛发言进行了补充。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW81aVM2Gdgrxfsa0vR4YVib2cALqGerSsSk4OyvmEYLS8wqgYOwKjRLxic0mDZiagjia8a73cxicez8JhA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Kalyan Veeramachaneni&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Synced：与大部分学术研究不同，您的许多研究项目都更加实际、偏重应用，比如您 2015 年对 MOOC 网站退课率的预测模型研究。是什么让您选择了这些课题？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Kalyan：我一直认为，学术界的许多研究灵感都是来源于商业：当旧的技术不能满足市场的时候，学术界就能够把握机会创造新的技术，计算机视觉、机器学习等都是这样的例子。同时，我也觉得，拥有应用价值的研究项目才是更有意义的项目。虽然学术界一直不太强调研究的实际应用，但我觉得这是有价值的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Synced：您觉得学术研究与商业应用存在脱节的现象吗，对此您有什么看法？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Kalyan：我确实认为存在一定程度的脱节，而这种脱节是可以缩小的。比如在麻省理工学院，学术圈与商业的交流非常频繁，我们能够很快地了解到商业企业的最近进展和技术需求，研究成果也能快速地投入商业中使用。所以，第三方机构，比如大学，在缩小这以差距上扮演了很重要的角色。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;张首晟——物理学家人工智能风投，当斯坦福与硅谷遇上中国&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;张首晟&amp;nbsp;&lt;/span&gt;&lt;span&gt;(斯坦福大学教授，丹华资本创始人)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW81aVM2Gdgrxfsa0vR4YVib28TtySOfu0d9rNrhzLicNXWQLtrpKo5IFNOARQJ0taEWv6qX4csfEJiag/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;张首晟教授在演说中提到硅谷的发源地，回溯在新泽西的贝尔实验室，肖克莱博士、巴丁博士和布菜顿博士发现晶体管，并借由此发现荣获诺贝尔奖的这段历史。他指出，信息技术依赖于摩尔定律的效应，如果摩尔定律停止应验，将无法继续发展。张教授与他的团队在量子自旋霍尔 (Quantum spin Hall effect) 与拓扑绝缘体 (Topological Insulators) 的研究上对芯片的升级有着重大贡献。在「量子自旋霍尔效应」下，芯片中的电子可以像高速公路的汽车一样正反流动，将「信息高速公路」拓建到芯片层次。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不过，张首晟此次主要以投资人亮相。他于 2013 年成立丹华资本，「丹」取之于斯坦福的音译，「华」取之于中华，试图搭建硅谷，斯坦福大学，与中国之间的技术创新桥梁。在讲到自己作为著名物理学家和新进投资人之间的身份转变时，张教授认为两者之间并无太大区别。像特斯拉 CEO 埃隆·马斯克，张教授也提到要从物理的「第一原理」开始思维，认清事物与事物之间的本质联系，强调理工思维在商业投资里起到的重要作用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;演说后，张教授对机器之心阐述了更多关于人工智能的看法和投资理念。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Synced：您的丹华投资在硅谷投了非常多的人工智能公司，是什么样的契机让您开始关注这一领域呢？&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;张首晟：人工智能是一个必然的趋势，这个趋势有三个重要的模块：优良的算法，大量的数据，还有我今天在演讲时提到的「摩尔定律」——计算能力势必以指数增长。人工智能是在 50，60 年代提出的概念，不过把以上三个模块整合在一起是近期才做到的。在这个意义下下，我们处于一个非常激动人心的时代，它会改变人类生活的每个角落。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Synced: 能讲讲您在硅谷投的公司吗？它们分别有什么样的特点？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;张首晟：我先讲我们投的人工智能公司吧。人工智能有两个，一个是做平台性的，比如像 DeepMind，MetaMind 等，像我们去年看到 AlphaGo 的成功。另外人工智能会改变垂直领域，在这个意义下，它能带来更多的机会。平台性的，大公司可能已经掌握了技术，它也有大量的数据和计算能力。但是有的时候在无人机上或者自动驾驶汽车上，你不可能用到云端的计算能力。该如何在局限的情况下把人工智能做好？我们投的一家公司叫 pilot.ai，它就找到了类似的初创公司生存空间。另外我们投的一家公司叫 Trustlook，它使用人工智能来识别安卓手机系统里的病毒。在以前，这是人工来做得事情，现在都会慢慢被机器取代。另外一个很大的领域是医药，比如说 radiology 的图片和 pathology 的图片，我们都可以用机器读取，机器在很多时候比人工更精准。相比较于人，机器大脑可以不休息地运作，一旦有了足够的训练集，我们就能够把它教得越来越成功。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Synced: 您如何看待国内的人工智能创业公司？这些公司的机遇与相对优势又在哪里？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;张首晟：国内真正原创的公司还是不够多，不过我相信在某些垂直的领域，技术虽然不一定是全球领先，但是它已经是有一定领先的应用，这样的话也是有竞争空间。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;张朝阳——立志返回互联网舞台中心的搜狐，在人工智能时代何去何从？&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;张朝阳&amp;nbsp;&lt;/span&gt;&lt;span&gt;(搜狐总裁，创始人兼 CEO)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW81aVM2Gdgrxfsa0vR4YVib2z4MekjY53t2W1EQXxbRicwk1XiaZz90saw7cN2BOcFvXL0F4z81qIRCQ/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;搜狐总裁张朝阳是此次 MIT-CHIEF 的最后一个嘉宾。面对 MIT 的观众，他轻松说起多年前的创业经历——从 MIT 毕业后的少年成功——其中不乏对搜狐倚重宣传，错失开发产品良机等历程的一些反思。作为总结语，张朝阳表示将尽力在未来几年将搜狐带回互联网中心，从内容娱乐，语音搜索等切入口更新整个平台。这位互联网界的大佬对机器之心给出了关于创新接地气的看法，其中包括人工智能在搜索，新闻，娱乐等方面的应用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Synced: 今年上半年，搜狗投资了 1.8 亿与清华联合成立了天工只能计算研究院，双方基于「清华搜狗搜搜索技术联合实验室」的研究向人工智能领域的前沿技术深入拓展。那么搜狐是否有计划进行全线业务的人工智能化呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;张朝阳: 这是一个持续一直在发展的事情。我们一直在投资人工智能，主要集中在搜狗方面。人工智能在新闻方面的应用据我所知，用机器学习的算法，深度学习的构架来处理编辑好的文章特征。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Synced: 那会不会有搜狐员工被自动化掉的危险？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;张朝阳：没有，因为将需要更多的人来写更好的软件。其实不是说会减少人，而是说工种变了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Synced: 那么编辑部的员工还安全吗？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;张朝阳：编辑部现在基本上是越来越少了，现在很多是公众号的东西写好，再由机器来筛选。打头阵的编辑部的团队需要更精炼地提选内容。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心原创文章，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Sun, 20 Nov 2016 11:17:41 +0800</pubDate>
    </item>
    <item>
      <title>C Talk | Face++产品体验：能不能借钱，机器说了算</title>
      <link>http://www.iwgc.cn/link/3579163</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;C Talk 专栏&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;公司：用钱宝&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;从最初作为学界内的研究，到企业战略部署的科技领域，再一点一点的实现商业化，人工智能已经离我们越来越近。业内众多创业公司的产品也得到了越来越多的客户的认可。为了从产品层次了解业内的众多公司，机器之心推出了 C Talk 专栏（客户说），让客户介绍如何用人工智能技术提升自己的效率，评价自己所用的人工智能产品。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;本文为该系列专栏的第一篇，&lt;span&gt;用钱宝的 CTO 齐鹏对 Face++人脸活体检测的感知。&lt;strong&gt;欢迎已经使用人工智能产品的用户向我们投稿，介绍经验和体验，邮箱：editor@almosthuman.cn&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;用钱宝目前已在年轻白领和蓝领中被熟知，它是为消费缺乏计划性、短期内需要小额资金周转的年轻人而设计的一款生活服务类的 APP。用钱宝使用以人工智能为核心的风控系统，所以用户填写信息、提交申请都在手机上搞定，风控评估到放款则都是由机器完成。对于用户来说，这意味着可以随时随地使用用钱宝，且方便快捷。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;据小编了解，用钱宝上线 16 个月的时间，就已经可以实现单月放款笔数超过 55 万笔。在这么短的时间内获得迅猛稳健的成长，不仅因为用钱宝极强的市场洞察力和贴心的产品设计，更因为它是一家以「技术基因」而闻名的公司——核心团队均是技术出身，CEO 焦可和 CTO 齐鹏都来自于百度，所以我们发现整个技术团队中相当于 T6 级别（技术总监或创业公司技术合伙人级别）的技术大拿就有十多个。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;那么这套以人工智能为核心的风控，是如何服务这些缺失银行数据的年轻人呢？小编采访了用钱宝的 CTO 齐鹏之后，才恍然大悟。传统银行对于人群的风险评估系统是建立在被称为「强特征」的基础上，比如有无房产、工资流水、社保征信等；然而年轻人大多却只拥有移动互联网时代下产生的海量「弱特征」。通过对于「弱特征」的挖掘、评估和使用，用钱宝建立了独有的专业风控体系，尽可能为更多的年轻人提供服务。Face++的人脸活体监测，就在这套风控体系中验真的环节，扮演了重要角色。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这套新型风控系统究竟如何运作，让我们来听听 CTO 齐鹏怎么说。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;齐鹏部分采访实录：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 用钱宝是针对都市白领跟蓝领的一款小额个贷的产品，可否透露都在使用哪些弱特征来做风控体系？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;传统金融是通过用户的还款能力来进行判断，这个比较容易理解。但是我们则是针对还款意愿来进行判断，因为理论上来说，只存在用户是不是有意愿进行偿还。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以，我们通过柯南特征工程、D-AI 机器学习模型以及 Anubis 大数据计算架构等人工智能技术，从海量弱特征中提取 500+有效特征，对用户进行建模，并借助快速积累的用户还款样本来进行系统优化，从而保证较高的通过率和较低的逾期率。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 怎么看媒体的评价，「用科技做智慧的金融」？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们的公司叫智融时代，从创立初期就一直秉持「让每个人享受智慧的金融」这一宗旨。「每个人」就是我们所服务的对象是银行所不能覆盖的人群，而智慧的金融就是我们以人工智能为核心的新金融技术。我们深信只有通过新金融技术，才能在未来的某一天，实现让每个人享受金融的魅力这一美好目标。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3. 所以，拥有科技团队的公司喜欢启用同类型的公司，face++的刷脸认证？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们使用 face++是基于两方面的考虑，一个是验真，一个是提升审核效率。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先我们要保证贷款个人是本人来申请，不是别人来冒名顶替，我们发现人脸核对身份是比较好的方式，另外人来核查跟机器相比还是慢很多，「face++的稳定性好，识别准确度高，使用很流畅，服务能力还不错」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4. 目前用户增长量？续贷率如何？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;增长量很快，从上线第一个月的 93 单到 10 月份增长到 55 万单，呈现指数级的发展态势。传统金融需求属于低频、决策时间长、流程久，而我们则是中高频需求，并且整个决策过程和业务流程都比较高效。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;5、1.56 亿元融资后的战略布局是？将围绕着「人工智能」为核心研发更多的新金融技术？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们会一直坚持两件事情，一个是让「每个人」享受金融服务的魅力，这说明我们服务的人群会一直不变；另一个则是智慧的金融，也就是新金融技术。在这样的基础上，我们可能会设计更多的产品线，来实现这一目标。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;C Talk：机器之心推出的文章系列，让客户介绍如何用人工智能技术提升自己的效率，评价自己所用的人工智能产品。&lt;strong&gt;欢迎已经使用人工智能产品的用户向我们投稿，介绍经验和体验，邮箱：editor@almosthuman.cn&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心C Talk系列文章，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Sun, 20 Nov 2016 11:17:41 +0800</pubDate>
    </item>
    <item>
      <title>重磅 | 世界首个光子神经网络诞生：比传统方法快1960倍</title>
      <link>http://www.iwgc.cn/link/3568914</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自arXiv.org&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;日前，来自普林斯顿大学的 Alexander N. Tait 等科学家在 arXiv 上发表了一篇题为《神经形态硅光子学（Neuromorphic Silicon Photonics）》的论文，介绍了世界上首个「光子神经网络（Photonic Neural Network）」。点击阅读原文可下载此论文。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以机器学习神经网络为代表的人工智能技术正在改变我们生活的许多方面，对支撑这些技术所需的数据处理能力的需求也越来越强。而针对神经网络的结构开发出神经形态芯片（neuromorphic chip）有望能大幅提升神经网络的性能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;日前，来自普林斯顿大学的 Alexander N. Tait 等科学家在 arXiv 上发表了一篇题为《神经形态硅光子学（Neuromorphic Silicon Photonics）》的论文，介绍了世界上首个「光子神经网络（Photonic Neural Network）」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;和我们目前主流的基于电子的处理方式相比，光子的方式的速度可以达到更快、也能实现更高的带宽。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;据 MIT Technology Review 的报道介绍，开发光子神经网络这个难题的核心是生产一种每个节点都有相同的响应特征的装置以用作神经元。这些节点采用了微型的环形波导（tiny circular waveguides）的形式，这些波导被蚀刻在硅衬底中，光可以在其中循环。当释放这个光并调制在阈值处工作的一个激光的输出时，该环境中输入光的一点微小的改变就会给该激光的输出带来巨大的影响。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其中的关键在于，该系统中的每个节点都工作在一定的光波长长——这是一种被称为波分复用（wave division multiplexing）的技术。在来自各个节点的光被送入该激光之前会被总功率检测求和。然后该激光输出会被反馈回节点以创造出一个带有非线性特征的反馈回路。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;那么这种非线性能在多大程度上模拟神经行为呢。研究表明其输出在数学上等效于一种被称为连续时间循环神经网络（continuous-time recurrent neural network）的输出。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些研究者为进行概念验证开发了一个 49 节点的硅光子神经网络——实验表明在一个实验性的差分系统仿真任务中比传统方法快了 1960 倍！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当然，验证性的实验不一定能够适用于实际的应用场景，但毫无疑问，这一研究为基于光子的神经网络的发展提供了重要的推动力。在带宽和速度需求日渐高涨的今天，这有望能为我们提供一种我们所需的解决方案。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;论文：神经形态硅光子学（Neuromorphic Silicon Photonics）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW81aVM2Gdgrxfsa0vR4YVib2oHGXtMueBWJRd0aIL6Ql79jc7sOibaWCAdGicsvZ0z8eTrG1lo7OZNMA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们报告首次观察到了集成模拟光子网络（integrated analog photonic network），其中的连接（connection）是通过 microring weight banks 和首次被用作光子神经元（photonic neurons）的电光调制器（electro-optic modulators）配置而成。这种硅光子电路和连续神经模型之间的数学同构（mathematical isomorphism）通过动态分叉分析（dynamical bifurcation analysis）而得到了证明。已有的神经工程工具可以利用这种同构性来适应硅光子信息处理系统。我们使用一种「神经编译器（neural compiler）」编程了一个的 49 节点的硅光子神经网络，它模拟了传统的神经网络，并且预计其表现在一个实验性的差分系统仿真任务中超过了传统方法 1960 倍。利用了硅光子平台的光子神经网络可以接入用于无线电、控制和科学计算的超快信息处理环境。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW81aVM2Gdgrxfsa0vR4YVib23nicicxz6UtbDfjEmKthoNVBPYaFFkI2WlnexOxFmppQCic9FSI7zMjhA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 1：带有用作神经元的调制器的 STAR broadcast-and-weight network。MRR: microring resonator, BPD: balanced photodiode, LD: laser diode, MZM: 马赫-曾德尔调制器 (Mach-Zehnder modulator), WDM: 波分复用器（wavelength-division multiplexer）。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW81aVM2Gdgrxfsa0vR4YVib2IqJRPVMib08b6ToIWLew9uSicvngjcbR4UTCiaia0DvRRTNiaMqHolcd4JA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 2：带有 2 个 MZM 神经元和一个外部输入的实验配置，阵列波导光栅（AWG）中进行波长复用，并耦合到一个片上 broadcastand-weight network。这个 2×2 的循环网络是由 MRR 权重配置的，w11，w12 等等。神经元状态由低通滤波跨阻抗放大器（low-pass filtered transimpedance amplifiers）的电压 s1 和 s2 表示。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译文章，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Sat, 19 Nov 2016 11:34:50 +0800</pubDate>
    </item>
  </channel>
</rss>
