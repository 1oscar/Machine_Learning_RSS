<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>机器之心</title>
    <link>http://www.iwgc.cn/list/670</link>
    <description>人与科技的美好关系</description>
    <item>
      <title>独家 | 吴恩达NIPS 2016演讲现场直击：如何使用深度学习开发人工智能应用？</title>
      <link>http://www.iwgc.cn/link/3801057</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;机器之心原创&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心特派记者加号&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;编辑：吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;当地时间 12 月 5 日，机器学习和计算神经科学的国际顶级会议第 30 届神经信息处理系统大会（NIPS 2016）在西班牙巴塞罗那开幕。大会第一天，百度首席科学家、Coursera 主席兼联合创始人、斯坦福大学 adjunct professor 吴恩达采用手写板书的形式做了一个主题为《使用深度学习开发人工智能应用的基本要点（Nuts and Bolts of Building Applications using Deep Learning）》的 tutorial 演讲。机器之心经授权对吴恩达教授演讲的幻灯片进行了汉化梳理。同时，机器之心特派记者加号也在现场聆听了吴恩达教授的演讲，并将演讲内容进行了整理和解读。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一年一度的 NIPS 又来了。今年举办地是笔者最爱的欧洲城市巴塞罗那。阳光沙滩配学术，确实很爽。这次的会议的第一天开场的大部分时间安排给了 tutorial。其中人数爆满的依旧是吴恩达（AndrewNg）的 session。笔者在此总结一下他的 tutorial 内容。一如以往的风格，这次吴恩达博士（有趣的是，本次官方介绍他的时候 使用的是 Dr. 而不是 Prof.）在台上也是纯白板讲演。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW83GIFs6icx4ictPqX5sphoStbRnGMZEcPOJv0mUDQmvQgheR8zicYsQ5NialLuEyVSmNgg73ZLL5uGyw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;开场的时候，&lt;/span&gt;&lt;span&gt;他问了一下全场观众哪些是来自工业界。哗哗哗，全场接近 50% 的观众举手了。确实，这几年的 NIPS 一年比一年火，并且工业界对这类学术会议的关注度也一年比一年高。吴恩达本人打趣道，正因为如此，他今天才没在准备的讲稿中加入任何一条公式，他希望他今天的 tutorial 更多的是能给大家带来理念上的更新，而不仅仅是晦涩难懂的新公式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;吴恩达博士这次 tutorial 的主题是：「nuts and bolts of building AI」，翻译成中文就是「建造人工智能系统小细节」，也就是说，这篇 tutorial 将会更多地注重于给涉足人工智能领域的业界公司一点点人生经验。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW83GIFs6icx4ictPqX5sphoStv1yeLSeMsZyzOOrnCYyHAetxvk77N8OBxmh9d3aF8GGOo2rwtRBKZA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;演讲主题概述：你应该怎样将深度学习用于你的业务、产品或科研？高扩展性的深度学习技术的兴起正在改变人们解决人工智能问题的最佳方式。这包括：如何定义你的训练/开发/测试（train/dev/test）分配，如何组织你的数据，应该如何在各种有希望的模型架构中选择你研究所需的架构，以及甚至你可以怎样开发新的人工智能驱动的产品。在这个 tutorial 中，你将了解到这个新兴领域中涌现出的最佳实践。你还将了解当你的团队在开发深度学习应用时，如何更好地组织你和你的团队的工作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;规模造就了深度学习（Scale driving Deep Learning progresses）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;开篇，吴恩达博士分析了一下当今深度学习这么火的原因。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW83GIFs6icx4ictPqX5sphoStslrh6z2rMPWmnpVmtd8rOU9PRNRJ9Ir64E4R8AMNnJ0rIJSY4SjEGA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;P2：趋势 1：规模正在推动深度学习的进步。随着数据量的增多，规模越大的神经网络的性能/表现（performance）就越好。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他指出，深度学习之所以这么火，主要原因是神经网络（NN）可以扩大规模（scale），甚至是可以无限地扩展。扩展之后所带来的效果是稳步提升的。并且靠扩展规模来引领深度学习，依旧会成为这个领域未来发展的大潮流。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;说到这里，吴博士开始给出他的第一条人生经验：我在百度的团队构架如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW83GIFs6icx4ictPqX5sphoStpicb76tic38oRFl2qQwMIwubWST7Gw2IrMRkZj7joC3Tx5XhKqcEDKSw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他认为在这个时代，没有人能做到在系统构架（底层）与深度学习（算法）方面都是专家，所以他的团队严格区分了两者的职责。所以，深度学习技术创业公司在技术团队建设的时候，可以做做参考。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;端对端学习的崛起（the rise of end-to-end learning）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;吴恩达博士还指出深度学习领域的另一个大潮将是端对端的学习（End2End learning）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW83GIFs6icx4ictPqX5sphoStiaRRhUqZOV1vs8MjpUh4Ou0PItdm4WNt5txm0t19HtDUaf3mHQiausibA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;P3：趋势 2：端到端学习的兴起&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;传统上的端到端学习是把实体数据表达成数字数据，并通过机器学习的方法，输出数字数据作为结果。比如对电影评论数据的情感分析：输入的是文本，然后通过自然语言处理（NLP）把文本数据表达成数字向量，再通过机器学习计算，得出一个情感值，用以作为对这条评论的情感判断。这也是一种端对端的模型，但是它的结果还是一个数字值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而现在随着深度学习的发展，更纯粹的端对端学习成为了可能。比如语音识别：输入的是语音，输出的是文本；比如机器翻译：输入的是英语，输出的是其他语言；再比如谷歌 DeepMind 的 WaveNet：输入的是文本，输出的是语音。这是比较纯粹的端对端学习。但是它也有缺点——也就是需要足够大的训练集。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW83GIFs6icx4ictPqX5sphoStkA9TMbtKcYByC2cJQIOa3Mae1JhHcsasDo3CRicia2jQsceicLzHpnnIA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;P5：端到端学习：语音识别。传统模型：音频→计算特征—（人工设计的 MFCC 特征）→音素识别器—（被识别出来的音素）→最后的识别器→输出。端到端学习：音频→学习算法→转录结果；在给定了足够的有标注数据（音频、转录）时，这种方法的效果会很好。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;传统的语音识别，需要把语音转换成语音特征量（一般来说，就是一组数字化的向量），然后把这组向量通过机器学习，分类到各种音节（Phonemes）上（这是一件语言学的事儿）。然后，我们通过音节，才能还原出语音原本要表达的单词。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而现在，我们可以直接通过深度学习将语音直接对标到我们最终显示出来的文本。通过深度学习自己的特征学习功能来完成从特征提取到音节表达的整个过程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当然，直接的端对端学习也有不太奏效的时候。比如，用计算机视觉判断进公司门的是否是自己的员工（用于公司打卡的计算机视觉）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这种情况下，端对端（E2E）的模型假设应该是：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW83GIFs6icx4ictPqX5sphoStBmp9eNPKP52DSOqRsHib9A2JdJXNS6wDty3onS5EbZbYJI7HEbmXibSQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然而，这种方法行不通，因为员工进场的背景会一直变化（想象一下，公司大门对面是公路，公路上的车每分每秒都不同，背景信息噪音太大）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以，现实情况下我们只能：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW83GIFs6icx4ictPqX5sphoStFC60mX3ajjGj9ViafzPPdb0MhpCuKL66HLicMdiafYwviccID6iaZw4C6wQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;先从图片中找到脸（使用 Attentional Network），然后将这张脸和公司内部的员工数据库比较来判断这个人的 ID（是不是我司的人）。这种方面就不是我们处女座的深度学习研究者所追求的端对端了，因为它的 workflow（流程）里掺和了太多其它信息和中间步骤，不够纯粹。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果，一个处女座的老板真的希望自己公司的门口用上非常纯粹的人工智能打卡机，那么他只能寄希望于非常非常大量的训练集。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;吴博士还举了一个关于深度学习用于医学领域的例子。这也是他在斯坦福的一个朋友的研究项——通过小孩手的 X 光来检测小孩子的年龄。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;同理，理想状态应该是直接从一张 X 光图中判断小孩子的年龄：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW83GIFs6icx4ictPqX5sphoSteuRbCRbez5hvOUzMsHupNAhqBPibZt9X89J8JrKSOHztW3C2VoSnTHw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;（注：左边那个是小孩的手的形象绘图）&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是实际上工业界的做法是首先通过 X 光图像判断出人骨的构架（一些代表人骨特征的数据），再依据医学上的公式来推导出被测试者的真实年龄：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW83GIFs6icx4ictPqX5sphoSticcDYPzGS9NGRRwjhAH1DAibMaBdoZiay1vkjqibqUFxw1Tq2sJNHS2Ficg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外还有一个例子是自动驾驶：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW83GIFs6icx4ictPqX5sphoSticaJwMEMonfKiaLBK1vnaD41OZMpb88OpANGuKZvQ63uyp7NSlX16FJA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;P6：端到端学习：自动驾驶。传统模型：相机图像→检测汽车+检测行人→为汽车规划路径→控制方向。端到端学习：相机图像→学习算法→控制方向。鉴于自动驾驶对安全的关键要求，所以也就需要极高的准确度，一种完全的端到端方法仍然难以应对这项工作。只有当你有足够的 (x,y) 数据时，端到端方法才会有效，才能学会所需复杂度水平的功能。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;吴博士说，他敢肯定现在市面上的自动驾驶技术都是如图所示的框架：通过图片观测附近的车（cars）与行人（pedestrians），计算出该有的路径规划（plan），然后通过公式/规则判断出应该进行的下一步行动（steering）。如果想直接把图片处理成最终的操作指令，那还真的还有很长很长的一段路要走。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以上种种例子归根结底的原因是：在这些端到端表现不太好的行业内，目前的数据规模还不足以支撑起一次靠谱的端到端的深度学习过程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;机器学习策略：如何有效地处理数据集&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW83GIFs6icx4ictPqX5sphoSt8Nia2sv4NxzGBOmiaHe5UibEZ4UWFCMZRTgXZicicLMAoQ48ibXmSiaX9rXOg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;P7：机器学习策略：在改进一个人工智能系统时，你往往会有大量的想法，你会怎么做？好的策略能帮助你节省好几个月的努力时间。&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;比如，我们以语音识别为例。如果我们的目标是识别出语音，我们可以把我们手上的原语音数据分割成：60% 训练集、20% 开发集和 20% 测试集：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW83GIFs6icx4ictPqX5sphoStKiaBa8iczSrq8zzQicKic12orHpbuoS8ECLAGUqW8ibvEbcRwkFAg9sZVYw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其中，训练集（training set）是我们用来训练模型的，开发集（dev set）指的是在开发过程中用于调参、验证（validation）等步骤的数据集（保证不被模型提前学习到），测试集（test set）很显然就是指测试时所使用的数据集。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有了这三个数据集，我们就可以得出三个误差值（分别为）：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW83GIFs6icx4ictPqX5sphoStolux34PVGpvUIcFc1RbhzyN0SUeRKM2BZ5t5diasHv4FAtyTOatQLZw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其中，人类水平的误差（human level error）是人类自己处理这类问题的误差值；训练集误差（training set error）是指在训练集上跑出来的误差值；开发集误差（dev set error）是指用开发集跑出来的误差值。（测试集误差后面会说）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然而我们关注的并不是这个误差值本身，而是它们互相之间的差距。人类误差与训练集误差之间的差距称为「avoidable bias」（可避免的偏差，可简称为偏差）。之所以说「可避免的（avoidable）」，是因为这部分误差可以通过进一步的学习/模型调整优化来避免。而训练集和开发集之间的差距称为「variance（方差）」，它是因为跑了不同的数据而导致的误差率变化（比如跑在见过的数据集上和没见过的数据集上的误差率之差）。这两种偏差合在一起，就是机器学习领域著名的 bias-variance trade-off（偏差-方差权衡）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;那么，同样是这三组数据，如果你遇到的情况是：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW83GIFs6icx4ictPqX5sphoStMrOmgyPicQpBiaxgpKMKFhjQCzGXBe4amXoZOibsicCwrWwEg3icx6keKibA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;（左边是 1%, 2%, 6% ; 右边是 1%, 6%, 10%）&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;左边的情况是：训练集误差率与人类自己的误差率只相差 1%，然而训练集误差跟测试集误差却差了很多；这就意味着你的模型在新的（没见过）的数据上表现很不好，换句话说，你的模型过拟合（overfitting）了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而对于右边的情况，如果你的训练集误差跟人类误差值相比就已经差了很多，而测试集误差则更加地多，那么，洗洗睡吧，这模型没戏。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;吴恩达博士表示，很多企业都不遵循他上文提到的这个洞察误差值区别的配方（recipe）。如果大家都能够科学地量化并且重视起这个误差差值的话，在工业应用开发上就会省事很多。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;于是，他给出了这个洞察偏差值的配方的具体操作步骤：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW83GIFs6icx4ictPqX5sphoStBfyRBsE1o2IbBy8JZZmAlSzBa0ZUFtBnFzEoAOL1yTTUjYEniaGR6rw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;P9：机器学习的基本配方：如果训练误差高（偏差），就使用更大的模型、训练更长的时间、采用新的模型架构；如果开发误差高（方差），就使用更多数据、正则化、新的模型架构。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先，判断训练集误差率是否过高？如果是的话，说明你遇到了 bias 危机，你可以（OR 的逻辑关系）：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 提高你的模型规模；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 加长你的模型训练时间；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3. 启用新的模型构架。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果训练集误差率不很高，那么，开发集误差是否很高？如果是的话，说明你遇到了 variance 危机，你可能需要（OR 的逻辑关系）：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 拿更多的数据；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 正则化；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3. 启用新模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;数据合成（Data Synthesis）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;什么是数据合成？举个例子，在语音识别领域，用清晰的声音记录来做训练集是不给力的。因为在应用场景中，不会有那么安静的背景环境。所以需要人为添加一些噪音。这些噪音在人类的眼里没什么大问题，但是对机器学习算法来说，却是个大大的考验。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;类似的例子还有：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW83GIFs6icx4ictPqX5sphoStfnVfib7uUqlCMOohRYUBsic5WWSkfywbZKzh5yeg7DCR3EhHKYq9UuOA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;P10：自动数据合成的例子。OCR：将文本插入随机背景中；语音识别：将清晰的音频混入不同的背景噪声中；NLP：语法纠错：合成随机的语法错误。有时候，一些在人眼看来很好的合成数据实际上对机器学习算法来说是信息不足的，而且只涵盖了实际数据分布的一小部分。比如说，从视频游戏中提取出来的汽车图像。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;讲到这里，吴博士突然又插播了一条人生经验：我们企业呀，不要整天想搞个大新闻，东边一个服务器，西边一个服务器，显得自己很国际化。可是这样搞得数据很不统一。他十分建议企业都使用 unified data warehouse（统一化的数据中心），让数据科学家可以安心的玩数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;经验分享介绍后，吴博士具体举个了智能后视镜的例子：如果我们要做个智能后视镜（语音操作的车内智能助手），我们的数据该怎么搞？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先，假设我们有 50000 小时的语音资料（随便在哪里下载来的）和 10 小时的车内对着后视镜讲话的语音资料（比如，让客户假装他的后视镜是智能的，然后录下一些语音指令……）。面对这些数据，我们该如何构造我们的训练集？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW83GIFs6icx4ictPqX5sphoStucAVGNjRm7duzia4LraQISzjbDNRlR0vib2BwPQHYxnmg6UoImfzPmDw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有人可能会这样说：50000 小时语料够大，可以分出一些来做开发集（dev set），其他的用来训练。而 10 小时珍贵的车内语音则做成测试集。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;错！这是个非常不好的处理方式，因为你的开发集和测试集没能遵从相同的数据分布（distribution）。换句话说，开发集和测试集的内容「根本就不在同一个宇宙」。这样的结果就是，你的数据工程师在开发集上花费了很大的精力之后，结果放到测试集上却发现并没有什么用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一个比较靠谱的处理方式应该是：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW83GIFs6icx4ictPqX5sphoStZPlN7XchIThtUgIaR5cGhjlBqSFnvc7Wxn0IUicYJTJdT3t9cpPx7tw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;把 10 小时的车内语料分成开发集和测试集。同时，你也可以拿出训练集中的一部分内容作为训练-开发集（train-dev set）。这个数据集能帮助你的算法在训练集上做好优化，再转移到真实场景中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;按照这个构架，我们于是可以得到五种不同的误差值：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW83GIFs6icx4ictPqX5sphoSt8FsjAz1GKWSvwqrBr6rvaKwwfic5P2jJyoias7wiauv0PSDtuTPb4tFTA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人类误差、训练集误差，训练-开发集误差、开发集误差、测试集误差&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其中，人类误差与训练集误差之间的差值还是称为 bias（偏差）；训练集误差与训练-开发误差之间的差值称为「训练集的过拟合」（也就是说，它代表了模型单纯在训练集上表现能力）；训练-开发误差与开发集误差之间的差值称为「data mismatch」（数据不匹配，就是刚才说的两组数据不在同一个「宇宙」带来的偏差）；开发集误差与测试集误差之间的差值称为「开发集过拟合」（同理）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个时候，拥有的差值就更多了，我们就需要一个新的处理策略：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW83GIFs6icx4ictPqX5sphoStWGsGniaqFfFetDicNSDu50nbB81hYnwQvia4lS9CxxlPy6ClqkkheNa0w/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;P13：用于机器学习的新配方：如果训练误差高（偏置），就使用更大的模型、训练更长时间、使用新的模型架构；如果训练-开发误差高（方差），就使用更多数据、正则化、新的模型架构；如果开发误差高（训练-测试数据不匹配），就使训练数据更近似于测试数据、进行数据合成（域适应）、使用新的模型架构。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当你遇到数据不匹配（data mismatch）时，你可以：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 让你的训练集跟测试集更加相似；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 数据合成；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3. 尝试新模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而这时候，如果你又遇到了测试集误差太高的情况，那么你就只能寻求更多的测试集了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;总结一下以上内容，我们可以得出下面这张表：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW83GIFs6icx4ictPqX5sphoStgMTzTNYERrlwW76DnjmxGGTaETmQ2gelMBVxfeHcOQQsaeNbciaQMrQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;P14：一般的人类/偏差/方差分析&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;人类水平的表现（Humen-Level performance）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于人类误差和机器学习误差，你会发现一个规律：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW83GIFs6icx4ictPqX5sphoStIPMRzFrzLvtYWsFuQDBrlIoDCd1GR3r36q5bdcL3IiazvFKzfenFAVw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当机器学习比人类水平低时，它的准确率的提升是很快的。但是当它超越人类以后，往往准确率提升效率就逐步降低了。并且，在人类水平线的上方，有一个叫 Bayes Optimal Error（贝叶斯最优误差）的线，这是我们人和机器学习都永远无法逾越的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW83GIFs6icx4ictPqX5sphoStNadoSGKQrrz0iawsbiblyDxaF347sV9HDglfgyiajXJSZ9jDgiaJxJDoLA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这一切的原因有二：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 机器学习超越人类以后，很快就会靠近贝叶斯最优误差线，这是一条理论上无法逾越的线。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 数据带有人类自己做的标签（label），所以本身就含有人类自己的见解（insight）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW83GIFs6icx4ictPqX5sphoStaiauhpOpEu7CKNn0QhHDGc23IxgDebXqTAyiaqEnpxc6T3630wSgNSew/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;P16：小测试：医学成像&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在医学领域，如果我们想用深度学习来观察医学图像并作出判断，那么，以下哪一种应该被我们选作人类的误差值（human-level error）？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 一个普通人 3%&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 一个普通医生 1%&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3. 一个专家医生 0.7%&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4. 一个医生专家组 0.5%&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;答案：选 4.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因为 4 是人类能达到的最大限度，也是最靠近 Bayes Error 线的地方。我们做机器学习的目的就是要让我们的误差率无限接近于 Bayes Error 线。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;关于人工智能的未来&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;讲到这里，吴恩达教授又顺便展望了一下人工智能的未来：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW83GIFs6icx4ictPqX5sphoStYSq72CbKhf6MCBo1pn1W5eA6IkD4R2lrax7SBP3J2PAIiby25lyCJhA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他说，从 2011 年以来，supervised learning（监督学习）是发展得最快的。也将继续快速发展下去，因为现有的有标签数据还远远没有被发掘完毕。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当然，他也不否认，真正的人工智能未来还是会落在 unsupervised learning（无监督学习）和 reinforcement learning（强化学习）上。但是，很明显，如我们所知，这两个领域目前的水平跟有监督的深度学习是完全没法比的。他预测这两个领域会在 2016 年以后逐步起飞。其中强化学习飞得慢点，因为目前大多数强化学习都还仅仅被运用在电子游戏模拟上，而无监督学习似乎是起点高一点，因为我们熟知的很多算法就已经是无监督学习了（比如：word2vec）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然而，在这一切还没有成熟之前，他认为还有一个折中的处理方法：迁移学习（transfer learning）。简单来说，就是把有标签或者数据量大的集合用于预训练（pre-train），然后在此基础上对真正的目标数据集进行无监督优化。相比于完全的无监督，这条路似乎更有希望。说到这里，吴恩达博士又振臂一呼：希望学界能在迁移学习上产出更多高质量的理论与论文。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;人工智能产品管理（AI product management）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，吴博士讲了人工智能领域的产品经理应该做些什么。他们被赋予了更多的职责，需要做更多的思考。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一个人工智能产品经理的工作流：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW83GIFs6icx4ictPqX5sphoSt21UJFGwxM2zic9IbiclfaCYdicS1HSgicKibiaia2JPcnSiaf3USKZercJwPSQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;跟一般的产品经理类似，PM 对用户负责，并将需求反馈给工程师。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;举个例子，在做语音识别的时候，我们可以选择：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;不同的噪音背景&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;重点关注的口音&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;语音文件的大小&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;等等&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能产品经理需要选择工程师应该关注的重点，从而让数据集能更准确地模拟出应用场景。简单来说就是寻找用户需求与当今机器学习技术的能力的交集：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW83GIFs6icx4ictPqX5sphoStyzs2afyWfG6n2KDZZQWwnCOYtOc6hicpFIXrLW5P5UbBRfF2VCnvIaA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;具体来讲，一个人工智能产品经理的任务如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW83GIFs6icx4ictPqX5sphoStLyBYj1PQicXm6gsibcfLPcwfBS88QheMtVXxeh0yic9yNbGqnOiaexd0ow/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;产品经理需要提供出靠谱的测试和开发集，并提出靠谱的验证方法（metrics）。相应地，工程师就会依照这个需求，来获取他们需要的训练集，并开发靠谱的人工智能系统。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，吴恩达博士在演讲幻灯片最后一页推荐了他的新书《Machine Learning Yearning》，对于人工智能产品设计理念及策略有兴趣的读者，可以在 http://www.mlyearning.org/ 免费订阅一部分。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW83GIFs6icx4ictPqX5sphoStNseMOUOuB84mdxT1Wo4PvYVlvp4ZFH1oJwtccBEUevR9n4tPkBRPog/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;总结&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;总体来说，吴恩达博士的这场 tutorial 非常客气地照顾到了人数庞大的工业界听众。具体的点都放在了人工智能产品开发的策略与技巧上，并还时不时地插入了几句人生经验。可见，他在谷歌和百度的这些年正在将他一步步从一位顶尖的学界大拿跨界成一位顶尖的产品人。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译文章，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 06 Dec 2016 11:55:24 +0800</pubDate>
    </item>
    <item>
      <title>重磅 | DeepMind 开源3D人工智能训练平台（附论文和视频）</title>
      <link>http://www.iwgc.cn/link/3801058</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自DeepMind blog&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：微胖、李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;DeepMind 的科学任务就是推进人工智能边界，研发无师自通、解决任何复杂问题的系统。为此，我们从这样一个前提出发：人工智能应该是通用的。智能体应该可以用于广泛任务当中并能自动适应变化中的环境。也就是说，它们不应该是预编程的，毋宁能从初始输入以及环境奖励信号中自动学习。这一研究有两部分：（１）设计更加智能的智能体，具有越来越成熟的认知技能，以及（２）打造日趋复杂的环境，可在其中训练和评估智能体。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;iframe class="video_iframe" data-vidtype="1" style="   z-index:1; " height="375" width="500" frameborder="0" data-src="https://v.qq.com/iframe/preview.html?width=500&amp;amp;height=375&amp;amp;auto=0&amp;amp;vid=g0352nezsz1" allowfullscreen=""&gt;&lt;/iframe&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;视频 Laser Tag Space Bounce Level&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;创新智能体的研发，与谨慎设计以及理性挑选、灵活以及维护良好的环境实现密不可分。为此，我们花费大量精力打造丰富模拟环境，作为人工智能研究实验室。现在，我们正在开源我们的旗舰平台——DeepMind Lab，因此，更为广大的社区就能用到它。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;iframe class="video_iframe" data-vidtype="1" style="   z-index:1; " height="375" width="500" frameborder="0" data-src="https://v.qq.com/iframe/preview.html?width=500&amp;amp;height=375&amp;amp;auto=0&amp;amp;vid=g0352odpi4h" allowfullscreen=""&gt;&lt;/iframe&gt;&lt;br/&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;视频 Nav Maze&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;DeepMind Lab 是一个类全3D游戏平台，为基于智能体的人工智能研究量身打造。通过模拟智能体的眼睛，从第一人称视角进行观察。我们使用丰富的科幻式视觉效果进行诠释。智能体可以在3D环境中环顾四周并进行移动。智能体的身体是一个悬浮圆形物，并配有一个摄像头，它能围绕主球面移动，充当追踪旋转观察动作的球窝关节。样本游戏包括收集水果、在迷宫中移动、横穿危险通道同时避免掉下悬崖、使用发射台跃于两个平台之间、玩激光标签以及迅速学习并记忆随机生成的环境。智能体如何感知并与世界互动的图解如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW83GIFs6icx4ictPqX5sphoStetc60Zp5wAvxmjjQM5wsibHhoo5QKSXnZUHtp3NUeicwxXYfUK20f7dQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;智能体将世界视为一张图像，以像素的方式，从自己第一人称视角进行诠释。他们也会收到奖励或惩罚信号。智能体能够激活其推进器进而在3D环境中移动，也能沿着水平、垂直轴线转动视角。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;DeepMind 的人工通用智能研究强调导航、记忆、第一任人称的3D视角、行动控制、计划、策略、时间以及全自动化智能体，必须能通过探索自己周边环境自学任务内容。所有这些因素让学习变得困难。每个内容都有资格被视为更加前沿的研究问题。像我们这样将它们放在一个平台上，是对这一领域的新的重要挑战。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;iframe class="video_iframe" data-vidtype="1" style="   z-index:1; " height="375" width="500" frameborder="0" data-src="https://v.qq.com/iframe/preview.html?width=500&amp;amp;height=375&amp;amp;auto=0&amp;amp;vid=j0352kjxdjw" allowfullscreen=""&gt;&lt;/iframe&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;视频Stairway to Melon&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;DeepMind Lab 高度可自定义、可延展。使用现成的编辑工具就能达到新级别（level）。此外，DeepMind Lab 包含一个进行 programmatic level-creation 的接口。使用 gameplay logic、item pickups、custom observations、level restarts、reward schemes、in-game messages 等更多工具可自定义出更高的级别。该接口可被用于创造这样的级别：在智能体训练时生成全新地图布局。这些特征在测试智能体是否适应不熟悉环境时非常有用。用户可以通过 Github 为该平台增加自定义级别。该资源以及所有的代码、地图和 level scripts 都被托管在了 Github 上。我们希望社区能帮助我们更进一步塑造以及开发该平台。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;DeepMind Lab 已在 DeepMind 内部被使用了一段时间了（案例：突破 | DeepMind为强化学习引入无监督辅助任务，人工智能的Atari游戏水平达到人类的9倍）。我们相信它对我们从多个方面思考智能有着极大的影响。然而，目前我们的努力只触摸到 DeepMind Lab 的表面。通过 DeepMind Lab，在大量仍未触及的研究领域中，也有机会作出有极大意义的贡献，比如导航（navigation ）、记忆（memory）和探索（exploration）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;和促进智能体（facilitating agent）评估一样，也有强有力的理由让人相信在 3D 世界中以第一视角开发智能更为简单，例如 DeepMind Lab。毕竟，在自然世界我们所知的通用智能的唯一案例就来自于进化、发育和学习的结合，以动物的身体和感官器官为基础。人类与动物智能的一大部分有可能是环境引发的直接结果，没有环境不太可能产生这种智能。替代思考一下：如果你或我生长在 Space Invaders （游戏名） 或 Pac-Man 这样的环境中，可能我们就无法获得很多的通用智能！&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译文章，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 06 Dec 2016 11:55:24 +0800</pubDate>
    </item>
    <item>
      <title>学界｜NIPS 2016现场：谷歌发布 28 篇机器学习论文（附全论文）</title>
      <link>http://www.iwgc.cn/link/3801059</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Google Blog&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：杜夏德、李泽南&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;本周，机器学习和计算神经科学领域的顶级大会第 30 届国际神经信息处理系统大会（NIPS2016）在巴塞罗那举办，内容包括演讲、展示和宣讲和海报展示，在这里可以一睹最新的机器学习研究。谷歌带着 280 名员工强势亮相，除了技术演讲和海报展示外，他们还将举办研讨会和多个 tutorials。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谷歌的研究一直走在机器学习的前沿，积极探索机器学习的各个方面，包括经典算法以及像深度学习这样的前沿技术，既关注理论也重视应用。他们在语言理解、语音、翻译、视觉处理、排名和预测上的很多成果都依赖于机器智能。在所有的任务中，他们收集了大量直接或间接的利益关系的证据，并开发学习理解和泛化的方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Invited Talk&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;标题：Dynamic Legged Robots&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;作者：Marc Raibert&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;新一代高性能的机器人正在离开实验室进入现实世界，出现在办公室、家庭以及一些普通机器无法到达的地方。这些新兴机器人使用探测器来观察周边，并依靠其在环境中导航，理解环境，与环境互动。它们敏捷、灵巧和自主和智能都在按照将人类从各种任务中解放出来的愿景在不断发展进化。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;28篇论文&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1.论文：Boosting with Abstention&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;作者：Corinna Cortes, Giulia DeSalvo, Mehryar Mohri&lt;br/&gt;论文地址：http://papers.nips.cc/paper/6335-boosting-with-abstention&lt;br/&gt;&lt;br/&gt;&lt;strong&gt;2.论文： Community Detection on Evolving Graphs&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;作者：Stefano Leonardi, Aris Anagnostopoulos, Jakub Łącki, Silvio Lattanzi, Mohammad Mahdian&lt;br/&gt;论文地址：http://papers.nips.cc/paper/6173-community-detection-on-evolving-graphs.pdf&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;&lt;strong&gt;&lt;span&gt;3.论文:Linear Relaxations for Finding Diverse Elements in Metric Spaces&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;作者：Aditya Bhaskara, Mehrdad Ghadiri, Vahab Mirrokni, Ola Svensson&lt;br/&gt;论文地址：http://papers.nips.cc/paper/6500-linear-relaxations-for-finding-diverse-elements-in-metric-spaces.pdf&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;&lt;strong&gt;&lt;span&gt;4.论文：Nearly Isometric Embedding by Relaxation&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;作者：James McQueen, Marina Meila, Dominique Joncas&lt;br/&gt;论文地址：http://papers.nips.cc/paper/6535-nearly-isometric-embedding-by-relaxation.pdf&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;&lt;strong&gt;&lt;span&gt;5.论文：Optimistic Bandit Convex Optimization&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;作者：Mehryar Mohri, Scott Yang&lt;br/&gt;论文地址：http://papers.nips.cc/paper/6429-optimistic-bandit-convex-optimization.pdf&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;&lt;strong&gt;&lt;span&gt;6.论文：Reward Augmented Maximum Likelihood for Neural Structured Prediction&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;作者：Mohammad Norouzi, Samy Bengio, Zhifeng Chen, Navdeep Jaitly, Mike Schuster, Yonghui Wu, Dale Schuurmans&lt;br/&gt;论文地址：http://papers.nips.cc/paper/6547-reward-augmented-maximum-likelihood-for-neural-structured-prediction.pdf&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;&lt;strong&gt;&lt;span&gt;7.论文：Stochastic Gradient MCMC with Stale Gradients&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;作者：Changyou Chen, Nan Ding, Chunyuan Li, Yizhe Zhang, Lawrence Carin&lt;br/&gt;论文地址：http://papers.nips.cc/paper/6359-stochastic-gradient-mcmc-with-stale-gradients.pdf&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;&lt;strong&gt;&lt;span&gt;8.论文：Unsupervised Learning for Physical Interaction through Video Prediction&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;作者：Chelsea Finn&lt;/span&gt;&lt;a style="font-size: 14px; text-decoration: underline;"&gt;&lt;span&gt;*&lt;/span&gt;&lt;/a&gt;&lt;span&gt;, Ian Goodfellow, Sergey Levine&lt;br/&gt;论文地址：http://papers.nips.cc/paper/6161-unsupervised-learning-for-physical-interaction-through-video-prediction.pdf&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;9.论文：Using Fast Weights to Attend to the Recent Past&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;作者：Jimmy Ba, Geoffrey Hinton, Volodymyr Mnih, Joel Leibo, Catalin Ionescu&lt;br/&gt;&lt;/span&gt;&lt;span&gt;论文地址：http://papers.nips.cc/paper/6057-using-fast-weights-to-attend-to-the-recent-past.pdf&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;10.论文：A Credit Assignment Compiler for Joint Prediction&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;作者：Kai-Wei Chang, He He, Stephane Ross, Hal III&lt;br/&gt;论文地址：http://papers.nips.cc/paper/6256-a-credit-assignment-compiler-for-joint-prediction.pdf&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;&lt;strong&gt;&lt;span&gt;11.论文：A Neural Transducer&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;作者：Navdeep Jaitly, Quoc Le, Oriol Vinyals, Ilya Sutskever, David Sussillo, Samy Bengio&lt;br/&gt;论文地址：http://papers.nips.cc/paper/6594-an-online-sequence-to-sequence-model-using-partial-conditioning.pdf&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;&lt;strong&gt;&lt;span&gt;12.论文：Attend, Infer, Repeat: Fast Scene Understanding with Generative Models&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;作者：S. M. Ali Eslami, Nicolas Heess, Theophane Weber, Yuval Tassa, David Szepesvari, Koray Kavukcuoglu, Geoffrey Hinton&lt;br/&gt;&lt;/span&gt;&lt;span&gt;论文地址：http://papers.nips.cc/paper/6230-attend-infer-repeat-fast-scene-understanding-with-generative-models.pdf&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;&lt;strong&gt;&lt;span&gt;13.论文：Bi-Objective Online Matching and Submodular Allocations&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;作者:Hossein Esfandiari, Nitish Korula, Vahab Mirrokni&lt;br/&gt;论文地址：http://papers.nips.cc/paper/6085-bi-objective-online-matching-and-submodular-allocations.pdf&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;&lt;strong&gt;&lt;span&gt;14.论文：Combinatorial Energy Learning for Image Segmentation&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;作者：Jeremy Maitin-Shepard, Viren Jain, Michal Januszewski, Peter Li, Pieter Abbeel&lt;br/&gt;论文地址：http://papers.nips.cc/paper/6595-combinatorial-energy-learning-for-image-segmentation.pdf&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;&lt;strong&gt;&lt;span&gt;15.论文：Deep Learning Games&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;作者：Dale Schuurmans, Martin Zinkevich&lt;br/&gt;&lt;/span&gt;&lt;span&gt;论文地址：http://papers.nips.cc/paper/6315-deep-learning-games.pdf&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;&lt;strong&gt;&lt;span&gt;16.论文：DeepMath - Deep Sequence Models for Premise Selection&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;作者：Geoffrey Irving, Christian Szegedy, Niklas Een, Alexander Alemi, François Chollet, Josef Urban&lt;br/&gt;论文地址：http://papers.nips.cc/paper/6280-deepmath-deep-sequence-models-for-premise-selection.pdf&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;&lt;strong&gt;&lt;span&gt;17.论文：Density Estimation via Discrepancy Based Adaptive Sequential Partition.&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;作者：Dangna Li, Kun Yang, Wing Wong&lt;br/&gt;论文地址：http://papers.nips.cc/paper/6217-density-estimation-via-discrepancy-based-adaptive-sequential-partition.pdf&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;&lt;strong&gt;&lt;span&gt;18.论文：Domain Separation Networks&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;作者：Konstantinos Bousmalis, George Trigeorgis, Nathan Silberman, &amp;nbsp;Dilip Krishnan, Dumitru Erhan&lt;br/&gt;论文地址：http://papers.nips.cc/paper/6254-domain-separation-networks.pdf&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;&lt;strong&gt;&lt;span&gt;19.论文：Fast Distributed Submodular Cover: Public-Private Data Summarization &lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;作者：Baharan Mirzasoleiman, Morteza Zadimoghaddam, Amin Karbasi&lt;br/&gt;http://papers.nips.cc/paper/6540-fast-distributed-submodular-cover-public-private-data-summarization.pdf&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;&lt;strong&gt;&lt;span&gt;20.论文：Satisfying Real-world Goals with Dataset Constraints&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;作者：Gabriel Goh, Andrew Cotter, Maya Gupta, Michael P Friedlander&lt;br/&gt;论文地址：http://papers.nips.cc/paper/6316-satisfying-real-world-goals-with-dataset-constraints.pdf&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;&lt;strong&gt;&lt;span&gt;21.论文：Can Active Memory Replace Attention?&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;作者：Łukasz Kaiser, Samy Bengio&lt;br/&gt;论文地址：http://papers.nips.cc/paper/6295-can-active-memory-replace-attention.pdf&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;&lt;strong&gt;&lt;span&gt;22.论文：Fast and Flexible Monotonic Functions with Ensembles of Lattices&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;作者：Kevin Canini, &amp;nbsp;Andy Cotter, &amp;nbsp;Maya Gupta, &amp;nbsp;Mahdi Fard, &amp;nbsp;Jan Pfeifer &lt;br/&gt;论文地址：http://papers.nips.cc/paper/6377-fast-and-flexible-monotonic-functions-with-ensembles-of-lattices.pdf&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;&lt;strong&gt;&lt;span&gt;23.论文：Launch and Iterate: Reducing Prediction Churn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;作者：Quentin Cormier, Mahdi Fard, Kevin Canini, Maya Gupta&lt;br/&gt;论文地址：http://papers.nips.cc/paper/6053-launch-and-iterate-reducing-prediction-churn.pdf&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;&lt;strong&gt;&lt;span&gt;24.论文：On Mixtures of Markov Chains&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;作者：Rishi Gupta, Ravi Kumar, Sergei Vassilvitskii&lt;br/&gt;论文地址：http://papers.nips.cc/paper/6078-on-mixtures-of-markov-chains.pdf&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;&lt;strong&gt;&lt;span&gt;25.论文：Orthogonal Random Features&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;作者：Felix Xinnan Yu, &amp;nbsp;Ananda Theertha Suresh, &amp;nbsp;Krzysztof Choromanski, &amp;nbsp;Dan Holtmann-Rice, Sanjiv Kumar&lt;br/&gt;论文地址：http://papers.nips.cc/paper/6246-orthogonal-random-features.pdf&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;&lt;strong&gt;&lt;span&gt;26.论文：Perspective Transformer Nets: Learning Single-View 3D Object Reconstruction without 3D Supervision&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;作者：Xinchen Yan, Jimei Yang, Ersin Yumer, Yijie Guo, Honglak Lee&lt;br/&gt;&lt;br/&gt;&lt;strong&gt;27.论文：Structured Prediction Theory Based on Factor Graph Complexity&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;作者：Corinna Cortes, Vitaly Kuznetsov, Mehryar Mohri, Scott Yang&lt;br/&gt;论文地址：http://papers.nips.cc/paper/6485-structured-prediction-theory-based-on-factor-graph-complexity.pdf&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;&lt;strong&gt;&lt;span&gt;28.论文：Toward Deeper Understanding of Neural Networks: The Power of Initialization and a Dual View on Expressivity&lt;/span&gt;&lt;br/&gt;&lt;/strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;作者：Amit Daniely, Roy Frostig, Yoram Singer&lt;br/&gt;论文地址：http://papers.nips.cc/paper/6427-toward-deeper-understanding-of-neural-networks-the-power-of-initialization-and-a-dual-view-on-expressivity.pdf&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Demonstrations&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;标题：Interactive musical improvisation with Magenta&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;作者：Adam Roberts, Sageev Oore, Curtis Hawthorne, Douglas Eck&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们结合了基于LSTM的循环神经网络和Deep Q-learning建立了实时生成音乐序列。LSTM的任务是学习音乐评分（编码为MIDI，而不是音频文件）的一般结构。Deep Q-learning用来改进基于奖励的序列，如期望的类型，组成正确性和预测人类协作者演奏的内容。基于RNN模型的生成与强化学习的结合是一种生成音乐的全新方式。这种方式比单独使用LSTM更为稳定，生成的音乐更加好听。该方法有两个任务：生成对短旋律输入的响应，以及实时生成对旋律输入的伴奏，持续对未来输出进行预测。本方法在TensorFlow中加入了一个全新的MIDI接口产生即兴的音乐体验，让使用者可以与神经网络实时交互。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;标题：Content-based Related Video Recommendation&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;作者：Joonseok Lee&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是一个相关视频推荐的展示，种子来源于YouTube上随机的视频，纯粹基于视频内容信号。传统的推荐系统使用协同过滤**（CF）** 方法，在有多少用户在看了种子视频之后观看特定的候选视频的基础之上来推荐相关视频。这种方式没有考虑视频内容但是考虑了用户行为。在这个展示中，我们关注的是冷启动问题，其中种子或者候选视频都是新上传的（或者未被发现的）。对此我们按照一个基于视频内容的相似性学习问题进行建模，并学习了深度视频嵌入经过训练去预测真实情况的视频关系（由一个CF基于协同手表的系统鉴定） &amp;nbsp;，但仅使用视觉内容。它基于任一新视频内容，将其嵌入进一个1024维的表征中，同时成对视频的相似性在嵌入的空间中仅当做一个点积来计算。我们发现，被学习的视频嵌入超越了简单的视觉相似性，并能捕捉复杂的语义关系。 &amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;更多的 workshops 和 tutorials 可点击网址：https://research.googleblog.com/2016/12/nips-2016-research-at-google.html&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译文章，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 06 Dec 2016 11:55:24 +0800</pubDate>
    </item>
    <item>
      <title>业界｜NIPS 2016现场：LeCun 联同英伟达，推深度学习教学工具包</title>
      <link>http://www.iwgc.cn/link/3801060</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Nvidia&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：朱思颖、李泽南&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;随着高校研究生对人工智能技术需求的剧增，我们（英伟达）发布了深度学习工具包来帮助高校的教学人员更好的指导他们的学生，尤其是在 GPU 加速计算方面的教学指导。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在本周一巴塞罗那举行的 NIPS2016 会议上，英伟达推出了这款工具包，并称是和深度学习界的领军人物 Yann LeCun 合作研发的，研发过程是基于 LeCun 在纽约大学的深度学习课程展开的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相比于之前的深度学习网络的训练时间消耗和计算设备耗资，在英伟达快速精进的 GPU 技术的支持下，现在的深度学习网络的训练更加高效和经济。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这也是由当前人工智能热所催生出来的，人工智能赋予了机器感知和理解我们周围所处环境的能力，更确切的说是以模仿人类自身认知的方式来感知和理解我们的环境，人工智能所赋予机器的能力甚至可以超越人类自身的认知能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「深度学习已经成为当前最重要的计算模型之一，这一领域的研究生对深度学习的理论和应用操作的需求是很迫切的，」LeCun 说道。「英伟达的深度学习指导工具包为高校深度学习的教学人员提供丰富的教学资源，同时也支持教员们将 GPU 与深度学习相结合用于目前开展和尚未开展的课程中。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过我们的 GPU 教员项目（GPU Educators Program），我们和学界的教授合作开发指导工具包。在我们的合作里，可以把业界最新的应用及趋势同深度学习的基础理论及测试的教学技术结合起来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;英伟达的深度学习学院是主导这次学界-业界合作的先锋力量，而且这项合作将惠及全世界的深度学习开发人员，提供开发者在应用中 如何设计、训练和部署由深度学习驱动的人工智能技术。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;英伟达的深度学习学院还同有名的线上教育机构开展合作（如 Udacity 和 Coursera），以及领先的云服务提供商积极合作（如微软），来通力打造线上个人训练项目以在全世界范围内普及深度学习。深度学习指导工具包将英伟达深度学习学院的影响力扩散到世界各地的大学中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;想更多的了解这款深度学习指导工具包以及英伟达其他的指导工具包，请访问英伟达开发者门户网站的指导包主页。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;地址：https://developer.nvidia.com/teaching-kits&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译文章，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 06 Dec 2016 11:55:24 +0800</pubDate>
    </item>
    <item>
      <title>业界｜Uber 成立人工智能实验室 Uber AI Lab，解决所有业务问题</title>
      <link>http://www.iwgc.cn/link/3801061</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自The Verge&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：曹瑞、蒋思源、杜夏德&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW83GIFs6icx4ictPqX5sphoStxREvbSjtEt1LTaBdEmlJHlOta4Lr1opzUmP2PpPYvCpwXJ9nkPxXbg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Uber 刚刚宣布成立新的研究小组 Uber AI Labs，专注于改善从外卖派送路线规划到 Uber 自动驾驶汽车行驶方式的所有任务。实验室主要成员来自一家名为 Geometric Intelligence 的创业公司成员（Uber 刚收购的一家公司，不过没有公开收购价格）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;新实验室成立宣告 Uber 继续经营着匹兹堡地区的无人车队，自 9 月以来它一直为一些特定的客户提供无人驾驶服务。它也为 Uber 的应用程序做一些重要的更新，如精简了许多功能使它比以往更有趣、更加容易操作。一位发言人说人工智能实验室解决整个业务中的所有问题，包括自动驾驶操作人员。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Geometric Intelligence 由三位教授和一名研究生于 2014 年 10 月创办，他们是 Gary Marcus（纽约大学的认知科学家），Zoubin Ghahramani（剑桥机器学习教授），Kenneth Stanley（中佛罗里达大学计算机科学教授）和 Douglas Bemis（纽约大学毕业的神经语言学博士）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Marcus 将担任 Uber 新实验室的主任，Ghahramani 担任副主任。初创公司 15 人团队中大部分人将搬到旧金山，并且所有学者将继续保留在各自大学的背景，虽然他们有些将离开大学在 Uber 全职工作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;短期内，该初创公司一直专注「稀疏数据」（sparse data）的问题，思考怎样去构建人工智能系统，并且这个系统能使用和现如今技术相比更少的训练数据快速识别目标或某种情形。Geometric Intelligence 开发了一个叫做 Xprop 的软件，麻省理工技术评论杂志对它的的描述是「在视觉任务训练上，相比于主流机器学习框架如深度学习，它所需要的例子要少得多」。该创业公司的研究人员最近合作了一项关于深度生成器网络（deep generator networks）的研究，该项研究创建一些图像，并显示网络中的每个神经元如何影响整个系统的理解。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;收购 Geometric Intelligence 说明 Uber 对像谷歌和微软一样开发强大的语音和图像识别软件非常感兴趣，但是其产品背后的算法需要的数据较少。Marcus 在今年 5 月曾表示，「我们生活在大数据的时代，所以我们在解决问题的时候只能依靠更多的数据。」「但是在一些问题上还是没有足够的数据。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Uber 首席产品官 Jeff Holden 曾说，尽管我们在机器学习领域取得了初步的胜利，但是「我们仍然处在机器智能的早期阶段。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Jeff Holden 在他的博客中写道，「由于存在的复杂性和不确定性，真实世界的谈判才是更高层次的智能问题。」「这体现在很多方面，从确定最优路径到计算你的车或者是 Uber 外卖（UberEats）什么时候会到达，再到为拼车（uberPOOL）匹配乘客。这似乎是在教一个自动驾驶机器自动安全地探索世界，不管这个机器是路上的汽车，宇宙空间中的飞行器还是一种新型的机器人设备。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尽管 Uber 的建立根基不是那么雄厚，但它利用自己融资 数十亿美元的优势持续扩大业务，Geometric Intelligence 是 Uber 最新收购的一家人工智能公司。今年年初，Uber 收购了自动驾驶卡车公司 Otto，Otto 打造的一辆自驾卡车不久前才刚刚在科罗拉多州完成开创性的第一次自动运送服务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译文章，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 06 Dec 2016 11:55:24 +0800</pubDate>
    </item>
    <item>
      <title>专访 | 机器之心独家对话百度 NLP：先解决语义理解，再谈机器翻译取代人类</title>
      <link>http://www.iwgc.cn/link/3786500</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心原创&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：虞喵喵&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;9 月 28 日，Google 在 Research Blog 中介绍其神经网络机器翻译系统（GNMT）进展，译文质量的大幅提升引发业内极大关注。据称，在双语评估者的帮助下，通过对维基百科和新闻网站的例句测定，在多个样本的翻译中谷歌神经网络机器翻译系统将错误降低了 55-85％甚至更多。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9VcITAU0nPDqhTVEC2p7Q5LPGlOic7yJffBQ7SXK4BrMrHphRwdDE7Stv93RXMtRde4eZ0UqSHAlw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;翻译质量对比，来自 Google Research Blog&lt;/span&gt;&lt;/em&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;即便如此，网友发现其翻译效果虽有显著提升，但仍未避免将「我想下班」翻译为「I want to work」等低级错误（第二天已被修复）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;事实上百度的在线翻译系统，一年前就应用了基于神经网络的翻译方法（NMT）。去年百度曾在 ACL 会议上发表论文《Multi-Task Learning for Multiple Language Translation》，探讨用 NMT 技术解决多语言翻译及语料稀疏的问题。该论文得到业内研究人员的极大关注，并被 ACL2016 的 NMT Tutorial 列为研究方向。Google 和 Bengio 的研究团队都在此论文的基础上进一步扩展了研究。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为此，机器之心专访百度自然语言处理部技术负责人吴华、高级总监吴甜，就神经网络机器翻译系统的优缺点、如何获得高质量训练数据及百度翻译目前进展展开话题。同时也借此机会了解百度自然语言处理部及其开展的 NLP 技术研发工作。以下为采访内容整理，以飨读者。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;NMT、SMT 的优与缺&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;机器之心：能请您先介绍一下百度 NLP 部门吗？&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;百度 NLP 部门在公司内部是具有较长历史的部门，从最初搜索诞生时，就已经有 NLP 方面的工作。2009 年底左右，百度正式成立自然语言处理部。现在，这个团队人员构成非常多元，有自然语言处理、机器学习、信息检索、数据挖掘、机器翻译等多领域的专业性人才，擅长工程实践和擅长科学研究的人才都能够在团队中发挥重要作用。同时，架构开发、前端开发、客户端等软件开发和硬件开发工程师，产品设计及语言学专业人才也是团队的重要组成部分。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;整个部门的大方向有几个。第一是为百度的众多产品提供最基础的、NLP 模型算法，包括百度所有产品都在用的分词算法、专名识别、词性分析、语义理解、篇章理解等等一些基础的一些工具。目前 NLP 部门为整个公司提供一个大型平台 NLP 云，未来这个平台也会对公司外有所开放，目前（这个平台）每天都有千亿量级的调动量。还有贴近应用的一些大型的应用系统，比如说深度问答系统。NLP 开发的深度问答系统在百度的搜索产品上，会有一些直接展示。比如在搜索引擎中提出一个问题，用户可以不需要打开网页，直观的得到答案。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第二大方向是语义理解，实际上从最初期开始，NLP 就一直在致力于这样的一个方向。在原来的搜索时代，会分析用户的搜索 Query 含义是什么。到今天新的产品形态产生之后，已经不仅仅是分析搜索的意图。越来越多的用户会开始尝试有上下文的、更积极的交互方式，这就需要有上下文的理解。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第三个方向是对话系统。对话系统就是让机器能像人一样，和用户有对话性质的交互。NLP 过去几年一直在积累相应的技术，通过对话引导让用户和机器人能一句一句的交流下去。这部分实际上已经应用在百度的度秘产品中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第四个就是机器翻译。百度在机器翻译上已有 6 年的积累，每天有大量用户使用线上机器翻译产品，翻译 API 也有很多外部的企业开发者在使用。从 2014 年开始，百度尝试做基于神经网络的翻译系统，正式上线发布时间要早于 Google 一年。并且我们在发布的同时，还开发了离线版本，可以在手机上使用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;还有一些是更前瞻的探索。比如小度机器人。机器人能看、能写、能听，和人相比它还需要一个特别重要的能力就是思考。思考的前提，是先能听得懂语言。所以从 NLP 角度来说，更多的是希望机器人能懂语言、理解语言，然后能够跟人交流。那这款小度机器人，过去的几年也有频繁的亮相。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9VcITAU0nPDqhTVEC2p7Q5NwLenMFibm6Rn9BJsFNZFqV2icYLxDRiaT7GLF18946r87GkEyFv0cdxQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;领导百度 NLP 工作的百度副总裁王海峰博士，已于近日当选 ACL Fellow&lt;/span&gt;&lt;/em&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;机器之心：谷歌最近发布了神经网络翻译系统，我们怎么看这个系统？&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;Google 发布的系统综合了 NMT（Neural Machine Translation，神经机器翻译）领域近年来的研究成果。其所使用的 Seq2Seq 翻译模型、Attention 机制、以及深层 LSTM，在此前已有 Bengio 团队等多篇论文提及，从 Google 发布的论文的参考文献中可以看到。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此外，Google 针对大数据和深层模型的训练，进行了诸多工程方面的优化。例如，其使用了自身研发的针对深度学习的计算机器—TPU，加速了训练和解码。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;机器之心：那么百度是否有相关的研究？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;百度在这方面的研究起步很早，成果也非常多。而且，我们的神经网络翻译系统早在 2015 年 5 月就正式上线发布了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们从 2014 年开始便尝试做基于神经网络的翻译系统，2015 年发布在线翻译系统的时，BLEU（Bilingual Evaluation Understudy）指标已经比传统的 SMT（统计机器翻译）系统高六、七个点。我们同时还开发了离线版本，可以在手机上使用，&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当时学术界对于深度学习的翻译方法到底是否实用还有一番争论，我们很早就发现基于 Attention 机制的 Seq2Seq 深度学习模型是有用的，经过多次实验验证，在很多集合上超过了传统方法。同时，针对 NMT 本身存在的一些问题，进行了技术攻关，短短 3 个月的时间便完成了开发和上线。当大家还在讨论 Attention 机制时，我们已经结合了原有的统计方法上线。可以说，百度翻译是全球首个互联网神经网络翻译系统。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;机器之心：NMT（基于神经网络的翻译系统）效果就真的好于 SMT（基于统计的翻译系统）吗？或者说他会在哪个方面会好于 SMT 呢？&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;机器翻译目前是两大流派，一大流派是统计翻译模型（SMT），在整个业界已经持续了 20 多年的研究。另一个就是基于神经网络的翻译模型（NMT），过去的两年发展比较迅速。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从很多公开的评测上能看出，基于神经网络的翻译系统已经取得了比以前系统更好的成绩。这两大翻译系统我们一直在向前推进研究。总体上来说，基于神经网络的翻译系统，在长句翻译上有明显优势。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：可以从技术角度具体解释下吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;从整体看，在数据训练比较充分，比如有大数据集的时候，NMT 效果是好于 SMT 的。一句英文翻译成一句中文，这算一个句对。如果中文和英文之间的双语语料对有很多，那么 NMT 整体上好于 SMT。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;原因就在于，SMT 以前用的都是局部信息，处理单位是句子切开以后的短语，最后解码时将几个短语联系在一起，并没有充分利用全局信息。NMT 则利用全局信息，整个句子的信息解码后，才生成结果。这就是它的优势，也是其在流畅性上更胜一筹的原因。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;再进一步，翻译有一个很重要部分是「语序调整」。比如中文会把所有的定语都放在中心词前面，英文则会把修饰中心词的介词短语放在后面，机器常混淆这个顺序。NMT 在语序学习上的优势也带来了它翻译的流畅性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而 SMT 在短句或者数据较小的情况下，优势较为明显。以成语翻译为例，实际上不是意译而是直译，必须在语料库中有对应内容才能翻译出来。NMT 的翻译过程决定了其有时不能很好的处理这类问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如今互联网用户的需求是多种多样的。翻译涉及口语、简历、新闻等多领域，一种方法很难满足所有的需求。因此现在百度的翻译系统中包含了 SMT、NMT，甚至还有传统的 EBMT。所以，一个线上服务的翻译系统，其实是综合的系统。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不过从整个大趋势看，随着神经网络技术的进一步发展，它会越来越成为主流。目前在我们的中、英、日、韩等多个系统中，它就是主流。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;机器之心：那么能否通过不断增加网络层数来提升 NMT 效果？&lt;/span&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;在网络层数的增加过程中，成本、复杂度也随之提升。并不是线性地增加网络层数，收益比就更高，我们会去继续研究，但并不代表不断增加层数就一定是好方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;就翻译本身这个任务，现在有两大问题造成翻译效果不好。一是在于，训练语料本身是有噪音的，我们花费了大量时间和精力研究怎样找到更好的训练语料，怎样清洗出更好的语料。第二个是模型本身的不完美性，我们会不断优化。这两大方面的工作都是我们的重点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;获取数据与解决语料稀疏问题&lt;/span&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：刚才有提到 NMT 是非常依赖数据规模的，以及训练语料中的噪音问题，如何获得高质量的训练数据？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我们能获取的语料很多，比如网络上存在的大量翻译句对，但这些数据存在三个问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一个在于它们可能是机器翻译产生的语料。因为机器翻译技术已经比较普及，尤其是医疗方面有大量的机器翻译产生的语料。由于国外的医疗研究比国内先进，很多人会借助机器翻译技术来看文档。而这种语料若进入语料库，翻译系统学出来的还是机器翻译的句子。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第二种噪声是来自于恶搞。比如我们最早的时候看到「how old are you」，翻译成「怎么老是你」。因为语料里面「how old are you」，全是「怎么老是你」，出现频次非常高。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第三种是翻译得不地道的。互联网上翻译内容的人不一定是翻译水平很高的人，他们在翻译文章时会自己加入一些内容。这种是比较难识别的，因为很零散。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;针对每一类噪声，我们都会建立一个不同的质量检测模型，结合了翻译自身的技术以及互联网技术。机器翻译的语料是不能用机器翻译的概率特征过滤的，比如「how old are you」每个对齐，怎么（how）老（old）是（are）你（you），翻译得特别完美肯定无法过滤。所以我们一般从网站本身的权威性着手，对于权威性低的，相应高置信度就要打低。此外，我们还通过识别翻译特征判断其是否为机器翻译语料，比如：流畅性不好、语序不对等等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：不同语言的语料规模的差别较大，英语可能会多一些，小语种会少一些。如何将 NMT 的研究成果，应用于不同语言语料的构建中？&lt;/span&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;这其实是语料稀疏问题。语料稀疏是 NLP 一直在面对的问题，以前有一些解决方案，比如说： Transfer Learning（转移性学习）、机器翻译的 Pivot-Language（枢轴语言）技术、标签传播等技术。从一种语言翻译到另外一种语言，即使同一种语言在不同领域的语料也是不一样的，从这个领域迁移到另外一个领域，都需要解决语料的构建问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;NMT 是可以应用于此的，因为 NMT 本质是把一种语言翻译成另外一种语言。它的好处在于，不同语言之间可以互相学习他们的语义表示，比如中文的「看」，和英文的「See」（看见）或者「Read」（看书）。以相似度来计算，相似度高的就认为它们拥有同样的语义，可以用在不同语言的标注上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9VcITAU0nPDqhTVEC2p7Q5AA8qzKjzSasDw3s6mJdO2D8XibN7sibPyrJJwv8OWAkB7nicdREibA5LGg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;用来解决语料稀疏问题的多任务学习框架，来自《Multi-Task Learning for Multiple Language Translation》&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这样说可能有些抽象，举例来说我们去年在 NLP 领域国际会议 ACL 上发表了一篇文章，讲述用 NMT 解决语料稀疏的问题。中文和英文之间的句对很多，但中文和其他语言如日文、泰文、西班牙文的句对就很少。怎么办？我们同时学习。中文翻译成英文、日文、韩文、泰语的句对都一起学习，这样就能充分利用中文在源语言端的表示。此外，还学习关联知识，韩语-日语之间结构类似，从日语中学习到的结构性信息适用于韩语翻译。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;后来 Bengio 团队还在我们论文的基础上做了类似的工作，他们在我们的研究基础上扩展成多（语言）对多（语言），其实思想是类似的。后来他们还把这个工作开源了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;机器翻译能否取代人工翻译？&lt;/span&gt;&lt;/strong&gt;&lt;em&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：很多人可能就会问，人工翻译会不会被机器取代？您怎么看这个想法？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;从很长一段时间来看，完全取代还是不太可能的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在基于互联网大数据的机器翻译的优势在于，突破了原来编辑规则的局限。与人工翻译相比的好处是能迅速翻译很多语言。同时它解决了一些问题，比如几个场景：出门旅游的沟通、写 E-mail 借鉴机器翻译用词、小孩利用机器翻译扩充词汇。这种形式解决了用户的一些问题，也达到了实用的程度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是翻译最终的目标是「信、达、雅」，「信」至少是忠于原文，「达」就是译文通畅，符合目标语言用语习惯，「雅」是在这个基础上表达生动、形象。尤其在「雅」上，目前机器翻译远远不够。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;就像我们说英文，能说但不一定达到「达」的标准。「达」的意思是用语非常「native」（地道），我想机器翻译也没到。更不用说「雅」，即使人工翻译也只有少数人能达到雅的标准。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：达到「信、达、雅」的关键是什么？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;主要是语义理解问题。我们现在的翻译方法，没有做到「理解」。深度学习只是在模式识别这个手段上更加高明一点，但还没有理解语言。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;与专业的人工翻译相比，机器翻译有很多不足。首先，机器翻译是以句子为单位，即使是篇章翻译也是不看上下文，翻译完一句算一句。人工翻译是以篇章为单位，翻译前要先通读一遍，抓住意境和主旨。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其次，翻译需要常识背景。口语交流、会议翻译、随意聊天、正式作文等所需的文体是不同的，而同一个词在不同的文体上翻译也不同，这也是机器翻译的缺点。尤其是意译，比如翻译诗歌。如果没有知识背景，将中国的诗翻译成英文就会显得直白而没有韵味。跨语言的「信、达、雅」，连人都很难做到。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;事实上，机器翻译需要综合多学科，包括计算机学、语言学、认知学等等。机器翻译，看似简单，实则很难。因此我认为，机器翻译的道路还任重道远。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心原创文章，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Mon, 05 Dec 2016 14:27:34 +0800</pubDate>
    </item>
    <item>
      <title>学界 | NIPS 2016 论文SpotlightVideo精选，三分钟了解一项最新研究进展（附论文）</title>
      <link>http://www.iwgc.cn/link/3786501</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;机器之心编辑&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;编译参与：吴攀、李亚洲、杜夏德、微胖&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;近日，NIPS 官网开放了部分录用文章的 Spotlight Videos，南京大学 Ph.D. Candidate 魏秀参在查看了这些视频之后「特别将一些有趣、有料的 highlight 出来分享给大家」，原分享文章发表在他个人的知乎专栏。机器之心在获授权后在此基础上编译了相关论文的摘要。（注：排名不分先后，但魏秀参根据自己的兴趣在每篇文章后用「★」标记出了推荐指数，五星为最高。）点击「阅读原文」下载所有论文。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;魏秀参专栏：&lt;span&gt;https://zhuanlan.zhihu.com/p/24158507&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;全部spotlight video链接：&lt;span&gt;https://nips.cc/Conferences/2016/SpotlightVideos&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9VcITAU0nPDqhTVEC2p7Q5iaA6gQiaDqjGiaRz0kNBKDvMG8tcVh9qibDAL6Rz4d8p2qPsYDzmNJSkng/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1.Fast and Provably Good Seedings for k-Means&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：传统 k-Means 算法受初始化影响较大，虽然后来有 k-Means++算法来优化初始化结果，但该算法不能适用于海量数据。本文提出了一种新的更优且高效的针对 k-Means 初始化方法（oral paper）★★★&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;论文地址：&lt;span&gt;https://papers.nips.cc/paper/6478-fast-and-provably-good-seedings-for-k-means.pdf&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;iframe class="video_iframe" data-vidtype="1" style="   z-index:1; " height="375" width="500" frameborder="0" data-src="https://v.qq.com/iframe/preview.html?width=500&amp;amp;height=375&amp;amp;auto=0&amp;amp;vid=x03528ke448" allowfullscreen=""&gt;&lt;/iframe&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：在为 k-means 获取高质量聚类（clustering）中，发现初始聚类中心的任务——seeding——是极其重要的。然而，当前最佳的算法 k-means++seeding 在大规模数据集上扩展不是很好，因为其内在是序列形式的，并且需要 k 值在数据中的完全通过。近期的研究表明，马尔科夫链蒙特卡罗采样法（Markov chain Monte Carlo sampling）可被用来有效地近似 k-means++ 的 seeding 步骤。然而，这一结果需要在生成分布的数据上进行假设。我们提出了一种简单的、更快的 seeding 算法，即使在没有数据上的假设的情况下也能产生好的聚类。我们的分析表明该算法可在解决方案质量和计算成本之间良好地权衡，能将 k-means++ 的 seeding 速度提升数个级别。我们在多个真实世界数据集上的大量实验中验证了该理论成果。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2.Hierarchical Question-Image Co-Attention for Visual Question Answering ：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;针对 VQA 提出不仅要在 image domain 需要 attention，同时为了增加鲁棒性还需在 question domain 同样加入 attention；★★&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;论文地址：&lt;span&gt;https://arxiv.org/pdf/1606.00061v3.pdf&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;视频地址：&lt;span&gt;https://www.youtube.com/watch?v=m6t9IFdk0ms&amp;amp;feature=youtu.be&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：近期有大量论文提出了用于 Visual Question Answering（VQA）的注意模型，VQA 的目标是为了生成突出了关于回答问题的图像区域的空间图（spatial maps）。在此论文中，我们认为除了建模「看哪里（where to look）」或视觉注意（visual attention）之外，建模「听哪些词（what words to listen to）」或问题注意（question attention）同样重要。我们提出了一个全新的用于 VQA 的联合注意模型（co-attention model），其可以联合推理图像和问题注意。此外，我们的模型可以通过一个全新的 1 维卷积神经网络以层级的形式推论问题（并最终能通过联合注意机制推论相应的图像）。我们的模型将 VQA 数据集上的前沿成果从 60.3% 提升到了 60.5%，在 COCO-QA 数据集上的结果从 61.6% 改进到了 63.3%。通过使用 ResNet，在 VQA 数据集上的结果进一步改进到了 62.1%，COCO-QA 的结果改进到 65.4%。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3.Residual Networks Behave Like Ensembles of Relatively Shallow Networks：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;实验角度探究了 ResNet，提出 ResNet 更像很多小网络的集成。比较有意思的 paper；★★★★★&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;论文地址：&lt;span&gt;https://arxiv.org/pdf/1605.06431v2.pdf&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;视频地址：&lt;span&gt;https://www.youtube.com/watch?v=jFJF5hXuo0s&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：在此文章中，我们提出了一种对残差网络的全新解释：残差网络可被视为不同长度的多个 path 的集合。此外，通过在训练中只使用短 path，残差网络能够使非常深度的网络成为可能。为了支撑这一观点，我们将残差网络重新编写为 path 的显性集合。不像传统的模型，通过残差网络的 path 的长度不同。此外，一个 lesion study 揭示出这些 path 显示出了 ensemble-like 行为，也就是不很强的依靠彼此。最后，也是最惊人的，大部分 path 都要比预期的短，在训练过程中也只需要短 path，这是因为长 path 对梯度没有任何贡献。例如，在 110 层的残差网络中的大部分梯度来自于只有 10-34 层深度的 path。我们的结果显示该方法的一个主要特性是使得训练极其深的深度网络成为可能：残差网络通过引入短 path 而避免梯度消失的问题，这些短 path 可以使梯度穿过非常深度的网络的延展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;4.Boosting with Abstention： &lt;/span&gt;&lt;/strong&gt;&lt;span&gt;利用 Boosting 框架处理了当有「弃权」情况产生时的分类情况；★★&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;论文地址：&lt;span&gt;https://papers.nips.cc/paper/6335-boosting-with-abstention&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;视频地址：&lt;span&gt;https://www.youtube.com/watch?v=NTKIXcpoJGM&amp;amp;feature=youtu.be&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：我们提出了一个用于二元分类的关键场景，带有 abstention 新的 boosting 算法，其中该算法可以以一个固定的成本为代价，放弃预测一个点的标签。在每一轮中，我们的算法都要选择一对函数：一个基本的预测器和一个弃权（abstention）函数。我们为与该问题相关的自然损失函数定义了凸上界（convex upper bounds），经过证明，它可以用相关的贝叶斯解决方案来校准。在对应函数类别的 Rademacher 复杂度上，我们的算法受益于通用的基于边界的学习保证，我们用其推导基本预测器和 abstention 函数的对。我们为我们的算法提供了收敛保证，并为 abstention stump 提供了线性时间弱学习算法。根据我们的报告，几次试验的结果显示我们的算法在实践中带来的提升显著超过了两个基于置信度的算法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;5.Stochastic Multiple Choice Learning for Training Diverse Deep Ensembles&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：多个深度模型集成算法；★★★★&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;论文地址：&lt;span&gt;https://arxiv.org/abs/1606.07839&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;视频地址：&lt;span&gt;https://www.youtube.com/watch?v=KjUfMtZjyfg&amp;amp;feature=youtu.be&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：很多实际的感知系统存在于更大的处理过程中，包括与用户的互动或者能够评估预测解决方案质量的附加组件。在这些情景中，为这些 Oracle 机制提供多种极有可能的假设而不是单一的预测是有益的。在本研究中，我们提出将产生多个输出的任务看作是深度网络集成上的一个学习问题——引进一种全新的随机梯度下降法来最小化与一个 Oracle 相关的损失。我们的方法实现起来很简单，无关于架构和损失函数，也不需要参数。在广泛的任务和深度架构上，相较于现有的方法，我们的方法实现了较低的 Oracle 误差。我们还以定性的方式显示了产生的多样解决方案通常都会提供任务模糊性的可解释的表征。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;6.Active Learning from Imperfect Labelers：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;提出一种 adaptive 算法以处理主动学习中 labeler 不不确定的情况；★★&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;论文地址：&lt;span&gt;https://papers.nips.cc/paper/6161-active-learning-from-imperfect-labelers&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;视频地址：&lt;span&gt;https://www.youtube.com/watch?v=zslooZuNNIk&amp;amp;feature=youtu.be&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们研究了主动学习（active learning），其中标注器（labeler）不仅能返回错误的标签还能放弃标记。我们考虑了该标注器的不同噪声和弃权（abstention）条件。我们提出了一种使用了弃权回应的算法，并在对于该标注器的噪声和弃权率的相对自然的假设下分析了其统计一致性（statistical consistency）和查询复杂性（query complexity）。该算法能达到某种程度的自适应，它能自动要求用带有更多信息的或更少噪声的标注器进行少量的查询。我们给我们的算法配上较低的下界，以表明在某些技术条件下，它能达到几乎最优的查询复杂性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;7.Deep learning for Human Strategic Behaviour：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;顾名思义，同时也是一篇 oral。另外，视频做的很有趣:) ★★&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;论文地址：https://papers.nips.cc/paper/6161-active-learning-from-imperfect-labelers&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;iframe class="video_iframe" data-vidtype="1" style="   z-index:1; " height="375" width="500" frameborder="0" data-src="https://v.qq.com/iframe/preview.html?width=500&amp;amp;height=375&amp;amp;auto=0&amp;amp;vid=f0352wa2i87" allowfullscreen=""&gt;&lt;/iframe&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：在战略环境中预测人类的行为是许多领域的重要难题。大部分已有的研究要么假设人类完全的理性，要么基于认知心理学和实验经济学试图直接建模人类的认知流程。在此研究中，我们提出了另一种方法：在不依赖专业知识的情况下自动完成认知建模的深度学习方法。通过使用矩阵单元而非标量单元，我们引入一种全新的架构使得单个网络能够在不同的输入和输出维度上进行泛化。而且结果表明其表现超越了之前的顶尖方法，也就是依赖专业结构特征的方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;8.Improved dropout for shallow deep learning&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：提出一种改进版本 dropout ★★★★&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;论文地址：&lt;span&gt;http://papers.nips.cc/paper/6561-improved-dropout-for-shallow-and-deep-learning.pdf&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;视频地址：&lt;span&gt;https://www.youtube.com/watch?v=oZOOfaT94iU&amp;amp;feature=youtu.be&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：在训练深度神经网络上，dropout 已经通过独立地使神经元的随机输出归零而取得了巨大的成功。它也在浅度学习（shallow learning）上引起了人们的兴趣，比如 logistic 回归。但是 dropout 的独立采样在用于收敛时可能并不是最优的。在这篇论文中，我们提出了用于 dropout 的多项采样（multinomial sampling），即基于不同特征/神经元的不同概率的多项分布来采样特征或神经元。为了展现出最优的 dropout 概率，我们使用多项 dropout 分析了浅度学习并建立了随机优化的风险边界（stochastic optimization）。通过最小化风险边界中一个独立于采样的因素，我们获得了独立于分布的 dropout，其带有依赖于该数据分布的二阶统计的采样概率。为了解决这种深度学习中神经元的演化分布的问题，我们提出了一种有效的自适应 dropout（名为 evolutional dropout），其可以根据 mini-batch 样本在传输过程中计算该采样分布。在多个基准数据集上的实验表明我们提出的这种 dropout 不仅能实现远远更快的收敛，而且还比标准 dropout 有更小的测试误差。比如说，在 CIFAR-100 数据上，相比于标准的 dropout，该 evolutional dropout 在预测表现上实现了相对超过 10% 的提升，而在收敛速度上的提升则超过了 50%。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;9.Single Pass PCA of Matrix Products：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;解决了大矩阵 PCA 分解问题 ★★★&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;论文地址：&lt;span&gt;https://papers.nips.cc/paper/6075-single-pass-pca-of-matrix-products.pdf&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;视频地址&lt;span&gt;：&lt;/span&gt;&lt;span&gt;https://www.youtube.com/watch?v=Ir4-eNz6tOw&amp;amp;feature=youtu.be&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;开源地址：&lt;span&gt;https://github.com/wushanshan/MatrixProductPCA&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：在本论文中，我们提出了一种用于仅使用两个矩阵 A 和 B 的单次通过来计算乘积&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;[Image: https://dx903567.quip.com/-/blob/YPDAAA37MfL/XBWTd3tni6shFkdMNmR4xw] 的低秩近似（low rank approximation）的新算法。实现这种方法的直接方法是（a）首先单独描绘（sketch）A 和 B，（b）然后在该 sketch 上使用 PCA 来寻找顶部成分（top components）。和其它算法相比，我们的算法保留了关于 A 和 B 的附加概要信息（如，行和列的规范等），并使用了这种额外的信息来获取来自这些 sketch 的更好的近似。我们的主要分析结果为已有的双通道方法建立了一个可比较的谱范数保证（spectral norm guarantee）；此外，我们还提供了一个 Apache Spark 的实现结果，其在真实世界的和合成的评估数据集上都实现了更好的计算和统计表现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;10.Convolutional Neural Fabrics&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：抽象化 CNN，学习网络结构 ★★★★&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;论文地址：&lt;span&gt;http://papers.nips.cc/paper/6304-convolutional-neural-fabrics.pdf&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;视频地址：&lt;span&gt;https://www.youtube.com/watch?v=bqPJFQEykbQ&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尽管 CNN 已经取得了很大的成功，但为特定的任务选择出最优的架构仍然还是一个悬而未决的问题。我们的目标并不是选择出单个的最优架构，我们提出了一种嵌入了非常大量的架构的「fabric」。该 fabric 由 3D 网格构成，这些网络将不同层、规模和信道的响应图（response maps）与一个稀疏的均匀的局部连接模式（sparse homogeneous local connectivity pattern）连接到了一起。一个 fabric 仅有的超参数就是信道和层的数量。当单个架构可以被作为路径（path）而恢复时，该 fabric 可以额外地将所有嵌入的架构组合到一起，在它们的重叠路径上共享它们的权重。参数可以使用基于反向传播的标准方法进行学习，但会有 fabric 大小上的线性扩展性的成本。我们给出了在 MNIST 和 CIFAR10 的图像分类任务上、以及在 Part Labels 数据集的语义分割任务上的可与当前最佳表现媲美的基准结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;11.Learning Deep Embeddings with Histogram Loss：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;提出无参的 Histogram loss 进一步优化深度模型特征嵌入；★★★&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;论文地址：&lt;span&gt;https://arxiv.org/pdf/1611.00822v1.pdf&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;视频地址：&lt;/span&gt;&lt;span&gt;https://www.youtube.com/watch?v=FMtfi7mpirY&amp;amp;feature=youtu.be&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：我们提出了一种学习深度嵌入的损失函数. 这个新的损失函数没有引入需要调试的参数以及在一系列数据组和问题上非常好的嵌入结果。该函数的计算方法是评估两个相似性的分布（针对正匹配和负匹配的样本对），然后基于一个评估的相似性分布，计算正匹配的概率，获取一个比负匹配更加低的相似性得分。我们表明，这一操作能够使用带有软分配操作的 1D 柱状图，以一种简单、分段-可微分的方式进行。这样就得到了适合使用随机优化学习深度嵌入的损失函数，在实验中，较之近期提出的替代方案，新函数表现地很有前途。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;12.Tagger: Deep Unsupervised Perceptual Grouping 很有料的文章，另外视频很赞，建议授予「最佳视频奖」:) ★★★★★&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;论文地址：&lt;span&gt;https://arxiv.org/pdf/1606.06724v2.pdf&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;iframe class="video_iframe" data-vidtype="1" style="   z-index:1; " height="375" width="500" frameborder="0" data-src="https://v.qq.com/iframe/preview.html?width=500&amp;amp;height=375&amp;amp;auto=0&amp;amp;vid=p03527eavzu" allowfullscreen=""&gt;&lt;/iframe&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们提出了一个高效的感知推理框架，可以对输入和特征的分割进行明确推理。这个框架不是训练进行任何具体分割，它以一种无监督方式或伴随任何监督任务学习处理 grouping process。我们能让一个神经网络通过一种可微分机制、以一种交互方式对不同目标表征进行聚合。通过让系统分摊聚合及其表征的联合迭代推理，我们实现了非常快速的收敛。与许多其他最近提出的用于解决多个对象场景的方法相比，我们的系统没有假设输入是图像，因此可以直接处理其他模态。我们评估了这个方法在非常杂乱的图像上的多数位分类（这需要纹理聚类）的结果。通过利用聚类机制，我们的方法显著改善了卷积网络上的分类结果，尽管是完全连接的。而且，我们观察到系统大幅改善了作为基线的梯形网络在我们数据组上的半监督结果。这些结果证明分组是一个有助于改善取样效率的强大工具。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为魏秀参授权机器之心转载并编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Mon, 05 Dec 2016 14:27:34 +0800</pubDate>
    </item>
    <item>
      <title>盘点 | 2016年人工智能十大失败：从种族主义到致命车祸</title>
      <link>http://www.iwgc.cn/link/3786502</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自TechRepublic&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Hope Reese&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李亚洲、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;自动驾驶汽车、语音识别、机器翻译……2016 年是见证机器学习研究和应用突飞猛进的一年，但与此同时，人工智能也在这一年里做出了一些可笑乃至可恨的事情。TechRepublic 今日发表了一篇文章《Top 10 AI failures of 2016》，总结了 2016 人工智能十大失败事件，机器之心对该盘点进行了编译整理，并稍微进行了一点扩展。希望这篇文章能给你带来对人工智能的更为立体的了解。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9VcITAU0nPDqhTVEC2p7Q5BK0gUO2r2hLBq8x37yJQhe4m42zGK9G50XE9XaiaOFzYEx3NCGTs9uA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图：人工智能选美比赛的获胜者，该结果表现出了对非白人面孔的歧视（来源：Beauty.AI）&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;过去一年，可以说我们亲眼见证了人工智能的爆发：无人驾驶汽车上路、语音识别屡屡突破、机器翻译更上层楼、人工智能甚至还掌握了古老复杂的围棋……看起来似乎人工智能很快就将无所不能了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是，虽然人工智能取得了如此之多的成功，但同时它也闹出了很多笑话，其中一些事件更是冒犯了一些群体和个人。了解这些人工智能的「失败」案例，能够帮助我们防微杜渐，预防未来可能出现的更严重的人工智能失误。路易斯维尔大学 Cybersecurity Lab 主任 Roman Yampolskiy 近日的一篇论文《Artificial Intelligence Safety and Cybersecurity: a Timeline of AI Failures》概述了人工智能「与这样的系统被设计所表现的智能直接相关的」失败的历史。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;据 Yampolskiy 表示，这些类型的失败都可归因于这些人工智能系统在学习阶段的错误或在表现阶段的错误。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这里 TechRepublic 所列举的人工智能十大失败事件是根据 Yampolskiy 的论文和多位人工智能专家的意见整理而成的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1. 为预测未来犯罪所打造的人工智能是种族主义的&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Northpointe 公司开发了一个设计用来预测被指控的罪犯再次犯罪的几率的人工智能系统。这个被 Gawker 称为「少数派报告类型」（借鉴自 Philip K. Dick 的一篇小说和衍生电影）的算法被指控带有种族偏见，因为相比于其它种族，黑人罪犯被标注为未来可能再次犯罪的概率要大得多。而另一家媒体 ProPublica 还发现 Northpointe 的算法「即使不管种族上的问题，也通常不能有效地预测。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2. 一个视频游戏中的非玩家角色创造出创造者规划之外的武器&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今年 6 月，一个加入了人工智能的视频游戏 Elite: Dangerous 表现出了一些其创造者计划之外的能力：该人工智能有能力创造出超出游戏设定之外的超级武器。据一家游戏网站表示：「玩家会遭遇那些装备有能将他们的战舰粉碎的可笑武器的战舰。」这些武器后来被该游戏的开发者撤下了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3. 机器人使一个儿童受伤&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今年 7 月份，一个由 Knightscope 平台所创造的一个所谓的「打击犯罪机器人（crime fighting robot）」在硅谷的一家商场里使一个 16 月大的男童受伤。洛杉矶时报援引该公司的话称这场意外是一个「奇怪的事故（freakish accident）」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;4. 特斯拉 Autopilot 模式下的死亡&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今年五月份，在佛罗里达的一条高速公路上，Joshua Brown 驾驶着一辆开启了 Autopilot 模式的特斯拉与一辆拖车发生了碰撞并最终陨命。这是涉及该公司的第一例死亡事件。事故发生后，特斯拉已经发布了对其 Autopilot 软件的重大更新，Elon Musk 声称该更新可以防止这样的碰撞发生。此外今年也还出现了其它一些与 Autopilot 相关的死亡事故，包括发生在中国的一起，但这些其它事故并不与人工智能的失败直接相关。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;5. 微软的聊天机器人 Tay 发布种族主义、性别歧视和攻击同性恋言论&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了和年轻的消费者搞好关系，今年春季的时候微软在 Twitter 上发布了一个人工智能驱动的聊天机器人 Tay。Tay 原本是为模仿一个十几岁的美国青少年女孩而设计的，但在和用户开放对话后不到一天的时间里，它就变成了一个「热爱希特勒、讥讽女权主义」的喷子。微软很快就下线了 Tay，并宣布将会对 Tay 的算法进行调整。另外提一点，近日微软新的英语聊天机器人 Zo 又在 Kik 平台上线了（https://earlyaccess.zo.ai/），希望这一次它会表现更好吧。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;6. 人工智能评美有种族歧视&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;据大赛网站称，在「首届国际人工智能选美大赛」上，基于「能准确评估人类审美与健康标准的算法」的机器人专家组对面部进行评判。但由于未对人工智能提供多样的训练集，比赛的获胜者都是白人。就像 Yampolskiy 说的，「美人在模式识别器中」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;7.Pokémon Go 使得游戏玩家集中到白人社区&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;7 月份，Pokémon Go 发布之后，多个用户注意到极少的 Pokémon 位于黑人社区。据 Mint 的首席数据官 Anu Tewary 说，这是因为算法的发明者没有提供多样的训练集，在黑人社区上没有花费时间。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;8. 谷歌人工智能 AlphaGo，败给了李世乭一局&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 3 月份的围棋大赛中，谷歌的人工智能系统 AlphaGo 4 比 1 击败了韩国李世乭。失败的一局表明人工智能算法如今还不完美。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;新南威尔斯大学的人工智能教授 Toby Walsh 说「看起来，李世乭发现了蒙特卡洛树搜索中的一个弱点。」虽然被视为人工智能的一次失败，但 Yampolskiy 说此次失败「可认为在正常操作规范之内。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;9. 中国的面部识别学习预测罪犯，有偏见&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;上海交通大学的两个研究人员发表了一篇名为「Automated Inference on Criminality using Face Images」的论文。据 Mirror 报道，他们「将 1856 张面部图片（一半是罪犯）馈送进电脑并进行分析」。在此研究中，研究人员总结说「有一些可识别的结构特征来预测犯罪，比如唇曲率（lip curvature）、眼内角距（eye inner corner distance），以及所谓的口鼻角度（nose-mouth angle）。」领域内的许多人质疑这些结果和道德问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;10. 保险公司使用 Facebook 数据观察出现问题的概率，有偏见&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今年，英格兰最大的汽车保险商 Admiral Insurance 打算使用 Facebook 用户的推文数据观察社交网站与好司机之间的联系。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然这不是一次直接的失败，确是对人工智能的滥用。Walsh 说「Facebook 在数据限制上做的很好」。这一被称为「first car quote」的项目未能落地，因为 Facebook 限制该公司获取数据，援引条款称国营企业不能「使用来自 Facebook 的数据做关于资质的决策，包括支持或反对一项应用，以及贷款利率应该提多少等。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在以上案例的证明下，人工智能系统极其倾向于有偏见。在多样的数据集上训练机器学习算法，从而避免偏见变得极其重要。随着人工智能能力的增加，确保研究的适当检测、数据多样性和道德标准也更为重要。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;原文链接：http://www.techrepublic.com/article/top-10-ai-failures-of-2016/&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译文章，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Mon, 05 Dec 2016 14:27:34 +0800</pubDate>
    </item>
    <item>
      <title>学界 | 卷积神经网络新玩法：分分钟让你变脸尼古拉斯·凯奇</title>
      <link>http://www.iwgc.cn/link/3786503</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自arXiv.org&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀、杜夏德&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote style="white-space: normal;"&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;近日，来自比利时根特大学和 Twitter 的几位研究者在 arXiv 上发表了一篇很有趣的利用人工智能进行「换脸」的论文《Fast Face-swap Using Convolutional Neural Networks》，而著名演员尼古拉斯·凯奇和著名歌手泰勒·斯威夫特很不幸地成为了他们的实验对象。机器之心对该论文进行了部分编译，论文原文可在 https://arxiv.org/pdf/1611.09577v1.pdf 查看。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicEbtCibsxKbicXXBy1TOXkviaEWqwSoVeTrUAntJdYeO0GQ5yIAGzBgdcULOm3kogg3fzLWUQnb7bJg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;摘要&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们思考了在图像中进行面部交换（face swapping）的问题——即在保持原有姿势、面部表情和光照的同时，将一个输入的身份转换成一个目标身份。为了执行这样的映射，我们使用了卷积神经网络，并训练使其能够从一个人的照片的非结构化集合中获取目标身份者的外观。这种方法是通过将该面部交换问题描述成一种风格迁移问题而实现，而风格迁移的目标是将一张图像渲染成另一张图像的风格。基于这一领域的最新进展，我们设计一种能让该网络生成高照片真实度结果的新损失函数（loss function）。通过神经网络和简单的预处理与后处理步骤的结合，我们的目标是无需来自用户的输入就能实现实时的面部交换。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1. 相关工作（略）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2. 方法&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;假设有了一张某人 A 的图像，我们要将他/她的身份变成某人 B，同时保持头部姿势和表情以及光照情况不变。使用风格迁移，我们输入图像 A 的姿势和表情作为内容，输入图像 B 的脸作为风格。光线以另一种单独的方式处理，下面会介绍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 Ulyanov et al. [33] 和 Johnson et al. [11] 的基础上，我们使用一个经过权重 W 参数化的卷积神经网络来将这个内容图像x（即输入图像A）转换成输出图像&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicEbtCibsxKbicXXBy1TOXkviajNaibibtm5VHLcEKWf6f5LoNXx2fhudVKAeIc26w0iaV0ELSPQic24jk6g/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;与之前的结果不同，我们假设给定的是一组而非一张风格图像，我们用 Y = {y1, . . . , yN } 来表示。这些图像描述了我们想要匹配的身份而且仅会在训练该网络的过程中使用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们的系统有两个另外的组分用来做脸对齐（face alignment）和背景/头发/皮肤分割。我们假设所有的图像（内容和风格）都与一张前向视角的参考脸。这可以通过一个仿射变换（affine transformation）实现，这需要将给定图像中的 68 个面部关键点对齐到参考的关键点。面部关键点是使用 dilb [13] 提取出来的。我们使用了分割来恢复来自输入图像 x 的背景和头发，而 x 目前还不会被我们的变换网络（transformation network）保存。我们使用了 OpenCV [22] 中的一种无缝克隆技术（seamless cloning technique）[25] 来拼接背景和所得到的面部交换了的图像。尽管目前确实存在一些相对准确的分割方法，包括一些基于神经网络的方法 [1, 21, 24]，但为简单起见，我们假设 segmentation mask 已经给出，并将重点放到了剩下的问题上。关于该系统的概述可见于图 2.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面我们会描述该变换网络的架构和训练中所使用的损失函数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicEbtCibsxKbicXXBy1TOXkvia34STiczuWFu1rhl6g2jNTyNb9ardVv1MhzzJiaswHOb1SmNRicxZGNprA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 2：我们方法的示意图。在将输入图像的脸和参考图像对齐了之后，我们的方法使用了一个卷积神经网络来修改它。之后，生成的脸被重新对齐，并且使用了一个 segmentation mask 与输入图像结合到了一起。最上面一行表示了用于定义对齐和重新对齐步骤的仿射变换的面部关键点，以及用于拼接的皮肤 segmentation mask。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2.1 变换网络&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们的变换网络的架构基于 Ulyanov et al. [33] 的架构，如图 3 所示。这是一个带有分支的多尺度架构，这些分支在输入图像 x 的不同下采样版本上执行运算。每一个这样的分支都有零填充的卷积（zero-padded convolution）模块，其后还跟着线性修正（linear rectification）。这些分支再通过相差一倍的最近邻上采样（nearest-neighbor upsampling）和沿信道轴的级联（concatenation along the channel axis）组合起来。该网络最后的分支是以一个 1×1 卷积和 3 色信道结束的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicEbtCibsxKbicXXBy1TOXkviata4AlREdmnqYVjoClAuGAsZWlFjAV9pAEvecoMHnklkWAbcP1I9IhA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 3：基于 Ulyanov et al. [33]，我们的变换网络有一个多尺度的架构，支持不同分辨率的输入。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图 3 中的网络是为 128×128 输入设计的，有 100 万个参数。对于更大的输入，比如 256×256 或 512×512，其可以直接推断出带有额外分支的架构。该网络的输出仅从最高分辨率的分支中获得。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2.2 损失函数&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicEbtCibsxKbicXXBy1TOXkviaFic1sbnXbeEF9PugXjteEzMiaI8tpsXdRohodWsbM7Q16ibKz3zL5Dkkw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 4：光照网络是一个 siamese network，其被训练用于最大化带有不同光照情况的图像（输入 A 和 C）之间的距离和最小化带有同等光照的图像（输入 A 和 B）之间的距离。这个距离被定义成了全连接层的特征空间中的一个 L2 范数（norm）。所有的输入图像都与同一张基准脸进行了对齐，这和对变换网络的输入的处理一样。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3. 实验&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3.1. CageNet 和 SwiftNet&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们训练了一个变换网络来执行与尼古拉斯·凯奇（Nicolas Cage）的面部交换，为此我们在互联网上收集了他大约 60 张不同姿势和不同表情的照片。为了进一步增加风格图像的数量，每一张图像还都进行了水平翻转。至于内容图像源，我们使用了包含超过 20 万张名人图像的 CelebA 数据集 [20]。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了测试我们的结果泛化到其它身份的情况，我们还使用了大约 60 张泰勒·斯威夫特（Taylor Swift）的照片训练了一个同样的变换网络。我们发现在同样的超参数（hyperparameter）下，这两个网络实现了质量相近的结果（图 5b）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicEbtCibsxKbicXXBy1TOXkvia8GmvSGzSibHMHCD0Ltxs2cstOWc5OUSx3vhEzicIUXza2F3BicEy0n1lg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 5：（a）原始图像；（b）上一行：使用尼古拉斯·凯奇的变脸结果，下一行：使用泰勒·斯威夫特的变脸结果；（c）上一行：CageNet 的原始输出，下一行：SwiftNet 的输出。注意我们的方法怎样改变了鼻子、眼睛、眉毛、嘴唇和面部皱纹的外观。其保持了凝视方向、姿势和唇部表情的完好，而且是以一种对目标身份来说很自然的方式。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图 6 给出了向目标函数加入光照损失（lighting loss）所产生的影响。当没有包含这样的损失的时候，CageNet 会生成光照均匀、缺乏阴影的图像。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicEbtCibsxKbicXXBy1TOXkviaEZB9Griaq7ljOyO8ZjytLsN5WdYck5xUBj1JI74iaicU2gqQrq9EwFhtQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 6：左图：原始图像；中图：带有光照损失训练的 CageNet 的结果；右图：不带光照损失训练的 CageNet 的结果&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;和之前的成果比较，我们发现我们的风格迁移结果严重依赖于风格权重和内容权重之间的平衡 [8]。我们还使用变化的风格权重训练了几个网络。图 7 的结果表明当风格权重较大时，该网络会忽略面部表情，而似乎会直接从风格集合中复制一张最适合的图像。有趣的是，该网络仍然能够检测和保存输入图像的姿势。这意味着用大的风格权重训练的网络能够再现 Bitouk et al. [2] 中类似的卷积面部交换。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicEbtCibsxKbicXXBy1TOXkviagp0u4n4oEIkzODtNAX6CQs6wIJWoibQZ5OGY28z8yDEnibMicqGVmRNicg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 7：左图：原始图像；中图和右图：在风格权重分别为 α = 80 和 α = 120 的 256×256 图像上训练的 CageNet&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;后面，我们探索了我们的方法的一些失败案例。我们注意到我们的网络在前向视角上比在侧向视角上效果更好。在图 8 中，我们可以看到随着我们从侧向视角转向正向视角，其脸会变得越来越像尼古拉斯·凯奇。这可能是由数据的不平衡导致的。我们的训练集（CelebA）和风格图像中的正向图像比侧向图像多很多，因为正向图像在互联网上也更为普遍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicEbtCibsxKbicXXBy1TOXkviaqyP6k2Zbjla1pD3ZcgpML3HAz3HRwvg0EVWRgyFvBBWKrEILIIu9uA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图 8：上一列：原始图像；下一列：与尼古拉斯·凯奇的对应变脸结果。可以看到随着脸从侧向转向正向，结果图像的脸也越来越凯奇了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图 9 给出了其它一些我们的方法无法很好处理的样本。特别是当有眼镜这些东西的时候，眼镜会被移除，然后留下一些奇怪的东西。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicEbtCibsxKbicXXBy1TOXkviauk7ziaGGG2xNxhANBRtS5CqVnlDgceDjHiaibhyCSkbic0twwAG5tGl1hA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 9：有问题的案例。左图和中图：面部遮挡，在这两个例子中，眼镜被移除，但还是留下了一些东西。中图：闭着的眼睛没有被正确地交换，因为在风格集中没有这样的表情图像。右图：因为姿势、表情和发型太困难，结果非常差。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译文章，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Mon, 05 Dec 2016 14:27:34 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 深度学习技术将让机器人市场规模至少扩大十倍</title>
      <link>http://www.iwgc.cn/link/3786504</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自ARK INVEST&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：James Wang&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：微胖、杜夏德&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;在工业机器人市场化的过程中，最困难的两点是降低成本和提升易用性。后者比前者更难。然而随着深度学习算法在机器人中应用的越来越多，这个两个问题都得到了不同程度的解决。未来，&lt;span&gt;深度学习驱动下的更小更聪明的机器人会接管机器人市场。&lt;/span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;深度学习是目前在视觉、语音、医疗诊断和其他领域中应用表现最好的机器学习算法，它也可能对机器人产业产生深远的影响。即便在制造业中，机器人已经被广泛使用，但是它们依然有造价昂贵、编程困难的问题。对于大部分业务来说，机器人还排不上用场。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 2015 年，全球范围内的工业机器人销售量仅为 250000 左右，这个数量是大型计算机销售峰值的十倍。相比之下，去年服务器和 PC 的销售总量分别大约为 1000 万台和 3 亿台。很明显，机器人产业还处于起步，它需要在成本和易用性上有很大的提升才能真正的走向主流市场。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器人的成本曲线正在下降。ARK 估计工业机器人的成本在未来十年内会下降一半，跌至大约 10 万美元一台。同时，一台与人协作的新品种机器人的价格大约 3 万美元。今天像软银的 Pepper 这种销售助理机器人的成本大约为 1 万美元，还包括服务费。更安全更敏捷，这个新品机器人不需要安全笼、重型设备或者专业编程。根据 ABB Robotics 的信息，一台工业机器人的安装程序部分只占总成本（TCO）的三分之一。由于机器人制造商从电子工业（如摄像头、处理器和感应器）中添加了很多部件，我们认为工业机器人的成本应该会接近消费电子品的价格。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在工业机器人中，提升易用性这一点比降低成本更难。工业机器人需要使用工业控制系统进行精确的编程，要将任务打散放进一系列动作和六个维度中。这些机器人没有从经验中学习的能力，它们只能依靠新程序来学习新任务，这种缺陷就限制了工业机器人在可预测的和明确的任务中的应用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然而深度学习已经带来了变革，它将机器人变成学习机器。不需要精确编程，机器人可以随着时间的推移从数据和经验中学习，并能执行多种任务。ARK 相信在某种程度上，一个能抓取货架上任何一个物品并将它放到箱子里的仓库机器人会是很多业务的福音。但是，没有深度学习最近的突破，识别和抓取各种形状大小的物体几乎是不可能的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在亚马逊的 AMZN Picking Challenge 的机器人抓取挑战赛中，带有摄像头的基于视觉的机器人尝试从一个货架上随机抓取一个物品放进箱子里。在 2015 年到 2016 年之间，赢得比赛的机器人性能提升了三倍，之前一个小时能抓取 30 个物体，现在是 100 个。2016 年的比赛中，冠亚军都将深度学习作为其视觉和抓取任务背后的核心算法。按照最近的性能提升速度来看，在抓取任务上，机器人两年内就会超过人类。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9VcITAU0nPDqhTVEC2p7Q5hUibpeOXgfzpLnUbQZEI5ia9NXddAwACt3B3kskxFibwebuZoicSnm4xjw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;图片来源：亚马逊，Preferred Networks&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;ARK 相信，给从事更加简单、更可预测任务的机器人编程，深度学习是一个高效得多的办法。据 Prefferred Networks（一家私人机器人公司）透露，借助深度学习，机器人可以在八小时内掌握一项任务，而在过去，人类程序员要花费数天时间才能教会机器人完成相同的任务。当 8 台机器人一同学习任务时，训练时间可以缩短至 1 小时。因此，在训练单独一台机器人时，深度学习的效率比人类程序员要高出五倍，而且平行训练能够将表现提升不止一个量级。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;较之传统机器人，采用将摄像头和机器人视觉结合起来的机器人会更加便宜。因为传统机器人没有视觉，因此，工作量必须精确布置出来，还常常需要支持硬件，比如固定装置。但是，拥有视觉的机器人会使用软件并根据工作量进行调整，而不是反过来。他们还能根据新任务进行快速编程，按照传统办法，这需要花费大量成本进行重新安排。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器人领域的重量级公司已经做出选择。2015 年，Fanuc，这家工业机器人制造商已经获得 Preferred Network 6% 的股权并计划将运行深度学习的机器人纳入不久的未来。ABB，这家瑞士机器人公司也投资了 Vicarious，一家拥有深度学习技术的人工智能创业公司。深度学习&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;深度学习还能显著扩大机器人目标市场，而传统机器人仅囿于安全笼并从事高度程序化的重复性工作。深度学习驱动的协作机器人能够运行于广泛不同场景。因为他们可以学习新任务并在人类身边安全运作，因此，我们认为机器人市场会像中小型市场开放，比如零售、农业，更别提家用了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尽管我们相信工业机器人仍然是大规模制造业中的驱动力，但是，他们的单位体积会被新的、更加敏捷的机器人秒杀，就像大型机被工作站、个人电脑和智能手机秒杀一样。其结果是，机器人的装运量会提高 10 到 100 倍。许多新机器人可能与今天的机器人没啥相似之处，就像智能手机与大型机完全不像。我们相信，深度学习驱动下的更小更聪明的机器人会接管机器人市场。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;原文链接：https://ark-invest.com/research/deep-learning-grow-robotics&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译文章，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Mon, 05 Dec 2016 14:27:34 +0800</pubDate>
    </item>
  </channel>
</rss>
