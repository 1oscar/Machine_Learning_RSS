<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>机器之心</title>
    <link>http://www.iwgc.cn/list/670</link>
    <description>人与科技的美好关系</description>
    <item>
      <title>深度 | 40年认知架构研究概览：实现通用人工智能的道路上我们走了多远？（附论文）</title>
      <link>http://www.iwgc.cn/link/3265307</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自arxiv.org&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：机器之心编辑部&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;今日，加拿大约克大学（York University）电气工程与计算机科学系在 arXiv 上发表了一篇关于认知架构研究的概览性论文，在感知、注意、学习和应用四个方面对认知架构方面的研究和应用进行了概述性的总结。机器之心对该论文进行了略有删减的编译，原论文可点击文末「阅读原文」下载。另外，作者还为本项目开发了直观的交互示意图，连同相关的额外资料可以在这里查看：&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;http://www.data.nvision2.eecs.yorku.ca/cognitive-architecture-survey/&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibsC7CE9mCiaYfYOVgk5GVGTPwDx8IonZxg8ia1QMqGo5pnibAws61icOpMjvunUib3ibbOvDceeZJtlxeg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;摘要&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这篇论文中，我们呈现了关于过去 40 年认知架构（cognitive architecture）研究的宏观概述。尽管目前已有架构的数量已经有数百种了，但绝大多数已有的调研都没有反映出这种增长，而只是重点强调了一小部分地位稳固的架构。虽然它们的贡献是不可否认的，但它们只能代表该领域研究的一部分。因此，在这篇调研中，我们将超越对重点的关注，而将我们的范围扩展成对认知架构研究的更具包容性和高层面的概述。我们最终的集合有 86 种架构，其中包括 55 种仍在活跃发展的架构，另外还从一些不同的学科（涵盖从心理分析学到神经科学等）中借用了一些。为了保证本论文长度合理，我们仅讨论了核心的认知能力，比如感知（perception）、注意机制（attention mechanism）、学习（learning）和记忆（memory）结构。为了评估认知架构的实际应用的广度，我们收集了超过 700 个使用了我们列表中的认知架构的实际项目的信息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们使用多种可视化工具重点突出了该领域发展的整体趋势。我们对实际应用的分析表明大部分架构都非常关注于一个特定的应用领域。因此，在机器人和计算机视觉领域的一般研究和在认知架构领域内的研究之间存在一个明显的鸿沟。可以非常明显地看到：生物启发的模型与基于工程原理和启发式的系统相比，在范围和效率上都不一样。我们观察到的另一个情况是合作的普遍缺乏。有几个因素妨碍了人们的交流沟通，比如许多项目封闭的本质（这里审查的架构中仅有三分之一是开源的）和术语差异。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;1 介绍&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本论文的目标是提供关于过去 40 年认知架构研究的宏观概述，并重点关注了感知、注意和实际应用。尽管认知架构领域一直以来都在稳健地增长，但过去 10 年来发表的大多数调研都没有反映出这种增长，而基本上只是关注了十几个最成熟的架构。上一次大规模的研究是在 2010 年由 Samsonovich et al. [1] 进行的，他们试图编目已经实现的认知架构。他们的调查包含了 54 种由它们各自的作者提交的认知架构。这些信息以「认知架构对比表」的形式发表到了网上（http://bicasociety.org/cogarch/architectures.htm）。当然，也还有其它认知架构的列表，但它们通常只是一个简短描述加上一个项目网址或软件库的链接而已。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;由于目前还没有详尽的认知架构列表，所以它们的准确数字还是未知的，但是据估计应该有大约 300 种左右，而且其中至少有三分之一的项目目前是活跃的。为了为我们的研究得到这份最初的列表，我们组合了其它调查（发表于最近 10 年内）中提及的架构以及一些大型的在线编目。我们还包含了这些调研文献未提及的最近的架构。图 1 展示了来自 17 个来源（调查、在线编目和谷歌学术）的 195 种认知架构的可视化。很明显可以看到 ACT-R、Soar, CLARION、ICARUS、EPIC、RCS 和 LIDA 等一小部分架构出现在了许多来源中，而所有其它项目只是在在线编目中有简短的提及。尽管这些主要架构的理论和实际贡献是不可否认的，但它们只能代表该领域研究的一小部分。因此，在这篇概述中，我们将避开对重量级架构的特别关注（其他人已经做了很多了），而是将对这整个领域进行一次高层面的概述。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibsC7CE9mCiaYfYOVgk5GVGTD7cvtOsLAuQZQNNmj5KQriaqVGkTiaHYyMicKak8mCNZqfAQNe8n1icicxQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 1. 来自调查、在线编目和谷歌学术的认知架构的组合列表。左侧的节点表示架构的调查和在线编目，右侧的节点表示单独的项目。节点的厚度表示连接到该节点的边（edge）的数量，即该架构出现的次数（右侧）或所包含的架构的数量（左侧）。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了使这次调研足够可操作，我们将原有架构列表缩减到了 86 项。因此，我们重点是至少有一个实际应用和多篇有同行评议的论文的已经实现的架构，我们没有考虑一些哲学上的架构（如 CogAff、Society of Mind、Global Workspace Theory、Pandemonium theory）。我们也排除了大规模脑建模项目（brain modeling project），这是较低层面的，不能轻易映射到由其它认知架构所建模的认知能力的广度上。另外，许多脑模型尚还没有任何实际的应用，因此也不满足本调查的参数。图 2 显示了本调查给出的所有架构和它们根据发表情况得出的大概时间表。它们中有 55 个项目目前是活跃的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;正如我们早些时候提到的，给已经实现的认知架构创建一个广泛的和有组织的编目的第一步是 [1]。这个概述包含了 26 个项目的扩展描述，其中包含的信息有：简要概述、主要元素的原理图、共同组分和特征（记忆类型、注意、意识等）、学习和认知发展、认知建模和应用、扩展性和局限性。这一类的调查将一些不相交的社区的研究者聚集到了一起，并帮助建立了这些不同方法和他们所使用的术语之间的映射。但是，这种描述性的和表格式的格式让我们无法对这些架构轻松地进行比较。因为我们的架构样本很大，所以我们实验了可做替代的可视化策略，例如冲积图（alluvial diagram）和圆图（circular diagram），它们常常被用于组织复杂的表格数据。这些图的交互式版本让我们可以探索这些数据和查看相关索引。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在后续的章节中，我们将提供关于认知的定义和分组认知架构方法的整体概述。作为我们的贡献之一，我们会根据认知架构的感知模式（perception modality）、注意的实现机制、记忆组织、学习类型和实际应用对它们进行映射。认知架构的其它特征，比如元认知（metacognition）、意识（consciousness）和情绪（emotion），不在本次调查的范围内。在准备这篇论文的过程中，我们广泛地审阅了文献，这项活动让我们得到了一个包含 2000 项的相关发表情况的参考目录（bibliography）。我们提供了这份参考目录，同时还带有每篇论文的简短摘要作为补充材料（发布地址：http://www.data.nvision2.eecs.yorku.ca/cognitive-architecture-survey/bib_html/index.html）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2 什么是认知架构？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;认知架构是通用人工智能（general AI）的一个研究分支，它起源于 20 世纪 50 年代，其目标是创建能够解决不同领域问题的程序、培养洞察力、能自己适应新情况并做出反应。同样，认知架构研究的最终目标是实现人类水平的人工智能。根据 Russell 和 Norvig [2]，这样的人工智能可以以四种不同的方式实现：像人类一样思考的系统，能理性思考的系统，像人类一样行动的系统，以及能理性行动的系统。现有的认知架构已经探索了所有四种可能性。例如，像人类一样的思想是源于认知模型的架构所追求的。因此，只要智能系统造成的错误如同相似情况下人类通常做出的错误，则它们的错误是可以容忍的。这与理性思维系统相反，理性思维系统需要为任意任务作出一致和正确的结论。像人类一样行动的机器和理性行动的机器之间的区别也与之相似。在后两种情况中，机器并不期望能像人类一样思考，我们关注的只是它们的行动或反应。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibsC7CE9mCiaYfYOVgk5GVGTcSNhfXYmcWq2Imz316ZXypibc6lygRfiaruFnlmW4Y4t0o3icxwPhgnaA/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 2 此次调查的 86 种认知架构的时间表。每条线对应一个认知架构。认知架构按照开始日期排序，因此最老的认知架构在图的最下部。由于只明确知道几个项目的开始和结束日期，因此我们按照项目网页的发布和活动日期还原了时间表。颜色对应于不同类型的架构：symbolic（符号式，绿色），emergent（层创式，红色）和 hybrid（混合式，蓝色）。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然而，由于认知没有明确的定义和一般理论，每个架构都是基于不同的前提和假设，使得比较和评估不同的认知架构变得困难。几篇论文试图解决这种不确定性，最著名的是 Sun 对认知架构的期望 [3] 和 Newell 的实用性标准（最初发表在论文 [4] 和 [5] 中，后来重新被 Anderson 和 Lebiere 提及 [6]）。Newell 的标准包括灵活的行为、实时操作、理性、海量知识库、学习能力、发展能力、语言能力、自我意识和大脑觉悟。Sun 的期望更广泛，包括生态、认知和生物进化现实主义、适应性、模块化、常规化和协同互动。除了定义标准，并把它们应用到认知架构的范围，Sun 也指出，明确界定认知的假设和方法存在缺失，这种缺失阻碍了智能研究的进展。他也提到了关于基本二分法（essential dichotomy）（隐式/显式，程序化/声明化等）、模块化认知和结构化记忆，存在一种不确定性。但是，快速浏览一下这些已有的认知架构就可以发现，这些架构在研究目标、结构、操作和应用方面长久存在分歧。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibsC7CE9mCiaYfYOVgk5GVGT4IeDicOpHzSXIG0c2B1XxxYtWrqnbWWwNMad0wZjfXz3mbOAUOOek7A/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 3 1973 至 2016 年间，活跃的符号式（symbolic）、层创式（emergent）和混合式（hybrid）架构的可视化。在图上显示了同时活跃的项目的最大数量。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相比于为智能寻求一个特定的定义，也许将智能定义为一个系统所体现的能力和行为的集合更为实际。虽然不存在一个智能所要求的能力的综合列表，但一些已经被认可的宽泛的方向也许可以作为目前认知架构领域工作的指导。例如，Adams 等 [7] 提议了 14 个方向，分别是感知、记忆、注意、社会交互、规划、动机、驱动、推理、交流、学习、为自身/他人建模、建造/创造以及算术能力（perception, memory, attention, social interaction, planning, motivation, actuation, reasoning, communication, learning, emotion, modeling self/other, building/creation and arithmetic abilities.）。这些可以进一步划分为更小的领域。可以说，其中一些类别也许看起来比其他的更重要，且历史上也受到更多关注。比如，根据 Metzler 和 Shea[8]，在近期认知架构的发表中最常被提到的认知功能仅包括感知、学习、推理、决策、计划和行动。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然而，即使在一个单一架构中仅实现一个缩减的功能集合，也是一个任务繁重的工程。因此，目前只有一小部分架构（如：Soar, ACT-R, NARS [9], LIDA [10]）和几个最近的项目（SiMA [11] 和 OpenCogPrime [12]）在追求通用人工智能（Artificial General Intelligence，AGI）。其他架构则专注某一特定的认知功能，例如注意（ARCADIA [13], STAR [14]）、情绪（CELTS [15]），对称感知（认知对称引擎（Cognitive Symmetry Engine）[16]）或者问题解决（FORR [17], PRODIGY [18]）。还有一些为特定应用设计的专门的架构，比如为平面视觉检测设计的 ARDIS[19]，以及为音乐理解和分类设计的 MusiCog[20]。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;使得一个软件系统能够被称为认知架构的标准也鲜被强调。大多数综述宽泛地定义认知架构为智能的一个蓝图，更具体地，是一个关于心智表征以及运行在这些表征之上的计算过程的设想，它们使得一定范围内的智能行为成为可能（[21], [22], [23], [24], [25]）。总的来说，新的认知架构不需要包括已有的认知架构，例如 Soar，ACT-R，EPIC，LIDA，ICARUS 等。然而，当它并不是那么常见或是一个全新的项目时，我们并不知道考虑现有的这些认知架构是否必要。举个例子，AKIRA 是一个明显的不能自我统一地认为其是一个认知架构 [26]，但是它的特性仍然被很多综述提及 [27]。类似的，知识库 Cyc [28] 从未对任何通用智能有所声称，却仍然在一篇论文中被总结为一个 AGI 架构 [29]。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Larid [30] 讨论了认知架构与其他软件系统有何不同。虽然它们都有记忆存贮、控制部件、数据表示和输入/输出设备，但其它软件系统只提供了一个用于一般计算的固定模型。而认知架构则必须随着发展而改变，并且高效地运用知识完成新的任务。此外，他认为用工具包（toolkit）和框架（framework）建立的代理（agent）架构也不能被当做认知架构，因为它们缺乏理论支持。这是一个相当严格的条件，除了 Soar 和 ACT-R，只有很少的架构能够符合这个要求。这一观点在综述论文里也不常见，通常代理架构和用来建造它们的工具包也会被包括在内。例如，代理架构 3T、PRS 和 ERE 被包括在了 [31] 内；Pogamut，一个用于建立智能代理的框架，也被包含在了 [1] 中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最近，谷歌（DeepMind）声称深度学习能够「解决人工智能（solving AI）」。类似地，Facebook 人工智能研究实验室（FAIR）及其它一些公司也在这个方向上活跃地进行研究。这些研究在认知架构方面具有怎样的地位呢？在目前，深度学习一些最广为人知的成就包括用于自动驾驶汽车的视觉处理（Mobileye）和谷歌的能够下围棋 [32] 和玩多种视频游戏 [33] 的神经网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一方面，DeepMind 发表的论文（没有在媒体上打广告）涵盖了范围很广的主题。比如说，许多论文都致力于与循环神经网络和深度神经网络相关的理论问题。此外，神经网络也被用来构建复杂的视觉注意和记忆（visual attention and memory）模型，比如：一种用于识别图像中多个对象（如门牌号序列）的基于注意的模型 [34]。记忆（memory）在深度学习领域具有特殊的重要性，因为为了寻找和利用数据中的复杂模式，网络应该要能执行链式的顺序计算。但是，在深度网络中，来自过去的计算的信息会受到新信息的影响。网格式长短期记忆（Grid Long Short-Term Memory/Grad LSTM）通过提供一种动态式选择或忽略输入的方式而解决了这个问题，从而可以在学习过程中保留重要的记忆 [35]。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;整体上看，DeepMind 的研究解决了人工智能领域里一些重要的问题，比如自然语言理解、感知处理、通用学习和用于评估人工智能的策略。尽管特定的模型已经证明了在有限领域内的认知能力，但目前它们还无法代表一种统一的智能模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;和 DeepMind 不一样，Facebook 的研究团队是在开发智能机器的更广阔的语境中明确讨论他们的成果 [36]。他们的主要观点是：人工智能是在太复杂了，以至于不能一次性开发出来，而是应该首先定义智能的通用特征。他们已经定义出了两个智能的通用特征：交流（communication）和学习（learning），并且还提出了一个逐渐发展它们的具体的路线图。这个方向的第一步是人工生态系统（artificial ecosystem，或称「幼儿园」），其被提出用于教育智能代理（intelligent agent），从而强调了这个过程的发展性本质。他们的计划是从更简单的模拟环境开始，然后逐渐增加其复杂度，直到最后它能够将人工代理和真实世界连接起来。鉴于这种对交流和学习的强调，这种智能机器的一种主要应用就是电子助理。作者承认类似的想法在过去已经得到过尝试（如，常被符号架构用于学习的 Blocks World 模拟），但它们都过于依赖于其创造者所提供的数据。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前没有文献提及这样的系统，但 FAIR 追求的研究主题与其人工智能展望也与各家公司的商业利益相一致。常见的相关话题包括可视化处理，特别是分割和目标探测、数据挖掘、自然语言处理、人机交互和网络安全。目前深度学习技术主要用于解决实际问题，并不代表一个统一框架，所以不包括在此次调查的范围内。当然，鉴于深度学习的潜力，这一方法将来可能会在认知架构中发挥作用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于其他架构，我们定义了以下选择标准，努力实现包容和一致：自我识别作为认知，机器人或代理架构，已有实现（不必是开源的），以及用于感知、注意和学习的机制。为了进一步缩小调查的范围，我们需要至少存在同行评审的论文和应用，而不能只有简单的演示。但为包括一些仍在开发中的新架构，其中的部分条件得到了放宽。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3 认知架构的分类&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;过去十年发表的许多论文提出的多是认知架构的评估而非分类。像之前提到的，Newell 的标准和 Sun's Desiderata 就属于评估这一类。相似的，Langley 等人将认知架构的能力，性能和评估标准定义成一个综合的列表。认知能力的建议集合包括识别，作出决定，感知，预测，计划，行动，交流和学习。为了评估构架，提出了例如通用性，多能性，自主性的标准。与此同时，Vernon 等人列出了比较认知和浮现式方法的 12 个特征，包括体现，感知，行为，适应，动机，自主化和其他。相似的，Asselman 等人则通过 7 个标准（认知，记忆，学习，模块化，目标设定，基本模型和解决问题）评估构架。Thorisson 和 Helgasson 基于 4 个标准（实时操作，学习，注意和元学习）来决定自主化的水平。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;许多标准可以被用来划分架构，但它们应用在一般的构架时会显得过于细致。因此，基于它们表现出的信息加工的种类来划分认知架构是更为常见的方法。三个分类方法被称作：符号式（认知主义），层创式（联结主义），混合式。这种基于信息加工的分类方法被 Duch 等人 [21] 拓展到含每个类别的典型记忆和学习性能（[38], [39])）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;符号式系统通常在一系列可用于表现世界的真相的符号中作为 if-then rules（也被称作 production rules）执行。因为它是知识的一种自然而直观的表达方式。符号式操作十分普遍。尽管经过设计，但符号式系统在计划和推理方面有优势，而在被要求处理变化的环境和感知过程时缺乏灵活性和坚固性。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;层创式方法通过建立大量的并行模型，类比神经网络（此处信息流是通过从输入节点的信号波及表现的）解决了上述问题。但是，这样的系统也丧失了它的透明性。因为知识不再是一系列符号化的实体而是分布在网络中。因而同样，传统意义上的推理在层创式架构中存在问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;自然地，每个范例都有着它的优缺点。例如，任何符号式架构都需要大量的工作去建立一个初始的知识基础。但一旦它建立好，整个架构就会变得十分有效。而另一方面，层创式架构更容易设计，但它们必须经过训练才能完成有效的动作。更重要的是，它们的已存在网络可能会因为接下来学习的新行为而被摧毁。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;由于没有任何一个范式（paradigm）可以单独处理全部的人工智能问题，混合架构试图结合符号式和层创式两种元素。总的来说，两者如何混合没有一个明确的限制，但有的方法更加直观且易于执行。例如，CLARION 基于不同知识类型有不同的表现形式：明确的事实知识用符号式，程序中暗含的知识用亚符号式 [40]。4CAPS 将传统的符号式生产系统用联结主义的计算机制：如阈值、激活、权重和并行处理来诠释 [41]。这种混合方式被 Duch 等人 [21] 称作符号式联结主义（symbolicconnectionist）。同时他们也定义了一种替代的地区性分布方法。后者很好的例子就是 Leabra，它在学习不变事物的检测时用到了标签的地方主义（localist）表征和特征的分布式表征 [42]。在 [43] 中，这两种混合式的表征被分别称作平行和垂直的整合。一个混合联结主义-符号化模型的更为细致的分类方法在 [44] 中呈现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibsC7CE9mCiaYfYOVgk5GVGTwPKQRvuL5Xia8Kfd5Qc9iazEm1FNLlIjcJdDVHRnMOw1ZGWkls5SNpjA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;图 4：Duch et al. 在 [21] 中提出的分类方式；&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;图 5：Sun 在 [45] 中提出的分类方式；&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;图 6：Gray 在 [46] 中提出的分类方式&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有趣的是，层创式架构只在最近时期才获得更多的比重，尽管这一方向的研究至少与传统人工智能一样活跃。例如 Langley 等人 [22] 在他们的调查中没有加入联结主义模型，因为他们没有发现这一架构与符号模型和混合模型相同的功能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;考虑到混合方式的优点，这样的架构有最高的增长趋势便不足为奇了（图 3）。所以，我们的数据证明了 Duch 等人 [21] 在 10 年前的预测。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;文献资料中仍没有多少其他的分类方法。Sun[47]（图 5）的方案强调模块化和模块之间的通信。然而，遵循此类方法需要所有架构的实现方式细节，这些信息经常不能获得。其他分类方案也很具体，如 Gray[46] 提出的方案，其重点在于架构的目的及使用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因此，在本次研究中，我们遵循符号、层创和混合架构的传统区分方式。由于我们介绍的架构的背景跨越从哲学到神经生物学的广泛研究领域，我们不会试图创立一个单一的体系来适应它们。我们不会对每一个认知功能分别进行讨论，而是以功能（即：感知、注意、记忆和学习）进行分类的讨论。我们从发表情况中提取了数据，并按频率进行了分组。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;4. 感知&amp;nbsp;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibsC7CE9mCiaYfYOVgk5GVGTYvZtXxTdJS6AVgQkJyMLia6RLppZ6NcHd0303DHU3MgLW3KGb9vmmfQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;图 7 显示了认知架构的感知通道（sensory modalities）。该架构分成三组： 符号式（绿色），层创式（红色）和混合式（蓝色），位于图底端。图中其他部分对应不同的感知通道，包括视觉、听觉、触觉、嗅觉和本体感觉。这个感知分类还包含了不对应任何人类感官的多种感知。「符号输入」类别表示的是认知架构中的输入只限于文本形式，或者需要通过 GUI。这不包括文本输入模拟音频、视觉或其他类型的信息。图中每个大类别扇形中的带表示的是这些感知通道的子类别（例如视觉类别下包括 Kinect、单眼相机、模拟等）。感知通道与架构之间的条形是用来表示它们之间的连接。如果一个架构控制多个感官，条形就越不透明。每个认知架构的感知方式列表都带有相关文献，被包括在补充材料和图形的互动版本中。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;5. 注意&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibsC7CE9mCiaYfYOVgk5GVGTODj3J4qfDrvz6XHWfwIUd2MQrIW3fertoBibdgTbhbXpj48E9aSuYDQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 8 显示了认知架构中不同类型的注意。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;6. 记忆&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibsC7CE9mCiaYfYOVgk5GVGTbXT8r3Blfib0wJpO1icJd0NonawYPt4RwBQc4GSjKOFn7RkI25W1jf8A/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 9 显示了认知架构中不同类型的短期记忆（STM）和长期记忆（LTM）&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;7. 学习&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibsC7CE9mCiaYfYOVgk5GVGTarZcGlmck6KU39GuEq8Km2pXwT1Lqp6rDmzI6kNkEkErW9VKeB5Eug/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 10 显示了认知架构中的学习机制。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;8. 认知架构的应用&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本论文中的回顾的大部分认知架构都是研究工具几乎很少被开发到学界之外的应用。然而，还是可以讨论一下他们的实际应用的，因为不同情境下有用的行为被认为是许多认知结构的目标。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;彻底研究过这些发表的论文后，我们使用 86 个认知架构确定了 700 多条 project，如图 11 显示。所有的应用都可以划分到几个大组（group）中，即人类表现建模（human performance modeling，HPM）、游戏和拼图（puzzles）、机器人、心理学实验，自然语言处理和其他杂项，还包括了不属于任何大组的项目，它们由于太少所以无法独立成大组。这样的分组强调了每个 project 的应用，即便每个研究者有不同的目的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一些应用可能会被划分到多个组。例如，装上一只机器手臂的 Soar 一直被用来玩棋盘游戏，这就同时关涉到机器人、游戏和拼图以及心理学实验。为了避免让这张图过于复杂，在这些案例中我们只将 project 放在了主要的组中考虑，在 Soar 的例子被划为游戏，因为它在机器人上的应用并不是很大，而且心理学实验组主要是使用 ACT-R 的 fMRI 实验。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;人类表现模型（HPM）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人类表现模型是一个与建立某个特定任务环境中的人类表现的量化模型相关的研究领域。这些模型主要用于几个工程领域，在这些领域中，设计可能性的空间非常大，导致实证的评估方式不可行或者成本太高。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这种建模类型一直用于军事应用，例如，Apache 直升机机组人员的负荷分析，战场感知中通信任务的影响建模 [230]，AAW 领域的决策制定 [231] 等等。普通的民用包括空中交通管制任务的模型（例如，COGNET[232]）, 飞机滑行失误 [233]，911 调度员 HPM 用的是少数专用架构，包括 OMAR、 APEX、COGNET,、MIDAS 和 IMPRINT。Soar 在大规模分布式军事模拟战中用于部署某个飞行员模型&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;例如，导航中会用到一个机器人，无论是从推理上还是作为某个学习算法的演示，它都会被归为机器人组。唯一的例外是心理学试验组，其中还包括心理社会学、fMRI 和 EEG 试验。这个组中的 project 是由认知架构执行的，用于与人类数据对比的特定的心理实验（例如倒数 n 任务、调节或注意的盲目性）。游戏和拼图类别包括不同领域中的棋盘游戏、视频游戏、拼图和逻辑推理的应用。HPM 对关于机组人员（aircraft crew）、核电站的操作员以及执行其他复杂任务的人的建模很有用，例如电话接线员和空中交通运维人员。大部分自然语言处理应用都关涉到对说出或打出来的命令的理解，也与社交机器人有关。然而该组中也有一些 project 用于意义排歧和句子整体意义理解的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;人机交互（HRI）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;HRI 是研究人与机器人对话中不同方面的多学科领域。这些互动大部分都发生在社交式的、辅助式的或发展式的机器人语境中。根据机器人的自动化水平，互动可以扩展到从直接控制机器人（遥控）到其完全自动化的任务中，实现人机对等合作。虽然该项研究中的系统还没有一个能达到完全自动化的水平，但它们可以实现一定程度上的监控，从用单韵母表示机器人的运动方向 [SASE236] 到自然语言指令（例如 Soar[237]，HOMER[88]、iCub[238]）。通常的假设是，一个命令有一个特定的形式，而且使用的词汇有限。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;某些架构也用于 HRI 的非口语（non-verbal）方面，例如对话的自然轮转（Ymir[239]，Kismet[240]，改变面部表情（Kismet [241]）或者转向护理机器人（MACsi[242]）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibsC7CE9mCiaYfYOVgk5GVGTSVPcJVrGPISd6CabzcNUwTDRkyq7G7YquAT7c2q796DTto1sbyVKhg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;图 11. 认知架构的实际应用图。这些架构被分成了三组：符号式（绿色）、层创式（红色）和混合式（蓝&lt;/span&gt;&lt;/em&gt;&lt;span&gt;&lt;em&gt;色）。应用被分成了代表不同领域的组。其中每一个应用都是使用了一种认知架构实现的特定项目，并且还得到了相关论文、软件或视频演示的支持。其中不包括仅有部分结果或实物模型的项目。另外，涉及与该架构中其它部分隔开的特定算法的例子也没有被包括进来。可视化使用 http://www.circos.ca (http://www.circos.ca/) 完成。关于每种认知架构的应用列表及相关索引可见于补充材料中，也可以在该图的交互式版本中查看。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;自然语言处理（NLP）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这一组的应用是关于理解书面语言和口头语言。尽管使用现成的软件来进行语音识别和文本解析对认知架构来说很常见，但也有一些架构为 NLP 研究做出了贡献。特定的例子包括：照明分辨率（Polyscheme [243]，NARS [244]，DIARC [245]）、语音识别基准（Sigma [246]，[247]，SASE [248]）和学习英语被动语态（NARS [244]）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;归类和聚类（Categorization and Clustering）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;归类（categorization）、分类（classification）、模式识别和聚类是从大数据集中提取概括信息（general information）的常见方式。在认知架构的背景中，这些方法可被用于处理嘈杂的感官数据。这一组的应用几乎完全都是用层创式架构（emergent architectures）实现的，比如 ART 和 HTM，它们被用作是复杂的神经网络。尤其是 ART 网络已经在范围广泛的领域的分类问题上得到了应用，包括电影推荐（Netflix 数据集 [249]）、医疗诊断（Pima-Indian 糖尿病数据集 [250]）、错误诊断（气动系统分析 [251]）、元音识别（Peterson and Barney 数据集 [252]）、气味识别 [253] 等等。HTM 架构面向时序数据分析（analysis of time series data），例如预测 IT 故障（grokstream.com）、监测库存（numenta.com/htm-for-stocks）、预测出租车乘客需求 [254] 和基于按键模式识别手机使用类型（电子邮件、电话等等）[255]。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一些非层创式架构（non-emergent architecture）的例子包括根据追踪套装识别手势（Ymir [256]）、电信网络故障诊断（PRS [257]）和基于关于作者和引用的信息分类文档（OpenCogPrime [258]）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;计算机视觉&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这一新兴的认知架构也被应用于解决典型的计算机视觉问题。目前只有一些独立的例子，例如笔记特征识别（HTM[259],[260]）、图像分类基准（HTM[261],[262]）、视角无关性字母识别（ART[263]）、纹理分类基准（ART[264]）、不变目标识别（Leabra[265]），等。计算机视觉的的应用经常是任务处理的一部分，如机器人导航，这在本论文的相关章节也有谈及。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;游戏和解谜&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该分类内的应用包括棋盘游戏、视频游戏以及解决有限领域内的难题。简单的包含重叠旗子的棋盘游戏如井字棋，八数码和五数码问题经常被用来证明知识迁移（例如 Soar[227]，FORR[266]）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;视频游戏也是认知架构应用的虚拟领域。在最受欢迎的游戏《虚幻竞技场 2004》（UT2004）中有一个开源工具包 Pogamut[267] 可以自由创建智能的虚拟角色。另外，它还有许多同类型的竞争者，玩家们在这些游戏中不仅需要关注得分和效率，同时也得保持与游戏中虚拟角色的关系（2K BotPrize Contest7）。Pogamut 不仅 实现了很多认知功能，它还是 BotPrize 比赛推荐的软件，可以经过修改实现更多的特性（[268], [269], [270], [271], [271], [272]）。其他的此类游戏包括《Freeciv（REM [273]）》，《Atari Frogger II（Soar [274]）》，《Infinite Mario（Soar[275]）》，网页端游戏（Star[276]）和一些定制游戏。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;心理实验&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;心理实验的应用是使用认知架构的多种心理生理学研究，包括 fMRI 和 EEG 实验。此类实验利用认知架构可以对人类指标进行数字化建模，或对心理现象给出合理的解释。如果由模拟产生的数据在一些或大多数方面与人类数据匹配，则说明给定认知架构可以模仿人类生理机制。随后，认知模型可以用于对不同情况下的行为进行预测或进一步分析，最后可帮助人们对已知现象背后的心理机制进行解释。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;大多数实验在模拟环境中进行，尽管在实体机器人中也存在一些例子（例如，在 DarwinVII 机器人上的感知分类模型 [181]）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;机器人&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在机器人中，认知架构有许多应用。导航和避障是基础的行为，对机器人自身有帮助，也可作为更复杂行为的一部分，比如辅助机器人。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在机器人早期研究中，做杂务是非常的流行的用来有效证明机器人能力的方式。一些著名的样例包括垃圾收集移动机器人（3T [277]）、苏打罐收集机器人（Subsumption [278]）。通过结合简单的视觉技术（比如边缘检测和模板匹配）和传感器技术（导航），这些机器人能够在未知环境中发现感兴趣的目标。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最近的认知架构倾向于分开解决搜索和目标操控任务。典型的，有的实验是在可控环境中完成视觉搜索，对明亮颜色或者可识别的形状的喜好可用来最小化视觉处理任务。有时会使用到标记（markers），比如将条形码附属到目标上进行更轻松的识别（Soar[279]）。需要主要的是，这些案例中的视觉搜索通常是更复杂任务的一部分，比如通过指令进行学习。在视觉搜索和定位是最终目标时，环境更为真实（例如，通过传感器和 SIFT 特征的结合，CoSy 控制机器人在书架上找到一本书 [280]）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目标操控涉及到控制机械臂触碰并抓取（reach and grasp）目标。虽然触碰是相对简单的一个问题，且许多架构部署不同形式的机械臂控制，在模拟环境中抓紧目标却更具挑战性。抓取的复杂性由多种因素决定，包括抓手的类型、目标的特性。一种变通方案是用软体目标进行试验，比如毛绒玩具（ISAC [281]）。近期的研究涉及到通过 DIARC [282], [282]控制的机器人证明可以抓取不同类型的目标（在顶部或边缘有抓手的目标）。另一个例子是 iCub[283] 根据抓取瓶罐的大小、抓取的箱子和直尺等不同目标进行适应。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其他应用包括机器人销售员、教师、医疗机器人等。工业应用由单个架构 4D-RCS 所代表，已经被远程控制的吊机机器人 [284]、架桥机器人[285]、自动清洗和去毛刺工作站机器人[286]和美国邮局自动邮票分发中的机器人[287]等使用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;虚拟代理&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;模拟和虚拟现实总是被频繁用为物理化身的替代。例如，在军事领域，危险情境下军人的模拟模型行为不会对身体造成伤害。其他例子包括在自杀式炸弹袭击场景中建模代理（CoJACK [73]）、维和部队训练（MAMID [190]）、在复杂的城区地形的指令和控制（RCAST[288]）、坦克战模拟（CoJACK[289]）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在民用领域，模拟建模智能代理的行为也非常常见。虚拟环境的一个优势是它能提供关于代理任意时间点的状态信息。这对学习临场情感影响非常有帮助，例如在社交环境（ARS/SiMA[290]）或学习场景中，比如与虚拟的狗狗玩耍（Novamente[291]）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;9 讨论（略）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;参考文献见下载论文&lt;/span&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Fri, 28 Oct 2016 15:48:33 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 机器已经学会隐藏自己：谷歌教会神经网络自己设计加密算法（附论文）</title>
      <link>http://www.iwgc.cn/link/3265308</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自NewScientist&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李泽南&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;计算机总是和秘密有关，人们将加密算法输入其中传递信息，又利用计算能力破译密码，信息的保护和破解随着硬件性能的加强不断升级。最近，谷歌深度学习项目 Google Brain 的一个小组提出了新方法，让计算机加密的方式更上一层楼，他们的系统可以自我增强加密算法。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibsC7CE9mCiaYfYOVgk5GVGTwwX28CpN3NSKVZkLp85IHDiceTEOw6t5eibWdrUR1uDYGPjryB1rGL2w/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;em style="color: rgb(136, 136, 136); text-align: center;"&gt;&lt;span&gt;机器已经学会如何互相传递秘密（图片：John Lund/Getty）&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谷歌科学家 Martín Abadi 和 David Andersen 在最近的研究中发现，神经网络——基于人工神经元的计算系统——可以学习如何使用加密技术。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在他们的实验中，计算机能够使用机器学习形成自己的加密形式，而不需要人类输入特定的加密算法。与目前的复杂计算机系统相比，这些加密算法相对简单，但它是探究神经网络的一个有趣进展。这一研究「仍不意味着密码学的发展」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Google Brain 团队首先使用名为 Alice，Bob 和 Eve 的三个神经网络，每个系统各司其职，互相联系。Alice 发送一串加密信息给 Bob，Bob 负责解密这条信息，而 Eve 则尝试窃取信息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了确保秘密，Alice 在自我训练中开始将明文信息转变为专业术语，让窃听者（Eve）无法理解。这种专业术语「密电」必须只能被 Bob 理解。此时 Alice 和 Bob 开始使用预先约定好的一组数字作为秘钥，以帮助解密，而 Eve 无法访问这组秘钥。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibsC7CE9mCiaYfYOVgk5GVGTytCv5hibjC8O0bmEzpaibc2gDicWSW3uIbRV8iclverH5w8XRmicrgIQeJQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;三个神经网络在系统中的训练方式&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;熟能生巧&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最初，神经网络发送的加密消息非常简单。但是随着它们不断的自我练习，Alice 慢慢发展出了自己的加密策略，Bob 则不断试图通过秘钥解密信息。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这一任务被分为 4096 批同时进行，研究人员发现，在执行约 15,000 次以后，Bob 学会了将 Alice 发出的密电转回原文本，而 Eve 平均只能猜出信息中二进制 16 位数字中的 8 位。鉴于二进制只有一和零两种表示，这表明它的解密结果只是纯粹的猜测。此项研究已经于 10 月 21 日在 arXiv 上发表。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibsC7CE9mCiaYfYOVgk5GVGT5vDHa3Xep8aqZBkhNXib8By30tu5uKuLI9XplzXM1JJHKztzKKnkNgw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Bob 和 Eve 解密信息的错误率随实验次数的变化&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;大多数人并不知道加密算法的机制，但机器学习的过程已经告诉我们它是如何产生的。目前为止，机器学习提供的加密算法并不能提供安全保证，该项研究对于网络安全的意义可能还很有限。但这种探索可以为加密算法的进一步研究提供新的思路，同时，研究人员认为神经网络在未来也可用于破解密码。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;总部位于密尔沃基的加密软件公司 PKWare 首席技术官 Joe Sturonas 评论道：「这个级别的神经网络计算机在近几年才投入使用，所以我们还只是在一切的开始。如果计算机想要接近人类设计出的密码的复杂性，还有很长的路要走。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;论文：对抗神经密码学——保护通信安全的研究（Learning to Protect Communications with Adversarial Neural Cryptography）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibsC7CE9mCiaYfYOVgk5GVGTFlSK5uCLOXicJAdH7VIrfhh3p3icWrMjYnY4ZRejludJlBx2Gof1qlOA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：在本研究中，我们让神经网络学习使用秘钥来保护从其他神经网络传递过来的信息。具体方法是：我们为了确保多代理系统（multiagent system）中的保密性进行秘钥升级，同时根据破解者的方式不断改变秘钥的属性。在试验中，系统中的神经网络名为 Alice 和 Bob，我们需要阻止名为 Eve 的第三个神经网络窃取前两者之间的通信内容。我们不对这些神经网络事先输入已有的加密算法；相反，我们以点对点的形式让它们互相对抗自我训练。我们证明了神经网络可以学习如何加密与解密，以及如何有选择地应用各种操作来让信息保密。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，机器之心系今日头条签约作者，本文首发于头条号，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Fri, 28 Oct 2016 15:48:33 +0800</pubDate>
    </item>
    <item>
      <title>学界 | MIT CSAIL 实验室新算法：能在损坏数据中寻找模式</title>
      <link>http://www.iwgc.cn/link/3265309</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;选自MIT CSAIL&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;包括 MIT 计算机科学与人工智能实验室（MIT CSAIL）的研究员在内一组团队创造出了一系列新算法，能够高效的在高维数据中拟合概率分布。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibsC7CE9mCiaYfYOVgk5GVGTJgniclw3b75ZFXKDvL80cz2aZJdoKticDksp4B1kLmibjK1RURibNtVBxw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数据分析，尤其是大数据分析，大多是将数据拟合到数学模型的问题，最熟悉的例子就是线性回归，也就是找到数据点近似分布的线。将数据拟合到概率分布，比如贝尔曲线，也很常见。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然而，如果数据集只有一些损坏的条目，也就是说损坏的难以测量，标准的数据拟合技术就不行了。该问题在高维数据或带有许多变量的数据中更为严重，而这类数据在数字化时代又是普遍存在的。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;众所周知，从 20 世纪 60 年代早期开始，就有一些算法能够除掉高维数据中的损坏数据（corruption），但过去 50 年提出的算法没有一个在变量超过 12 的时候很实用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该进行改变了。在本月初，来自 MIT CSAIL 实验室、南加州大学、加州大学圣迭戈分校的一组研究人员在 IEEE Symposium on Foundations of Computer Science 上展示了一系列新的算法，能够高效的在高维数据中拟合概率分布。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;引人注目的是，在同一会议上，来自 Georgia Tech 的研究人员提出了一个非常类似的算法。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在能够忍受损坏数据的「稳健统计」或统计方法上的首创工作是由统计学家完成的，但新的论文都来自一堆计算机科学家。这可能反射出该领域内注意力的转向，开始注意模型拟合技术的计算效率。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;MIT Rockwell International Career Development 助理教授 Ankur Moitra 说，「从理论计算机科学的优势来看，很明显一个能被有效解决的问题有多稀少。如果你从假设作为开始，就会很糟糕，因为这是低效的。你应该从你知道你能高效进行的事情开始，并搞清楚如何将它们合在一起从而更稳健。」Moitra 也是 MIT-USC-UCSD 项目的领导者之一。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;抵制损坏数据&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了理解稳健统计之后的原理，Moitra 解释说想想正态分布，贝尔曲线，数学的说法也就是一维高斯分布。一维高斯分布完全由两个参数所描述：平均值和方差。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果数据集中的数据（假设是给定人群的身高）能被高斯分布很好的描述，那平均值就是算术上的平均。但假设你有一个包含 100 位女性身高的数据集，其中大部分身高是 64 英寸，一些很高，一些很低。其中一人的身高因某些原因达到 1000 英寸。用算术平均得到女性平均身高是 6.4 英尺，不是 5.4 英尺。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一种避免这种荒谬结果的方法是评估平均值，不采用数据的算术平均，而是找到其中值。使用中值评估平均值的算法要更为稳健。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;中值只是平均值的近似值，而且随着变量的增多该近似的准确率会急剧下降。大数据分析可能需要测试千个甚至百万个变量。在这种情况下，平均值的中值近似法基本不能用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;异常点识别&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一种将高维数据集中的损坏数据清除掉的方法是采用数据图的 2-D 交叉界面，并观察它们看起来是否像高斯分布。如果不是，你可能置入了一类假的数据点，比如 80 英尺高的女人，这些数据点可被轻易的切除。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;问题是，将先前已知的算法应用到该方法时，找到损坏数据所需要的交叉界面的数是维度量的一个指数函数。相比之下，这组研究人员发现一种算法，这种算法的运行时间随着数据维度的数量以更合理的比率增长（计算科学术语来讲就是 polynomially）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他们的算法依赖两种洞见。首先是在测量数据集离分布范围（近似同样的形状）多远时使用什么 metric。这能让他们分别是否淘汰了足够的损坏数据，从而更好的拟合。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一种洞见是如何识别界面开始交叉时的数据的区域。为了做到这一点，研究人员依靠被称为分布的峰态（kurtosis of a distribution）来测量其 tails 的大小，或者说是数据距离平均值降低的速率。再次强调，有多种从数据样本中推断 Kurtosis 系数的方法，选择正确的一个是该算法的核心。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;研究人员的这种方法能结合高斯分布，也能结合其他常见的分布——乘积分布（&lt;span&gt;product distribution&lt;/span&gt;）。他们相信该方法可被扩展到其他类型的分布上，在接下来的研究中，他们将主要关注将该技术用到真实数据上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Fri, 28 Oct 2016 15:48:33 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 迪士尼推出新面部捕捉系统：更少的数据捕捉更精确的表情</title>
      <link>http://www.iwgc.cn/link/3265310</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;选自Disney Research&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：杜夏德&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;em style="color: rgb(136, 136, 136);"&gt;&lt;span&gt;迪士尼研究（Disney Research）开发出一种新的面部捕捉系统（facial capture system）用于捕捉演员的特定表情，相对于常规的系统，该系统需要的时间与投入更少。&lt;/span&gt;&lt;/em&gt;&lt;br/&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;研究者发现他们可以使用采用小样本的录像，然后合成生成必要的数据来训练这个系统，无需详尽地录下演员在多种灯光条件的组合与机位下表现出的各种表情。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这种生成数据的方法能够使他们来确定一组小于常规量的数据（小了几十到几百倍）训练数据，不会影响到面部捕捉的精确性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在今年 10 月 25 日在帕洛阿尔托举办的 3D 视觉国际大会上（International Conference on 3D Vision）展示了他们的这项技术。「由于机器学习的进展，实时无标记的面部表情捕捉在电影和视频游戏制作中已经逐渐流行起来，」迪士尼研究的副总裁 Markus Gross 说到。「通过减少训练这些系统所需的面部图像数量，我们的团队已经大大增加了这项技术的灵活性和效率。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibsC7CE9mCiaYfYOVgk5GVGTia3w2TPIwjWMFASmbUbOHhHZVSicjJ2jmcRjUna7Ac7zQtkxXuuMPn4g/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器学习技术加速了从视频中推断面部几何的过程，但这需要详尽的训练程序使用大量经过注释的人脸图像。「不仅需要捕捉到所有的表情，还要考虑不同的灯光条件和拍摄角度，这会花掉大量的精力，」高级研究员 Kenny Mitchell 说到。「我们的想法是如果我们能够利用策略在特定的条件下捕捉某个演员的表情，我们可以合成所有的训练数据来得到一个目标场景，节省很多时间。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;iframe class="video_iframe" data-vidtype="1" style="   z-index:1; " height="375" width="500" frameborder="0" data-src="https://v.qq.com/iframe/preview.html?vid=l0341irgjtf&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0" allowfullscreen=""&gt;&lt;/iframe&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;研究员使用一台多相机捕获设备在均匀光照条件下，初步记录某个演员脸上的 70 个表情。这些表情数据被用来创建一个面部合成机器（face rig），也是一个可移动的、可塑造型的该演员脸部的模型。之后这个 face rig 被用来生成经过修剪的合成训练数据，可用于多种环境条件和不同性能的相机，而且能达到和制片人期望的实际设置差不多的效果。迪士尼研究的博士后 Martin Klaudiny 说。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些研究员确定他们可以通过训练更多的表情和光照变化数据来达到最佳精确度，同时保证摄像视角的变化对最终结果的影响相对较小。「我们的试验结果显示，最佳的设计策略能够减少一到两个数量级的图像数量，同时计算量也会成比例地减少，而且不损害精确度。」该研究小组另一位关键的博士后研究员 Steven McDonagh 补充道。该研究延续了迪士尼利用最新技术讲述故事建设未来娱乐的传统。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Fri, 28 Oct 2016 15:48:33 +0800</pubDate>
    </item>
    <item>
      <title>深度 | 谷歌增强型风格迁移新算法：实现基于单个网络的多种风格实时迁移（附论文）</title>
      <link>http://www.iwgc.cn/link/3247856</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Google Research&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Vincent Dumoulin、Jonathon Shlens、Manjunath Kudlur&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李亚洲、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;pastiche 是一个法语词，它的意思是将一件艺术品模仿另一件艺术品的风格（请不要与看起来和它接近的更幽默的希腊源词 parody 混淆）。尽管这种方法已经在视觉、音乐和文学等艺术领域被使用了很长一段时间，但 pastiche 直到最近才在 Reddit 网络论坛（https://www.reddit.com/r/deepstyle/）上将大众的注意力吸引到了给图像染上著名画作的风格的任务上。通过使用一种叫做风格迁移（style transfer）的技术，用户可以通过手机或网页应用让他们自己的图片带上著名艺术作品的风格。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尽管用户已经能通过当前的技术得到美轮美奂的 pastiche 了，但我们觉得我们可以将其做得更吸引人。目前，每一种画作都有它自己的独特风格，也就是说：用户提供一张内容图像，选择一种艺术风格，然后得到一张 pastiche。但如果我们能结合多种不同的风格，探索著名艺术家风格的独特混合从而创造出一种完全独特的 pastiche 呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;学习艺术风格的表征&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在我们的论文《A Learned Representation for Artistic Style》中，我们介绍一种可以让单个深度卷积风格迁移网络（deep convolutional style transfer network）同时学习多种风格的简单方法。该网络在学习了多种风格之后可以做到 style interpolation（风格插补），其中 pastiche 可以平滑地从一种风格变成另一种风格。我们的方法也能实现实时的风格插补，让其不仅可以应用于静态图像，还可应用于视频。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;iframe class="video_iframe" data-vidtype="1" style="   z-index:1; " height="375" width="500" frameborder="0" data-src="https://v.qq.com/iframe/preview.html?vid=d0340au56y5&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0" allowfullscreen=""&gt;&lt;/iframe&gt;&lt;/em&gt;&lt;/span&gt;&lt;em style="color: rgb(136, 136, 136); line-height: 1.75em;"&gt;&lt;span&gt;扮演者：Google Brain 团队办公室的狗 Picabo&lt;/span&gt;&lt;/em&gt;&lt;span&gt;&lt;em&gt;&lt;br/&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在上面的视频中，多种风格被实时地结合到了一起，最后得到的风格通过一个单风格迁移网络（single style transfer network）得到了应用。其用户可获得 13 种不同的绘画风格，可以通过滑块调整最终风格中这些风格的相对强度。在这个演示中，该用户是产生该 pastiche 的一位活跃的参与者。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;风格迁移简史&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尽管将一张图像的风格迁移成另一张的风格的技术已经存在了近 15 年时间 [1][2]，但利用神经网络来做这件事还是最近才出现的，而且这很吸引人。在论文《A Neural Algorithm of Artistic Style》，研究者 Gatys、Ecker 和 Bethge 介绍了一种使用深度卷积神经网络（CNN）分类器的方法。其 pastiche 图像是通过优化（optimization）找到的：该算法会寻找一张给出了该 CNN 的底层中同种类型激活（activation）的图像，这些底层会获取风格输入（宽笔触和立体美感等等）的整体粗糙美感；该算法还会在更高层产生激活，这是获取能使对象可被识别出来的东西，这接近于那些由内容图像所得出来的东西。从某个起始点（如：随机噪声或内容图像本身）开始，该 pastiche 会逐渐细化直到这些要求都得到满足。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9ud9Ce5mvD8vXXnwE6wtH7FXl0TjqY2cgXict45vYD7zHictjrSIfh1kI4gZ47Qpgu0Y7ttooMsjbw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;内容图像：Andreas Praefcke 拍摄的 Tübingen Neckarfront；提供风格的画作：Georges Rouault 的「Head of a Clown」&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过这个算法生成的这个 pastiche 看起来很壮观（spectacular）：图片来自 L. Gatys et al. "A Neural Algorithm of Artistic Style" (2015).&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9ud9Ce5mvD8vXXnwE6wtH7IC5VE6SOaTBmwq4ibtotHMfbmntRtQ2hJV4s8IwGSU0s8ZeHXcogtAQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该成果被认为是深度学习研究领域的一项突破，因为它首次提供了基于神经网络的风格迁移的概念证明。不幸的是，这种为单张图像施加风格的方法对计算的要求很高。比如说，在网络上首次可用的演示中，用户需要将图片上传到一个服务器，然后还要等上足够喝一杯咖啡的时间才能得到结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;后续的研究 [4,5] 为这一过程提速了不少，这些研究认识到可以将这个优化问题转变成图像变换问题（image transformation problem），其希望将单个固定的风格应用到任意一张内容图像（比如一张照片）上。然后该问题就可以这样被解决：训练一个前馈的深度卷积神经网络来调整内容图像的 corpus 以使之匹配某画作的风格。这个训练出的网络有两重目的：保持原有图像的内容，同时匹配绘画的视觉风格。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这样得到的最终结果是：一旦在一张静态图像上花了几分钟后，就可以实时运行了（例如，将风格迁移应用于实时视频）。但是，实现实时风格迁移的速度提升是有代价的——一个给定的风格迁移网络只能固定于一种单一画作的风格，失去了一些原来的算法的灵活性，因为原来的算法并不固定于任何一种风格。这意味着：如果要开发一个能够建模 100 幅画的风格迁移系统，就需要训练和存储 100 个单独的风格迁移网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;我们的贡献：学习并结合多种风格&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们开始于对印象派时期的许多艺术家的观察，采用类似的笔触和调色板。此外，说到莫奈的画，视觉上更是相似。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9ud9Ce5mvD8vXXnwE6wtH7PdZj9hUXXlLGeXmpBXib5UGYLBmn2g9Zp3YzicZsbVAED8Uh7U4MiczhA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Poppy Field (左) 和 Impression, Sunrise (右) by Claude Monet&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们在机器学习系统的训练中用到了这一观察。也就是，我们训练一个能够捕捉且概括众多莫奈作品、或者其他流派不同画家作品的单个系统。产生的 &lt;span&gt;pastiche &lt;/span&gt;足以媲美之前工作产生的画，同时源自同样的风格迁移网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9ud9Ce5mvD8vXXnwE6wtH7QPanSDuj6JxCcrbibLRMNia7WsTGyqqXY98ia6AXR7GSOAJosZ1bRo10Q/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;由我们的单网络产生的 &lt;span&gt;pastiche &lt;/span&gt;实在 32 个不同的风格上训练得到的。这些画质量上等同于由单风格网络创造的作品。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们开发的该技术简单易部署，也不需要密集的存储。此外，我们的网络在数个艺术风格上进行训练，允许实时结合多个绘画风格，就像文中视频展示的那样。下面就是 4 种风格按不同比例结合的成果：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9ud9Ce5mvD8vXXnwE6wtH70qy0tMKiafOoGEZLT8nnPDAqibhKwDNuGmFsrSFKddeyhtCaDrHibFB8g/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不像之前快速迁移风格的方法，我们认为这种同时建模多种风格的方法开启了一种让用户与风格迁移算法交互的新方式，不仅是允许基于多个风格的混合进行自由创造，而是这个过程是实时的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;关于该算法的细节和运行该模型的 TensorFlow 源代码将在未来发布。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;论文：A Learned Representation For Artistic Style&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：绘画风格的多样性对构建图像而言代表丰富的视觉词汇。如果不是通常画像，学习或捕捉这些视觉词汇的程度表达出了我们对更高层次绘画的理解。在此研究中，我们调查了如何构建单个、可延展深度网络，能够贪婪的捕捉不同派别的艺术风格。我们证明这样的网络能够通过将一种绘画降低到到嵌入空间的一个点，从而概括不同的艺术风格。重要的是，该模型允许用户通过任意结合单个绘画的风格来探索新的绘画风格。我们希望这项研究能够为迈向建立丰富的绘画模型提供帮助，也希望在艺术风格表征学习的建构上提供一个窗口。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;References&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[1] Efros, Alexei A., and William T. Freeman. Image quilting for texture synthesis and transfer (2001).&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[2] Hertzmann, Aaron, Charles E. Jacobs, Nuria Oliver, Brian Curless, and David H. Salesin. Image analogies (2001).&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[3] Gatys, Leon A., Alexander S. Ecker, and Matthias Bethge. A Neural Algorithm of Artistic Style (2015).&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[4] Ulyanov, Dmitry, Vadim Lebedev, Andrea Vedaldi, and Victor Lempitsky. Texture Networks: Feed-forward Synthesis of Textures and Stylized Images (2016).&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[5] Johnson, Justin, Alexandre Alahi, and Li Fei-Fei. Perceptual Losses for Real-Time Style Transfer and Super-Resolution (2016).&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 27 Oct 2016 12:10:56 +0800</pubDate>
    </item>
    <item>
      <title>深度 | NVIDIA CEO黄仁勋解读智能工业革命：基于GPU的深度学习大爆炸</title>
      <link>http://www.iwgc.cn/link/3247858</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Nvidia&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：黄仁勋&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：武竞、王旭雯、杜夏德&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;随着深度学习的兴起，支持大规模并行计算的 GPU 已经成为人工智能发展的重要硬件基础。作为 GPU 行业的领军者，NVIDIA 公司最近以来一直在推动应用于机器学习的 GPU 技术的发展和创新。近日，NVIDIA 联合创始人兼 CEO 黄仁勋（Jen-Hsun Huang）在 NVIDIA 博客上发表了一篇题为The Intelligent Industrial Revolution（智能工业革命）的文章，解读了自己在最近的 GPU Technology Conference（GTC）会议上的所讲所学所见以及对计算发展的未来的看法。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;过去六个星期，NVIDIA 搞了一个世界巡回的开发者大会。GPU 技术大会（GTC）于 2009 年开始，旨在促进使用大规模并行处理的 GPU 来开发高性能计算的新方法。GTC 已经成为 GPU 深度学习的中心——这个新的计算模型引发了现代人工智能的大爆炸。人工智能正在像野火一样蔓延。GPU 深度学习开发者的数量在短短两年内就跃升了 25 倍。已经有大约 1500 个人工智能创业公司出现。这种爆炸式增长刺激了世界各地对 GTC 大会的需求。到目前为止，我们已经在北京、台北、阿姆斯特丹、东京、首尔和墨尔本举办过活动。华盛顿定于本周举办大会，孟买定在下个月举办。我参加了其中 4 场 GTC 大会的开幕式。人工智能是下一个计算浪潮，给一个又一个行业带来了革命，关于它，下面是我在大会上的所讲所学，以及我对不久未来看法的总结。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9ud9Ce5mvD8vXXnwE6wtH7LrG8TV2htQzm8ay0O3Xh2nvlwFty8Blic9TvhbKxSicqPQO7qhMvbgBA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;计算的新时代&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;由人工智能计算机驱动的智能机器可以学习、推理和与人互动已经不再是科学幻想的场景。今天，由人工智能驱动的自动驾驶汽车可以找到路，并曲折地穿过夜间的乡村道路。人工智能机器人可以通过反复尝试来学习运动技能。这是一个不同寻常的时代。在我 30 年的计算机行业生涯中，没有什么比这个有更多潜力、更有趣的了。人工智能的时代已经开始。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;计算机行业推动了大规模的工业和社会变革。随着计算机行业的发展，成立了新公司，创造出新产品，我们的生活因此而改变。回顾过去几轮计算浪潮，每一个背后都有革命性的计算模型来支撑，在当时，这个计算模型架构扩展了计算能力和计算范围。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 1995 年，PC-Internet 时代是由低成本微处理器（CPU），标准操作系统（Windows 95）和一个新的信息门户（Yahoo!）的集成引发的。PC-Internet 时代给大约十亿人带来了计算能力，实现了微软将「计算机放在每一个桌子和每个家庭」的愿景。十年后，iPhone 在我们的口袋里放了一个「互联网通信」设备。加上亚马逊 AWS 的推出，Mobile-Cloud 时代诞生了。大量应用程序走进我们的日常生活，有约 30 亿人因此享受移动计算提供的自由。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今天，我们站在下一个时代的开端，人工智能计算时代，被一个新的计算模型——GPU 深度学习——点燃。这种新模型——其中深层神经网络被训练以识别大数据中的模式——已被证明能「不可理解的」高效解决计算机科学中的一些最复杂的问题。在这个时代，软件可以自己编写，机器可以自己学习。不久之后，数以亿计的设备将注入智能。人工智能将彻底改变每个行业。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;GPU 深度学习「大爆炸」&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为什么是现在？我在早前的博文（「Accelerating AI with GPUs: A New Computing Model」）中提到，2012 年将是人工智能标志性的一年。多伦多大学的 Alex Krizhevsky 创建了一个深度神经网络，能够从一百万个样本中自动学习识别图像。在 NVIDIA GTX 580 GPU 上仅仅用了几天的训练，「AlexNet」就赢得了那一年的 ImageNet 比赛，打败了所有人类专家磨炼了几十年的算法。同一年，在意识到更大的网络、更大的大脑、更多的学习之后，斯坦福大学的吴恩达和英伟达研究院（NVIDIA Research）组队开发使用大型 GPU 计算系统来开发训练神经网络的方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9ud9Ce5mvD8vXXnwE6wtH7kZ99Bw0Wgk7icWjaribVOm1LPWAE4GibHhkgClRubCUj3wqeicwfFb5X6A/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;世界开始关注到这一点了。各个地方的人工智能研究者都转向了 GPU 深度学习。百度、谷歌、Facebook 和微软最先用它来进行模式识别。到了 2015 年，他们开始实现「超人类」的结果——一台计算机识别图像的能力比人类还要高。在语音识别领域，微软研究院（Microsoft Research）使用 GPU 深度学习使对话语音达到了和人类相同的水准，实现了历史性的里程碑。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图像识别和语音识别——GPU 深度学习已经为机器学习、感知、推理和解决问题提供了基础。GPU 的使用从模拟人类想象引擎开始，魔术般地跳跃到视频游戏和好莱坞电影中惊人的虚拟世界里。现在，英伟达的 GPU 能够运行深度学习算法，模拟人类智能，作为计算机、机器人和自动驾驶汽车的大脑，感知并理解这个世界。就像人类想象和智能是连在一起的一样，计算机图形和人工智能在我们的架构中也是一同运作的。人脑有两种模式，GPU 也有两种模式。这或许就解释了为什么英伟达的 GPU 被广泛用于深度学习，英伟达也逐渐成为大家熟知的「人工智能计算公司」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;一种用于新计算模型的端到端平台&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;作为一个新的计算模型，GPU 深度学习正在改变软件的开发过程和运行方式。过去，软件工程师创造了程序并精心编码算法。现在算法能从成堆的现实世界的例子学习，软件可以自己编写出来。编程实际上是编码指令，深度学习就是创建和训练神经网络。这个网络可以被部署到数据中心，通过学习大量新数据来执行推断（infer）、预测和分类工作。网络还能被部署到如相机、汽车和机器人之类的智能设备中来理解世界。有了新的经验后，新数据会被收集来进一步训练和精炼这个网络。从数十亿的设备中学习能让网络上的设备变得更加智能。神经网络会收益于 GPU 处理和大型网络效应的指数增长。也就是说，它们会以一种比摩尔定律更加快的方式变得更加聪明。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9ud9Ce5mvD8vXXnwE6wtH7HnbI7iaQmwJYeicnFEXRYBA3EdFib1FhbMC6Fgpxic6czEEe3lkJsyCoibw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;旧有的计算模型是「指令处理」密集型的，而这种新的计算模型须要海量的「数据处理」。为了推进人工智能的全面进展，我们正在建立一个端到端的人工智能计算平台，一个能够跨越训练、接口以及数十亿设备的架构很快就会出现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们从训练开始。我们的新 Pascal GPU，投入 20 亿美元，动用了数千名工程师，花了三年时间才弄好。它是第一台用于深度学习的经过优化的 GPU。Pascal 训练的网络比 Kepler GPU（Alex Krizhevsky 在这篇论文中使用的 [1]）训练的网络要大 65 倍，而且速度更快。一个单一的配备 8 个 Pascal GPU 与 NVLink 连接的计算机，创造了有史以来吞吐量最高的互连，训练网络的速度比传统的服务器快 250 倍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9ud9Ce5mvD8vXXnwE6wtH7fsM8jAsFfVwjY2b3bz9RyN7uhXTfgU4ugUnJjkjoWibzAsD9p7mwDYA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;很快，每天数百亿个来自互联网的请求（queries）都会需要人工智能，也就意味着，每个请求将需要超过数十亿词数学运算。云服务上的总装载量需要足够大以保证实时响应。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有了更快的数据中心推理性能，我们发布了 Tesla P40 and P4 GPUs。P40 将数据中心的推理吞吐量加速了 40 倍。P4 仅需要 50 瓦的电源，设计用于加速 1U OCP 服务器，典型的超大规模数据中心。软件是英伟达深度学习平台中重要组成部分。在训练上，我们有 CUDA 和 cuDNN。在推理（inference）上，我们发布了 TensorRT，一个优化的推理引擎。TensorRT 通过在一个层内和跨层融合操作，修剪低贡献权重，降低 FP16 或 INT8 的精确度，以及其他多个技术，在不影响精度的情况下，提升了性能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;终有一天，数十亿个智能设备会利用深度学习来实现看似智能的任务。无人机会自动导航飞到仓库，寻找并拿到特定的物品。便携的医药器械会利用人工智能当场检测血液样本。智能相机能够学会仅在我们关心的情景中提醒我们。我们创造了高效能的人工智能超级计算机，Jetson TX1，应用到那些智能物联网设备中。只有信用卡大小的模块，Jetson TX1 可以仅用 10 瓦的电源，达到 1TeraFLOP FP16 的工作性能。它和我们最强大的 GPU 拥有相同的构架，并且可以运行所有相同的软件。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;简单地说，我们提供了一个端到端的人工智能计算平台——从 GPU 到深度学习软件和算法，从训练系统到车内的人工智能计算机，从云到数据中心到 PC 到机器人。NVIDIA 的人工智能计算平台无处不在。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;适用于所有领域的人工智能计算&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们端到端的平台是保证每个领域都能接入人工智能的第一步。NVIDIA GPU 深度学习下的全球生态系统正在快速扩张。突破性的成果引发了一场将人工智能运用到消费者网络服务的竞争——搜索、识别、推荐、翻译以及更多。云端服务供应商，从阿里巴巴、亚马逊，到 IBM 和微软，让大大小小的公司都用上了 NVIDIA GPU 深度学习平台。全球最大的企业技术公司已经在基于英伟达的 GPU 配置服务器。很高兴能够在我们的 GTC 巡回中强调我们在重要领域中的战略：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能交通：交通是一个人工智能可以改变的，价值 10 万亿美元的产业。无人驾驶车辆可以减少事故，提升卡车和出租车的效率，使得新的移动服务成为可能。我们宣布百度和 TomTom 均选择 NVIDIA DRIVE PX2 用于无人驾驶车辆。对它们每家公司，我们都会建立一个包含高清地图，人工智能算法和人工智能超级计算机的「云端-车」的平台。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;驾驶是我们学习获得的第二天性，但我们目前还不能让计算机学会开车。无人驾驶要求每个方面都能做到人工智能——感知环境，合理地决定环境的状态，计划行动的最佳过程。同时，也持续学习以提升对于这个多样化世界的认识。大范围的无人驾驶需要一个开放的，可升级的构架——从高速路上自动巡航，到自主驾驶到目的地，到没有司机的全自动公共汽车。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9ud9Ce5mvD8vXXnwE6wtH7PccPIbgHiacVlX6cxC3U0ciaBpdc1lqShb5bfhHF3kMlIpCqw2LjLrbA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;NVIDIA DRIVE PX2 是一个用于自动驾驶的可升级架构，包含了整个范围的人工智能技术。在 GTC，我们发布了 DRIVE PX 2 AutoCruise 专为高速公路上自动驾驶设计，带有持续定位和地图。我们还发布了 DriveWorks Alpha 1，我们无人驾驶车上的操作系统几乎涵盖了无人驾驶的所有方面——侦查，定位，计划路线，行动。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们将所有的功能集中在我们的无人驾驶车 NVIDIA BB8 上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;NVIDIA 着重在视觉处理的交叉点的创新，以及人工智能和高性能的计算——一个在智能和自主的机器核心的特殊结合。这是第一次，我们有了让无人驾驶车辆和自主机器人成为可能的人工智能算法。但它们需要一个实时的，有成本效益的计算平台。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 GTC，我们介绍了 Xavier。Xavier 是我们有史以来做过的最有雄心的单片机，是世界第一个人工智能超级计算机芯片。Xavier 有 7 亿个晶体管——比起最先进的服务器级别 CPU 更复杂。但神奇的是，Xavier 和今年早些时候在 CES 发布的 DRIVE PX 2 有相同的马力——每秒钟 20 万亿次深度学习的操作——仅用 20 瓦的电源。像 Forbesnoted 一样，我们加倍生产了带有 Xavier 的无人驾驶车。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;人工智能企业&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：IBM，一个在认知计算领域看到价值二十亿美元机会的公司，发布了新 POWER8 和 NVIDIA Tesla P100 服务器，它们均是为将人工智能带入企业而设计的。在软件上，SAP 声称他们已经收到了了 2 台第一批的 NVIDIA DGX-1 超级计算机，并正在为 190 个国家的 320，000 个消费者建立机器学习的企业解决方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;人工智能城市&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：到了 2020 年，世界上将会有 10 亿台相机。Hikvision 是全世界检测系统的领导者，它正在运用人工智能让我们的城市更加安全。它用 DGX-1 进行网络训练，现已在 16 Jetson TX1 中央处理器上建立了一个突破性的服务器，叫做「Blade」。Blade 只需要基于 21 个 CPU 的服务器的 1/20 的空间和 1／10 的能量就可以达到相同的性能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;人工智能工厂&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：在全球范围内已有 20 亿左右的工业机器人。日本是机器人创新的中心。在 GTC，我们宣布 FANUC，一个日本的工业机器人巨头，将会在 NVIDIA 人工智能平台上建造一个端到端的未来工厂。它的深度神经网络将由 NVIDIA GPU 来训练，GPU 驱动下的 FANUC Fog 单元将控制一群机器人，让他们能够共同学习。每个机器人都会植入 GPU，使之成为实时人工智能。麻省理工技术评论对他的故事这么写到：「日本的机器人巨头为它的武器加上了大脑」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;创业公司的爆发是人工智能横扫各个产业的又一指示。Fortune 最近写到，深度学习会「改变美国的大公司」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9ud9Ce5mvD8vXXnwE6wtH7dR8B1mKFedIv4S8msicYlA4b83t41NCYSALiaSsvMlDd6Fprxv7I880g/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能可以提前解决我们能力范围外的问题。从现实生活中的数据，计算机可以学会认识那些对于人工编写的软件甚至是人来说太复杂、太巨大或太微小的图案。通过 GPU 深度学习，这个计算机模型现在已经被熟练应用在解决世界上最大的产业的问题上。无人驾驶汽车将会改变 10 万亿美元的交通运输业。在医疗保健上，医生可以使用人工智能帮助你更早发现疾病、或是了解人类基因组的奥秘去治疗癌症、又或是从大量的药物数据和研究中学习，向你建议最好的治疗方法。人工智能会开创第四次工业革命——继蒸汽机、大规模制造和自动化之后——智能机器人会引领巨大的生产力提高的新浪潮，为大规模客户定制化提供了可能。人工智能将会触及每一个人。人工智能的时代已经到来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 27 Oct 2016 12:10:56 +0800</pubDate>
    </item>
    <item>
      <title>业界 | Yoshua Bengio创立孵化器Element AI：助力深度学习学生创业</title>
      <link>http://www.iwgc.cn/link/3247860</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自连线&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：CADE METZ&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李泽南&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9ud9Ce5mvD8vXXnwE6wtH7lH1FicKPW2dTWRibsJWGqayUUDkD5b8rEfV549WuaFWjHk2EibswSWyHw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Y&lt;/span&gt;&lt;span&gt;oshua Bengio，深度学习背后最重要的推动者之一，刚刚宣布在蒙特利尔创立了一个硅谷式的创业孵化器，他希望以此发展这种最具影响力的人工智能形式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这家孵化器名为 Element AI，旨在帮助来自蒙特利尔大学和 McGill 大学的创业者们在人工智能领域施展拳脚。Bengio 目前任蒙特利尔大学计算机和运筹学院教授，他表示这一努力是在蒙特利尔开发人工智能生态的一部分。Bengio 希望他的努力能在硅谷之外开创一个科技新领域，他认为这座城市已聚集了全世界深度学习领域最为尖端的研究者，其研究成果已经在谷歌、Facebook 和微软这样大公司的产品中得到了广泛应用。「Element AI 将帮助创业者们在这块神奇的土地开展事业，他们将获得我和我的专家团队的帮助，我们将指引这些新生企业进入正确的轨道。」Bengio 说道。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;根据 Bengio 介绍，目前约有 100 名研究人员在蒙特利尔大学研究深度学习，同时约有 50 名科学家正在 McGill 大学做着类似的工作。这样的数量是否首屈一指还有待商榷——欧洲也是此类研究的温床——但蒙特利尔在深度学习的重要地位毋庸置疑。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;上周，微软研究人员发布了识别准确率超过人类的英文语音识别系统。当从电话语音中转录音频时，系统出现的误差少于人类专业速记员。这一成果表明深度学习在过去五年有了长足进步。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过使用深度神经网络，进行大量数据学习的硬件和软件网络，谷歌，IBM 和百度这样的科技巨头已将语音识别发展到近似人类的水平。而类似的技术让这些公司和他们的竞争对手们已经建立起了面部识别和图像特征识别系统。深度学习正在迅速地重塑一切，从机器翻译到谷歌搜索引擎背后，无不存在它的身影。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;深度学习起源于一个不大的学术圈子，其中的大部分研究者现在已经成为各家科技公司的骨干。该流派的创始人之一 Geoff Hinton 现在正为谷歌工作。另一位先驱，Yann LeCun，在 Facebook 领导人工智能实验室。近年来，硅谷的巨头们收购了一家又一家深度学习初创企业。其中最为引人注目的就是谷歌收购的 DeepMind，这是一家来自伦敦的科技公司，今年已经使用深度学习等技术攻克了古老而又复杂的围棋。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Hinton，LeCun 和 Bengio 是深度学习的三驾马车，他们自 20 世纪 80 年代到本世纪初孜孜不倦地探索这一领域，尽管在一开始，很少有人意识到这种技术蕴含的潜力。在深度学习广为人们所知以后，Bengio 并没有随前两人进入科技公司，他一直专注于学术。微软人工智能研究者黄学东称他为「一位伟大的教育家」，这也是深度学习界为他打上的绰号。Bengio 现在可以利用他在 IBM 顾问身份，和刚刚启动的 Element AI 架起一道桥梁，让深度学习的研究成果通向商用领域。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这一举措的重要性毋庸置疑。如今，深度学习领域的研究人员仍然稀少，硅谷巨头们正在争抢这些人才，激烈程度远超其他领域的工程师。去年，这一竞争达到了巅峰，OpenAI，一家由艾隆·马斯克资助的初创公司，从谷歌和 Facebook 挖走了多名人工智能研究骨干。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Bengio 的孵化器对于研究者而言同样重要——它有点类似于 YC——因为它可以消除人工智能专家对需求和产品的距离。「在深度学习领域，有大量的研究人员可以熟练地构建强大的算法，但却并不总是知道如何处理真实世界的各种问题，」深度学习初创企业 Skymind 创始人 Chris Nicholson 说道，「这些天才需要获得一点点指导。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于那些获得了正确指导的研究者，他们拥有技术的价值对于市场而言不可估量。深度学习目前只能应用于部分大型公司。而且只有相当数量的研究者参与其中。我们也许很快就将看到孵化器带来的新风向。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;span&gt;	&lt;/span&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 27 Oct 2016 12:10:56 +0800</pubDate>
    </item>
    <item>
      <title>前沿 | 机器学习破解基因密码：斯坦福大学开发出鉴定致病性基因突变的新工具（附论文）</title>
      <link>http://www.iwgc.cn/link/3247861</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自斯坦福&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Erin Digitale&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：曹瑞、李泽南&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2012 年，Shayla Haddock 的医生对她所患的一种罕见的遗传疾病进行了测试，但是他们没办法确诊。畸形足、身材矮小、不正常的面部特征和先天性耳聋等症状将伴随她一生——这使得她的医生怀疑这是由基因突变造成的。但是对于像 Shayla 一样的孩子来说，在 30 亿 DNA 碱基对当中找到致病基因是非常困难的。在基因测序之后，几乎每一个病例都需要一位训练有素的基因学家花 20-40 小时来分析。并且大约有 75% 的患者在第一次尝试中没办法被确诊。&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9ud9Ce5mvD8vXXnwE6wtH7mKRzBgq7K2OrPmqyNVkG5plxZliars2dibiadV3g4oon6jsH6n8GmGHtQ/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;斯坦福的一些计算机科学家最终解决了 Shayla 的困境，他们设计了一种自动化的方式，将患者的症状和变异基因与已有的遗传疾病数据库中的信息作对比。2016 年初，他们发现 Shalya 所患的疾病早些年在医学文献当中报道过。而在两周前，Shayla 的医生仍然不能告诉她的家人病因到底为何。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在，这个斯坦福大学的科研团队，在计算机科学家、基因学家、哲学博士 Gill Bejerano 的带领下，在病情诊断方面的发展又进了一步。他们研制出了一种更加精细的工具，可以自动评估遗传密码中单个字母的错误。这种新工具叫做 M-CAP，他们的研究论文已发布在今天的《Nature Genetics》上，这个团队使用了一种机器学习的算法，根据是否有可能致病性基因突变进行分类。这项成果的全部细节已公布在网上，以供全世界的遗传学研究人员使用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「纵观人类基因中的各种可怕变异，有数以万计的变化可能会导致严重的儿童早期疾病。而这些变异和与健康人基因当中的变体相比是非常不一样的。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他解释道，最基本的问题是，每个人的基因密码中合成蛋白质的部分都有 1 万个小光点或者说是变体，这些 DNA 中的每一个碱基对都与正常的人类基因序列不同。几乎所有的这些光电都是无害的。但是在那些从出生就有一些难以解释的症状的孩子身上，我们有足够的理由相信是由于一个或者两个基因上的变化才引起了他们的疾病。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在他们的评估当中，遗传学家们试图将一个到两个最有可能导致疾病的基因变体归零。比如说，他们会忽略那些在普通人群中非常普遍的基因变体，因为我们相信这些罕见的疾病都是由一些罕见的基因突变引起的。他们已经人工将需要评估的基因变异列表减少到每位患者 300 种左右。M-CAP 让这个列表更加精简，大约每位患者 120 种基因变体，Bejerano 的团队希望随着遗传疾病研究的推进，这个列表可以更加的更精确。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;非常重要的一点是，M-CAP 要比以往自动分类基因变体的方式更加精确。传统的方式会将四分之一到三分之一的致病基因变体错误的标记为无害。M-CAP 出现这种错误的几率只有 5%。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Bejerano 说：「我们挑战是要尽力将这个基因变体的列表减少到最短，并不仅仅包括哪些罕见、没有潜在功能的基因，还有所有存在危险性的基因。」「但更重要的是，我们不能告诉患者致病的基因突变是良性的。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;论文：M-CAP精确消除临床外显子组中大量意义未定的基因变体&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：变体致病性分类器例如 SIFT、PolyPhen-2、CADD 和 MetaLR 通过优先确认良性突变，有助于在典型患者基因组中解释数百个罕见的错义突变（missense variants）。目前广泛使用的分类器对于已知的致病突变有 26% 至 38% 的错误率，这些方法如果在临床中应用可能会导致误诊。我们开发了 M-CAP，一种临床致病性分类器，它在所有方面优于目前的方法，同时可以在典型基因组中以 95% 灵敏度正确排除 60% 的罕见的、不确定的错义突变。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 27 Oct 2016 12:10:56 +0800</pubDate>
    </item>
    <item>
      <title>重磅 | 亿万词汇构建神经网络，Facebook提出语言模型训练新算法</title>
      <link>http://www.iwgc.cn/link/3231915</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Facebook Research&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Edouard Grave、Justin Chiu、Armand Joulin&amp;nbsp;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：杜夏德、武竞&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Facebook 人工智能研究（FAIR）设计出一种新式的 softmax 函数逼近，专用于 GPU，帮助其在语言模型的基础上通过巨量词汇来有效训练神经网络。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;由于在语音识别、机器翻译或语言建模等领域的优异表现，用于序列预测的神经网络最近重新获得关注。然而这些模型都需要巨量的计算，这反而限制了它们的应用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在语言建模领域，最近的研究进展用到了海量的大型模型，这些大型模型只能在大型 GPU 集群上训练，并且一次需要几周时间。这些处理密集型工作很棒，也有利于探索大型计算基础设备，但这些计算设备对于学术界来说通常十分昂贵，投入生产也不实际，以至于限制了研究的速度、再生产能力和结果的可用性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;意识到这种计算上的瓶颈，Facebook 人工智能研究（FAIR）设计出一种新式的 softmax 函数逼近，专用于 GPUs，帮助其在语言模型的基础上通过巨量词汇来有效训练神经网络。我们的方法叫做自适应 softmax（adaptive softmax），利用不平衡词分布形成簇（cluster），这种簇能明确地减少对计算复杂度的期望，从而规避对词汇量的线性依赖。这种方法通过利用流行架构的特殊性和矩阵-矩阵向量运算（matrix-matrix vector operations）进一步减少了训练和测试时的计算成本。这使得它特别适合于 GPU，而以往的方法，如分层 softmax，NCE 和重要性采样，都是为标准的 CPU 设计的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;FAIR 也开发并正在开源一个名为 torch-rnnlib 的库，这个库允许研究者设计出新的循环模型并在 GPU 上以最小的代价测试这些原型（prototypes）。它也允许通过绑定 torch.cudnn 无缝对接快速基线。几个标准循环网络，如 RNN、LSTM 和 GRU 都已经被部署进来，下面我们将展示如何利用这个库来设计一个新的循环网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些工具和技术后来被一起用来应对标准基准，如 Euro Parl 和 One Billion word，这些都是因需要使用巨大的词汇量而复杂的训练环境，让我们无法在 GPU 上拟合一个大模型和 full softmax。结果显示我们在单一的 GPU 上每秒能处理 12500 个单词，通过标准逼近，大大提升了效率，减少了从试验到结果的时间，同时得到的精确度接近于 full softmax 的精确度。这就能让学界和业界的工程师与研究者都能在短时间内在资源有限的情况下训练出最好的模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;利用 torch-rnnlib 建立一个循环模型&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;循环模型的定义有很多，我遵循的是这一条：循环网络随着离散时间对变量序列建模。它遵循马尔可夫的属性，其未来的状态只取决于它的现状。最简单的循环模型是 Elman 的循环模型。根据当下的输入变量 x[t] 以及之前的状态，在每个时间步骤 t，就会输出一个 y[t]。更确切的说，Elman 的循环模型可以通过下面的等式来定义：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;h[t] = f(R * h[t-1] + A * x[t]),&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;y[t] = B * h[t]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其中，h 代表网络（隐藏的）内在的状态，f 是 sigmoid 函数。Elman 之后就有人提出了更复杂的循环模型，如 LSTM、GRU 或者 SCRNN。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;什么是语言模型？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;语言建模的目的是在一个给定词典中的一个词序列上学习一个概率分布。该联合分布被定义为给定状态下的词的条件分布的一个乘积。确切地说，一个 T 词序列 w[1],...,w[T] 的概率被给定为的 P(w[1],..., w[T])) = P(w[T]|w[T-1],..., w[1])...P(w[1]).&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个问题通常由基于计数统计的非参数模型解决（详见 Goodman, 2001）。最近，基于循环神经网络的参数模型在语言建模上才流行起来（例如，Jozefowicz 等人, 2016，obtained state-of-the-art performance on the 1B word dataset）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;如何用 Torch-rnnlib 建立一个标准的模型&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们给出了用于建构带有循环连接的三个不同的 API：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1.nn.{RNN, LSTM, GRU} 接口可以用来建构在所有层都带有相同数量隐藏单元的循环网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWib9ezqHLusWxfqaFozVbpOR2AFKnxJYlaWAJmZCKEOCHQfc884T05Wsr0VGyrVCcwaN26DBbZh2xw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2.rnnlib.recurrentnetwork 的接口能用于构建任意形状的循环网络。上一个和这个接口都为你考虑到了节省隐藏状态。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWib9ezqHLusWxfqaFozVbpORFG3iaa76HYUibpohBz3GoOhAewicg2lwvpRFFxRUePf8SmYHYeAiaECQMg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3.nn. SequenceTable 接口能用来将计算像一个『scan』一样链接起来。nn. RecurrentTable 构建器（constructor）仅仅是一个轻量级的封装，能随着时间为你克隆循环模块。然而，要注意的是这是最低层级的接口，你还需要 rnnlib.setupRecurrent(model, initializationfunctions) 来设定循环隐藏状态行为。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWib9ezqHLusWxfqaFozVbpORvwF1DZicDGhjbfRCQHkk9QMvfNv9sW5IlmEy7ZvPj2xbbhxPjDWbQNA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;建立你自己的循环网络&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你也可以通过定义一个行为像 cell 那样的函数来创建你自己模型，以及一个类似于这个 cell 状态的初始化函数。&lt;/span&gt;&lt;span&gt;在 rnnlib.cell 中有预定义的 cell，如 LSTM、RNN、和 GRN。下面来看看如何一步步建立一个 RNN：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWib9ezqHLusWxfqaFozVbpORNqibQXqHuKibllnNKP6yC2Qhn8HobjVV6A002ZZdbnamduP9bSdxwyfQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;在 GPU 上训练它&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;既然 torch-rnnlib 连着 nn 模块接口，仅需要在模型上调取：cuda（）就能将它拉进 GPU。rnnlib 的目的是允许用户自由创建新 cell，或者使用快速基线。这样就 OK 了，如果你在上一节中使用第一或第二个 API 来构建循环网络，就可以轻松使用 cudnn 来大大加速你的网络。对于 nn.{RNN, LSTM, GRU} 接口，仅需要用 usecudnn=true 就能调取这个建构器（constructor）：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWib9ezqHLusWxfqaFozVbpOR09L1hvicAic8mGCQqHZS8G8mibibofGuLUIJOQsicK9c9dXbop0WcyYm5VQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于第二个 API，仅需要将 rnnlib.Recurrent 替换成 rnnlib.makeCudnnRecurrent 并将 cell 函数改为 cudnnAPI 中已有的一个 cell 串。例如：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWib9ezqHLusWxfqaFozVbpORm0gfOLXuqqp5ITooun7ibTCRuFjN0YICNNkjHma2KvZX0qF39qQAN7Q/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最终的结果通常是，模型的循环部分至少能提速两倍。要注意的是，不是整个模型提速两倍，尤其是如果大部分计算不是在循环部分中时。例如，如果你的模型中有一个 softmax，比循环部分需要更多的计算，那最终速度可能只提升 1.3 倍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWib9ezqHLusWxfqaFozVbpORzX2KNAT3z4aXia2HGIVw4bEPibZxAMK8OakbhjUc6SJ1sicsicNqia7icmUA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Adaptive-Softmax：为 GPU 定制的 softmax 近似模型&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当处理大输出空间（如语言模型）时，分类器（classifier）可能是模型的计算瓶颈。过去已经提出了许多解决方案（分层 softmax（hierarchical softmax），噪声对比估计（noise contrastive estimation），差分 softmax（differentiated softmax）），但是它们通常被设计用于标准的 CPU，并且很少充分利用 GPU 的特性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们研究出了一种新的近似方法，叫做自适应 softmax（adaptive softmax）：一个使其计算载荷量（computational budget）适应数据分布的 softmax。它通过更快地访问最常用的类（class），为它们提供更多的资源，来达到优良的近似效果和快速运行时间之间的平衡。更准确地说，它学习了一个 k-通道（k-way）的层次 softmax（hierarchical softmax），它考虑了 GPU 的架构以有效地分配计算。这种计算资源的分配可以使用一个简单的动态规划算法来精确求解。几个技巧可以进一步处理分类器的计算负载问题：我们使用分枝少的树（shallow tree）来避免顺序计算（sequential computation），并且我们为每个 GPU 集群（cluster）确定类（class）的最小值，以避免浪费 GPU 的并行计算能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;正如表格 1 中显示的，自适应 softmax 几乎可以与完整 softmax（full softmax）的结果相媲美，并且自适应 softmax 速度更快。它也优于 GPU 运行的其他近似模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWib9ezqHLusWxfqaFozVbpORz9IejxHa3nrWLqjv2vtK74ziaBHgyx2aibpibaqQHXYlDWax9066xvyaQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;表格 1. 使用 Text8 的模型结果比较。ppl 值越小越好。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWib9ezqHLusWxfqaFozVbpORwesiajeX3PA4dRwka5STtHxEX7Fic4iaYFlg06HibmnuE7DrSEXBWwtLJg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图. 语言模型在不同 softmax 近似模型上的收敛效果。它建立在 LSTM 模型之上。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;10 亿单词数据集在单个 GPU 上几天内达到了值为 45 的困惑度值&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除自适应 softmax（adatpive softmax）外，在技术细节方面，我们使用相对标准的设置：对于小模型，我们使用层数为 1、2048 个神经元单位的的 LSTM；对于大模型，我们使用层数为 2、2048 个神经元单位的 LSTM。我们使用 L2 正则化（regularization）的权重和 Adagrad 来训练模型。我们使用大小为 128 的批处理（batch），同时设置反向传播（back-propagation）窗口的大小为 20。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;关于自适应 softmax，我们使用 10 亿单词的训练数据集分布的最佳设置，即 4 个 GPU 集群（cluster），每用一个集群，数据的维数减少 4 倍（更多细节详见论文）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWib9ezqHLusWxfqaFozVbpOR4osX6tZgAj9CFTzROL7YAhqicbAShxhncWe3akXIdLOQwMJXFnibNCeA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;表格 2. 使用 10 亿数据集的模型 perplexity 值比较（值越小越好）。注意到 Jozefowicz 等人用了 32 个 GPU 训练，我们只用了 1 个 GPU。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;正如表格 2 中显示的，我们的小模型在几天内就达到了 43.9 的 perplexity 值。我们的大模型在 6 天内达到了 39.8 的 perplexity 值。目前最好的 perplexity 值（越小越好）是 30.0，由 Jozefowicz 等人在 2016 年达到。这个结果是他们用 3 周的时间，使用了 32 个 GPU 达到的。他们也声称使用 18 个 GPU 训练的更小模型，达到了数值为 44 的 perplexity 值。我们的小模型的速度为 180 毫秒/批，并在一个迭代（epoch）后（迭代时间大约为 14 小时）达到数值为 50 的 perplexity 值。不使用 cuDNN 加速库，小模型的速度为 230 毫秒/批，这比之前只慢了 30%。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 26 Oct 2016 11:51:05 +0800</pubDate>
    </item>
    <item>
      <title>重磅 | 微软开源Microsoft Cognitive Toolkit深度学习工具包，加入强化学习元素</title>
      <link>http://www.iwgc.cn/link/3231916</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Microsoft Blog&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Allison Linn&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀、李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;今天，微软宣布发布了 Microsoft Cognitive Toolkit 的更新版本，这是一个用于深度学习的系统，可用于加速 CPU 和 NVIDIA GPU 上的语音和图像识别以及搜索相关性等领域的发展。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;项目地址：https://github.com/microsoft/cntk&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个工具包之前被称为 CNTK，最早是由微软一些想要更快更高效地做自己的研究的计算机科学家开发的。它很快就超越了语音领域并演变成了一个产品，包括一些领先的国际家电制造商和微软的旗舰产品组（flagship product groups）在内的客户依靠它来执行各种各样的深度学习任务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;微软 Artificial Intelligence and Research 部门首席科学家和 Microsoft Cognitive Toolkit 的一位关键架构师 Frank Seide 说：「我们将其从一个研究工具变成了可以用在产品之中的东西。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWib9ezqHLusWxfqaFozVbpORUYUibYw9b58SIewX24IbTXaBXKICw6jwhmetNQ0Raa4f5Iw4jKic2esg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Frank Seide&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该工具包的最新版本现已通过一个开源证书发布到了 GitHub 上，其新增功能包括对 Python 和 C++ 编程语言的支持。研究者还可以使用这个新版本开发一种叫做强化学习（reinforcement learning）的人工智能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，该工具包的性能也优于之前的版本。它也比其它工具包更快，尤其是当需要跨多台机器运行大数据集时。为了开发消费者产品和专业产品，这种大规模部署对跨多个 GPU 的深度学习来说是必需的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这也是加速研究突破的关键。上周，&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719843&amp;amp;idx=1&amp;amp;sn=0c6387d422cf9765b9b10c178d160680&amp;amp;chksm=871b021db06c8b0b0b0447124c5c07818f53a17ba470305049af1d7d49806c87e07307a93811&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719843&amp;amp;idx=1&amp;amp;sn=0c6387d422cf9765b9b10c178d160680&amp;amp;chksm=871b021db06c8b0b0b0447124c5c07818f53a17ba470305049af1d7d49806c87e07307a93811&amp;amp;scene=21#wechat_redirect"&gt;微软 Artificial Intelligence and Research 宣布在识别对话上已经达到了人类的水平&lt;/a&gt;。这个团队将实现这一里程碑背后的巨大速度提升归功于了 Microsoft Cognitive Toolkit。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;开发了这个微软工具包的团队说其跨多服务器工作的能力是超过其它深度学习工具包的关键优势。当这个微软工具包被用于解决更大型的数据集时，可以实现更优的性能和准确度。Microsoft Cognitive Toolkit 有内置的算法来最小化这种计算的退化（degradation of computation）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「使用 Microsoft Cognitive Toolkit 的一个关键理由是其可以针对大型数据集跨多 GPU 和多机器进行有效地扩展，」微软合作伙伴工程经理 Chris Basoglu 说，他在该工具包的开发中扮演了一个关键的角色。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWib9ezqHLusWxfqaFozVbpOR7UFoq8bHqGHeAZiaSxLAo1Zcjbeg6CWZm1y6CyNvM2iaTTiamkDicQ6AHQ/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Chris Basoglu&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Microsoft Cognitive Toolkit 可以轻松处理从相对较小到非常非常大等各种规模的数据集，既可以在一台笔记本上运行，也可以运行在数据中心中的一系列计算机上。它可以运行在使用传统 CPU 或 GPU 的计算机上；GPU 以前主要的用途是处理对图形要求较高的视频游戏，后来人们发现可以用它来非常高效地运行深度学习所需的算法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「Microsoft Cognitive Toolkit 代表着微软和 NVIDIA 紧密合作以为深度学习社区带来进步，」NVIDIA 的 Accelerated Computing Group 总经理 Ian Buck 说，「和以前的版本相比，在扩展到一个 NVIDIA DGX-1™ 中的 8 个 Pascal GPU 之后，其性能几乎提升了两倍。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Microsoft Cognitive Toolkit 是为在多个 GPU 上运行而设计的，包括 Azure 的 GPU 产品，该产品目前还是预览版。该工具包已经经过了优化，可以最好地利用 NVIDIA 硬件和 Azure 产品的网络功能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;民主化人工智能及其工具&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当小型创业公司和大型科技企业都看到了深度学习的使用对语音理解和图像识别的可能性时，我们发布了该工具。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;广义上讲，深度学习是一种需要用到大量数据（被称为训练集）的人工智能技术，从而能教会计算机系统学会识别图像或声音等输入中的模式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;比如说，可以用一个包含了各种水果和蔬菜图片的训练集来训练一个深度学习系统，之后该系统能学会自己识别水果或蔬菜的图片。它获得的数据越多，它的表现就会越好；所以每次当它遇到一个新的、长相奇怪的茄子或扭曲的苹果时，它都可以调整自己的算法以使其变得更为准确。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWib9ezqHLusWxfqaFozVbpORwibnllspnDiaWMib5EhpZ00A2aictNwtBYm31gzGo3HNAdumHZaPMpuDJw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;在使用 Microsoft Cognitive Toolkit 训练语音声学模型中，随着应用更多的数据，它能收敛出更高的准确率。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这类的成果不只是研究的里程碑。由于深度学习的进步，加上计算马力的大幅度增长，我们如今有了像 Skype Translator 这样的消费者产品，能识别语音并提供实时语音翻译。还有 Cortana 数字化助手，能理解语音并帮助你做机票搜索和备忘约会这样的所有事。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;微软首席语音科学家黄学东说，「这就是使用 Microsoft Cognitive Toolkit 民主化人工智能的一个样例。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;更灵活的完成更复杂的任务&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Basoglu 说在他们第一次开发该工具箱的时候，他们发现许多开发者不能或不想写大量代码。所以他们创造出一个自定义系统，能让开发者更简单的配置深度学习系统，不需要额外的代码。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然而，随着该系统变得越来越流行，他们了解到一些开发者想将自己的 Python 或 C++ 代码与该工具箱的深度学习能力结合起来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他们也了解到一些研究人员想要使用该工具箱进行强化学习研究。强化学习是代理通过大量试错直接学习做某些事的一种研究领域，比如在房间中找到线路或合成句子。这类研究可能最终引向真正的人工智能，也就是系统能够自己做复杂的决策。新版本的工具箱就给了开发者做强化学习研究的能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尽管 Microsoft Cognitive Toolkit 最初由语音研究员开发，如今却能被用于多种目的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了给用户提供更好的结果，Bing relevance 团队使用它更好的发现搜索词条相关的隐藏的链接。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;例如，在用户输入「How do you make an apple pie?」的时候，带有深度学习的系统经过训练可自动明白用户在寻找菜谱，即使「recipe」一词并不在搜索词条内。没有这样的系统，这种规则只能手动编程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Bing relevance 团队的软件开发工程师 Clemens Marschner 说，他们团队和该工具箱的创造者们有着非常紧密的合作，从而更好的让开发者做除了语音之外的深度学习任务。对他们而言，所得的回报就是使用大规模的计算能力快速的获得结果。他说，「没有其他解决方案能让我们这么简单的将学习在 GPU 上扩展到大型数据上。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;微软也在不断使用 Microsoft Cognitive Toolkit 改进语音识别。语音服务部门的应用科学经理 Yifan Gong 说，他们已经使用该工具开发出了更准确的声学模型，应用到了包括 Windows 和 Skype Translator 在内的产品中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Gong 说他的团队依靠该工具开发新的深度学习架构，包括使用 LSTM 技术来为顾客导出更准确的结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 26 Oct 2016 11:51:05 +0800</pubDate>
    </item>
  </channel>
</rss>
