<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>机器之心</title>
    <link>http://www.iwgc.cn/list/670</link>
    <description>人与科技的美好关系</description>
    <item>
      <title>重磅 | 英伟达发布深度学习GPU训练系统DIGITS 5，自带图像分割与在线模型库</title>
      <link>http://www.iwgc.cn/link/3484418</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自 NVIDIA&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：杜夏德、王宇欣、李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;英伟达近日发布了 NVIDIA DIGIT 5。DIGIT 5 有许多新功能，本文将着重介绍下面两个：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 一个完全集成的分割工作流（segmentation workflow），允许创建图像分割数据库和将一个分割网络的输出可视化。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2.DIGITS 模型库（model store），一个公开的在线知识库，可下载网络描述和预先训练的模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这篇文章将探索图像分割的对象。将使用 DIGIT 5 来教一个神经网络识别和定位 SYNTHIA 数据库中合成图像里的汽车、路人、路标以及城市里的其它物体 ：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图 1 展示了本文大概要做的内容&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_gif/KmXPKA19gWibskqI8OpeUjInsDATicOtgdIYT6KwDTD4icm7jib1EeAHXicLZ6nUmkgmlwqKe0TRga5ZTt5IQJagg7w/0?wx_fmt=gif"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;em&gt;&lt;span&gt;图 1：使用 DIGITS 5.0 的采样可视化交替展示了输入图像、FCN Alexnet 预测的一个 overlay，FCN-8 预测和 ground truth 的 overlay。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;从图像分类到图像分割&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;假设你想要为自动驾驶汽车设计图像理解软件。偶然间你听说了 Alexnet、GoogleLeNet、VGG-16 以及其他图像分类神经网络架构，你或许会从这些网络开始做起。图像分类是计算机程序告诉你图像中的目标是狗的一种计算过程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一个图像分类模型输出的是离散概率分布：经过训练的模型识别的每一个分类都有一个 0 到 1 之间的一个数字，也就是一个概率。图 2 说明了在 DIGITS 中使用 Alexnet 进行的猫的图像分类样例。效果非常好：要知道 Alexnet 已经用 1000 个类别的不同对象训练过了，包括动物、乐器、蔬菜、汽车和其他物品，得到的信度高达 99%，一台机器能够正确地将图像中的主体分类为猫科。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibskqI8OpeUjInsDATicOtgdSEPvVlcAE1TGj6rnOle60XB3aWdK9kcpoyjKDic5mwjOQWQkrIKfY3g/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 2：PASCAL VOC 数据库中 Alexnet 分类的一只猫的图像&amp;nbsp;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是如果你给一只猫和一只狗的图像分类，会发生什么？常识会让你相信该神经网络会给这两只动物分配相等的概率分布。让我们来试一下：图 3 显示了结果。预测中混合了猫和狗，但是 AlexNet 并没有像我期望的那样给出对半的概率。中间的那张图的前 5 个预测中事实上没有猫。这个结果挺让人失望，但是另一方面 Alexnet 用 120 万张图像构成的一个「小」世界训练过了，它在这个小世界中只看到一个对象，所以大家不能合理地期望它能很好的呈现多种对象。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibskqI8OpeUjInsDATicOtgdM0r5w04dN0yP36YJ39aibic33jO5vxN9LOTY49QPETtsXRGV68YVYyMQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 3：PASCAL VOC 数据集中的猫和狗的图像的 Alexnet 分类&amp;nbsp;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;分类网络的另一个局限是它们无法区分图像中物体的位置。但是这可以理解，因为它们没有经过这样的训练，然而这确是计算机视觉里的主要障碍：如果一辆自动驾驶汽车不能确定道路的位置，它可能就无法开的很远！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图像分割为这些短板解决了一些问题。不单独为整张图像预测一个概率分布，而是将图像分成多个区块，每个区块有自己的概率分布。在最常见的使用中，图像被分解到像素水平，每个像素都可被分类：对于图像中的每个像素来说，神经网络被训练用来预测每个像素的分类。图像分割通常都会生成一个与输入图像尺寸相同的标签图像，其像素会根据它们的颜色来编码。图 4 展示了一张图像中四个不同类别分割的例子：桌子、椅子、沙发和盆栽。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibskqI8OpeUjInsDATicOtgd5xemvicrnflxtghB73D4WXJibpmd0HmT4EFvz2eCXbibBTvaU2INPnLdQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 4：PASCAL VOC 数据集中的图像分割例子（白色区域是未定义的像素如对象的轮廓和未分类的对象）&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在图像进一步细化实例感知图像分割（Instance-aware Image Segmentation，IASI）中，神经网络学习识别图像中每一个对象的轮廓。这在实际应用中非常有用，它必须能识别图像中出现的类别，即便是在区别不明显的情况下，比如图 5：中间的图像是图像分割标签，而最右边的图像是 IAIS 标签图像（注意颜色编码是如何唯一确定出每一个人的）。这里就不深入将 IAIS 的问题，主要说一说实例分割（instance segmentation）；但是建议大家可以查看一下 Facebook 的 SharkMask。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibskqI8OpeUjInsDATicOtgdWSvrE1q7BFp8UILuH5Wib5ku8muPmzDibdZE209icU2HwDkzULAYR0EAQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;图 5：图像分割（中间）vs. 实例感知图像分割（右）。图像来源于 PASCAL VOC 数据集。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;让我们看一看如何设计一个能分割一张图像的网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;从卷积神经网络到全卷积网络（FCN）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;上一节介绍中，区分了图像分类模型（为每张图像做概率分布预测）和图像分割模型（为每个像素预测概率分布）。总体上，这两种模型听上去差不多，你或许认为解决这两个问题的是同一个技术。毕竟，它只是增加了一个空间维度。本文将向你展示仅仅是一些小小的调整也足够将一个分类神经网络转换成一个语义分割神经网络，并将用到在论文《Fully Convolutional Networks for Semantic Segmentation》中首次提到的技术（我称之为 FCN）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;开始之前，先介绍一些术语：我会将 Alenet 这样典型的分类网络称为卷积神经网络，这有点不妥，因为卷积神经网络可用于除图像分类外的多种用途，但这是一种常用到的近似等同。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在一个卷积神经网络中，常见的做法是将网络分成两部分：在第一个部分特征提取器中，数据会经过若干卷基层来逐步提取更加复杂和抽象的特征。卷积层中通常会穿插非线性迁移函数（transfer function）和池化层（pooling layer）。每一个卷基层都可看作一组图像过滤器，可对特定模式触发高响应。例如，图 6 展示了 Alexnet 中第一个卷基层中过滤器的一个表征，和一张包含简单形状（假设 AlexNet 将这张图像归为一面墙钟）的虚拟图像的激活（输出）。这些过滤器对水平和垂直的边缘以及角落上触发了一个高响应。例如，看一下底部左边的过滤器，看上去很像黑白相间的条纹。再看看相对应的激活和对垂直线条的高响应。类似的，下一个过滤器会立即对斜条形生成一个高响应。网络里面的卷积层将能对多边形这类更加精巧的形状触发高响应，然后最终学习感知自然物体的纹理和各种成分。在一个卷基层中，通过在输入中将每个过滤器应用到一个 window（也叫 receptive field，感受野）来计算每一个输出，通过层滑动来滑动 window 直到处理完全部的输入。感受野与过滤器的尺寸相同。该过程见图 7。注意，输入 window 跨越了输入图像的所有通道。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibskqI8OpeUjInsDATicOtgdscYRx9XotHLM6fvXGAiaYbHcW8jJiaJprr5bibBaicLRsRBqt9vcvS2eZg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 6：DIGITS 中呈现的是 AlexNet 卷积层 1。从顶端到底部：数据层（输入）；卷积层 1 的过滤器的可视化；卷积层 1 的激活（输出）。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibskqI8OpeUjInsDATicOtgdewn1dcyVgRMPJeyxZ5y3jYRE4kSbWEPxnLtusw1uibRkoExciaib9Fr7A/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 7：左边：一个红色的样本输入量，第一卷积层中的神经元的样本量。在输入量中该卷积层中的每一个神经元只单独与一个本地区域全深度相连（例如所有的颜色通道）。注意，沿着这个深度上有多个神经元（该样本中有 5 个），看的都是输入中的同一个区域。右边：这些神经元仍然要用带有一个非线性（non-linearity）输入计算它们权重的节点乘积，这样一来它们的连接性在空间上会被限制在本地中。来源斯坦福 CS231 课程。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在一个卷积神经网络的第二和最后一个部分中，分类器由有大量完全连接的层构成，其中第一层从特征提取器中接收它的输入。这些层会学习不同特征之间的复杂关系，来赋予网络一个对图像内容的高水平理解。例如，出现大眼睛和皮毛 可能会让网络倾向于一只猫。这个网络能如此精确的弄清这些特征有点不可思议，也是深层学习的纯粹美的另一个特质。这种无法解释的特性有时会受到批评，但它与人类大脑功能的方式 不同：你能解释你是怎么知道一张猫的图像不是一张狗的图像的吗？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;全卷积网络（Fully Convolutional Networks，FCN），只由卷积层和上面提到的偶尔几个非参数层构成。消除全连接层如何能创建出一个看似更强大的模型呢？要回答这个问题，我们需要先思考另一个问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibskqI8OpeUjInsDATicOtgdUyQHd3aqH28GdIGSudbnsF4wXZGEaibsibYgLvrFrMmz6x51qRttuEwA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;图 8：DIGITS 中的输入、权重和 Alexnet 第一个全连接层（fc6）的激活&lt;/span&gt;&lt;/em&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个问题是：一个全连接层和一个卷积层之间有什么差别？这很简单：在一个全连接层中，每一个输出的神经元计算输入 值中的加权求和。相比之下，在卷积层中，每一个过滤器都计算感受野的加权求和。等等，这说的同一个事情吗？是的，但是，只有当层的输入与感受野具有相同的大小时才成立。如果输入比感受野大，那么卷积层就会滑动它的输入 window 并计算另一个加权求和。这个过程会一直重复到输入的图像从左到右，从上到下都扫一遍为止。最后，每个过滤器都会生成一个激活矩阵；每个这样的矩阵叫做一个特征图（feature map）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这就提供了一个思路：为了用一个相等的卷积层替换一个全连接层，只要将过滤器的尺寸设置成层输入的尺寸，并使用数量与全连接层中的神经元数量相同的过滤器。我们会在 Alexnet（fc6）的第一个全连接层中展示这个过程：相关层的 DIGITS 可视化见图 8。你能见到 fc6 从 pool5 中接收了它的输入，同时输入的形状是一个 256-channel 6×6 的图像。此外，fc6 上的激活是一个长度为 4096 的向量，这意味着 fc6 有 4096 个输出神经元。也就是说，如果我想用一个相等卷积层替换 fc6，我要做的就是将这个过滤器的大小设为 6×6，将输出特征图的数量设置为 4096。一个小小的题外话，你认为这一层有多少个可训练的参数？对于每个过滤器，感受野中每个数字都有一个偏项（bias term）加上一个权重。这个感受野的深度为 256，大小为 6×6，因此每一个过滤器都有 256×6×6+1=9217 个参数。因为有 4096 个过滤器，所以这一层的参数总数为 37752832。那正是 DIGITS 认为 fc6 会有的参数数量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在实际中，取代该层很简单。如果你使用 Caffe，只需要用表 1 右边的定义取代左边的定义就行。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibskqI8OpeUjInsDATicOtgdPFftR0xdOQouwm4bQCxags0VwHAHR5RMFqph8YlHP09jqrwVVkEvIw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;表 1：左：fc6 定义，右：对等的带有大小为 6 的核函数的 conv6，因为向 fc6 输入的是 6×6 的图像块。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;了解了这些之后，你可以继续将所有的完全连接层转换成相应的卷积层。注意，不要用 DIGITS 计算这些层的输入的形状；你可以手动计算。听上去很有趣，但我保证要在 VGG-16 中做完所有的 16 层你会失去耐心，而且还没有暂存器来暂存记录。此外，作为一个深度学习爱好者，你应该适应让机器来为你干活。所以，就让 DIGITS 帮你做这些吧。&lt;/span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;由此产生的 FCN 有与基础卷积神经网络数量相同的可学习的参数以及相同的表现和计算复杂性。由于输入相同，输出也就相同。你或许会惊讶：为什么这么麻烦滴转换模型？好吧，「卷积化」基础 CNN 引进了大量的灵活性。模型不再被限制在一个固定的输入尺寸（Alexnet 中是 224×224 个像素）上运行。它能像滑动 window 一样扫描整个输入来处理更大的图像，并且无需为整个输入单独输出一个概率分布，而是每 224×224 个 window 生成一个概率分布。网络输出的是一个带有 KxHxW 形状的张量，其中 K 是类别的数量，H 是垂直轴上滑动 window 的数量，W 是水平轴上滑动 window 的数量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;关于计算效率的一个提示：理论上你可以通过重复选择图像块并将它们馈送到 CNN 进行处理来实现 sliding window。但在实际中，计算效率会非常低：在你递增移动 window 时，只有一小部分新像素可被发现。如今，每个图像块都需要完全被 CNN 处理，即使在相邻图像块之间有很大的重叠。因此你可能要多次处理每个像素。在 FCN 中，因为这些计算都在网络内发生，只有小量的运算需要执行，因此处理速度有了量级增加。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;总而言之，这给我们带来了新的里程碑：为分类网络增加了两个空间维度。在下一章节中，我讲演示如何进一步精调模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;图像分割 FCN&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在前面的章节中展示了如何设计一个预测每个 window 的一个类概率分布的 FCN。明显的是，在扫描输入图像时，window 的数量由输入图像的大小、window 的大小和 window 之间使用的 step 的大小所决定。理想上，一个图像分割模型将为图像中的每个像素产生一个概率分布。但在实际中如何做到这些？这里我会再次利用来自 FCN 论文的一个方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当输入图像连续穿过「卷积的」Alexnet 的各个层时，输入中的像素数据被有效的压缩为一系列粗糙的、更高层次的特征表征。在图像分割中，这么做的目的是插入这些粗糙特征来为输入中的每个像素重建出好的分类。事实证明使用解卷积（deconvolutional）层能很好的做到这些。这些层进行与卷积相反的逆运算：给定卷积输出和 filter 定义的情况下，一个解卷积层能够发现会生成这种输出的输入数据。记住在处理输入时，卷积层（或池化层）中的 stride 决定了 window 滑动的距离，因此它也是输出如何下采样的一种测量。相反，在解卷积层中的 stride 是输出如何上采样的一种度量。把 stride 选择为 4，输出就更大了 4 倍！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下一个问题是：在模型中，我如何决定上采样多少最后卷积层的激活函数，从而获得与输入图像同样大小的输出？我需要检查每一层，并谨慎的记下它的换算系数（scaling factor）。一旦我检查了所有层，只需要把所有换算系数相乘就行。让我们看一下 Alexnet 中的第一个卷积层：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibskqI8OpeUjInsDATicOtgd9VfdkNQjMOZ1ALksl3hSQGibicX7qiakpfsDBlkZd9XsxOp1qsJugtnSA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;卷积层 1 的 stride s 是 4，因此换算系数是 1/4。在所有层上重复此过程，我测定该模型的所有换算系数是 1/32，就像表 2 总结的那样。因此，解卷积层所需的 stride 大小是 32。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibskqI8OpeUjInsDATicOtgdADq92ykK35gqnpwYShyTuBXMNWExpWaBDFSomm9FEk94xohJz48ib4A/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了完备性，我必须要说的是卷积层的 stride 产生的输出在所有空间维度上都是输入大小的数倍这一说法并不完全正确。在实际中，向输入中增加 padding 将增加激活函数的数量。相反，使用核函数将打掉输入中的激活函数。如果你向该层提供无线长的输入，输入/输出比例将确实存在于所有（空间）维度。事实上，每个卷积（池化）层的输出都被移动了。表 2 是对这些计算的总结：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibskqI8OpeUjInsDATicOtgdOovdwHSacibAEOc1enZoGHy67PjqDv1JGLfxDBk7NkiauXoSY6bUVBeg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;表 2 展示了网络的输出移动了 18 个像素。在此分割模型中我要用的最后一个技巧是一个层 crop 该网络的输出，并在每个边界移除 18 个额外像素。在带有 Crop 层的 Caffe 上很容易做到这一点，在下面列表中有所定义&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibskqI8OpeUjInsDATicOtgdY2C2ibvexiagYCtiaGvckibCLLtHBnYMicGsZ0TZiaicFBozKC460SgbNiafkA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你可能注意到此版本的 Alexnet 要比卷积层 1 中的 padding 更多。有两个原因：一个原因是为了生成更大的初始迁移，以便于连续层招致的 offset 不被消化进图像。然而另一个主要原因是让该网络处理输入图像边界的方式是它们能够近似的碰触到网络的感受野。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;终于，我有了复制 FCN-Alexnet 模型的所有东西。接下来，让我们看一下来自 SYNTHIA 数据集的新鲜图片。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;SYNTHIA 数据集&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;SYNTHIA 数据集首次公开在论文《The SYNTHIA Dataset: A Large Collection of Synthetic Images for Semantic Segmentation of Urban Scenes》中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图 9 展示了来自 SYNTHIA 数据集的图像样本。这些图像综合地展示了生成的带有各种目标分类的城市场景，比如建筑、道路、汽车和行人，该数据集也包括白天、黑夜不同场景下的情景。有趣的是，这些图像看起来很真实，足以迷惑人类：呃，第一张图中有人站在马路中间读报纸看起来很怪异，他肯定不怀好意！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibskqI8OpeUjInsDATicOtgdWgA5bOibGu0IL5uJFoCHbkzk0CxgCHMqwnbH1xSxzLricrVKzAyIWB3A/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;图 8：来自 SYNTHIA 数据集的样本。左：要分割的图像；右：ground truth&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 DIGITS 5.0 中，创造一个图像分割数据集简单到点到输入和 groud-truth 图像 folders 并点击「创造」按钮。DIGITS 支持各种标记形式，比如 palette 图像（标记图像中的像素值是调色板指针）和 RGB 图像（每种颜色指代一种类别）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 DIGITS 中创造自己的数据集之后，你可以可视化的探索里面的内容，就像图 10 一样。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibskqI8OpeUjInsDATicOtgdbNM81UUzfguONuynrvrHWQMqMgTwVx8e4PEvOMcIyIPOp0UMyFrHZw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 10：DIGITS 中的数据集探索。Top：输入图像，Bottom：标记。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;训练模型&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 DIGITS 中开始训练模型所需要的只是对数据集和网络的描述。如果你认为卷积的 Alexnet 的流程有些复杂或者太耗时间：DIGITS 5.0 加上了一个模型库（model store），FCN-Alexnet 可从库中取回。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然而，如果你选择较难的方式，并创造自己的模型描述，你可能就想用到像 Kaiming（MSRA）方法这样合适的权重初始化 scheme，它如今是 Rectified Liner Units 的顶尖方法。通过在 Caffe 中向参数层加入一个 weight_filler { type: "msra" } 可轻松做到这一点。如果你在 DIGITS 中以这种方式训练模型，你可能会得到类似于图 11 的曲线。你可以看到表现有些不尽人意。验证准确率高峰在 35%（意味着验证集中只有 35% 的像素被准确标记了。）训练损失与验证损失一致，表明该网络在训练集上欠拟合。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibskqI8OpeUjInsDATicOtgdcDUSicwGZXg0G32xq96ZF1ZT1Vhib66VCjTsuG0b3tAu2Ic4ibzACe7Dw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 11：在 Synthia 上使用 DIGITS 中的权重初始化训练 FCN-Alexnet 时的训练/验证损失和验证准确率。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你可以在样本图像上尝试一下，并用 DIGITS 对图像分割进行可视化。你会得到类似图 12 的图像，在此你能看到网络在建立时任意的分类每件事。结果证明这种建立是 SYNTHIA 中最具代表的目标分类，该网络通过在建立时标记所有东西也慢慢地学到了 35% 的准确率。处理网络欠拟合训练集的方法都有哪些呢？&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;更长的训练：观察损失曲线，因为训练看起来已经达到了高点所以毫无办法。该网络已经进入了一个局部最小化，难以逃脱。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;增加学习率并减小 batch 大小：这可能激励陷入局部最小化的网络探索周围环境外的东西，尽管这增加了网络偏离的风险。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;增加模型的大小：这可能增加了模型的表达性。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我发现的另一个在计算机视觉上表现极好的方法是迁移学习。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibskqI8OpeUjInsDATicOtgdt5Sicomfco2bPWnAhwZfTwScqnibGA3kms8QR3amxnTy92nV5cRsFunA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 12：在 SYNTHIA 数据集上使用随机权重初始化训练 FCN-Alexnet 时，DIGITS 中图像分割的样本可视化。该网络在建立的时候就分类了每件事。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你不必从随机初始化权重开始来训练模型。在很多情况下，它有助于重新使用网络在另一个数据集上训练时学习到的知识。这在使用 CNNs（卷积神经网络）的计算机视觉当中尤其如此，因为许多的低维特征（线、角、形状、纹理）直接适用于任何的数据集。因为图像分割是在像素的级别上进行分类，因此图像分类数据集中的迁移学习是有意义的，例如，ILSVRC2012。这在使用 Caffe 时显得相当简单—当然这会有一个或两个问题！记住，在 Alexnet 的 fc6 当中，权重的形状为 4096×9216。在 FCN-Alexnet 的 conv6 当中，权重的形状为 4096×256×6×6。这个数量与权重的数量完全相同，但是因为形状的不同，Caffe 无法自动携带权重给 FCN-Alexnet。该操作可以使用 net surgery script 来进行，其示例可以在 Github 上的 DIGITS 存储库中找到。net surgery script 的作用是将参数从完全连接层转移到它们对应的卷积层上。但是你可能会发现，直接从公共的 DIGITS 模型库上下载预训练模型会更加容易。图 13 显示了模型库的预览：单击「FCN-Alexnet」旁边的「导入」，DIGITS 将会下载预训练模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em style="color: rgb(136, 136, 136); text-align: center; white-space: pre-wrap;"&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibskqI8OpeUjInsDATicOtgdDHoeiaXaJVuicHF9NoQw0eO5noOv4bZ8O8U4bk3ajhLKJmbLAgicmwNPQ/0?wx_fmt=png"/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一个相关的担心是如何初始化之前在文本上添加的上采样层，因为这一层并非是初始化的 Alexnet 模型：在 FCN 论文中，建议随机初始化相关权重并且使网络进行学习它们。论文的作者随后意识到，以这样的方式初始化这些权重也很简单，即通过进行双线性插值，该层仅充当放大镜。在 Caffe 中，这是通过向该层添加 weight_filler {type: "bilinear"} 指令来完成的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;使用预训练的 FCN-Alexnet 模型时，你会注意到精度会快速地超过 90%，并且当测试独立的图片的时候（如图 14 所示）结果将会是一个更令人信服的图像分割，拥有者 9 个不同的对象类的检测。然而，你可能会稍微有些失望地看到对象的轮廓都非常粗糙。阅读下一部分和最后一部分，了解如何进一步提升我们的分割模型的精度和准确度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibskqI8OpeUjInsDATicOtgdZ3ZbO2Q8jjVgowTGJeG0Ugs0DHesacGjV0RpB7JhOI1FlcYiaB3Dkbw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 14：使用 ILSVRC2012 预训练的 Alexnet 在 SYNTHIA 数据集上训练 FCN-Alexnet 时 DIGITS 中图像分割的样本可视化。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;精细分割&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;记住，添加到 FCN-Alexnet 的新的上采样层将 conv7 的输出放大了 32 倍。在实践当中，这意味着网络对每一个 32×32 的像素方块都会进行单独的预测，这解释了为什么对象的轮廓如此粗糙。FCN 论文中介绍了另一个解决这个限制的好方法：添加跳过链接，直接将 pool3 和 pool4 重定向到网络的输出。因为这些合并层在网络当中进一步回退，它们在低维特征上操作并且可以捕获到更加精细的细节。在被称为 FCN-8 的网络架构中，FCN 论文介绍了基于 VGG-16 的网络，其最终的输出是 pool3 上采样的总和的 8 倍，pool4 的上采样的 2 倍和 conv7 的 4 倍，如图 15 所示。这导致网络可以在更精细的颗粒上进行预测，下降到 8x8 的像素块。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibskqI8OpeUjInsDATicOtgdNL4gOJZ20F5vIA3UcwyzPaVTNoBUFIXfOg3wq0GrRKmKeD7pgVuiblg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;图 15： FCN-8 跳过链接的图示—来源：FCN 论文&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了你的方便起见，可以从公共 DIGITS 模型商店下载预训练的 FCN-8。（你不会想要手动卷积 VGG-16 的！）如果你使用 DIGITS 训练 SYNTHIA 上的 FCN-8，你应该看到 只有几个时期，验证的准确率超过 95%。更重要的是，当你测试样例图片并且观察到 DIGITS 非常棒的图像分割可视化时，你会看到更加清晰地对象轮廓，如图 16 所示。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibskqI8OpeUjInsDATicOtgdFxcSjl6dnwxkKnzeTAmicFqg35BbD2KFNZzaOsah2wRFmEwGyiajuYXQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 16：在 SYNTHIA 数据集上训练 FCN-8 时，DIGITS 中图像分割的样例可视化。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Sun, 13 Nov 2016 15:37:12 +0800</pubDate>
    </item>
    <item>
      <title>资源 | DeepMind提出的可微神经计算机架构的TensorFlow实现</title>
      <link>http://www.iwgc.cn/link/3484419</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自GitHub&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;本篇文章介绍了对 DeepMind 最近在 Nature 上介绍的可微神经计算机（DNC）架构的TensorFlow 实现。关于DNC的介绍，可参考机器之心文章《&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719745&amp;amp;idx=2&amp;amp;sn=242eda88fa9a5572e60b43e451a1549b&amp;amp;chksm=871b027fb06c8b693cff17f43553625f008fcb7965582119b651dbbd17e116e35dc801ebeec3&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719745&amp;amp;idx=2&amp;amp;sn=242eda88fa9a5572e60b43e451a1549b&amp;amp;chksm=871b027fb06c8b693cff17f43553625f008fcb7965582119b651dbbd17e116e35dc801ebeec3&amp;amp;scene=21#wechat_redirect"&gt;业界 | DeepMind深度解读Nature论文：可微神经计算机&lt;/a&gt;》。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;项目地址：https://github.com/Mostafa-Samir/DNC-tensorflow&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该实现不包括论文中介绍的所有任务，但它注重对该架构一般的独立任务的关键特性的探索与重现。然而，在设计上该实现具有可延展性，因此适应到其他任务时也会很简单。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;本地实现环境&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所有的实验和测试都在下面的机器上实现：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;一个 Intel Core i5 2410M CPU @ 2.30GHz (2 physical cores, with hyper-threading enabled)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;4GB SO-DIMM DDR3 @ 1333MHz&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;No GPU.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Ubuntu 14.04 LTS&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;TensorFlow r0.11&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Python 2.7&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;实验&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;动态记忆机制&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;设计该实验是为了证明外部记忆访问机制各种功能，比如顺序检索（ in-order retrieval）和 allocation/deallocation。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一个类似于论文中的方法是训练一个 2 层前馈模型，具体方法参见：https://github.com/Mostafa-Samir/DNC-tensorflow/tree/master/tasks/copy。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该模型能够学习如何成功复制输入，而且它确实学会了使用记忆机制，下图就展示了这一点：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibskqI8OpeUjInsDATicOtgdXRSTdicaNNgrQb5mbz7DdDtjAcjJicpuCiacIPL4mw5uIxZlYJ7sGcziaA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 Visualization Notebook 中，你可以重现类似的图。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;在该图的 Memory Locations 部分，可以明显看到该模型能够以被编写的顺序读取记忆位置(memory location)。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;在该图的 Free Gate 和 Allocation Gate 部分，展示了在 memory location 被读取之后可被完全激活，且变得过时，虽然在编写阶段有较少激活。Memory Locations Usage 也证明了 memory location 是如何被一次又一次的使用、释放（freed）、再使用的。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在门的激活程度上，该图与DeepMind 论文中图有些不同。这可能是由于该模型比较小，以及相对较少的训练时间。然而，这并不影响模型的操作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;泛化和记忆可扩展性（ Memory Scalability）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;设计该实验是为了检查：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;训练模型是否已经学习了一个可被泛化到更大输入长度的隐形复制算法；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;学习模型是否不依赖训练记忆的大小且可被扩展到更大的记忆大小。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了做到这些，在复制问题上训练了一个带有 15 个 memory location 的 2 层前馈模型，训练流程的细节可参加：https://github.com/Mostafa-Samir/DNC-tensorflow/tree/master/tasks/copy。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然对该模型进行测试，结果显示它确实能够没有再训练的情况下高效的归纳并使用可用 memory location。下图中的描述类似于 DeepMind 论文中的 Extended Data 图2：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibskqI8OpeUjInsDATicOtgdItfW5mYrLJpicnYxK4WEMRRicC87yCbgGJe1TMTK3EGymZ62liaek0G9w/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;类似的图可在 Visulizaiton Notebook 中重现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;To-Do&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;核心：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="list-style-type: decimal;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;稀疏关联矩阵&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;跨越同样batch的可变序列长度&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;任务：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="list-style-type: decimal;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;bAbI 任务&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;图形推断任务&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Mini-SHRDLU 任务&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;作用：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一个忽略了所有关于迭代、学习率等细节的任务建立器，将它们提取到了命令行参数的配置中，用户只需要考虑定义计算图就行。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Sun, 13 Nov 2016 15:37:12 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 如何建立一只高效的机器学习团队？这是你需要知道的四点经验</title>
      <link>http://www.iwgc.cn/link/3484420</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Mixpanel&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Suhail&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：曹瑞&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从 CEO 到产品经理，再到风险投资人，每一个人都想加强对机器学习的理解，因为他们知道机器学习有潜力让他们的软件更上一层楼。他们因为机器学习感到兴奋。他们已经读过 TechCrunch 和 Fortune 的文章，也可能已经快速做了一次或者两次线性回归。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是很多产品负责人在机器学习中所面临的最重要的问题在于，他们不仅仅想要的这些程序只会做数字运算，同时，他们还希望这些程序能够代替他们思考。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他们会说，「我希望这个算法能够告诉我为什么。为什么我的客户不能到我这边来呢？为什么这个功能没有我预期的好？我想知道原因！」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;事情是这样的。机器学习的目的不是为了证明某些原因，它的存在是为了针对一些特定的数据、行为或者是模式做出一些高质量的预测。算法唯一的工作就是让你能够更加有效、更加精确地达成目标，而不是告诉你为什么。从表面上看来，这似乎有一些让人失望。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但事实上，只要你恰当使用，就能激发它的功效。机器学习带来了一次更高级别的数据分析革命。目前机器学习的基础就是帮助工程师制造出更好、更复杂精巧的软件。此外，一些精明的企业已经放弃了不惜一切代价追求增长的模式，开始投身这个具有可预测性的产业当中。可预测性，事实让就是机器学习的发展前景。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是对于工程师来说，机器学习并不是小菜一碟。这并不是像在你已经了解 Ruby 的情况下选择 Python。在 2 年前，所有工程师，包括我自己，都对机器学习一无所知。我知道如果我们想利用机器学习分析产品，我们必须要认识到我们对于未知的情况完全一无所知，而且我们面对的是复杂的数学，而不是魔术。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;我们最大的挑战以及要吸取的经验教训&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器学习最让我感兴趣的一件事情是它能够让软件自动做很多事情，而这些事情是我们直接用编程做不到的。对于一个工程师来讲，这真是太令人兴奋了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是对于一个产品负责人来说，机器学习也带来了新的挑战，这些挑战是我之前从未面临过的。我聘请了 Jenny Finkel 博士，她是一名真正的机器学习方面的专家，而不是尝试自己成为一名这方面的专家。我希望能够建立一个团队来成功应对机器学习带来的各种挑战，并帮助 Mixpanel 迈上一个新台阶。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我非常骄傲地看到我们在过去两年中所取得的成就，我更引以为傲的是我们在建立 Mixpanel 的机器学习团队中所学习到的。下面是我认为其中最重要的一些经验：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 你需要专家。这一点是我很快就意识到的，我们需要真正的机器学习专家来研发真正的机器学习产品。顶级的机器学习方面的博士，都去了谷歌和微软就职。为了弥补这一点的不足，人们用数据来武装自己的公司。这似乎让他们更加像是一个真正的机器学习团队，但是机器学习中所涉及到的数学问题，其复杂程度是无法和一些数学统计工作者所涉及的相比的。我认为我们需要真正的机器学习专家，如果重新决策的话，我还是会做同样的决定。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 我们很难知道从哪儿开始。你可能会迫切地希望立马就建立一些疯狂并且复杂的算法，但是在那之前，在数据方面你还有还有很多的事情要去做，甚至是从运用机器学习开始。起初，你可能并没有数据，你可能没有建立模型的可用数据，甚至你可能连模型都没有。所以，事情并不是像「我们就从运用机器学习开始」这么简单。这一定会让工程师感到精疲力竭。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3. 规模的问题总是存在。比起统计学所面临的，规模会在更大程度上影响到机器学习的成败。工程师们知道，在统计学当中数据量并不是非常重要。这就是为什么，比如说，我们随机抽取一些电子商务客户的样本，这样就能得到一个相对精确的模型，了解到所有的客户对在线促销的反应。我们不需要知道所有的购买产品组合，或者是了解每一种可能的潜在结果，才能明白可能出现的结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;可在机器学习方面，数据量的作用要大得多。你对每一种可能结果的了解更多，你的预测能力就会越好。仅在一些过去的事件或是实时的动态当中取样是远远不够的，你的模型需要知道每一种情况，并且能够趋向于给出一种正确的解决方案，这样才能发挥可预测性的优势。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们继续说电子商务的例子，如果说电子商务公司除了想要预测谁会对促销有所反应，了解更加复杂的购买模式之外，还想知道更多。机器学习需要了解电子商务公司 200 万客户当中每一个人的情况，了解他们购买的产品，用每一种可能的组合方式分析他们的购买情况，建立一个最精确的购买模型。这样，将来的购买模型就可以利用 数据粒度上的增长做出更加精准的预测。从如此庞大的数据当中得出这样的细节信息，似乎有一点疯狂。这就是为什么你需要一个真正的机器学习工程师团队，能够快马加鞭干正事，并且能建立出最好的模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4. 要记住，我们的目标是可预测性，而不是找原因。企业一直都盼望能够预测本季度的销售，看看通过促销他们到底能够吸引多少客户，或者是能够预测需求量的波动。机器学习主要能够提升模式识别，这同时会推动可预测性的发展。这就是为什么我知道我必须要在这一领域进行大型投资。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所有的这些经验都不应该让你灰心。毕竟，机器学习中的「为什么」对于产品团队来说很简单。机器学习能比人更快更准确地弄清楚人们觉得棘手的问题，继而自动采取行动。如果你能够创造一个用户反馈和更好的用户体验之间的良性循环，或许就可以让更多人使用你的产品。之后，你就可以利用这个数据网络效应，吸引更多的用户，这也会让你获取更多的数据，从而建立更好的模型，同样这会为了你带来更多的用户。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;作为产品负责人，你的工作就是要创造出优良的产品，然后把它们推广给你的客户。从产品发展的角度来讲，机器学习是最令人兴奋的，因为它能够通过分析（比如说通过异常检测）自动处理你的很多工作和顾虑。所以，如果你在认真考虑要实行机器学习，那你就应该认真想一想你需要解决的问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在你成立一个机器学习团队之前，你必须要明白你是否具备完成你远大抱负的基础设施。认识到你可能不具备这一点并不能够能明你没有远见卓识，只是机器学习是一种有潜在风险的前沿技术，每个人都必须要清楚地知道如何才能最好地利用它的功能，并将它的所带来的利益最大化。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;「创造 vs. 购买」这是一个错误的命题&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;底线是这样的：计算机在记忆大量数据方面非常在行，它们可以在记忆的所有数据当中找出一定的模式和趋势，而人类在这些方面的能力都很弱。如果你想要让公司的竞争力有所改善的话，就需要通过模型获得一些见解，以此来解决一些复杂的问题。现在能做到这一点的唯一方法就是通过机器学习，另外还需要具备一个技术娴熟的团队来帮你弄清楚这些模式是什么，为什么它们是这个样子。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果是一个小公司，那么你的工程师可以在他们的电脑上建立一些模型，在开始阶段，这些模型应该就足够了。但是如果你拥有大量数据，你从只依靠自己来解决问题当中获得的，与在机器学习当中获得的是完全不同的，并且这样做也不利于公司保持竞争力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最重要的一点是关于权衡。建立一个机器学习模型需要很长的时间。工程师在非核心功能上花费多一分钟，你在核心产品上花的时间就少一分钟。此外，大多数的机器学习都会涉及到大规模的迭代问题，因为有大量的数据需要收集、标注，并且进行重复处理。如果你想要自己解决这个问题，这对你的工程师团队来说就成了一项额外的负担，而且还要花费上万美元。你需要决定自己做什么，不做什么。在 Mixpanel，我们致力于将机器学习和产品分析用正确的方式结合起来，而不是用一些博人眼球的奇怪方式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Predict 和 Smart Alerts 对我们来说只是开始，即使你才刚刚开始追踪分析，我&lt;/span&gt;&lt;span&gt;们想要帮你创造正确的产品——而不是一直在观察你的数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果机器学习能够被正确使用，它的功能是非常强大的。机器学习能够创造准确的预测模型，这些模型能够做的事情也非常的令人兴奋，比如说创造高度定制的用户体验、用照片对成千上万中物体进行分类，还能在没有编程的条件下产生大量有突破性的、针对特定行业的结果。机器学习带给我们的机会让我们可以创造出全新的文明，而不是在一座空城里仅有一幢摩天大楼。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，机器之心系今日头条签约作者，本文首发于头条号，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Sun, 13 Nov 2016 15:37:12 +0800</pubDate>
    </item>
    <item>
      <title>学界 | Embedding 新框架模型：Exponential Family Embeddings</title>
      <link>http://www.iwgc.cn/link/3484421</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心经授权转载&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：洪亮劼（微博）&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;是不是被各种Embedding模型弄得眼花缭乱啊？这篇论文统一了很多类似模型，提供了一个简单框架。论文可点击阅读原文下载。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibskqI8OpeUjInsDATicOtgd1z09O6J4GHHheJpjAOJUKK7c2UEdjqeMqg7iazv7puib548eOLrRd79w/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这篇文章来自David Blei的实验室。文章的核心思想非常直观，那就是如何把Word2Vec的思想能够给Generalize到其他应用场景，提供一个比较通用的模型框架。在这个新的框架下，其他的很多类似模型都能够归纳成为这个新框架的特殊形式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;新的框架模型叫做Exponential Family Embedding（EF-EMB）。其中包含三个要素：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;A Context Function&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;A Conditional Exponential Family&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;An Embedding Structure&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先，Context Function是定义如何把当前的数据点（Data Point）和一个Context里面的其他数据点联系起来。这是一个建模的选择。比如，对于Language Data来说，这个Context可以就是周围的字；而对于Neural Data来说，这个Context则可以是周围的Neuron；对于Shopping Data来说，这个Context则可能就是购物车里的其他商品。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其次，Conditional Exponential Family定义一个合适的Distribution，来解释数据的产生过程。比如，对于Language Modeling来说，这个分布就是Categorical Distribution；而对于Real-Valued数据来说，则就是Gaussian Distribution。另外，在这个Conditional Exponential Family的定义里，每一个Data Point有两种Embeddings：一种叫做Embedding Vector；另一种叫做Context Vector。通俗得讲，也就是每个数据点分解成为了Embedding Vector和一组Context Vector（这个被上面的Context Function所定义）的乘积形式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第三个要素Embedding Structure定义在建模中，Embeddings是如何被共享（Shared）的。比如，对于Language Data来说，每一个词只有唯一的Embedding Vector和唯一的Context Vector。还有其他的一些Setting里，这两者也可以是相同的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在定义了之前的这些结构以后，Objective Function则是Log Conditional Probability的加和，外加Log定义的Regularizer。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;文章讨论了好几个模型的例子，这里就不复述了。总之，现有的一些Embedding模型都很容易在这个框架下被重现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;模型的Inference则采用了SGD。文章里还讨论了在SGD的情况下，如何得到类似于Negative Sampling的结果。同时，文章后面有详细的模型讨论。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;总之，这篇文章很值得细看一下。一方面也是因为这里面统一了很多关于Embedding模型的讨论；另一方面，从软件工程角度来说，也许也能够设计和实现一个类型的模型框架。 &amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©机器之心经授权转载，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系作者获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Sun, 13 Nov 2016 15:37:12 +0800</pubDate>
    </item>
    <item>
      <title>深度 | 构建人工智能学术搜索引擎，Semantic Scholar和微软向谷歌发起挑战</title>
      <link>http://www.iwgc.cn/link/3473008</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Nature&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Nicola Jones&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李泽南、曹瑞&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW98QD1hEWLxDWicq6SK8W62VTtIbY0TTWrdDL67pJhsvIEwaiajtV4fXCSCDMcUzYe983Nek3Kkb1sQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;em&gt;&lt;span&gt;人工智能搜索引擎「Semantic Scholar」由艾伦人工智能机构的首席执行官 Oren Etzioni 牵头研发。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以人工智能为基础的免费学术搜索引擎 Semantic Scholar 刚刚宣布，它已经覆盖了 1000 万计算机和神经科学论文。这一搜索引擎旨在利用更先进的技术来构建一套智能学术搜索引擎，并超越谷歌学术。自去年 11 月发布以来，Semantic Scholar 的出现壮大了人工智能搜索引擎的阵营，而在这些检索工具中，最引人注目的则是重新上线的微软学术。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;位于西雅图的非盈利性机构艾伦人工智能研究所（AI2）的 Semantic Scholar 搜索刚刚在神经科学年会上发布了新版本，并受到了科学家们的欢迎。「它会改变游戏规则，」斯坦福大学的神经生物学家 Andrew Huberman 说道。「现在学术界的信息庞杂，有了这个搜索引擎，学者们的工作将会获得指引。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这一搜索引擎于 2015 年 11 月发布，其开发者宣称它对论文的搜索排名基于对内容和上下文复杂的认知方式。目前最流行的学术搜索谷歌学术可以链接 2 亿篇文档，而且覆盖付费内容。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是，谷歌的工具依赖于文章关键字，而且内容和影响力对搜索结果的影响有限；不过，Semantic Scholar 则与此不同，它的搜索结果显示的是内容与搜索词存在相关性的文章，排名则有关引用增加的速度——这篇文章到底有多热门。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Semantic Scholar 刚刚上线时只能检索到 300 万篇计算机科学领域的论文。在 AI2 兄弟机构的协助下，搜索引擎中的内容逐渐增多。艾伦脑科学研究所已将数百万神经科学和医学论文加入其中，并添加了新的 filters。这些 filters 允许用户在细分领域进行搜索，如有关大脑特定部分、大脑中特定细胞、研究哪个模型生物体以及使用什么方法的论文。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「明年，AI2 的目标是索引所有 PubMed 中的内容（PubMed 包含来自 MEDLINE、生命科学类期刊和在线图书中超过 2600 万的生物医学文献），并将覆盖面扩大到所有的医学细分领域。」Oren Etzioni 说道。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前，这个搜索引擎仍然需要进行内容的扩充，马德里 Expert System 软件公司的 Jose ManuelGómez-Pérez 说道：「我目前使用最多的仍然是 Google Scholar，但 Semantic Scholar 引擎还有很多潜力。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;微软的复兴&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW98QD1hEWLxDWicq6SK8W62VnN1Y53dlb7k0niaXZjeUoTllQo4icDOpFqbRezRodXvibdUEibQVfy4cibw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;微软学术图景显示了科学出版物记录、出版物引用关系以及作者之间的关系。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Semantic Scholar 并不是唯一一个基于人工智能的搜索引擎。电脑巨商微软在今年 5 月份也公开发布了自己的人工智能学术搜索工具——微软学术（Microsoft Academic），取代了它的「前辈」微软学术搜索（Microsoft Academic Search），后者的服务在 2012 年被公司停止。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;微软这次的野心并不止于学术搜索。目前，所有研究者都可以通过 API 和开放学术社区（Open Academic Society）接触到微软学术搜索的算法和数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;开放学术社区是微软研究院和艾伦人工智能研究所以及其他机构的合作构建的平台。微软 MSR Outreach Innovation 的常务董事 Wang Kuansan 说道，「越多人研究这个问题，情况就会越来越好。」他认为 Semantic Scholar 已经逐步深入到了自然语言处理上，也就是说能够理解论文和查询中完整语句的含义。但是微软的工具，是由公司的网页搜索引擎必应的语义搜索功能所驱动的，所以涵盖的范围更广，能覆盖 1.6 亿篇学术论文。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;和 Semantic Scholar 相似的是，微软学术也提供了实用的（可能不够广泛的）filters，可以根据作者、期刊和研究领域进行信息过滤。同时，它还采用了一种排行榜的形式，将每一个分支学科中最有影响力的科学家做了排序。这些人一般是那些在某个领域有极其「重要」影响的出版人，而这些排名都是由一个递归算法（免费可用）基于这些论文在其他一些重要的论文中的引用与否来判断的。根据微软学术的显示，在过去的半年当中最顶尖的神经科学家是美国明尼苏达州罗彻斯特梅奥诊所（Mayo Clinic）的 Clifford Jack。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其他的一些学者也表示对微软的研究印象深刻。Anne-Wil Harzing 正在英国密德萨斯大学研究科学计量学，在分析过这一新产品之后，她表示：「这个搜索引擎正在将谷歌学术搜索大覆盖面的优点和斯高帕斯数据库 (Scopus) 和科学引文索引数据库（Web of Science）等数据库能产生有结构性的文献订阅数据的优点相结合。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「不可否认，微软学术已经在不断发展壮大了。」微软研究院表示，他们正在研究一种能够允许用户登录的个性化版本，这样微软就能够根据他们的关注领域推荐给他们合适的新论文，或者是提醒他们自己的论文被引用，这个版本预计在明年初完成。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其他公司和学术研究机构也都在发展人工智能驱动的软件，希望能够更加深入研究到在线内容查找。比如说，位于德国萨尔布吕肯（Saarbrücken）的马克斯·普朗克计算机科学研究（Max Planck Institute for Informatics）正在研究一种叫做 DeepLife 的引擎，专门针对健康和生命科学领域。Etzioni 表示，「这些都是研究原型，不是可持续的长期研究计划。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「艾伦人工智能研究所的长期目标是创造一个能够回答所有科学问题的系统，它将能够提出新的实验设计，甚至能够帮我们做出合理的猜想。」Etzioni 说道，「在 20 年之后，人工智能就可以拥有阅读科学文本的能力——更重要的是，拥有理解的能力。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译文章，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Sat, 12 Nov 2016 12:23:24 +0800</pubDate>
    </item>
    <item>
      <title>深度 | 吴恩达呼吁企业设立首席人工智能官，并给出四点建议</title>
      <link>http://www.iwgc.cn/link/3473009</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自HBR&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;作者：吴恩达&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;不久前，百度首席科学家吴恩达在哈佛商业评论上发表了一篇文章《&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720407&amp;amp;idx=2&amp;amp;sn=86603b0276580e9e969e78cac606fe3c&amp;amp;chksm=871b0ce9b06c85ff79c95b4b42ad8bfa8fa14438266e689e7ffe3a882ee024bfd3e0ac90655e&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720407&amp;amp;idx=2&amp;amp;sn=86603b0276580e9e969e78cac606fe3c&amp;amp;chksm=871b0ce9b06c85ff79c95b4b42ad8bfa8fa14438266e689e7ffe3a882ee024bfd3e0ac90655e&amp;amp;scene=21#wechat_redirect"&gt;深度 | 百度首席科学家吴恩达刊文：人工智能的能力和不足&lt;/a&gt;》，向企业讲述人工智能的能力与不足。今天他又撰写了一篇文章建议企业聘请首席人工智能官，并给出了在招聘首席人工智能官时的建议。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;100 多年前，电的出现转变了无数的产业。20 年前互联网的出现也是如此，人工智能也将产生同样的影响。为了利用人工智能的优势，公司需要理解人工智能能够做什么以及它如何影响到公司的战略。但为了准备这一颠覆性时刻的到来，公司应该如何组织领导团队呢？答案在于追溯历史。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW98QD1hEWLxDWicq6SK8W62VeKXpJRK1dmryjZES9SXxpmwyjHxlHDFAQ5DDnbFBVWZnGqFDribCX4Q/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;100 年前的电力系统真的很复杂。你需要在直流电、交流电、不同的电压、不同水平的可靠性以及价格等之间做出合理的选择。而且如何使用电力也很难搞清楚：你是应该注重建立电灯？还是注重用电动机取代燃气轮机？于是，当时许多公司聘请了电力副总裁（VP of Electricity）帮助组织工作，以保证公司内的每个职能在自己的工作目标或产品上考虑到电的存在。随着电力系统的成熟，这一角色才消失。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;近年来，在 IT 和互联网的变革中，我们看到了 CIO 的崛起，来帮助公司组织信息。随着 IT 成熟，发展公司的互联网策略逐渐成为了 CEO 的工作。确实如此，许多标准普尔 500 的公司都希望它们能更早的发展互联网战略。这样做的公司如今确实占据着优势。而在今后的 5 年内，我们将同样如此讲述人工智能战略。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能仍不成熟，但发展迅速。所以期望每个高管完全了解人工智能是不合乎情理的。但如果你所在的产业能产生大量的数据，那就有很大的机会使用人工智能将这些数据转换成价值。对大部分有数据但缺乏深度人工智能知识的公司来说，我建议聘请一个首席人工智能官（chief AI officer）或人工智能副总裁（VP of AI）。（一些首席数据官和有超前思维的 CIO 实际上在扮演这一角色。）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;拥有首席人工智能官的收益是他能够确保全公司筒仓（silos）都应用人工智能。大部分公司天然的开发筒仓职能，从而确保各部门的专业化、变得更高效。为了便于讨论，假设你的公司有礼物卡部门，人工智能很有可能使得礼物卡的销售与处理过程变得更好。如果公司有专业技术能吸引到并部署人工智能人才，务必任其施为！然而在大部分情况下，这是不现实的。因为人工智能人才如今还很匮乏，能吸引到顶级人才在高级部门做礼物卡方面的工作还不太可能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;专业的人工智能团队要比单个礼物卡部门有更高的机会吸引到人工智能人才和维护标准，而且无论怎样新的人才会被融入进其他业务单位，从而给予支持。但专业的团队需要领导，我也看到更多的公司聘请高级人工智能领导者帮其建立跨越全职能的人工智能团队。聘请到正确的人工智能领导者能急剧增加公司成功的机会，但只是在你选到正确的人的情况下。基于我在谷歌、斯坦福、百度带领、扶持过一些成功的人工智能团队的经验，以下是在寻找首席人工智能官或人工智能副总裁时我给出的一些建议：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;对人工智能和数据基础设施好的技术理解。例如，他们曾建立过重要的机器学习系统。在人工智能时代，数据基础设施（你如何组织公司的数据库并保证所有相关数据都被安全、可访问的存储）非常重要，尽管数据基础设施技能相对普通。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;跨职能的工作能力。人工智能本身不是产品或业务，而是一种用来帮助已有业务线并创造全新产品和业务线的基础技术。因此，有能力了解不同的业务单位或职能团队并与他们合作就很重要。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;强大的企业家技能。人工智能创造建立新产品的机会，从自动驾驶汽车到能与之交流的代理，这在几年前还形不成经济，甚至是科幻小说中的东西。一个掌握企业家技能的领导者将会增加公司成功创造出这种创新的几率。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;吸引并留住人工智能人才的能力。这种人才备受追捧。在新的大学毕业生中，我观察到该领域内的学生有明显不同的薪水。好的首席人工智能官需要知道如何留住人才，例如通过注重感兴趣的项目、给团队成员培养技能的机会等。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有效的首席人工智能官应该有管理人工智能团队的经验。由于人工智能进化飞快，他们需要跟得上变化，但要求他们必须处于最前沿就没那么重要的（虽然这能帮助吸引人才）。更重要的是他们能跨职能部门进行合作，有搞清楚如何适应公司已有人工智能工具的业务技能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译文章，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Sat, 12 Nov 2016 12:23:24 +0800</pubDate>
    </item>
    <item>
      <title>技术| IBM 开源DIY纸板机器人： TJ Bot</title>
      <link>http://www.iwgc.cn/link/3473010</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自IBM&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Maryam Ashoori&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：杜夏德&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;IBM开源了一个 DIY 纸板机器人：TJBot ，召集世界各地的 Bot 爱好者来制作属于自己的个性化 Bot。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;项目地址：&lt;/span&gt;&lt;span&gt;https://github.com/ibmtjbot/tjbot&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;TJBot 延续了手工社区的精神，它是一套 DIY 工具包，可让你建立由Waston驱动的可编程纸板机器人。该机器人由一块切割的纸板（可以是3D打印或者激光切割）、Raspberry Pi 和多种插件（包括一个RGB LED灯、一个麦克风、一个伺服电机和一个摄像头）构成。同时，TJ Bot还是一个开源项目，我们可在 Instructables.com 和 GitHub 上查看相关指导。IBM的团队已经提供了三个TJ Bot 启动指导，但他们希望所有人都能贡献出自己的DIY机器人装配指导。&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;iframe class="video_iframe" data-vidtype="1" style="   z-index:1; " height="375" width="500" frameborder="0" data-src="https://v.qq.com/iframe/preview.html?width=500&amp;amp;height=375&amp;amp;auto=0&amp;amp;vid=z0345lnicon" allowfullscreen=""&gt;&lt;/iframe&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;iframe class="video_iframe" data-vidtype="1" style="   z-index:1; " height="375" width="500" frameborder="0" data-src="https://v.qq.com/iframe/preview.html?width=500&amp;amp;height=375&amp;amp;auto=0&amp;amp;vid=l03456bf56o" allowfullscreen=""&gt;&lt;/iframe&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以下是已有的 TJ Bot 的制作过程：&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;让 TJ Bot 回应情感。TJ Bot 头上的 RGB LED 灯会根据 Twitter 上的某个给定话题的公共情绪改变颜色。它与 Twitter API（https://dev.twitter.com/overview/api）相连，&lt;/span&gt;&lt;span&gt;能自动抓取推文，并能通过运行Watson Tone Analyzer&lt;/span&gt;&lt;span&gt;（http://www.ibm.com/watson/developercloud/tone-analyzer.html） 来识别整体的情绪。例如，你可以给 TJ Bot 编程让它实时跟踪关于艾美奖的大众社会情绪。&lt;/span&gt;&lt;span&gt;教程地址：&lt;/span&gt;&lt;span&gt;http://www.instructables.com/id/Make-Your-Robot-Respond-to-Emotions-Using-Watson/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;用你的声音控制 TJ Bot。你可以用你的声音给 TJ Bot 下一些基础的命令。例如，你可以要求TJ Bot「把光调成黄色」，然后它就会把自己的灯光调成黄色。TJ Bot使用Watson Speech To Text API 来转录、分析和理解你说的话。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;教程地址：http://www.instructables.com/id/Use-Your-Voice-to-Control-a-Light-With-Watson/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;与TJ Bot聊天。使用三个Watson API创作一个“聊天”bot，你只需要三步。Watson Speech To Text API（http://www.ibm.com/watson/developercloud/speech-to-text.html）会将你的声音转换成文本，然后Watson Conversation（https://www.ibm.com/watson/developercloud/conversation.html）会处理文本并计算出一个回复，之后Watson Text To Speech会将文本转换成音频，让 TJ Bot 做出回应。你可以和 TJ Bot 聊从天气到你最喜爱的电视节目的任何事情，这取决于你如何编程你的Rasberry Pi。&amp;nbsp;教程地址：http://www.instructables.com/id/Build-a-Talking-Robot-With-Watson-and-Raspberry-Pi/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;TJ Bot 是『具身认识（embodied cognition）』的一个例子，也就是将人工智能植入你日常生活中的具体物体中。在这个例子中，我们把 Watson 技术放入一个切割的纸板中，想象着让你家的墙壁、你的家具或你家里的各种物体能具备以上几种能力。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;创作出认知具身的关键之一就是理解人类与事物互动的方式。与这些物体的互动，比如与TJ Bot 的互动要比与现有计算设备互动更加自然：你不需要用键盘打字，只需用声音命令它可以了。&amp;nbsp;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不论你是想写出一个具有「big idea」的代码，还是完成课业的某个课题，都可以参与 TJ Bot 的开源项目中来。&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译文章，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Sat, 12 Nov 2016 12:23:24 +0800</pubDate>
    </item>
    <item>
      <title>一周论文| 机器翻译、表示学习、推荐系统和聊天机器人的最新研究进展</title>
      <link>http://www.iwgc.cn/link/3473011</link>
      <description>&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 5px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;引言&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本期的PaperWeekly一共分享四篇最近arXiv上放出的高质量paper，包括：机器翻译、表示学习、推荐系统和聊天机器人。人工智能及其相关研究日新月异，本文将带着大家了解一下以上四个研究方向都有哪些最新进展。四篇paper分别是：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1、A General Framework for Content-enhanced Network Representation Learning, 2016.10&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2、Collaborative Recurrent Autoencoder: Recommend while Learning to Fill in the Blanks, 2016.11&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3、Dual Learning for Machine Translation, 2016.11&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4、Two are Better than One: An Ensemble of Retrieval- and Generation-Based Dialog Systems, 2016.10&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 5px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;A General Framework for Content-enhanced Network Representation Learning&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 5px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;作者&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Xiaofei Sun, Jiang Guo, Xiao Ding and Ting Liu&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 5px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;单位&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Center for Social Computing and Information Retrieval, Harbin Institute of Technology, China&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 5px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;关键词&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;network representation, content-enhanced&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 5px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;文章来源&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;arXiv&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 5px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;问题&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;同时利用网络结构特征和文本特征来学习网络中节点的embedding&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 5px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;模型&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;总的来说这篇paper的思路比较清晰，学习的方法上很大程度上参考了word2vec的方法。对于一个节点v，将与v相连的节点当做正例，不想连的节点当做负例。那么如何融入内容呢？在网络中设置虚拟的内容节点c，将描述v节点的文本内容c_v当做正例，其他的当做负例c_v’。在优化时同时考虑网络相似性和文本相似性，让v的向量靠近正例远离负例。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a title="network-illustration" class="" rel="gallery0" style="color: rgb(37, 143, 184); max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmhIYUdDmxen0BRptpxsLQkfmvBcPpMVrVtKgoRMYWSjlVUdXrt7mSiaeIFpC2hd0LqOznf1vewtxw/0?"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;总的优化函数如下所示，由两个部分L_nn(节点与节点连接)和L_nc(节点与内容连接)线性组合而成，alpha越大则考虑网络结构越多文本内容越少。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a title="joint-learning" rel="gallery0" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmhIYUdDmxen0BRptpxsLQkqUDUs9EpSiaqawr3sib1AFjSm002tfiadV7Cy5QZq26TqWyic5iatib6MBaA/0?"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;L_nn和L_nc大体思想如上面所言，两者损失函数一致，尽量接近正例远离反例。但是两者在描述节点概率（相似度）上会有所不同。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a title="node-node-link" rel="gallery0" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmhIYUdDmxen0BRptpxsLQkIlZJ92FZKV13UeibyaL1LvV7k29U0VJDsxRWRcn4z1VQH4NMPTOOAIw/0?"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于节点与节点之间的概率，由于网络结构要考虑有向性，因此将节点的embedding切分成in和out两半，用sigmoid算两个节点的相似度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a title="node-node-probability" rel="gallery0" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmhIYUdDmxen0BRptpxsLQkL877fTicZddw42MyXx01e2QeX4C3f6QEZJt449Wo961KyweRBs6OALw/0?"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;节点与内容的概率也是类似，不过内容节点的embedding是固定的，通过额外的文本模型训练出来的。这里尝试的文本model包括word2vec，RNN和BiRNN。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a title="node-content-probability" rel="gallery0" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmhIYUdDmxen0BRptpxsLQkzNIBzZapWYdq92oNq08gNKN0A0MqnB1xmXZPW3YicuT5f7zw3lrIuYA/0?"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后在节点分类任务上进行了评测，同时结合网络结构特征和文本特征确实带来了明显的提高。&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 5px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;资源&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;用到的数据集是DBLP（cn.aminer.org/citation）和自己采集的知乎用户网络。&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 5px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;相关工作&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;这两年network representation的工作如雨后春笋，在DeepWalk之后有十余篇论文出现。这篇文章在相关工作里有相对全面的覆盖，对这方面工作有兴趣的同学值得参考。&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 5px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;简评&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;尽管相关模型层出迭见，但略感遗憾的是感觉目前并没有在network embedding之上的较为成功的应用，大多benchmark都是节点分类和链接预测，应用价值有限。十分期待一些更为新颖的benchmark的出现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 5px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Recurrent Autoencoder Recommend while Learning to Fill in the Blanks&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 5px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;作者&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Hao Wang, Xingjian Shi, Dit-Yan Yeung&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 5px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;单位&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;HKUST&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 5px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;关键词&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Recommendation, Collaborative Filtering, RNN&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 5px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;文章来源&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Arxiv, to appear at NIPS’16&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 5px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;问题&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;本文的主要贡献是提出collaborative recurrent autoencoder (CRAE)，将CF (collaborative filtering)跟RNN结合在一起，提高推荐的准确率，并且可以用于sequence generation task。&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 5px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;模型&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;传统的LSTM模型没有考虑进噪声，对不足的训练数据稳定性不好，文章提出RRN (robust recurrent networks)，为RNN的加噪版本，RRN中的噪声直接在网络中向前或者向后传播，不需要分开的网络来估计latent variables的分布，更容易实现且效率高。CARE的模型如下图所示，序列处理的信息保存在cell state s_t和输出状态h_t中，两个RRN可以组合形成编码译码结构。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;a title="collaborative1" rel="gallery0" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmhIYUdDmxen0BRptpxsLQkl39nAMUB5SibiaT3DVFu9hSF7Q0H1IhALK3JicXTabwK15PVKph18usYg/640?wx_fmt=png"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Wildcard denoising的目的是缓解overfitting，做法是随机选择一些词，替换成&lt;/span&gt;&lt;wildcard style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;，而不是直接扔掉词，实验验证准确率会提成20%左右。Beta-pooling的目的是将向量序列pool成固定长度为2K_W的单向量，帮助rating matrix的矩阵分解；因为不同序列可能需要不同大小的权重，所以需要变长的beta向量来帮助pooling，文章采用beta分布。&lt;/span&gt;&lt;/wildcard&gt;&lt;/p&gt;&lt;p&gt;&lt;wildcard style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;br/&gt;&lt;/wildcard&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Learning的过程采用MAP，类似于CDL和DTR。学到矩阵U和V之后，我们可以预计评分矩阵R。&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 5px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;资源&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;1、CiteULike&lt;br/&gt;2、Netflix&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 5px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;相关工作&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;选取当中两个比较有意思的work。&lt;br/&gt;1、CTR (collaborative topic reguression)&lt;br/&gt;将topic model和probabilistic matrix factorization (PMF)，但是CTR采用bag-of-words的表示形式，忽略了词序和每个词的局部语境，而这些对文章表示和word embeddings能提供有价值的信息。&lt;br/&gt;2、CDL (collaborative deep learning)&lt;br/&gt;将CF和probabilistic stacked denoising autoencoder (SDAE)结合起来，是一个以bag-of-words为输入的feedforward模型，并不能解决sequence generation的问题。&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 5px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;简评&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;这篇文章将RNN用于recommendation，并且与rating matrix结合起来，比较有意思，而且考虑了数据稀疏的情况，pooling的方法也值得借鉴。&lt;/span&gt;&lt;/p&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/h1&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 5px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;Dual Learning for Machine Translation&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 5px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;作者&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Yingce Xia1, Di He, Tao Qin, Liwei Wang, Nenghai Yu1, Tie-Yan Liu, Wei-Ying Ma&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 5px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;单位&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;1、University of Science and Technology of China&lt;br/&gt;2、Key Laboratory of Machine Perception (MOE), School of EECS, Peking University&lt;br/&gt;3、Microsoft Research&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 5px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;关键词&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Dual Learning, Machine Translation, Deep Reinforcement Learning&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 5px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;文章来源&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;arXiv, 1 Nov 2016&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 5px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;问题&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;文章针对机器翻译时需要的人工标注的双语平行语料获取代价高的问题，提出了Dual Learning Model使用单语语料来进行训练，取得了比使用双语平行语料训练的模型更好的结果。&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 5px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;模型&lt;/strong&gt;&amp;nbsp;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;模型的核心思想见下图：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;a title="Dual_Learning" class="" rel="gallery0" style="color: rgb(37, 143, 184); max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmhIYUdDmxen0BRptpxsLQktdYR6QTJAeXwDYhIo7DbOozE9fPwWsbmVtaAAR3I8S4ZDbumycYWxg/640?wx_fmt=png"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;注:上图来自CCL2016马维英老师PPT&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;对上图的详细解释：&lt;br/&gt;模型中有两个Agent，Agengt_A和Agent_B,Agent_A只能够理解A语言，Agent_B只能理解B语言，model f是将A语言翻译成B语言的翻译模型，model f是将B语言翻译成A语言的翻译模型。上图的执行过程可以按照下面的解释进行：&lt;br/&gt;1、Agent_A 发送一句A语言的自然语言的话X1&lt;br/&gt;2、model f将X转换成为B语言的自然语言Y&lt;br/&gt;3、Agent_B收到Y，并将Y 传送给model g&lt;br/&gt;4、model g将Y转换成源语言A的自然语言X2&lt;br/&gt;5、比较X1和X2的差异性，并给出反馈.并进行1到4的反复训练&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;模型的算法过程：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;a title="Dual_Learning_Algorith" rel="gallery0" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmhIYUdDmxen0BRptpxsLQkiaX5h7iaBh2aY73pdWcGXbJmsicWWa8NsIULGIlJJDoGDvj4lLfXBCypg/640?wx_fmt=png"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在step8的时候对翻译模型翻译的结果使用语言模型做了一个判定，判定一个句子在多大程度上是自然语言。step9是给communication一个reward，step10将step8和step9加权共同作为样例的reward.然后使用policy gradient进行优化。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;需要说明的model f和model g是已有的模型或者说在刚开始的时候使用少量的双语语料进行训练得到吗，然后逐渐加大单语语料的比例。&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 5px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;资源&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;1、NMT code:&lt;/span&gt;&lt;a target="_blank" rel="external" style="max-width: 100%; font-size: 14px; box-sizing: border-box !important; word-wrap: break-word !important; text-decoration: underline;"&gt;&lt;span&gt;https://github.com/nyu-dl&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;span&gt;2、compute BLEU score by the multi-bleu.perl:&lt;/span&gt;&lt;a target="_blank" rel="external" style="max-width: 100%; font-size: 14px; box-sizing: border-box !important; word-wrap: break-word !important; text-decoration: underline;"&gt;&lt;span&gt;https://github.com/moses-smt/mosesdecoder/blob/master/scripts/generic/multi-bleu.perl&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 5px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;相关工作&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;1、the standard NMT, Neural machine translation by jointly learning to align&lt;br/&gt;and translate. ICLR, 2015.&lt;br/&gt;2、pseudo-NMT, Improving neural machine translation models with monolingual data. In ACL, 2016.&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 5px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;简评&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;本文的思想很创新，利用了机器翻译中的dual mechinism，仅仅利用少部分双语语料和大部分单语语料就可以达到之前NMT的效果，甚至还高了2到3个百分点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;dual的思想不仅可以用于机器翻译中，还可以用于图片、语音、文字等多种语言的共同学习，这样的相互作用共同学习更接近于人类对周围世界认识的方式，接受来自各个方面的信心，综合进行学习。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 5px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Two are Better than One: An Ensemble of Retrieval and Generation-Based Dialog&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 5px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;作者&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Yiping Song, Rui Yan, Xiang Li, Dongyan Zhao, Ming Zhang&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 5px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;单位&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;北京大学&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 5px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;关键词&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;对话系统、open domain、chatbot&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 5px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;文章来源&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;arXiv&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 5px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;问题&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;对话系统中可将问题和检索的结果同时作为输入Encoder之后进行解码Decoder，再将生成的结果和原检索结果重排序&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 5px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;模型&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a title="" class="" rel="gallery0" style="color: rgb(37, 143, 184); max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgmhIYUdDmxen0BRptpxsLQkNyJYSBBK8Ty07DoKQK2GI1LVq597UPmibticslESsVRvHpxt2SsOPlTA/640?wx_fmt=jpeg"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a title="" class="" rel="gallery0" style="color: rgb(37, 143, 184); max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgmhIYUdDmxen0BRptpxsLQk8dqO9fgSEY8mcn1yXQq1ibm62EEfr4NoUws73DqkyJ2r5rRuIp4ibERQ/640?wx_fmt=jpeg"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 5px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;相关工作&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;a title="" class="" rel="gallery0" style="color: rgb(37, 143, 184); max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgmhIYUdDmxen0BRptpxsLQkGmdHyorQ66rBFbxEhe9WlWicEx6R030FHEQ6Sdx89qQRnicHmHdPU3TQ/0?"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;a title="" class="" rel="gallery0" style="color: rgb(37, 143, 184); max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgmhIYUdDmxen0BRptpxsLQko3YYHGJSV4XfX8d4XAGkL8Tibt7ksBGpSftMVbm1MjnJsIDkYaA6l0w/640?wx_fmt=jpeg"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 5px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;简评&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;作者的思路非常简单，原来的回复生成模型容易发生回复内容短或者回复信息无意义的问题，在此作者将候选结果和原来的问句同时作为RNN生成器的输入，生成结果后再将本次生成的结果加入原检索候选集中，进行重新排序，实验结果证明此种方法比单独使用检索或单独使用生成效果有大幅提升。&lt;/span&gt;&lt;/p&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 5px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; margin-bottom: 5px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;总结&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;新的研究成果不见得可以直接应用于工程中，但新的paper，尤其是高质量paper中，一定会有很多的创新点，每一个创新点都可能会为后续的研究、工程实现等带来启发，甚至是一些技术上的突破。从本期开始，PaperWeekly会不定期地分享类似的内容，以方便大家了解最新的研究成果。感谢&lt;strong&gt;@memray &lt;/strong&gt;&lt;strong&gt;@积翠如云 &lt;strong&gt;@chunhualiu&lt;/strong&gt;&lt;/strong&gt;和&lt;strong&gt;@tonya&lt;/strong&gt; 四位童鞋的辛勤工作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;【查看链接请点&lt;span&gt;&lt;strong&gt;阅读原文&lt;/strong&gt;&lt;/span&gt;】&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;广告时间&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;PaperWeekly是一个分享知识和交流学问的学术组织，关注的领域是NLP的各个方向。如果你也经常读paper，也喜欢分享知识，也喜欢和大家一起讨论和学习的话，请速速来加入我们吧。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;微信公众号：PaperWeekly&lt;/span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgkSMlEJFo90NY8rCXr3mJMBibduVHxMKSHzQtVkHz8kNwpjCKBiccGuqLE0WpPuAbdtEs6cTF5iabpAQ/640?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;微博账号：PaperWeekly（&lt;/span&gt;&lt;a target="_blank" rel="external" style="max-width: 100%; font-size: 14px; box-sizing: border-box !important; word-wrap: break-word !important; text-decoration: underline;"&gt;&lt;span&gt;http://weibo.com/u/2678093863&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&amp;nbsp;）&lt;br/&gt;微信交流群：微信+ zhangjun168305（请备注：加群 or 加入paperweekly）&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Sat, 12 Nov 2016 12:23:24 +0800</pubDate>
    </item>
    <item>
      <title>重磅 | 信息提取重大进展，MIT利用强化学习从外部网络抓取数据</title>
      <link>http://www.iwgc.cn/link/3458796</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自MIT&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Larry Hardesty&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：杜夏德、蒋思源&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;在上周以计算语言协会主办的自然语言处理实证方法大会（EMNLP）上，来自 MIT 的计算机科学与人工智能实验室研究者们凭借一个颠覆传统机器学习的信息提取新方法获得了最佳论文奖。点击阅读原文下载此论文。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;互联网上有大量有价值的信息是开放的，大部分都是纯文本形式的。回答无数问题所需要的数据——包括，特定化学物质的工业使用与疾病事件之间的关联，或者新闻报道模式与选民投票结果之间的关联——或许全都在网上。但是要从纯文本中提取并组织这些数据然后进行分析可能会非常耗时。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;信息提取——或者自动分类数据项以纯文本储存起来——是人工智能研究的一个主要课题。在上周以计算语言协会主办的自然语言处理实证方法大会（EMNLP）上，来自 MIT 的计算机科学与人工智能实验室研究者们凭借一个颠覆传统机器学习的信息提取新方法获得了最佳论文奖。大多数机器学习系统依靠结合训练样本和对应的人类注解者提供的分类运行。例如人类可能为一组文本中的部分语音打上标签，机器学习系统会尝试识别解决歧义的模式——例如，当「her」是一个直接宾语以及当「her」是一个形容词时。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一般来说，计算机科学家会尝试用尽可能多的数据来训练机器学习系统。这通常会更有可能得到一个能处理棘手问题的系统。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相比之下，MIT 的研究者们在数据不足的情况下训练系统——因为在他们正在调查的这种情况下，这些已经他们可用的所有数据了。他们发现信息有限这个问题很容易解决。「在信息提取中，通常是在自然语言处理中，你有了一篇文章，你需要对这篇文章做任何能从中提取正确内容的事情，」该论文的另一个作者 Regina Barzilay 说。「这与你或我会做的事情都不同。当你阅读一篇你无法理解的文章时，你会上网搜一篇你能理解的」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;信度提升&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;基本上，这些研究者的新系统做的是同样的事情。一个机器学习系统会大概会为每一个分类分配一个置信度得分，这是统计学上的一个度量，用于测量分类正确的可能性，因为模式是从数据中得出的。用了这些研究者的新系统，如果信度得分太低，该系统自动生成一个网络搜索查询，然后从这些新文本中的一个文本提取相关数据，随后调和结果与最初的提取内容。如果置信度依然很低，它会移到下一个由搜索字符串抓取的文本。这个过程会一直持续下去。「这个基础提取器是不变的，」MIT 电子工程与计算机科学系的研究生 Adam Yala 说到，他也是这篇论文的合作者。「你会发现对于这个提取器来说，有些文本比较容易理解。所以如果你有一个非常弱的提取器，你就只管让它自己适应着从网络上找数据好了。」论文的第一作者 Karthik Narasimhan 补充道，他和 Yala 来自同一个系。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;值得一提的是，该系统做的每一个决定都是机器学习的结果。该系统学习如何生成搜索查询，测量一个新文本与其提取任务相关的可能性，并确定出用于融合多次尝试提取的结果的最佳策略。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;唯有事实&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在实验中，研究者将他们的系统应用到两个提取任务，一个是搜集美国群众枪击事件数据，这是研究枪支管制影响的基本资料。另外一个是收集食品污染实例数据的任务。这两个任务是独立地训练其机器学习系统。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在第一个案例中，群众枪击事件的数据库是要求将枪手的名字、枪击事件发生地点、受伤及死亡人数都提取出来。在食品污染案例中，需要提取出来食品类型、污染类型和污染地点。每一个系统大约都是由 300 个文档训练出来。而对于这些文档，系统通过学习检索项目集群从而倾向于连接那些想要提取出来的数据条目。例如，群众枪击事件的枪手姓名总是和「警察」、「指认」、「被捕」和「被控」等词汇相关。在训练的过程中，系统要分析每一篇文章，平均来说它从每个网页提取 9 到 10 篇新闻文章。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;研究者比较了他们的系统与用更传统的机器学习技术训练出来的几个提取器的表现。在这两个任务提取出来的每个数据条目中，新的系统要比以前的好得多，通常情况下效果要好 10%。宾夕法尼亚大学计算机科学助理教授 Chris Callison-Burch 说：「自然语言困难之处在于你能通过很多不同的方式表达相同的意思，建立语义理解模型的困难也在于要捕捉到所有这些变化。Barzilay 和她同事们的模型已经有这种超级智能的部分，它能够自己去查询可以让学习过程变得更加简单的信息。这非常智能并能得到充分地执行。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Callison-Burch 的团队正在使用结合了自然语言处理和人类评论的系统建立一个枪支暴力信息数据库，这一点很像 MIT 所训练的系统。「我们已经爬取了数百万新闻文章，然后通过分类器提取出和枪支暴力相关联的文本文章，随后我们再手工进行信息提取，如果能有一个像 Regina 那样的模型，我们就可以通过它预测已经标注的文章是否与之相关，这将节省我们非常多的时间，这也就是未来我很兴奋去做的一件事情。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;论文：Improving Information Extraction by Acquiring External Evidence with Reinforcement Learning&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWic8TSoHeibFWzUS6NyeZBv4dcjXicydSicA2uCkexElpTTicRpljWFTlgh641gYbfsicpoxjhITiaXBUTwQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：&lt;/span&gt;&lt;span&gt;大部分成功的机器学习提取系统在运行时都可以访问一个大型文件集。在这项研究中，我们探索了获取并结合外部证据来提升多个训练数据稀少的域中的提取精确度。这个过程需要发布搜索查询，从新的来源中提取数据，并对提取的值进行调和，这一过程一直重复到收集到足够的证据为止。我们使用了一个强化学习框架，在这个框架中我们的模型会基于情境信息学习去选择最优的行动。我们还应用了一个 Q-network，训练它来优化一个奖励函数，这个奖励函数反映了提取精确度的同时还会惩罚额外的工作。我们在两个数据集上做了试验，一个是枪击案件，一个是食品掺假情况，证明了我们系统的表现显著优于传统的提取器，以及一个极具竞争力的元分类基线。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译文章，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Fri, 11 Nov 2016 13:00:53 +0800</pubDate>
    </item>
    <item>
      <title>深度 | 机器学习中的并行计算：GPU、CUDA和实际应用</title>
      <link>http://www.iwgc.cn/link/3458797</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自KDnuggets&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Matthew Mayo&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀、李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;如果机器学习任务无法使用并行处理，那么经济价值就无法得到体现，但是并行可能是一件比较麻烦的事。这篇文章对基于 GPU 的并行和 CUDA 框架进行了介绍性的概述，并且还谈到了作者对实际实现并行的一些想法。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;传统上（不管这里的传统到底是什么意思），机器学习是在一个单处理器环境中执行的，其中算法的瓶颈可能会导致模型处理过程中出现极大的延迟——从训练到分类、再到距离和误差计算等等。除了最近对神经网络训练的利用，许多机器学习（包括 scikit-learn 这样现成的库和开发者自己实现的算法）都没有使用到并行处理。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这种并行处理（在这里是指在共享内存架构上的并行执行）的缺乏妨碍了我们使用大量并发式执行的线程（concurrently-executing threads），这些线程可以分别执行不同的任务以实现有经济价值的性能表现。缺乏并行性的原因是多种多样的，其中至少有一点是：并行编程（parallel programming）很难。事实也确实如此。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWic8TSoHeibFWzUS6NyeZBv4dU9UXNBVicPk74DYxWgxdEql5e8jKILcXMFH5eaiaI8DGibyNhlv4Fd8Fg/0?wx_fmt=gif"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 1：并行问题的大概形式&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当然，并行处理不是万能魔法，并不是对每一种情形都适用；另外在将并行处理整合进某个项目中时，还要考虑实际和理论上的算法设计问题。但是，因为大数据（Big Data）包含了非常大量的数据，其相关的问题也正越来越依赖于常规的机器学习，所以考虑到并行可能在算法执行的时间节省等问题上所带来的价值，其所可能具有的麻烦就是值得我们去面对的了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;在图形处理器（GPU）上的通用计算&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在适当情况中最常用的并行以及这篇文章的重点是使用图形处理单元上的通用计算（GPGPU），这种方法是利用现代高端图形处理器（GPU）的大量处理内核来同时执行计算成本高的任务。尽管并非所有的机器学习任务（或其它软件任务的集合）都受益于 GPGPU，但毫无疑问目前已有大量的高计算成本和高时间成本的任务可以享受到 GPGPU 的优势。修改算法以使其中一些特定的任务可使用 GPU 并行能够为任务的性能表现和完成速度带来显著的提升。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWic8TSoHeibFWzUS6NyeZBv4dlwevYRh3USQU1bTgaAiaXxeQzx9XBTbm5EozBQbfRN1fERVxTn6pXRA/0?wx_fmt=gif"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 2： Flynn 分类法。左上：单指令流单数据流（SISD）；左下：多指令流多数据流（MISD）；右上：单指令流多数据流（SIMD）；右下：多指令流多数据流（MIMD）&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;GPGPU 范式符合 Flynn 分类法中的「单程序多数据（SPMD）」架构，这不同于传统的多核 CPU 计算范式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWic8TSoHeibFWzUS6NyeZBv4dbVZXUkOIO3iaYoexP0OoJb1fdPb7w1zUC1IcQIX89vxkuC8dZF8Zwag/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 3：MIMD 的单程序多数据（SPMD）分支&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;应该指出的是，尽管这些修改无疑能有利于处理非常大的数据集（这就是大数据（Big Data）的意思），但它们的实现对小得多的数据也能有很好的效果。一些特定的任务可能不管数据大小如何，其计算成本和时间成本都很高。将这些并不必需串行处理的任务并行化也能在小数据上带来好处。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器学习算法还可以通过并行处理具有许多相同算法的常见任务来实现性能提升，比如执行矩阵乘法（许多分类任务会用到）、回归、聚类技术、以及特别有价值的线性回归。对于这种在任务执行延迟上的理论加速，还需要说明的一点是：Amdahl 定律说明在整个任务的执行上的理论加速会随着每个系统的资源的增量提升而增加。但是，不管整体的提升幅度如何，理论上的加速都会受到不能受益于并行改进的任务组分的限制。所以它存在一个极限，就像木桶只能装符合最短木板的那么多水一样。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;要更深入地了解通用并行计算，请参考来自劳伦斯利物摩尔国家实验室 Blaise Barney 的详细介绍《Introduction to Parallel Computing》：https://computing.llnl.gov/tutorials/parallel_comp/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;CUDA 并行编程框架&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;来自英伟达的 CUDA 并行编程框架是 GPGPU 范式的一种特定的实现。CUDA 曾经是 Compute Unified Device Architecture（计算统一设备架构）的缩写，但英伟达放弃了这种解释，现在就仅使用 CUDA。这种架构可以使用通过 GPU 加速（GPGPU 的另一种说法）的机器学习并行化，它需要特别的条件才能有效地管理可用资源和提供最大化的执行速度增益。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;CUDA 在技术上是一种异构计算环境，也就是说它利用了同时在 CPU 和 GPU 上的协调计算。CUDA 架构由主机（host）和设备（device）组成；其中主机是指传统的 CPU，而设备则是指带有大量算术单元的处理器，通常是 GPU。CUDA 提供了传统编程语言的扩展（CUDA 捆绑的原生语言是 C，但也移植或加入了许多其它语言）、可以创建核（kernel，核是指并行执行的函数）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当一个核被加载时，它会被大量 CUDA 设备的线程同时执行，其中的某个集合可以被称为一个线程块（block of threads），块可以集聚为网格（grid）。线程在块中被排布成三维布局的形式，然后块又在网格中被排布成三维的形式。图 4 给出了这些关系和布局。一个核（kernel）所部属的线程、块和网格的总数量是由该核被加载的主机上所执行的程序员的代码所策略性地规定的，这要基于给定的情况的要求。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;重要的是，主机和设备都有自己的内存空间，这些空间是彼此独立的。一个 CUDA 设备只有一个全局内存空间。加载核和产生大量用于计算的设备线程的首要条件是将所需的数据从主机复制到设备内存。一旦计算完成，还必须按相反的方向将结果复制回去。这都是通过 CUDA 扩展来实现的，并且从程序员的视角来看，这都发生在一个非常抽象的层面上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当管理设备的内存时，给核分配正确的块是很关键的；太少会导致计算能力缺乏，而太多的话则会浪费线程——多余的线程可以被分配给其它同时执行的核。举个例子，在 k-fold 交叉验证建模过程中，这可能会导致分配给特定 fold 的的线程太少，从而导致比预期耗时更长的验证过程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相对地，这也可能导致在 k-fold 交叉验证建模过程中分配了过多的线程，从而让很多线程无法得到使用，进而延长了所有 fold 完成它们的模型验证所需的时间。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;幸运的是，设备内存（包括被分配给块和最终的核的线程的数量）的管理是可以被用户定义的（但存在上限，比如每个块最多 1024 个线程）。CUDA 也提供了将这种管理半自动化的聪明方法，让内存管理函数可以将数学表达式用作参数，这样就可以，比如说，在执行的核就能计算出一个数组或矩阵这样的数据结构的大小，然后分配适合其计算的内存大小和维度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWic8TSoHeibFWzUS6NyeZBv4dWfPphSWSJlywbufodx4P1LDnS6EneWtZTI0r9pKyFmgMYsxchAOuzg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 4： CUDA 网格组织&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们提倡并行化的线性回归的一个方面是矩阵乘法——考虑一下矩阵乘法及其在 CUDA 架构上的实现。不考虑矩阵的大小，在高层面上我们假设在设备全局内存中有两个矩阵 M 和 N 相乘，另外还有用于结果矩阵 P 的空间。然后我们将矩阵 M 和 N 复制到设备。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了简单，我们假设所有矩阵都可以放进一个块中，我们每个块线程都能计算 P 的一个元素。要完成这个计算，每个线程都载入 M 的一行和 N 的一列，计算出点积并将其存储为 P 的对应元素。因为每一个点积都是并行计算出来的，那么其执行矩阵乘法的总时间就是其执行单个点积计算所用的时间。计算完成后，矩阵 P 被从设备内存复制回主机内存，其在这里可以继续被串行代码使用。通常情况下，这样的一次核运算之后，设备内存会解除分配（deallocation）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是一个高层面的概述。在实际情况下还需要执行一些额外的任务，比如确定块的大小。这也是一个简单的特定案例；但是尽管这种内存管理和设备计算技术必定根据算法的不同而会有所不同，但也可在多种不同的任务之上概括成：确定可并行化的计算、分配设备内存、复制数据到设备、执行并行化的计算、复制结果回主机、继续执行串行代码。注意这里的内存分配和数据复制开销可能会很容易变成瓶颈——这些过程可能会妨碍某些计算时间上的节省。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;机器学习中的算法应用&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;给定适当的数据、算法实现的知识，结合自己的意图，你就能在机器学习中的并行处理上进行无限的尝试。当然，就像前面提到的那样，确定代码的并行部分是最难的任务，在给定的算法中就没这种问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一个比较好的起始点是矩阵乘法，就像上面一样，它是实现线性回归算法的很好的方法。在 GPU 上实现线性回归可参加论文：Performance improvement of data mining in Weka through GPU acceleration。该论文注重对速度的增加，而且提出了一些对概念化并行算法的其他洞见。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一个机器学习中使用的、已经成熟的并行任务是距离计算（distance calculation）。欧几里得距离是在大量算法上反复计算所需的一个非常常见的度量，包括 k-值簇。因为逐个迭代的单独距离计算不依赖于同一迭代的其他计算，这些计算可并行进行（如果我们不将内存管理的花费作为统筹的瓶颈。）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWic8TSoHeibFWzUS6NyeZBv4diarbQYBETBSnjtkQ8We6nBTTic5FjvSrkCib2xaFMgicXkSqSBzyLBkdbg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 5：k-fold 交叉验证&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然上面提到的这些统计任务可能从执行效率上得到好处，还有机器学习数据流的其他方面可能产生更大的收益。机器学习模型验证中使用的一个常见的评估手段是 k-fold 交叉验证，涉及到密度，不需要数据集分割的连续处理。k-fold 交叉验证（k-fold cross-validation）是模型建立的确定性方法（deterministic method），通过省去数据集的一个 k 分割片段进行验证，或者说是 fold。在所有的 k-1 分割上训练，并使用剩下的第 k 个分割片段测试。然后重复这一过程 k 次，结合所有的预测误差结果并在一个混合模型中进行平均。这种方法提供了可变性，可以尽可能的产生最准确的预测模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在顺序进行这一模型验证时，相对来说有些耗时间，特别是在每个 fold 都配对一个计算成本昂贵的算法任务时，比如线性回归矩阵相乘。k-fold 交叉验证是预测给定机器学习算法误差率的标准方法，试图来增加验证的速度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对 Python 使用的考虑超出了算法设计的范围，涉及到优化本地代码和相比于并行实现的运行时间，这超出了本文的讨论范围。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在任何情景下都能利用无限的计算资源需要算法上的思考，这与机器学习没什么不同。有了明智的思考，深入了解自己想做什么，再加上工具集和文档，你想象不到自己能做到哪一步。并行计算、GPU 和传统机器学习会成为你的好朋友。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译文章，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Fri, 11 Nov 2016 13:00:53 +0800</pubDate>
    </item>
  </channel>
</rss>
