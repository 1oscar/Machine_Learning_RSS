<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>机器之心</title>
    <link>http://www.iwgc.cn/list/670</link>
    <description>人与科技的美好关系</description>
    <item>
      <title>深度 | 谷歌增强型风格迁移新算法：实现基于单个网络的多种风格实时迁移（附论文）</title>
      <link>http://www.iwgc.cn/link/3247856</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Google Research&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Vincent Dumoulin、Jonathon Shlens、Manjunath Kudlur&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李亚洲、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;pastiche 是一个法语词，它的意思是将一件艺术品模仿另一件艺术品的风格（请不要与看起来和它接近的更幽默的希腊源词 parody 混淆）。尽管这种方法已经在视觉、音乐和文学等艺术领域被使用了很长一段时间，但 pastiche 直到最近才在 Reddit 网络论坛（https://www.reddit.com/r/deepstyle/）上将大众的注意力吸引到了给图像染上著名画作的风格的任务上。通过使用一种叫做风格迁移（style transfer）的技术，用户可以通过手机或网页应用让他们自己的图片带上著名艺术作品的风格。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尽管用户已经能通过当前的技术得到美轮美奂的 pastiche 了，但我们觉得我们可以将其做得更吸引人。目前，每一种画作都有它自己的独特风格，也就是说：用户提供一张内容图像，选择一种艺术风格，然后得到一张 pastiche。但如果我们能结合多种不同的风格，探索著名艺术家风格的独特混合从而创造出一种完全独特的 pastiche 呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;学习艺术风格的表征&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在我们的论文《A Learned Representation for Artistic Style》中，我们介绍一种可以让单个深度卷积风格迁移网络（deep convolutional style transfer network）同时学习多种风格的简单方法。该网络在学习了多种风格之后可以做到 style interpolation（风格插补），其中 pastiche 可以平滑地从一种风格变成另一种风格。我们的方法也能实现实时的风格插补，让其不仅可以应用于静态图像，还可应用于视频。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;iframe class="video_iframe" data-vidtype="1" style="   z-index:1; " height="375" width="500" frameborder="0" data-src="https://v.qq.com/iframe/preview.html?vid=d0340au56y5&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0" allowfullscreen=""&gt;&lt;/iframe&gt;&lt;/em&gt;&lt;/span&gt;&lt;em style="color: rgb(136, 136, 136); line-height: 1.75em;"&gt;&lt;span&gt;扮演者：Google Brain 团队办公室的狗 Picabo&lt;/span&gt;&lt;/em&gt;&lt;span&gt;&lt;em&gt;&lt;br/&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在上面的视频中，多种风格被实时地结合到了一起，最后得到的风格通过一个单风格迁移网络（single style transfer network）得到了应用。其用户可获得 13 种不同的绘画风格，可以通过滑块调整最终风格中这些风格的相对强度。在这个演示中，该用户是产生该 pastiche 的一位活跃的参与者。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;风格迁移简史&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尽管将一张图像的风格迁移成另一张的风格的技术已经存在了近 15 年时间 [1][2]，但利用神经网络来做这件事还是最近才出现的，而且这很吸引人。在论文《A Neural Algorithm of Artistic Style》，研究者 Gatys、Ecker 和 Bethge 介绍了一种使用深度卷积神经网络（CNN）分类器的方法。其 pastiche 图像是通过优化（optimization）找到的：该算法会寻找一张给出了该 CNN 的底层中同种类型激活（activation）的图像，这些底层会获取风格输入（宽笔触和立体美感等等）的整体粗糙美感；该算法还会在更高层产生激活，这是获取能使对象可被识别出来的东西，这接近于那些由内容图像所得出来的东西。从某个起始点（如：随机噪声或内容图像本身）开始，该 pastiche 会逐渐细化直到这些要求都得到满足。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9ud9Ce5mvD8vXXnwE6wtH7FXl0TjqY2cgXict45vYD7zHictjrSIfh1kI4gZ47Qpgu0Y7ttooMsjbw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;内容图像：Andreas Praefcke 拍摄的 Tübingen Neckarfront；提供风格的画作：Georges Rouault 的「Head of a Clown」&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过这个算法生成的这个 pastiche 看起来很壮观（spectacular）：图片来自 L. Gatys et al. "A Neural Algorithm of Artistic Style" (2015).&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9ud9Ce5mvD8vXXnwE6wtH7IC5VE6SOaTBmwq4ibtotHMfbmntRtQ2hJV4s8IwGSU0s8ZeHXcogtAQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该成果被认为是深度学习研究领域的一项突破，因为它首次提供了基于神经网络的风格迁移的概念证明。不幸的是，这种为单张图像施加风格的方法对计算的要求很高。比如说，在网络上首次可用的演示中，用户需要将图片上传到一个服务器，然后还要等上足够喝一杯咖啡的时间才能得到结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;后续的研究 [4,5] 为这一过程提速了不少，这些研究认识到可以将这个优化问题转变成图像变换问题（image transformation problem），其希望将单个固定的风格应用到任意一张内容图像（比如一张照片）上。然后该问题就可以这样被解决：训练一个前馈的深度卷积神经网络来调整内容图像的 corpus 以使之匹配某画作的风格。这个训练出的网络有两重目的：保持原有图像的内容，同时匹配绘画的视觉风格。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这样得到的最终结果是：一旦在一张静态图像上花了几分钟后，就可以实时运行了（例如，将风格迁移应用于实时视频）。但是，实现实时风格迁移的速度提升是有代价的——一个给定的风格迁移网络只能固定于一种单一画作的风格，失去了一些原来的算法的灵活性，因为原来的算法并不固定于任何一种风格。这意味着：如果要开发一个能够建模 100 幅画的风格迁移系统，就需要训练和存储 100 个单独的风格迁移网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;我们的贡献：学习并结合多种风格&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们开始于对印象派时期的许多艺术家的观察，采用类似的笔触和调色板。此外，说到莫奈的画，视觉上更是相似。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9ud9Ce5mvD8vXXnwE6wtH7PdZj9hUXXlLGeXmpBXib5UGYLBmn2g9Zp3YzicZsbVAED8Uh7U4MiczhA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Poppy Field (左) 和 Impression, Sunrise (右) by Claude Monet&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们在机器学习系统的训练中用到了这一观察。也就是，我们训练一个能够捕捉且概括众多莫奈作品、或者其他流派不同画家作品的单个系统。产生的 &lt;span&gt;pastiche &lt;/span&gt;足以媲美之前工作产生的画，同时源自同样的风格迁移网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9ud9Ce5mvD8vXXnwE6wtH7QPanSDuj6JxCcrbibLRMNia7WsTGyqqXY98ia6AXR7GSOAJosZ1bRo10Q/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;由我们的单网络产生的 &lt;span&gt;pastiche &lt;/span&gt;实在 32 个不同的风格上训练得到的。这些画质量上等同于由单风格网络创造的作品。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们开发的该技术简单易部署，也不需要密集的存储。此外，我们的网络在数个艺术风格上进行训练，允许实时结合多个绘画风格，就像文中视频展示的那样。下面就是 4 种风格按不同比例结合的成果：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9ud9Ce5mvD8vXXnwE6wtH70qy0tMKiafOoGEZLT8nnPDAqibhKwDNuGmFsrSFKddeyhtCaDrHibFB8g/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不像之前快速迁移风格的方法，我们认为这种同时建模多种风格的方法开启了一种让用户与风格迁移算法交互的新方式，不仅是允许基于多个风格的混合进行自由创造，而是这个过程是实时的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;关于该算法的细节和运行该模型的 TensorFlow 源代码将在未来发布。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;论文：A Learned Representation For Artistic Style&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：绘画风格的多样性对构建图像而言代表丰富的视觉词汇。如果不是通常画像，学习或捕捉这些视觉词汇的程度表达出了我们对更高层次绘画的理解。在此研究中，我们调查了如何构建单个、可延展深度网络，能够贪婪的捕捉不同派别的艺术风格。我们证明这样的网络能够通过将一种绘画降低到到嵌入空间的一个点，从而概括不同的艺术风格。重要的是，该模型允许用户通过任意结合单个绘画的风格来探索新的绘画风格。我们希望这项研究能够为迈向建立丰富的绘画模型提供帮助，也希望在艺术风格表征学习的建构上提供一个窗口。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;References&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[1] Efros, Alexei A., and William T. Freeman. Image quilting for texture synthesis and transfer (2001).&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[2] Hertzmann, Aaron, Charles E. Jacobs, Nuria Oliver, Brian Curless, and David H. Salesin. Image analogies (2001).&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[3] Gatys, Leon A., Alexander S. Ecker, and Matthias Bethge. A Neural Algorithm of Artistic Style (2015).&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[4] Ulyanov, Dmitry, Vadim Lebedev, Andrea Vedaldi, and Victor Lempitsky. Texture Networks: Feed-forward Synthesis of Textures and Stylized Images (2016).&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[5] Johnson, Justin, Alexandre Alahi, and Li Fei-Fei. Perceptual Losses for Real-Time Style Transfer and Super-Resolution (2016).&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 27 Oct 2016 12:10:56 +0800</pubDate>
    </item>
    <item>
      <title>深度 | NVIDIA CEO黄仁勋解读智能工业革命：基于GPU的深度学习大爆炸</title>
      <link>http://www.iwgc.cn/link/3247858</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Nvidia&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：黄仁勋&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：武竞、王旭雯、杜夏德&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;随着深度学习的兴起，支持大规模并行计算的 GPU 已经成为人工智能发展的重要硬件基础。作为 GPU 行业的领军者，NVIDIA 公司最近以来一直在推动应用于机器学习的 GPU 技术的发展和创新。近日，NVIDIA 联合创始人兼 CEO 黄仁勋（Jen-Hsun Huang）在 NVIDIA 博客上发表了一篇题为The Intelligent Industrial Revolution（智能工业革命）的文章，解读了自己在最近的 GPU Technology Conference（GTC）会议上的所讲所学所见以及对计算发展的未来的看法。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;过去六个星期，NVIDIA 搞了一个世界巡回的开发者大会。GPU 技术大会（GTC）于 2009 年开始，旨在促进使用大规模并行处理的 GPU 来开发高性能计算的新方法。GTC 已经成为 GPU 深度学习的中心——这个新的计算模型引发了现代人工智能的大爆炸。人工智能正在像野火一样蔓延。GPU 深度学习开发者的数量在短短两年内就跃升了 25 倍。已经有大约 1500 个人工智能创业公司出现。这种爆炸式增长刺激了世界各地对 GTC 大会的需求。到目前为止，我们已经在北京、台北、阿姆斯特丹、东京、首尔和墨尔本举办过活动。华盛顿定于本周举办大会，孟买定在下个月举办。我参加了其中 4 场 GTC 大会的开幕式。人工智能是下一个计算浪潮，给一个又一个行业带来了革命，关于它，下面是我在大会上的所讲所学，以及我对不久未来看法的总结。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9ud9Ce5mvD8vXXnwE6wtH7LrG8TV2htQzm8ay0O3Xh2nvlwFty8Blic9TvhbKxSicqPQO7qhMvbgBA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;计算的新时代&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;由人工智能计算机驱动的智能机器可以学习、推理和与人互动已经不再是科学幻想的场景。今天，由人工智能驱动的自动驾驶汽车可以找到路，并曲折地穿过夜间的乡村道路。人工智能机器人可以通过反复尝试来学习运动技能。这是一个不同寻常的时代。在我 30 年的计算机行业生涯中，没有什么比这个有更多潜力、更有趣的了。人工智能的时代已经开始。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;计算机行业推动了大规模的工业和社会变革。随着计算机行业的发展，成立了新公司，创造出新产品，我们的生活因此而改变。回顾过去几轮计算浪潮，每一个背后都有革命性的计算模型来支撑，在当时，这个计算模型架构扩展了计算能力和计算范围。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 1995 年，PC-Internet 时代是由低成本微处理器（CPU），标准操作系统（Windows 95）和一个新的信息门户（Yahoo!）的集成引发的。PC-Internet 时代给大约十亿人带来了计算能力，实现了微软将「计算机放在每一个桌子和每个家庭」的愿景。十年后，iPhone 在我们的口袋里放了一个「互联网通信」设备。加上亚马逊 AWS 的推出，Mobile-Cloud 时代诞生了。大量应用程序走进我们的日常生活，有约 30 亿人因此享受移动计算提供的自由。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今天，我们站在下一个时代的开端，人工智能计算时代，被一个新的计算模型——GPU 深度学习——点燃。这种新模型——其中深层神经网络被训练以识别大数据中的模式——已被证明能「不可理解的」高效解决计算机科学中的一些最复杂的问题。在这个时代，软件可以自己编写，机器可以自己学习。不久之后，数以亿计的设备将注入智能。人工智能将彻底改变每个行业。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;GPU 深度学习「大爆炸」&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为什么是现在？我在早前的博文（「Accelerating AI with GPUs: A New Computing Model」）中提到，2012 年将是人工智能标志性的一年。多伦多大学的 Alex Krizhevsky 创建了一个深度神经网络，能够从一百万个样本中自动学习识别图像。在 NVIDIA GTX 580 GPU 上仅仅用了几天的训练，「AlexNet」就赢得了那一年的 ImageNet 比赛，打败了所有人类专家磨炼了几十年的算法。同一年，在意识到更大的网络、更大的大脑、更多的学习之后，斯坦福大学的吴恩达和英伟达研究院（NVIDIA Research）组队开发使用大型 GPU 计算系统来开发训练神经网络的方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9ud9Ce5mvD8vXXnwE6wtH7kZ99Bw0Wgk7icWjaribVOm1LPWAE4GibHhkgClRubCUj3wqeicwfFb5X6A/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;世界开始关注到这一点了。各个地方的人工智能研究者都转向了 GPU 深度学习。百度、谷歌、Facebook 和微软最先用它来进行模式识别。到了 2015 年，他们开始实现「超人类」的结果——一台计算机识别图像的能力比人类还要高。在语音识别领域，微软研究院（Microsoft Research）使用 GPU 深度学习使对话语音达到了和人类相同的水准，实现了历史性的里程碑。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图像识别和语音识别——GPU 深度学习已经为机器学习、感知、推理和解决问题提供了基础。GPU 的使用从模拟人类想象引擎开始，魔术般地跳跃到视频游戏和好莱坞电影中惊人的虚拟世界里。现在，英伟达的 GPU 能够运行深度学习算法，模拟人类智能，作为计算机、机器人和自动驾驶汽车的大脑，感知并理解这个世界。就像人类想象和智能是连在一起的一样，计算机图形和人工智能在我们的架构中也是一同运作的。人脑有两种模式，GPU 也有两种模式。这或许就解释了为什么英伟达的 GPU 被广泛用于深度学习，英伟达也逐渐成为大家熟知的「人工智能计算公司」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;一种用于新计算模型的端到端平台&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;作为一个新的计算模型，GPU 深度学习正在改变软件的开发过程和运行方式。过去，软件工程师创造了程序并精心编码算法。现在算法能从成堆的现实世界的例子学习，软件可以自己编写出来。编程实际上是编码指令，深度学习就是创建和训练神经网络。这个网络可以被部署到数据中心，通过学习大量新数据来执行推断（infer）、预测和分类工作。网络还能被部署到如相机、汽车和机器人之类的智能设备中来理解世界。有了新的经验后，新数据会被收集来进一步训练和精炼这个网络。从数十亿的设备中学习能让网络上的设备变得更加智能。神经网络会收益于 GPU 处理和大型网络效应的指数增长。也就是说，它们会以一种比摩尔定律更加快的方式变得更加聪明。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9ud9Ce5mvD8vXXnwE6wtH7HnbI7iaQmwJYeicnFEXRYBA3EdFib1FhbMC6Fgpxic6czEEe3lkJsyCoibw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;旧有的计算模型是「指令处理」密集型的，而这种新的计算模型须要海量的「数据处理」。为了推进人工智能的全面进展，我们正在建立一个端到端的人工智能计算平台，一个能够跨越训练、接口以及数十亿设备的架构很快就会出现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们从训练开始。我们的新 Pascal GPU，投入 20 亿美元，动用了数千名工程师，花了三年时间才弄好。它是第一台用于深度学习的经过优化的 GPU。Pascal 训练的网络比 Kepler GPU（Alex Krizhevsky 在这篇论文中使用的 [1]）训练的网络要大 65 倍，而且速度更快。一个单一的配备 8 个 Pascal GPU 与 NVLink 连接的计算机，创造了有史以来吞吐量最高的互连，训练网络的速度比传统的服务器快 250 倍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9ud9Ce5mvD8vXXnwE6wtH7fsM8jAsFfVwjY2b3bz9RyN7uhXTfgU4ugUnJjkjoWibzAsD9p7mwDYA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;很快，每天数百亿个来自互联网的请求（queries）都会需要人工智能，也就意味着，每个请求将需要超过数十亿词数学运算。云服务上的总装载量需要足够大以保证实时响应。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有了更快的数据中心推理性能，我们发布了 Tesla P40 and P4 GPUs。P40 将数据中心的推理吞吐量加速了 40 倍。P4 仅需要 50 瓦的电源，设计用于加速 1U OCP 服务器，典型的超大规模数据中心。软件是英伟达深度学习平台中重要组成部分。在训练上，我们有 CUDA 和 cuDNN。在推理（inference）上，我们发布了 TensorRT，一个优化的推理引擎。TensorRT 通过在一个层内和跨层融合操作，修剪低贡献权重，降低 FP16 或 INT8 的精确度，以及其他多个技术，在不影响精度的情况下，提升了性能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;终有一天，数十亿个智能设备会利用深度学习来实现看似智能的任务。无人机会自动导航飞到仓库，寻找并拿到特定的物品。便携的医药器械会利用人工智能当场检测血液样本。智能相机能够学会仅在我们关心的情景中提醒我们。我们创造了高效能的人工智能超级计算机，Jetson TX1，应用到那些智能物联网设备中。只有信用卡大小的模块，Jetson TX1 可以仅用 10 瓦的电源，达到 1TeraFLOP FP16 的工作性能。它和我们最强大的 GPU 拥有相同的构架，并且可以运行所有相同的软件。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;简单地说，我们提供了一个端到端的人工智能计算平台——从 GPU 到深度学习软件和算法，从训练系统到车内的人工智能计算机，从云到数据中心到 PC 到机器人。NVIDIA 的人工智能计算平台无处不在。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;适用于所有领域的人工智能计算&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们端到端的平台是保证每个领域都能接入人工智能的第一步。NVIDIA GPU 深度学习下的全球生态系统正在快速扩张。突破性的成果引发了一场将人工智能运用到消费者网络服务的竞争——搜索、识别、推荐、翻译以及更多。云端服务供应商，从阿里巴巴、亚马逊，到 IBM 和微软，让大大小小的公司都用上了 NVIDIA GPU 深度学习平台。全球最大的企业技术公司已经在基于英伟达的 GPU 配置服务器。很高兴能够在我们的 GTC 巡回中强调我们在重要领域中的战略：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能交通：交通是一个人工智能可以改变的，价值 10 万亿美元的产业。无人驾驶车辆可以减少事故，提升卡车和出租车的效率，使得新的移动服务成为可能。我们宣布百度和 TomTom 均选择 NVIDIA DRIVE PX2 用于无人驾驶车辆。对它们每家公司，我们都会建立一个包含高清地图，人工智能算法和人工智能超级计算机的「云端-车」的平台。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;驾驶是我们学习获得的第二天性，但我们目前还不能让计算机学会开车。无人驾驶要求每个方面都能做到人工智能——感知环境，合理地决定环境的状态，计划行动的最佳过程。同时，也持续学习以提升对于这个多样化世界的认识。大范围的无人驾驶需要一个开放的，可升级的构架——从高速路上自动巡航，到自主驾驶到目的地，到没有司机的全自动公共汽车。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9ud9Ce5mvD8vXXnwE6wtH7PccPIbgHiacVlX6cxC3U0ciaBpdc1lqShb5bfhHF3kMlIpCqw2LjLrbA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;NVIDIA DRIVE PX2 是一个用于自动驾驶的可升级架构，包含了整个范围的人工智能技术。在 GTC，我们发布了 DRIVE PX 2 AutoCruise 专为高速公路上自动驾驶设计，带有持续定位和地图。我们还发布了 DriveWorks Alpha 1，我们无人驾驶车上的操作系统几乎涵盖了无人驾驶的所有方面——侦查，定位，计划路线，行动。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们将所有的功能集中在我们的无人驾驶车 NVIDIA BB8 上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;NVIDIA 着重在视觉处理的交叉点的创新，以及人工智能和高性能的计算——一个在智能和自主的机器核心的特殊结合。这是第一次，我们有了让无人驾驶车辆和自主机器人成为可能的人工智能算法。但它们需要一个实时的，有成本效益的计算平台。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 GTC，我们介绍了 Xavier。Xavier 是我们有史以来做过的最有雄心的单片机，是世界第一个人工智能超级计算机芯片。Xavier 有 7 亿个晶体管——比起最先进的服务器级别 CPU 更复杂。但神奇的是，Xavier 和今年早些时候在 CES 发布的 DRIVE PX 2 有相同的马力——每秒钟 20 万亿次深度学习的操作——仅用 20 瓦的电源。像 Forbesnoted 一样，我们加倍生产了带有 Xavier 的无人驾驶车。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;人工智能企业&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：IBM，一个在认知计算领域看到价值二十亿美元机会的公司，发布了新 POWER8 和 NVIDIA Tesla P100 服务器，它们均是为将人工智能带入企业而设计的。在软件上，SAP 声称他们已经收到了了 2 台第一批的 NVIDIA DGX-1 超级计算机，并正在为 190 个国家的 320，000 个消费者建立机器学习的企业解决方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;人工智能城市&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：到了 2020 年，世界上将会有 10 亿台相机。Hikvision 是全世界检测系统的领导者，它正在运用人工智能让我们的城市更加安全。它用 DGX-1 进行网络训练，现已在 16 Jetson TX1 中央处理器上建立了一个突破性的服务器，叫做「Blade」。Blade 只需要基于 21 个 CPU 的服务器的 1/20 的空间和 1／10 的能量就可以达到相同的性能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;人工智能工厂&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：在全球范围内已有 20 亿左右的工业机器人。日本是机器人创新的中心。在 GTC，我们宣布 FANUC，一个日本的工业机器人巨头，将会在 NVIDIA 人工智能平台上建造一个端到端的未来工厂。它的深度神经网络将由 NVIDIA GPU 来训练，GPU 驱动下的 FANUC Fog 单元将控制一群机器人，让他们能够共同学习。每个机器人都会植入 GPU，使之成为实时人工智能。麻省理工技术评论对他的故事这么写到：「日本的机器人巨头为它的武器加上了大脑」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;创业公司的爆发是人工智能横扫各个产业的又一指示。Fortune 最近写到，深度学习会「改变美国的大公司」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9ud9Ce5mvD8vXXnwE6wtH7dR8B1mKFedIv4S8msicYlA4b83t41NCYSALiaSsvMlDd6Fprxv7I880g/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能可以提前解决我们能力范围外的问题。从现实生活中的数据，计算机可以学会认识那些对于人工编写的软件甚至是人来说太复杂、太巨大或太微小的图案。通过 GPU 深度学习，这个计算机模型现在已经被熟练应用在解决世界上最大的产业的问题上。无人驾驶汽车将会改变 10 万亿美元的交通运输业。在医疗保健上，医生可以使用人工智能帮助你更早发现疾病、或是了解人类基因组的奥秘去治疗癌症、又或是从大量的药物数据和研究中学习，向你建议最好的治疗方法。人工智能会开创第四次工业革命——继蒸汽机、大规模制造和自动化之后——智能机器人会引领巨大的生产力提高的新浪潮，为大规模客户定制化提供了可能。人工智能将会触及每一个人。人工智能的时代已经到来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 27 Oct 2016 12:10:56 +0800</pubDate>
    </item>
    <item>
      <title>业界 | Yoshua Bengio创立孵化器Element AI：助力深度学习学生创业</title>
      <link>http://www.iwgc.cn/link/3247860</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自连线&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：CADE METZ&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李泽南&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9ud9Ce5mvD8vXXnwE6wtH7lH1FicKPW2dTWRibsJWGqayUUDkD5b8rEfV549WuaFWjHk2EibswSWyHw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Y&lt;/span&gt;&lt;span&gt;oshua Bengio，深度学习背后最重要的推动者之一，刚刚宣布在蒙特利尔创立了一个硅谷式的创业孵化器，他希望以此发展这种最具影响力的人工智能形式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这家孵化器名为 Element AI，旨在帮助来自蒙特利尔大学和 McGill 大学的创业者们在人工智能领域施展拳脚。Bengio 目前任蒙特利尔大学计算机和运筹学院教授，他表示这一努力是在蒙特利尔开发人工智能生态的一部分。Bengio 希望他的努力能在硅谷之外开创一个科技新领域，他认为这座城市已聚集了全世界深度学习领域最为尖端的研究者，其研究成果已经在谷歌、Facebook 和微软这样大公司的产品中得到了广泛应用。「Element AI 将帮助创业者们在这块神奇的土地开展事业，他们将获得我和我的专家团队的帮助，我们将指引这些新生企业进入正确的轨道。」Bengio 说道。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;根据 Bengio 介绍，目前约有 100 名研究人员在蒙特利尔大学研究深度学习，同时约有 50 名科学家正在 McGill 大学做着类似的工作。这样的数量是否首屈一指还有待商榷——欧洲也是此类研究的温床——但蒙特利尔在深度学习的重要地位毋庸置疑。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;上周，微软研究人员发布了识别准确率超过人类的英文语音识别系统。当从电话语音中转录音频时，系统出现的误差少于人类专业速记员。这一成果表明深度学习在过去五年有了长足进步。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过使用深度神经网络，进行大量数据学习的硬件和软件网络，谷歌，IBM 和百度这样的科技巨头已将语音识别发展到近似人类的水平。而类似的技术让这些公司和他们的竞争对手们已经建立起了面部识别和图像特征识别系统。深度学习正在迅速地重塑一切，从机器翻译到谷歌搜索引擎背后，无不存在它的身影。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;深度学习起源于一个不大的学术圈子，其中的大部分研究者现在已经成为各家科技公司的骨干。该流派的创始人之一 Geoff Hinton 现在正为谷歌工作。另一位先驱，Yann LeCun，在 Facebook 领导人工智能实验室。近年来，硅谷的巨头们收购了一家又一家深度学习初创企业。其中最为引人注目的就是谷歌收购的 DeepMind，这是一家来自伦敦的科技公司，今年已经使用深度学习等技术攻克了古老而又复杂的围棋。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Hinton，LeCun 和 Bengio 是深度学习的三驾马车，他们自 20 世纪 80 年代到本世纪初孜孜不倦地探索这一领域，尽管在一开始，很少有人意识到这种技术蕴含的潜力。在深度学习广为人们所知以后，Bengio 并没有随前两人进入科技公司，他一直专注于学术。微软人工智能研究者黄学东称他为「一位伟大的教育家」，这也是深度学习界为他打上的绰号。Bengio 现在可以利用他在 IBM 顾问身份，和刚刚启动的 Element AI 架起一道桥梁，让深度学习的研究成果通向商用领域。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这一举措的重要性毋庸置疑。如今，深度学习领域的研究人员仍然稀少，硅谷巨头们正在争抢这些人才，激烈程度远超其他领域的工程师。去年，这一竞争达到了巅峰，OpenAI，一家由艾隆·马斯克资助的初创公司，从谷歌和 Facebook 挖走了多名人工智能研究骨干。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Bengio 的孵化器对于研究者而言同样重要——它有点类似于 YC——因为它可以消除人工智能专家对需求和产品的距离。「在深度学习领域，有大量的研究人员可以熟练地构建强大的算法，但却并不总是知道如何处理真实世界的各种问题，」深度学习初创企业 Skymind 创始人 Chris Nicholson 说道，「这些天才需要获得一点点指导。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于那些获得了正确指导的研究者，他们拥有技术的价值对于市场而言不可估量。深度学习目前只能应用于部分大型公司。而且只有相当数量的研究者参与其中。我们也许很快就将看到孵化器带来的新风向。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;span&gt;	&lt;/span&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 27 Oct 2016 12:10:56 +0800</pubDate>
    </item>
    <item>
      <title>前沿 | 机器学习破解基因密码：斯坦福大学开发出鉴定致病性基因突变的新工具（附论文）</title>
      <link>http://www.iwgc.cn/link/3247861</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自斯坦福&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Erin Digitale&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：曹瑞、李泽南&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2012 年，Shayla Haddock 的医生对她所患的一种罕见的遗传疾病进行了测试，但是他们没办法确诊。畸形足、身材矮小、不正常的面部特征和先天性耳聋等症状将伴随她一生——这使得她的医生怀疑这是由基因突变造成的。但是对于像 Shayla 一样的孩子来说，在 30 亿 DNA 碱基对当中找到致病基因是非常困难的。在基因测序之后，几乎每一个病例都需要一位训练有素的基因学家花 20-40 小时来分析。并且大约有 75% 的患者在第一次尝试中没办法被确诊。&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9ud9Ce5mvD8vXXnwE6wtH7mKRzBgq7K2OrPmqyNVkG5plxZliars2dibiadV3g4oon6jsH6n8GmGHtQ/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;斯坦福的一些计算机科学家最终解决了 Shayla 的困境，他们设计了一种自动化的方式，将患者的症状和变异基因与已有的遗传疾病数据库中的信息作对比。2016 年初，他们发现 Shalya 所患的疾病早些年在医学文献当中报道过。而在两周前，Shayla 的医生仍然不能告诉她的家人病因到底为何。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在，这个斯坦福大学的科研团队，在计算机科学家、基因学家、哲学博士 Gill Bejerano 的带领下，在病情诊断方面的发展又进了一步。他们研制出了一种更加精细的工具，可以自动评估遗传密码中单个字母的错误。这种新工具叫做 M-CAP，他们的研究论文已发布在今天的《Nature Genetics》上，这个团队使用了一种机器学习的算法，根据是否有可能致病性基因突变进行分类。这项成果的全部细节已公布在网上，以供全世界的遗传学研究人员使用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「纵观人类基因中的各种可怕变异，有数以万计的变化可能会导致严重的儿童早期疾病。而这些变异和与健康人基因当中的变体相比是非常不一样的。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他解释道，最基本的问题是，每个人的基因密码中合成蛋白质的部分都有 1 万个小光点或者说是变体，这些 DNA 中的每一个碱基对都与正常的人类基因序列不同。几乎所有的这些光电都是无害的。但是在那些从出生就有一些难以解释的症状的孩子身上，我们有足够的理由相信是由于一个或者两个基因上的变化才引起了他们的疾病。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在他们的评估当中，遗传学家们试图将一个到两个最有可能导致疾病的基因变体归零。比如说，他们会忽略那些在普通人群中非常普遍的基因变体，因为我们相信这些罕见的疾病都是由一些罕见的基因突变引起的。他们已经人工将需要评估的基因变异列表减少到每位患者 300 种左右。M-CAP 让这个列表更加精简，大约每位患者 120 种基因变体，Bejerano 的团队希望随着遗传疾病研究的推进，这个列表可以更加的更精确。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;非常重要的一点是，M-CAP 要比以往自动分类基因变体的方式更加精确。传统的方式会将四分之一到三分之一的致病基因变体错误的标记为无害。M-CAP 出现这种错误的几率只有 5%。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Bejerano 说：「我们挑战是要尽力将这个基因变体的列表减少到最短，并不仅仅包括哪些罕见、没有潜在功能的基因，还有所有存在危险性的基因。」「但更重要的是，我们不能告诉患者致病的基因突变是良性的。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;论文：M-CAP精确消除临床外显子组中大量意义未定的基因变体&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：变体致病性分类器例如 SIFT、PolyPhen-2、CADD 和 MetaLR 通过优先确认良性突变，有助于在典型患者基因组中解释数百个罕见的错义突变（missense variants）。目前广泛使用的分类器对于已知的致病突变有 26% 至 38% 的错误率，这些方法如果在临床中应用可能会导致误诊。我们开发了 M-CAP，一种临床致病性分类器，它在所有方面优于目前的方法，同时可以在典型基因组中以 95% 灵敏度正确排除 60% 的罕见的、不确定的错义突变。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 27 Oct 2016 12:10:56 +0800</pubDate>
    </item>
    <item>
      <title>重磅 | 亿万词汇构建神经网络，Facebook提出语言模型训练新算法</title>
      <link>http://www.iwgc.cn/link/3231915</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Facebook Research&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Edouard Grave、Justin Chiu、Armand Joulin&amp;nbsp;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：杜夏德、武竞&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Facebook 人工智能研究（FAIR）设计出一种新式的 softmax 函数逼近，专用于 GPU，帮助其在语言模型的基础上通过巨量词汇来有效训练神经网络。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;由于在语音识别、机器翻译或语言建模等领域的优异表现，用于序列预测的神经网络最近重新获得关注。然而这些模型都需要巨量的计算，这反而限制了它们的应用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在语言建模领域，最近的研究进展用到了海量的大型模型，这些大型模型只能在大型 GPU 集群上训练，并且一次需要几周时间。这些处理密集型工作很棒，也有利于探索大型计算基础设备，但这些计算设备对于学术界来说通常十分昂贵，投入生产也不实际，以至于限制了研究的速度、再生产能力和结果的可用性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;意识到这种计算上的瓶颈，Facebook 人工智能研究（FAIR）设计出一种新式的 softmax 函数逼近，专用于 GPUs，帮助其在语言模型的基础上通过巨量词汇来有效训练神经网络。我们的方法叫做自适应 softmax（adaptive softmax），利用不平衡词分布形成簇（cluster），这种簇能明确地减少对计算复杂度的期望，从而规避对词汇量的线性依赖。这种方法通过利用流行架构的特殊性和矩阵-矩阵向量运算（matrix-matrix vector operations）进一步减少了训练和测试时的计算成本。这使得它特别适合于 GPU，而以往的方法，如分层 softmax，NCE 和重要性采样，都是为标准的 CPU 设计的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;FAIR 也开发并正在开源一个名为 torch-rnnlib 的库，这个库允许研究者设计出新的循环模型并在 GPU 上以最小的代价测试这些原型（prototypes）。它也允许通过绑定 torch.cudnn 无缝对接快速基线。几个标准循环网络，如 RNN、LSTM 和 GRU 都已经被部署进来，下面我们将展示如何利用这个库来设计一个新的循环网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些工具和技术后来被一起用来应对标准基准，如 Euro Parl 和 One Billion word，这些都是因需要使用巨大的词汇量而复杂的训练环境，让我们无法在 GPU 上拟合一个大模型和 full softmax。结果显示我们在单一的 GPU 上每秒能处理 12500 个单词，通过标准逼近，大大提升了效率，减少了从试验到结果的时间，同时得到的精确度接近于 full softmax 的精确度。这就能让学界和业界的工程师与研究者都能在短时间内在资源有限的情况下训练出最好的模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;利用 torch-rnnlib 建立一个循环模型&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;循环模型的定义有很多，我遵循的是这一条：循环网络随着离散时间对变量序列建模。它遵循马尔可夫的属性，其未来的状态只取决于它的现状。最简单的循环模型是 Elman 的循环模型。根据当下的输入变量 x[t] 以及之前的状态，在每个时间步骤 t，就会输出一个 y[t]。更确切的说，Elman 的循环模型可以通过下面的等式来定义：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;h[t] = f(R * h[t-1] + A * x[t]),&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;y[t] = B * h[t]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其中，h 代表网络（隐藏的）内在的状态，f 是 sigmoid 函数。Elman 之后就有人提出了更复杂的循环模型，如 LSTM、GRU 或者 SCRNN。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;什么是语言模型？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;语言建模的目的是在一个给定词典中的一个词序列上学习一个概率分布。该联合分布被定义为给定状态下的词的条件分布的一个乘积。确切地说，一个 T 词序列 w[1],...,w[T] 的概率被给定为的 P(w[1],..., w[T])) = P(w[T]|w[T-1],..., w[1])...P(w[1]).&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个问题通常由基于计数统计的非参数模型解决（详见 Goodman, 2001）。最近，基于循环神经网络的参数模型在语言建模上才流行起来（例如，Jozefowicz 等人, 2016，obtained state-of-the-art performance on the 1B word dataset）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;如何用 Torch-rnnlib 建立一个标准的模型&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们给出了用于建构带有循环连接的三个不同的 API：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1.nn.{RNN, LSTM, GRU} 接口可以用来建构在所有层都带有相同数量隐藏单元的循环网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWib9ezqHLusWxfqaFozVbpOR2AFKnxJYlaWAJmZCKEOCHQfc884T05Wsr0VGyrVCcwaN26DBbZh2xw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2.rnnlib.recurrentnetwork 的接口能用于构建任意形状的循环网络。上一个和这个接口都为你考虑到了节省隐藏状态。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWib9ezqHLusWxfqaFozVbpORFG3iaa76HYUibpohBz3GoOhAewicg2lwvpRFFxRUePf8SmYHYeAiaECQMg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3.nn. SequenceTable 接口能用来将计算像一个『scan』一样链接起来。nn. RecurrentTable 构建器（constructor）仅仅是一个轻量级的封装，能随着时间为你克隆循环模块。然而，要注意的是这是最低层级的接口，你还需要 rnnlib.setupRecurrent(model, initializationfunctions) 来设定循环隐藏状态行为。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWib9ezqHLusWxfqaFozVbpORvwF1DZicDGhjbfRCQHkk9QMvfNv9sW5IlmEy7ZvPj2xbbhxPjDWbQNA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;建立你自己的循环网络&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你也可以通过定义一个行为像 cell 那样的函数来创建你自己模型，以及一个类似于这个 cell 状态的初始化函数。&lt;/span&gt;&lt;span&gt;在 rnnlib.cell 中有预定义的 cell，如 LSTM、RNN、和 GRN。下面来看看如何一步步建立一个 RNN：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWib9ezqHLusWxfqaFozVbpORNqibQXqHuKibllnNKP6yC2Qhn8HobjVV6A002ZZdbnamduP9bSdxwyfQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;在 GPU 上训练它&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;既然 torch-rnnlib 连着 nn 模块接口，仅需要在模型上调取：cuda（）就能将它拉进 GPU。rnnlib 的目的是允许用户自由创建新 cell，或者使用快速基线。这样就 OK 了，如果你在上一节中使用第一或第二个 API 来构建循环网络，就可以轻松使用 cudnn 来大大加速你的网络。对于 nn.{RNN, LSTM, GRU} 接口，仅需要用 usecudnn=true 就能调取这个建构器（constructor）：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWib9ezqHLusWxfqaFozVbpOR09L1hvicAic8mGCQqHZS8G8mibibofGuLUIJOQsicK9c9dXbop0WcyYm5VQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于第二个 API，仅需要将 rnnlib.Recurrent 替换成 rnnlib.makeCudnnRecurrent 并将 cell 函数改为 cudnnAPI 中已有的一个 cell 串。例如：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWib9ezqHLusWxfqaFozVbpORm0gfOLXuqqp5ITooun7ibTCRuFjN0YICNNkjHma2KvZX0qF39qQAN7Q/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最终的结果通常是，模型的循环部分至少能提速两倍。要注意的是，不是整个模型提速两倍，尤其是如果大部分计算不是在循环部分中时。例如，如果你的模型中有一个 softmax，比循环部分需要更多的计算，那最终速度可能只提升 1.3 倍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWib9ezqHLusWxfqaFozVbpORzX2KNAT3z4aXia2HGIVw4bEPibZxAMK8OakbhjUc6SJ1sicsicNqia7icmUA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Adaptive-Softmax：为 GPU 定制的 softmax 近似模型&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当处理大输出空间（如语言模型）时，分类器（classifier）可能是模型的计算瓶颈。过去已经提出了许多解决方案（分层 softmax（hierarchical softmax），噪声对比估计（noise contrastive estimation），差分 softmax（differentiated softmax）），但是它们通常被设计用于标准的 CPU，并且很少充分利用 GPU 的特性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们研究出了一种新的近似方法，叫做自适应 softmax（adaptive softmax）：一个使其计算载荷量（computational budget）适应数据分布的 softmax。它通过更快地访问最常用的类（class），为它们提供更多的资源，来达到优良的近似效果和快速运行时间之间的平衡。更准确地说，它学习了一个 k-通道（k-way）的层次 softmax（hierarchical softmax），它考虑了 GPU 的架构以有效地分配计算。这种计算资源的分配可以使用一个简单的动态规划算法来精确求解。几个技巧可以进一步处理分类器的计算负载问题：我们使用分枝少的树（shallow tree）来避免顺序计算（sequential computation），并且我们为每个 GPU 集群（cluster）确定类（class）的最小值，以避免浪费 GPU 的并行计算能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;正如表格 1 中显示的，自适应 softmax 几乎可以与完整 softmax（full softmax）的结果相媲美，并且自适应 softmax 速度更快。它也优于 GPU 运行的其他近似模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWib9ezqHLusWxfqaFozVbpORz9IejxHa3nrWLqjv2vtK74ziaBHgyx2aibpibaqQHXYlDWax9066xvyaQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;表格 1. 使用 Text8 的模型结果比较。ppl 值越小越好。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWib9ezqHLusWxfqaFozVbpORwesiajeX3PA4dRwka5STtHxEX7Fic4iaYFlg06HibmnuE7DrSEXBWwtLJg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图. 语言模型在不同 softmax 近似模型上的收敛效果。它建立在 LSTM 模型之上。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;10 亿单词数据集在单个 GPU 上几天内达到了值为 45 的困惑度值&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除自适应 softmax（adatpive softmax）外，在技术细节方面，我们使用相对标准的设置：对于小模型，我们使用层数为 1、2048 个神经元单位的的 LSTM；对于大模型，我们使用层数为 2、2048 个神经元单位的 LSTM。我们使用 L2 正则化（regularization）的权重和 Adagrad 来训练模型。我们使用大小为 128 的批处理（batch），同时设置反向传播（back-propagation）窗口的大小为 20。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;关于自适应 softmax，我们使用 10 亿单词的训练数据集分布的最佳设置，即 4 个 GPU 集群（cluster），每用一个集群，数据的维数减少 4 倍（更多细节详见论文）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWib9ezqHLusWxfqaFozVbpOR4osX6tZgAj9CFTzROL7YAhqicbAShxhncWe3akXIdLOQwMJXFnibNCeA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;表格 2. 使用 10 亿数据集的模型 perplexity 值比较（值越小越好）。注意到 Jozefowicz 等人用了 32 个 GPU 训练，我们只用了 1 个 GPU。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;正如表格 2 中显示的，我们的小模型在几天内就达到了 43.9 的 perplexity 值。我们的大模型在 6 天内达到了 39.8 的 perplexity 值。目前最好的 perplexity 值（越小越好）是 30.0，由 Jozefowicz 等人在 2016 年达到。这个结果是他们用 3 周的时间，使用了 32 个 GPU 达到的。他们也声称使用 18 个 GPU 训练的更小模型，达到了数值为 44 的 perplexity 值。我们的小模型的速度为 180 毫秒/批，并在一个迭代（epoch）后（迭代时间大约为 14 小时）达到数值为 50 的 perplexity 值。不使用 cuDNN 加速库，小模型的速度为 230 毫秒/批，这比之前只慢了 30%。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 26 Oct 2016 11:51:05 +0800</pubDate>
    </item>
    <item>
      <title>重磅 | 微软开源Microsoft Cognitive Toolkit深度学习工具包，加入强化学习元素</title>
      <link>http://www.iwgc.cn/link/3231916</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Microsoft Blog&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Allison Linn&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀、李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;今天，微软宣布发布了 Microsoft Cognitive Toolkit 的更新版本，这是一个用于深度学习的系统，可用于加速 CPU 和 NVIDIA GPU 上的语音和图像识别以及搜索相关性等领域的发展。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;项目地址：https://github.com/microsoft/cntk&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个工具包之前被称为 CNTK，最早是由微软一些想要更快更高效地做自己的研究的计算机科学家开发的。它很快就超越了语音领域并演变成了一个产品，包括一些领先的国际家电制造商和微软的旗舰产品组（flagship product groups）在内的客户依靠它来执行各种各样的深度学习任务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;微软 Artificial Intelligence and Research 部门首席科学家和 Microsoft Cognitive Toolkit 的一位关键架构师 Frank Seide 说：「我们将其从一个研究工具变成了可以用在产品之中的东西。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWib9ezqHLusWxfqaFozVbpORUYUibYw9b58SIewX24IbTXaBXKICw6jwhmetNQ0Raa4f5Iw4jKic2esg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Frank Seide&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该工具包的最新版本现已通过一个开源证书发布到了 GitHub 上，其新增功能包括对 Python 和 C++ 编程语言的支持。研究者还可以使用这个新版本开发一种叫做强化学习（reinforcement learning）的人工智能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，该工具包的性能也优于之前的版本。它也比其它工具包更快，尤其是当需要跨多台机器运行大数据集时。为了开发消费者产品和专业产品，这种大规模部署对跨多个 GPU 的深度学习来说是必需的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这也是加速研究突破的关键。上周，&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719843&amp;amp;idx=1&amp;amp;sn=0c6387d422cf9765b9b10c178d160680&amp;amp;chksm=871b021db06c8b0b0b0447124c5c07818f53a17ba470305049af1d7d49806c87e07307a93811&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719843&amp;amp;idx=1&amp;amp;sn=0c6387d422cf9765b9b10c178d160680&amp;amp;chksm=871b021db06c8b0b0b0447124c5c07818f53a17ba470305049af1d7d49806c87e07307a93811&amp;amp;scene=21#wechat_redirect"&gt;微软 Artificial Intelligence and Research 宣布在识别对话上已经达到了人类的水平&lt;/a&gt;。这个团队将实现这一里程碑背后的巨大速度提升归功于了 Microsoft Cognitive Toolkit。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;开发了这个微软工具包的团队说其跨多服务器工作的能力是超过其它深度学习工具包的关键优势。当这个微软工具包被用于解决更大型的数据集时，可以实现更优的性能和准确度。Microsoft Cognitive Toolkit 有内置的算法来最小化这种计算的退化（degradation of computation）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「使用 Microsoft Cognitive Toolkit 的一个关键理由是其可以针对大型数据集跨多 GPU 和多机器进行有效地扩展，」微软合作伙伴工程经理 Chris Basoglu 说，他在该工具包的开发中扮演了一个关键的角色。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWib9ezqHLusWxfqaFozVbpOR7UFoq8bHqGHeAZiaSxLAo1Zcjbeg6CWZm1y6CyNvM2iaTTiamkDicQ6AHQ/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Chris Basoglu&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Microsoft Cognitive Toolkit 可以轻松处理从相对较小到非常非常大等各种规模的数据集，既可以在一台笔记本上运行，也可以运行在数据中心中的一系列计算机上。它可以运行在使用传统 CPU 或 GPU 的计算机上；GPU 以前主要的用途是处理对图形要求较高的视频游戏，后来人们发现可以用它来非常高效地运行深度学习所需的算法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「Microsoft Cognitive Toolkit 代表着微软和 NVIDIA 紧密合作以为深度学习社区带来进步，」NVIDIA 的 Accelerated Computing Group 总经理 Ian Buck 说，「和以前的版本相比，在扩展到一个 NVIDIA DGX-1™ 中的 8 个 Pascal GPU 之后，其性能几乎提升了两倍。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Microsoft Cognitive Toolkit 是为在多个 GPU 上运行而设计的，包括 Azure 的 GPU 产品，该产品目前还是预览版。该工具包已经经过了优化，可以最好地利用 NVIDIA 硬件和 Azure 产品的网络功能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;民主化人工智能及其工具&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当小型创业公司和大型科技企业都看到了深度学习的使用对语音理解和图像识别的可能性时，我们发布了该工具。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;广义上讲，深度学习是一种需要用到大量数据（被称为训练集）的人工智能技术，从而能教会计算机系统学会识别图像或声音等输入中的模式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;比如说，可以用一个包含了各种水果和蔬菜图片的训练集来训练一个深度学习系统，之后该系统能学会自己识别水果或蔬菜的图片。它获得的数据越多，它的表现就会越好；所以每次当它遇到一个新的、长相奇怪的茄子或扭曲的苹果时，它都可以调整自己的算法以使其变得更为准确。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWib9ezqHLusWxfqaFozVbpORwibnllspnDiaWMib5EhpZ00A2aictNwtBYm31gzGo3HNAdumHZaPMpuDJw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;在使用 Microsoft Cognitive Toolkit 训练语音声学模型中，随着应用更多的数据，它能收敛出更高的准确率。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这类的成果不只是研究的里程碑。由于深度学习的进步，加上计算马力的大幅度增长，我们如今有了像 Skype Translator 这样的消费者产品，能识别语音并提供实时语音翻译。还有 Cortana 数字化助手，能理解语音并帮助你做机票搜索和备忘约会这样的所有事。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;微软首席语音科学家黄学东说，「这就是使用 Microsoft Cognitive Toolkit 民主化人工智能的一个样例。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;更灵活的完成更复杂的任务&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Basoglu 说在他们第一次开发该工具箱的时候，他们发现许多开发者不能或不想写大量代码。所以他们创造出一个自定义系统，能让开发者更简单的配置深度学习系统，不需要额外的代码。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然而，随着该系统变得越来越流行，他们了解到一些开发者想将自己的 Python 或 C++ 代码与该工具箱的深度学习能力结合起来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他们也了解到一些研究人员想要使用该工具箱进行强化学习研究。强化学习是代理通过大量试错直接学习做某些事的一种研究领域，比如在房间中找到线路或合成句子。这类研究可能最终引向真正的人工智能，也就是系统能够自己做复杂的决策。新版本的工具箱就给了开发者做强化学习研究的能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尽管 Microsoft Cognitive Toolkit 最初由语音研究员开发，如今却能被用于多种目的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了给用户提供更好的结果，Bing relevance 团队使用它更好的发现搜索词条相关的隐藏的链接。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;例如，在用户输入「How do you make an apple pie?」的时候，带有深度学习的系统经过训练可自动明白用户在寻找菜谱，即使「recipe」一词并不在搜索词条内。没有这样的系统，这种规则只能手动编程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Bing relevance 团队的软件开发工程师 Clemens Marschner 说，他们团队和该工具箱的创造者们有着非常紧密的合作，从而更好的让开发者做除了语音之外的深度学习任务。对他们而言，所得的回报就是使用大规模的计算能力快速的获得结果。他说，「没有其他解决方案能让我们这么简单的将学习在 GPU 上扩展到大型数据上。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;微软也在不断使用 Microsoft Cognitive Toolkit 改进语音识别。语音服务部门的应用科学经理 Yifan Gong 说，他们已经使用该工具开发出了更准确的声学模型，应用到了包括 Windows 和 Skype Translator 在内的产品中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Gong 说他的团队依靠该工具开发新的深度学习架构，包括使用 LSTM 技术来为顾客导出更准确的结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 26 Oct 2016 11:51:05 +0800</pubDate>
    </item>
    <item>
      <title>前沿 | 脑机接口可以将我们的思想直接翻译成文本吗？（附论文）</title>
      <link>http://www.iwgc.cn/link/3231917</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Science Daily&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：曹瑞、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你曾经有没有想过要是有一个设备能够将你的想法解码成真实的语音或是书面文字的话会怎么样呢？或许这会增强现存的一些设备语音接口的性能，可能会引起语言病理学上的变革，尤其是对于那些没有语言和运动能力的「闭锁综合症」患者来说更是如此。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;《人类神经科学前沿》中一篇评论的作者Christian Herff说道：「所以，我不需要去问『Siri，今天的天气怎么样』或者是『Google，我可以去哪儿吃午饭』，只需要想象我在说这些话就可以」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;读取某人的想法或许还只是存在于科幻小说当中，但是科学家已经可以将我们在说话或者是聆听时大脑中的信号进行解码，生成语音。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Herff 和他的合著者Dr. Tanja Schultz在他们的综述当中，比较了在大脑中使用各种脑成像技术捕捉神经信号，并将其解码为文本的利与弊。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些技术包括功能性磁共振成像（MRI）、近红外成像（能够根据神经元的代谢活动检测到神经信号）、脑电图（EEG）和脑磁图（MEG）（能够检测到与语音相对应的神经元的电磁活动）等。特别是一种叫做脑皮层电图描记法（ECoG）的方法，在Herff的研究之中展现出了很大的发展前景。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这项研究提出了一种大脑到文本（Brain-to-text）系统，这种系统在已经植入了电极网格以便治疗的癫痫病人参与者身上进行了实验。他们将他们面前的屏幕上的文本读出来，同时他们的大脑活动将被记录下来。这就形成了可以将语言音素（或者说是「语音」）与神经信号模式匹配起来的数据库的基础。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当研究者们将语言和词典的模型都运用到了算法当中时，就可以高度精确地将神经信号解码成文本。Herff说道，「这是我们第一次证明可以在大脑信号当中使用自动语音识别（ASR）技术，将大脑活动进行足够准确解码。但是从现在对植入电极的需求可以看出，这项技术还需要很长的时间才能被运用到日常生活当中」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因此，这个领域要是想从现在发展到一个可正常工作的思维检测设备要怎么做呢？ Herff说道：「第一个里程碑应该是要将想象的短语从大脑活动中解码，但是我们还有很多的技术问题有待解决。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个研究的结果虽然非常令人激动，但对于这类型的脑机接口研究来说还只是处于初步阶段。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;论文：神经信号的自动语音识别： 一份焦点评述（Automatic Speech Recognition from Neural Signals: A Focused Review）&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：语音接口目前已经被广泛接受，并且被运用于很多真实生活中的应用和设备当中，它们已经成为了我们日常生活中的一部分。尽管我们认为语音接口能够生成可以理解的语音，但是由于嘈杂的环境、吵闹的旁观者或者是使用者不能说话（比如说患有闭锁综合症的患者），这种能力就会从可能变成不可能。出于这些原因，想象出说话的场景要比真实说话更加可取。基于想象语言的语音接口不需要听得见的声音就能够进行快速、自然的交流，这让因为各种情况不能说话的人都有了发声的机会。这份焦点评述分析了不同的脑成像技术使用自动语音识别技术来识别神经信号中语音的潜力。我们认为基于代谢过程的方式，比如说功能近红外光谱成像和功能性磁共振成像技术，因其低分辨率不适合神经信号的自动语音识别，但在研究语音过程的神经机制中却非常有用。相反，电生理活动能够快速捕捉语音过程，也更适宜运用到自动语音识别当中。我们的实验结果也证明了这些通过无创测量大脑活动（脑皮层电图描记法）产生的信号在神经数据语音识别上的潜力。作为使用神经信号自动语音识别技术的第一个实例，我们对大脑到文本（Brain-to-text）系统进行了讨论。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWib9ezqHLusWxfqaFozVbpORcvLQOClJGbbo602eVT8WdQ3u61TdEOw4vx5JzrPYUttibPTvEna1AjQ/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 1. ECoG 和音频数据同时被记录下来。然后语音解码软件被用于确定声学数据中元音和辅音的时间。然后 ECoG 模型通过计算所有与特定音素（phone）有关联的片段的均值和协方差而为每个音素单独接受训练。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWib9ezqHLusWxfqaFozVbpORJp98otFRAbZcvRyNPnMlnabezHfRj6KI7QdJBXr2t47IlaPS9Hel5g/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图2. Brain-to-text 系统的解码过程。Broadband gamma power 被提取出来用于 ECoG 数据的短语。然后通过结合 ECoG 音素模型的知识、词典和语言模型解码出最有可能的词序列。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，机器之心系今日头条签约作者，本文首发于头条号，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 26 Oct 2016 11:51:05 +0800</pubDate>
    </item>
    <item>
      <title>业界 | IBM推出Watson数据平台，机器学习的力量将无处不在</title>
      <link>http://www.iwgc.cn/link/3231918</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自IBM News&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李泽南&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;IBM 宣称要提供世界最快的数据采集引擎和机器学习服务，加速商务人工智能。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWib9ezqHLusWxfqaFozVbpORT7wVbJRvkYjFvz2DWPLkE5JAcbiawe8RDIWudbIdKXfuRnC4kiauy5sw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今天，IBM 宣布推出 IBM Watson 数据平台，旨在帮助其他公司从数据中获得更有价值的信息。该平台向数据人员提供了世界上最快的数据采集引擎和认知决策，使他们能够在 IBM Cloud 中与他们想要的服务进行协作。IBM 同时启动了 IBM Watson 机器学习服务，通过直观的自助服务界面使机器学习变得简单。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;大数据是让技术人员梦想成真的基础。随着科技巨头间竞争的不断升级，这项技术已经进入每个人的手中，成为了生产力工具。在大数据普及之后，更多想法和创造性的解决方案将不断涌现。在目前「数据第一」的风潮之下，Watson 数据平台的出现让未来变得触手可及。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「机器学习已经变得前所未有的强大，但是目前的数据专业人员缺乏将之充分利用的能力，」IBM 分析师，高级副总裁 Bob Picciano 说道。「Watson 数据平台应用认知辅助来创建机器学习模型，让数据分析的速度更快。它还提供一个访问机器学习服务和语言的接口，使任何人，从应用开发者到首席数据官，可以无缝协作。我们的平台能让数据更有意义，提出更好的问题，做出更有效的决策。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;IBM 副总裁 Rob Thomas 则使用保险公司做了一个简单的例子，向我们解释企业如何通过机器学习变得「更聪明」。「大多数保险公司根据历史数据评价风险，」Thomas 说道。「而我们启用了实时评分系统，使得保险公司编写的每个条款，每个外部因素——所有数据都可以进入模型，同时这个模型实时更新。不同的保险公司会要求不同的保费，一切取决于数据的分析。这是机器学习的本质，也宣告了机器学习的核心技术已能被人们掌握。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;基于 Apache Spark，Watson 机器学习可以从结构化和非结构化数据以及开放式机器学习库中自动构建模型，同时将模型快速部署，为业务运营助力。其专利的数据科学认知辅助技术根据获得的数据对每个机器学习算法进行评分，为满足需求作出最佳匹配。它还包括业界最全面的算法集。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;通过协作扩大人工智能在商务领域的影响&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;根据最近的《哈佛商业评论》调查，80％的组织认为团队无法在共有数据上合作是高效完成业务目标的障碍。数据专业人员在工作时互相独立，使用不同的编程语言，没有相同的关注点，并且不得不将时间浪费在数据收集和清理上。Watson 数据平台有助于解决所有这些问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Watson 数据平台可以使不同专业的数据人员通力合作——如数据科学家，数据工程师，商业分析师和开发者，允许他们在数据集中协同工作，使用他们各自使用的语言，服务和工具。此外，该平台使数据专业人员能够轻松地在整个企业中分享可视化的分析成果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Watson 数据平台利用 IBM 在 Apache Spark，IBM Cloud，认知计算和 The Weather Company 等项目中的成果，并应用了 IBM 研究院开发的多种技术。令数据专业人员有能力：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;以创纪录的速度（大于每秒 1000 亿字节）将大量不同数据导入云中&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;清理，编辑和塑造数据，以方便建模&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;在版本维护时根据需要添加和删除协作者&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;将服务拖放到分析薄中，以提高效率，节约时间&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过基于 IBM Cloud 的 Watson 数据平台，公司可以将自己的数据与外部数据结合使用，利用内置管理来解决流程，隐私和法规要求，同时保持对数据的控制。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Watson 数据平台正在构建一个不断扩大的技术服务生态系统，使数据专业人员能够自由使用自己喜欢的语言和他们需要的服务。IBM 已将 SQL，Python，R，Java 和 Scala 纳入 Watson 数据平台，同时已发展了二十多个合作伙伴，以扩展平台服务，包括：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Qubole——使 IBM Data Science Experience 的用户能够使用 Spark 在他们选择的公共云设备上处理数据；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;RStudio——支持 R 软件包的开发，集成了 R 的现有工具，包括 Shiny 和用于 Apache Spark，sparklyr 的新 R 接口，可快速将数据科学工作流用于生产；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Keen IO——提供了强大的 API 集合，允许数据科学家收集，分析和可视化任何存在于网络中的事件。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「数据专业人员使用各种不同的工具和语言，他们可以在处理数据时自由选择，无论 R，Python 还是 Scala，——他们同时可以使用多种机器学习和可视化服务，他们可以使用任何已知的方式随时随地处理数据」，IDC 分析和信息管理集团副总裁 Dan Vesset 评论道。」IBM Watson 数据平台为数据专业人员提供了一个开放，强大的生态系统，为人们提供了一个易于使用的平台，鼓励人们协同工作。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;目前的服务&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Watson 数据平台将「Project DataWorks」推向市场，并已在 IBM 云的自助服务和企业计划中推出，数据专业人员在已经可以在平台中使用他们需要的工具。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;IBM Watson 机器学习服务将从 Apache SparkML 开始，未来会继续加入其他算法，并且可以通过 Watson Data Platform 访问，作为 IBM Bluemix 或 z/OS 上的 API。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 26 Oct 2016 11:51:05 +0800</pubDate>
    </item>
    <item>
      <title>访谈 | 艾伦人工智能研究所CEO Oren Etzioni：深度学习离人类水平的人工智能还差得很远</title>
      <link>http://www.iwgc.cn/link/3222891</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自SebastianRuder Blog&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Larry Greenemeier&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李亚洲、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Elon Musk 正在全面押注自动驾驶汽车的新计划，他需要强大的人工智能技术来确保特斯拉汽车能够实时理解不同的驾驶情况，并据此实时地做出反应。人工智能正在实现非凡的成就：上周，&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719745&amp;amp;idx=2&amp;amp;sn=242eda88fa9a5572e60b43e451a1549b&amp;amp;chksm=871b027fb06c8b693cff17f43553625f008fcb7965582119b651dbbd17e116e35dc801ebeec3&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719745&amp;amp;idx=2&amp;amp;sn=242eda88fa9a5572e60b43e451a1549b&amp;amp;chksm=871b027fb06c8b693cff17f43553625f008fcb7965582119b651dbbd17e116e35dc801ebeec3&amp;amp;scene=21#wechat_redirect"&gt;AlphaGo 计算机程序的创造者报告&lt;/a&gt;了他们的软件已经学会了像一个伦敦本地人一样在纷繁复杂的地铁线路中导航。甚至就连白宫也来凑热闹了，他们在不久前放出了一份报告，旨在帮助美国为机器能像人类一样思考的未来做好准备。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但已经在研究和尝试解决人工智能的基本问题上工作了几十年的计算机科学家 Oren Etzioni 说：在人们可以或应该将世界交给人工智能接管之前，人工智能还有很长的路要走。Etzioni 目前是艾伦人工智能研究所（AI2）的首席执行官；该组织是由微软的联合创始人 Paul Allen 于 2014 年组建的，该组织的目标是开发人工智能的潜在好处——以及纠正好莱坞乃至其他人工智能研究者鼓吹的人工智能可能威胁人类种族的观念。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;AI2 自己的项目可能并不非常疯狂——比如说他们有一个基于人工智能的学术研究搜索引擎 Semantic Scholar（https://www.semanticscholar.org/）——但他们确实在解决推理（reasoning）等人工智能领域的问题，这将使得这一技术超越 Etzioni 所说的「只在一件事上做得非常好的狭隘的专家」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Scientific American 在纽约最近的一场人工智能会议上对 Etzioni 进行了采访，在采访中他表达了自己对企业过于鼓吹人工智能的当前能力——尤其是被称为深度学习的机器学习技术——的担忧。这个处理过程需要将大型的数据集通过模拟人脑神经网络的网络，以便教会计算机学会自己解决特定的问题，比如识别模式或确定照片中存在的特定物体。Etzioni 还解释了他为什么认为十岁孩童比谷歌 DeepMind 的 AlphaGo 程序更聪明，以及为什么终将需要开发人工智能「卫士」程序来防止人工智能程序变得危险。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9LprWu7eD2xib3jhgiaXmPYWyYlpIvclfEsMzcKOjSgwxPqkibXMs4caOmibV3KFLq9D3yN8FTXaibCnw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Oren Etzioni&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面是经过编辑整理的采访内容：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;在开发最好的人工智能技术上，人工智能研究者前面还有什么鸿沟吗？&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Etzioni &lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;：&lt;/span&gt;一些人已经靠他们自己取得了一点点领先。我们已经在语音识别、自动驾驶汽车（或者说自动驾驶的有限形式）以及当然的围棋等领域取得一些实质性的进展。所有这些都是非常实质的技术成就。但我们该怎样解读它们呢？深度学习无疑是一项很有价值的技术，但在创造人工智能上，我们还有很多其它的问题要解决，其中包括推理（意味着计算机不仅能计算 2+2=4，还能进行理解）和获取可被机器用于创造语境的背景知识。还有另一个例子是自然语言理解。尽管我们已经有 AlphaGo 了，但我们还没有一个能够读懂和完全理解一段话或甚至一句话的程序。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;有人说深度学习是「我们最好的（the best we have）」人工智能技术。那是对深度学习的批评吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Etzioni &lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;：&lt;/span&gt;当你有大量进行了标注以使计算机能理解其含义的数据和大量算力，以及需要找到那些数据中的模式的时候，我们可以发现深度学习是无敌的。再次说到 AlphaGo 的例子，该人工智能程序为了学会在不同情形下的正确走子而处理过 3000 万个棋盘局面。还有很多类似的情形——比如放射图像——其中图像需要被标记为有肿瘤或没有肿瘤，一个经过调节的深度学习程序可被用来确定其之前看过的图片中是否有肿瘤。深度学习方面还有很多的工作要做，而且确实，这是前沿的技术。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;那么问题出在哪里？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Etzioni &lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;：&lt;/span&gt;问题是对于智能，除了有大量可用来训练程序的情况，还有很多其它情况。比如学生准备 SAT 或 New York Regents exams（大学入学考试）这样的标准考试时所用的数据。他们可不能通过考察之前的 3000 万份标注了「成功」或「不成功」的考试来获得高分。这是一个更为复杂的交互式的学习过程。智能还涉及到从建议、对话的语境或阅读书籍中学习。但是同样地，尽管深度学习领域有这些惊人的进步，我们也还是不能得到一个能做到十岁孩童所能做的事情的程序，即：拿起一本书，读一章，然后回答有关读到的内容的问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;为什么人工智能通过标准考试可以成为这项技术的重大进步？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Etzioni ：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;/span&gt;我们艾伦人工智能研究所实际上已经将其作为一个研究项目了。去年我们宣布设立了一个 50,000 美元的奖给任何开发出了能够通过标准的 8 年级科学考试的人工智能软件的人。来自全世界的 780 支团队用了几个月的时间想要达到这一成就，但没有人能够得到超过 60% 的分数——即使那只是 8 年级考试中的多项选择题。这为我们目前所处的现状提供了一个现实的和定量的评估。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;能够正确回答问题的人工智能系统是怎样的？&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Etzioni：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;/span&gt;线索通常在语言之中。最成功的系统使用了经过精心调制的科学文本和其它公共源的信息，然后再使用经过了精心微调的信息检索技术进行搜索以定位每个多项选择题中最好的候选答案。比如，下列物体中最好的电导体是：塑料勺子、木叉子或铁拍子？程序非常善于配对，可以检测到电和铁或导体和铁比塑料和导体远远更常见地共同出现在文档之中。所以有时候程序可以通过这样的捷径找到答案。这差不多也就是孩子们靠已知的信息猜答案的方法了。没有任何系统的得分超过 60%，我可以说这些程序都是在使用统计进行有根据的猜测，而不是对问题进行仔细的推理。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;AlphaGo 背后的 DeepMind 团队现在已经有一个可以使用外部记忆系统超越深度学习的人工智能程序了。他们的成果对创造更像人的人工智能有什么影响？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Etzioni：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;/span&gt;在推动深度神经网络（模拟人脑设计的人工智能）的发展上，DeepMind 将继续作为领导者。这个特定的贡献是很重要的，但也只是在图结构（比如一个地铁网络）中互连的事实上实现推理的一小步。已有的符号程序就可以轻松地执行这样的任务，但这里的成就（已经发表在 Nature 上）是关于神经网络如何根据样本学习执行任务。整体上看，是 DeepMind 的一大步，却是人类的一小步。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;人们可以怎样结合深度学习、计算机视觉和记忆等方法来开发更完整的人工智能？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Etzioni：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;/span&gt;这是一个非常吸引人的概念，实际上当我还是华盛顿大学的一位教授时的很多研究都是基于使用互联网作为人工智能系统的数据库的想法。我们开发了一个叫做开放信息提取（open-information extraction）的技术，它索引了 50 亿个网页，并且可以从其中提取句子并将其映射到机器可操作的知识上。该机器在抓取网页和所有句子上能力超强。问题是这些句子是在文本或图片中。我们人类的大脑有非常强大的能力——我们计算机科学家还没有破解这些能力——可以将那些行为映射到推理等等。为什么这种通用数据库和人工智能接口的想法仍然还是科学幻想呢？因为我们还没有搞清楚如何将文本和图像映射成机器可以用来像人类一样进行操作的东西。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;em&gt;你提到过实现人类水平的人工智能至少还要 25 年的时间。人类水平的人工智能是什么意思？为什么会有这样的时间框架？&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Etzioni：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;/span&gt;真正的自然语言理解、人类智能的广度和通用性、我们既能下围棋也能过马路还能制作好看的煎蛋的能力——这种多样性是人类智能的标志，而我们今天做的只是开发在一件小事上做得非常好的狭隘专家。为了得到这个时间框架，我询问了美国人工智能协会（AAAI）的研究者：什么时候我们将实现在广义上和人类一样聪明的计算机系统？没人说那会在未来 10 年内发生，67% 的人说会在接下来 25 年或更往后，25% 的人说「永远不会实现」。他们可能错了吗？可能吧。但你该相信谁，难道是那些紧握行业脉搏的人？还是好莱坞？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;为什么有如此多备受尊敬的科学家和工程师警告说人工智能会加害我们？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Etzioni：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;/span&gt;我很难推断霍金、Elon Musk 这群人如此讨论人工智能的动机是什么。我猜测可能是黑洞讨论一段时间之后有点无聊了，黑洞是一个慢速发展的主题。我想说的是，在他们以及我极为尊重的比尔盖茨在讨论人工智能会变得邪恶或潜在灾难性后果的时候，他们总是插入「最终」或者「可能」这样的限定符。这我是同意的。如果我们讨论千年以后或无限的未来时，人工智能有可能为人类带来末日吗？当然是有可能的，但我认为这种对未来的讨论不应该分散我们对人工智能与就业、人工智能与武器系统这样真正问题的注意。而且「最终」、「概念上」这样的限定符在转译时往往会丢失。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;在人工智能有缺陷的情况下，人们应该担心汽车制造商对自动驾驶汽车不断扩大的兴趣吗？&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Etzioni：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;/span&gt;我对没有方向盘或刹车踏板这样的自动驾驶汽车没有多大兴趣。以我对计算机视觉和人工智能的了解，我对这种汽车相当不舒服。但我是复合系统的粉丝，例如，在你开车瞌睡时它能为你踩刹车。司机加上自动系统要比任何单独一个都更安全。然而这并不简单，将新科技融入到人类生活与工作中不是件容易的事。但是，我不确定融合新科技的解决方案就是让汽车做所有的事。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;谷歌、Facebook 和其他科技巨头最近合作建立了 Partnership on Artificial Intelligence to Benefit People and Society (https://www.partnershiponai.org/) 组织为人工智能研究设定最好的道德实践。是不是人工智能技术已经发展到足够的程度了，让他们能进行有意义的对话？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Etzioni：&lt;/span&gt;&lt;/strong&gt;世界上顶级的科技公司聚到一起想这些事是非常好的思路。我想他们如此做是为了应对人工智能将掌管世界的担心。很多对人工智能的担心完全过分了。即使我们有自动驾驶汽车，也不是说 100 辆车就聚到一起说是要，「拿下白宫」。Elon Musk 这群人提到的风险即使不是百年之后也是数十年之后的事。而且，我们存在一些真正的问题：自动化、数字科技和一般的人工智能真的在影响就业场景，无论是机器人还是其他情景，这才是真正的担心。自动驾驶汽车、卡车将来是会大幅度的改进安全性，但也会影响大量依靠驾驶为生的工人。该新组织应该讨论的另一件事是人工智能可能造成的歧视。如果人工智能技术被用于处理贷款或信用卡应用，他们会以合乎法律与道德的方式来做吗？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;你如何保证人工智能项目会合乎法律与道德的进行？&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Etzioni：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;/span&gt;例如你有一家银行，有处理贷款的软件项目，你也无法隐藏在软件的背后。说计算机这么做的并不能成为一个借口。即使计算机项目不使用种族或性别作为明确变量，它也可能有歧视行为。因为计算机项目会接触大量的变量、大量的统计数据，它可能找到邮政编码与其他变量之间的关系，这些关系会构成种族或性别变量的替代。如果它使用这种替代变量影响到决策，就会造成问题，而且人们难以检测或追踪缘由。所以我们提议的思路是人工智能卫士（AI guardian），也就是监测、分析基于人工智能的贷款处理程序的系统，从而保证程序随时间进化时能遵循法律、合乎道德。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;如今有人工智能卫士的存在吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Etzioni：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;/span&gt;我们正在向社区呼吁开始研究并建立这种东西。我认为如今可能有一些琐碎的存在，但这是目前一个很大的愿景。我们想用人工智能卫士的思路反击一直以来认为人工智能是邪恶的整体力量的普遍场景，就像终结者这样的好莱坞电影传播的那样。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 25 Oct 2016 19:37:26 +0800</pubDate>
    </item>
    <item>
      <title>技术| 词嵌入系列博客Part3：word2vec 的秘密配方</title>
      <link>http://www.iwgc.cn/link/3222892</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自SebastianRuder Blog&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Sebastian Ruder&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：Terrence L&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;本文是词嵌入系列博客的 Part3，介绍了流行的词嵌入模型全局向量&lt;span&gt;GloVe&lt;/span&gt;。 part2 请点击 &lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720050&amp;amp;idx=2&amp;amp;sn=9fedc937d3128462c478ef7911e77687&amp;amp;chksm=871b034cb06c8a5a8db8a10f708c81025fc62084d871ac5d184bab5098cb64e939c1c23a7369&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720050&amp;amp;idx=2&amp;amp;sn=9fedc937d3128462c478ef7911e77687&amp;amp;chksm=871b034cb06c8a5a8db8a10f708c81025fc62084d871ac5d184bab5098cb64e939c1c23a7369&amp;amp;scene=21#wechat_redirect"&gt;技术 | 词嵌入系列博客Part2：比较语言建模中近似softmax的几种方法&lt;/a&gt;；Part1请点击 &lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;em style="text-decoration: underline; max-width: 100%; font-size: 12px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719971&amp;amp;idx=2&amp;amp;sn=c7e0d1f6dd4e9ddce291e9bc2c85c65f&amp;amp;chksm=871b029db06c8b8b7557095989dd3fdb57b86a1d7923c388ca1e74255d07f08992bb0461d958&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719971&amp;amp;idx=2&amp;amp;sn=c7e0d1f6dd4e9ddce291e9bc2c85c65f&amp;amp;chksm=871b029db06c8b8b7557095989dd3fdb57b86a1d7923c388ca1e74255d07f08992bb0461d958&amp;amp;scene=21#wechat_redirect" style="text-decoration: underline; max-width: 100%; font-size: 12px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;技术 | 词嵌入系列博客Part1：基于语言建模的词嵌入模型&lt;/a&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;em style="text-decoration: underline; max-width: 100%; font-size: 12px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;br/&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em style="text-decoration: underline; max-width: 100%; font-size: 12px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9LprWu7eD2xib3jhgiaXmPYWdbIqaJ0f3m5aeLIJyjFUdT9RYgMzn6XQ6Sog9orJTc5AhOOPFHm12Q/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;全局矢量（GloVe）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;词嵌入量与分布式语义模型&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;模型&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;超参数&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;结果&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;请原谅之前的噱头。这是一篇我很久之前就想要去写的博客。在这篇文章中，我想要强调那些使得 word2vec 成功的秘密成分。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我特别要专注于通过神经模型训练的词嵌入与通过传统的分布式语义模型（DSMs）产生的词嵌入之间的联系。通过展示这些组分是如何被转移到 DSMs 中的，我将会证明分布式的方法是丝毫不逊色于流行的词嵌入方法的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然没有什么新的见解，但我感觉传统的方法经常被深度学习的热潮所掩盖，它们之间的相关性应该受到更多关注。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因此，这篇博客所依据的文献是 Levy 等人在 2015 年发表的通过词嵌入获得的提升分布式相似性的研究。如果你还没有阅读过，我建议你抓紧搜索。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这篇公开的博客中，我将首先介绍一个流行的词嵌入模型 GloVe，然后我将突出词嵌入模型和分布式予语义方法之间的联系。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;紧接着，我将会介绍用来衡量不同因素影响的四款模型。之后我会给出除了算法选择之外其他学习词表示中额外因素的概述。最终我将呈现 Levy 等人的建议和结论。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;全局矢量（&lt;strong&gt;GloVe&lt;/strong&gt;）&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在之前发布的那篇博客中，我们已经对流行的词嵌入模型进行了概述。我们遗漏的一个模型便是 GloVe。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;简而言之，GloVe 希望能明确表明 SNGS 的隐式操作：编码含义作为嵌入空间中的向量偏移——看起来只是一个偶然发现的 word2vec 的副产品——才是 GloVe 的特定目标。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;具体来说，GloVe 的作者表明两个词同现概率的比值（而不是它们的同现概率本身）是包含信息并计划作为向量差来编码信息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了实现这一目标，他们提出了一种加权最小二乘法的物体 J，旨在最小化两个词的向量点积与它们共现次数的对数之间的差异。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9LprWu7eD2xib3jhgiaXmPYW5sHHSx6u0hyHW7DrzbBIm9lqBc2bkRBI63Bc65b5MNZCRuvePg68VQ/0?wx_fmt=png"/&gt;&lt;br/&gt;当 wi 和 bi 分别作为词语 i 的词向量和偏差，w~j 和 bj 分别作为词语 j 的文本词向量和偏差，Xij 是在词语 j 的文本中出现词语 i 的次数，而 f 是将相对低的权重分配给稀有和频繁共现的加权函数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;共现次数可以被直接编码到词语上下文的共现矩阵中，GloVe 会将这样的矩阵而不是整个语料库作为输入。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你想更多地了解 GloVe，最好的参考便是相关的论文或者附属网站&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（http://nlp.stanford.edu/projects/glove/）。除此之外，通过 Gensim 的作者，Quora 问答（https://www.quora.com/How-is-GloVe-different-from-word2vec）或是这篇发布的博客&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（https://cran.r-project.org/web/packages/text2vec/vignettes/glove.html），你可以对 GloVe 及其与 word2vec 的差异有更多的了解。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;词嵌入与分布式语义模型&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;词嵌入模型，尤其是 word2vec 和 GloVe 变得如此流行的原因是它们的表现似乎一直以来都显著优于 DSMs。许多人将此归因于 Word2vec 的神经架构或是它能预测词语这个事实，这看起来要比只靠共现计数有天然的优势。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们可以将 DSMs 看做计数模型，因为它们通过操作共现矩阵来计算词语的共现次数。相反，神经词嵌入模型可以被看作是一种预测模型，因为它们会去预测周围的词语。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2014 年，Baroni 等人表明预测模型几乎在所有的任务中都优于计数模型，从而为词嵌入模型显而易见的优越性提供了一个清晰的证明。这就是终点了吗？并不是。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们已经看到和 GloVe 的差异并不是那么明显：当 GloVe 被 Levy 等人认为是一个预测模型时，它显然是正在分解一个词语上下文共现矩阵，这使其更接近于诸如主成分分析（PCA）和潜在语义分析（LSA）等传统的方法。不止如此，Levy 等人还表示 word2vec 隐晦地分解了词语上下文的 PMI 矩阵。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以，虽然在表面上 DSM 和词嵌入模型使用不同的算法来学习词语表示——前者计数，后者预测——但从根本上来说，两种类型的模型表现了相同的底层数据统计，即词语间的共现次数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因此，仍然存在同时也是这篇博客剩下的部分想要回答的一个问题是：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为什么词嵌入模型的表现仍然比几乎拥有相同信息的 DSM 更好？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;模型&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;继续 Levy 等人 2015 年的成果，我们将分离和鉴定影响神经词嵌入模型的因素并展示它们是如何通过比较以下四个模型来被转移到传统方法中的：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;PPMI：PMI 是衡量两个词之间相关性强度的一个常用指标。它是两个词 w 和 c 之间联合概率与边际概率乘积之间的对数比：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9LprWu7eD2xib3jhgiaXmPYWOia5bxY5VCxkoKfhwib0ahN34EjdflZh0icBibz0SbHyRVBhjVrq41hrtg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp;PMI(w,c)=logP(w,c)P(w)P(c)。由于词对（w,c）的 PMI(w,c)=log0=−∞从未出现，所以 &amp;nbsp; &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp;实际上 PMI 经常被 PPMI 替代，其将负值看作是 0，即：PPMI(w,c)=max(PMI(w,c),0)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;奇异值分解（SVD）：SVD 是最流行的降维方法之一，最初是通过潜在语义分析（LSA）进入自然语言处理（NLP）。SVD 将词文本共现矩阵转化为三阶矩阵 &amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9LprWu7eD2xib3jhgiaXmPYWEPtaqjOxvrzHIOazkc2VaEvS3RGzibS3iaZAxQUE25J0f4aEQUWX7UYg/0?wx_fmt=png"/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;的产物，其中 U 和 V 是正交矩阵（即方形矩阵的行和列是正交单位向量），Σ是特征 &amp;nbsp; &amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;值在减弱过程中的对角矩阵。实际上，SVD 经常被用于因式分解由 PPMI 产生的矩&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;阵。一般来说，只有Σ顶端的 d 元素被保存，从而得到：&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9LprWu7eD2xib3jhgiaXmPYWKA91ZiaCZyIckSFrmbv1LTibAMWxx8XawYFNdA1Op885Ndrs4ibzEPQVg/0?wx_fmt=png"/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;，&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;通常被分别用来表示词语和上下文。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;基于负采样的 Skip-gram 模型也就是 word2vec：要了解更多 skip-gram 结构和负采样可以参考我之前的博客文章。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;全局矢量（GloVe）已经在上一节中介绍过。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;超参数&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们来看看以下这些超参数&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;预处理&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: circle;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;动态上下文窗口&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;常用词下采样&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;删除罕见词语&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;关联度量&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: circle;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;转移&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;上下文分布平滑&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;后期处理&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;添加上下文向量&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: circle;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;特征值加权&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;向量规范化&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;预处理&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Word2vec 引入了三种预处理语料库的方法，这三种方法也可以很容易地应用于 DSM。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;动态上下文窗口&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一般来说，在 DSM 中，上下文窗口并未加权，并且具有恒定大小。然而，SGNS 和 GloVe 使用了一种会将更多权重分配给更接近的词语的方案，因为更接近的词通常被认为对词的意义更重要。此外，在 SGNS 中，窗口大小不是固定的，但实际窗口大小是动态的，并且在训练期间在 1 和最大窗口之间均匀采样。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;常用词下采样&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;SGNS 通过概率：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9LprWu7eD2xib3jhgiaXmPYWzj0badbicGXQHy7tgY8viadtgzbSt038w8E4bsicXb6rtvvvEzTFicl0Hg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;来随机去除频率 f 高于某个阈值 t 的词语，从而获得那些非常频繁出现的词语。由于这种下采样是在实际创建窗口之前完成的，因此 SGNS 在实践中所使用的上下文窗口要大于实际所指示的上下文窗口。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;删除罕见词语&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 SGNS 的预处理中，罕见词语也在创建上下文窗口之前被删除，这进一步增加了上下文窗口的实际大小。虽然 Levy 等人在 2015 年发现这并不会对性能产生什么重大的影响。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;关联度量&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;PMI 已被证明是用于测量词语之间关联程度的有效方式。Levy 和 Goldberg 在 2014 年已经表示 SGNS 对 PMI 矩阵进行隐含地因式分解，因此可以将该公式的两个变化引入到常规 PMI 中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;PMI 转移&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 SGNS 中，负样本 K 的数量越多，使用的数据就越多，参数的估计也越好。K 影响了有 word2vec 隐性因式分解的 PMI 矩阵偏移，即 k 通过 log k 来转移 PMI 值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果我们将其转换为常规 PMI，我们获得 Shifted PPMI（SPPMI）：SPPMI(w,c)=max(PMI(w,c)−logk,0)。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;上下文分布平滑&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 SGNS 中，根据平滑的一元分布，即提高到α的幂的一元分布来对负样本进行采样，并根据经验将其设置为 34。这会导致频繁的词语被采样的几率要比它们频率所指示的相对较少。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们可以通过将上下文词汇 f（c）的频率同等地提高到α的幂来将其传送到 PMI：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;PMI（w，c）= log p（w，c）p（w）pα（c）其中 pα（c）= f（c）αΣcf（c）α和 f（x）是字 x 的频率。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;后期处理&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;类似于预处理，可以使用三种方法来修改由算法产生的词向量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;添加上下文向量&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;GloVe 的作者建议添加词嵌入和上下文向量以创建最终输出向量，例如： v⃗cat =w⃗cat +c⃗catv→cat = w→cat + c→cat。这增加了一阶相似性项，即 w⋅v。然而，该方法不能应用于 PMI，因为 PMI 产生的是稀疏向量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;特征值加权&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;SVD 产生以下矩阵：WSVD = Ud·Σd 和 CSVD = Vd。然而，这些矩阵具有不同的性质：CSVD 是标准正交的，而 WSVD 不是。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相反，SGNS 更对称。因此，我们可以用可调整的附加参数 pp 来对特征值矩阵Σd 加权，以产生以下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;WSVD = Ud·Σpd。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;向量规范化&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，我们还可以将所有向量归一化为单位长度&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;结果&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Levy 等人在 2015 年训练了英文维基百科所有转储模型，并基于常用词语的相似性和类比数据集对它们进行了评价。你可以在他们的论文中了解有关实验设置和培训详情的更多信息。我们在下文总结出了最重要的结果和收获。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;额外收获&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Levy 等人发现 SVD——而不是词嵌入算法的其中一种——在相似性任务上执行得最好，而 SGNS 在类比数据集上执行得最好。他们还阐明了与其他选择相比，超参数的重要性：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 超参数与算法：超参数设置通常比算法选择更重要。没有任意单一的算法能始终胜过其他方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 超参数与更多数据：在更大的语料库上训练对某些任务有帮助。在 6 个例子中有 3 个都能说明，调整超参数更有益。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;揭露之前的观点&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有了这些见解，我们现在可以揭露一些普遍存在的观点：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="list-style-type: decimal;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;嵌入式比分布式方法优秀吗？使用正确的超参数，没有一种方法比另一种方法具有持续的优势。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;GloVe 是否优于 SGNS？SNGS 在所有任务上都胜过 GloVe。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;CBOW 是不是很好的 word2vec 配置？CBOW 在任何任务上都比不上 SGNS。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;建议&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后——也是这篇文章中我最喜欢的一部分——我们可以给出一些具体的实际建议：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;不要将迁移的 PPMI 与 SVD 一起使用。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;不要「正确」使用 SVD，即不使用特征向量加权（与使用 p = 0.5 的特征值加权相比性能下降 15 个点）。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;请使用具有短上下文（窗口大小为 22）的 PPMI 和 SVD。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;请使用 SGNS 的许多负样本。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;对于所有方法，请始终使用上下文分布平滑（将一元分布提高到α= 0.75 的幂）。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;使用 SGNS 作为基准（训练更加稳健，快速和经济）。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;请尝试在 SGNS 和 GloVe 中添加上下文向量。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;结论&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些结果与通常假设的情况背道而驰，即词嵌入优于传统方法，并且表明它通常没有什么区别，无论使用词嵌入还是分布式方法 - 重要的是，你调整超参数并使用适当的预处理和后期处理步骤。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;来自 Jurafsky 小组 [5 , 6 ] 的最新论文回应了这些发现，并表明 SVD——而不是 SGNS——通常是当你关心精确词语表达时的首选。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我希望这篇博客对于目前备受关注的，揭示传统分布语义和嵌入模式之间的联系的研究能够有所帮助。正如我们所看到的，分布式语义的知识使得我们可以改进当前的方法并开发现有方法的全新变体。为此，我希望下一次训练词嵌入时，您会将分布式方法纳入考虑范围，或从这些思考中获益。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;参考文献：&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Levy, O., Goldberg, Y., &amp;amp; Dagan, I. (2015). Improving Distributional Similarity with Lessons Learned from Word Embeddings. Transactions of the Association for Computational Linguistics, 3, 211–225. Retrieved from https://tacl2013.cs.columbia.edu/ojs/index.php/tacl/article/view/570 ↩&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Pennington, J., Socher, R., &amp;amp; Manning, C. D. (2014). Glove: Global Vectors for Word Representation. Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing, 1532–1543. http://doi.org/10.3115/v1/D14-1162&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Baroni, M., Dinu, G., &amp;amp; Kruszewski, G. (2014). Don’t count, predict! A systematic comparison of context-counting vs. context-predicting semantic vectors. ACL, 238–247. http://doi.org/10.3115/v1/P14-1023&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Levy, O., &amp;amp; Goldberg, Y. (2014). Neural Word Embedding as Implicit Matrix Factorization. Advances in Neural Information Processing Systems (NIPS), 2177–2185. Retrieved from http://papers.nips.cc/paper/5477-neural-word-embedding-as-implicit-matrix-factorization&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Hamilton, W. L., Clark, K., Leskovec, J., &amp;amp; Jurafsky, D. (2016). Inducing Domain-Specific Sentiment Lexicons from Unlabeled Corpora. Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics. Retrieved from http://arxiv.org/abs/1606.02820&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Hamilton, W. L., Leskovec, J., &amp;amp; Jurafsky, D. (2016). Diachronic Word Embeddings Reveal Statistical Laws of Semantic Change. arXiv Preprint arXiv:1605.09096.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 25 Oct 2016 19:37:26 +0800</pubDate>
    </item>
  </channel>
</rss>
