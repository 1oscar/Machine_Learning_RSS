<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>机器之心</title>
    <link>http://www.iwgc.cn/list/670</link>
    <description>人与科技的美好关系</description>
    <item>
      <title>独家 | Hinton、Bengio、Sutton等巨头聚首多伦多：通过不同路径实现人工智能的下一个目标</title>
      <link>http://www.iwgc.cn/link/3316956</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心原创&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：机器之心编辑部&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;技术顾问：Yuxi Li&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote style="max-width: 100%; color: rgb(62, 62, 62); font-size: 16px; white-space: normal; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p&gt;&lt;em style="color: rgb(136, 136, 136); font-size: 12px;"&gt;当地时间 10 月 27 日，Creative Destruction Lab 在多伦多举办了 2016 机器学习与智能市场（2016 Machine Learning and the Market for Intelligence）会议。会议云集了人工智能投资及科研界众多世界级明星。在下午的科研分论坛上 Yoshua Bengio、Geoffrey Hinton、Richard Sutton 和 Ruslan Salakhutdinov 等机器学习领域的巨星人物聚首于此，以接下来 1-5 年的人工智能方面的前沿科研方向为主题进行了公开探讨，并分享了很多有价值的知识和经验。机器之心现场观摩了这些大师级人物对机器学习技术、应用和未来的探讨。未来一段时间，机器之心将陆续发布对本次会议内容的独家整理报道。&lt;/em&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;整理内容如有疏漏之处，请不吝指正：留言或发送邮件到 editors@jiqizhixin.com。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以下为机器之心的分论坛现场整理。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Yoshua Bengio、Geoffrey Hinton、Richard Sutton 和 Ruslan Salakhutdinov 同台共同探讨人工智能这一研究领域的接下来 1-5 年的人工智能方面的前沿科研方向。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个明星小组论坛的主持人是科技领域的明星风投公司 DJF（Draper Fisher Juvetson）的合伙人 Steve Jurvetson。Steve 曾经投资过 Hotmail、Tradex、SpaceX、Nervana、D-Wave 和特斯拉等众多明星科技创业公司，他还拥有世界上第一辆 Tesla model S 和第二辆 Tesla model X（第一辆在 Elon Musk 手里）。但是，即使是 Steve，主持这场大师云集的小组论坛还是很有压力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibQiblzyVh1Iicfga2kY36K3YGI5wKK58sSznVpJlW9BSP1b8Qv3sHbzNwdxaryxwL3p7y49xo85ia6g/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本次小组论坛的主题是「What's Next?The Research Frontier（接下来是什么？研究前沿）」。论坛开始，Steve 先请每位小组成员分别讨论自己对人工智能领域，其是机器学习领域下一阶段的科研方向的看法。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;下一步，去向何方？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在未来的一年里 Bengio、Hinton、Sutton 和 Salakhutdinov 教授认为都有哪些问题需要解决？我们会在哪些方向取得进展？&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Yoshua Bengio&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Yoshua Bengio 教授与 Hinton 教授和 LeCun 教授是深度学习崛起背后的领军人物。从 20 世纪 80 年代到 90 年代再到 21 世纪前几年，在那段很少有其他人看到深度学习的发展潜力的时间里，他们三位一直在培养和孕育深度学习。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibQiblzyVh1Iicfga2kY36K3YZcg4d1Oa4VW6b7dxFyo1aFe7cZjLXgu5Edl6C8ZCrlG91zmLYhiagqg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Bengio 教授列出了两个方向：&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1. 解释性的无监督学习（Explanatory Unsupervised Learning）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&amp;nbsp;&lt;strong&gt;&amp;nbsp;&amp;nbsp;1）当前的模型通过提取表面的规律来解决表面的问题。&lt;/strong&gt;Bengio 教授给出了一个图像识别系统的例子。该系统可以被各种各样的色调愚弄，比如背景绿化仍会增加物体被识别成野生动物的可能性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;strong&gt;2）机器无法做到人类非常擅长的无监督学习。&lt;/strong&gt;即使两岁孩童也能理解直观的物理过程，比如丢出的物体会下落。人类并不需要有意识地知道任何物理学就能预测这些物理过程。但机器做不到这一点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;strong&gt;&amp;nbsp;3）处理罕见的危险状态所需要的带有隐变量（latent variable）的预测 (（predictive）,，因果（causal）和解释性（explanatory）模型&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;a. 研究和开发带有隐变量的模型非常重要&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;b. 为什么带有隐变量的模型很重要？因为在可观察到的事物与观察不到的事物之间存在因果关系&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;c. 除了要有更好的模型，处理无标签数据也很重要。无标签意味着没有进行人类解读。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;d. Bengio 教授给出了一个关于开发安全的自动汽车的例子：自动汽车应该要能搞清楚其在训练过程中从未见过的危险状况。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;strong&gt;4）基于模型的强化学习、域适应（domain adaptation）、半监督学习、多任务学习等的应用&lt;/strong&gt;。Steve 问 Bengio 教授因果模型（causal model）是否能以一种无监督的方式衍生出来。Bengio 教授认为无监督将会是一个关键的组成元素，但我们必须使用所有的信息源。我们既应该使用有标签数据，也需要无标签数据。事实上，我们遇到的数据大多是无标签的，也就是说没有提供人类的注解。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibQiblzyVh1Iicfga2kY36K3YKGS6libsLlia8DNVgnXCibf4laibF6jJT5Ma1LiahUx6I9c9nLPOV2ic5ibPg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2. 记忆（Memory）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Bengio 教授还提到未来几年记忆（memory）将成为一个热门的研究领域。为什么记忆会在这个领域如此重要呢？因为记忆与推理存在紧密的联系。从本质上讲，推理就是各种信息的组合过程。为了能够得出能够准确预测未来的结果，你需要有合理的预测步骤。这个过程会在很大程度涉及到记忆。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;Geoffrey Hinton&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Hinton 教授是第一批使用反向传播算法来训练多层神经网络的研究者之一，他也是深度学习社区的一位重要大师。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibQiblzyVh1Iicfga2kY36K3YnSibD2Aj8VIWKpANov2HibqjicV41h70gsMMavFJqX5hgtWWXXm2mvYjg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Hinton 教授用一个他常开的玩笑开场。他对医学院学生说不要去当放射科医生，因为这个工作在未来 5 年内就会被深度学习应用取代。Hinton 教授指出，通常而言，如果你有大量数据和高速的计算芯片，并且需要解决预测问题，深度学习基本上都能派上用场。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibQiblzyVh1Iicfga2kY36K3YiaJfxgJCGIpoibTF0lIW14aUcSJmuQZBG1dwuxoAxUOwQiavG4ByPDbOQ/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Hinton 教授认为未来可能会实现的两件事：&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1. 发现比 ReLU 效果更好的「神经元（neurons）」模型&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;发现比我们的标准 logistic 单元或修正线性单元（ReLU）效果更好的「神经元（neurons）」模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了解释这个问题，Hinton 教授首先简要谈论了自 50 年代以来人工神经元（artificial neuron）的定义的发展史。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;50 年代的时候，人们认为神经元是逻辑门，是确定性的和二进制形式的。然后人们发现它实际上是随机的二进制（stochastic binary）。然后到了 80 年代，Hinton 教授那一代人对神经元的理解从确定性的逻辑门转变成了 S 型的 logistic 单元（sigmoid logistic units）。此后 30 年来，人们一直在使用 logistic 单元；直到 2011 年，修正线性单元随 AlexNet 被引入，进而带来了革命性的影响。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2. 在相对较小的数据集上训练带有大量参数的神经网络。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相较于探索无监督学习，Hinton 教授相信监督学习领域仍然还有一些工作要做。计算能力将越来越便宜，数据集将越来越大，这是如今的趋势。Hinton 教授认为计算能力降价的速度将会超过数据集增长的速度。也就是说，更多的参数可能将不再是噩梦。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数周前，在 Hinton 教授为多伦多大学研究生做的一次讲演中，他表达了自己关于如何做出好成果的观点，他认为可以在网络中利用我们拥有的计算能力并注入尽可能多的参数来获取数据的规律（包括可靠的与不可靠的），并结合所有这些意见来做出预测。这个观点已经在许多任务的完成中得到了成功的证明。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了解释更多的参数能打造更好的模型，他举了一个关于人类的例子：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们每个人都有 100,000,000,000,000 个突触。一个人在一生中大概要进行 1000 万次注视（fixation）。以每 5 秒一次计算，就是 200 万秒。如果我们将每次注视都看作是一个数据点，那么参数的数量和数据的数量之间就存在大约 10,000 倍的差异。如果你一次处理一个数据，那么当你有更多的参数时，你所得到的模型的效果就越好。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于这个例子，Hinton 教授继续指出人脑处理的数据比注视过程中接收的数据多 10,000 倍，但仍然可以处理。而我们的计算机能力不足的原因很可能是因为我们还没有提出一种用于 dropout 的规范化的方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Steve 提出对是否可以使用机器学习来优化参数，同时是什么让 Hinton 相信参数是解决问题的关键的疑问。对于 Steve 的这个问题，Hinton 表示赞同可以将其转变成一个机器学习问题，而且这能给科学研究带来很大的裨益。但同时，Hinton 也并未过多深入探讨参数的问题，反而指出人们实际上仍然不知道神经元实际的工作方式，但在研究上我们甚至有避免将我们在生物神经元上观察到的基本性质应用到人工神经元上的趋势。当前的人工神经元仍然还存在诸多限制，还只能计算一些非常简单的问题。为了解决更复杂的问题，我们还需要继续改变基本的神经元。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Richard Sutton&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Richard Sutton 教授被认为是现代计算强化学习之父，他在该领域有几个重要贡献，包括时间差分学习（temporal difference learning）、策略梯度方法（policy gradient methods）和 Dyna 架构。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibQiblzyVh1Iicfga2kY36K3YWdITSrnub5KicXYC7gZ8L4k2raOpRA3DStQ4HAykc6u7qNa2dgbChqg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Sutton 教授的兴趣点在于智能本身，以及学习的本质。Sutton 教授并没有探讨接下来一年什么会帮助公司企业获得利益，而是探讨了接下来一年里，他认为机器学习最重要的进展。主要有以下三个方面：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1. 从普通经历中规模化学习的能力&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2. 将机器学习扩展到下一阶段&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3. 使用深度强化学习进行长期预测，（可能）进行无监督学习&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibQiblzyVh1Iicfga2kY36K3YZzU0XqFWcupibw1ZJoicCUZiaK6iaIQ6ic1W07aicukXnQ7XILKVXxDRkiajw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在的机器学习过程和人类学习的方式并不相同。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Sutton 教授提到了经验学习法，比如人类和动物会通过生活经验来学习知识。在最近的深度学习方法种借鉴了这种经验法，我们用经验构建起巨大的训练集。能像人类那样学习是件非常重要的事情。不过在机器学习中，这种经验学习的方法还关涉到训练集的可扩展性和限制。这就是为什么现在的系统只能「被动学习（learned）」无法「主动学习（learning）」的原因。一个被动学习的系统建立在训练数据之上，而在主动学习系统中，系统能随时能通过新的经验不断提高。对于未来一年机器学习领域的发展，Sutton 总结道：了解世界的运行规律、可扩展的深度学习方法、用于长期预测的深度强化学习以及无监督学习。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 Sutton 教授看来，学习应该源自与世界交互的过程，而不需要使用有标签的数据集进行训练。它应该是一种更加自然的方式，就像人类小孩与动物的方式一样。它应该有关世界的运行规律和因果规律。Sutton 教授认为他和 Bengio 是在用不同的术语和方法讨论同一个问题。他在用强化学习的方法，而 Bengio 则用的是无监督学习。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他最后说，人工智能目前还有很长一段路要走，我们还仅仅出于旅程的起点，我们将会找到一个稳定的方式赶上甚至超越摩尔定律。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当 Steve 问到这和人类与大脑连接的类比时，Sutton 只是微笑着把问题让给了 Bengio 教授。Bengio 提到 logistic 单位模型受神经元科学假说的影响很大。我们还需要探索更多，才能消除神经科学与机器学习之间的差距。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Ruslan Salakhutdinov&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Ruslan Salakhutdinov 教授是卡耐基梅隆大学计算机科学院机器学习系的副教授，之前是多伦多大学的教授，也是 Hinton 的博士生。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibQiblzyVh1Iicfga2kY36K3YRaWHNxOSaXNkiadR7t9rAibAJ3BaT93DNYy49OQG5L9fmXHclJat0pKQ/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibQiblzyVh1Iicfga2kY36K3Yx0Oh4zL3HibwsP72vKKSnCbswewAvzicd7iaSVN7XShhvib5UPg3fMXZHg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719828&amp;amp;idx=3&amp;amp;sn=5f72f8b9bbd0078d483ad233e578081a&amp;amp;chksm=871b022ab06c8b3ce2ef881c941e1ea532e3f465bbc1109c74e0aa0a72b283a8408dca7b353f&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719828&amp;amp;idx=3&amp;amp;sn=5f72f8b9bbd0078d483ad233e578081a&amp;amp;chksm=871b022ab06c8b3ce2ef881c941e1ea532e3f465bbc1109c74e0aa0a72b283a8408dca7b353f&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;Salakhutdinov 教授最近作为机器学习研究的负责人加入了苹果&lt;/span&gt;&lt;/a&gt;&lt;span&gt;。他说他们正在组建一个顶级科学家团队。有很多棘手的项目和研究要做。他的工作是确保他们能开发出新的优秀算法。因为机器学习正在被应用到苹果内部的每个角落。他很高兴能够兼顾到所有的地方。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Salakhutdinov 教授说，人工智能与机器学习在未来一到三年内存在四大挑战：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1. 无监督学习/一次性学习（One-Shot Learning）/迁移学习&lt;/span&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Salakhutdinov 教授表示他在卡内基梅隆大学的实验室里已经利用数据进行了大量研究，已经可以使用监督学习从数据中提取结构，这是一个新进展，但计算机距离无监督学习还很远。他还提到了一次性学习，Bengio 和 Hinton 也提到过这种方法。只是目前的机器还不能像人类一样从少数例子中学到新的知识与概念。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2. 推理、注意和记忆&lt;/span&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Salakhutdinov 教授没有深入探讨这一部分，但他提出了一个问题：如何让系统具有内建记忆，帮助我们进行决策。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3. 自然语言理解/对话与提问/自动应答系统&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;即使我们在自然语言的推理中取得了很大的进展，但我们距离人机自然交互仍然有很长的一段距离。Salakhutdinov 在被问及建立嵌入记忆是否是让自然语言理解语境和长对话的关键时回答说：需要有正式的记忆网络，能在神经网络中进行读取和存储。建立和设计新的神经网络架构是我们要探索的问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Steve 还问到了人机交互自然对话界面建立的时间表，Salakhutdinov 则说，我们仍需在有限的环境中做很多工作，而不是在通用人工智能上。Bengio 则开了个玩笑：「严肃的科学家从不给出时间表。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;4. 深度增强学习&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Salakhutdinov 推荐对这一话题感兴趣的人们阅读 Sutton 的著作。他认为认真总结上个世纪 80 到 90 年代增强学习的成就之后，人们将会取得更伟大的进步。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;讨论花絮&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除了讨论这一个领域未来的展望，教授们还探讨了很多有趣的想法，互相开了开玩笑，与 Steve 进行问答，下面是从讨论中摘录的部分有意思的花絮。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Hinton 教授的灵感之源：「它（大脑）是如何工作的？」&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;待四位教授说完自己对未来科研风向的观点后，Steve 问了一个问题，是什么让教授们坚信，并且在不知道什么时间才会出成果的情况下，全身心将事业投入于此？（在会议中 Bengio 教授曾笑言：「（对科研态度）严肃的教授是不会给你（出成果的）时间线的。」）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;Hinton 教授谈到自己的坚持是希望探索出大脑是如何工作的。Steve 追问，「这个强烈的兴趣就在于我们对大脑真实工作情况理解的越多，模拟就能做的越好。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Hinton 教授：「不，我不关心这个。我只关心大脑如何工作。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibQiblzyVh1Iicfga2kY36K3YJVV8ic5ORMlBmpxskjpkq0dIuI1Ip72uC3SV0LtYTPL1bzcgic8Pfu4A/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;关于智能，存在一个简单的解释吗？&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在讨论到自由意志这个主题时，Bengio 教授还聊了聊自己正在思考怎样才能简单的解释智能。他提到 Pedro Domingos 教授在书中写过，很多机器学习（和深度学习）都有基础假设。有一些可以理解的简单原理能解释我们的智能以及我们大脑理解世界的能力。如果这个方法复杂到我们无法理解，那就不好玩了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Geoffrey Hinton 最近的工作&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;讨论中，Hinton 教授提到谷歌正全力支持他探索新型人工神经元及其工作原理，谷歌对他基础研究的支持非常有效，有了些突破性进展。他开玩笑说实际上谷歌是比 NSERC（加拿大自然科学与工程技术研究理事会）更好的资金来源。但由于这些讨论的内容本身很难，再加上 Hinton 浓重的英国口音就更加晦涩难懂。Bengio 教授则建议大家可以阅读他们最近发表的论文（论文点击「&lt;span&gt;阅读原文&lt;/span&gt;」下载，这是 Geoffrey Hinton之前的论文：&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719971&amp;amp;idx=3&amp;amp;sn=c23aa4b6172bd4ccea042d139ffa5daf&amp;amp;chksm=871b029db06c8b8b939ba2e0eb256db1d5fdd5ce2b229139cb31e7e54e5bdd2772761ce01c19&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719971&amp;amp;idx=3&amp;amp;sn=c23aa4b6172bd4ccea042d139ffa5daf&amp;amp;chksm=871b029db06c8b8b939ba2e0eb256db1d5fdd5ce2b229139cb31e7e54e5bdd2772761ce01c19&amp;amp;scene=21#wechat_redirect"&gt;&lt;em&gt;使用快速权重处理最近的过去&lt;/em&gt;&lt;/a&gt;的修订版）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Yoshua Bengio 教授 :「自由意志是一种错觉！」&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当 Steve 问 Bengio 教授他如何看待自由意志和计算决定论时，Bengio 教授并没有正面回答，而是给出了一个引人深思观点：「自由意志是一种错觉！」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;深度增强学习渐热&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Sutton 教授和 Salakhutdinov 教授都在强调深度强化学习。这种方法会催生通用人工智能吗？我们还不知道。但我们明白目前还有很多工作要做，而在这条路上我们将会有很多收获。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibQiblzyVh1Iicfga2kY36K3YGzHjcXzUmkcfc4r7QdVrzbZ3kNiajoCA2hHibodlkT6QUzA81f9RRcEw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;我们需要知道大脑的运作机制&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在会议和讨论中，Hinton 教授不断地讲述他关于神经、突触、脉搏、电流和其他工作的进展。他同时提到了图灵对神经网络的观点，并多次强调我们其实还是不明白它（人工神经网络以及大脑）的具体机制。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Bengio 教授与 Hinton 分享了类似的观点，他认为将大脑运作机制研究清楚是非常重要的——「如果我们不这么做一定是疯了」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Hinton：「我们不知道它的工作机制。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Bengio：「或者说，我们不知道我们大脑的工作机制！」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibQiblzyVh1Iicfga2kY36K3YCuQ3PeSXu78IpCFINp4jAf44LQcKoBIcbjRJl4PtT9aX7UfIf0zIyg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;本文是机器之心对 2016 机器学习和人工智能市场会议的第一篇小组论坛要点报道。该会议由多伦多 Creative Destruction Lab 于 2016 年 10 月 27 日在多伦多举办。我们希望本篇总结可以让大家从这些研究者的观点中受益。随后的一段时间里，机器之心将会陆续发出该会议的其他精彩小组论坛总结报道。请锁定机器之心，第一时间获得感兴趣的小组论坛总结报道。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心原创，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 01 Nov 2016 16:26:34 +0800</pubDate>
    </item>
    <item>
      <title>学界 | 微软重磅论文提出LightRNN：高效利用内存和计算的循环神经网络</title>
      <link>http://www.iwgc.cn/link/3316957</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;选自arXiv.org&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李泽南、吴攀、蒋思源&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQiblzyVh1Iicfga2kY36K3YNNKLJ7BbGrq6rTRLpKjpnHsdFPhHZxtVsxDKojEMntPibyc9IdUD9ibQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;摘要&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;循环神经网络（RNN）已经在许多自然语言处理任务上取得了最出色的表现，比如语言建模和机器翻译。然而当词汇量很大时，RNN 模型会变得很大（可能超过 GPU 最大的内存能力），这样训练将变得很低效。在这项工作中，我们提出一种全新的方法来解决这一挑战。其中的关键思想是使用二分量（2-Component(2C)）共享的词表征的嵌入（embedding for word representations）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们将词汇表中的每一个词都分配到一个表格中，其中每一行都关联了一个向量，每一列则关联了另一个向量。根据一个词在表中的位置，该词可由行向量和列向量两个维度联合表示。因为该表中同一行具有相同的行向量，同一列具有相同的列向量，所以我们仅仅需要 2p|V|个向量来表示带有|V|个词的词汇表，这远远少于现有的方法所需要的向量数|V|。基于二分量（2-Component）共享嵌入的方法，我们设计了一种新的 RNN 算法，并且使用几个基准数据集上的语言建模任务对其进行了评估。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;结果表明，我们的算法可以显著地减少模型的大小，并且能在不牺牲精度的情况下加快训练速度（它实现了与当前最佳的语言模型相近或更好的困惑度（perplexity））。值得注意的是，在 One-Billion-Word 基准数据集上，我们的算法实现了和以前语言模型差不多的困惑度，同时却将模型的大小减小了 40 到 100 倍、训练过程也加快了 2 倍。我们将我们提出来的算法命名为 LightRNN, 这主要是反应它在模型大小上的精简和很快的训练速度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQiblzyVh1Iicfga2kY36K3Ykw75jfcsfYRZu7VArMce4A8zh3TUFoicA8cEfDx45EibK8hZyXJttjBQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;训练 ACLW-French 时的困惑度对比&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;引言&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最近，循环神经网络（RNN）已被用于处理多种自然语言处理（NLP）任务，例如语言建模、机器翻译、情绪分析和问答。有一种流行的 RNN 架构是长短期记忆网络（LSTM），其可以通过记忆单元（memory cell）和门函数（gating function）建模长期依赖性和解决梯度消失问题。因为这些元素，LSTM 循环神经网络在当前许多自然语言处理任务中都实现了最佳的表现，尽管它的方式几乎是从头开始学习。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然 RNN 越来越受欢迎，但它也存在一个局限性：当应用于大词汇的文本语料库时，模型的体量将变得非常大。比如说，当使用 RNN 进行语言建模时，词首先需要通过输入嵌入矩阵（input-embedding matrix）从 one-hot 向量（其维度与词汇尺寸相同）映射到嵌入向量。然后为了预测下一词的概率，通过输出嵌入矩阵（output-embedding matrix）将顶部隐藏层投射成词汇表中所有词的概率分布。当该词汇库包含数千万个不同的词时（这在 Web 语料库中很常见），这两个嵌入矩阵就会包含数百亿个不同的元素，这会使得 RNN 模型变得过大，从而无法装进 GPU 设备的内存。以 ClueWeb 数据集为例，其词汇集包含超过 1000 万词。如果嵌入向量具有 1024 个维度并且每个维度由 32 位浮点表示，则输入嵌入矩阵的大小将为大约 40GB。进一步考虑输出嵌入矩阵和隐藏层之间的权重，RNN 模型将大于 80GB，这一数字远远超出了市面上最好的 GPU 的能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;即使 GPU 的内存可以扩容，用于训练这样体量模型的计算复杂度也将高到难以承受。在 RNN 语言模型中，最耗时的运算是计算词汇表中所有词的概率分布，这需要叠乘序列每个位置处的输出嵌入矩阵和隐藏状态。简单计算一下就可以知道，需要使用目前最好的单 GPU 设备计算数十年才能完成 ClueWeb 数据集语言模型的训练。此外，除了训练阶段的难题，即使我们最终训练出了这样的模型，我们也几乎不可能将其装进移动设备让它进入应用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了应对这些挑战，在本研究中我们提出了将二分量（2-Component）共享的嵌入用于循环神经网络中词表征的方法。我们将词汇表中的所有词放入一个表中，每一行都与一个向量关联，每一列都与另一个向量关联。这样我们就能够通过两个组件来表示一个词：对应的行向量和列向量。因为该表中同一行具有相同的行向量，同一列具有相同的列向量，所以我们仅仅需要 2p|V|个向量来表示带有|V|个词的词汇表，这样可以大幅度减少模型体积（相比而言，vanilla 方法需要|V|个不同的向量）。同时，由于模型尺寸的减小，RNN 模型的训练速度将会显著加快。因此，我们将这一新算法称为 LightRNN，以表示模型的小尺寸和极高的训练速度。这种方法的最大技术难题是如何将词合适地分配到表中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmsns.qpic.cn/mmsns/KmXPKA19gWibQiblzyVh1Iicfga2kY36K3YfrIj0081O9ruFYI5JuZibEQ/0"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;LightRNN（左）对比常规 RNN（右）&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了这个目的，我们提出一个引导框架：（1）首先随机初始化词分配（word allocation），并训练 LightRNN 模型。（2）解决训练了的嵌入向量（对应为表格中的行和列向量），然后细化分配来最小化训练损失（training loss），这是图论（graph theory）最小权重完美匹配问题，我们能够有效地解决。（3）重复第二步，直到满足确切的终止标准。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们使用在多个基准数据集进行语言建模任务来评价 LightRNN。实验表明，在困惑度（perplexity）上面，LightRNN 实现了可与最先进的语言模型媲美或更好的准确度。同时还减少了模型大小高达百倍，加快了训练过程两倍。请注意，对于高度紧凑的模型来说这个可预见的（没有准确性下降）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先，这使得将 RNN 模型运用到 GPU 甚至是移动设备成为了可能。其次，如果训练数据很大，需要执行分布式数据平行训练时，聚合本地工作器（worker）的模型所需要的交流成本会很低。通过这种方式，我们的方法使先前昂贵的 RNN 算法变得非常经济且规模化了。因此，它将会对用于人工自然语言处理（NLP）任务的深度学习有深远的影响。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;结论和未来的方向&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在本研究中，我们提出了一个全新的算法 LightRNN，该算法可用于自然语言处理任务。通过用于词表征的二分量共享的嵌入（2-Component shared embedding for word representations），LightRNN 在模型尺寸和运行时间上都取得了高效的表现，特别是在具有大词汇量的语料库中。在未来，这种算法有很多方向可以进一步研究。首先，我们计划将 LightRNN 应用于更大的语料库中，如 ClueWeb 数据集——传统的 RNN 模型还不能将其装进一个现代的 GPU 中。第二，我们会将 LightRNN 应用于机器翻译和问答等其它自然语言处理任务中。第三，我们会探索 k-分量分享嵌入（k&amp;gt;2）并研究 k 在权衡效率和有效性之间的作用。最后，我们将会整理我们的代码，以便在近期通过 CNTK 将其发布出来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;论文下载：https://arxiv.org/pdf/1610.09893v1.pdf&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 01 Nov 2016 16:26:34 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 超越R，Python成为最受欢迎的机器学习语言</title>
      <link>http://www.iwgc.cn/link/3316958</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;选自Machine Learning Mastery&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Jason Brownlee&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你应该挑选正确的工具做机器学习。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你正在做的特定预测模型问题要求特定的编程语言、库、甚至是机器学习算法。但如果你只是刚开始呢？还在找一个平台学习并实践机器学习呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在此文章中，你会发现 Python 正在成为做机器学习逐渐流行的平台，在采用率与能力上极可能超过并推翻 R 语言。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;读完该文章后，你将会明白：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;对 Python 机器学习的搜索量增长迅速，已经超越了 R 语言机器学习的搜索量；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Python 机器学习招聘的比例正在增长，已经超越了 R 语言；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;调查中，近 50% 的调查对象使用 Python，而且正在增长；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;用 Python 做机器学习的趋势在增长&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;让我们看一下以下三个领域，从此三方面都能看到使用 Python 进行机器学习的趋势正在增长：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;搜索量&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;招聘广告&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;专业工具使用&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;搜索量&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;搜索量可能表明学生、工程师和其他从业者搜索信息开始或者深入这一主题的趋势。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谷歌提供了一个名为 Google Trends 的工具，能让我们观察关键字随时间变化的搜索量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们能够调查 2014 年至 2016 年「Python 机器学习」的增长趋势，如下图所示：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQiblzyVh1Iicfga2kY36K3Y7PiajCxjGs2sXQTcxTIUUvcK0lG6icEupxqq6UA5TqXyEwqgAXfyqj8g/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们能够看到在 2012 年趋势开始上涨，在 2015 年急剧上涨，这可能是因为 TensorFlow 这样的 Python 深度学习工具。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们也可与 R 机器学习的搜索量进行对比，我们可以看到在 2015 年中期，Python 机器学习已经超过 R 机器学习：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQiblzyVh1Iicfga2kY36K3YPX5QfPn106tKPrDoMPA4HM3tnkO9hAAfFURGAiaUHuDmQSYfEpY6eVQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;蓝色代表「Python 机器学习」，红色代表「R 机器学习」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Python 机器学习招聘增长&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Indeed 是一个招聘搜索网站，像 Googel Trends 一样，它可提供匹配关键词的招聘广告量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们能够调查过去 4 年的「Python 机器学习职位」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQiblzyVh1Iicfga2kY36K3Y5r5ruliaQmDoS0gH1Q2LErbtU45zibticsqOJZibmoOoOIWjPTYBPlJLGQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们能够看到 X 轴上的时间和匹配关键词的招聘比例。该图显示从 2012 年至 2015 年几乎呈现线性增长，在 2016 年有曲棍球式的增长。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们也可以对比 Python 和 R 的招聘广告。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQiblzyVh1Iicfga2kY36K3YXvHhOtwp1CYZKK7PCP8ibtq4OicInuweVoKxUofqn512JPPldKAhCfCg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;蓝色表示 Python 机器学习，橙色表示 R 机器学习&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;与谷歌搜索量有显著的对比。从 Indeed 网站获得的招聘广告的比率显示从 2012 年开始，对 Python 机器学习技能的需求一直高于对 R 机器学习技能的需求，差距在近几年逐渐拉大。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;KDnuggets 调查结果：更多人使用 Python 进行机器学习&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过回顾 KDnuggets Software Poll Results 我们能够观察机器学习从业者使用的工具：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面就引自 2016 年的结果：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;R 语言仍然主导工具，占有 49% 的份额，但 Python 增长迅速，几乎赶超 R 语言。——Gregory Piatetsky。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该调查追踪了机器学习和数据科学从业人士使用的工具，在调查中，从业者可以选择多种工具。以下是过去 4 年 Python 机器学习的增长比例：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQiblzyVh1Iicfga2kY36K3Y7PR3P1hokzicjZ6IvkpSibnofXdF2KOVNsPdwVfnAlibSIVNIbSTOYwdw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面是一张增强趋势图：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQiblzyVh1Iicfga2kY36K3YtDwUtdlBib5vwElQ39kBgENfS9HsZTtqcUgHlCEicDUiaefx2wUIJCPPg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们可以看到几乎呈现线性增长趋势，在 2016 年刚好低于 50%&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;值得注意的是，近几年的调查中参与调查的对象也从几百增加到了几千人，参与者是自选择的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;O'Reilly 调查结果：更多人使用 Python 进行机器学习&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;O'Reilly 展示了年度数据科学薪水调查结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他们收集了大量数据科学家和机器学习从业者的数据，并展示了调查结果。该调查追踪了从业人员对工具的使用情况。从下面这段话中，我们可以看到 Python 如今在数据科学薪资中扮演重要角色：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Python 和 Spark 是最对薪资有贡献的工具。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;回顾此调查结果，我们可以看到类似的增长趋势：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQiblzyVh1Iicfga2kY36K3YjsiaZMHrZRnbca4t66cmuWDZo6sPaExGLQZT6SYhDktEUAOyMiaaXQEA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图形展示如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQiblzyVh1Iicfga2kY36K3Y4A9VQBTDC9ic4CuuVWE3eIkN1jwOWMXdXHfqh2VJiaW99PHDScUjholg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有趣的是 O'Reilly 的调查结果非常类似于 KDNuggeets 的结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 01 Nov 2016 16:26:34 +0800</pubDate>
    </item>
    <item>
      <title>学界 | DeepMind最新论文：线性时间的神经机器翻译</title>
      <link>http://www.iwgc.cn/link/3316959</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自arXiv.org&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibQiblzyVh1Iicfga2kY36K3YQPuwgqiawCVMAo5jghfuzpnPruESfCdQnNCq5W8fuuicp3vbMZ5kicgtQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;摘要&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们提出了一种用于序列处理（sequence processing）的神经架构。ByteNet 是一种两个扩张的卷积神经网络（dilated convolutional neural networks）的堆叠；其中一个网络用于编码源序列（source sequence），另一个网络用于解码目标序列（target sequence）——这个过程中目标网络动态展开从而生成可变长度输出。ByteNet 有两个核心特性：它在与序列长度成线性的时间上运行；它能保留序列的时间分辨率（temporal resolution）。ByteNet 解码器在字符级的语言建模上获得了顶尖水平，并超越了之前循环神经网络取得的最好结果。ByteNet 也在原始的字符级机器翻译（raw character-level machine translation）上获得了接近最好的神经翻译模型（运行在二次时间（quadratic time）中）所能取得的顶尖表现。由 ByteNet 学习到的隐含架构能反映出序列之间的预期对应。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;论文下载：https://arxiv.org/pdf/1610.10099v1.pdf&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 01 Nov 2016 16:26:34 +0800</pubDate>
    </item>
    <item>
      <title>专访 | 顶级语音专家、MSR首席研究员俞栋：语音识别的四大前沿研究</title>
      <link>http://www.iwgc.cn/link/3299917</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心原创&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;记者：老红&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;编辑：吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;9 月中旬，微软报告了在语音识别方面取得的新里程碑：&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719135&amp;amp;idx=1&amp;amp;sn=012d179f83a6c3b38c6e58b4ac9ba82f&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719135&amp;amp;idx=1&amp;amp;sn=012d179f83a6c3b38c6e58b4ac9ba82f&amp;amp;scene=21#wechat_redirect"&gt;新系统的识别词错率降至 6.3%&lt;/a&gt;；一个月后，微软又公布了在这一领域成功实现了历史性突破：&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719843&amp;amp;idx=1&amp;amp;sn=0c6387d422cf9765b9b10c178d160680&amp;amp;chksm=871b021db06c8b0b0b0447124c5c07818f53a17ba470305049af1d7d49806c87e07307a93811&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719843&amp;amp;idx=1&amp;amp;sn=0c6387d422cf9765b9b10c178d160680&amp;amp;chksm=871b021db06c8b0b0b0447124c5c07818f53a17ba470305049af1d7d49806c87e07307a93811&amp;amp;scene=21#wechat_redirect"&gt;他们的语音识别系统实现了和专业转录员相当甚至更低的词错率（WER），达到了 5.9%&lt;/a&gt;！机器之心在此期间曾对&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719843&amp;amp;idx=2&amp;amp;sn=4611f810734df8a72286567e90c65a92&amp;amp;chksm=871b021db06c8b0b283ac93f267d95365392be02b3cde5d2fe6df85b359aa96368f25318e2f5&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719843&amp;amp;idx=2&amp;amp;sn=4611f810734df8a72286567e90c65a92&amp;amp;chksm=871b021db06c8b0b283ac93f267d95365392be02b3cde5d2fe6df85b359aa96368f25318e2f5&amp;amp;scene=21#wechat_redirect"&gt;微软首席语音科学家黄学东进行了专访&lt;/a&gt;，探讨了这一连串突破性背后的技术和语音识别领域未来的可能性。近日，机器之心又对微软研究院首席研究员俞栋进行了一次独家专访，谈论了深度学习与语音识别相辅相成的发展以及相关领域的现状和未来。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;俞栋简介&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：1998 年加入微软公司，现任微软研究院首席研究员，兼任浙江大学兼职教授和中科大客座教授。语音识别和深度学习方向的资深专家，出版了两本专著，发表了 160 多篇论文，是 60 余项专利的发明人及深度学习开源软件 CNTK 的发起人和主要作者之一。曾获 2013 年 IEEE 信号处理协会最佳论文奖。现担任 IEEE 语音语言处理专业委员会委员，曾担任 IEEE/ACM 音频、语音及语言处理汇刊、IEEE 信号处理杂志等期刊的编委。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;以下是此次专访的内容：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：请俞老师先给我们的读者介绍一下目前语音识别方面最值得关注的一些方向。&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;俞栋&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：在安静环境下并使用近距麦克风的场合，语音识别的识别率已越过了实用的门槛；但是在某些场景下效果还不是那么好，这就是我们这个领域的 frontier。现在大家主攻几点：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;首先，是不是能够进一步提升在远场识别尤其是有人声干扰情况下的识别率&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。目前一般远场识别的错误率是近场识别错误率的两倍左右，所以在很多情况下语音识别系统还不尽如人意。远场识别至少目前还不能单靠后端的模型加强来解决。现在大家的研究集中在结合多通道信号处理（例如麦克风阵列）和后端处理从拾音源头到识别系统全程优化来增强整个系统的 表现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;另外，大家还在研究更好的识别算法&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。这个「更好」有几个方面：一个方面是能不能更简单。现在的模型训练过程还是比较复杂的，需要经过很多步骤。如果没有 HTK 和 Kaldi 这样的开源软件和 recipe 的话，很多团队都要用很长时间才能搭建一个还 OK 的系统即使 DNN 的使用已经大幅降低了门槛。现在因为有了开源软件和 recipe，包括像 CNTK 这样的深度学习工具包，事情已经容易多了，但还有继续简化的空间。这方面有很多的工作正在做，包括如何才能不需要 alignment 、或者不需要 dictionary。现在的研究主要还是基于 end-to-end 的方法，就是把中间的一些以前需要人工做的步骤或者需要预处理的部分去掉。虽然目前效果还不能超越传统的 hybrid system，但是已经接近 hybrid system 的 performance 了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;另外一个方面，最近的几年里大家已经从一开始使用简单的 DNN 发展到了后来相对复杂的 LSTM 和 Deep CNN 这样的模型&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。但在很多情况下这些模型表现得还不够好。所以一个研究方向是寻找一些特殊的网络结构能够把我们想要 model 的那些东西都放在里面。我们之前做过一些尝试，比如说人在跟另外一个人对话的过程中，他会一直做 prediction，这个 prediction 包括很多东西，不单是包括你下一句想要说什么话，还包括根据你的口音来判断你下面说的话会是怎样等等。我们曾尝试把这些现象建在模型里以期提升识别性能。很多的研究人员也在往这个方向走。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;还有一个方向是快速自适应的方法—就是快速的不需要人工干预的自适应方法（unsupervised adaptation）&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。现在虽然已经有一些自适应的算法了，但是它们相对来说自适应的速度比较慢，或者需要较多的数据。有没有办法做到更快的自适应？就好像第一次跟一个口音很重的人说话的时候，你可能开始听不懂，但两三句话后你就可以听懂了。大家也在寻找像这种非常快还能够保证良好性能的自适应方法。快速自适应从实用的角度来讲还是蛮重要的。因为自适应确实在很多情况下能够提升识别率。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从识别来讲，我觉得目前主要是这些方向。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：Google DeepMind 最近提出了一种通过学习合成波形的方式生成语音的技术 WaveNet，据说可以生成感觉更自然的语音，微软在这方面有什么研究项目？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;俞栋&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：微软也在做类似的工作，但是因为合成的研究团队和工程团队都在中国，我对他们具体到哪个地步不是特别清楚。有一些信息我也不能直接披露，所以就不详细讲了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：深度学习已经在语音识别得到了非常出色的表现，您觉得未来语音识别还能在深度学习的哪些方面实现突破？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;俞栋&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：刚才我讲了，其中的一个可能性就是通过各种类型的 prediction 和 adaptation 使得深度学习模型表现更出色，这是有可能继续提升的地方。另外就是 end-to-end 建模。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;还有，像我们最近也在做一些特殊环境中的语音识别，比如说在高噪音环境下、或者你说话的时候有背景的音乐、或者是会议室里面有多个人同时说话——这些情况下现在的语音识别效果是很差的。所以我们也在研究如何用深度学习的方法在比如多说话人的情况下做得比原来传统的方法好。我们现在已经在 arXiv 上面发布了一个早期结果的预印本（Permutation Invariant Training of Deep Models for Speaker-Independent Multi-talker Speech Separation），含有更多实验结果的正式版本现在正在审稿中。我们的这一称为 Permutation Invariant Training 的方法主要用于语音分离。用这种方法整个 process 比较简单而效果很好。在这些方面深度学习都能带来一定的突破。当然，我前面也讲了，完全解决这些问题需要软硬结合，从拾音到前端和后端需要系统性优化。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：在类似汉语这种多音字、多音词比较多的语言中，语音识别方面有什么和英语这样的拼音语言不一样的地方？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;俞栋&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：从语音识别的技术角度来讲，没有太大的区别。因为你最终都是将语音信号，即 waveform sequence，变成字或者词的 sequence。多音字和多音词只是词表里对应的字或词有多个发音规则而已，这在其他语言比如英语中也很常见。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不过中文是一个有音调的语言，音调对字和词的识别是有影响的。音调信息如果用好的话，就有可能提升识别率。不过大家发现 deep learning 模型有很强的非线性映射功能，很多音调里的信息可以被模型自动学到，不需要特别处理。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;唯一可能不一样的地方是如果你用 end-to-end system，建模单元会不一样。因为在英语里面你一般会选用字母、音素、或音节 作为建模单元，而不会选用词作为建模单元。但在中文里面你可以直接用汉字作为建模单元。所以建模单元的选择上可能会不太一样。除此之外，基本上没有太大区别。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：技术上没有太大区别？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;俞栋&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：没有太大区别。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：具体来说，您觉得自然语言处理能够给语音识别带来哪些帮助？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;俞栋&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：目前来讲，自然语言处理对语音识别本身的帮助还不是很大。要说帮助比较大的方面——如果语言模型（language model）算做自然语言处理的话，语言模型还是起到了很大作用的，尤其是在有噪音的环境下，如果没有语言模型来做约束，效果一般来说都比较差。但是除此之外，现在的 NLP 技术对语音识别没有起到很大的作用。大家尝试过很多用自然语言处理技术提升识别率的方法，但效果都不理想。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是理论上来讲它应该是可以起到作用的。因为我们理解句子含义，我们能发现有一些语音识别结果是不 make sense 的，比如说前面的主语跟后面的宾语根本就不搭，在这种情况下识别系统应该选择其他的 hypothesis，对话系统则应该寻求澄清，但是现有系统没有这么做。没有这么做的原因在于它其实不理解到底用户说了什么，也没能充分利用远距离的 dependency 信息。这样的错误，有可能通过自然语言处理的技术发现并得到更正。但是语义分析是个很困难的问题，如何做还是一个未知数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：刚才我们讲到在噪音环境下，包括远距离环境下的识别，除了这个，还有多个说话人一起说话的情况下的语音识别。在这三个方面，您觉得现在和未来可以通过什么样的方式来解决这个问题？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;俞栋&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：前面提到过，解决远距离识别很重要的一点是需要硬件的支持。至少以目前的技术，仅仅通过后端处理效果还不够好。因为信号在传输的过程中衰减很厉害，距离越远衰减越厉害，信噪比就越差。所以远距离识别一般都需要做增强。比较好的增强需要硬件支持，比如说麦克风阵列。深度学习方法也能提供一些帮助。当你有多通道信息的时候，深度学习方法还可以做自动的信息融合以提升远距离语音识别的性能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;多通道信号处理，比如麦克风阵列，对分离含噪语音和多人混合语音也至关重要。另外，深度学习方法比如我刚才提到的 Permutation Invariant 训练方法也可以解决一部分语音分离问题，是整体解决方案中的重要一环。分离后的结果可以送到后端做识别。后端的识别结果反馈回来也能帮助提升分离和说话人跟踪的效果。所以最终的系统应该是前端的分离跟后端的识别融合互助的系统。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：从您和邓力老师的那本书《Automatic Speech Recognition： A Deep Learning Approach》出版到现在，您认为期间深度学习有了什么新的研究成果? 哪些研究成果您认为是很重大的？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;俞栋&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：我们写这本书的时候，LSTM 这样的模型才刚刚开始成功应用于语音识别。当时大家对其中的很多 技巧 还没有很好的了解。所以训练出来的模型效果还不是那么好。最近，我的同事 Jasha Droppo 博士花了很多时间在 LSTM 模型上面，提出了一种很有意思的基于 smoothing 的 regularization 方法使得 LSTM 模型的性能有了很大的提升。他的 smoothing 方法的基本思想在我们的 human parity 文章中有介绍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外一个比较大的进展是 Deep CNN。最近两年里，很多研究组都发现或证实使用小 Kernel 的 Deep CNN 比我们之前在书里面提到的使用大 kernel 的 CNN 方法效果更好。Deep CNN 跟 LSTM 比有一个好处。用 LSTM 的话，一般你需要用双向的 LSTM 效果才比较好。但是双向 LSTM 会引入很长的时延，因为必须要在整个句子说完之后，识别才能开始。而 Deep CNN 的时延相对短很多，所以在实时系统里面我们会更倾向于用 Deep CNN 而不是双向 LSTM。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;还有就是端到端的训练方式也是在我们的书完成后才取得进展的。这方面现在大家的研究工作主要集中在两类模型上。一类就是 CTC 模型，包括 Johns Hopkins 大学的 Dan Povey 博士从 CTC 发展出来的 lattice-free MMI；还有一类是 attention-based sequence to sequence model。这些模型在我们的书里面都没有描述，因为当时还没有做成功。即便今天它们的表现也还是比 hybrid model 逊色，训练的稳定性也更差，但是这些模型有比较大的 potential。如果继续研究有可能取得突破。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外一个进展是单通道语音分离，尤其是多人混合语音的分离。这方面有两项有趣的工作。一个是 MERL 的 John Hershey 博士提出的 Deep Clustering 方法，另外一个是我们提出的 Permutation Invariant Training。实现上，Permutation Invariant Training 更简单。John Hershey 认为有迹象表明 deep clustering 是 permutation invariant training 的一个特例。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些都是在我们完书之后最近两年里比较有意义的进展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：也是在这个月，Google 发了神经网络翻译系统（GNMT），您对这个系统有什么看法？微软在这方面有没有这样的研究？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;俞栋&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：微软很早以前就在做类似的工作了。你可能知道微软有个基于文本的翻译系统，在 Skype 上也有一个 speech to speech translation system。在这些系统里我们已经用到了 neural machine translation 的一些东西。不过翻译主要是由另外的团队在做，我在这里面涉及比较少。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：语音特征参数提取与鲁棒性语音识别与合成的关键因素，特征参数在不利的噪声环境下，鲁棒性都会急剧下降。目前有什么新的研究可以在特征提取中保持语音信号的最重要参数吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;俞栋&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：目前，一个方法是用信号处理技术对输入信号进行分离和增强。另一个方法是用 deep learning 取代人工从 waveform 直接提取特征。只要训练数据的 coverage 足够大，各种各样场景的训练数据都有，模型的结构设计合理，那么模型的泛化能力和鲁棒性就能得到提升。两种方式结合可以得到更好结果。不过，泛化是机器学习的一个未解决的基本问题，更好的解决方案有待于机器学习理论的进展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：微软在语音识别上如何解决方言带来的口音问题，比如说「le」和「ne」？针对方言，微软的语料库是从何而来的？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;俞栋&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：一个简单的方法是增加带口音的训练语料。如何有效利用这些语料有些讲究。大概 3、4 年前，我们发过一篇文章，研究怎么样在 deep learning model 上做自适应。带口音的识别问题可以看作一个自适应的问题。假设你已经有标准语音的模型，带口音的语音可以看成标准语音的某种偏离。所以我们的解决方法是做自适应。做自适应的时候，我们可以把有类似口音的语料聚合在一起以增加训练数据。我们发现这样做效果挺不错。如果已经有系统上线，收集带口音的语料并不困难。如果你用过 Windows Phone，你就知道 Windows Phone 的 Cortana 里面有个选项——你想用标准的识别模型还是想用含口音的模型？用户可以选择。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：今年，微软发布了 CNTK。您能说一下 CNTK 跟 Theano、TensorFlow、Torch、Caffe 这些工具的区别吗？以及在微软语音系统上是怎么样应用 CNTK 的？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;俞栋&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：所有的这些开源工具现在都做得相当好了，都能够满足一般的研究或者是工程的需要。但是每一个开源工具都有自己的长处和弱点。CNTK 是唯一一个对 Windows 和 Linux 都有比较好的支持的深度学习工具。相比较其他工具，CNTK 对多 GPU 并行训练有更好的支持, 不仅并行效率高，而且简单易用。CNTK 对 C++的支持也是最全面的，你可以完全使用 C++来构建、训练、修改、和解码模型。CNTK 版本 1 对 Python binding 支持比较弱。但是刚刚发布的版本 2.0 提供了非常强大的 Python binding。另外，CNTK 提供了许多运行效率很高的并行文件阅读模块，大大提升了并行效率。这里我想提一下，我的很多同事都对 CNTK 2.0 有很大贡献。尤其值得一提的是 Amit Agarwal，他是我见过的非常难得的优秀软件工程师和架构师，他主导设计了 CNTK2.0 的主要 API。我在他身上学到很多东西，我非常享受与他讨论的时间。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我和几个同事刚开始写 CNTK1.0 的时候，主要用户是语音识别研究员和工程师，所以 CNTK 对语音相关的模型、数据结构、和文件格式支持得相对比较好。因为语音识别系统训练数据很大，我们很早就在 CNTK 中实现了并行训练的算法。目前，微软产品线所有的语音识别模型都是用 CNTK 训练的。最近我们的语音识别系统在 SWB 数据集上能做到比专业转录员错误率还低，CNTK 对缩短我们达到这一里程碑所需的时间有很大贡献。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：您曾说过，人工智能的成功在于将多种方法的整合到一个系统。在你们最近发表的论文中，我们看到目前最新的语音识别的研究用到了多任务优化（Multitask Joint learning）以及多种模型混合（ensembles of models）的方法，能谈谈他们的优势吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;俞栋：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;语音识别相对来说是一个任务比较单一而非通用的人工智能系统。语音识别的问题定义得也比较清晰。在这样的系统里面，把深度学习模型与其他模型进行整合的重要性相对来说比较小。这也就是为什么只要你有足够的数据和运算能力，即便是完全的 deep learning end-to-end system 表现也不错。不过目前来讲，深度学习和 HMM 相结合的混合模型在大多数场景下仍然表现最佳。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;语音识别中使用多任务优化的主要目的是增加模型的泛化能力或利用一些不能直接利用的辅助信息。而多种模型混合（ensembles of models）的主要目的是利用模型间的差异来增强混合后模型的表现。值得指出的是，由于深度学习模型是非线性非凸的优化问题，当初始模型不同时，最后的模型也不同。尽管这些模型的平均表现很接近，但因为他们收敛到的点不一样，模型之间仍有差异，融合这些模型也能提升一些性能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是更通用的人工智能系统还需要能做决策（decision-making）、要做推理、要能理解。对于这样的系统来说，单靠深度学习方法远远不够。而需要结合过去几十年里人工智能其他分支取得的一些进展，比如说增强学习、逻辑推理、知识表达、以及最优和次优搜索。还有如果我们想让一群人工智能系统自己从与环境的交互中快速寻找答案，那么诸如蚁群算法和遗传算法一类的算法就变得很重要了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：今年您觉得在语音识别方面有哪些比较重量级的论文值得去读，能否推荐几个给我们的读者？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;俞栋&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：除了前面提到的 LF-MMI 、 Deep CNN（包括我们最近发表的 LACE 模型）、和 Permutation Invariant Training，另外一个比较有意思的论文是 MERL 在 arXiv 上发表的一篇文章。他们结合了 CTC 和 attention-based model，利用这两个模型各自的长处来克服对方的弱点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;	&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：您是怎么看待监督学习、半监督学习和无监督学习这三个学习方式呢？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;俞栋&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：监督学习是比较 well-defined，有比较明确的任务。目前来讲，深度学习对这一类问题 效果比较好。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;无监督学习的目的是要寻找数据中的潜在规律。很多情况下，它试图寻找某种特征变换和相对应的生成模型来表达原始数据。但无监督学习不仅本身困难，对无监督学习系统的评价也很难。原因是通过无监督学习找到的规律不一定对你将来的任务有帮助，或者它对某一任务有帮助，换一个 任务就没有帮助了。当然，如果你的目标仅仅是数据压缩，评价还是容易的，但我们使用无监督学习压缩本身往往不是主要目的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：那半监督学习呢？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;俞栋&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：半监督学习介于两者中间。因为你已经有一部分标注信息了，所以你 的任务是明确的，不存在不知如何评估的问题。半监督学习在实用系统里还是有一定作用的。比如说我们需要标注大量数据来训练语音识别系统，但人工标注既花时间又花钱，所以你往往有比标注数据多得多的未标注数据。没有标注过的数据，也有很多可以利用的信息，虽然它们的价值远远小于标注的数据。半监督学习对我们的系统性能有一定的提升。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：最后一个问题，在整个人工智能的布局上，您认为语音识别是一个怎样的定位？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;俞栋：在很多应用场合，语音识别是一个入口。没有这个入口的话，大家都会觉得这个智能机器不够智能或者与这个智能机器交互会有困难。人机交互中语音识别是第一步。如果语音识别做得不够好，那后期的自然语言理解等的错误率就会大幅上升。这也是为什么语音到语音的翻译要比文本到文本的翻译难很多，因为在语音对语音的翻译系统里语音识别产生的错误会在后面翻译的过程中放大。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;历史上，语音识别也为机器学习和人工智能提供了很多新的方法和解决方案。比如语音识别里的关键模型 Hidden Markov Model 对后来机器学习的很多分支都有帮助。深度学习也是先在语音识别上取得成功，然后才在图像识别和其他领域取得成功的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8G2Aqj8cfARvWSIzEs1ZXZgT6VrNdsVA4icyCrL6lqQtv3wPx1Ij2rZn8odibiaN7LBAPnqsPNXxteg/0?wx_fmt=jpeg"/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;专访 | 微软人物志 &lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650714822&amp;amp;idx=1&amp;amp;sn=e56ee226cdacab228e1ad9fc40646adf&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650714822&amp;amp;idx=1&amp;amp;sn=e56ee226cdacab228e1ad9fc40646adf&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;微软研究院人工智能首席科学家 | &lt;/span&gt;&lt;span&gt;邓力&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719843&amp;amp;idx=2&amp;amp;sn=4611f810734df8a72286567e90c65a92&amp;amp;chksm=871b021db06c8b0b283ac93f267d95365392be02b3cde5d2fe6df85b359aa96368f25318e2f5&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719843&amp;amp;idx=2&amp;amp;sn=4611f810734df8a72286567e90c65a92&amp;amp;chksm=871b021db06c8b0b283ac93f267d95365392be02b3cde5d2fe6df85b359aa96368f25318e2f5&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;&lt;span&gt;微软首席语音科学家 | &lt;/span&gt;黄学东&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=400579280&amp;amp;idx=1&amp;amp;sn=b13556c48c2937593ee833e8284f2c89&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=400579280&amp;amp;idx=1&amp;amp;sn=b13556c48c2937593ee833e8284f2c89&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;微软亚洲研究院院长 | 洪小文&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=401882267&amp;amp;idx=1&amp;amp;sn=eb5a4cf6e10b6dc3787303f421a8f77b&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=401882267&amp;amp;idx=1&amp;amp;sn=eb5a4cf6e10b6dc3787303f421a8f77b&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;微软（亚洲）互联网工程院院长 | 王永东&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650714905&amp;amp;idx=2&amp;amp;sn=ad19a7e003ecdb48b0ffc524e8c2c94b&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650714905&amp;amp;idx=2&amp;amp;sn=ad19a7e003ecdb48b0ffc524e8c2c94b&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;微软亚洲研究院首席研究员 | 霍强&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;strong&gt;机器之心&lt;/strong&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8G2Aqj8cfARvWSIzEs1ZXZ248wIRLFyLjemC1oeWWd1em6qPOfHVREYUvcibiamyGHjAkDJH7mOC4w/0?wx_fmt=jpeg"/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;</description>
      <pubDate>Mon, 31 Oct 2016 12:46:20 +0800</pubDate>
    </item>
    <item>
      <title>学界 | CMU全新编码器解-码器框架：一种用于描述生成的Review Network（附项目地址）</title>
      <link>http://www.iwgc.cn/link/3299918</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;选自GitHub&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：杜夏德&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;卡耐基梅隆大学提出了一种新的编码器-解码器框架 —— review network，该框架在提升图像和源代码描述的任务上超过了现有其他最先进的系统。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们提出了一种编码器-解码器框架的新扩展，叫review network。这种 review network是通用的，能够增强任意现有的编码器-解码器模型：在这篇论文中，我们探讨了带有CNN和RNN编码器的RNN解码器。该review network在编码器隐藏状态下执行一些review步骤，并在每一次review后输出一个 thought vector；这些 thought vectors 在解码器中被用作注意力机制（attention machine）的输入。我们发现在我们的框架中，卷积的编码-解码器是一个特例。经过实证，我们发现我们的框架在提升图像和源代码描述的任务上超过了目前所有最先进的编码器-解码器系统。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;项目地址：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt; https://github.com/kimiyoung/review_net&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;用于描述生成的 R&lt;span&gt;eview Network&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;在 MSCOCO 上给图像添加描述&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你可以在这个 repo 中使用这个代码来生成一个 MSCOCO 评估服务器（CIDE.r=0.96+), 这个过程需要几个小时。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;无需微调，没有花哨的技巧。仅训练三个端到端的 &lt;span&gt;review network&lt;/span&gt;，然后做一个集成：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;特征提取：并行 2 小时&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;单一模型训练：6 小时&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;集成模型训练：30 分钟&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;描述生成的波束搜索：并行 3 小时&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面是我们的系统在 MSCOCO 评估服务器上与其他先进系统的比较（根据已发表的论文）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;th&gt;Model&lt;/th&gt;&lt;th&gt;BLEU-4&lt;/th&gt;&lt;th&gt;METEOR&lt;/th&gt;&lt;th&gt;ROUGE-L&lt;/th&gt;&lt;th&gt;CIDEr&lt;/th&gt;&lt;th&gt;Fine-tuned&lt;/th&gt;&lt;th width="79"&gt;Task specific features&lt;/th&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;Attention&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.537&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.322&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.654&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.893&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;No&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="79"&gt;No&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;MS Research&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.567&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.331&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.662&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.925&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;No&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="79"&gt;Yes&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;Google NIC&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.587&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.346&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.682&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.946&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;Yes&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="79"&gt;No&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;Semantic Attention&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.599&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.335&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.682&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.958&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;No&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="79"&gt;Yes&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;Review Net&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.597&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.347&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.686&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.969&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;No&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="79"&gt;No&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 image_caption_online 目录下，你可以使用里面的代码重现我们的评估服务器的结果。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 image_caption_offline 目录下，你可以使用离线评估重新运行我们论文中的实验。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;添加代码描述&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一个有趣的任务是预测一条源代码的注释。在这个 repo 中，除了一个&lt;span&gt;review network&lt;/span&gt;的代码外，我们也开放了一个带有 train/dev/test 分类的数据集。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;查看 code_caption 目录。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面是我们的框架系统在代码描述数据集上与基线的比较。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;th&gt;Model&lt;/th&gt;&lt;th&gt;LLH&lt;/th&gt;&lt;th&gt;CS-1&lt;/th&gt;&lt;th&gt;CS-2&lt;/th&gt;&lt;th&gt;CS-3&lt;/th&gt;&lt;th&gt;CS-4&lt;/th&gt;&lt;th&gt;CS-5&lt;/th&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;LSTM Language Model&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;-5.34&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.234&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.2763&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.3&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.3153&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.329&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;Encoder-Decoder&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;-5.25&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.2535&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.2976&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.3201&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.3367&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.3507&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;Encoder-Decoder (Bidir)&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;-5.19&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.2632&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.3068&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.329&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.3442&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.357&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;Attentive Encoder-Decoder (Bidir)&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;-5.14&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.2716&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.3152&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.3364&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.3523&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.3651&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;Review Net&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;-5.06&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.2889&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.3361&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.3579&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.3731&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;0.384&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;参考文献：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;用于描述生成的review networks（Review Networks for Caption Generation），&lt;/span&gt;&lt;span&gt;这个 repo 中包含的代码和数据可在这篇论文中找到。（点击「阅读原文」下载论文）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Mon, 31 Oct 2016 12:46:20 +0800</pubDate>
    </item>
    <item>
      <title>学界 | Yoshua Bengio最新论文：一种用于训练循环网络的新算法Professor Forcing（附论文）</title>
      <link>http://www.iwgc.cn/link/3299919</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;选自arXiv&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9I0lJy7h7Z6eSXUB9HJUgibXwlVb7BOrFvyibhww67kZd61G4ptL1icZ5htQ9Ako7VJI7CmVSP6M35A/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：&lt;/span&gt;&lt;span&gt;Teacher Forcing 算法通过将被观察到的序列值作为训练过程中的输入和使用该网络自己的提前一步的预测（one-step-ahead predictions）来进行多步采样（multi-step sampling）。我们在这里介绍 Professor Forcing 算法，其使用了对抗域适应（adversarial domain adaptation）来促进训练网络的动态（dynamics）在训练网络时和从网络中进行多个时间步骤的采样时一样。我们将 Professor Forcing 应用到了语言建模、在原始波形的声音合成、手写生成和图像生成上。我们的实验表明 Professor Forcing 可用作正则化器（regularizer），其能提升在字符级 Penn Treebank 和序列的 MNIST 上的测试似然（test likelihood）。我们还发现该模型可以定性地改进样本，尤其是当要进行大量时间步骤的采样时。这也得到了人类对样本质量的评估的支持。我们讨论了 Professor Forcing 和 Scheduled Sampling 之间的权衡。我们产生了 T-SNE，表明 Professor Forcing 能成功使训练过程和采样过程中的网络动态更为相似。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9I0lJy7h7Z6eSXUB9HJUgib5mmYZBS2bWmK8KVDBwggWibz0OwMILCsJq2Bpq61d64FWdIkgsfZ4dQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 ：Teacher Forcing（左）和 Professor Forcing（右）的样本&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Mon, 31 Oct 2016 12:46:20 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 智能技术+电力驱动：曾被巨头们垄断的汽车业正迎来变革</title>
      <link>http://www.iwgc.cn/link/3299920</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;选自TechCrunch&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李泽南、吴攀、蒋思源&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;法国 Mulhouse 的汽车城（Cité de l’ Automobile）是一个神奇的地方。这里有全世界最大的汽车收藏，瑞士兄弟 Hans Schlumpf 与 Fritz Schlumpf 为这里提供了大量藏品。他们将生意赚来的钱用于购买各种汽车，这对兄弟拥有一家纺织厂。有趣的是，他们的姓「Schlumpf」在德语中的意思是蓝精灵，如果你记得《蓝精灵》，在这里你也许会惊呼「Smurftastic!（真是蓝精灵的风格！）」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;由于他们的疯狂收集——以及纺织业中心在 20 世纪 70 年代转向亚洲——兄弟们的债务变得难以偿还，他们最终被迫离开了法国，回到瑞士。在那个时候，他们的汽车收藏已经价值连城，法国政府甚至发布了历史保护法令，让这些收藏免于被毁、拆解或出口，最终在 1978 年，这里被法国国务院认定为历史遗产加以保护。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9I0lJy7h7Z6eSXUB9HJUgibK2HewhPRGjoheEj5NtHm3P8OBanGW8HBmGYKJGmTut3aFKbtjCckvg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Cité de l’Automobile中的汽车长廊&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;几年前，我有幸来到这里参观，这里现在已是世界最大的汽车博物馆了，就像汽车时代的时间胶囊。当你漫步在博物馆的大厅里，身边数百辆各个时代的汽车依次排开，你会发现这些品牌都是由一个「初创」（是的，我想你可以把这个词语用在过去的公司上）阶段开始制造汽车、创立品牌、在市场竞争中获得立足之地。在汽车发展的过程中，马匹再也不是最好的交通工具了，它们最终变成了有钱人的玩具。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一次汽车行业繁荣是由工业革命带来的新技术推动的，这给当时的初创公司提供了机会，以有限的资金来设计和制造他们的第一辆车。举个例子：在二十世纪二十年代，汽车主要是框架车身，这种结构允许不同的供应商分别制造汽车的每一个部分，最终在生产线上将汽车拼装在一起。后来，一体化车身出现了，汽车的制造门槛开始提高，行业开始高度集成——这让大规模的公司变得越来越有竞争力。现在的电动汽车让我们想起了那个框架车身的年代，就像 BMW i3，它拥有固定框架容纳传动系统和电池。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以下这些名字只是 Mulhouse 博物馆馆藏的一部分，如果你认识其中三个以上名字的话，你就是一个汽车专家了：ABC,Amilcar, Arzens, Aster, Ballot, Bardon, Barraco, Barré, Baudier, B.N.C, Bollée, Brasier, Charron, Cisitalia, Clément de Dion, Clément-Bayard, Clément-Panhard, Corre La Licorne, Darracq, Decauville, De Dietrich……&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些上古时代的优秀初创企业并没有遇到其后阻止一切新来者的技术壁垒——内燃式发动机。这是一个被通用、福特、奔驰、丰田、宝马和大众等巨头占据超过 40 年的领域。它的出现让大小厂商之间出现了一道难以逾越的鸿沟，如今，迈凯伦、布加迪和 Lotus 早已无力向这些巨头发起挑战。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当然，现在也有像 DeLorean、Fisker 和 Artega 这样的汽车创业公司，但是提到普通汽车的制造和销售，更不用说维持经销渠道和资金链，大多数人认为这是一个由大规模和纯粹的金融力量主导的游戏。成功地在汽车行业中创建一个新的品牌难度颇大。每个获得资金少于 1 亿美元的企业迟早都会失败。特别是对于投资者来说，这个行业被认为是一个禁区，因为涉及的风险很大、成功率低。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;「我们看到了数量巨大的轿车，商用汽车和其他交通工具的初创企业。」&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这一切都在 2004 年台湾的一个路演中被改变了。有一个人带着他的汽车模型，试图为他的产品募集资金：Tesla Roadster。这辆新车的大多数零件都来自于这个两千三百万人口的岛屿，台湾以提供世界 80% 的 PC 与笔记本电脑闻名于世，提供 iPhone 和其他手机的几乎所有芯片。这些制造商里不乏知名企业，包括富士康、和硕联科和纬创。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 2006 年初代特斯拉发布的时候，它的发动机就是在台湾生产的。伊隆 ·马斯克在所有人之前认识到，科技和汽车世界中，初创阶段没有区别。他获得了初始投资并开始大胆展望——没有听从那些专家的意见。特斯拉在 2009 年之间实现融资 1.8 亿美元，卖出了 147 辆汽车。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9I0lJy7h7Z6eSXUB9HJUgibR75lEFCwjt86FS7ffScZTmbQgfcJxRPUqaHK3IHWcC9ODzklxY7zpg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;em&gt;&lt;span&gt;特斯拉 Roadster，第一辆可以跑上公路的锂电池纯电动汽车&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;几年以后，数十亿美元的资金涌入特斯拉，世界看到了特斯拉能够做到其他公司想都不敢想的——向汽车工业发起进攻。因为计算机的力量，革新开始出现，故事进入了「创业者困境」的又一个章节，这一阶段就像哈佛大学教授 Clayton Chrstensen 说到的，新技术会让旧的巨头分崩离析。更重要的是，奥迪、宝马、丰田和奔驰等现在的大公司们已经开始紧张起来，认真对待电动汽车及其技术了。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;金融和技术上的壁垒已被打破。风险资本的世界对这些机遇感到兴奋，并且已经开始向这一行业投资。过去五年里，这一领域内的并购交易已经增长了超过 2200 亿美元。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;基于高度复杂生产技术（例如内燃机）的进入壁垒将会被抹平。电动机开始成为主流。比如说，电动传动现在可以外包给 Magna 这样的公司，它也许最终会成为这一领域的富士康。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但更重要的是特斯拉在机器学习上的独特优势，而且其在传统技术（内燃技术、未连接的汽车）的根基缺乏反倒让它能够先于对手进入这个规模更大、增长更快的市场。这种做法将会将没有连接和计算机的传统模式转变成拥有自主性、共享交通、乃至最终的按需用车的自主交通（Autopia-on-demand autonomous mobility）的模式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们正看到有很多想要创造新式汽车、商用载具和其它交通方式的创业公司涌现出来，其中包括：NextEV, Atieva, ThunderPower, Gogoro, Navya, Borgward, Local Motors, ZMP, Faraday Future, Starship, Varden Labs, Easy Mile, Auro Robotics, Gaius, LeEco（乐视超级汽车）, Dyson, Mission Motors, Boosted, Lit Motors,Renovo Motors, Inboard Technology, Future Motion, GLM, Dubuc Motors, Dagmy Motors, Newton Vehicles, ALTe Technologies, Lumen Motors, Barham Motors, Highlands Power, Myers Motors , Tratus, Virtus Motors, AC Motors, Scalar Automotive, Fenix Vehicles, Marfil, Esco Motors, Lithos Motors。我预计在未来几年内，还会有另外几百家公司出现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;如果不久的将来你看到有红牛牌汽车在路上行驶，不要感到惊讶。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;即使最创新的交通概念也会需要载具。和今天的载具相比，它们可能会有不同的构成因素，即是由不同的材料制成的、有不同的驱动方式和不同的控制方式。但总有人要去开发、制造、销售、维护和保护这些载具。如果一些参数像我们描述的那样发生了改变，现有的汽车制造商仍然还有随时间进行调整的能力。它们有获得利润的知识和流程，仍然能生产出复杂的、持久的和以安全为重的产品，而且它们知道怎么将其规模化。除此之外，它们已经有自己的品牌、声望和客户忠诚度了，这些都将能持续一段时间。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在特定一段时间内，主要的品牌将具有优势。动作快和资金充裕的新进入者也是如此。我们还有可能会看到专注于某些特定交通领域的品牌和公司出现。未来的许多进展都将基于现在尚没有答案的问题，比如新载具将会如何使用、城市和农村地区的交通如何分离、电动载具和自动化技术发展会有多快、人们会怎样接受、监管会帮助推进发展还是会拖后腿。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在汽车领域，消费者仍然会看重一些品牌的价值。保时捷这样的高端品牌就能够从这种价值受益，因此很可能不会受到像大众市场品牌那样大的影响。汽车的品牌将会有新有旧，就像大众甲壳虫的 Fender、Mini 的 Paul Smith、菲亚特 500 的 Gucci 等等。如果不久的将来你看到有红牛牌汽车在路上行驶，不要感到惊讶。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此外，即使汽车交通变得更加智能和更廉价，品牌也仍有它们的一席之地。即使 easyJet、维珍和瑞安等一些低成本的航空公司也具有自己的定位品牌。在航空业，旅客所选择的受欢迎的品牌是服务提供商（航空公司），而非载具（飞机）的制造商。我们可以想象在汽车行业和航空业之间存在一定的相似性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;还记得在 Cité de l’ Automobile 上展出的汽车公司列表吗？创业公司来了又去，只在博物馆里留下了一点遗迹。同样地，显然未来几年后前面所提到的一些汽车公司可能就已经不在了——但其中一些肯定会成为我们日常出行的主要装置。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现如今有很多新的品牌和新的想法进入这个庞大的交通运载市场（麦肯锡估值 6.4 万亿美元），并且它们并不仅仅是在制造汽车，更是在发展一个实现交通互联的新方式，这个新方式将能减少交通事故、加强道路安全、等等更多的提升。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一段时间之后，像 Schlumpf 兄弟那样的博物馆将陈列的是我们今天所熟知的汽车品牌。我很期待能有收藏者将这些新型汽车（最终的载具）都搜集到一起，并创建一个博物馆。这并不简单，但会给我们的后代带来很大的乐趣。历史总会不断重复。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Mon, 31 Oct 2016 12:46:20 +0800</pubDate>
    </item>
    <item>
      <title>思想 | 智能的终极命题：宇宙级的融合心智即是上帝本身</title>
      <link>http://www.iwgc.cn/link/3299921</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;选自科学美国人&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：&lt;span&gt; Freeman Dyson&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：曹瑞&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;「科学神学」思考的是心智的最终目的。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;科学神学家 Freeman Dyson 在评论智能的长远发展时说道：「我并没有在心智（mind）和上帝（God）之间划出明显的界限。心智在超出我们理解的范围之外时就会成为上帝。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9I0lJy7h7Z6eSXUB9HJUgibuJoMUp2lzw7aIRPDrV7D61qWXibuIWibRds6UEaCibJAGk0bzTmzJXnWQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这到底是好是坏呢？作为一个头发花白的科学迷，新的事物对我来说都像是老掉牙的了。比如说，在最近的一次人工智能大会上，听着那些聪明人们谈论、思考那些超级智能会想要什么，而对我来说，我一直在思考一些我曾经听过、看过和读过的东西。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;正如一些演讲者所认为的，无数科学幻想中都曾经想象过人工心智想要什么。电影中一些常见的答案有能量（比如说像《2001 太空漫游》、《终结者》、《黑客帝国》）、自由（像是《我，机器人》、《机械姬》），还有爱（斯蒂芬·斯皮尔伯格的《人工智能》、斯派克·琼斯的《她》）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是要是机器既具备能量，又拥有自由（可以说是同等的），还有它们需要的爱，会怎么样呢？或者说如果所有的机器都融合成一个庞大的心智呢？在这个时候，自由、能量和爱这些社会目标就会变得无关紧要。这些宇宙级的计算机到底想要什么呢？它们会做些什么来打发时间呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在《科学的终结》（The End of Science）一书中，我把这种推测叫做「科学神学（scientific theology）」。物理学家 Freeman Dyson 是我最喜欢的实践者。1979 年，他发表了一篇名叫「Time Without End: Physics and Biology in an Open Universe」的论文，对现代物理学进行了评论。Dyson 写这篇论文的目的就是为了反驳另一位物理学家 Steven Weinberg 臭名昭著的观点：「宇宙越难以理解，它就似乎越毫无意义」。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Dyson 反驳道，「没有智能的宇宙是没有意义的」。他试图向大家展示，即使是在一个不断膨胀的宇宙当中，通过精确地能量守恒，智能几乎能够永远坚持下去，防止热寂（heat death）。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在他 1988 年的文集Infinite in All Directions当中，Dyson 展望了智能充满整个宇宙并转化为巨大的宇宙级心智的情景，并问道：「在心智可以知会并且控制宇宙之后会选择做什么呢？」他认为我们不能确切地回答这个问题。因为这个问题涉及的是神学而不是科学：「我没有在心智和上帝之间划分明显的界限，心智在超出我们理解的范围之外时就会成为上帝。上帝可以被认为是一个世界灵魂，或者说是世界灵魂的集合。我们是当前这个星球上神的最主要入口，我们会随着神的成长而成长，要不然我们就会落后」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Dyson 的想法是受到了科幻小说作家（和哲学家）Olaf Stapledon 的影响，Olaf Stapledon 在 1950 年就去世了。在他的两部作品*Last and First Men*和*Starmaker*当中，Stapledon 想象了心智在上百万甚至是上亿年之后会变成怎么样？他假设宇宙心智想要创造。然后它就会成为一个艺术家，它的作品就是整个宇宙。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个想法很酷（这也意味着我们就生活在某个艺术作品当中），但是我还是更喜欢 Dyson 的假设。他猜想，一个宇宙心智不是一个艺术家，而是一个科学家，一个探索知识的人。我在 1993 年采访 Dyson 的时候，他非常有信心地说道对知识的追求的没有尽头的，因为知识是无穷无尽的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他的这种积极的态度部分是从哥德尔定理衍生而来的，每一个公理系统提出的问题都无法用这些公理解答。这条定理也暗示着数学是没有限制的，所以可以永远延续下去。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Dyson 对我说，「因为我们已经知道了物理定律其实是数学上的，而我们也知道数学是一个不相容的系统，所以说我们似乎有理由相信物理也是不相容的」，而且没有限制的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我在最后想象终极宇宙计算机——也就是「上帝」——的时候经历了非常艰难的时期，因为数学和物理问题让我想破了头。我的想法是（诚然是由于毒品的启发）它可以基于自己的来源思考问题。元问题是：它会解决这些玄之又玄的问题吗，还是说会永远被它难住？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;后记：另外还有两位神学家值得一提：物理学家 Frank Tipler，在他 1994 年出版的作品 The Physics of Immortality 中，他认为最终，像上帝一样的机器可以让在网络天堂（cyber-paradise）中幸福生活的每一个生物都能复活。另外一位是 Stanislaw Lem，他在 1961 年的小说《索拉里斯星》（Solaris）当中想象了人类和一个有感知的星球相遇的场景。他认为超智能是难以预测的。他的观点是否定的神学，因为他认为上帝永远都是在我们的理解范围之外的。Lem 非常聪明的一点是，他认为普通的人类心智也是非常难以预测的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Mon, 31 Oct 2016 12:46:20 +0800</pubDate>
    </item>
    <item>
      <title>深度 | 一篇文章带你进入无监督学习：从基本概念到四种实现模型（附论文）</title>
      <link>http://www.iwgc.cn/link/3288864</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Eugenio Culurciello's blog&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Eugenio Culurciello&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李亚洲、武竞&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em style="font-size: 12px;"&gt;这是今年 6 月份普渡大学副教授 Eugenio Culurciello 写的一篇关于无监督学习的概述性文章。除了基本概念，本文还介绍了无监督学习的四种实现模型：&lt;em style="color: rgb(136, 136, 136); text-align: justify; white-space: pre-wrap; font-size: 12px;"&gt;聚类学习、自动编码器、生成模型、PredNet。&lt;/em&gt;前几日，Culurciello 教授根据最近无监督学习的发展对此篇文章进行了更新与调整，机器之心对此进行了编译。文中提到的论文可点击「阅读原文」下载。&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;注：刘帝伟（译者）、刘翔宇（审校）两位老师对 6 月份的版本进行了编译并发布到了 CSDN 极客头条上，此篇编译文章借用了两位老师之前的翻译（有部分调整），如有不允，请联系机器之心，谢谢！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;无监督学习可谓是深度学习的圣杯，其目标是建立可兼容小数据集进行训练的通用系统，即便是很少的数据。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如今深度学习模型往往在大型监督型数据集上训练。所谓监督型数据集，即每条数据都有一个对应的标签。比如流行的 ImageNet 数据集，有一百万张人为标记的图像。一共有 1000 个类，每个类有 1000 张图像。创建这样的数据集需要花费大量的精力，同时也需要很多的时间。现在想象创建一个有 1M 个类的数据集。试想一下，对有 100M 数据帧的视频数据集的每一帧进行分类。该任务量简直不可估量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在，回想一下你在小时候是如何进行学习的。是的，那时候会有人指导你，你的父母会告诉你这是一个「猫」，但是他们不会在你余生的每一分每一秒都告诉你这是一只「猫」！如今的监督学习也是这样：我一次一次地告诉你，什么是「猫」，也许高达 100 万次。然后你的深度学习模型就学会了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;理想情况下，我们希望有一个模型，它的表现与我们的大脑非常相似。只需少量的标签便可理解这个多类的世界。这里所说的类，主要是指对象类、动作类、环境类、对象组成类等等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;基本概念&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;无监督学习研究的主要目标是预训练一个模型（称作「识别」或「编码」）网络，供其他任务使用。编码特征通常能够用到分类任务中：例如在 ImageNet 上训练会表现出很好的结果，这与监督模型非常接近。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;迄今为止，监督模型总是比无监督的预训练模型表现的要好。其主要原因是监督模型对数据集的特性编码的更好。但如果模型运用到其他任务，监督工作是可以减少的。在这方面，希望达到的目标是无监督训练可以提供更一般的特征，用于学习并实现其它任务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;自动编码器（auto-encoders）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该理论主要源于 1996 年 Bruno Olshausen 和 David Field（参见论文：Sparse Coding with an Overcomplete Basis Set：A Strategy Employed by V1）发表的文章。此文表明，编码理论可应用于视觉皮层感受野。他们发现，我们大脑的主要视觉皮层（V1）使用稀疏原理来创建可以用来重建输入图像的最小基函数子集。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;YannLeCun 团队在该领域也做了很多工作。在余下的文章中，你将看到一个很好的例子来解释类似 V1 的稀疏滤波器是如何学习的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;栈式自动编码器也会被用到，以贪婪式的方式逐层重复训练。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;自动编码器方法也被称为「直接映射」方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;自编码器/稀疏编码/堆栈自编码器的优点与缺点&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;优点：&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;简单技术：重建输入&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;可堆栈多层&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;直觉型，且基于神经科学研究&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;缺点：&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;贪婪训练每一层&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;没有全局优化&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;比不上监督学习的表现&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;层一多会失效&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;输入的重建可能不是学习通用表征的理想度量（metric）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;聚类学习（Clustering Learning）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一种技术是使用 K-均值聚类来学习多层的 filters。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们团队将这种技术命名为：聚类学习（参见论文：Clustering Learning for Robotic Vision）、聚类联结（参见论文：An Analysis of the Connections Between Layers of Deep Neural Networks）和卷积聚类（参见论文：Convolutional Clustering for Unsupervised Learning），最近它们在 STL-10 无监督数据集上取得了非常好的结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们在此领域的研究独立于 Adam Coates 和吴恩达（参见论文：Learning Feature Representations with K-means）的研究。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;众所周知，受限玻尔兹曼机（RBMs）、深度玻尔兹曼机（DBMs）、深度信念网络（DBNs）难以训练，因为解决其配分函数（partition function）的数值难题。因此它们还未被普遍用来解决问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;聚类学习的优缺点&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;优点：&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;简单技术：聚类相似输出&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;可被多层堆栈&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;直觉型，且基于神经科学研究&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;缺点：&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;贪婪训练每一层&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;没有全局优化&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;在一些情况下，比不上监督学习的表现&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;层数增加时会失效，收益递减&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;生成模型（generative models）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;生成模型，尝试在同一时间创建一个分类（识别器或编码器）网络和一个生成图像（生成模型）模型。这种方法起源于 Ian Goodfellow 和 Yoshua Bengio（参见论文：Generative Adversarial Networks）的开创性工作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Alec Radford、Luke Metz 和 Soumith Chintala 的 DCGAN（参见论文：Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks）是一种生成对抗模型，实例化这种模型，能够得到很好的结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面是系统框架图：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8G2Aqj8cfARvWSIzEs1ZXZRpNLOtd8REOOanicgibxl0UmwicOicztTk0Liban0BiaVfVEtQTYHkbODnYg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;DCGAN 识别器的目的是识别输入图像是否真实，或来自数据集，或是生成器生成的伪图。该生成器需要一个随机噪声向量（用 1024 个数值表示）作为输入，并产生一个图像。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 DCGAN 中，生成器网络如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8G2Aqj8cfARvWSIzEs1ZXZKjUOHvVzexib3jYSR0CjhrLwsghgOWNdQ1dKwbJljUp08VTiabdjWhTg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;识别器是一个标准的神经网络。详情请见下文。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;关键是以并行的方式训练两个网络而不是完全地过度拟合，从而复制数据集。学习特征需要推广到未知的实例，因此用于学习的数据集将不能再用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Torch7 提供了 DCGAN 训练代码（代码地址&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt;https://github.com/soumith/dcgan.torch），&lt;/span&gt;&lt;span&gt;可用于实验中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在生成器和识别器网络训练好之后，两者便可使用了。主要目标是为其它任务训练一个很好的识别器网络，例如对其它数据集进行分类。生成器则可用于生成随机向量的图像。这些图像有着非常有趣的特性。首先，他们提供了输入空间的平滑转换。看下面这个例子，它展示了在 9 个随机输入向量之间进行移动产出的图像：&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8G2Aqj8cfARvWSIzEs1ZXZS5iaKUk5uicxeGwsubOW4tbq3Hvt5pTUOrADcmicfxa4yJy7Dn6n28XTQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;输入向量空间还提供数学特性，表明学习特征是根据相似性进行组织的：&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8G2Aqj8cfARvWSIzEs1ZXZ1bRVtQfTicNCiasae8JMkNpBsMbA2SScmLsVicGp0OXd7bacU37RkHG3A/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;由生成器学到的光滑空间表明识别器也具有类似的性质，使它成为图像编码出色的特征提取器。这在不连续图像数据集训练 CNN 网络的经典问题上很有帮助，在这些数据集，对抗性噪声往往致使其走向失败（参见论文：Intriguing properties of neural networks）。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;近期对 GAN 训练的一次更新（参见论文：Improved Techniques for Training GANs）取得了在 CIFAR-10（只有 1000 个标记样本）上的 21% 错误率。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最近关于 infoGAN（参见论文：InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets）的一篇论文能够产生带有可被松解（disentangled）和有更多尤其意义的图片特征的非常锐利的图像。然而他们没有报告在任务或数据集上学习特征的表现，从而作为对比。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一个有趣的例子是作者使用生成式对抗训练来学习如何产生图像的文本描述。如下图：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8G2Aqj8cfARvWSIzEs1ZXZ3iaIiblro6j5BDR9yYeQVvibV4rwzamrcFJPfspicuTTZ488rEaaQibjtiaw/0?wx_fmt=png"/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我对此工作的赞赏之处在于它使用文本描述作为生成器的输入，这与随机向量完全不同，因此能够准确控制生成器的输出。如下图：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8G2Aqj8cfARvWSIzEs1ZXZsNvQcV5QnWZJVqHFM10IBQWia02lB6nfqppOAdjDulPqEyaibwtkwO2g/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;优点：&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;整个网络的全局训练（global training）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;代码和应用简单明了&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;缺点：&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;难以训练和转化（conversion）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;在某些情况下，与有监督学习的表现相似&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;需论证展示方法（representation）的可用性（这是所有无监督算法面临的问题）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过设定不需要标签的无监督学习任务，并设立训练目标解决任务，这些模型直接从无标签的数据学习。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;解决拼图谜题的无监督学习的视觉展示是一个很好的例子。作者将图像拆分，并以拼图谜题的形式呈现，最后通过训练一个深度神经网络来解决这个谜题。训练得到的网络是产生最好结果的预训练网络之一。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图像块（patch）和局部（locality）的无监督学习的视觉展示的也是一个很好的例子。这里，他们使用同一张图像上的两个位置相近的图像块。从统计数据来看，这 2 个图像块反映的是同一个对象。第 3 个图像块是随机从图片的任意位置获取的，从统计数据来看，与其它 2 个图像块反映的不是同一个对象。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然后，将这 3 种图像块传入一个深度神经网络进行训练，以区分相同对象和不同对象。训练得到的网络是产生最好结果的预训练网络之一。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;立体图像重建的无监督学习的视觉展示，例如通过左视图重建右视图。虽然这不是无监督学习的特有工作，但它可以使用无监督学习！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;使用替代类别（surrogate category）的无监督学习的视觉展示，使用图像块来创建大量的替代类别。增强这些图像块，然后用于训练基于增强替代类别的有监督网络。这给出了无监督特征学习的最好结果之一。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;使用视频的无监督学习的视觉展示，使用 LSTM 作为编码/解码器。LSTM 编码器通过运行一组视频帧（video frame）序列，来生成内部图像。这个内部图像然后通过另一个 LSTM 解码器，来产生一组目标序列。为了达到无监督学习，一种方法是预测与输入序列相同的序列。另一种方式是预测未来的视频帧。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一篇论文（MIT：Vondrick 和 Torralba）的视频有令人非常信服的结果。这项工作从 2015 年 4 月就开始了！这个思路的亮点是从视频输入来预测未来帧的图像。它使用的模型如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;PredNet&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;PredNet 是一个用于预测视频未来帧的网络。这个网址有很好的例子：https://coxlab.github.io/prednet/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;PredNet 是一个非常聪明的神经网络模型，在我们看来，它将在未来的神经网络中的发挥重要的作用。PredNet 的神经网络架构超越了单个有监督的 CNN 框架。PredNet 结合了生物启发和生物导向模型 [ 模拟人类大脑模型 ]（参见论文 https://papers.nips.cc/paper/1083-unsupervised-pixel-prediction.pdf）。它使用预测编码和使用 [ 神经模型中的反馈连接 ]（参见论文 http://arxiv.org/abs/1608.03425）。以下是 PredNet 模型和 2 个堆叠层（stacked layer）的示例：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该模型还具有以下优点：&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;使用无标签数据训练！&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;每层纳入损失函数（loss function）计算误差&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;通过监视错误信号来在线学习（online-learning）：当它不能正确预测输出时，它知道模型需要学习更新了&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;未来&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;未来由你创造。&lt;/span&gt;&lt;span&gt;无监督学习是一个非常开放的主题，你可以通过以下方式做出巨大贡献：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;创建一个新的无监督任务来训练神经网络，例如：解决一个谜题，对比图像块，生成图像，等等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;思考创建更好的无监督特征训练任务，例如：什么是对象以及什么是背景，立体图像的相同物体识别，视频帧的相同物体识别…… 这与人类的视觉系统的进化相似。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Sun, 30 Oct 2016 14:06:07 +0800</pubDate>
    </item>
  </channel>
</rss>
