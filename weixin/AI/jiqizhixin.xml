<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>机器之心</title>
    <link>http://www.iwgc.cn/list/670</link>
    <description>人与科技的美好关系</description>
    <item>
      <title>深度 | 亚马逊发布多款智能助理开发工具，看看Alexa副总裁怎么说？</title>
      <link>http://www.iwgc.cn/link/3735624</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自backchannel、geekwire&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;参与：微胖、吴攀、杜夏德&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;em style="color: rgb(136, 136, 136); font-size: 12px;"&gt;&lt;br/&gt;&lt;/em&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;em style="color: rgb(136, 136, 136); font-size: 12px;"&gt;亚马逊、苹果、谷歌和微软巨头之间正上演着类似《权力的游戏》一样的人工智能竞争，而亚马逊这家公司虽然一直以来对自家的技术谈得不多，但是却为消费者提供了很多实实在在的商品、为数以千计的公司提供了数据中心的托管服务、并且还拿出了一款能够回答问题、播放音乐以及完成其它 4998 种功能的突破性主打产品。&lt;/em&gt;&lt;span&gt;&lt;em&gt;&lt;br/&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在昨日拉斯维加斯召开的 AWS re:invent 大会上，亚马逊发布了三款新产品，Amazon Lex、 Amazon Polly、 Amazon Rekognition，并展示了开发者可以如何使用这三款产品为 Slack、Facebook Messenger、ZenDesk 等平台上的应用植入人工智能功能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9NeY8VCvx4aZszGgWsAG4Kz1Naa1iaxibfSVd6zFumbRYy2jIgFv65PUJMkWhdn0pibnhCGxlEldicqA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该想法的目标是让开发者能够用上亚马逊为自己开发的服务（比如 Alexa）。AWS 的客户不用再自己开发人工智能软件了，只要使用一个 API 调用或者 AWS 管理控制台（AWS Management Console）将一些智能功能添加到他们自己的应用中即可。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;AWS 的 CEO Andy Jassy 指出亚马逊已经研究人工智能和机器学习技术 20 年了，目前亚马逊现在的业务中有数千人服务于人工智能。现在公司要向三分之二的开发者开放后端设施。除了大会上发布的三款产品，未来一年亚马逊还会有更多的产品出来。亚马逊官方新闻稿上写道，「亚马逊的人工智能服务是全面管理的服务，所以开发者就没有开发深度学习算法、训练模型和投入基础设施的需要了。这就解放了开发者，让他们能够专注于打造全新一代能看、能听、能说、能理解、还能与周边世界互动的应用。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面简单介绍一下这三款新产品：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先是一款图像识别服务「Rekognition」，可以识别物体和场景；谷歌、微软也有类似的服务。亚马逊强调其系统的智能水平已经足够识别出图像中狗的品种，虽然竞争对手也能达到这个技术水平，但是不要紧，因为「Rekognition」还有价格优势，然而 Jassy 并没有在大会上给出报价。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第二款产品是 Amazon Polly，一种文本-语音转换服务，其中使用了大量机器学习技术。Jassy 说这款产品发出的声音能达到逼真的效果，「Polly 是专为解决语音生成技术中的难题而设计的。比如它能区分出单词『live』在短语『I live in Seattle 』和『Live from New York』中的发音差异。Polly 知道这对同形异义词的拼写相同但发音迥异。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Polly 能发出 47 种不同男性和女性的声音，支持 24 种语言。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后一个也最重要的产品是「Lex」。Jassy 说它就是驱动 Alexa 的技术，可以让你打造能实现 multi-step 对话功能的应用。开发者可以开始在 Lex 控制台（Lex Console）上设计自己的对话 bot，而且他们可以用少数样本短语训练这个 bot。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「你可以使用 Amazon Lex 打造自己的聊天 bot 和支持逼真互动的其他类型的网络&amp;amp;移动应用，这些 bot 可以为你提供信息、启动应用、简化工作活动、还可用来控制你的机器人、无人机和玩具。」在大会的展示上，我们看到 Lex 还可以轻松实现语音定机票。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Lex 还与 Lamda 等 AWS 的其它服务深入地整合到一起。此外，除了亚马逊自己的产品外，它还与 Facebook Messenger、Slack 和 Twilio 进行了整合，可以内置到几乎任何其它设备中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尽管亚马逊的产品整容豪华，但众所周知，在技术和产品规划上，有时候亚马逊甚至比苹果还神秘（今年早些时候，苹果启动了自己的机器学习项目）。不过后来，亚马逊 Alexa 的 Head scientist 兼副总裁 Prasad 已经公开论及公司在语音识别、自然语言理解技术方面的卓尔不群。当然，Alexa 就是支持热门产品 Echo 的对话平台系统。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Rohit Prasad 演讲之前，Backchannel 和他聊了聊，他阐明了 Alexa 的方向以及如何在为贝索斯招兵买马的同时又不涸泽而渔。出于长度和清晰度的考虑，本文对采访内容做了编辑。（Prasad 简称 P，BlackChanel 简称 B）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9NeY8VCvx4aZszGgWsAG4KNV7larfhoZPgmjibd4icVW2xIcvwzicibDc2Eo4fuPTJ1GGlVHa7D1lwFg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图：Rohit Prasad&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;B：你是 Alexa 部门的副总裁，请给我说说 2016 年的情况如何。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;P：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我们对目前的形势感到很兴奋。我们特意投放了几款设备，也对它们进行了扩展。在教会 Alexa 更好了解用户方面，我们已经取得巨大进步（就 Alexa 所涉的界面领域以及搜索资料的准确度而言）。以音乐领域为例：我们已经能够根据歌词为用户搜索或播放一首歌。最近，Alexa 上来自第三方的功能的增长速度越来越快。今年早些时候，我们只有几百个功能，现在却已经达到了 5000 的级别。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;B：想通过 Alexa 平台实现的对话愿景是什么？我们是不是可以和 Echo 进行交谈？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;P: &lt;/span&gt;&lt;/strong&gt;&lt;span&gt;Alexa 已经具备一大套功能和体验，用户只需单方面表达几个意图，系统就能以极高的准确度予以回应。就对话方面而言，我认为，正确实现这一点需要大量的权衡。Alexa 不应该回过头来为用户（没有必要的）的问题。否则会很让人沮丧。但是，必要时，它应该问问题，而且对话能力非常重要。你留意了 Alexa Prize 竞赛吗？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;B：就是今年 9 月宣布的，面向 CS 学生、奖金为 250 万美元的挑战赛吗？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;P：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;没错。在学术领域，很难在对话领域做研究，因为他们没有像 Alexa 这样的系统进行合作。所以，我们帮助他们用修改版的 Alexa 工具包，简单搭建新的对话功能。这个挑战赛旨在创造一种的社交机器人，它能够进行 20 分钟有意义、连贯、引人入胜对话。&lt;/span&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;B：你认为会是图灵测试类的对话吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;P：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我不这么认为。图灵测试归根结底也是是否能骗到人——你能骗到一个局外人（outsider) 以为它是一个人吗？如果你说的是某些任务，Alexa 已经超越人类。比如，人类很难在数以百万的目录中立刻找到某首曲目，是吧？Alexa 可以阶乘 60，人类却很难做到。所以，我们肯定不想让它类似一个图灵测试，更多与连贯性和参与度（engagement）有关。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;B：在于 Alexa 的二十分钟对话中，人们要谈论些什么呢？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;P：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我们给出主题。「你能说一下今天报纸的热门话题吗？」我们期待社交 bots 可以与你谈论类似科学发明或金融危机类的话题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;B：比赛反响热烈吗？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;P：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我们已经收到数以百计的申请。我们正在资助大学的学生——那些能从研究中抽身或者与其研究方向契合的研究生们，所以，我们想要确保这些学生做出的有吸引力的语言英语能够得到资助。申请很多，以至于我们不能仅资助原来计划的最初十支队伍，最终资助了十二支队伍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因为与人工智能和机器学习领域最优秀学生进行合作的需求很大，所以，学界也担忧会失去这个领域的核心人才。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这令人担忧。这也是我发起 Alexa Prize 的原因之一。我们希望能打造下一代的机器学习，人工智能科学家和学术界在这其中扮演重要角色。如果每一位教授都跳槽诸如我们这样的公司，不仅目光短浅也是非常吓人的事情。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一方面，显然，你们正在招人工智能人才，与谷歌、Facebook、微软、苹果甚至传统公司竞争。亚马逊心仪什么水准的新人？&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;B：我认为不需要回答这个问题，因为其他公司会抄袭。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;P：&lt;/span&gt;&lt;/strong&gt;实际上，如果你回答好了，那些人才可能会在这篇采访里的读到这些并给我们投简历。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在亚马逊这样的公司中，搞研究的独特之处在于聚敛数据、计算能力以及世界上最优秀人才来解决用户面对的问题。研究一个用户面临的问题并不会带走创新——事实上会加速创新，我们尝试解决的问题都是超级难的问题。Alexa&amp;nbsp;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;初诞之时，在许多领域解决语音识别、自然语言理解都是异常困难的事情。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;B:今天，你们在宣布一些会帮助开发者的新工具，对吧？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;P：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;是的。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em style="text-align: justify; white-space: pre-wrap;"&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;B：今天你们还发布了协助开发者的新工具，对吧？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;P：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;是的。我们想要为开发者简化的一个关键是我们称之为的「built-in intent（内置意图）」和「slot type（插槽类型）」问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;B：请解释一下。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;P：&lt;/span&gt;&lt;/strong&gt;对于大部分功能，人们可能都会需要说：「Alexa, stop」或「cancel」。你希望能够将这些命令或意图展现给开发者，而不是告诉开发者去自定义 cancel/stop 意图的执行。slot type 是指像城市名、词汇项这样的东西。这些方面我们之前已经做了一些，开发者通常会用到大约 10 个意图和 15 个插槽类型。所以，作为第三方功能的一部分，我们还宣布了一个包含了数百个内置功能（插槽类型）的大集合，其横跨多个不同的领域，包括书籍、视频和本地商家。同时也包含了一个大的意图集合，这可以用来帮助回答用户向 Alexa 提出的问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以换句话说，如果我是开发者，我就可以依赖你们内置的词汇库或你们对同义词的解释来使我的功能更加智能。而且你们还在继续做到更多。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;确实如此，这能在功能的交互上给你提供一个好得多的起点。我们是将其作为一个开发者的预览版本宣布的，原因有二。一是我们想看到人们会如何在他们的意图中使用这些，因为我们自己对这些意图的使用和应该被使用的类型有自己预设的心态。但是开发者的心态可能会稍微不一样。我们希望确保能够从开发者那里得到一些反馈，帮助我们不断改进，而我们也将继续增加越来越多的内置功能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;B：目前来看，当用户在 Echo 上调用一个功能时，Alexa 的心智在某种程度上是开发者心态的体现。所以你们今天在做的事情的目标是实现开发者可以接插上去的标准 Alexa 词汇库和执行方法吗？&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;P：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;完全正确。这会为共享和帮助 Alexa 自己变得越来越好而创建一个共同的词汇库。开发者可以继承这个新功能，这样他们就不再需要重新创造同样的东西了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;strong&gt;B：&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;对于&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt; Alexa，我的问题是它的功能太多了，我有点招架不住。一般来说，你首先要了解一个功能，然后才能使用它。现在你们有多达 5000 个功能了，而且还在增加，用户怎么跟得上？&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;P：&lt;/span&gt;&lt;/strong&gt;我们肯定希望 Alexa 能通过第三方功能告诉你如何完成你的请求，即使你自己并不知道这个功能。我们还没有完成，但很显然这在我们的规划之中。一个共同的词汇库能够帮助我们打通这种连接。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;B：使用人工智能打造对话式接口的公司没有几家，亚马逊就是其中之一。你们的方法有什么独特之处？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;P：&lt;/span&gt;&lt;/strong&gt;不涉及到手的操作能力是其中的关键。这是语音的「杀手级应用」。如果你特别思考一下 Alexa 和 Echo，它们必须要能够解决没有屏幕的困难的交互问题。所以在对话式接口应该采用的形式上，我们从一开始的想法就和其它公司非常不同。这和在手机上可不一样；这是一种没有屏幕的完全专用的设备。我们必须解决这个难题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;B：家里摆着一个开放的麦克风，人们有什么需要担心的吗？如果人们担心「天啦！亚马逊一直在监听我！」，你会怎么说？&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;P：&lt;/span&gt;&lt;/strong&gt;隐私是很重要的，对于我们应对隐私的方式，我们一直是非常非常透明的。我们的云并没有监听你。只是设备，而且它也只是充当检测器，而不是识别所有对话的识别器。它只会检测有没有人对 Alexa 说话，而不会做其它的事。一旦它很确信了有人确实在对 Alexa 说话之后，我们才会开始向云传送数据流。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;B：Alexa 会变得像 Google Now 或苹果通知那样积极主动吗？比如说，如果它听见我在屋子里面走动，它就会提醒我应该出发了，不然会议就可能会迟到？&lt;/span&gt;&lt;br/&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;P：&lt;/span&gt;&lt;/strong&gt;我们当然思考过这个问题。因为在 Echo 上并没有屏幕，所以就出现了一些新的难题。在有关你所说的那种类型的通知上，我们想要做一些正确的工作。但目前我还不能披露我们具体讲采用的方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;B：目前，人们基本上必须为他们的助理选择一个对话式接口。未来我们有望看到 Alexa、Cortana、Google Home 或 Samsung Viv 等等一起协同工作吗？&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;P：&lt;/span&gt;&lt;/strong&gt;对话这个领域目前还处于非常早期的阶段。我已经在这个行业 20 多年了，但我仍然觉得 Alexa 和 Echo（的知识产权）是革命性的材料，尤其是在接口方面。我认为这还有待观察；每一家公司都有一套不同的产品，所以你可以想象会有很多个人工智能。但在互操作方面，现在要说还为时尚早。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;B：Echo 和 Alexa 技术对我们很多人来说都很惊奇，一开始的时候人们还以为这是一款用来在亚马逊上快速购物的工具。而现在，它已经成为了亚马逊最受欢迎的产品和最显著的平台之一。你们的目标发生过变化吗？&lt;/span&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;P：&lt;/span&gt;&lt;/strong&gt;我不会说目标发生过变化。我们现在做的和我们三年说我们应该会做的仍然是基本一致的。只是现在我们工作中的很大一部分是让 Alexa 能够为我们的客户提供更加神奇的服务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;原文链接：https://backchannel.com/alexa-tell-me-where-youre-going-next-739c53ff10b3#.2oy0t675j&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译文章，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;hr style="max-width: 100%; color: rgb(62, 62, 62); font-size: 16px; white-space: normal; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;由中国人工智能学会主办，网易科技和智能君博联合承办、机器之心协办的 2016 中国人工智能产业大会暨第六届吴文俊人工智能科学技术奖颁奖盛典将于 12 月 16 日-17 日在深圳举行。&lt;span&gt;点击「阅读原文」报名参与颁奖典礼。现已开通免费观众票，仅限国内外高校老师和学生报名&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW942YmKCia4laJY4jCLNvlbY0PLAS4uvymZOREU26gPaibrsKUjgcAernPMYlIsjyVFN5nRRWyybKHQ/640?wx_fmt=jpeg"/&gt;&lt;/span&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 01 Dec 2016 13:19:52 +0800</pubDate>
    </item>
    <item>
      <title>福布斯深度特写：英伟达的转型之路——从显卡制造商到人工智能变革者</title>
      <link>http://www.iwgc.cn/link/3735625</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自福布斯&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Aaron Tilley&amp;nbsp;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;参与：朱思颖、蒋思源、李泽南、吴攀、微胖&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;英伟达的联合创始人 Chris Malachowsky 正在加州圣何塞贝律耶沙的一家 Denny 吃他的香肠蛋卷，一边小口地啜吸碳烧咖啡。1993 年的 4 月，也就是在这样的一个昏暗的小餐厅里，三位年轻的工程师——Malachowsky、Curtis Priem 以及现在的英伟达总裁黄仁勋（Jen-Hsun Huang）决定创建一家芯片公司。三个人最原始的想法是生产一种专用芯片，这种芯片可以加快电子游戏中图形图像的渲染速度，同时也能有更逼真的显示效果。当时的圣何塞东区还只是市区后面的荒芜地带，而这家餐厅朝向街道的外墙上密密麻麻地布满子弹孔。没有人能预料到这三个每天狂饮咖啡的年轻人正在悄然改变未来计算机产业的发展。毫无疑问英伟达定义了 21 世纪前几十年计算机技术发展的基础，这和上个世纪 90 年代 Intel 公司一样。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「在 1993 年的时候，英伟达的芯片还没有市场，但是我们预料到这股浪潮即将来到，」Malachowsky 说。「在每年特定的 5 个月内加州会举办冲浪比赛。当远在太平洋另一端的日本有风浪的迹象出现时，加州的冲浪选手就蠢蠢欲动了，因为两天之内风浪就会到达加州海岸。这跟当时我们决定创建芯片公司的情形是一样的，我们是最先下水的冲浪选手。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9NeY8VCvx4aZszGgWsAG4Kf1kfbRn7ayToEnPTkd9eichpzO3kzbH8U5EP2yXLW9ypaOLGH2QADrA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;英伟达的创始人所预料的浪潮就是当时还处于市场萌芽期的图形处理器，也就是大家现在所熟知的 GPU。这些芯片最初是以板卡的形式出售给游戏玩家的，游戏玩家需要自己动手将芯片装到 PC 主板上，从而拥有更快的 3D 图形处理速度。他们的产品命名也很有讲究，用「Titan」"GeForce"这样具有超能力的字眼来开辟市场。他们的芯片单块价格甚至能到 1200 美元，20 年间所创造的收益占据 英伟达 50 亿美元市场收入的大半。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 PC 游戏上的意外收获（英伟达最近一个季度的市场报表显示即使在 PC 市场已经很饱和的情况下，其 PC 部分的营业额相比去年仍有 63% 的增长），并不是华尔街最垂涎这家公司的地方。华尔街最眼红的是&lt;span&gt;英伟达&lt;/span&gt;撞上了人工智能的浪潮。或许是硅谷给予&lt;span&gt;英伟达&lt;/span&gt;的魔力，这家公司在图像处理上的技术（如：游戏中召唤出逼真的巨型外星景观或者如真实图片般十全十美的爆炸场景）居然可以神奇地为当前人工智能领域的研究热点——深度学习——所利用。深度学习可以让计算机具备自己学习的能力，不再需要程序员来敲入所有的代码，其已经在图像识别和语音识别上取得无可匹敌的识别精度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谷歌、微软、Facebook 和亚马逊这几家技术巨头正在大量购买&lt;span&gt;英伟达&lt;/span&gt;的芯片来扩充自己数据中心的处理能力。一些研究机构也在用&lt;span&gt;英伟达&lt;/span&gt;的芯片来处理图像，如 Massachusetts General Hospital 正在用&lt;span&gt;英伟达&lt;/span&gt;的芯片来标记 CT 扫描图片上的病变点。特斯拉也在最近宣布将在所有的汽车上安装&lt;span&gt;英伟达&lt;/span&gt;的图形处理器，进而来实现无人驾驶。NVIDIA 的芯片还能为虚拟现实设备头设提供强大助力，在 Facebook 和 HTC 推向市场的产品中就有。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「在人工智能到来之前，&lt;span&gt;英伟达&lt;/span&gt;从来都没有处于一个如此巨大的市场的中心，」黄仁勋在加州圣塔克拉的&lt;span&gt;英伟达&lt;/span&gt;总部接受采访时说道；他依然是以一身纯黑的标配出现：黑色的皮鞋、黑色的裤子、黑色的 Polo 衫以及黑色的皮夹克。「这充分表明了一个事实，那就是我们在 GPU 的计算处理技术上无人能及。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前在全世界范围内有大约 3000 家人工智能公司，它们大部分都通过&lt;span&gt;英伟达&lt;/span&gt;的平台来开发自己的业务。他们使用&lt;span&gt;英伟达&lt;/span&gt;的 GPU 从而完成他们应用中的人工智能需求，这些应用包括股票交易、在线购物和无人驾驶。甚至有一家家电公司 June 也运用&lt;span&gt;英伟达&lt;/span&gt;的芯片制造了一款人工智能驱动的烤箱。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我们正在投资不同领域里新兴的需要借助深度学习来构建业务的公司，这些公司能够很好地从我们提供的平台上起步，」风险投资公司 Andreessen Horowitz 的 Marc Andreessen 谈到。「这跟以前通过微软 Windows 来构建服务以及最近通过 iPhone 来发布应用一样。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我们公司内部有一个玩笑，如果我们是对冲基金投资人我们将会投哪些大型公司，我们的选择是全部投给 。」Andreessen 补充说。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;英伟达&lt;/span&gt;在 GPU 市场上拥有无可撼动的霸主地位，占据了总个市场份额的 70%，而且还在扩张新市场，这也使其股价飙升。&lt;span&gt;英伟达&lt;/span&gt;的股价在过去的 12 个月内上涨了 200%，在过去的 5 年内上涨了 500%。500 亿美元的市值将会继续给&lt;span&gt;英伟达&lt;/span&gt; 带来 40 倍的市场收入，这在业内是拥有最高收益的公司。这也给黄仁勋本人带来 24 亿美元的收入（最初合伙人 Malachowsky 已处于半退休状态，而另一个创始人 Priem 已不在&lt;span&gt;英伟达&lt;/span&gt;）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;英伟达&lt;/span&gt;飙升的股价也是美国最佳就职企业前 100 位排名将其排在半导体行业公司前列的原因之一。美国最佳就职企业前 100 排名是通过调查在 1000 个美国大型公司就业的 5 万就业人员而得出的，调查主要考虑的因素包括雇员对公司的评价、顾客对公司的评价以及股东的评价。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在报告考察的 10 个领域内，&lt;span&gt;英伟达&lt;/span&gt;在员工薪水支付和员工福利、企业属性和对环境影响上的表现都远超平均水平。友好的员工工作政策，包括富裕的休假时间、弹性的工作时间以及压力缓解项目，这些使&lt;span&gt;英伟达&lt;/span&gt;在 Glassdoor 的排名远远好于行业内的其他公司，Glassdoor 是硅谷技术人员跳槽的判断来源网站。在一个男性为主的行业，&lt;span&gt;英伟达&lt;/span&gt;甚至有专门提高女性和少数族裔工程师在企业核心职位的政策。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我运营公司的方式是把公司当做一个人来管理，公司是一个生命体。」黄仁勋说，「公司的文化是公司的精髓也是公司运作的保障。在怎么创建公司上我所学到的唯一有价值的东西就是：公司的文化是这个公司最宝贵的财富。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9NeY8VCvx4aZszGgWsAG4KxE2LaUYe6HkDcCsZ0XtMibydt3azByDMAuo9jia8eI2NYGaANKFqZpug/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;由 Nvidia’s GTX 1080 显卡驱动的 Titanfall 2 游戏截屏&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;黄仁勋一直知道他们的图形芯片不只是能驱动最新的视频游戏，而且还有很大的潜力，但他并未预见到图形芯片向深度学习的转向。深度学习技术（传统上是指神经网络）可以说是在大脑中的神经元和突触的工作方式上获得了一点点启发。至少自 1960 年代以来，它们就一直存在于学术界了，到了 1980 年代和 1990 年代，学术界也取得了一些重大的进展。但这段时间还有两个因素一直在阻碍着深度学习的腾飞：算法的训练所需要的数据量和廉价纯粹的计算处理能力。互联网解决第一个问题，似乎突然之间，我们就有了带着每个人的标签的无限数据。但算力的问题还有待解决。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从 2006 年开始，&lt;span&gt;英伟达&lt;/span&gt;发布了一个名叫 CUDA 的编程工具包，该工具包让开发者可以轻松编程屏幕上的每一个像素。为了渲染每一个像素，GPU 往往需要同时执行成千上万个微型的计算操作。这些操作执行的是很多更低层面的数学计算，比如渲染阴影、反射、光照和透明度。在 CUDA 发布之前，给 GPU 编程对程序员来说是一件极其痛苦的事，因为这涉及到编写大量低层面的机器码。而 CUDA 经过了 Nvidia 的多年开发之后，成功将 Java 或 C++ 这样的高级语言开放给了 GPU 编程，从而让 GPU 编程变得更加轻松简单。使用 CUDA，研究者可以更快更便宜地开发他们的深度学习模型。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「深度学习几乎就像是大脑一样，」黄仁勋说，「它高效得难以置信。你几乎可以教他做任何事。但它也有一个巨大的短板：它需要大量的计算。而现在我们有了 GPU，这简直就是为深度学习所设计的完美计算模型。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;大规模采用深度学习的关键时刻出现在 2010 年 Palo Alto 一家日式餐厅的晚宴上。斯坦福大学一位语气温和的教授吴恩达当时正在那里面见谷歌（现 Alphabet）CEO Larry Page 和时任 Google X 负责人的天才计算机科学家 Sebastian Thrun。两年之后，吴恩达写出了世界上最早的一篇关于有效应用 GPU 计算深度学习模型的学术论文。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「在 2008 年，深度学习还非常不受欢迎，」吴恩达说，「思考算法技巧可要性感多了。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Thrun，首批实用自动驾驶车辆中的一部分就是由他研发的，在斯坦福时与吴恩达一个办公室，而且这两位科学家向 Page 游说，要在谷歌建造一支深度学习研究团队。这是有意义的：对于建造世界上最大的神经网络来说，谷歌庞大的计算基础结构再合适不过了。佩奇同意了，Google Brain（谷歌大脑）也因此诞生。如今，谷歌大脑的深度学习研究几乎渗透到每个谷歌产品中，特别是搜索、语音和图像识别。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当谷歌开始成立谷歌大脑时，2500 英里之外的另一位研究人员也正在摆弄着深度学习技术。2012 年，Alex Krizhevsky 当时还是多伦多大学的博士生，向 ImageNet 提交了一些令人吃惊的研究。Alex Krizhevsky 将 120 万张图片输入一个深度学习神经网络，这个网络是由英伟达的 GeForce 游戏卡驱动的。他的模型的图像识别准确率是当时最高的，误差率仅为 15%——之前还高达 25%，这是一巨大飞跃。Alex Krizhevsky 不仅轻易赢得了比赛，而且其成绩也在学术界中迅速火起来（目前，Alex Krizhevsky 和他的前多伦多大学教授都在谷歌工作。）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些成果既出，深度学习开始如野火般燎原。除了谷歌，微软、Facebook 和亚马逊也出现了前瞻的深度学习研究项目。英伟达决定重金投资带有 CUDA 的重点软件生态系统，这也是这一转变的关键促成因素。在英伟达领导 CUDA 研发的 Ian Buck 说，「多年来我们进行了大量投资。现在，很清楚，我们正受益于这一长期愿景。Jen-Hsun 投入其中多年。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;英伟达&lt;/span&gt;已经在为深度学习定制最优化硬件，这就体现在最新的服务器芯片 Tesla P100 上，他将八块芯片安装在 3 英尺长 5 英寸厚的矩形容器 DGX-1 上，并且&lt;span&gt;英伟达&lt;/span&gt;将其称之为「世界上第一台人工智能超级计算机」。这个价值 13 万美金的机器性能上能进行每秒 170 万亿次浮点运算，而传统的服务器标准为 250 万亿次浮点运算每秒。八月份时，黄仁勋亲自将其中第一块交付给了 Elon Musk 及其在旧金山非营利性人工智能研究组织 OpenAI。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;iframe class="video_iframe" data-vidtype="1" style="   z-index:1; " height="375" width="500" frameborder="0" data-src="https://v.qq.com/iframe/preview.html?width=500&amp;amp;height=375&amp;amp;auto=0&amp;amp;vid=w0351i6r1oo" allowfullscreen=""&gt;&lt;/iframe&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;黄仁勋 1963 年出生于台湾，早年就显现出竞争的意识，10 岁时就读于肯塔基州东部乡下了一所寄宿制学校，当时他的父母还在办移民手续。这是一所混乱的学校，他的室友已经 17 岁了，比他年长 7 岁；当时他正在从一场最后给他留下了 7 个刺伤的打架中恢复。黄仁勋开始痴迷于乒乓球，这成了他逃避混乱环境的一种方式。1978 年，15 岁的黄仁勋在美国乒乓球公开锦标赛中获得初级双打第三名。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;高中时黄仁勋爱上了计算机，后来去了俄勒冈州立大学学习计算机科学和芯片设计，并在那里遇到了未来的妻子 Lori。毕业后，他们搬到了硅谷，黄仁勋在那里为英特尔竞争对手 AMD 工作，这是他第一份设计处理芯片的工作。他没有放弃学业，并于 1992 年获得斯坦福大学电气工程硕士学位。在芯片制造商 LSI 公司工作时，他遇到了 Malachowsky 和 Priem，他们都在 Sun Microsystems 工作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;那时黄仁勋刚刚 30 岁，三个人开始设想着开创个图形芯片公司。他们看到了提升基本图形处理上的一个巨大机会，当时的基本图形处理还只能在 PC 端使用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;英伟达&lt;/span&gt;的第一个芯片 NV1 发布于 1995 年，花费了 1000 万美元的开发经费，这笔钱是由 Sequoia Capital 和 Sutter Hill Ventures 资助的。不幸的是，这款芯片试图解决太多的问题，并没有赢得多少付费客户。&lt;span&gt;英伟达&lt;/span&gt;当时只有两岁，几乎快破产了且被迫裁员一半，剩下 40 人左右。但其 1997 年发布的第三个芯片 RIVA 128 却是一个突破性的成功。它比任何其他图形处理器都快了 400％，公司的生存也就得到了保证。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;随后跟随他们进入这一领域的其它公司的芯片打破这一性能记录。接下来的十五年中这一行业经历了激烈的竞争。最后在 20 世纪 90 年代末存在的 70 个 GPU 公司中，只有 &lt;span&gt;英伟达&lt;/span&gt;和 AMD 生存下来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在那段时间里，黄仁勋设法创造了一个非常健康快乐的团队，这反映其在Just 100 榜单上的排名。黄仁勋十分关心他的员工，在 2015 年职场多样性会议上发表演讲后，他向&lt;span&gt;英伟达&lt;/span&gt;少量女性员工讲述了他们在向前攀登时所面临的挑战。育儿例假是黄仁勋做出的重大改进。现在新的父母可以得到 22 个星期的带薪休假，然后用另外 8 个星期的灵活时间过渡回来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;黄仁勋把很多员工的幸福归功于&lt;span&gt;英伟达&lt;/span&gt;现在所正在做的努力。并且进入深度学习等领域已经重振了其员工活力。黄仁勋说：「你的工作和社会的利益之间必须有联系，我们为了使社会受益所做的工作在某种程度上几乎就是科学幻想了，我们希望能够进一步探索推进癌症的治疗，这听起来不可思议。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;英伟达&lt;/span&gt;的成功没有被忽视。事实上每个芯片厂商的主要力量都突然投入到实现人工智能梦想上了。许多新兴的创业公司正在设计新类型的深度学习芯片架构，而且芯片玩家也不是唯一兴奋的。深度学习对于未来科技业务至关重要，谷歌以前是&lt;span&gt;英伟达&lt;/span&gt;最重要的客户之一，并从未制造过自己的芯片，然而现在也成为了竞争对手。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 5 月份年度开发者大会上，谷歌宣布已经构建了名为张量处理单元（Tensor Processor Unit）的定制芯片，该芯片是为 TensorFlow 及其深度学习框架量身定制的。谷歌表示，它已经为其数据中心配备了这些芯片来改进匹配和搜索结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;类似地，另一个英伟达客户微软正在为其数据中心制造自己的芯片：称为可编程门阵列（field-programmable gate array 或 FPGA）的定制芯片，其在制造后可以重新编程，并已被证明对人工智能应用十分有用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;半导体行业领军者英特尔似乎特别害怕英伟达正在取得的进步。英特尔 在智能手机市场上失败后之后，它十分渴望不要错过下一个深入学习的潮流。不过它缺乏自己最先进的人工智能研究，所以已经开始狂热地收购了。最近 Intel 兼并了两个人工智能芯片初创公司：Nervana，其在 4 月份报告称用了 4 亿多美元，还有未公开金额的 Movidius。去年，英特尔用 167 亿美元拍下了 FPGA 制造商 Altera。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;英特尔是在保护其最赚钱的摇钱树：数据中心，它几乎完全垄断了 99％的市场份额。英伟达目前的芯片还不能取代那些 Intel 处理器，它们暂时只能加速这些处理器。但英特尔显然更喜欢它的客户完全使用它的硬件。到 2017 年，英特尔计划推出针对深度学习优化的服务器芯片，即新的 Xeon Phi 处理器。有了 Nervana 团队的技术支持，英特尔现在敢于宣称它能在 2020 年之前加速深度学习网络 100 倍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相对于英特尔、AMD 和其他竞争对手，英伟达有很大的占先优势。但它不能放松，多年来在这个领域它一直是垄断的，不过现在这个市场热闹了起来。「我认为英伟达处于一个很好的位置，有很大的胜算，但我现在还不会给他们让步，」资深技术分析师 Jon Peddie 说。「有太多的人盯着这块领域了。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;黄仁勋说：「人工智能计算就是计算的未来，只要继续让我们的平台成为人工智能计算最好的平台，我认为我们就能在许多业务上取得领先地位，GPU 将会是所有公司的必备产品。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而且黄仁勋已经继承了 Intel 老板 Andy Grove 在上个世纪 90 年代发行的畅销书「唯偏执狂才能生存（Only the Paranoid Survive）」中倡导的哲学。他说：「我常常设想想企业会在一个月后倒闭，这一点对我来说永远不会改变，这并不是对失败的恐惧，而是对自满情绪真正的恐惧，我并不想让这种自满发生。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;原文链接：http://www.forbes.com/sites/aarontilley/2016/11/30/nvidia-deep-learning-ai-intel/#7a339e139ccb&lt;/em&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译文章，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 01 Dec 2016 13:19:52 +0800</pubDate>
    </item>
    <item>
      <title>人工智能黎明，美国参议院举行听证会邀请顶级学者探讨未来（附证词）</title>
      <link>http://www.iwgc.cn/link/3735626</link>
      <description>&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自TechRepublic&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;参与：曹瑞、李泽南&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;美国东部时间周三下午 2:30，在罗素参议院办公楼，专家和议员们召开了一场听证会，讨论的主题是当前最重要、最复杂的新技术：人工智能。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这次会议由空间、科学和竞争力听证小组举办，这个小组是参议院商务，科学和交通委员会的一部分。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本次听证会由参议员泰德·科鲁兹主持，主题是探讨人工智能当前的形势，对政策的影响及其对商业形态的改变。卡耐基梅隆大学计算机科学院院长 Andrew Moore 在会上概述了本次会议的三大目标：「首先，厘清何为人工智能；其次，探索未来十年人工智能的发展道路；最后，为美国在人工智能军备竞赛——这一本世纪最重要的技术竞争中摆正位置。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9NeY8VCvx4aZszGgWsAG4KsiarZMcpUH1Uk88Omv4eWK8MQ0x5txOvVjAsHXkMk5aRX6ZKlsnxAEQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Andrew Moore，卡耐基梅隆大学计算机科学院院长，在听证会中&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本次会议是在奥巴马在 10 月份有关人工智能的一系列行动后举行的，其中包括对未来人工智能的报告，&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719745&amp;amp;idx=1&amp;amp;sn=4c8b294e5eb537bcd638612653e5c434&amp;amp;chksm=871b027fb06c8b699ce17d0bd2924eb9f233e6dbe9b582b81bba88ae26ee943ee28d638b1d80&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719745&amp;amp;idx=1&amp;amp;sn=4c8b294e5eb537bcd638612653e5c434&amp;amp;chksm=871b027fb06c8b699ce17d0bd2924eb9f233e6dbe9b582b81bba88ae26ee943ee28d638b1d80&amp;amp;scene=21#wechat_redirect"&gt;《连线》杂志的客座访谈&lt;/a&gt;，以及白宫前沿会议，一个由匹茨堡大学和卡耐基梅隆大学合办的峰会。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;10 月 12 日，白宫科技政策办公室（Office of Science and Technology Policy）曾发布了一份名为「为人工智能的未来做好准备」的报告。该报告概述了人工智能的机遇，包括如何利用人工智能促进社会公益，改进政府运作的建议。在报告中提出了 23 个政策建议和一项战略计划，建议联邦政府资助的研究和发展计划应该把人工智能放在首要位置。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;昨天的参议院听证会中，共有五位专家出席作证：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Eric Horvitz，微软研究实验室总经理，人工智能伙伴关系委员会临时共同主席&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Andrew Moore，卡耐基梅隆大学计算机科学院院长&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Andrew Futreal，德州大学安德森癌症中心基因医学教授&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Greg Brockman，OpenAI CTO，共同创始人&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Steve Chien，资深学者，Autonomous Space System and Technical Group 主管，Artificial Intelligence Group，NASA 喷气推进实验室，加州理工学院特约教授&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然目前还不清楚专家的挑选流程，但是值得注意的一点是专家组中没有女性。卡内基梅隆大学的一位知情人士称，对 Andrew Moore 的邀请是在他参加美国 CBS 金牌栏目「60 分钟」之后做出的决定。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;奥巴马总统对人工智能的关注，以及对发展人工智能意义的认同，受到了人工智能业界的广泛赞许。一些专家也在质疑特朗普总统上台之后人工智能在教育、科研经费和自动化武器安全发展方面存在的风险。南威尔士大学的人工智能教授 Toby Walsh 说，「在过去的一年当中，白宫在人工智能上做出了很大的努力，深入了解并且在发布的报告中提出了很多好的建议。」「如果这一切努力都化为乌有的话就真的是太可惜了。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然而，他也说道，举行听证会也表示「政府已经意识到自动化主导的新经济体会带来的巨大改变，这是一个具有挑战性的时代。毫无疑问，参议院委员会收到一些来自人工智能界最有声望的人物提出的非常冷静的建议。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Vince Conitzer 是杜克大学计算机科学系教授，他也同样认为，「奥巴马总统对待人工智能的态度非常严肃认真，能听听参议员们在这件事情上的看法应该会很有意思，尤其是在参众两院都被共和党控制的情况下。」「考虑到最近在大选中出现的话题，我猜人工智能影响就业的话题应该会尤其突出。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在唐纳德·特朗普当选新一届总统以后，科技发展和就业的关系成为了目前人们关心的重要问题。人工智能对就业的影响确是此次会议引人关注的议题，参议员们围绕工作机会进行了质询，佛罗里达州民主党参议员 Bill Nelson 在听证会上说道：「人工智能的一部分就是替代人类的工作，我们必须为此做好准备。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对此，专家们则有不同的看法。「我认为现在人们都在关注人工智能对就业机会的影响，而忽视了新技术对于劳动力培训的需求。」Andrew Moore 说道。Eric Horvitz 在作证时也表达了类似的看法：「我们迫切需要优先考虑美国劳动力的培训和再培训，以确保他们的技能水平符合未来发展的需求。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「人工智能也有可能为近期和长期的经济增长做出贡献。」小组委员会主席泰德·克鲁兹说道，他援引了 Accenture 报告的数据。这份报告认为，到 2035 年，人工智能将使经济增长速度增加一倍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在听证会中，专家证词的重点有关人工智能发展对隐私安全需求的增加，如何与中国和俄罗斯等国家展开竞争，政府如何与研究部门和私营公司展开合作。专家同时回答了议员们有关如何处理新技术与伦理和法规的关系等问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译文章，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 01 Dec 2016 13:19:52 +0800</pubDate>
    </item>
    <item>
      <title>专栏 | 中文分词工具测评</title>
      <link>http://www.iwgc.cn/link/3735627</link>
      <description>&lt;header&gt;&lt;h1 style="text-align: justify; line-height: 1.75em; margin-bottom: 5px;"&gt;&lt;/h1&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;转自PaperWeekly&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;作者：张俊&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;h1 style="text-align: justify; line-height: 1.75em; margin-bottom: 5px;"&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/h1&gt;&lt;h1 style="text-align: justify; line-height: 1.75em; margin-bottom: 5px;"&gt;&lt;strong&gt;引言&lt;/strong&gt;&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/header&gt;&lt;p&gt;&lt;span&gt;分词对于研究和应用中文自然语言处理的童鞋来说，都是一个非常非常基础的部件，分词的质量直接影响到后续词性标注、命名实体识别、句法分析等部件的准确性。作为一个基础部件，学术界对分词的研究已经非常久了，市面上流行的几大开源分词工具也被工业界的各大公司应用很多年了。最近，中文分词随着一篇博文的发表被推到了风口浪尖，引发众多大牛在微博、微信群里的激烈讨论。本文并不想对这篇博文进行过多评论，只是想用公开的数据集对各大分词工具进行一个客观地测评，以供大家在选择工具时有所依据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;h1 style="text-align: justify; line-height: 1.75em; margin-bottom: 5px;"&gt;&lt;strong&gt;&lt;span&gt;中文分词工具&lt;/span&gt;&lt;/strong&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;本文选择了4个常见的分词工具，分别是：哈工大LTP、中科院计算所NLPIR、清华大学THULAC和jieba，为了对比分词速度，选择了这四个工具的c++版本进行评测。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1、LTP &lt;/span&gt;&lt;a target="_blank" rel="external" style="font-size: 14px; text-decoration: underline;"&gt;&lt;span&gt;https://github.com/HIT-SCIR/ltp&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;span&gt;2、NLPIR &lt;/span&gt;&lt;a target="_blank" rel="external" style="font-size: 14px; text-decoration: underline;"&gt;&lt;span&gt;https://github.com/NLPIR-team/NLPIR&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;span&gt;3、THULAC &lt;/span&gt;&lt;a target="_blank" rel="external" style="font-size: 14px; text-decoration: underline;"&gt;&lt;span&gt;https://github.com/thunlp/THULAC&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;span&gt;4、jieba &lt;/span&gt;&lt;span&gt;&lt;a target="_blank" rel="external" style="font-size: 14px; text-decoration: underline;"&gt;https://github.com/yanyiwu/cppjieba&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h1 style="text-align: justify; line-height: 1.75em; margin-bottom: 10px;"&gt;&lt;strong&gt;&lt;span&gt;测试数据集&lt;/span&gt;&lt;/strong&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;1、SIGHAN Bakeoff 2005 MSR, 560KB &amp;nbsp;&lt;/span&gt;&lt;a target="_blank" rel="external" style="font-size: 14px; text-decoration: underline;"&gt;&lt;span&gt;http://sighan.cs.uchicago.edu/bakeoff2005/&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;span&gt;2、SIGHAN Bakeoff 2005 PKU, 510KB &amp;nbsp;&lt;/span&gt;&lt;a target="_blank" rel="external" style="font-size: 14px; text-decoration: underline;"&gt;&lt;span&gt;http://sighan.cs.uchicago.edu/bakeoff2005/&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;span&gt;3、人民日报 2014, 65MB &amp;nbsp;&lt;/span&gt;&lt;span&gt;&lt;a target="_blank" rel="external" style="font-size: 14px; text-decoration: underline;"&gt;https://pan.baidu.com/s/1hq3KKXe&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;前两个数据集是SIGHAN于2005年组织的中文分词比赛所用的数据集，也是学术界测试分词工具的标准数据集，本文用于测试各大分词工具的准确性，而最后一个数据集规模较大，用于测试分词速度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;h1 style="text-align: justify; line-height: 1.75em; margin-bottom: 10px;"&gt;&lt;strong&gt;&lt;span&gt;测试方法&lt;/span&gt;&lt;/strong&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;用SIGHAN Bakeoff 2005比赛中所自带的score脚本、test gold数据和training words数据对4个工具进行准确性测试，具体使用方法可参考：&lt;/span&gt;&lt;a target="_blank" rel="external" style="font-size: 14px; text-decoration: underline;"&gt;&lt;span&gt;http://sighan.cs.uchicago.edu/bakeoff2005/data/icwb2-data.zip&lt;/span&gt;&lt;/a&gt;&lt;span&gt; 中的readme文件。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;h1 style="text-align: justify; line-height: 1.75em; margin-bottom: 10px;"&gt;&lt;strong&gt;&lt;span&gt;测试硬件&lt;/span&gt;&lt;/strong&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;Intel Core i7-6700 CPU@3.40GHz*8&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;h1 style="text-align: justify; line-height: 1.75em; margin-bottom: 10px;"&gt;&lt;strong&gt;&lt;span&gt;测试结果&lt;/span&gt;&lt;/strong&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;1、MSR测试结果&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9cClXW96bXrFpguJSTML8icOmur6vstxjsXrWyGwstqxiaX1Rge1zAYXSjuiadr1eGeYBlgF93Ce81Q/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2、PKU测试结果&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9cClXW96bXrFpguJSTML8iclh5E37TrLKIdOqoy9MIqpEwzEG7PoIXKnOIhQib639vyhGbVQTeNtlw/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3、人民日报测试结果&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9cClXW96bXrFpguJSTML8ic8gOHr1icw3F0DhlpicjAcwqpda15xOUnxcpXSJ6yegbhQoKPG5we96vQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;h1 style="text-align: justify; line-height: 1.75em; margin-bottom: 10px;"&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/h1&gt;&lt;h1 style="text-align: justify; line-height: 1.75em; margin-bottom: 10px;"&gt;&lt;strong&gt;&lt;span&gt;测试结论&lt;/span&gt;&lt;/strong&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;1、一个好的分词工具不应该只能在一个数据集上得到不错的指标，而应该在各个数据集都有很不错的表现。从这一点来看，thulac和ltp都表现非常不错。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2、因为分词是个基础部件，分词速度对于一个分词工具来说也至关重要。从这一点来看，thulac和jieba表现的不错。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3、大家都知道，基本的分词依赖模型，但真正想用分词工具来解决应用层面上的问题，都需要借助于词库，本文测试的4个工具均支持用户自定义词库。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4、特别需要强调的一点是，哈工大的ltp支持分词模型的在线训练，即在系统自带模型的基础上可以不断地增加训练数据，来得到更加丰富、更加个性化的分词模型。&lt;/span&gt;&lt;/p&gt;&lt;h1 style="text-align: justify; line-height: 1.75em; margin-bottom: 10px;"&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/h1&gt;&lt;h1 style="text-align: justify; line-height: 1.75em; margin-bottom: 10px;"&gt;&lt;strong&gt;&lt;span&gt;总结&lt;/span&gt;&lt;/strong&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;争论是一个好的事情，尤其是不同背景的人站在不同的角度对同一个事情进行争论，常常会碰撞出知识的火花，对于这个领域的发展有更好地推动作用。希望类似的争论可以多一些，让刚刚入门的或者准备入门的童鞋可以更加客观地看到一个领域的发展现状，而不是盲目地被一些热门的词蒙蔽双眼，失去判断。对于分词来说，最近几年大热的深度学习模型，并不会比之前传统的crf模型有多大性能上的突破，所以大家应该理性地看待深度学习以及人工智能，捧得越高可能摔得越惨。&lt;/span&gt;&lt;/p&gt;&lt;h1 style="text-align: justify; line-height: 1.75em; margin-bottom: 15px;"&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/h1&gt;&lt;h1 style="text-align: justify; line-height: 1.75em; margin-bottom: 15px;"&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;参考文献&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;1、Zhongguo Li, Maosong Sun. Punctuation as Implicit Annotations for Chinese Word Segmentation. Computational Linguistics, vol. 35, no. 4, pp. 505-512, 2009.&lt;br/&gt;2、Meishan Zhang, Yue Zhang, Guohong Fu. Transition-Based Neural Word Segmentation&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;a target="_blank" rel="external" style="font-size: 14px; text-decoration: underline; color: rgb(136, 136, 136);"&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;http://www.aclweb.org/anthology/P/P16/P16-1040.pdf&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;3、Meishan Zhang, Zhilong Deng，Wanxiang Che, and Ting Liu. Combining Statistical Model and Dictionary for Domain Adaption of Chinese Word Segmentation. Journal of Chinese Information Processing. 2012, 26 (2) : 8-12 (in Chinese)&lt;br/&gt;4、Wanxiang Che, Zhenghua Li, and Ting Liu. LTP: A Chinese Language Technology Platform. In Proceedings of the Coling 2010:Demonstrations. 2010.08, pp13-16, Beijing, China.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 01 Dec 2016 13:19:52 +0800</pubDate>
    </item>
    <item>
      <title>重磅 | 谷歌研发人工智能眼科医生：用深度学习诊断预防失明</title>
      <link>http://www.iwgc.cn/link/3725485</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自ICLR、VentureBeat&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：蒋思源、吴攀、朱思颖&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;谷歌的人工智能已经比人类更好地掌握了古老的围棋、学会了识别人脸和口语、能帮你在网络中智能地筛选答案、甚至还能将你说的话翻译成上百种语言。而除了玩游戏和提供更便捷的智能手机应用之外，谷歌的人工智能还能做一些更为严肃的事，比如疾病诊断。实际上，谷歌已经严肃起来了。昨天，谷歌研究者在其 Research 博客上更新了一篇文章，介绍了他们在研究自动识别糖尿病性视网膜病变（diabetic retinopathy）上的最新进展，相关论文已经发表在美国医学协会杂志（Journal of the American Medical Association）上。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;糖尿病性视网膜病变（diabetic retinopathy，以下简称 DR）是现在增长最快的致盲病因，全世界大概有 4.15 亿糖尿病患者存在失明风险。如果发现得早，这个疾病是可被治愈的；如果发现得晚，它就可能会导致不可逆转的失明。不幸的是，世界上很多糖尿病高发地区还缺乏有能力检测这种疾病的医学专家。我们相信机器学习能够帮助医生检查有需要的病人，尤其是那些尚未得到足够医疗服务的人群。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;几年前，我们中一些人开始思考能不能使用谷歌的技术来改进 DR 的筛选过程，特别是能否借助机器学习和计算机视觉领域的最新进展来做到这一点。在今天发表于 JAMA 的论文《用于检测视网膜眼底照片中糖尿病性视网膜病变的深度学习算法的开发和验证（Development and Validation of a Deep Learning Algorithm for Detection of Diabetic Retinopathy in Retinal Fundus Photographs）》中，我们提出了一种可以解读视网膜照片中 DR 发病迹象的深度学习算法，这有望能帮助资源有限地区的医生正确地筛选出更多的病人。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;检测糖尿病性眼病的一种最常见的方法是让专科医生来检查眼后部的图像（图 1），然后再评估疾病是否存在及其严重程度。其中疾病的严重程度是由病变（如微动脉瘤、出血、硬渗出物等）的类型所确定的，这些症状表明了眼部之中的出血和液体渗出情况。然而解读这些照片需要经过专门的训练，而在世界上许多地区，还没有足够多合格的评估者能够筛选出存在发病风险的每个人。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9cClXW96bXrFpguJSTML8icOmhLzVRtJ6g2KT71GFAPWnWPJKV0kCWI7EdVozs9qQOOBGB1Xdicmjw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;em&gt;&lt;span&gt;图 1：为了筛选 DR 而拍摄的视网膜眼底照片样本。左侧的图像是健康的视网膜（A），而右边的图像则是可引起糖尿病性视网膜病变的视网膜（B），可以看到存在出血状况（红点）。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过与印度和美国的医生紧密地合作，我们创建了一个包含 128,000 张图像的开发数据集，其中每一张图像都得到了 54 位眼科医生中 3 到 7 位医生的评估。这个数据集被用来训练了一个可以检测可诱发糖尿病性视网膜病变的病症的深度神经网络。然后我们在两个互相独立的包含大约 12,000 张图像的临床验证集上测试了该算法的表现，该测试所参考的标准是一个 7 或 8 人的美国认证眼科医生中大多数人的意见。为验证集所选择的眼科医生的意见与训练集原来的 54 位医生的意见表现出了高度的一致性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9cClXW96bXrFpguJSTML8icquUY4ia0zzS3MZwxqnzJoMfMcC6Kr7VYia0DPbaW8BPwsGr6v5Gibm2Eg/0?wx_fmt=png"/&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 2显示了算法和眼科医生在包含9,963张图像的验证集上的判断表现。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图 2. 算法性能（黑色曲线）和八位眼科医生（彩色圆点）在由9963个图像组成的验证集上判断病变，即判断是否存在可引起的糖尿病性视网膜病变（中度或更严重的糖尿病性视网膜病变或可疑的糖尿病性黄斑水肿）。图上的黑色方块对应在高灵敏度和高特异性操作点中，算法的灵敏度和特异性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;结果显示我们算法的表现和眼科医师的诊断是处于同等水平的，例如，在图2中描述的验证集上，算法具有0.95的F-Score值（结合灵敏度和特异性的度量，最大值为1），算法的表现稍微高于我们所咨询的8个眼科医生F-Score中位数值（0.91）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些是十分令人振奋的结果，但仍然我们还有很多要做。首先，虽然使用常规质量度量评价我们的算法结果是鼓舞人心的，但我们正在与视网膜专家合作去定义更强健能量化临床表现的参考标准。此外，我们在论文中证明解释2D眼底照片只是诊断糖尿病性视网膜病变多步骤过程的一部分。在某些情况下，医生需要使用3D成像技术，光学相干断层扫描（OCT），详细检查视网膜的各个层。将机器学习应用于这种3D成像模式已经在DeepMind的带领下进行了。在将来，这两种互补方法可以一起使用，以帮助医生诊断更多的眼科疾病。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;高精度自动糖尿病性视网膜病变（DR）扫描方法有很大的潜力，因为它能帮助医生评估更多的患者，并且迅速地将需要帮助的人匹配给专科医生。我们正在与医生、研究员一起研究世界各地的扫描全过程，并希望我们可以用最有利的方式将我们的方法整合到临床工作流程中。最后，我们正与美国食品药品监督管理局（FDA）还有其他监管机构合作，以进一步评估这些技术在临床中的表现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;考虑到最近深度学习有许多进展，我们希望我们的研究只是众多激发兴趣的例子之一，希望它证明机器学习能够更广泛地帮助解决医疗成像，甚至是更广泛的医疗保健问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;论文：用于检测视网膜眼底照片中糖尿病性视网膜病变的深度学习算法的开发和验证（Development and Validation of a Deep Learning Algorithm for Detection of Diabetic Retinopathy in Retinal Fundus Photographs）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;重要性：深度学习是指能让算法通过学习能展现出预期行为的大量样本以进行自我编程的一系列方法，这让我们可以不再需要特定一些明确的规则。这些方法在医学成像上的应用还需要进一步的评估和验证。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目标：为了应用深度学习来创建一种能通过视网膜眼底照片自动检测糖尿病性视网膜病和糖尿病性黄斑水肿的算法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;设计和配置：我们使用了一种被称为深度卷积神经网络的专为图像分类而优化过的神经网络类型，该网络使用 128175 张视网膜图像的可追溯的开发数据集进行了训练，其中的每一张图像都针对糖尿病性视网膜病变、糖尿病性黄斑水肿和图像等级进行了 3 到 7 次评估，评估者来自 54 个美国有执照的眼科医生和眼科学资深专家在 2015 年 5 月到 12 月之间所作出的评估。所得到的算法使用 2016 年 1 月和 2 月的两个互相独立的数据集进行了验证，其中的每张图像都至少经过了 7 位美国认证的眼科医生的高 intragrader 一致性的评估。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;揭示深度学习训练的算法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;主要结果和措施：这种用于检测可发病的糖尿病性视网膜病（RDR/referable diabetic retinopathy，即中度和更糟糕的糖尿病性视网膜病）、可发病的糖尿病性黄斑水肿或同时两者的算法的灵敏度（sensitivity）和特异性（specificity）是基于眼科专家小组中大多数决策的参考标准。该算法在为两个开发集所选择的 2 个操作点上进行了评估，其中一个是为高特异性选择的，另一个则是为高灵敏度选择的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;结果：EyePACS-1 数据集包含了来自 4997 位病人（平均年龄 54.4 岁）的 9963 张图像；其中 62.2% 的女性；普遍是 RDR，683/8878 完全可分级的图像（占 7.8%）。Messidor-2 数据集有来自 874 位病人（平均年龄 57.6 岁）的 1748 ；42.6% 女性；普遍是 RDR，254/1745完全可分级的图像（占 14.6%）。为了检测 RDR，该算法在 EyePACS-1 上的受试者操作曲线（ ROC 曲线）下的面积为 0.991(95% CI, 0.988-0.993)，在 Messidor-2 上的 ROC 曲线下的面积为 0.990 (95% CI, 0.986-0.995)。使用第一个高特异性的操作切入点（operating cut point），对于 EyePACS-1 ，灵敏度为 90.3% (95% CI, 87.5%-92.7%)、特异性为 98.1% (95% CI, 97.8%-98.5%)。对于 Messidor-2，灵敏度为 87.0% (95% CI, 81.1%-91.0%)、特异性为 98.5% (95% CI, 97.7%-99.1%)。使用开发集第二个高灵敏度的操作点，对于 EyePACS-1，灵敏度为 97.5% 而特异性为 93.4%；对于 Messidor-2，灵敏度为 96.1% 而特异性为 93.9%。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;结论与相关：在这项成人的糖尿病性视网膜眼底照片的评估中，基于深机器学习的算法对可疑糖尿病性视网膜病变检测时具有高灵敏度和特异性。 进一步的研究是必要的，这将确认此算法应用在临床中的可行性，并确定与目前的眼科评估相比是否使用该算法可以改善治疗和诊断结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;点击二维码阅读论文原文：&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9cClXW96bXrFpguJSTML8icJ8uYRHbgAPib3OpqkCrq7GVhLoguseKiabFQWjIXJPc0d86pbhqcbhQw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;本文选自 Google Research Blog：&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;https://research.googleblog.com/2016/11/deep-learning-for-detection-of-diabetic.html&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译文章，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 30 Nov 2016 11:48:03 +0800</pubDate>
    </item>
    <item>
      <title>深度 | 颠覆乔姆斯基的语言学习理论?没那么容易</title>
      <link>http://www.iwgc.cn/link/3690817</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Scientific American&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Jeffrey Lidz&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;9 月初，Yann LeCun 转发了一条推特，推荐 Scientific American 上 的&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719036&amp;amp;idx=1&amp;amp;sn=b1e4cd924024ac7b7cd2f1659500da08&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719036&amp;amp;idx=1&amp;amp;sn=b1e4cd924024ac7b7cd2f1659500da08&amp;amp;scene=21#wechat_redirect"&gt;一篇颠覆乔姆斯基语言学理论的文章&lt;/a&gt;，并认为此文在乔姆斯基的普遍语法理论的棺木上又多钉了几枚钉子。然而，Scientific American 近日又发了一篇文章推翻了之前的那篇文章，认为其对乔姆斯基的理论存在根本性误解。看来围绕乔姆斯基的争论远未止息...... &lt;span&gt;你支持乔姆斯基的语言学理论吗？请在文章结尾投上你的一票&lt;/span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;没读过 Ibbotson 和 Tomasello（以下 I&amp;amp;T）最近在科学美国人（Scientific American）上发表的文章「Evidence Rebuts Chomosky's Theory of Language Learning」的朋友，或许会对文章的标题不明所以。同时你也可能在猜测，这篇文章中或许会列举很多具体的实证来驳斥诺姆乔姆斯基的语言学习理论。但是，文章中并没有这样的实证论述。回顾乔姆斯基的语言学思想，这位语言学生成学派泰斗并没提出任何关于语言习得的具体理论。他的思想是通过对人类可能的语言空间的初始条件定义来论述语言习得在理论上的可能。这也是 I&amp;amp;T 无法在其文中列举具体实证来反驳乔姆斯基的原因之一。另外，I&amp;amp;T 也几乎没有找到任何与生成学派的语言习得理论完全相左的强有力证据。I&amp;amp;T 对乔姆斯基语言学思想的根本性误解是其文章中没有相关论述的原因所在。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibJ8ujNQ9xK748XAMhia4Om5GrEeCxSBVqCfyqdbA8lhFky9SM23icq8p1acZXk48gsVzGBXBq0mib9A/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em style="text-align: justify; white-space: pre-wrap;"&gt;&lt;span&gt;诺姆乔姆斯基（Noam Chomsky），麻省理工学院荣誉退休教授，有史以来论文被引用数量第 8 的学者。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em style="text-align: justify; white-space: pre-wrap;"&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;20 世纪 50 年代到 60 年代，乔姆斯基提出了一个研究人类语言机能的范式。这个范式包含三部分：（1）语言学知识的正式明确性模型的构建，（2）普遍语法规则的检索对可能语法空间的精准勾勒，（3）语法知识和语法使用可以被视为不同的方法性假说。这项研究曾经宣称其最终的理论是为了解释普遍语法规则的运用是语言习得理论的一个重要组成部分。语法规则将和语言学习者的经验及其他能力共同推进语言学习者语法知识的增长。在乔姆斯基的研究中，对语言学习者的语言习得作用因素进行了明确的区分，这种区分与生物体的生长是由其基因结构、外部环境以及其他内部因素三部分互相作用的区分类似。就如没有生物学家会认可基因结构理论和生物进化理论等价一样，任何语言学家（当然乔姆斯基本人除外）都不会认可语法结构和语言习得理论是等价的。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人类可能习得的语言理论能够为语言习得提供理论支撑的论断部分来源于刺激贫乏论，刺激贫乏论认为相比于普通孩子所在的语句环境，我们在以后的成长过程中可以逐渐学到更加复杂的语言知识。这个学说的论证可以遵从以下例子的步骤进行：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;基本语料：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;（1）a.Val is a good volleyball player and Al is too &lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;b.Val is a better volleyball player than Al is&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这两句话中，第二个从句中有一个未明确指出的谓语，这个谓语来源于第一个从句（即：a good volleyball player）。为了简化，我们把（1a）称为并列省略（coordinate ellipsis），（1b）称为比较省略（comparative ellipsis）。我们还进行进一步区分，在省略谓语的句子里，中括号中的补充文字即为所省略的谓语内容。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;(2) a. Val is a good volleyball player and Al is [a good volleyball player] too&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;b. Val is a better volleyball player than Al is [a good volleyball player]&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些省略的结构对孩子们的口语来说是很普遍的。我们同样能观察到这些未说出口的谓语动词和他前期能理解多从句（multi-clause）之间的关系，即使是在孩子们没有听到许多这种多从句（multi-clause）类型的句子时候。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;(3) a. Val is a good volleyball player and I think that Al is [a good volleyball player] too&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;b. Val is a better volleyball player than I think that Al is [a good volleyball player]&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;c. Val is a good volleyball player and I heard you say that Al is [a good volleyball player] too&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;d. Val is a better volleyball player than I heard you say that Al is [a good volleyball player]&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然而，当嵌入从句是关系从句的时候，这两种省略句将会区分开来。并列省略（coordinate ellipsis）仍然能组成一些英语的句子，但是比较省略（comparative ellipsis）就不能这样（意味着不能组成英语句子）。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;(4) a. Valentine is a good value-ball player and I heard a rumor that Alexander is [a good volleyball player] too&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;b. * Valentine is a better value-ball player than I heard a rumor that Alexander is [a good volleyball player]&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这里要解释的是，为什么这个儿童学习者在为并列和比较省略组织表达时，不会将沉默的谓词以同样的方式用在两个例子中。这个两个例子都可以被解释为等同于在（1）和（3）的所有句子中的主句谓语。然而，如果省略的谓词是在一个关系从句里面，它就可以被解释为等同于并列省略而不是比较省略中的主句谓语。这可能会得出一个类比，但是事实上不可以。英语学习者不会遇上像（4a）或（4b）那样的句子，但是有时我们都会意识到英语中可能会有像（4a）那样的句子吗，它会是什么样子的？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这种乔姆斯基式的答案只能提供部分解答。它表示像 (1b) 中那样的比较结构（comparative constructions）有一个与问题共同的结构特征。要了解这能够使 (4b) 不可能的原因，让我们先考虑一下被构建出来的问题。类似 (5) 这样的成分问题（constituent questions）可以将句子起始处的一个短语和该句子中后面的一个动词联系起来：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;(5) What did Ellen take?&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这里的动词 take 是及物动词，它需要一个直接宾语，这使得 (6a) 是一个可能的句子而 (6b) 并不是：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;(6) a. Ellen took a picture&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;b. * Ellen took&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 (5) 中，直接宾语是 what，其出现在句子开头，但其作用和 (6a) 中的 a picture 这个短语是一样的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这种依赖（dependency）也可以跨多个从句进行延伸：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;(7) a. What do you think that Ellen took?&amp;nbsp;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;b. What did you hear Tonia say that Ellen took?&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但如果这个动词本身就在一个关系从句（relative clause）中，那么这种依赖就不能形成：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;(8) * What did you hear a rumor that Ellen took?&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;像 (7b) 和 (8) 这样的句子都不在典型的儿童语言学习者的经验范围内，但我们都能认识到 (7 a/b) 是可能的句子而 (8) 并不是。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果我们通过检查许多依赖和许多语言来在英语中的这些观察上进行构建，那么我们会发现人类语言中（至少）存在两种依赖（dependency）。一类可被构建成关系从句，另一类则不能。给定这两种分类，我们可能会提出这些依赖的类别内建于学习者的语言机能中。这个观点会改变语言学习问题的本质。学习者的工作并不是去发现被学习的语言的每一种属性，而是（在这个领域内）去发现该语言中的依赖是属于哪种类别。对其中依赖进行了分类之后，学习者就会知道它们之中哪些特定的元素可以被用在关系从句中（如：并列省略（coordinate ellipsis）），或不能这么用（如：比较省略（comparative ellipsis）和成分问题）。该学习者并不需要搞清楚每一种依赖能否出现在关系从句中，他只需要明白一种依赖属于哪一类。根据这个类别，与相关性（relativization）的交互作用便遵循一开始定义这些类别的普遍语法（Universal Grammar）原则。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;I&amp;amp;T 宣称：这都是错的，而且事实已经证明了这一点。但他们给出的证据只牵扯到语言特征中最简单最容易观察的部分，比如一个动词是否需要一个直接宾语，这些对于构建一种学习理论来说太过简单了，因为它们在学习者的经验中是非常丰富的。乔姆斯基的观点允许观察（observation）、进行类比（analogy making）和分布式分析（distributional analysis）的概念，以解释它们被学习到的方式，就像 I&amp;amp;T 所支持的基于使用的理论（usage-based theory）一样。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但当其涉及到高度抽象的和跨语言稳定的性质（如：依赖的分类）时，基于使用的理论就沉默得可疑。这种沉默是可以从这种理论的形状（shape of the theory）上预见到的。任何曾经精确和正式地学习过学习和归纳（learning and generalization）的人都知道，分布式分析、类比进行和归纳的理论开始于可观察特征的类别的陈述（statement）和可投射谓词（projectible predicates）的类别的陈述——这些谓词定义了归纳时所遵循的维度（dimensions）。因为基于使用的理论没有提供归纳的可能维度的规范，那么它就在设计上没有给学习者归纳的方式提供解释；而更重要的是，除了学习者无法使用的数据，其也没有给与数据一致的归纳提供解释。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，基于使用的理论学家告诉我们：语言知识和语言使用部分独立的方法原理是一个不连贯的（incoherent）思想，几乎不能解释语言的习得。因此，他们认为这种方法原理应当被拒绝。但是，他们既没有解释这种不连贯是如何产生的，也没有解释语言行为（linguistic behavior）是如何在没有这种区分的情况下取得成功的。举一个简单的例子，我知道如何拼写 language，但是有时候我打字太快时我会把它写成 langauge——其中 a 和 u 的位置被写反了。关于我打字这种情况可以通过两个因素进行解释：（1）我对于这个词的拼写的正确表示、（2）我的运动规划和行动系统导致了这一情况，使得序列 g-u-a 的输入需要交替使用我的左右手，而尽可能快速打字的压力使得正确交替的模式变得更加困难，从而导致有时候我用左手打出 g-a 序列时，我的右手还没有来得及按下 u。这是否意味着我并不知道正确的拼写，还是说我在表示这个语言的拼写时，80% 是这个方式，20% 是另一种方式？甚至 I&amp;amp;T 也不会这么想。那么为什么我的语言能力会有所不同呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为什么我们说话的过程不能通过类似的方式进行解释呢？这个过程涉及到我们对知识的整合，其中包括：句子的构建方式、词的发音方式、概念上的知识、记忆系统、预测过程等等。实际上，识别这种区别能让我们可以将特定的事实归属于我的语法知识或使用这些知识的处理系统。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;稍微举个例子说明一下，考虑一下一致性吸引现象（phenomenon of agreement attraction）：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;(9) The key to the cabinets is/#are on the table&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个现象是指人们偶尔会在上面这样的句子中使用 are 而非 is（据 Kay Bock 的研究，在实验生产的任务中有大约 8% 的可能性），而且在加速的可接受性判断任务（speeded acceptability judgment task）中，他们甚至无法注意到 are 的怪异。为什么会发生这种事？一些心理学家认为这和在句子理解的过程中句子的部件在工作记忆（working memory）中的存储和重新获取有关。也就是说，使用独立理解的工作记忆模型并将其应用到句子理解上，这些作者解释了英语说话者注意或没有注意到的这种类型的一致性错误（agreement errors）。所以，在一些情况中，表现（performance）掩蔽了能力（competence）。这种情况允许我们将解释分配到语法理论和处理理论上，这使得我们不需要去复杂化我们的主语-动词一致性的语法理论。这样的解释难道没有那些不能将解释跨领域分配的解释科学吗？明显不是。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;I&amp;amp;T 还宣称这种知识和使用（用乔姆斯基的术语来说是能力（competence）和表现（performance））之间的区别是有害的，并且削弱了关于语言习得的观点的可证伪性。但是原因为何？考虑以下情况。所有的语言使用者都是逐渐理解句子的——他们一边听句子一边构建自己的理解，而不是等待句子结束才开始理解。这有时候会带来问题。比如这个例子：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;（10）Put the frog on the napkin in the box.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当听到这种语句时，我们最初的理解是词组「on the napkin」是说话者希望把青蛙摆放的位置。随着对话继续，我们修改了之前的理解，「on the napkin」是对于「the frog」目前状态的解释，相当于「the frog that is on the napkin.」这一修正过程可在被实验者的视觉轨迹中观察到。孩子们会难以理解这句话，这从他们的视觉轨迹和行动中都可以看出来，有时他们会把青蛙放在餐巾上。有可能这表示人类在年幼时期这些机制仍未发展完全，这些机制抑制快速理解或反应。实际上，大脑受损的患者和做出错误反应的人显示出了类似的行为。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这种理解困难可以解释为什么儿童有时在学习语言上遇到了障碍。例如，Akira Omaki 测试了英语和日语母语的 4 岁儿童对下面一句话的解释：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Where did Lizzie tell someone that she was going to catch butterflies？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这句话难以理解之处在于「where」和主动词到底是「tell」还是「catch」。现在，如果把孩子比作增量分析程序，他们可能会难以修改第一印象形成的判断，我们假定英语儿童会难以分析动词，他们强烈地倾向于第一个动词为主动词。而日语儿童却存在相反的强烈偏见，因为在日语中这句话的语序会出现颠倒。事实上，这正是 Omaki 的发现，分析系统的性能和可以独立理解的短语可以解释孩子的行为。因此，理解系统的机制可以让我们解释为什么同样的意思不同语言里会出现不同的表达。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;综上所述，Paul Ibbotson 和 Michael Tomasello 宣称乔姆斯基语言学已经灭亡，但它仍未引起这一领域的注意。I&amp;amp;T 和它引用的研究一起，没有证明任何乔姆斯基语言学的核心观点。它们没有验证乔姆斯基在 20 世纪 60 年代理论框架中的逻辑；也没有验证这一框架存在的基础。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;iframe scrolling="no" frameborder="0" class="vote_iframe js_editor_vote_card" data-display-style="height: 173px;" data-display-src="/cgi-bin/readtemplate?t=vote/vote-new_tmpl&amp;amp;__biz=MzA3MzI4MjgzMw==&amp;amp;supervoteid=440868380&amp;amp;token=459015809&amp;amp;lang=zh_CN" data-supervoteid="440868380" allowfullscreen=""&gt;&lt;/iframe&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;乔姆斯基开创性地提出了生成语法理论，这个理论将语言学研究的重点从语言行为转移到人语言行为的大脑产生机制上来。其理论的切入点来源于在语料环境有限的情况下，儿童在短期内仍然可以快速习得母语的观察，通过对儿童的观察认为在进化过程中人类的认知体系中有独立掌管语言的机制 [1]。这一机制是人类的先天语言能力的反映，并在后天的成长中逐步发展成熟。而语言机能的独特运作模式，就是乔姆斯基所谓的语法。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;[1] 乔姆斯基将其称作语言机能（faculté de language），此概念始见于他 1965 年的著作《句法理论的若干问题》(Aspects of the Theory of Syntax. Cambridge, MA: MIT Press.)，在其后的英文著作中乔姆斯基均用 faculty of language。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译文章，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;hr style="white-space: normal;"&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720758&amp;amp;idx=5&amp;amp;sn=3393e25835c0f96ee82396992a8ff27b&amp;amp;chksm=871b0d88b06c849e711c1c42750b1518b42cbb098526f1095ac2a39c9b21b7d2aaf7388fb764&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720758&amp;amp;idx=5&amp;amp;sn=3393e25835c0f96ee82396992a8ff27b&amp;amp;chksm=871b0d88b06c849e711c1c42750b1518b42cbb098526f1095ac2a39c9b21b7d2aaf7388fb764&amp;amp;scene=21#wechat_redirect" style="max-width: 100%; font-size: 14px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;查看interface第二期活动详情&lt;/span&gt;&lt;/a&gt;&lt;span&gt;，或者点击阅读原文直接报名。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9pZ66E9ez8iaqUibbbBGWL6lxkDsobpZnV3eKibsshEKGeQLUoJDTib7Y0qodwrzzFMsj2FYNdQLp2kw/640?wx_fmt=jpeg"/&gt;&lt;/p&gt;</description>
      <pubDate>Mon, 28 Nov 2016 12:37:29 +0800</pubDate>
    </item>
    <item>
      <title>深度 | LSTM之父Jürgen Schmidhuber为何名声不显？</title>
      <link>http://www.iwgc.cn/link/3690819</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自NYT&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：John Markoff&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李泽南、李亚洲、杜夏德&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;作为 LSTM 发明人、深度学习元老，Jürgen Schmidhuber 的识别度一直没有 Yann LeCun、Yoshua Bengio 等人那么高。近日，纽约时报约翰·马尔科夫 的一篇文章向我们揭示了这位人工智能领域的大牛为何名声不显。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Jürgen Schmidhuber 也许会是人工智能研究领域的 Rodney Dangerfield（一位演员、编剧）。在紧邻意大利的一个瑞士城市，我们和他见上了一面，简短的交流后我们终于理解了这位行业先驱为什么如此低调。这种情况对于演艺界的人来说，叫未获得尊重。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibJ8ujNQ9xK748XAMhia4Om5eDpAkrCD8ia61TXwru1b6tPkXGWWqhbicoZ2A3MbTzGqZZWDTfuqTeicQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;远离硅谷，在世界的另一端，欧洲的科技公司正在开发自动驾驶汽车，语音助手，甚至能预测你行为的人工智能助理。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在大多数圈子里，那些开创新技术的人会成为明星。许多人都认识 Sebastian Thrun，谷歌自动驾驶汽车的奠基人。Adam Cheyer 和 Tom Gruber 因为 Siri 语音智能助理而闻名于世。Yann LeCun，因为神经网络的先驱地位而被从纽约大学请到 Facebook，成为这家科技巨头的领军人物。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但即便是在旧金山程序员经常光顾的自动午餐馆里提起 Jürgen Schmidhuber 的名字，知道他的人也不多。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在最近一趟去苏黎世的火车上，Schmidhuber 博士，一名 53 岁的运动员，也是 Dalle Molle 人工智能研究所的副主任，他回顾了自己是如何认为早期的研究常常被忽视。「这就像其他社会的大部分，」他说。「社会偶尔超现实（postfactual）」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;Schmidhuber 博士的委屈在研究圈子里是有名的，这些研究者们五年前把学术的一潭死水搅活，变成了价值数十亿美元的产业。他被指控窃取他人研究，甚至在维基百科上使用多个假名编写，来让大家认为有很多人支持他的帖子。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;LeCun 博士在一封 email 中写道：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Jürgen is manically obsessed with recognition and keeps claiming credit he doesn』t deserve for many, many things. It causes him to systematically stand up at the end of every talk and claim credit for what was just presented, generally not in a justified manner.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Schmidhuber 博士用一个更大的理由反驳了对自己的批评：他不是唯一一个在人工智能研究者圈子中没有获得应有名誉的人。事实上，他说自上世纪 60 年代以来的成果总是会被今天的研究名人所忽视。虽然他坚持自己对其他的知名研究者并无恶意，但这使他一直都没什么好人缘。Schmidhuber 博士说，「我圈子里的某些研究人员装作他们好像发明了点什么东西，然而，好东西是其他人的成果，他们却从来不提。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是要理解他早期的研究成果为什么没有给他带来名气却不是一件容易的事情。虽然他居住的地方远离技术产业中心，但这也无法完全作为解释。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这一争端关于神经网络的根源，神经网络允许机器通过识别模式来学习，其应用很广。作为一个科学领域，神经网络的研究可以追溯到上世纪 40 年代。但是最近几年该领域的研究才有了较大进展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;几十年来，神经网络都是实验室里的「怪胎」，常常受到质疑。但是自上世纪九十年代起，随着计算机的速度越来越快也越来越廉价，以及设计神经网络的新思路的出现，它终于得到了发展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 1997 年，Schmidhuber 博士和 Sepp Hochreiter 发表了一篇技术论文，后来证明这篇论文对最近的视觉和语音上的快速进展起到了关键作用。这个方法被称长短期记忆，简称为 LSTM。这个方法在刚引进时没有得到广泛的理解。它主要提供了一种记忆形式，或者说是一种神经网络的环境。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;就像人类不会每次都从头学起一样，神经网络的机制中存在循环和记忆的机制，每个输入的单词和观察到的像素都会被其理解。长短时记忆（LSTM）的出现让这种系统的表现得到了很大的提升，输出结果瞬间变得准确。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这可能是 Schmidhuber 的不幸——他的时代太早了，在计算机硬件性能足够处理这些算法之前。直到今天，他提出的概念才开始流行开来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;去年，谷歌的研究人员在这一方面的研究得到发表，他们使用 LSTM 减少了 49% 的语音识别错误，这是一个飞跃性进步。但是 Schmidhuber 和 Hochreiter 的研究和今天的最新进展之间还有着很大差距——这就是如今的问题所在，其他研究者会说他们在解决实际问题的过程中做出了很多贡献，这就是他们正在做的事。「他的研究是为这一领域奠定基础，」OpenCV 计算机视觉系统的创始人 Gary Bradski 说道，「但他并不是让这些技术流行起来的那个人，这有点像维京人发现了北美，但人们都只知道哥伦布的事迹。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Schmidhuber 教授的心中有一个宏伟的人工智能未来——拥有自我意识的「意识机器」，他认为这种机器很快就能被创造出来，这是一个正被同行们广泛讨论的话题。他加入了这场大辩论中：人工智能是一个工程学概念，或是人类新时代的造神运动？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Schmidhuber 站在造神的立场上，他认为这种技术的基本概念已经存在，而且人类意识没有什么特别的。「简而言之，意识和自我认知被神化了，」他说道，他认为机械意识体会随着先进的硬件和算法出现，而整个系统的大体框架早已设计完成。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从那个爱读科幻小说的德国少年到现在的计算机科学家，博士，他对此一直深信不疑。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Schmidhuber 教授回忆说，「当我长大的时候，我一直在问自己：我能给世界带来最大的影响是什么？，所以我对建造一个比我更聪明的机器这一目的十分明确，它甚至能自己建造些更聪明的东西等等，最终它能殖民并改变整个宇宙，让自己变得智能。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Nnaisense 的首席执行官是美国计算机科学家 Faustino Gomez，他是 Schmidhuber 教授多年的研究合作者。他不仅为自己的研究伙伴辩护说 Schmidhuber 完成过开创性的工作，同时反对人工智能已经开始动摇世界工业和经济的乐观态度。他说，「我们现在正在终结人工智能的萌发。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译文章，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Mon, 28 Nov 2016 12:37:29 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 科技巨头环境好待遇高，大学留不住人工智能人才</title>
      <link>http://www.iwgc.cn/link/3690820</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自WSJ&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Daniela Hernandez、Rachael King&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：杜夏德&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;近日，原斯坦福大学人工智能实验室主任李飞飞被谷歌挖去作为其人工智能新部门的领导人，又一位人工智能学术明星在科技巨头的诱惑下离开了学界。是什么原因让越来越多的学术明星加入业界？更好的待遇还是为了更好的研究？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;李飞飞作为受人尊敬的计算机科学家，在其 Facebook 主页上写道她加入谷歌的部分原因是为了「普及人工智能」。她加入了近几年来其他顶级教授离开学界走向科技业界岗位的大军。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9pZ66E9ez8iaqUibbbBGWL6lQqmJdP5RW8SONcnKw3z5kck1Qib8k8KSUxUeJhhv3GPmxmaN8ibSLjlQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最近几年，多伦多大学的 Geoffrey Hinton 加入谷歌，纽约大学的 Yann LeCun 进入 Facebook，斯坦福大学的吴恩达投向百度的怀抱，以及卡耐基梅陇大学的 Alex Smola 进入亚马逊，这些研究者中很多人仍然在大学保留了职位，但很多只是挂名了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一些研究人员警告，科技公司正在挖光大学里的科学家，他们下一代研究学者的培养者，也是从天文学到环境科学到物理学等一些冷门领域中紧迫问题的研究者。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;根据国家科学基金会的数据，过去 10 年中，毕业后进入业界工作的美国计算机科学博士生从 38% 上升到了 57%。据计算研究协会（Computing Research Association）称，虽然这一领域的博士生人数上升了，但是留在学界的人数却达到了有史以来的最低点，&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;长期来看，这将影响到未来大学教员的数量，因为计算机科学领域的博士学位一般需要三到五年才能毕业。「大家开始质疑，这么做是不是以危害我们的能力为代价去满足业界的需求，」佐治亚理工学院娱乐智能实验室主任 Mark Riedl 说到。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;这种人才紧缺的情况在深度学习领域中尤其严重。深度学习技术在在线图像搜索、语言翻译和广告投放等赚钱的业务上扮演了重要角色，蒙特利尔大学蒙特利尔学习算法研究所主任 Yoshua Bengio 说到。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能专业的学生的身价能达到「500 万到 1000 万美元，」CMU 计算机学院院长 Andrew Moore 说到。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;科技巨头提供的工作环境是很多大学都比不上的，包括稳定的资金、海量的数据集和强大计算能力，还有创造用户数百万的产品带来的快感。此外企业薪酬要高得多，而且还有股票期权的分红。根据 NSF 的数据，2014 年，计算机和信息科学专业的大学博士后年薪为 55,000 美元，相比之下业界实验室提供的年薪为 110,000 美元，是大学的两倍。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;研究人员担心人才流失会干扰像环境科学这样的学科的前沿问题的研究。「我担心这会拖慢大学和研究实验室的研究进度，因为最好的最聪明的人才都不在这里，」国家大气研究中心（National Center for Atmospheric Research）的 Sue Haupt 说到。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;她们的顶级研究者之一被 Weather Company 公司挖走了，这家公司现在属于 IBM。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;卡耐基梅隆大学为了应对与大公司的人才抢夺战已经开始允许教员在业界和学校轮岗。Moore 博士认为，他手下会有 10% 到 20% 人会在某个时刻离职，去业界工作或者自己创业。「我们真的希望他们能在业界和大学之间流动。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;微软、谷歌和 Facebook 等科技巨头的人工智能专家说他们正在通过资助大学各系和训练学生来努力为学界保留人才。据 IBM Research 副总 Guru Banavar 介绍，IBM 最近有发布了认知地平线网络（Cognitive Horizon Network），一个由六所学校组成的联合会，旨在保留大学里的学者。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Facebook、百度和微软也称在资助学界的研究。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而苹果和亚马逊对此事不予置评。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在某些情况下，这些技术公司允许他们的学术雇员保留大学中的任职，但是会削减其教学时间，甚至限制讨论和相关话题。斯坦福的李博士在其 Facebook 主页上说她继续在斯坦福教几个学季（quarter），但没有透露具体细节。Hinton 博士一边在 Google 工作一边在多伦多大学教书，他名下还带了三名研究生。在纽约大学课程目录上可查 LeCun 博士一边领导者 Facebook 人工智能研究室，一边还在大学带了一个班级，没进 Facebook 之前他带两个班。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「大量业界研究者一般都还有另一个学术职位，可这对学生来说不是什么好事，」康奈尔大学人工智能教授 Bart Selman 说到。最近，一些学院的人工智能相关课程的选课人数增加了三倍，如此一来，剩下的老师花在每个学生身上的时间就会非常少了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Mon, 28 Nov 2016 12:37:29 +0800</pubDate>
    </item>
    <item>
      <title>前沿 | 量子计算新突破：英国科学家提出大大简化囚禁离子的新技术</title>
      <link>http://www.iwgc.cn/link/3690822</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自International Business Times&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Mary-Ann Russon&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：朱思颖、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;苏塞克斯大学的物理学家日前向外界公布一项颇具开创性的技术，称这一新技术可以大大简化大尺度囚禁离子量子计算机的构建&lt;/span&gt;&lt;/em&gt;&lt;em&gt;&lt;span&gt;，这使我们离量子计算机的真正问世又更近了一步。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前量子计算机还处于「概念」阶段，但来自世界各地的大量计算机科学研究人员，正在这个已投入亿万资金的研究课题上如火如荼地展开研究，并且相信在近 50 年超级强大的量子计算机将会被研发出来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在量子计算机系统的构建上，大部分用来创建量子门所利用的「原料」主要有以下几种：囚禁的离子和原子；光粒子；作为量子位元的超导电路（IBM 所使用的技术）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;利用囚禁的离子的方法来构建的量子计算机，目前主要通过激光光束来创建量子门。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这种方法在创建小型的量子计算机（只有几个量子位）上是可行的。然而要构建真正意义上的量子计算机，仅仅只有几个量子位（quantum bits）是远远不够的。因为量子位太少，无法实现大规模的计算，这也意味着用这种方法你需要一个拥有数亿激光束的系统来构建量子门，并且激光束的排布需要控制在 5 微米误差之内。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以上的方法在实际中非常难以实现，这也是为什么至今也没有真正意义上的量子计算机出现。苏塞克斯大学的研究人员所提出的方法，解决了通过囚禁的离子这种方法来构建超级计算机所遇到的瓶颈。通过微芯片上电压的改变来创造量子门来代替之前的激光光束，这个方法操作起来极为简便。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9pZ66E9ez8iaqUibbbBGWL6lHvP2FRZic81w5sIZhib0oA9pKod9XJ9okmfiakk6FmumqzbEUvsua3hMw/0?wx_fmt=png"/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过囚禁离子（trapped-ion）构建的量子计算机将会拥有一组量子位的 X 结（X-junctions），这些量子位是通过对量子芯片表面上各自独立的离子的捕获而产生的（灰色区域）。这些彼此独立的量子位可以通过操控电压来获得，就像通过调频来收听不同的频道那样简单。试想以下情形：在 V1 电压下，没有任何量子位的操作（蓝色区域）；V2 电压下，产生了一个量子位（绿色区域）；V3 电压下，产生两个「纠缠」态的量子位（红色区域）。以此类推，一个任意大的量子计算机都可以完全通过如此简单的工程方法来实现。（图片来源于苏塞克斯大学。）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我们的方法将构建量子计算机的难度降到与经典计算机构建同等难度。经典计算机的构造中含有很多晶体管，这些晶体管的作用是通过电压来执行经典的逻辑门，」苏塞克斯大学的离子量子技术研究组的量子技术研究教授 Winfried Hensinger 在 IBTimes UK 的采访中说到。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我们运用微波辐射技术，也就是将整个量子计算机包围在微波之中，然后我们设置将要处理区域的局部磁场梯度变化，在这之后就可以运用电压的改变来产生量子门，通过对离子位置的改变来控制离子和整个微波场的相互作用。」这项研究已经在 Physical Review Letters 上发表，论文标题「Trapped-Ion Quantum Logic with Global Radiation Fields」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;一个创建量子门的简易方法&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;要创建一个量子门，两个量子位的量子纠缠是必备条件。其中两个粒子可以保持相同状态，即使两个粒子在空间距离上相距很远，其中一个粒子的状态改变也会同步到另一个粒子。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你想构建一个量子门，那么你将需要囚禁的离子之间能够「共鸣」。但如果你仅仅需要一个单独的量子位，那么你会需要改变离子位置的选择，这样它就不会和全局微波场交互，这个过程在目前技术下是完全可以实现的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;苏塞克斯大学是 Networked Quantum Information Technologies (NQIT) 的核心成员之一，该机构的研究资金来源于英国政府，也是英国政府在量子科技产业上的前沿阵地。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;英国政府寄希望于英国的量子科技产业能诞生两个大型的量子计算机范本——一个是在牛津大学，另一个就是在苏塞克斯大学。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前为止，超导量子位和囚禁离子型量子计算机的研究已取得了一定的进展，目前科学家已经实现大约 10 个量子位。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相比之下，目前苏塞克斯大学的研究员在他们实验室中所构建的量子计算机仅 2 量子位，但是他们 下一代的量子计算机将会有 10 量子位，而且预计在三到四年之内研发完成。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「大型量子计算机的构建难度已大为降低。有史以来第一次，你可以仅使用电压来控制囚禁离子量子位以打造量子计算机，」Hensinger 说到，并且他个人认为囚禁离子型的量子计算研究将比超导量子研究的进展更快。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「这项研究将会彻底改观当前囚禁离子型量子计算机的构造过程，就像是从功能型手机到智能手机的转变。最明显的优势是这个技术可以产生数以万计的量子位，而且完全是当前技术可实现的。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;原文连接：http://www.ibtimes.co.uk/quantum-computing-breakthrough-uk-scientists-develop-technique-greatly-simplify-trapped-ions-1593317?utm_source=social&amp;amp;utm_medium=twitter&amp;amp;utm_campaign=/quantum-computing-breakthrough-uk-scientists-develop-technique-greatly-simplify-trapped-ions-1593317&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，机器之心系今日头条签约作者，本文首发于头条号，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Mon, 28 Nov 2016 12:37:29 +0800</pubDate>
    </item>
    <item>
      <title>盘点 | 今年GitHub排名前20的Python机器学习开源项目</title>
      <link>http://www.iwgc.cn/link/3679239</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自KDnuggets&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Prasad Pore&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：杨旋、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote style="max-width: 100%; color: rgb(62, 62, 62); font-size: 16px; line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;p&gt;&lt;span&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;当今时代，开源是创新和技术快速发展的核心。&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;本文来自 KDnuggets 的年度盘点，介绍了&lt;/em&gt; 2016 年排名前 20 的 Python 机器学习开源项目，在介绍的同时也会做一些有趣的分析以及谈一谈它们的发展趋势。和去年一样，KDnuggets 介绍了 GitHub 上最新的并且排名前 20 的 Python 机器学习开源项目。令人吃惊的是，去年一些最活跃的项目已经停滞不前了，也有一些项目跌出了前 20 名（在 contribution 和 commit 方面），当然，也有 13 个新项目进入了前 20。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9pZ66E9ez8iaqUibbbBGWL6lJDZttRbGkO1kRvGLp5z4Fw0MpuI7jlbUgDKJ1Ta4YLL15kMB5VYkQw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;2016 年排名前 20 的 Python 机器学习开源项目&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1.Scikit-learn&lt;/span&gt;&lt;/strong&gt;&lt;span&gt; 是一种基于 NumPy、SciPy 和 matplotlib 的用于数据挖掘和数据分析的工具，其不仅使用起来简单高效，而且还是开源的，可供所有人使用，并且拥有商业可用的 BSD 许可证，在不同的环境下都能很好的被使用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;提交：21486，贡献者：736&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：http://scikit-learn.org/&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2.TensorFlow &lt;/span&gt;&lt;/strong&gt;&lt;span&gt;最初由 Google 机器智能研究机构的 Google Brain 团队的研究人员和工程师开发。该系统旨在促进对机器学习的研究，同时也让机器学习研究原型过渡到生产系统更加高效容易。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;提交：10466，贡献者：493&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：https://www.tensorflow.org/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3.Theano &lt;/span&gt;&lt;/strong&gt;&lt;span&gt;能让您更加高效地定义、优化和评估涉及多维数组的数学表达式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;提交：24108，贡献者：263&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：http://deeplearning.net/software/theano/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;4.Caffe&lt;/span&gt;&lt;/strong&gt;&lt;span&gt; 是一个由伯克利视觉与学习中心（BVLC）和社区贡献者开发的深度学习框架，它兼具表现力和速度，还有模块化的优点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;提交：3801，贡献者：215&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：http://caffe.berkeleyvision.org/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;5.Gensim &lt;/span&gt;&lt;/strong&gt;&lt;span&gt;是一个免费的 Python 库，它具有诸如可扩展的统计语义等特征，它可用于分析纯文本文档的语义结构和检索语义相似的文档。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;提交：2702，贡献者：145&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：https://radimrehurek.com/gensim/&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;6.Pylearn2 &lt;/span&gt;&lt;/strong&gt;&lt;span&gt;是一个机器学习库。它的大部分功能都是建立在 Theano 的基础之上。这意味着你可以使用数学表达式编写 Pylearn2 插件（新模型、算法等），然后 Theano 将为你优化这些表达式让其更加稳定，并将根据你的选择把它编译适配相应的后端（CPU 或 GPU）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;提交：7100，贡献者：115&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：http://github.com/lisa-lab/pylearn2&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;7.Statsmodels &lt;/span&gt;&lt;/strong&gt;&lt;span&gt;是一个允许用户挖掘数据、估计统计模型和执行统计测试的 Python 模块。描述性统计、统计测试、绘图函数和结果统计的详细列表可用于不同类型的数据和估计器。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;提交：8664，贡献者：108&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：https://github.com/statsmodels/statsmodels/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;8.Shogun&lt;/span&gt;&lt;/strong&gt;&lt;span&gt; 是一种提供大量高效且统一的机器学习（ML）方法的机器学习工具箱。它能容易地把多种数据表示，算法类和通用工具紧密地联系起来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;提交：15172，贡献者：105&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：https://github.com/shogun-toolbox/shogun&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;9.Chainer &lt;/span&gt;&lt;/strong&gt;&lt;span&gt;是一个基于 Python 并且独立的深度学习模型开源框架。Chainer 提供一种灵活、直观且高效的方法来实现整个深度学习模型，包括如循环神经网络和变分自动编码器等最先进的模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;提交：6298，贡献者：84&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：https://github.com/pfnet/chainer&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;10.NuPIC&lt;/span&gt;&lt;/strong&gt;&lt;span&gt; 是一个基于一种被称为分层式即时记忆（HTM/ Hierarchical Temporal Memory）的新皮质理论的开源项目。HTM 理论中的一部分已经在应用中被实现、测试和使用了，而其他部分仍在开发中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;提交：6088，贡献者：76&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：http://github.com/numenta/nupic&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;11.Neon &lt;/span&gt;&lt;/strong&gt;&lt;span&gt;是 Nervana (http://nervanasys.com/) 公司的一个基于 Python 的深度学习库。它提供易用性的同时也提供了最高的性能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;提交：875，贡献者：47&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：http://neon.nervanasys.com/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;12.Nilearn &lt;/span&gt;&lt;/strong&gt;&lt;span&gt;是一个用于在 NeuroImaging 数据上快速轻松地进行统计学习的 Python 模块。它利用 scikit-learn Python 工具箱来处理如预测建模、分类、解码或连接分析等多变量统计信息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;提交：5254，贡献者：46&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：http://github.com/nilearn/nilearn&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;13.Orange3&lt;/span&gt;&lt;/strong&gt;&lt;span&gt; 是一个新手和专家都可以使用的开源机器学习和数据可视化工具。在交互式数据分析工作流程中拥有大型的工具箱。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;提交：6356，贡献者：40&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：https://github.com/biolab/orange3&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;14.Pymc &lt;/span&gt;&lt;/strong&gt;&lt;span&gt;是一个实现贝叶斯统计模型和拟合算法的 Python 模块，其中包括马尔可夫链和蒙特卡罗方法。其灵活性和可扩展性使其适用于大量问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;提交：2701，贡献者：37&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：https://github.com/pymc-devs/pymc&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;15.PyBrain&lt;/span&gt;&lt;/strong&gt;&lt;span&gt; 是 Python 的一个模块化机器学习库。它的目标是为机器学习任务提供灵活且易于使用但仍然强大的算法，以及各种预定义环境来对你的算法进行测试和比较。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;提交：984，贡献者：31&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：http://github.com/pybrain/pybrain&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;16.Fuel&lt;/span&gt;&lt;/strong&gt;&lt;span&gt; 是一个数据管道框架（data pipeline framework），它为你的机器学习模型提供所需的数据。它将被 Blocks 和 Pylearn2 神经网络库使用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;提交：1053，贡献者：29&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：http://github.com/mila-udem/fuel&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;17.PyMVPA &lt;/span&gt;&lt;/strong&gt;&lt;span&gt;是一个用于简化大型数据集的统计学习分析 Python 包。它提供了一个可扩展的框架，具有大量用于分类、回归、特征选择、数据导入和导出等算法的高级接口。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;提交：9258，贡献者：26&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：https://github.com/PyMVPA/PyMVPA&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;18.Annoy&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;（Approximate Nearest Neighbors Oh Yeah）是一个绑定 Python 的 C ++库，用来搜索在空间中距离给定查询点较近的点。它还创建了基于大型只读文件的数据结构，这些数据结构被映射到内存中，以便许多进程可以共享相同的数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;提交：365，贡献者：24&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：https://github.com/spotify/annoy&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;19.Deap &lt;/span&gt;&lt;/strong&gt;&lt;span&gt;是一个用于快速原型和测试思想的新颖的进化计算框架。它试图使算法更加浅显易懂，数据结构更加透明。它与并行机制（例如 multiprocessing 和 SCOOP）能完美协调。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;提交：1854，贡献者：21&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：https://github.com/deap/deap&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;12.Pattern &lt;/span&gt;&lt;/strong&gt;&lt;span&gt;是 Python 编程语言的 Web 挖掘模块。它捆绑了数据挖掘（Google + Twitter +维基百科 API、网络爬虫、HTML DOM 解析器）、自然语言处理（词性标记、n-gram 搜索、情感分析、WordNet）、机器学习（向量空间模型、k-means 聚类、朴素贝叶斯+ k-NN + SVM 分类器）和网络分析（图形中心性和可视化）等工具。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;提交：943，贡献者：20&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：https://pypi.python.org/pypi/Pattern&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从下面的图表中我们可以得知，与其它项目相比，PyMVPA 具有最高的贡献率。令人吃惊的是，相比于其它项目，尽管 Scikit-learn 的贡献者最多，但是它的贡献率比较低。这背后的原因可能是因为 PyMVPA 是一个新的项目，经历了早期的发展阶段，由于新的想法/功能开发，缺陷修复，重构等原因导致了许多提交。而 Scikit-learn 是一个早期的并且比较稳定的项目，所以拥有较少的改进或缺陷修复等提交。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9pZ66E9ez8iaqUibbbBGWL6lyK9Mz9Y6nfhqbgccSR6Knk9yxjxCW3E2ibLcleCKWUdKicRBWh44Jndg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们对 2015 年和 2016 年的项目进行了比较，它们都是排名前 20 名的项目。我们可以看到 Pattern、PyBrain 和 Pylearn2 的贡献率没有明显的改变，也没有新的贡献者。此外，我们可以在贡献者的数量和提交的数量中看到一个显著的相关性。贡献者的增加可能会导致提交的增加，这也是我认为开源项目和社区神奇的地方；它可以导致头脑风暴，产生新想法以及创造更好的软件工具。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9pZ66E9ez8iaqUibbbBGWL6l23Jic2rtxTR0gNjibUcY7Vla4YgPia1gX9ZkCdEadj5wq6nofRUyDpjwg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以上就是 KDnuggets 团队根据贡献者数量和提交数量对 2016 年排名前 20 的 Python 机器学习开源项目的分析。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;开源和知识共享是令人快乐的一件事！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;原文连接：http://www.kdnuggets.com/2016/11/top-20-python-machine-learning-open-source-updated.html&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;----------------------------&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720758&amp;amp;idx=5&amp;amp;sn=3393e25835c0f96ee82396992a8ff27b&amp;amp;chksm=871b0d88b06c849e711c1c42750b1518b42cbb098526f1095ac2a39c9b21b7d2aaf7388fb764&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720758&amp;amp;idx=5&amp;amp;sn=3393e25835c0f96ee82396992a8ff27b&amp;amp;chksm=871b0d88b06c849e711c1c42750b1518b42cbb098526f1095ac2a39c9b21b7d2aaf7388fb764&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;"&gt;&lt;span&gt;查看interface第二期活动详情&lt;/span&gt;&lt;/a&gt;&lt;span&gt;，或者点击阅读原文直接报名。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9pZ66E9ez8iaqUibbbBGWL6lxkDsobpZnV3eKibsshEKGeQLUoJDTib7Y0qodwrzzFMsj2FYNdQLp2kw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Sun, 27 Nov 2016 13:05:06 +0800</pubDate>
    </item>
  </channel>
</rss>
