<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器之心</title>
    <link>http://www.iwgc.cn/list/670</link>
    <description>人与科技的美好关系</description>
    <item>
      <title>重磅 | Yann LeCun推荐：新证据出现，乔姆斯基的普遍语法理论正被颠覆</title>
      <link>http://www.iwgc.cn/link/2638726</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Scientific American&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Paul Ibbotson, Michael Tomasello&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：Rick、吴攀、李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;诺姆·乔姆斯基的许多语言学革命——包括对我们学习语言的方法的描述——正在被颠覆。近日，Yann LeCun 在他的 Facebook 和 Twitter 上推荐了 Scientifc American 的这篇文章，他表示这在乔姆斯基的普遍语法理论的棺木上又多钉了几枚钉子。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibx10fYjKxeuYboDW2ic5N9YZmkTZlrOYibQmUfJa4y3iaCGicXibHgBTG1kuEyZw3fyRJ8ia5jDV5PyOYg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们的大脑天生具有学习语法的心理模板——这个被 MIT 的诺姆·乔姆斯基所信奉的知名观念——已经统治了语言学近半个世纪。尽管如此，由于新研究考察了许多不同的语言，最近认知科学家和语言学家们已经在成群结队地抛弃乔姆斯基的「普遍语法（universal grammar）」理论，也就是年幼的孩子学习理解并说当地社会语言的方式。这项工作没能支持乔姆斯基的主张。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这项研究提出了一个完全不同的观点，它认为一个儿童学习第一门语言的过程并不依赖于一个固有的语法模块。新的研究反而表明，年幼的孩子使用不同类型的思维方式，这个方式可能一点也不特定于语言——比如分类的能力（比如这是人还是物）以及了解事物之间关系的能力。这些能力，配合人类独特的获取其他人在交流中想要表达的含义的能力，就发生了语言。这项新的研究结果表明，如果研究人员真正想要了解孩子们和其他人如何学习语言，他们就需要走出乔姆斯基的理论。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个结论是重要的，因为语言研究在不同学科中起着核心作用——从诗歌到人工智能再到语言学本身；误导的方法导致可疑的结果。此外，没有动物能够对应上人类使用语言的方式；如果你明白什么是语言，你就对人的天性多了一分了解。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;乔姆斯基的第一版理论是在 20 世纪中期提出的，它与西方知识分子的生活中出现的两个新兴趋势相吻合。首先他指出，人们在日常生活中用来交流的语言，表现得就像是计算机科学领域中新兴的基于数学的语言。他的研究探讨了语言的基本计算结构，并提出了一套能创建出「构成良好（well-formed）」的句子的一系列流程。这个革命性的想法认为，一个类似计算机的程序可以产生出真实的人认为是符合语法规则的句子。据称这个程序也可以解释为人们造句的方式。这种讨论语言的方法引起了许多学者的共鸣，他们热衷于将一种计算方法信奉为一切。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;随着乔姆斯基发展他的计算理论，他同时提出这种理论植根于人类生物学。二十世纪后半叶，正变得越来越明显的观点是：我们独特的进化史是造成我们独特的人类心理状态的许多方面的根源，因此乔姆斯基的理论也在该水平上与之共鸣。他的普遍语法是作为人类思维的先天成分被提出来——它允诺要揭示出世界 6000 多种人类语言的深层生物学基础。最强大的、且不说最美的科学理论揭示出表面多样性下隐藏着的统一性，那么这一理论就会立即引起关注。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是不支持乔姆斯基的理论的证据已经出现了，后者多年来一直在缓慢地走向死亡。它死得太慢了，因为正如物理学家马克斯·普朗克曾指出的那样，年长的学者倾向于坚持旧方法：「科学每进一步就有一个葬礼。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;起初&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;20 世纪 60 年代最早的普遍语法化身采用「标准常态欧洲语（standard average European）」语言的基本结构作为它们的出发点——大多数从事这方面研究的语言学家都说这种语言。因此普遍语法程序以语言块的形式运行，比如名词短语（「不错的狗」）和动词短语（「喜欢猫」）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然而相当快地，开始出现波动的多语种语言比较并不适合这个整洁的模式。一些澳大利亚本土语言，如 Warlpiri，它有散落在句子中的语法元素——没有被「打包整齐」因而不能够插入到乔姆斯基的普遍语法中去的名词和动词短语——和一些完全没有动词短语的句子。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些所谓的异常值难以与建立在欧洲语言实例上的普遍语法相调和。乔姆斯基理论的其他例外来自于对「主动格（ergative）」语言的研究，比如巴斯克语或乌尔都语，其句子主语被使用的方式非常不同于许多欧洲语言，这再次挑战着普遍语法的理念。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibx10fYjKxeuYboDW2ic5N9Y9AD0alicw7RR9eCaapWoHA4iaugShXamXwPuuwuQtP3hUJfORWnqlQBA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些发现连同语言理论工作，导致乔姆斯基和他的追随者在 20 世纪 80 年代期间大规模修改普遍语法的概念。该理论的新版本被称为原则和参数（principles and parameters），由一组控制语言结构的「通用（universal）」原则取代了囊括所有世界语言的一种单一的普遍语法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些原则在每种语言中都有不同的表现。打个比喻：我们天生拥有一组与文化、历史和地理相互作用着的基本味觉（甜、酸、苦、咸、鲜），从而在当今的世界美食中产生变化。这个原则和参数理论是语言学的一个味觉比喻。它们与文化（无论一个孩子是学习日语还是英语）相互作用从而语言学中产生了今天这些变化， 并定义了一套可能的人类语言。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;比如西班牙语可以产生无需单独主语的完全合乎语法的句子——例如 Tengo zapatos （「I have shoes」），其中有鞋子的这个人，「我」，并没有由一个单独的词而是由动词末尾的「o」来表示。乔姆斯基争辩说，一旦孩子们遇到几个这种类型的句子，他们的大脑会设置一个「打开」开关，表示该句子主语应该被丢弃。然后他们就会知道他们可以在所有句子中丢弃这个主语。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个「主语-丢弃」参数一般也决定了该语言的其他结构特征。这种普遍原则的概念相当适合许多欧洲语言。但是非欧洲区语言的数据表明，它们并不适合修订版的乔姆斯基理论。事实上已­­有研究试图去确定那些参数，比如主语–丢弃，这最终导致了对于普遍语法的第二化身的丢弃，因为它没能经得起推敲。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最近，在一篇发表于 2002 年的《科学》杂志上的著名论文中，乔姆斯基与其合著者描述了一个普遍语法，它只包含一个称作计算递归（computational recursion）的特征（尽管许多普遍语法的拥护者仍然宁愿假定存在许多普遍性的原则和参数）。这个新转变允许组合有限数量的单词和规则，从而产生无限多个句子。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;由于递归在另一个类型相同的短语中嵌入短语的方式，无尽的可能性是存在的。例如英语能够将短语嵌入到右边（「John hopes Mary knows Peter is lying」）或中间（「The dog that the cat that the boy saw chased barked」）。无限地嵌入这些短语在理论上是可能的。在实践中，正如在这些例子所描述的，当这些短语被堆积在另一个短语上面时，理解就开始崩溃了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;乔姆斯基认为这种崩溃并不直接与语言本身有关。相反，它是人类记忆的一个局限性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;更重要的是，乔姆斯基提出这种递归能力使得语言独立于其他类型思维，比如分类以及感知事物之间的关系。最近他还提出，这种能力是由发生于­十万到五万年前的一个单一的遗传突变所引起。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;之前，当语言学家真的去看了世界各地的语言变化时，他们发现了这一断言的反例，即这种递归是语言的一个本质属性。有些语言——例如亚马逊人的 Pirahã——似乎不兼容乔姆斯基的递归。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;和所有语言理论一样，乔姆斯基的普遍语法试图达到一个平衡。这个理论必须简单得足够值得拥有。也就是说，它必须预测一些不在理论本身之中的东西（否则它只是一列事实）。但理论并不会如此简单，否则它就无法解释其应该解释的东西。以乔姆斯基的观点，在世界上所有的语言中，句子都有一个「主语」。问题是一个主语的概念更像是特征的一个「家族相似性（family resemblance）」而非一个整洁的类别。一个主语的特征大约由 30 种不同的语法特征所定义。任何一种语言将只有一个这些特征的子集——而这个子集往往不与其他语言重叠。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;乔姆斯基试图定义语言的基本工具包组件——允许人类语言发生的某种心理机制。在那些反例被发现的地方，乔姆斯基的支持者就回应说那只是­­因为一种语言缺乏某种工具——例如递归——这并不意味着它不在工具包里。同样地，只是因为某种文化的季节性食物中缺少盐，并不意味着咸味就不在它的基本口味条目里。不幸的是，这种推理使得乔姆斯基的建议难以在实践中得到检验，而且在某些地方它们正濒临不可证伪的边缘。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;死亡丧钟&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;乔姆斯基理论中的一个关键缺陷是当其被应用于语言学习时，它们规定年幼的儿童运用抽象语法规则造句的能力是与生俱来的。（精确的说法取决于的是哪个理论版本。）然而现在的大量研究表明，语言习得不是以这种方式发生的。相反年幼的孩子们是以学习简单的语法模式作为开始；然后他们渐渐地觉察到其背后规则的点点滴滴。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因此年幼的孩子最初只说基于特定单词模式的、具体而简单的语法结构：「Where’s the X?」；「I wanna X」；「More X」；「It’s an X」「I’m X-ing it」；「Put X here」；「Mommy’s X-ing it」；「Let’s X it」；「Throw X」；「X gone」；「Mommy X」；「I Xed it」；「Sit on the X」；「Open X」；「X here」；「There’s an X」；「X broken.」后来孩子们把这些早期的模式结合进更复杂的模式中，比如「Where’s the X that Mommy Xed?」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;普遍语法的许多支持者都接受这种儿童早期语法发展的特点。但接着他们认为当更复杂的结构出现时，这个新阶段反映了一种使用普遍语法及其抽象语法类别和抽象语法原则的认知能力的成熟。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;例如大多普遍语法方法都这假定说，一个儿童是通过遵循一组基于语法类别的规则来造问句，比如「What （宾语） did （助动词）you （主语）lose （动词）?」回答：「I（主语） lost（动词）something （宾语）.」如果这个假设正确，那么在一个特定的发育期，儿童应该在所有 wh-似的问句中犯类似的错误。但儿童犯的错误并不符合这个预测。他们中的许多人在发育的早期都犯了下面这些错误，比如「Why he can’t come?」但同时当他们犯这个错误时——不能将「can’t」置于「he」之前——他们正确地使用「wh-疑问词」和助动词组织了其他问句，比如这句「What does he want?」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;实验研究证实，儿童大都使用特殊 wh- 疑问词和助动词来造出正确的问句（通常是那些他们与之有大部分经验的单词，比如「What does ...」），在而含有其他（通常较少） wh- 疑问词和助动词结合的文具中继续犯错误：「Why he can’t come?」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;普遍语法学家对这样的这种发现的主要反应是，儿童有语法能力而其他因素会阻碍他们的表现，因而它们隐藏了儿童们的语法的真实本质，也妨碍了他们对于「纯粹」的乔姆斯基语言学所假定的语法的学习。掩盖基本语法的那些因素，他们说，包括不成熟的记忆、注意力和社交能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然而乔姆斯基对儿童行为的解释不是唯一的可能。记忆、注意力和社交能力可能无法掩盖语法的真实状态；相反它们对于早期的语言建立很可能是不可或缺的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;例如最近一项由我们之中的某人（Ibbotson）所合著的研究表明，儿童造出正确的不规则过去时态动词——比如「Every day I fly, yesterday I flew」（不是「flyed」）——与他们抑制一个与语法无关的诱人响应的能力相关。（例如在看一张太阳的图片而要说出单词「moon」。）不是记忆、心理类比、注意力以及有关社交场合的反应阻碍了儿童表达乔姆斯基语言学的纯粹语法，那些智力可能解释了语言发展的方式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;随着跨语言学数据和工具包争论的撤退，表现掩盖了能力——这种思想也几乎无法证伪了。在衰退中的、缺乏一个强有力的经验基础的科学范式中，它们撤退到这类断言中去是常见的——例如思考一下弗洛伊德心理学和­­历史学的马克思主义解释。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;即使超越这些对于普遍语法的实证挑战，从事儿童研究工作的心理语言学家很难在理论上构思这一过程，即儿童对所有语言在一开始都使用相同的代数语法规则，然后继续找出一种特定语言——无论是英语还是斯瓦希里语——是如何与规则体系相连接的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;语言学家称这个难题为连接（linking）问题，而在普遍语法的背景下去解决这个难题的一个不寻常的系统尝试，是由哈佛大学的心理学家 Steven Pinker 为研究句子主语所做的。然而 Pinker 的思考却并不符合儿童­­发展研究的数据，或者说并不适用于主语之外的其他语法类别。因此该连接问题——应当是将普遍语法应用到语言学习中去的中心问题——从未被解决，甚至从未被严肃对待过。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;另一种观点&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所有这一切都不可避免地导致了认为普遍语法完全是错误的的观点。当然，即使面对着有矛盾的证据，科学家也从不会放弃他们最喜欢的理论，直到有一种合理的替代理论出现。现在已经出现了这样一种替代理论，它被称为基于使用的语言学（usage-based linguistics）。这个有多种形式的理论提出语法结构并不是内生的。事实上，语法是历史（塑造语言形式的过程一代接一代）和人类心理（让一代人从一开始就学习的社会和认知能力集合）的产物。更重要的是，这个理论提出语言所使用的大脑系统可能并不是为此目的专门进化的，所以这不同于乔姆斯基的递归（recursion）的单基因突变的思想。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这种新的基于使用的方法中（其中包括来自功能语言学、认知语言学和构式语法的思想），儿童并不是生而就具备普遍的、专门的学习语法的工具。相反他们继承了瑞士军刀式的在心智上全能的套件：一组通用目的的工具，包括归类、读取交流意图和进行类比；使用这些工具，儿童可以从其周围所听到的语言中学习语法类别和规则。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;比如说，说英语的儿童理解「The cat ate the rabbit」，而且通过类比，他们也能理解「The goat tickled the fairy」。他们通过听一个又一个的样本来进行归纳。在经过了足够多的样本后，他们可能就能猜出句子「The gazzer mibbed the toma」中谁对谁做了什么，即便其中有的词本质上是胡言乱语的。语法是他们所要理解的超越词汇本身的东西，因为这些句子在词的水平上的相似度很低。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;语言中的含义通过词本身的可能含义（比如「ate」这个词所表示的意思）和这些词所在的语法结构的含义之间的互动而涌现。比如说，尽管「sneeze」在词典中是一个不及物动词，只有单一的施动者（actor）（打喷嚏者），但如果有人强迫它成为一个双及物结构（可以由直接宾语和间接宾语），那么结果可能会是「She sneezed him the napkin」，其中「sneeze」是一种转移的动作（也就是说，她使这个餐巾纸到他那里去了）。这个句子表明语法结构对一个句子的含义的重要性和词的重要性一样。相比于乔姆斯基，他认为语言层面是完全不具备含义的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个瑞士军刀式的概念也能够解释语言学习，而不需要像普遍语法理论一样牵扯到两个现象。一是用于组合符号的一系列代数规则——一种内置于大脑中所谓核心语言（core grammar）。第二是一个词汇集（lexicon）——覆盖了自然语言中所有需要被学习的习语和特殊用法的例外情况列表。这种双路径的方法的问题是一些语法结构是部分基于规则的且又有部分不基于规则——比如说：「Him a presidential candidate?!」，其中的主语「him」保留了直接宾语的形式，但其在句子中的元素并不处在合适的位置上。使用同样的方法，一位英语母语者可以生成无限多个类似的句子：「Her go to ballet?!」或「That guy a doctor?!」所以问题就来了：这些话语是核心语言的一部分还是例外列表的一部分？如果他们不是核心语法的一部分，它们必须每次都要单独学习。但如果儿童可以学习这些部分规则，部分例外的话语，那为什么他们不能以同样的方式学习语言中的其它部分呢？换句话说，他们究竟为什么需要普遍语法？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;事实上，普遍语法的思想与儿童通过社交学习语言和使用语言学社会随时间所创造的句子构建（sentence construction）获得实践的证据是矛盾的。在一些案例中，在这些学习过程的确切发生方式上我们有很好的数据。比如说，在世界各地的语言中，定语从句是相当常见的，而且往往源自不同句子的啮合。因此，如果有句子「My brother.... He lives over in Arkansas.... He likes to play piano.」因为各种各样的认知过程机制——涉及到图式化、习惯化、脱离语境和自动化（schematization, habituation, decontextualization and automatization）这些术语——这些短句可以融合成一个更为复杂的结构：「My brother, who lives over in Arkansas, likes to play the piano.」或者它们也可将「I pulled the door, and it shut」这样的句子逐渐变成「I pulled the door shut.」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;更重要的是，我们似乎有一种能够解码他人的交际意图（说话人想说什么）的种族天赋。比如说，我不需要说「She donated the library some books」，我可以说「She gave/bequeathed/sent/loaned/­sold the library some books」。最近的研究表明存在一些能让儿童约束这些类型的不适当类比的机制。比如说，儿童不会做没有意义的类比。所以他们往往不会说「She ate the library some books.」此外，如果儿童常常听到「She donated some books to the library」，那么这就会抑制他们说「She donated the library some books」的想法。对于那些他或她尝试理解的人的交流意图，这样的约束机制会极大地限制他们会使用的可能类比。我们都会使用这种类型的意图读取，比如我们可以理解「你能为我开门吗？」是请求帮助，而不是询问对方是否具备开门的能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;乔姆斯基允许在其关于语言工作方式的广义理论中的这类的「语用学（pragmatics）」——我们如何在语境中使用语言。考虑到语言能有多模糊，他也不得不这样做。但他似乎将语用看作是语法的主要工作的辅助。在某种程度上，来自基于用途的方法的贡献已经将其它方向上的争辩转变成了在说话者需要转向句法（syntax）规则前，语用对语言有多大作用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;基于用法的理论远远不能为语言的工作方式提供一个完整的解释。对儿童从所听到的口语句子和短语的有意义的归纳并不是儿童构建句子的方法的全部——而且有的归纳有意义但却不符合语法（比如：He disappeared the rabbit）。在儿童所有的有意义然而却不符合语法的归纳中，这种的似乎非常少。原因似乎是他们对他们所属的语言社区所确认的规范非常敏感，他们知道只能以「这种方式」进行交流。不过他们取得了一个微妙的平衡，因为儿童在语法规则上既具有创造性（「I goed to the shops」），又具有构造性（conformative，「I went to the shops」）。基于使用的理论还有很多的工作要做，以解释这些力量在童年的交互方式，以便能确切地解释语言发展的路径。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;向前看&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在乔姆斯基范式被提出来的时候，它是在当时流行的非正式方法上的一次彻底突破，它吸引了人们对足以支撑说话和理解语言的认知复杂性的关注。但乔姆斯基等人的理论在让我们可以看见新事物的同时，也让我们无法看到语言中的其它方面。在语言学极其相关领域，许多研究者原来越对完全形式化的语言不满，比如普遍语法——更不要提该理论的实证经验不足。此外，很多现代的研究者也并不满足于完全的理论分析，现在已经有了大量语言学数据的语料——许多可以在网上获取——这些可被用来对一项理论进行测试。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个范式转换肯定是不完整的，但对很多人来说，它就像是涌入语言学领域的一股新鲜空气。通过研究世界上不同语言的细节，已经出现了一些激动人心的新发现：它们如何相似又如何不同、它们在历史上出现了怎样的变化，幼儿是如何获得一种或多种语言的能力的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;普遍语法看起来已经陷入了最终的死胡同。在这个地方，对基于使用的语言学的研究可以为全世界 6000 多种语言的学习、使用和历史发展的实证研究提供一个前进的途径。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Sat, 10 Sep 2016 16:20:02 +0800</pubDate>
    </item>
    <item>
      <title>机器之心 x MIT-CHIEF | Sunus Health 开发智能输液监控平台，Sunny Crown个性化AI因材施教</title>
      <link>http://www.iwgc.cn/link/2638727</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心原创&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Mandy&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;编辑：Rita Chen&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;麻省理工学院中国创新与创业论坛（简称 MIT-CHIEF) 是美东地区最大的创新创业平台，汇集了美国最尖端的人才和项目，融合了中国和美国的各项优势资源。在刚刚过去的七月里，十六支涵盖医疗健康，新能源，教育及金融等领域的创业团队和 MIT-CHIEF 一起，走访了北京，上海，深圳和成都四大城市和与其相关的创业合作基地，与当地的政府，企事业单位代表进行了卓有成效的合作与交流。机器之心有幸采访到了其中的十一支团队，在接下来的一个月里，我们将作为专题采访的形式呈现给大家。&lt;/span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Sunus Health 和 Sunny Crown 是此次中国行活动中分别在医疗和教育领域有独特创新的团队。机器之心有幸在这里采访到了 Sunus Health 的创始人和 CEO 孙瑞 和 Sunny Crown 公司的创始人的王冠。&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Sunus Health 开发的智能输液管理系统是以智能输液监控硬件为核心的网络输液监控平台。该系统能有安全有效地降低输液风险、提升医院管理效率、降低医疗陪护痛苦度，同时记录输液流程，有效追溯历史数据来保证责任明确，同时可以与医院现有网络体系兼容，从而为未来病例信息化做终端数据来源服务。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicKq75cdUs4R02hSKFqcUUFiblNrcVicpW9qDBrZTTYGtK3mXVicAQ5dDQn8bF22AicCOiar0M9w4E4Oxg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Sunny Crown 是一家专注于人工智能的公司。其产品 PI TUTOR 是一款基于人工智能与人机交互技术的个性化智慧教育系统。基于深度学习等核心技术，PI TUTOR 能迅速理解用户学习过程中的行为，为用户提供个性化体验，开创性地实现「因材施教」。该系统支持动态书写识别，用户可以在允许范围内输入任意题目，系统支持全部合理的解法。在解题的过程中，系统会精确找出用户每一步所犯的错误和不足，给出针对性建议。在用户需要帮助时，系统会依据用户特点推荐最佳的辅导方法，从而让用户按最有效的方式进步。该系统将学生、教师、家长纳入多位一体平台，教师和家长可以实时了解每一位学生的准确情况，知道学生哪里不足，用最短的时间针对性地进行辅导。通过系统发布作业，系统会为每个学生量身推荐最适合的题目。当学生需要帮助时，教师可以第一时间发挥指导作用。学生可以将更多的精力集中在短板和效率最高的内容上，事半功倍。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicKq75cdUs4R02hSKFqcUUFySM4bfN7QNQQJs1ZicPPK0ibgIh3GLJVEtqBnu20m0PXZrGPU9AlLN8A/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;hr style="line-height: 28.4444px; white-space: normal;"&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibx10fYjKxeuYboDW2ic5N9YqWOyicLibUXbh6tEOXDQJAlxEDnycu5HiaRMYAzZYqWworntzZlI2vbWQ/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Synced：很高兴能认识两位。请你们两位分别介绍一下你们自己以及团队。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;孙瑞：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;大家好，我是孙瑞，Sunus Health 团队的创始人兼 CEO。我首先解释一下 Sunus Health 这个名字是怎么来的。除了我个人姓孙之外，主要是取之于太阳（sun）和我们（us）的两个单词。因为我们主要做得是跟医疗，健康，取其与阳光相关之意。我们第一款产品叫 IntelliMonitor 智能输液管理系统。致力于解决目前国内普遍存在的医患纠纷比较严重的问题，以及输液安全风险很高的问题，从这两个东西入手，为医院打造物联网的数据接口平台。以智能硬件为基础，接入到医院现有的网络平台中，为它提供未来的数据模块，通过分析和控制病人的输液情况，来为病人提供更好的输液体验，为护士减少工作量提升效率，对医生反馈病人的数据，对这次以及下次的诊断做出更好的判断。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWicKq75cdUs4R02hSKFqcUUFDTrGq6kibrKpRlaM8A8HkLrKOKZfLbKZPibOlhmibb2NKQCmPKF3U8m4w/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;王冠：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;大家好，我是 Sunny Crown 的王冠。Sunny Crown 基于机器学习和 HCI 人机交互这两个核心技术，在不同场景寻找应用方向。这次参加中国行，主要推广的是一个教育方面的项目，叫做 Personalized Intelligent Tutor，(PI TUTOR) 个性化智能教育。我们把增强学习（Reinforment Learning）和深度学习（Deep Learning）应用在教育场景，实现因材施教的效果。传统的教育方式，无论是欧洲，美国，还是中国, 受限于有限的教育资源，教师没办法对每个学生充分了解，其精力和时间都不允许他为每个学生指定最合适的教学方案。我们用 AI 取代人来完成了解学生的过程，针对性地为每个孩子提供最适合他的方案，充分了解、量身定做，学生学习的内容、速度、作业、评价方式都因人而异。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Synced:最初是一个什么契机开始要做这个产品？&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;孙瑞：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;首先我们的想法是来自于美国的一个需求。因为我上学的最后一年在美国波士顿医疗中心（Boston Medical Center）实习，在里面观摩手术，其中一个就是心脑血管造影术，也就是现在国内非常多人做心脏支架的手术方式。在观摩手术的过程中我们发现，在美国这类输液是没有进行监控的，监控空白容易导致脑空气栓塞及脑血栓，还有一些其他副作用产生，甚至导致术后死亡。这个问题很严重的。当时医院就希望我们去解决这个问题。我们回头调查国内，想看看国内医院有没有类似的问题，但发现国内的医院很复杂的一种架构。我们直接去调查相关做手术的医生是问不到任何消息的。首先，他们封闭自己的信息，其次，美国一次用四个输液作为安全防护，国内一次只用一个或者两个，这就是问题。我们无法直接深入到系统内部。同时我们调查其他的输液场景，发现国内近期出现输液问题特别多，而且护士对我们反馈的就是他们工作压力很大，目前医患矛盾严重，导致生命有潜在安全问题，他们希望有设备能够降低他们的劳动力，同时提升对病人来说更安全的体验，通过这个我们想到做这么一套方案去解决这个问题。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWicKq75cdUs4R02hSKFqcUUFibYlNRxw2ibs1c9QkJeeLPjUdVpZ0Y4okl89w5jYJlx7ucWqVJFiaibSicA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Sunny Crown 的 PI TUTOR 发展背景&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;王冠：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我们团队的核心成员 2010 年的时候就认识。那个时候我们希望用自己的在机器学习方面的知识做一些有意义的事情，所以大家做了很多尝试，我们发现教育领域存在潜在的巨大需求。我们这一代基本是独生子女，爸妈非常舍得在教育上花钱，但很多都花的是冤枉钱。十年前的家教费用每小时就可以达到 100 人民币以上，这个对很多家庭来说是非常夸张的。很多辅导教育的东西其实可以用 AI 来解决。去年年底，Facebook 的创始人 Zuckerberg 写了一封「致女儿书」，里面很大篇幅强调了个性化教育的问题，就是面向每个人的个性化学习工具，在当时技术上是没有解决方案的。我们看到了以后很激动，写了封信给他，但是还没收到回复（笑）。美国的教育与亚洲的传统文化不同，强调个性，而不是把每个人都训练成螺丝钉。中国的当代教育体系强调社会应用，而不注重人的个性的张扬。有一种被普遍接受的教育理论，「兴趣就是天赋」。举个例子，如果你对绘画有兴趣，那你学绘画就会比别人更有耐心，愿意花更多时间。如果我对数学有兴趣，那我可能更适合做这些辛苦的东西。我们希望可以充分了解每个孩子的特性，因材施教，让他把有限的精力放在最可能有效果的那个领域上。另外在中国，如果一个家庭解决了孩子的教育问题，那么家庭的很多其他问题也迎刃而解，比如买房，所以我们觉得这是一个有意义的事情。我们回国路演收到最多的反馈，就是即使别人不明白我们的技术，但觉得我们从事的是一件正确的事情，是应该发生的事情。我们坚信，哪怕它可能比较难，还是希望把有意义的事情做下去。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Synced：是的，不管是医疗还是教育都是和每个人息息相关的，每一点不同或者努力也许都能影响到未来的生活方式。但推动进步和改变需要好的产品。好的产品在磨合出来的过程肯定有各种困难。就现阶段而言，不论产品是成熟了也好，还是在初期优化，你觉得你团队最大的困难和障碍是什么？&lt;/span&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;孙瑞：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我想从三个点说吧。&lt;strong&gt;第一个就是人的问题，&lt;/strong&gt;创业团队都存在人之间磨合以及合作的关系。从我创业到现在起，核心团队（早期除了我之外也没什么核心团队），周围人一直在换。首先创业是件很难的事情，坚持下来也很难。其次医疗领域本身就是个非常复杂难进的领域，作为一个创业团队想做医疗很难，很多人在跟我合作的过程中不断发现难的问题他们就撤了。现在经过了将近三四十人不断的筛选后，留下来的六七个人算是我们最终的核心。&lt;strong&gt;第二个比较难的是和国内医院打交道的问题&lt;/strong&gt;，其中一点就是说国内的医疗销售（美国也有类似的，但国内更多），全部依赖于中间商的销售（就是医疗销售代表）。因为他们自己跑出来的医院，认识的医生跟他们之间有很好的销售关系，第三方是没法直接交流的。一旦医院采购部门换了人，或者院长不满意这个项目或者产品，整个销售渠道就断掉了。所以跟医疗销售商打交道也是非常头疼的问题，这块很难打通这个供应链。&lt;strong&gt;第三个就是医院本身架构的问题。&lt;/strong&gt;就算是接触到了医院，他们到底愿不愿意买你这个产品？如果你的想法太新，或者利润太低，他们可能就不要了。这个医疗系统下每家医院都是独立的个体，打通一个医院不代表能够打通第二家。不过目前能看到国内很多政策在改进这一块，包括分级诊疗，把医院的职能往下推。还有一些正在建设的网络采购平台，医院可以直接在网络上采购，这样你只要通过一条渠道就可以铺盖到医院的各个方面。这些是我们目前发现的困难点，我们在一个个尝试去攻克他。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;王冠：我们跟孙瑞讲的能够找到共鸣。&lt;strong&gt;第一是人才的问题&lt;/strong&gt;，对我们来说，真正意义上懂深度学习（Deep Learning)的人很稀有，这个圈子非常小，以至于说一有风吹草动大家都会知道有发生什么事。很多大公司不惜重金去挖人才，最吸引人才的并不是薪酬，而是这些企业的计算能力、数据和应用场景。作为初创公司，虽然规模小，在这一方面我们也有自己的优势，核心人员磨合很多年，彼此熟悉，同时每个人在科研或工业界发展都还不错，有一定声誉，而且我们的数据是独有的。但是在招人的时候就面临这样的问题：请动优秀的人很难。一般来说他们的风险成本更高，因为会面临更好的待遇的诱惑，流动性也更大。第二是&lt;strong&gt;我们觉得创业是不具有可复制性的&lt;/strong&gt;，有些产品即使在技术上看非常相似，但商业模式和推广渠道会相差甚远。很多东西我们是摸着石头过河，非常的谨慎。我们希望通过MIT-CHIEF中国行和机器之心招募优秀的人才。如果有懂机器学习，尤其是增强学习和深度学习，或者有计算机或编程经验的，我们非常欢迎您的加入。在我们的心中，人才永远是第一位的。&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Synced：正好你谈到了中国行，那么我们就聊聊 MIT-CHIEF 中国行的这次活动。这次中国行你们两位都亲身去感受了。能分享下最大的收获吗？和你们的预期有什么不同么？&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;孙瑞: &lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我觉得这次 MIT-CHIEF 办得中国行特别棒。整个活动安排得很顺畅，中间没有出现什么问题，组织方组织地特别好。其次，我们走得这几个地方，能明显能看出各个地方政府支持方向是不一样的。像上海就比较支持健康产业，智能化软件、算法。我就拿上海做个举例吧，能感觉到政府和创业团队交流是很顺畅的，几乎没有阻碍，不像以前死板的印象。而且政策推广得特别好。通过这些活动我们认识了很多政府和民间的一些资本，前前后后见了几十家的资本机构，跟他们进行详聊，聊完之后后期跟进，而且 MIT Chief 还不断给我们比赛报名的信息，让我们去参加。这几天认识了同样的小伙伴，我们都是在一条路上的，彼此间的想法也有很多交流沟通的机会。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;王冠：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;首先要感谢 MIT-CHIEF，同时感谢孙瑞。我们最开始对参加创业类的比赛或活动并没有很浓的兴趣，孙瑞强烈推荐 CHIEF，于是我们就参加了。参加之后大开眼界，原来这个事情比想象中要好得很多。我们觉得 MIT-CHIEF 做得非常有水平，很少几个人就可以把活动做到这样的规模、高度和影响，除了 MIT 本身的影响力，更重要的是团队成员的高素质与努力。这次中国行，我们见识了很多，从投资机构、到资源提供方、到潜在商业伙伴，到政府各方面，都学到很多，了解了市场各方面的信息，这非常有价值。我们也深刻感受到了国内经济面临的巨大压力，很多企业面临各种问题，在积极求变。最后一点，像孙瑞刚才提到的，不同的人、机构和地区的风格不一样。我们有很愉快的合作经历，也有些值得反思的教训，都给我们上了非常宝贵的一课。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Synced：对你们二位而言，在这次参观拜访的四个城市中，哪一个城市印象最深刻？&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;孙瑞：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;除了上海之外（因为上海本身就非常发达），我觉得，成都是一个非常亮眼的城市。首先这次成都办了一个双创会，规模很大，整体对创业者的支持力度非常高。成都的郊区在大力的进行改造，建了很多像 CBD 这样的金融区或者是创业园，能看出来成都在这方面下了很大的力度。而且成都是中国一带一路的中西部地区的起点，所以我们能看出来成都政府对这方面很重视。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;王冠：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我对成都的好吃的印象比较深，细节就不必多说了。既然孙瑞谈到成都，我讲讲另外一个城市：深圳。深圳给我的感觉是人比较注重效率，比较务实，没有那么多客套或繁文缛节。人和企业思想开放，对新知识和文化的包容性很强，也比较有共享的精神，很多时候帮助他人会很直接。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Synced：二位在国外这边学习，团队也有跟美国这边的公司、教授交流。结合这次中国行的经历，你们认为国内外的创业氛围有没有什么差异？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;孙瑞: &lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我觉得差异还是比较大的，因为我也参加过很多美国这边的创业比赛。美国人办得比赛整个流程都是非常完善的，前期后期中期都有。举个例子，Mass Challenge 这种大赛，他们的整个孵化系统，运作模式、盈利模式都非常完善。选手只要去报名，就算没有选上也会帮你去推这些东西。而且美国的中小学，包括认识的一些美国的朋友，他们在初中高中就参加过各种创业比赛。我认识的一个马上就要来 MIT 读大一的小姑娘，她就是在高中做了两个校园安全以及个人安全方面 App，获了大奖。他们通过这种创业比赛慢慢培养氛围，再在每年的期末项目上做个升华，所以他们的过渡很顺畅，不会存在忽然创业爆棚这样的现象。国内中小学缺乏创造力的模式，通常都是考试测验。我在国内读本科，我那些学工科的同学做毕业论文，都不是做实物，它让你做仿真，这跟美国要你搭手去创造一个东西还是有差距的。不过现在国内的特点是有政策力量在推广，好处是说能留下来这样的创业渠道，创业媒体和创业资本，可以为我们后一辈人提供更好的平台。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;王冠：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我认为中美两国现今工业发展的阶段是不一样的。在全球经济不景气的情况下美国的表现相对更好，是因为它有创新的传统和成熟的体系。在美国创业，不用考虑太多商业化的细节，只要在想法上、技术上、或模式上有突破，实现「0 到 1」，就会相对容易找到成熟的资源来帮助你把这件事变成现实。美国的创业更关注本质，是 0 到 1，而不仅是 6 到 9。中国的创业更明显表现为受政策和资本驱动。在中国想要创业不但要有核心的技术，还要设计好如何商业化，形成完整的流程，才更容易获得资源。两国的投资环境也有明显区别。第一点，美国的投资工具和渠道更多、更成熟；第二点，中国的投资机会更多，很多项目对核心技术竞争力要求更宽容。很多从 0 到 1 的技术突破性事件都发生在美国，而中国更擅长学习国外的先进技术和模式，学以致用、后来居上。此外有一点，咱们中国比其他国家好特别多的，是政策扶持，尤其是深圳、成都这些受国家战略影响的地区。企业、政府的思维非常先进，思想很开放，对创业者和团队的支持很强力。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWicKq75cdUs4R02hSKFqcUUFBWU12ibDecwTeOhfOeA8micTFVYgTicQstUnLkt6uPt3dOQHSibfjjN6tQ/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;em style="color: rgb(136, 136, 136); font-size: 12px; line-height: 1.75em;"&gt;&lt;span&gt;Sunus Health 的 IntelliMonitor 智能输液管理系统&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Synced：接下来我们想要单独采访两个团队，更深入地了解下你们的核心技术，你们能不能从技术的角度给我们普及一下产品本身不同的地方或特点。从智能输液开始，你说智能输液管理系统，它是什么怎么运作的？&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;孙瑞：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我先介绍一下系统组成吧。我们最开始做得是智能硬件，主要是输液监控，美国这边的输液室一定会有一个输液泵，它的核心作用只有一个，就是控制输液时间。护士只需要一到两个步骤设置完，人就可以离开了。美国很不了解中国市场，当我跟他们讲中国市场没有用到输液泵这个产品的时候，他们表示很惊讶：「什么，居然没有用输液泵？那他们怎么输液？」这是他们提出的问题，所以我们要通过自己研发制作一个适合中国市场的产品，我们不可能再做一个输液泵，因为这个东西又大又笨重，而且相较于其他产品并不便宜。&lt;strong&gt;我们就想设计的是全无线的，一个小的智能输液盒子完善所有输液泵的功能&lt;/strong&gt;。输液泵是利用重力原理的主动输液，我们不可能把它一下替换成被动输液。所以我们通过调控重力输液的输液速度，检测气泡从而实现安全。最后结合一些现在常见的无线传输和智能处理模块，和医院的互联网相接。这一点和美国这边的医院也很不一样。美国一进医院里就只能用 beeper（哔哔机），因为没有信号手机是无法使用的。但是，在国内刚好相反，现在的大型医院都有自己的铺网系统，一般是铺三层。第一个层是医院内部的加密网，第二个是设备之间内部用的互联网，第三个就是公用网。这个就大大减少了我们产品接触医院的成本。&lt;strong&gt;在减少成本后，我们在软件层面再给医生，护士，和病人提供不一样的服务层面。&lt;/strong&gt;其中给医生提供的是病例，信息收集，他能看到病人从输液完成到下一次的数据。护士是可以通过平板电脑看到每个病人的流程表，直接按时间顺序排序一个个去就可以了。在紧急情况下，病人还可以通过设备进行报警，护士就可以提前看到哪个病人出现了什么问题，立即做出合理的判断。&lt;strong&gt;当所有医院智能化之后，智能化病例就自然而然出现了。&lt;/strong&gt;病例收集的并不是手写的或者医生开的一些文字，而是个人的数据库，它收集所有过程中的数据，作为一个数据库，储存在你的个人 ID 下面，这才是电子病例发展模式。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWicKq75cdUs4R02hSKFqcUUF7vFFjEekfC4xjbXh0MBvqZgN0exfNv2Y0ExIkF60C7tp1ia6v1hBEsg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;IntelliMonitor 智能输液管理系统铺网结构图&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Synced：你刚才说到数据的手机，那你公司有没有辅助的副产品？对于数据的私密性和安全性这一块你怎么看？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;孙瑞：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;有几个不同的层面。第一个是从硬件层面本身。硬件层面，有人问我最多的是，如果有人侵入到你的设备中，随便控制它怎么办？是这样的，气泡和流速控制这些是我们自己研发的，你入不入侵都无所谓，因为你接触到的只是数据而已。它关键是流速控制的模块。这块我们在设计时就限定了最高刘流速。所以我们会设定一个上限，不管你怎么入侵顶多是拿走了数据，这个对病人安全是没有什么问题的。在医院层面，我们并不是自己去处理这个数据，医院会使用自己的云提供商例如阿里云等等，可以利用他们的服务器在云端为医院提供服务，也可以是（如果不愿意放到云上）做一个本地的服务器供医院内部使用。我们可以帮他们把收集上来的数据进行数据化，进行标准化。这样就避免了我们对数据的敏感度或者安全的风险问题。当未来的情况下，你看美国的医院有自己的数据库，也有开放的数据库，都有病人的信息。如果他们都能做，那国内的安全问题应该也不是问题。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Synced：好的，谢谢。那再问一下 Sunny Crown 这边，你之前有谈到 Deep Learning 的一些东西。它到底是如何实现因材施教的？它是针对个人的还是用大家集成的数据对个人进行分析？&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;王冠：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;简单来说，我们把每个用户使用产品全部的行为都考虑了进来，包括思考时间，笔触变化，甚至眼球动态识别。在最开始的时候任何用户都没有数据，而且市场上也找不到个人数据。这些数据对别人而言，第一没有办法获取，第二获取了也没有意义。我们的核心算法是自主设计，具有学习的能力，而且学习能力会不断增强。&lt;strong&gt;用户用得越多我们就越了解他，比如说通过不同学生的行为，来判断他的行为习惯如何、智商如何、性格如何&lt;/strong&gt;；哪一种方式最能帮到他？这个孩子是否存在偏科的情况？如果这个孩子使用足够久，我们就能全面地了解他的情况。举一个例子，在学生学习过程中，假设三个人犯了同一个错误：一加一等于二，但他们都写等于三，这时我们的系统可能会给出三个不同的反馈，因为每个人犯同样错误的原因很可能是不同的。另外一点，即使孩子没有做错，但思考时间过长，比如两个人在考同一张试卷，一个人一分钟就写完了，另一个人想了一个小时也写完了，两人都满分。但是这里面蕴藏了截然不同的信息。前面的人对知识的掌握可能非常熟练，后面的人可能就非常吃力。如果从传统教学方式看，因为都是满分，很可能会忽略其中的问题。但实际情况中，遇到真正的重大考试或者是关键时刻，后面的孩子很可能会出问题。我们把传统教育无法获取的东西，通过人工智能训练到系统里，现在不敢说考虑周全，但我们相信通过算法的不断优化可以逐步实现。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibx10fYjKxeuYboDW2ic5N9Yaehxc2AaR6Iibov7tgKwfiaj9FtTDxTDQyusJgAYmY4OqPiazLicdW91Fw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;em style="color: rgb(136, 136, 136); font-size: 12px; line-height: 1.75em; text-align: justify;"&gt;&lt;span&gt;Sunny Crown 的 PI TUTOR 功能介绍&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Synced：这个产品主要是针对幼龄儿童么？还是用户学任何东西都可以用到这个？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;王冠：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;大部分的教育内容都可以实现，从学龄到大学的高等数学，成人职业教育也可以，比如精算，保险业等等。只要学科内容可逻辑化，我们的算法就能实现。目前我们展现的第二代产品只有数学功能，第三代产品会支持物理，化学，GRE，GMAT，SAT，不断迭代覆盖新的内容。&lt;strong&gt;我们认为，人类的知识有强逻辑、强系统性，可以追根溯源，可以学习。&lt;/strong&gt;比如我们看量子力学，可以从最基础的 1+1=2 找到其完整的发展轨迹，这是一个可以学习的过程，我们的产品也通过学习而获得提升。我们在美国做测试的时候有个印度的小朋友，使用了一种我们无法理解的解题方式，但是解题正确而且很快。虽然我们无法理解，但是我们的算法能够识别并学习。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWicKq75cdUs4R02hSKFqcUUFq6C6hazeThuTPvZwaSicQaU7y89gNkjEHN9X2woyv6TQ2oZicxyQQJibw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Sunny Crown 的 PI TUTOR 理念和愿景&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Synced：任何一个产品都需要去试点，你找学校也好，医院也罢，都需要真正接触到受众才知道切实的反馈。那么，在开发和试验的过程中，你们是怎么找寻试点对象的呢？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;孙瑞：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我们走访了很多医院，认识了很多医生，医生里面所有对产品有意向的人，都愿意帮我们试验产品的功能，虽然没有签具体合同。另外，我们发现很多医院都有类似于科研与实业的项目，&lt;strong&gt;即科研项目实业化&lt;/strong&gt;。我们联系了国内的几家医院医生朋友，包括肿瘤医院，他们对于智能输液这个项目很感兴趣，也很愿意配合我们做第一批试点的对象。有了医院就有了第一批的数据，有了数据才可以申请 CFDA 的认证。所以前期和医院的沟通时至关重要的。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;王冠：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;在美国我们现在有四所试点学校，一共约 500 个学生使用过我们的产品，效果还是比较好的。针对某阶段的知识，准备具有对照性的多组试卷给孩子们做，将未使用过产品的对照组和我们的实验组进行对比。接下来，让没有用过产品的对照组也使用产品进行一段时间的学习，再进行测试，看他们自己的成绩有没有发生变化。对于学生来说，由于每次错了都会知道原因，以及下次的注意事项，所以当遇到类似的问题时就会提高警惕和注意力——而注意力是和成绩正相关的。我们曾收到过非常积极的反馈，有家长写了金额很高的支票给我们表示感谢，希望我们可以把产品继续研发下去。因为是我们和学校合作的科研项目所以不能收费，我们很感动，也坚定了信心。现在在国内正在做实验，还没有数据可以公布。&lt;strong&gt;我们在深圳，上海，成都，大连四个城市签了几百所学校，等中文版成熟后就会在每个城市进行试点。&lt;/strong&gt;这也是我们这次回国最大的收获之一，找到了非常多很好的合作渠道商。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Synced：我这边最后一个问题，谈到产品和服务。后期的服务，一代、二代、三代的更新是很重要的。你们自己是不是对这方面已经有一些想法，是不是在和护士或学校沟通的过程中，他们有一些新的期望，但你们之前没有想到，你能不能分享下？&lt;/span&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;孙瑞：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我先讲一下期望差。一代产品解决了最简单的需求，在我们和医生示范产品功能的时候，他们提出了一些新的需求，比如他们想在监控的同时了解病人的生理体征。针对这一点，我们可以采购一些设备来辅助监控任务。我们第二代产品可能做一个基于机器学习应用的体征监控设备，但当一个智能型产品进入医院，就会存在如何和原有设备更迭的问题。这就是很多数码产品和网络产品进医院碰壁的原因。我们提出的方案是给医院做外包服务，我们并不卖设备，而是提供服务。我们正在提供这个使用细节，一旦帮医院解决了输液管理的问题，这里面硬件我们提供，软件也是我们提供，那未来要更新换代我们直接在上面换就可以了。这有点像目前 Adobe 还有一些网络公司开始收年费而不是收硬件软件单独费用的模式。我觉得这是一个医院一体化方案的开始。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;王冠：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我们从学校得到了很多积极的反馈。有的学校希望我们提供硬件，但目前我们对硬件的态度比较谨慎。这次回国通过跟很多相关机构谈，收货几个非常好的建议。第一个是除了和学校直接合作之外，向国内已经有大量用户的教育产品提供技术支持。这方面我们已经有了一些接触，对方表示了非常强的兴趣。这样我们可以直接获得数据，而且能以极低的成本获得亿级的用户。第二个是，有的学校希望在实时反馈的基础上在更进一步，给孩子生成最适合他做的作业和考试题目。如果能实现的话，老师会非常欢迎，因为老师没有办法针对每个孩子设计作业，但是我们可以。另外一点是老师批改作业的时候只需要关注孩子需要帮助的部分，而不是简单地评判对错。这个功能目前我们已经基本实现，还可对每个学生的考试成绩进行预估，在中考高考的估分等环节可以发挥很大作用。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWicKq75cdUs4R02hSKFqcUUFVf7RibtQoficfcRUdRxwgtbEIarWbfPB33qHCZBqUgpVvib7g7Q5RgibDg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Synced Talk 对话 Sunus Health 团队的创始人孙瑞（左）和 Sunny Crown 公司的创始人的王冠（右）&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Synced：非常感谢，采访最后是我们 Synced Talk 的固定快问快答环节。每一期我们都有固定的主题，这一期我们的主题是大数据。问题是这样，在当今的社会中，你会觉得 big data 在哪个领域（可以是交通，信息传播，营销或者是更多）在哪个领域有最大的助力？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;孙瑞：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我相对比较了解医疗行业和健康产业，我觉得这里面有巨大的潜力。医疗数据最有助力的地方就是人的基因数据，因为基因和每个个体的疾病预测密切相关。现在缺乏的不是基因的数据，而是基因表型的数据，就是每个人基因对应的所有——其实这里是最难的。医院测的那些血脂血压都是最简单的数据。真正的应该是细胞的分布，细胞特点，分泌的蛋白组份等等。如果在未来可以把这些数据收集归纳，我们就能很好地预测所有疾病。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;王冠：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;数据对几乎所有行业都有巨大支持，这是没有悬念的。人工智能有三件事做得特别好，第一件事是识别，第二件事是决策，第三件事是预测。识别的话，我举个例子，Tesla 的自动驾驶，识别周围环境信息，用户开过一遍的地方就可以建立 3D 场景。第二个是决策，我看到了路灯，这时候能判断红灯停绿灯行。第三个是预测，我可以看到哪里拥堵哪里路况不好。如果要说助力最大，目前来说，我认为是气象，交通，地质，医疗，金融这些领域。在并不遥远的未来，个性化人工智能将成为潮流，具有学习能力、可交互的人工智能产品将有能力诠释「智能」的真正含义。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Synced : 谢谢！也希望你们在中国的推广和落地一切顺利！&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWicKq75cdUs4R02hSKFqcUUF7yW6gjWLvN3JQT1XLNzdHfbr1fevA0PueclACk22uLIzTYgzibyia8Iw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibx10fYjKxeuYboDW2ic5N9YLRLfBWgRpz8D3UVicpPeXhmEejcotPDOJ7R1Q85iadAEXvaRZprQCVMA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;===========================================&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;麻省理工学院中国创新与创业论坛 (MIT-CHIEF)2016 Community 继续招募优质创业团队入驻！「2106 MIT-CHIEF Conetst 暨商业企划书大赛」正式向团队开放，详情请登录 &lt;span&gt;www.mitchief.org&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心原创，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Sat, 10 Sep 2016 16:20:02 +0800</pubDate>
    </item>
    <item>
      <title>前沿 | 全球首例，牛津大学使用机器人进行眼内手术</title>
      <link>http://www.iwgc.cn/link/2638728</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自BBC&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Fergus Walsh&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;外科医生首次使用机器人在眼内做手术，帮助病人恢复视力。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibx10fYjKxeuYboDW2ic5N9YicYtymMKvMl051klW6l0t6Bxiauichn1XicR46Gib4We9B6fTulc3bibNoDw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Preceyes 机器人有一根可深入眼中的细针，使用图中左边的操纵杆进行控制。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;牛津约翰瑞德克里夫医院的一个团队使用 Preceyes 机器人，通过操纵杆进行控制，移除眼中大约百分之一毫米的薄膜。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;牛津的一位助理牧师，也就是病人 Bill Beaver 说这如同「神话一样。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;外科医生希望它能为比目前手动操纵的更复杂的眼科手术铺平道路。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;我能看见&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;病人 Beaver 说，「这如同神话一样，但却是真实的。我非常幸运能成为第一个尝试的人。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibx10fYjKxeuYboDW2ic5N9YkD9ibVqT7DSS259SestHj7LZGE7dkmEeKbQdTmxTbV5eoX8SrSHFbQQ/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt; 机器人协助外科手术很常见，但目前为止还从未应用到眼内手术中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;来自牛津大学的教授 Robert MacLaren（手术带头人）告诉我，「在眼睛内部进行手术需要极大的精确度，其中的挑战是让机器人系统穿过眼睛内壁的小孔进行手术，在四处移动的时候不能对眼睛造成损害。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「大部分机器人都很大，做大型工程，然而这个机器人很小，所有东西都缩小。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Preceyes 外科机器人由荷兰的已经公司开发，这家公司由埃因霍分大学衍生。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;外科医生使用一个操纵杆和触摸屏指引探针进入眼睛，同时通过一个显微镜监控进展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;像机械手移动的机器人有 7 个发动机，能够避免医生手颤等问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;操纵杆上大幅度的移动引发机器人的小移动，如果医生松开操纵杆，机器人的任何行为都会固定住。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;病人&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Rev Beaver 直到去年一直在担任皇家装备骑兵团的牧师。7 月份时，他的眼科医生发现他右眼后面张出了一层膜。产生的压力在他的视网膜上造成了一个孔，破坏了他的中央视觉。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在手术前他说，「当我看书时，我所能看到的都在中心，我这只眼的视野都被限制在外围。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 8 月底，医生对他实施了这场先进的外科手术。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;MacLaren 说，「一般情况下，我们做这种手术时会碰触到视网膜，也会出血。但使用机器人能完全清除里面的膜。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;手术结果是修复了 Beaver 的右眼中央视觉。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;眼中的气泡意味着他目前有些近视，但接下来几个月会恢复到正常距离水平。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Beaver 说，「视觉退化的非常吓人，我害怕我会永远的失去视力，所以这种轻松的治疗方式真是上帝所赐。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 NIHR 牛津生物医学研究中心的支持下，12 个病人也将使用该机器人进行手术。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;另一水平&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该试验试作为理论的支持，是为了表明机器人能够做眼科医生所做的手术，而且有着更高的准确性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibx10fYjKxeuYboDW2ic5N9YD6KMvJDlKLAS0T1ibxHuPqIS3LrzCsib6iaSv1GxPB9oYicndHTlNozX3Q/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但最终的目标是将机器人做外科手术带到另一水平。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;MacLaren 教授说，「我内心好不怀疑我们见证了未来眼科手术的一角。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我们无疑能改进目前的手术，但我希望机器人能使我们做新型的、更复杂的、更精致的手术，这些手术用人手是难以完成的。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;牛津是世界上几个实验视网膜基因治疗的研究中心中的一个，这是一种防治眼盲的新型治疗方式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前这种手术都是人来完成，而未来的治疗手段中涉及到干细胞植入，需要将细胞缓慢的注入眼中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器人要使得医生能在 10 分钟左右将细胞注入，这对手动操作来说几乎不可能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Preceyes 机器人的出现，让我们看到了未来手术机器人的前景。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心经授权编译，机器之心系今日头条签约作者，本文首发于头条号，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Sat, 10 Sep 2016 16:20:02 +0800</pubDate>
    </item>
    <item>
      <title>一周论文| 深度强化学习、文本生成、arXiv优质论文</title>
      <link>http://www.iwgc.cn/link/2638729</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;转自Paper Weekly&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Paper Weekly&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;第一部分：&lt;span&gt;基于强化学习的文本生成技术&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;引&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;2013年以来Deep mind团队相继在NIPS和Natures上发表了用深度增强（强化）学习玩Atari游戏，并取得良好的效果，随后Alpha go与李世乭的一战更使得深度增强学习家喻户晓。在游戏上取得了不错的成果后，深度增强学习也逐渐被引入NLP领域。本期介绍目前NLP领域较为热点的研究方向，基于强化学习的文本生成技术（NLG），共选择了三篇文章，分别为：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;(1)《Generating Text with Deep Reinforcement Learning》&lt;br/&gt;应用Deep Q-Network作为生成模型用于改善seq2seq模型&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;(2) 《Deep Reinforcement Learning for Dialogue Generation》&lt;br/&gt;应用强化学习进行开放领域的文本生成任务，并对比了有监督的seq2seq加attention模型和基于最大互信息的模型&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;(3)《Hierarchical Reinforcement Learning for Adaptive Text Generation_lshowway》&lt;br/&gt;以任务为导向的户内导航对话系统用分层强化学习进行文本生成&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;Generating Text with Deep Reinforcement Learning&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;1&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 28.4444px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;作者&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/h2&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;Hongyu Guo&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 28.4444px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="单位" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;单位&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/h2&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;National Research Council Canada&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 28.4444px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="关键词" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;关键词&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/h2&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;Reinforcement Learning、Seq2Seq、Text Generation&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 28.4444px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="来源" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;来源&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/h2&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;NIPS2015 Workshop (2015.10.30)&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 28.4444px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="问题" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;问题&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/h2&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;本文提出将Deep Q-Network作为生成模型用于改善seq2seq模型，将decoding修改为迭代式的过程，实验表明本模型具有更好的泛化性。&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;模型&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对seq2seq模型改进的论文层出不穷，本文率先引入深度强化学习的思想，将DQN用于文本生成。对DQN还不了解的同学可以先阅读DeepMind的论文Playing Atari with Deep Reinforcement Learning。本文的模型如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgkSMlEJFo90NY8rCXr3mJMBibCfNcziaUmMiavQg4G8QIuPib1qda0iaras6SWIKTpeZrtW85Ap62ALIjg/640?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如同一般的神经网络，我们也可以把DQN当做一个黑盒来使用。只需要准备好DQN需要的四个元素s(i),a(i),r(i),s(i+1)，分别代表i时刻下state,action,reword和i+1时刻的state。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对照上图我们把算法解剖分为4个步骤：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Step 1&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;: 先是传统的seq2seq模型。通过LSTM先把输入序列encode为一个定长向量EnSen(i)，然后作为decode阶段的初始状态依次生成新的序列DeSen(i)（decoding search使用beam search算法来 expand next words）。经过第一步我们得到初始state：(EnSen(i), DeSen(i))和action集合：每个位置的hypotheses。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Step 2&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;: 接下来从hypotheses（actions）中选择一个可以获得最大reward的单词（action）作为该位置新生成的词，用新单词来代替之前的旧词，于是生成新的state：(EnSen(i), DeSen(i+1))。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Step 3&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;: 接着就是标准的DQN的部分，计算Loss函数并对其应用梯度下降。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Step 4&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;: 回到Step 2，对得到的state继续迭代，每一次迭代都只生成一个新词来代替旧词，直到迭代次数达到设好的值（作者将次数定为句子长度的两倍，同学们可以思考一下理由）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;总结DQN所需的四个元素对应如下：&lt;br/&gt;(1) i时刻下的state：(EnSen(i), DeSen(i))；&lt;br/&gt;(2) i时刻下的action：beam search得到的每个位置的hypotheses；&lt;br/&gt;(3) i时刻下的reword：target sentence和DeSen(i+1)的相似度（BLEU score）；&lt;br/&gt;(4) i+1时刻下的state：(EnSen(i), DeSen(i+1))；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了更好的提取句子的特征，作者在decode阶段使用了双向LSTM。同时还在reinforcement learning中加入attention机制，可以达到先decode比较简单的部分再处理困难部分的效果。最后在生成相似句子的实验中得到了比只用LSTM decoder效果更好的结论：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgkSMlEJFo90NY8rCXr3mJMBxsz5icyMMZgyP2MVNrFKVv1Sg7ksAIKmTSiaBtpkmicNGBkiaEBuiaTjUTA/640?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 28.4444px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;strong&gt;&lt;span&gt;相关工作&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgkSMlEJFo90NY8rCXr3mJMB1Cl7vOaVhiaxTagibbqF7U5ice9wy85QV1yibEGrdj7f6O2yOeaa1yQeEQ/640?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 28.4444px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;strong&gt;&lt;span&gt;简评&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;本文的思想其实非常符合写作的一种情况，就像贾岛推敲的故事，回想小时候刚学习写句子时，也不能一次写好，总会不断对一些词语进行修改。Google DeepMind的文章《DRAW：A Recurrent Neural Network For Image》也和本文异曲同工：画画也不是一次画好，也要不断的完善。不同之处在于本文率先引入DQN做文本生成。在机器学习各个分支下，强化学习和人类与环境的交互方式非常相似，在许多领域开始初露头角，期待看到更多将强化学习结合语言模型的应用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;span&gt;Deep Reinforcement Learning for Dialogue Generation&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;2&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 28.4444px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;strong&gt;&lt;span&gt;作者&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Jiwei Li, Will Monroe, Alan Ritter, Michel Galley, Jianfeng Gao, Dan Jurafsky&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 28.4444px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;strong&gt;&lt;span&gt;单位&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;(1) Stanford University, Stanford, CA, USA&lt;br/&gt;(2) Microsoft Research, Redmond, WA, USA&lt;br/&gt;(3) Ohio State University, OH, USA&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 28.4444px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;strong&gt;&lt;span&gt;关键词&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Reinforcement Learning、Seq2Seq、Text Generation&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 28.4444px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;strong&gt;&lt;span&gt;来源&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;arXiv.org(2016.06.25)&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 28.4444px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;strong&gt;&lt;span&gt;问题&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;本文提出利用强化学习进行开放领域的文本生成任务，并对比了有监督的seq2seq加attention模型和基于最大互信息的模型&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 28.4444px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;strong&gt;&lt;span&gt;模型&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;强化学习中的reward&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgkSMlEJFo90NY8rCXr3mJMB7A6RVd4fvNibhJgtobXmibZagV8ribiam1ibicbbq9sfgAlOianEIhDiaiabadQ/640?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;易被响应（Ease of answering），不容易出现对话僵局，其中 S 是无意义回答合集，s是某一时刻的响应&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgkSMlEJFo90NY8rCXr3mJMBPgNYafnK6jhgu5MVxBICrByB56viar1TyFxx2TOBNrhk16F6cvKedjA/640?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;信息流，若开辟新的话题，有利于对话的继续发展，隐层表示 hpi 和 hpi+1 的夹角余弦&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgkSMlEJFo90NY8rCXr3mJMBMM1mAJGUWnrNuiaf3yOD8LrhBGjbrc4Jq6pXu0PptwqfUiaiaibocD0hEA/640?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;语义连贯性，减少与对话无关问题的影响，其中，pseq2seq(a|pi,qi) 是由上一轮状态得到响应的概率，后一项是由当前产生响应通过网络生成之前的 qi 的概率。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgkSMlEJFo90NY8rCXr3mJMBcuHStJ82Yr11iao9rYDMuGfmf3Now8Y3yNxk72rsqhP3TIAp2fBZYIQ/640?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最终的reward是对三者加权求和，系数分别为：0.25、0.25、0.5.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对比试验：&lt;br/&gt;(1) 对话初始状态为一个SEQ2SEQ加attention的模型作为强化学习的初始状态。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;(2) 在前面的基础上将最大互信息加入其中作为reward，对于一个给定的输入[pi,qi]，可以根据模型生成一个候选回答集合A。对于A中的每一个回答a,从预训练模型中得到的概率分布上可以计算出互信息的值 m(a,[pi,qi])。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;(3) 将互信息训练过的模型作为初始模型，用策略梯度更新参数并加入课程学习策略，最终最多限定五轮对话。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgkSMlEJFo90NY8rCXr3mJMBpGgXCfUCp4Ba1mtElA5ibhQQDy9whrbVmOJ7rJicrl6zqusYEMuMtUqw/640?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 28.4444px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;strong&gt;&lt;span&gt;相关工作&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgkSMlEJFo90NY8rCXr3mJMBvNaqiam9ntHuDT9GlKGVnjHBcv7yVITOquwbK8cUvvBaNGAhTGmowpw/640?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 28.4444px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;strong&gt;&lt;span&gt;简评&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;本文作者提出了一个强化学习框架，模拟两个agent让其自动对话训练神经网络SEQ2SEQ模型，将Encoder-Decoder模型和强化学习整合，从而能保证使对话轮数增加。文中使用的模型非常简洁，reward函数定义清晰，评价指标也较为科学，可以生成信息更为丰富、易于响应的对话系统。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;span&gt;Hierarchical Reinforcement Learning for Adaptive Text Generation&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;3&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 28.4444px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;strong&gt;&lt;span&gt;作者&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Nina Dethlefs, Heriberto Cuay´ahuitl&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 28.4444px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;strong&gt;&lt;span&gt;单位&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;University of Bremen, Germany&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 28.4444px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;strong&gt;&lt;span&gt;关键词&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;NLG, 分层强化学习, 文本生成, wayfinding&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 28.4444px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;strong&gt;&lt;span&gt;来源&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;国际自然语言生成会议INLG(2010)&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 28.4444px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;strong&gt;&lt;span&gt;问题&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;在wayfinding（户内导航对话系统）领域利用分层强化学习进行文本生成。该方法的目标是对wayfinding的NLG任务整合进行优化，并在模拟系统中验证该方法的有效性。&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 28.4444px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;strong&gt;&lt;span&gt;模型&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;本文任务在wayfinding中的NLG任务有多个，且各个任务之间并非独立。从而提出应该根据用户类型，导航距离， 环境条件等作出不同的导航策略，介绍了分层强化学习。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;文章将户内导航对话系统的文本生成问题分为四块：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;(1) Content Selection：给不熟悉环境的用户的导航要比熟悉环境的用户的导航更细致&lt;br/&gt;(2) Text Structure：根据导航距离以及用户熟悉环境程度给予不同类型的导航，如大白话的，以fisrt， second…表达或者示意性的。&lt;br/&gt;(3) Referring Expression Generation：一间房间可以叫“A203”，也可以叫“办公室”或者“小白楼”&lt;br/&gt;(4) Surface Realisation：往前走可以用“go”也可以用“walk”等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;强化学习示意图如下，分层强化学习的思想与强化学习类似，但在强化学习的基础上加上层次，不同层次的模型处理不同层次的问题。&lt;br/&gt;&lt;/span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgkSMlEJFo90NY8rCXr3mJMBiansDbmsXnW2ADdO1KJeLdcWGQVfny5aZFmic9v1bNJS7nx1kYNdsfkQ/640?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;agent根据当前状态，执行动作a与环境交互，之后环境产生一个新的状态s并返回给agent一个奖赏r（可正可负），强化学习的目标函数便是使agent获得奖赏r最大。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;分层增强学习包含L个层，每层N个模型，如Figure 1是有15个agents的hierarchy，其中不同的agent负责不同的层次。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgkSMlEJFo90NY8rCXr3mJMBLaONOOXrxmJflCzsmyXdZqHCPNNia5Cwpr6C6QhjOCicZhksl6KtQ4xA/640?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;每个agent定义为半马尔科夫决策过程，可以表示成一个四元组&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgkSMlEJFo90NY8rCXr3mJMBv8iaiaao1wtWwle3xdre14UwbDOIpVzq96yiapUkAnHHiaOaxf5oWVWdiaw/640?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;分别为状态集，动作集，转换函数，奖励函数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;奖励函数表示agent在时间t状态s是执行动作a转换到新的状态s’所获得的奖励。半马尔科夫的目标是找到policy π*，&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgkSMlEJFo90NY8rCXr3mJMBPDA7E6Gdqian1dLujHR1UJQePfd14vx4DpqwaZ5CXjSgIcVeic4Eib2lw/640?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;使得在从当前状态转换到新的状态获得的累计奖励最多。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本文使用两种奖励函数，一种着重在 interaction length， 另一种着重在alignment and variation之间的平衡（具体公式可见论文）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本文是在模拟环境中进行试验，其中模拟环境包括user type（熟悉环境，不熟悉环境）， information need（高，低），length of the current route（短，中长，长），next action to perform（转，直走），current focus of attention（继续走，关注标识）。baseline为为部分agent随机选择action，即不考虑用户类型，导航距离等因素。经与baseline比较，效果较好。&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 28.4444px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;strong&gt;&lt;span&gt;资源&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;词性标注工具：&lt;/span&gt;&lt;a target="_blank" rel="external" style="text-decoration: underline; max-width: 100%; font-size: 14px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;http://nlp.stanford.edu/software/tagger.shtml&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 28.4444px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;strong&gt;&lt;span&gt;简评&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;将来的工作：将分层强化学习应用于其他NLG任务&lt;br/&gt;不足之处：实验是在模拟环境下进行的，未来应该在真实环境进行评估。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;总结&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;这三篇文章皆是强化学习在NLP领域的应用，第一篇主要侧重点在于应用DQN进行文本生成，并用BLUE指标进行评价，对比传统的LSTM-decoder和加入DQN之后的结果；第二篇文章侧重点在于虚拟两个Agent，在传统Seq2Seq的基础上加入强化学习从而使得聊天能够持续下去；第三篇文章侧重点在于任务驱动的对话系统应用分层强化学习，针对不同情况进行分层处理。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以上为本期Paperweekly的主要内容，感谢&lt;strong&gt;lshowway&lt;/strong&gt;、&lt;strong&gt;美好时光海苔&lt;/strong&gt;、&lt;strong&gt;Tonya&lt;/strong&gt;三位同学的整理。&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;第二部分：本周 arXiv.cs.CL论文&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;引&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;本周（2016.09.05-2016.09.09）质量较高的arXiv cs.CL的paper如下：&lt;br/&gt;（点击标题可看原文）&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;Convolutional Neural Networks for Text Categorization: Shallow Word-level vs. Deep Character-level&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;1&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; line-height: 25.6px; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;简评&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;span&gt;张潼老师的文章，通过实验对比了shallow word-level CNN（本文工作）和deep char-level CNN模型在而文本分类任务上的表现，结论是本文工作又快又准。&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;（这篇文章对于选择char-level还是word-level做文本分类非常有指导意义）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;Skipping Word: A Character-Sequential Representation based Framework for Question Answering&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;2&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; line-height: 25.6px; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;简评&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;span&gt;本文用char-level CNN模型来做句子表示，然后进行question和answer之间的相关匹配学习，CIKM2016 short paper accepted。&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;End-to-End Reinforcement Learning of Dialogue Agents for Information Access&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;3&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; line-height: 25.6px; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;简评&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;span&gt;本文是微软研究软邓力老师的文章，构建了一种从知识图谱中形成response的聊天机器人KB-InfoBot，并且提出了一种端到端的增强学习训练方案。&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;（本文对于构建一个端到端的KB + task-oriented chatbot非常有启发和指导意义）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;Joint Online Spoken Language Understanding and Language Modeling with Recurrent Neural Networks&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;4&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; line-height: 25.6px; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;简评&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;span&gt;本文提出一种模型，将intent detection、slot filling和language modeling融合在一起进行学习，用于解决对话系统中的SLU task。本文是SIGDIAL 2016 paper。&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;用到的数据集在Dropbox有一份&lt;span&gt;copy (https://www.dropbox.com/s/3lxl9jsbw0j7h8a/atis.pkl?dl=0)&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;Attention-Based Recurrent Neural Network Models for Joint Intent Detection and Slot Filling&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;5&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; line-height: 25.6px; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;简评&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;span&gt;和上一篇paper是同一个作者，解决的是同一个问题。将RNN换成了attention-based RNN，被另外一个会议录取。(有点灌水的意思)&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;Ask the GRU: Multi-task Learning for Deep Text Recommendations&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;6&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; line-height: 25.6px; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;简评&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;span&gt;本文提出了用端到端的解决方案来做paper的推荐任务，用GRU将文本序列（标题、摘要等）encode到一个latent vector中。并且通过多任务学习来完成内容推荐和条目预测两个task，取得了不错的效果。&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;以下内容为arXiv外的&lt;/span&gt;&lt;span&gt;优质内容&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;Discriminative Methods for Statistical Spoken Dialogue Systems&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;1&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; line-height: 25.6px; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;简评&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;span&gt;剑桥大学Spoken Dialogue System组毕业的Matthew Henderson博士，师从于Steve Young教授，研究领域是对话系统中的Dialogue State Tracking，主要特色是用transfer learning来解决discriminative model的扩展性和通用性。&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;如果你对chatbot感兴趣，强烈建议好好研读一下这篇博士论文。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;CONNECTING IMAGES AND NATURAL LANGUAGE&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;2&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; line-height: 25.6px; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;简评&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;span&gt;斯坦福大学Feifei Li的博士生Andrej Karpathy的PhD thesis，Karpathy维护着几个非常流行的开源代码库，并且有着一个影响力非常大的博客。名师出高徒，这篇博士博士论文值得一看！&lt;/span&gt;&lt;span&gt;最近，他更新了一篇博客，谈论了一些自己对读博的思考和建议。&amp;nbsp;&lt;/span&gt;&lt;span&gt;&lt;a target="_blank" rel="external" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;A Survival Guide to a PhD&lt;/a&gt;&lt;/span&gt;&lt;/h2&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; line-height: 25.6px; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;br/&gt;&lt;/h2&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;Mendeley Docs&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;3&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); white-space: normal; line-height: 25.6px; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;简评&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;span&gt;paper越看越多，一个优秀的paper管理工具就变得非常必要了，Mendeley是其中最优秀的代表之一。&lt;/span&gt;&lt;span&gt;Easily organize your papers, read &amp;amp; annotate your PDFs, collaborate in private or open groups, and securely access your research from everywhere.&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;广告时间&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;PaperWeekly是一个分享知识和交流学问的民间组织，关注的领域是NLP的各个方向。如果你也经常读paper，也喜欢分享知识，也喜欢和大家一起讨论和学习的话，请速速来加入我们吧。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;微信公众号：&lt;strong&gt;PaperWeekly&lt;/strong&gt;&lt;/span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgkSMlEJFo90NY8rCXr3mJMBibduVHxMKSHzQtVkHz8kNwpjCKBiccGuqLE0WpPuAbdtEs6cTF5iabpAQ/640?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;微博账号：&lt;strong&gt;PaperWeekly&lt;/strong&gt;（&lt;/span&gt;&lt;a target="_blank" rel="external" style="color: rgb(64, 64, 64); text-decoration: underline; max-width: 100%; box-sizing: border-box; font-size: 14px; word-wrap: break-word !important; background-color: transparent;"&gt;&lt;span&gt;http://weibo.com/u/2678093863&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&amp;nbsp;）&lt;br/&gt;知乎专栏：&lt;strong&gt;PaperWeekly&lt;/strong&gt;（&lt;/span&gt;&lt;a target="_blank" rel="external" style="color: rgb(64, 64, 64); text-decoration: underline; max-width: 100%; box-sizing: border-box; font-size: 14px; word-wrap: break-word !important; background-color: transparent;"&gt;&lt;span&gt;https://zhuanlan.zhihu.com/paperweekly&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&amp;nbsp;）&lt;br/&gt;微信交流群：微信+ &lt;strong&gt;zhangjun168305&lt;/strong&gt;（请备注：加群 or 加入paperweekly）&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Sat, 10 Sep 2016 16:20:02 +0800</pubDate>
    </item>
    <item>
      <title>重磅 | DeepMind最新生成模型WaveNet，将机器合成语音水平与人类差距缩小50%（附论文）</title>
      <link>http://www.iwgc.cn/link/2623140</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自DeepMind&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Aäron van den Oord、Heiga Zen、Sander Dieleman&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀、李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;今日，谷歌 DeepMind 发布博客介绍他们在文本转语音系统上取得的重大进展。DeepMind 表示，他们最新的深度生成模型 WaveNet 将机器语音合成的表现与人类之间水平的差距至少缩减了 50%。在文章中，DeepMind 提供了大量的音频体验，在这篇文章中就不再给予展示，感兴趣的读者可浏览原文体验，原文网址：https://deepmind.com/blog/wavenet-generative-model-raw-audio/。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这篇文章提出了 WaveNet——一种原始音频波形（raw audio waveforms）的深度生成模型。我们的研究表明 WaveNet 可以生成模拟任何人类声音的语音，而且其听起来比已有最好的文本转语音（Text-to-Speech）系统更为自然，与人类表现之间的差距缩减了超过 50%。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们的研究也证明该网络还可被用于生成音乐等其它类型的音频信号，我们还给出了一些引人注目的模拟钢琴演奏的音乐片段。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;说话的机器&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人与机器交谈是人机交互领域内一个长久以来的梦想。最近几年来，随着深度神经网络的应用（如 Google Voice Search），计算机理解自然语音的能力已经得到了彻底革新。但是，使用计算机生成语音——这个过程通常被称为语音合成（speech synthesis）或文本转语音（TTS）——仍在很大程度上基于所谓的拼接 TTS（concatenative TTS），其中有一个由单个人录制的大量短语音片段构成的非常大的数据库，然后再将这些短语音组合起来构成完整的话语。这使得如果没有录制一个全新的数据库，修改语音就会非常困难（比如切换成一个不同的说话者，或改变它们语音的强调或情绪）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这带来了对参数 TTS（parametric TTS）的巨大需求，其中生成数据所需的所有信息都存储在模型的参数中，因此语音的内容和特征都可以通过该模型的输入进行控制。但是，到目前为止，参数 TTS 往往听起来都不如拼接 TTS 那样自然——至少在英语等语音的合成上是这样。现有的参数模型往往是通过将它们输出经过信号处理算法（被称为语音编码器（vocoders））来生成音频信号。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;WaveNet 改变了这一范式，而是选择直接建模音频信号的原始波形，一次处理一个样本。除了能够产出听起来更为自然的声音，使用原始波形意味着 WaveNet 可以建模几乎任何类型的音频，包括音乐。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;WaveNet&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_gif/KmXPKA19gW87xwIbibLI3Lwib1NkTnn1nkP0iaHBMcQC8ADUKcNYmicG9ALv06IQHKklho2J3hvibMSUGbdr1Z9mICw/0?wx_fmt=gif"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;研究者通常会避免对原始音频进行建模，因为波形波动得非常快：每秒通常有 16,000 甚至更多个样本，而且在许多时间尺度上都存在重要的结构，在这些结构中，对每一个样本的预测都会受到之前所有样本的影响（用统计学的话来说：每一个预测分布的前提是所有先前的观察），这显然是一个具有挑战性的任务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是，我们今年初发布的 PixelRNN 和 PixelCNN 模型表明不仅一次一个像素式地生成复杂的自然图像是可能的，而且也可以一次一个颜色信道（colour-channel）地生成，这需要对每张图像进行数千次预测。这启发了我们将我们的二维 PixelNet 调整为一维的 WaveNet。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_gif/KmXPKA19gW87xwIbibLI3Lwib1NkTnn1nk9MEoCGk9hBJa0CQ6Cojd8K126t2gOZU4J98ETIYGmqwQ2txHI4vvRQ/0?wx_fmt=gif"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以上的动画展示了 WaveNet 的结构。这是一个完全卷积的神经网络，其中的卷积层有不同的膨胀系数（ dilation factors），这让其感受野（receptive field）可在深度（depth）上指数式地增长并可覆盖数千个时间步骤（timesteps）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在训练时间，其输入序列是由人类说话者录制的真实波形。训练之后，我们可以对这个网络进行采样以生成合成话语。在采样的每一个时间步骤，都会从该网络所计算出的概率分布中取出一个值。然后这个值会被反馈进入输入，并为下一个步骤生成一个新的预测。像这样一次一步地构建样本具有很高的计算成本，但我们发现这对生成复杂的、听起来真实感强的音频而言至关重要。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;改进当前最佳的结果&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们使用谷歌的一些 TTS 数据集训练 WaveNet，所以我们能评估其表现。与谷歌目前最好的 TTS 系统（parametric 和 concatenative）和使用平均意见得分（Mean Opinion Socres，MOS）测试的人类语音相比，下图显示了 WaveNet 从 1 到 5 的质量表现。MOS 是一个主观的声音质量测试的标准测量方法，包含带有人类受试者的盲测（在 100 条测试语句上的超过 500 个评级）。就像我们看到的那样，在英语和汉语普通话上，WaveNet 减少了顶尖水平与人类水平之间的差距，减小的这个差距超过了 50%。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;无论是汉语还是英语，谷歌目前的 TTS 系统被认为是全球最好的，所以使用一个模型对两者都有改进是一件非常重大的成就。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW87xwIbibLI3Lwib1NkTnn1nkCJBntqmmFgJyZwAEg17SZmmafTLUkdUNHzGQXnP4mbRzh742wKkYXg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这里是一些来自是三个系统的样本，你可以自己听听，做个对比（此部分为 6 个音频文件，读者可浏览 DeepMind 官网体验）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;知道说什么&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了使用 WaveNet 将文本转化为语音，我们需要识别文本中是什么。我们通过将文本转换为一序列的语言和语音特征（包含了当前音素、音节、词等方面的信息）并将其输送到 WaveNet 中做到这一点。这意味着网络的预测不只以先前的音频样本为条件，也以我们想要它说的文本为条件。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果我们在没有文本序列的情况下训练网络，它仍能生成语音，但现在它需要编造它所说的内容。就像你从下面的样本中听到的那样，结果会导致像是在胡说，原文字被组成的像是声音的文字解释。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;注意，非语音声音，比如呼吸和动嘴产生的声音，有时也会被 WaveNet 生成。这反映出了原音频模型的更强大的适应性。就像你能从这些样本中听到的那样，一个简单的 WaveNet 能够学习许多不同声音的特性，不论男性女性。为了保证它知道使用给定话语的哪些声音，我们将对说话者的识别作为该网络的条件之一。有趣的是，我们发现在多个说话者中建模一个说话者的训练要比单个说话者的训练更好，表现出了一定形式的迁移学习（transfer learning）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过改变说话者身份，我们能使用 WaveNet 用不同的声音说同样的事：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;类似地，我们能为模型提供额外的输入，比如情绪或口音，使得语言更加多变且有趣。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;制造音乐&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因为 WaveNet 可被用于建模任何音频信号，我们认为用它来生成音乐也会很有意思。和 TTS 实验不同，我们没有调节该网络的输入序列，以告诉它该播放什么（比如，一个音乐评分）；相反，我们只是让它生成任何其想生成的东西。当我们在一个古典钢琴曲的数据集上训练它时，它产出了一个如下的让人惊叹的样本（此处有音频）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;WaveNet 为开启了 TTS、音乐生成和广义上的音频建模的大量可能。可以使用深度神经网络一个时间步骤一个时间步骤地直接生成在所有的 16 kHz 音频上都是有效的，这个事实非常让人惊讶，更不要说其表现还优于当前最佳的 TTS 系统。我们很高兴看到下一步我们能用它来做什么。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;更多细节可查看原论文，下面是对该论文的摘要介绍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;论文：WaveNet：一种用于原始音频的生成模型（WAVENET: A GENERATIVE MODEL FOR RAW AUDIO）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW87xwIbibLI3Lwib1NkTnn1nkPjulhNuvjFRIKDYYsgjYUZmeQWbUEUGLS46Z6MtsXQhrvAEhLXTadQ/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：&lt;/span&gt;&lt;span&gt;这篇论文介绍了 WaveNet——一种用于生成原始音频波形的深度神经网络。该模型是完全概率的和自回归的（ fully probabilistic and autoregressive），其每一个音频样本的预测分布的前提是所有先前的样本；不过我们的研究表明它可以有效地在每秒音频带有数万个样本的数据上进行训练。当被应用于文本转语音时，它可以得到当前最佳的表现，人类听众评价它在英语和汉语上比当前最好的参数（parametric）和拼接（concatenative）系统所生成的音频听起来都显著更为自然。单个 WaveNet 就可以以同等的保真度捕获许多不同说话者的特点，而且可以通过调节说话者身份来在它们之间切换。当训练该模型对音乐建模时，我们发现它可以生成全新的、而且往往具有高度真实感的音乐片段。我们的研究还证明其可以被用作判别模型，可以为音速识别（phoneme recognition）返回很有希望的结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;点击「阅读原文」，下载论文↓↓↓&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;</description>
      <pubDate>Fri, 09 Sep 2016 12:31:02 +0800</pubDate>
    </item>
    <item>
      <title>专访 | 东南大学漆桂林教授：知识图谱不仅是一项技术，更是一项工程</title>
      <link>http://www.iwgc.cn/link/2623141</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心原创&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;7 月 22 日，中国信息学会语言与知识计算专委会在深圳主办了一场主题为「人工智能×机器人——知识图谱」的专场论坛。中国中文信息学会秘书长、中科院软件所孙乐研究员、清华大学李涓子教授、英国阿伯丁大学 Jeff Z. Pan 教授、浙江大学陈华钧教授、东南大学漆桂林教授、Gowild 智能科技 CTO 王昊奋博士等众多国内外知识图谱顶级专家和青年新锐共同探讨了知识图谱技术的发展和应用。现场干货十足，作为本次论坛的协办方之一，机器之心有幸对东南大学漆桂林教授进行了专访。漆桂林教授做了题为《知识图谱中的推理技术介绍》的报告（报告演讲内容附于文后，对应幻灯片可点击文末「阅读原文」下载），讲解了中文知识图谱的发展现状与应用，并详细阐释了非结构化数据处理的相关技术。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWicKq75cdUs4R02hSKFqcUUFlY284ywLcSfQ0kAgAqz46DjcXFlfSkBj9XZMuam8246IA2iaQmuZ9Qw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote style="white-space: normal; line-height: 25.6px;"&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;漆桂林教授简介：东南大学教授、博导，担任中国中文信息学会语言与知识计算专业委员会副主任和中国计算机学会中文信息技术专业委员会专委委员。漆教授于2006 年从英国贝尔法斯特女皇大学获得计算机科学博士学位，师从人工智能界著名专家 Weiru Liu 教授。2006 年8 月至2009 年8 月，在德国 Karlsruhe 大学 AIFB 研究所做博士后研究，师从语义 Web 界国际知名专家Rudi Studer教授。在人工智能和知识图谱的科研和实践方面有近20年的经历。发表高质量学术论文100余篇。特别是在国际人工智能联合会议（IJCAI）、AAAI人工智能会议（AAAI）、知识表示与推理会议（KR）、不确定性推理会议（UAI）、语义网会议（ISWC）发表论文 20 余篇。担任语义 Web 权威期刊 Journal of Web Semantics 的编委。担任 Journal of Advances in Artificial Intelligence 的副主编。与欧洲科学院院士 Frank van Harmelen 合作，主编了Annals of Mathematics and Artificial Intelligence的一个特刊（special issue）；与 ECCAI Fellow Henri Prade 教授合作，主编了 Journal of Applied Logic 的一个特刊。连续10多年担任国际著名会议 AAAI、IJCAI 、WWW、ISWC 等会议的程序委员，并担任过中国语义 Web 和 Web 科学联合会议主席（CSWS2012）等职务。先后承担包括国家自然科学基金和欧盟第七框架项目 Marie Curie IRSES 在内的多项科研项目，作为第二负责人参与了由科大讯飞牵头的 863 课题「高考机器人」的一个子课题，并且承担华为、百度等著名公司项目。&lt;/span&gt;&lt;/em&gt;&lt;br/&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;机器之心：能介绍下你目前所做的研究吗？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;漆桂林：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我们现在所做的研究主要涉及人工智能领域的三个部分。第一个非常重要的部分是知识表示与推理（Knowledge Representation and Reasoning），这是人工智能领域里较为传统的一个分支，这部分工作主要偏重于符号逻辑——怎么把我们人类的知识用符号逻辑表示或表达出来，以及当我们能把人类的知识用符号逻辑表达出来以后，我们怎么能够使用符号逻辑的推理机从这些知识里推理出隐含的知识——这也是我们人类智能里非常重要的一部分。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第二部分就是目前比较火的知识图谱。我们目前关注的是知识图谱的构建，这里面会用到许多机器学习技术，包括深度学习以及传统的机器学习技术。知识图谱的构建我们分为两类：一是「事实性知识（fact knowledge）」，这类知识包括人与人之间的关系、企业与企业之间的关系；另一类是更抽象的知识，称作「模式知识（schema knowledge）」，比如投资的关系，里面包含了投资人和被投资公司（个人）——我们要知道它的定义域是什么，它有什么样的人物和事物来做投资，它的宾语又是什么，就是说你要知道投资的是什么受众。这种更抽象的知识的表示方式也更复杂，作用也非常大——它可以帮助我们更好地对知识进行组织和推理。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第三部分叫做规则。这实际上兴起于七八十年代，在深度学习出现之前就非常火了，在很多公司里也用得非常普遍。我们在做各种规则的推理引擎，以及一些基于规则的自动和半自动的学习算法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除了以上三大方面，我们也关注图像，但和传统的机器学习研究不大一样的是，我们做的是多模态图像理解。多模态有很多种，比如图像和语音的混合多模态，我们研究的是图像和文字的多模态。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;机器之心：就像是现在比较流行的 image caption（图像描述）?&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;漆桂林：部分对，image caption （图像描述）方面我们也在研究，不过我们不会局限于image caption。以上就是就是我们目前在人工智能领域的布局，以及我们实验室未来几年准备做的事情。我们也会做一些上层的应用，比如利用这些技术来做一些问答、推荐和情感分析，这都是我们关注的领域。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;机器之心：刚才你提到在做知识图谱时会用到深度学习，能否解释一下它们之间的关系？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;漆桂林：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;前面说了知识图谱方面目前的工作有两类。其中一种是学习各种实体之间的关系，比如企业之间的关系、合作伙伴之间的关系、人物之间的关系（比如领导关系、父子关系等），这是自然语言处理领域里一个比较传统的问题——关系抽取（relation extraction）。这个任务可以使用机器学习来完成，但也有使用规则的。最近几年随着深度学习的兴起，我们会考虑使用深度学习模型来抽取关系，当然前提是你已经积累了足够的语料——没有足够语料，深度学习是做不了的。对于我们来说，深度学习是我们实现自然语言理解的一个工具。当然，我们也在考虑从知识表达的角度来融合知识图谱和深度学习，提出新的深度学习模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;机器之心：在与中文理解的相关研究中，我们是否经常面临语料缺失的问题？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;漆桂林：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;对，这是一个很大的问题。特别是当我们要做一个各种领域的知识图谱时，语料缺失是导致我们很难快速做出比较高质量的知识图谱的最大障碍。就是说，当你面临一个新的领域时，你首先需要一些比较低级的方法，比如写一些规则，然后再使用这些规则来抽取一些比较高质量的关系，其中你需要做很多人工标注，把里面的关系对正确标注出来作为训练样本（当然人也可能犯错，但一般我们认为是正确的）。但我们可能不会马上就使用深度学习，我们会使用一些简单的机器学习方法来做关系的学习。当语料比较多了以后，可能才会采用深度学习的方法。一般都有一个过程，不会一开始就使用深度学习。另外可以考虑的一个方法是结合深度学习和迁移学习（transfer learning）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;机器之心：现在还有一些传统方法和深度学习的结合？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;漆桂林：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;从业界的角度来看，用传统的方法还是比较多一点。但是各种方法结合其实是很正常的，比如说谷歌的AlphaGo采用的就是深度学习和增强学习（reinforcement learning）的结合。而最近很多人关注怎么把规则和深度学习结合，提出新的混合模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;机器之心：目前基于深度学习的关系抽取的效果是否比传统的翻译模型更好呢?&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;漆桂林：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;在某些特定的条件下，比如标注数据足够的情况下，深度学习会好一些，但也不会好多少。比如说我用传统的方法可能能达到 85%，用深度学习也最多只能到 86% 或 87%；所以我们会想这样的代价是否是值得的。就是说，如果我花了大量的时间给数据做标注，结果只提升了一到两个点，那从业界的角度来看这就很不值得。但如果你有足够的资源，你也可以做。你标注的数据越多，模型越来越复杂，学习的效果肯定会越好。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;机器之心：有的观点认为之后所有的商业都是数据商业，那数据再往后可能就是知识。从实践角度，传统行业如何去构建这种数据的知识图谱关系？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;漆桂林：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;具体还是要看实际应用。不能说给你一个领域，就开始构建知识图谱。这是不行的，这样不是目标驱动的。一旦你的应用和需求确定了，你才能确定要从怎样的数据源去抽取信息。比如说电商这一领域，如果我是一家电商公司，我肯定有一些电商的数据，而且这些数据是结构化的，可以直接用于知识图谱。然后我们可以使用一些外部的数据源，比如淘宝、天猫和京东的数据源——我们可以用爬虫技术把这些数据爬下来，把这些数据抽取出来然后进行集成。这些从电商网站获取的数据也是结构化比较好的。另外还有一些来自各种论坛或新闻的数据，从这些数据中进行抽取的难度就更大了。所以说你是说各种不同的数据源中进行数据抽取。 总的来说，首先你要把你的应用确定好，然后再确定要从哪些数据源获取所需的数据，然后再考虑要用怎样的方式将这些数据集成起来。这样的考虑是必需的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;机器之心：来自社交网络或新闻等的数据很多是非结构化的，我们可以怎样解决这个问题？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;漆桂林：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;对非结构化数据的处理是知识图谱的一个非常有用的地方。其实我们知道大数据里面很多数据都是非结构化的——所谓的大数据，更多的并不是企业内部关系数据库里面的数据，更多的是互联网上每天通过各种媒体产生的数据，这种数据的量是非常大的。如果我们把这个看作大数据，根据 IBM 等公司的统计，其中大部分——80% 以上——是非结构化数据。非结构化数据可以分成几类，一类是音频数据，比如说我们今天的录音；第二类是文本数据，比如你们记录下来放在本子上的数据；第三类是图像数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;处理这三类数据所用的技术是不一样的。音频数据目前都在用深度学习了，图像数据处理也基本如此。深度学习在这两方面已经比传统的处理方法好很多了，但在文本方面，深度学习还没显示出那么强大的威力。这方面也有各种讨论：文本的东西可能和我们人类的智能存在关联，图像这些感知方面的处理可能层次更低一点，而人的语言则更偏向于认知方面，处理的难度也更大。深度学习不一定适合做这样的事情。目前的学术成果也能够验证这样的说法。可以说在很多自然语言处理和自然语言理解的任务中，深度学习并没有那么强大的表现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;深度学习可能在某些方面比传统方法更好，但它其实需要付出很大代价，比如说要做很多人工标注。而且事实上即便是在音频和图像方面，采用深度学习的代价也是很大的，同样需要很多人工标注。自然语言更复杂，对自然语言进行标注是很困难的，也很难做到高效，因为换一个领域就需要重新标注。所以深度学习虽然是一个很好的方法，但它并不是唯一的方法。我认为在非结构化数据的处理方面，对文本数据的处理是非常重要的一块；从技术上来说，我们会把人工智能领域的一些技术都利用起来。从大的方面来说，我们会用到基于规则的技术和基于学习的技术，比如 SVM（支持向量机）、以及现在比较热的深度学习技术。而在文本分析这一特定领域，还有一些特定技术，比如我们前面提到的对知识图谱的构建非常重要的关系抽取，另外还有自然语言处理里面的命名实体识别——比如文本里面有一个机构或人名，你能不能将其准确识别出来？你至少要识别到这个人，才能识别到其两者之间的关系。当你把这个事情做好了以后，我们还需要考虑怎么把这些数据集成起来。比如说在一个文本里提到的某个人在另一个文本里也出现了，但命名却不一样（比如我们在一个文本里说「习近平」，在另一个文本里说「习大大」），你怎么知道这两个人是同一个人？我们构建知识图谱时就需要解决这个问题。这种实体之间的消岐对提高质量来说是非常重要的技术。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有了知识图谱之后，我们还需要做什么事情呢？只有结构化的数据是不够的，如果新来一个文本会怎样？我怎么对这个文本做理解呢？我们需要把我们已有的知识图谱中的各种实体和实体之间的关系链接到新来的文本中，这样才能做到对文本的理解——这里面有一种叫做实体链接的技术。如果要想得到我刚刚所说的抽象的 schema 知识，那就还需要做对 schema 知识的学习，这也是单独要做的一种技术。此外当数据来自于不同的人的时候，schema 知识也需要做匹配。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从图谱构建的角度来说，它有很多技术，除了刚才提到的，另外还有推理技术。比如说，如果有一个知识图谱里面两个节点之间的边是缺失的，但它们之间其实是有关系的，只是没有显示的抽取出来；那么我们就可以通过与这两个节点关联的节点将它们之间的关系推理出来。这就是推理技术，而推理技术也可以分为很多种，包括：逻辑推理和统计推理。所以在知识图谱的构建上存在很多技术。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;机器之心：所以知识图谱是非常复杂的技术。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;漆桂林：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;就像我经常在外面做讲座时强调的那样：如果你要理解知识图谱，你要知道它不仅仅是一种技术，而是一种工程。它是自七八十年代以来在人工智能领域慢慢兴起的一个分支——知识工程。我刚刚说的知识表示和推理其实也是知识工程的一部分。知识工程是老一代人工智能学者提出来的——94 年的图灵奖获得者 Feigenbaum 提出了知识工程这个概念。80 年代时，人工智能里面的专家系统非常盛行，它也使用的是知识工程。要理解知识工程，做计算机的人可以思考一下软件工程：软件都有需求分析，然后用各种技术去构建软件，有各种开发流程，还有各种质量验证等等。知识工程也是一样，只是其中的知识对应了软件工程中的软件，所以也同样是一项工程。就像我们刚才说的，如果你要构建电商的知识图谱，你首先要了解需求，没有需求就不要说图谱。你不能说我要建电商知识图谱，这是没法建的，你必须告诉我具体需求是什么。有了需求，我才知道该从什么数据源抽取什么知识，然后我才能选择合适的技术来做这件事，还要做好质量控制。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此外，就和软件工程里的软件更新一样，知识库和知识图谱同样需要动态更新。知识图谱不是静态的东西，如果你做的是静态的，那就没有价值，是死的；只有当它是动态时，才具有生命力。你还要让别人经常使用，有了使用才有反馈，你可以使用这些反馈对你的知识图谱做各种修改和更新，这样它才能变成真正的商品，它的价值才能真正体现出来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;机器之心：所以这是一个知识不断积累、不断学习的过程。现在在深度学习领域里有一个比较火的研究方向是 learn to learn，人们认为深度学习很难做到，因为它没有知识管理，不擅长推理。如果我们要实现 learn to learn 的目标，知识图谱是一种很重要的方式吗？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;漆桂林：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;对，深度学习最大的一个问题是没有可解释性。对于知识图谱，一旦构建好了以后，在对于任务进行推理时，不管你用的是基于规则的推理还是逻辑推理，都是可以解释的。就是说我们知道为什么推理出了这个结果，而不是另一个结果；我们也知道我们是从哪个数据源进行抽取的。这些数据我们都是可以保留的，这就是知识的溯源性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（要实现 learn to learn 的目标，）知识图谱是一种很重要的方式，但我们不能说它是唯一的方式。现在在机器学习领域里面有不少学者提出来可以用非监督的学习方法，也就是说不再需要人去标注数据，能实现机器的自主学习。这也是一种方式。但现在还没有人能真正把无监督学习做出来，所以具体我们还不太清楚。但它可能会结合知识图谱来完成这个任务。对于我们做知识图谱的人来说，我们也会把机器学习作为一种手段来实现知识的自学习。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;机器之心：在知识图谱方面，我们知道百度有知心，搜狗有知立方，你对这些科技公司的知识图谱项目有了解吗？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;漆桂林：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我们请过百度和搜狗的人到一些中文知识图谱的会议上做过报告，我只能从听过这些报告里谈谈我的认识。但我没有具体参与他们的工作，所以我不能比较和乱评价，但我觉得百度和搜狗在知识图谱方面都是做得非常好的。他们都是中国知识图谱方面比较先驱的公司，做得非常早，所以他们也能很早就到我们这些特邀的会议上做报告。前期来看，我觉得百度的知心和搜狗的知立方这两者的差异性不是特别大，前期还主要是集中在百科的数据上。百度有百度百科的数据，这是天然的优势；搜狗也能通过一些渠道获取数据，比如互动百科、维基百科，或也可能会爬百度百科的数据。在这一块，他们都做得非常好。比如说，他们可以用他们构建好的「通用知识图谱」来回答问题，比如回答「王菲的老公是谁？」这种娱乐圈里面比较热门的话题。这些用户比较关注的问题他们应该都能回答得很好。包括人物的关系链推理等等，他们都有涉及。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是他们公司的定位和侧重点不一样。据我所知，百度知心在教育、游戏和医疗这些领域投入比较大，他们做了一些比较垂直的知识图谱构建和应用。比如在医疗方面，我们和百度有一个合作，我们的学生去百度实习，帮助他们完成了一个医疗网站，把医疗器械等医疗方面信息利用起来构建了一个医疗方面的知识图谱，能帮助他们进行一些决策，比如保健品的推荐等等。他们在这方面投入了一些力量，做得也比较好。而搜狗还在推广自己的搜索引擎。据我所知，搜狗也做了一些人物关系的知识图谱，这主要是在娱乐圈方面做得比较多。另外搜狗也可能会把知识图谱应用到他们的智能输入法里面。所以我们不能说他们谁强谁弱，他们只是侧重点不一样。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是从技术方面来说，百度可能在知识图谱上的积累更多一点。据我所知，百度有两个知识图谱团队，在深圳有一个，在北京有一个，而且都有上百人。所以他们的投入比较大。但我不清楚搜狗的投入有多大，这里就不妄下评论了。另外，百度在自然语言处理方面在国内是比较领先的。自然语言处理和知识图谱是息息相关的，所以我个人认为百度在知识图谱的技术和整体布局上是非常强的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;机器之心：知识图谱的概念比自然语言处理更大一些吗？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;漆桂林：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我们可以把知识图谱看作是自然语言理解。自然语言处理是什么呢？比如说给定一个句子，我们怎么知道这个句子的结构，我们能否构建出一个语法树出来，我们能不能做好分词的工作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而知识图谱则更接近自然语言理解，也就是说我们不仅要把这个句子解析出来，而且还需要知道句子中的每个词的含义是什么、词跟词之间的关系是什么、每个词有什么属性等等。我们要了解其中方方面面的信息。就像我们见到一个人，如果我只是知道他是个人，那我也谈不上了解这个人。但如果我知道他的职业、他的朋友圈、他的子女和他擅长的事这些信息，我就能对他进行逻辑推理，从而对这个人有很好的理解。这和仅仅识别他是一个人是有很大区别的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;机器之心：在大数据以及机器学习技术兴盛的今天，您如何看待知识图谱的前景与挑战？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;漆桂林：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我觉得目前最大的挑战不是技术上的，因为实际上大家在技术和算法上做得都还可以，和国外的技术差距也并不是特别大；真正的挑战是我们没有一些成型的工具。为什么深度学习能得到大家的广泛使用呢？因为它有很多工具，比如 TensorFlow。这些工具能让我们很快做出一些基于深度学习的应用，比如图像理解，所以它能让很多不是很有专业水平背景人应用起来。但知识图谱不是这样的：第一是缺工具，第二是缺数据。我们很少有开放的数据，这也是我们知识图谱正在大力解决的一个问题。我们正在打造一个知识图谱开放平台，能够把知识图谱的数据和工具开放出来让大家都能够使用，从而扩大其受众，让业界能开发出各种好的应用；这样才能更好地促进我们的技术的发展，实现更好的前景。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;hr style="white-space: normal; line-height: 25.6px;"&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;知识图谱中的推理技术介绍&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;报告摘要&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;知识图谱的概念于 2013 年以后开始在学术界和业界普及，并在智能问答、医疗、反欺诈等应用中发挥重要作用。本次报告将系统介绍知识图谱中的推理技术，包括基于符号逻辑的推理和基于统计的推理。并且探讨基于逻辑和基于统计推理的结合。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;演讲内容&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;非常荣幸来这里和大家做交流。今天我讲的是关于知识图谱中的推理，并且会讲到我们最近做的高考机器人的工作怎么和推理结合起来。今天早上陈华钧教授为我们做了非常精彩的知识图谱的介绍，大家对知识图谱将来有什么样比较好的应用场景充满期待，我们当然希望将来高考机器人能做出来，以及能够把我们知识图谱以及推理技术真正用起来。&lt;br/&gt;&amp;nbsp;&lt;br/&gt;我今天首先会给大家介绍知识工程的历史，也就是知识图谱的历程；二是给大家讲一下我们在知识图谱中的知识表述以及推理的简要作用介绍；三是讲我们做的高考机器人的推理例子，最后会总结一下。&lt;br/&gt;&amp;nbsp;&lt;br/&gt;其实我们要谈到知识图谱的时候，大家千万不要把它看成一个图，这样理解有局限。你要把它看成一个工程，其实它是一个知识工程，它涉及到怎么把图构建起来，怎么把图用起来，其实是一整套的方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicKq75cdUs4R02hSKFqcUUFrmQak4YF5EFCt3K8ibygAH3ia5dRc287hgeniaP2eOmlnmuORjvEe6Dmw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们如果从这个方面理解，我们应该非常感谢图片上的这位先生，是他提出了知识工程的概念，其实是人工智能领域在 80 年代兴起来的非常里程碑的概念。知识工程不仅仅在 80 年代火了一下，其实它有很深远的历史。从 60 年代开始其实就有很多学者开始关注这方面的研究了，最早做认知科学的人想做什么呢？他说人类的自然语言是非常复杂的，它和计算机里面信息存储的差别是非常大的，计算机把人类的自然语言是看成符号，不知道是什么，都是字符串。我们如何把人的自然语言用一种形式化的方式能够表示出来？这其实是以前的人在想的事情。最后想出来一个东西：它可以用有向图把人类的自然语言表述或者表达出来，这样计算机可以利用这个东西做一些事情。&lt;br/&gt;&amp;nbsp;&lt;br/&gt;70 年代，人工智能最顶级的 IJCAI，国际人工智能联合会议里面有很多论文都是关于这个的。80 年代，随着规则的兴起，大家都用这些规则，以及各种专家的知识，这时候专家系统非常流行。而这时候费根鲍姆和他的学生提出知识工程的概念。因为大家对这个东西期待很高，而且因为知识工程不像机器学习那样，能够比较容易上手，能够非常快的根据数据跑出结果，他要把知识能用人工的方式写出来，这个代价很大。这就导致一个问题，比如我在医学领域，我能够把知识库构建的很好，能做各种应用，感觉很不错。但是换一个领域又得重新做，而且可能比较困难。一开始大家期望很高，又没有出现达到了全人工智能或者做通用的人工智能的产业，大家的期望值一下降下来了，缺少经费导致知识工程举步维艰。当然，还是有些人继续研究语义网络和知识工程，比如说前雅虎首席科学家 Ron Brachman。语义网络的问题是，一个句子不同的人用不同的方式表述，而且规则也不一样，最后跑出来的结果，不同的人推理后跑出来的结果不一样。&lt;br/&gt;&amp;nbsp;&lt;br/&gt;为了把这个东西做的更形式化，Brachman 等人引入了逻辑，使得语义网络的推理更加严谨。而到了 2000 年左右，就像陈教授介绍的，随着语义 Web 的提出，大家觉得逻辑必不可少，然后各种标准就出来了，「逻辑」实在太强大了，但是有时候又和现实的生活离的太远。到 2009 年的时候语义网络又开始走下坡路，因为大家一开始以为这个东西会很有用，结果又没有达到期望。谷歌在这样的背景下提出了知识图谱的概念，他们只关注数据，关注怎么把自然语言里面把各种关系获取出来，然后用这些东西做各种提高搜索引擎的效果，以及做一些问答等等，使得这个知识图谱的实用性大大增强。它的实用性增强以后，我们做研究的人才有经费，才可以做各种实用的推理。&lt;br/&gt;&amp;nbsp;&lt;br/&gt;讲推理首先要讲表示，为什么呢？你都不知道你的知识怎么表示或者表达，你怎么做推理？到底用图表示还是用什么表示？首先要有语言表示。有几个标准的语言：RDF、RDFS、OWL。RDF 其实很简单，就是主谓宾结构，但不是那么简单，因为它多了一个 URI 的东西，它要有一个唯一的标识，给你一个有利的标识，然后会有一些自定义的东西。这个东西其实就是我们现在大家非常熟悉的知识图谱，就是用这个东西表述的，就是主谓宾结构表述的。&lt;br/&gt;&amp;nbsp;&lt;br/&gt;这还是不够，所以研究者又提出了 RDFS，引入了「类」这个东西，类是指实例的集合。比如「狗尾草」是一个公司，而「人工智能公司」是一个类，很多公司都在这个类里面。我们有了这个类以后可以做各种分类体系，比如可以说人工智能公司都是高科技公司，我可以分类了——我有这样的分类，还有 subclass 的关系。还有一个是关系，比如投资关系，我们要知道它是由什么样的一类人或者一类事物来投资什么样一类人或者一类事物。如果是投资关系，一般我们大家想的更多的一般是由投资人来投资公司。如果我把这个东西给形式化出来，后面就有作用了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicKq75cdUs4R02hSKFqcUUFzQ2WemYW0ZY295khphJcNMfUvDKznjVODTQuQ6EWVly92VHjf0ZqwQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们先看第一个推理，假设我知道 Gowild 是一个人工智能公司，我知道人工智能公司是高科技公司，那我就可以说 Gowild 是高科技公司，这样没有问题，大家很容易理解。投资是投资人投资公司，然后我发现胡海泉投了 Gowild，当然我就可以推出它是一个投资人，因为投资的关系，左边出现的必须是一个投资人，右边出现的是一个公司。所以我可以推出胡海泉是一个投资人，Gowild 是一个公司，这是非常简单的推理。&lt;br/&gt;&amp;nbsp;&lt;br/&gt;OWL 可以做得更复杂，人类的自然语言不是那么简单的，如果那么简单，那我们人类智商也太低了。我们可以知道火车和汽车不是同一类东西，知道一个东西是火车，那肯定不是汽车，这是不相交的，这就要引进否定，否定就不是前面的东西能搞定的，你可以加进来。然后你还可以有些存在的东西，比如说交响乐是包含乐章的大型管弦乐曲。交响乐是大型管弦乐曲，这里存在包含至少一个乐章的东西，所以这里面就说我要有这样的量词，要有一个量词来处理这个事。我直接加这个就可以了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicKq75cdUs4R02hSKFqcUUFMRVfaHRFCJ07VGXIib7oiaV52qK4al8D0iaXhsSSKZ8cKWMXdxibguCTbg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为什么还可以加量词和否定？其实你加进来的时候，每加一个东西，它表达的能力就会有所提升，推理的复杂度也会随之提升。表达能力和计算复杂度的权衡怎么做好，这是我们要考虑的，这里面很多坑，看起来很简单，但是做起来不是这么回事。你怎么做好权衡，特别是应用的时候，具体细节我不再介绍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;另外是规则，在公司很多人都非常苦逼的写规则，你不写智能就体现不出来，所以你必须不停地写规则。比如说沉积岩岩层越往下，形成年代越早。这时候写一个规则如果 A 是沉积岩，B 是沉积岩，A 在 B 的下面，A 的年代比 B 的年代更早。它可以否定，如果某个区域有断层，那就不适合修建水库，A 如果是断层，那就否定它不是做这个事情。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicKq75cdUs4R02hSKFqcUUFSp1Efjo4baaoZ429wOWUqX9oEfLwceEA5JApvgZvKv86vHJwSznjXA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们还可以做约束，一个地区不可能是平原又是高原。所以规则可以做很多事情，甚至可以做到前面说的事情，但是它的表述方式是不一样的。刚刚刘知远老师讲的还可以做关系补全的工作，因为刘老师普及了这方面的知识，我就不再介绍。我可以把知识图谱看成有向的带标签的图，我知道两个节点是不是有某个关系，就可以用一个算法或者表示学习的算法，然后判断出来这两个东西是不是有这样的关系。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicKq75cdUs4R02hSKFqcUUFnRL7iaAUVkxGX2icGcMqfNgGqtL3hHCibibbVkA5EFYyTMtMh6TaHx6u1g/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;br/&gt;比如说这么复杂的图，这个人和这样的词之间，这样的概念之间，是不是有关系，你想知道这个人和这个词有关系，你就要它们的边，然后来计算这种关系成立的概率有多大，这里用的就是 path ranking。这是统计关系推理很重要的一部分。我今天不可能列举所有的，我们还要处理各种空间的推理，像今天早上讲的时间、空间等维度的推理，这个东西很复杂，因为我们有很多推理的方式，我们做地理的题目麻烦的不得了，还有这种图，地图等等，这中间要标出来，各种国家、地区之间的位置关系等等，你都要标出来。我们可能要引入距离模型还有空间模型，可能还要有扩展表示的对象，我们可能要考虑动态对象，然后线和点，所以很多表示是很复杂的。空间类不讲太多。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicKq75cdUs4R02hSKFqcUUFiadQ0H9jBVhfXHN5sXH1tdemMJ0OmiacWOSVN0yOZcib1xOQWrj28ibL1w/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我具体讲一下推理的框架。比如我们做地理的时候，有一个地理知识库，我们有这个题目，题目也可以提取一些知识，然后生成一些知识库，先推空间推理，然后到规则，再做其他推理的事情。比如看到这个题目，我不知道有没有人有做地理试题的，可能高中很痛苦，看到这个有人都要流眼泪了。这个很复杂，首先要读图，读图以后再回答问题，图还分各种岩层，石灰岩、砂岩、页岩、沉积物等，比如这个层到下面去，因为有洪水，你读图要回答 ABCD 哪个是对的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicKq75cdUs4R02hSKFqcUUFMIwR7KpIfRbzpF8bOgsRBvfsAkpZdKbmCTIyrEHPhHZ2NCmV7hLwvA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们做这种事情要各种知识，比如要知道石灰岩是沉积岩，页岩是沉积岩，我要知道沉积岩同层形成年代一致，我们还要做图片的标注。我们现在是人的手工标，以后还有自动标注的方法，这就是目前所谓的深度学习的方法处理不了这种标注。我们要用各种方法来标，这涉及到图像理解。你要理解这个东西是什么，要理解它的方位等等。这是人标出来的，有这个东西还要形式化表示出来，页岩是沉积岩，石灰岩是沉积岩等，我们会做什么事呢？还要把规则写出来，就是这里的规则。完了以后我才能去到这里，上面是我从地理课本、各种百科里面拿出来的知识，下面是我从图片里面标出来的东西，把它放到临时的知识库里面。我会先对方位做推理，然后得到新的关系，岩层的上下位关系。我再扔回来，再扔到推理里面用规则推，就得到岩层 3 形成年代比岩层 2 更早，这就是我们前面的选项 A 就可以直接获取。&lt;br/&gt;&amp;nbsp;&lt;br/&gt;我们再看一个试题，这是 2016 年考试的题目，我们要知道在这个时间段，这个会在北京举办，前面是在哪里举办。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicKq75cdUs4R02hSKFqcUUFefprgPhwfbFX2XZDQiaxrPgk2icqXKiclDXNpJfAZPTROO2HLMxulva7Q/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然后读图，让我们回答这个问题，到底是 ABCD 哪个对。这里面我们又要把一些课本或者百科里面的知识拿出来，要有一些原则，比如说处暑是公历 8 月 23 日，华盛顿位于哪个区，还有一些规则，我们又要把它形式化出来，处暑我们就写成三元组的形式，时间段也要写出来，全部形式化出来。我们还要有些大于，时间大于什么时间，把这些拿出来，我们把它推理好。还要把规则形式化出来，然后我们把这些知识、规则用推理机跑出结论，然后把答案 A 给找出来，因为 A 说的是处暑和这个时间是相似的。我们用这种推理的好处是什么呢？我们是可以没错的，我们用这种知识图谱或者逻辑的推理，它和我们统计的，特别是深度学习也有推理，它的好处是我推出来的东西我知道它为什么是这样的，我可以知道它是用这些知识点，用了这个规则，把这样的新的事实给推出来，我可以告诉你，这个东西有什么用呢？非常有价值。假设这个东西做出来了，那么将来可以做什么？将来高考的辅导老师其实都没啥用了，因为我们可以搞在线教育，你学生到这里解题，解完以后还可以告诉你这个题目为什么这么解，这样老师就没有什么作用了。这是非常有用的，但是也不知道能不能做出来。&lt;br/&gt;&amp;nbsp;&lt;br/&gt;总结一下，知识图谱中本体和规则都是很有用的，我们可以推理出隐含的知识，可以检测一个知识图谱是不是有些逻辑的冲突。做搜索或者问答的时候，我可以用我已有的知识做各种查询，以及处理各种异常。为什么要处理异常，比如我刚刚说的火车和汽车是不相交的，但是知识不是永远是对的，随着时间的推移，保不准将来出什么交通工具，火车变成汽车，汽车变成火车，所以会有异常。将来的工作，我觉得还是要很多事情要做，比如地理知识怎么表示，空间知识怎么表示，空间推理怎么做，这都是非常困难的。而且目前空间推理这块是缺少比较好的工具。现在大家比较关注的是我们怎么把逻辑的推理和统计推理能够去结合起来，这当然也是陈华钧教授上午讲到的，深度学习的创始人 Hinton 等人也想这个事情，他以前做过很多工作，包括分布式表示、语义网络等，他在并行知识表示和推理上做得很不错，也许他设计深度置信网络（deep belief network）的时候就考虑到了语义网络跟神经网络的结合。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心原创，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Fri, 09 Sep 2016 12:31:02 +0800</pubDate>
    </item>
    <item>
      <title>前沿 | 如何避免机器人相撞？乔治亚理工要克服机器人的「被破坏妄想症」</title>
      <link>http://www.iwgc.cn/link/2623142</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自IEEE Spectrum&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Evan Ackerman&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：孙睿、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;乔治亚理工学院的研究人员在教机器人如何避免相撞。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_gif/KmXPKA19gW87xwIbibLI3Lwib1NkTnn1nktBuWcAGFVFN0IrWQibHgmiadpg3dmQ2YJIobZ2X6dmVfSEZchgAQ9KIw/0?wx_fmt=gif"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你还没注意到，那我要说，我们在这里是非常、非常支持尽可能地使用机器人的。作为记者，我们并不会真正思考不断增加机器人的后果，而如果不对此多加注意的话，就可能会由于机器人过多而产生各种问题。更糟糕的情况是，一堆机器人一天到晚都在试图避免彼此相撞，而没做任何有用的事情。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在乔治亚理工学院，Li Wang 与 &amp;nbsp;Aaron D. Ames 教授和 Magnus Egerstedt 就在研究如何能够让大量机器人一起工作，而不会相撞，或是挡住其它机器人的路。这对像我这样，有着 37 个 Roomba 自动吸尘器的人来说，真的是很重要的；而如果你能够想见未来路上满是自动驾驶汽车的情景，你也会认同这项研究的重要性的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最根本的问题在于机器人的「被害妄想症」。当机器人在四处移动的时候，出于安全的考虑，它们会保持一个基于传感器的「恐慌区域（panic zone）」，如果任何东西进入到这个区域中，它们就会十分害怕然后停止移动。如果只有两个机器人在行动，它们可以保持一个合适的距离，但是当机器人的数量增长，「恐慌区域」重合的概率也直线上升，而当这种情况出现的时候，大面积的机器人瘫痪也不远了。或者正如乔治亚理工的研究人员说的那样：「当机器人数量增长，且任务难度上升的时候，设计一个能够进行多任务处理的单一控制器就变得更加困难了，例如，形成各种形状、避免碰撞和维持网络连接。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;往常，机器人们使用不同的控制系统，来完成不同的任务。主控制器的主要工作就是让机器人做些事情，例如「走到那里去」，辅助控制器（secondary controller，也叫作安全控制器）用于保证机器人不会在主控制器运行的时候撞到其它东西。在多数情况下，安全控制器是被动运行的，但是当它认为情况危急的时候，它能够超驰主控制器。而当安全控制器总是超驰主控制器的时候，问题就产生了，因为机器人会忙于「保证安全」，从而无法完成原本的任务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW87xwIbibLI3Lwib1NkTnn1nkx4pq42xkJOxL8jJm2Qp0rezz68sGqpzicMOBkLu6MR3Ns3P7ZS9MX4A/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;来自瑞士的机器人制造团队 K-Team Khepera III 机器人是一个装有多个传感器的小型机器人&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了解决这一问题，乔治亚理工的这个团队研发了一种用于移动机器人的新型安全控制器，它能尽量避免影响主控制器的工作，也就是说，「只在碰撞、或失去连接的问题已经迫在眉睫的时候，才启动避让的行为。」（为了在真正的机器人群中测试他们的算法，他们使用了 Khepera III——一种瑞士公司 K-Team 生产的小型移动机器人。）在理想情况下，所有安全控制器在所有场景下都会依此工作，但是真正困难的事情是，在从原理上能够完成「多项必须达成的目标」的同时，能够「从原理上保证避免碰撞和维持连接。」「保证」和「从原理上」这两个词对控制器的使用者来说当然是好的，然而我想对设计者来说却十分令人头痛。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然而最终，乔治亚理工还是让这一切实现了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「一个拒绝独自行动的机器人」这句话，在我听来像是代码化的「难以预测的任性人类」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这项技术同样也适用于四轴飞行器。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;研究人员认为，这样的技术，在自动驾驶汽车与运输飞机越来越多的未来会更加重要。安全问题自然需要关注，但是如果机器人无法在保证安全的同时完成任务，那么不论我们拥有多少机器人，它们都不会有太大的用处。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心经授权编译，机器之心系今日头条签约作者，本文首发于头条号，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;</description>
      <pubDate>Fri, 09 Sep 2016 12:31:02 +0800</pubDate>
    </item>
    <item>
      <title>深度 | 李飞飞高徒Andrej Karpathy：计算机科学博士的生存指南（附博士论文）</title>
      <link>http://www.iwgc.cn/link/2612470</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Github.io&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Andrej Karpathy&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：孙睿、吴攀、李亚洲、杜夏德&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;近日，Open AI 人工智能研究科学家 Andrej Karpathy 完成在斯坦福的博士学位，其博士论文和他在博客上写的读博指导建议都获得了极大关注。机器之心编译了 Andrej Karpathy 就读斯坦福计算机科学博士学位的建议，希望对大家有所帮助。在文后机器之心也对他的博士论文进行了摘要翻译，读者们可点击阅读原文下载。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicxmPYrSYxsFzwwTibibQqW0NB5bGCKaXw8OKXN7e4v7Dd2TeS3NIDUu3Bdrlk3QCYJEcxtogrBFAYQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如今，我即将完成自己的 PhD 学位，我想要写一篇文章回顾自己的经历，希望这对你们有一些帮助。不像本科指导，博士指导要更加难写，因为一个人如何完成自己的博士生涯相比本科有更多的变化。因此，很多事情可能是有争议的，我熟悉的一些部分（计算机科学/机器学习/计算机视觉研究）会具体写一下。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;预热&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWicxmPYrSYxsFzwwTibibQqW0N0ApcUPwrIW7nseqAnod79LrwVjQ9wkzKbXQGlUGDHMbcia6Hsk9MGVQ/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先，你想要获得博士学位吗？在年轻的时候我就很幸运的明知我真的想要一个 PhD。不幸的是，我并没有经过深思熟虑：首先，我是真的喜欢学校和学习，我想尽可能多学一些东西。其次，我真的想成为游戏《半条命》里面的 Gordon Freeman 博士这样的人（从 MIT 获得理论物理博士学位）。我喜欢这个游戏。但在做人生决策时你更加敏感又会怎样？还会想要读 PhD 吗？（这里作者引用了自己在 Quora 上的回答，当时他在大公司的 offer 与读博之间做出的抉择。）我假设你正在考虑是否加入一个中型公司（大部分人都是如此），你可以问自己该公司是否有如下吸引力：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;自由&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。读博在你想要追求和学习的主题上能提供很大的自由度。你在被别人管着。当然，读博也会有导师加以约束，但很大程度上要比其他更自由。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;所有权&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。你做出的研究成果将会是你自己的，上面附属自己的名字。相反，在大公司内，「blend in」会很常见。常有的一个感觉是成为了「齿轮上的一个齿」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;排他性&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。很少有人单独成功做到顶级的博士项目。你将是加入一个由数百杰出个人组成的团队，相比于公司可能是数千人组成的团队。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;地位&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。不管是不是这样，向前进并最终获得博士学位在文化上是值得崇敬的，也是一项了不起的成就。你也将成为一个博士，这很棒。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;个人自由&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。博士生是自己的老板。今天想睡觉？可以。今天想溜号休假？可以。所有的一切就是最后的博士成果，没人逼你要朝九晚五。当然，一些导师在这方面有很大的灵活性，一些公司也会灵活一些，但个人自由确实是初级声明。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;最大化未来的选择&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。加入博士项目并不是关闭了一些出路或减少了未来职业/生活方式的选择。你可以选择走一条路（PhD→其他），但并不只是一条路可走（其他→PhD→学术/研究）。此外（尽管应用机器学习专业相当特殊），博士毕业生甚至博士退学生更可能被雇佣，很多公司也愿意将你安排到更有趣的位置或给你更好的起始薪资。更广泛的说，最大化选择是你未来可以遵循的一个很具启发性的方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;最大化你的转变&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。你还年轻，没必要这么着急进公司。一旦你从博士毕业接下来有 50 年的时间花费到公司。在你的人生经历中，选择有更多的转变。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;个人成长&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。PhD 是一段快速成长（学到很多）和个人自我发现（成为掌握自我心理状态的大师）的浓重经历。PhD 项目（特别是如果你能成功进入一个好的项目）也能频繁的为你提供机会，交往一些格外阳光的朋友。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;专业性&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。PhD 可能是你人生中唯一的机会真的深入一个主题，并在某些事情上成为世界上处于领导地位的专家。在没有分心与约束的压力下，探索人类知识的边缘。这是一件非常美好的事，如果你不同意这一点，这可能就是一个你不适合读 PhD 的信号。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;放弃&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。我也想说一下可能存在的消极面和失败模式。PhD 是一段非常特殊的经历，有大量的人会放弃。你将不可避免的发现自己做起来特别难（特别是该交论文之前）。你需要适应这些痛苦，并有足够的心理耐力和决心处理这些压力。有的时候你可能会过的不知道今天是周几，吃厨房的剩菜剩饭。在一个美妙的、阳光明媚的下午，翻动 Facebook 照片你发现朋友们拿着比自己多 5 到 10 倍的薪水享受着异国旅行，你要一个人坐在实验室精疲力尽。有时你会需要 3 个月的时间远离自己的研究，才能调整好健康的心态。在朋友们做着 TechCrunch 文章里面提到的创业时，或者在朋友们将产品推销给百万人时，你却挣扎着意识到几个月的研究花费到了一篇只有几个引用的论文上。你会经历自我认知的危机，怀疑生活中的抉择，想知道花费自己人生中最宝贵的时间正在做什么。最后，你应该相当确信，自己在追求科学研究与发现的路上，能够在无序的环境中成长、繁盛。如果你不确信，你会容易因是被而消极。在你决定读博之前，理想上你可以先在一个夏季研究项目上作为本科生尝试一下做研究。事实上，在 PhD 招聘期间，研究经验如此被看重的主要原因不是研究本身，而是博士生更知道自己正在做什么。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，我想到有人说如果你想进入学术圈就读 PhD。基于上面提到的，我认为 PhD 有强大的固有价值，PhD 本身就是一个目的（end），而不只是达到某个目的（比如，学术圈的工作）方式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;进入一个博士项目&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：推荐、推荐、推荐。好，你决定努力争取一个项目，现在就是如何进入一个好的 PhD 项目？第一等级的逼近方式相当简单，目前最重要的就是强有力的推荐信。理想场景是一个知名教授这样为你写推荐信，「xx 是曾与我一起工作过的学而生中的前 5 名，她积极主动，有自己的想法，并付诸实践。」最差的推荐信就是，「xx 上了我的课，做的不错。」来自夏季研究项目的你自己的学术著作是一个强有力的加分，但并不如你有强有力的推荐信。特别提醒：分数并不强相关，但你一般不太想分数太低吧。本科时这在我身上并不明显，因为我花费大量精力取得好成绩。只有可能就直接与研究有关（或者最低限度就是与个人项目有关），尽可能的多，也尽可能的早，如果可能也要得到多人指导（你需要 3 个以上的推荐信！）最后一点，突然的纠缠未来可能成为你导师的人不会提供任何帮助。他们总是非常的忙，如果你想在回忆上或者通过邮件强势的接近他们，想要给他们深刻的印象，这可能反而会激怒他们。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;选择学校&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。一旦你进入一些 PhD 项目，然后如何选择学校？很简单，斯坦福啊！开玩笑啦。严肃的说，梦想中的大学是首选（不是因为它看起来对你的履历/简历好，而是因为它的反馈环路。顶级学校也吸引其他顶尖人才，你可以跟其中的很多人相识、一起工作。）。第二就是有一些想要一起工作的导师。我说「一些」导师是很认真的，如果首选因各种原因无法达成，比如因理想教授离职、搬走或自然死亡而脱离了掌控，多一些导师选择对你而言很重要，也是一种安全保障。第三，选择一个好的物理环境，我认为新生不够注重这一点：你将花费生命中最好的 5 年时间生活在校园之中。相信我，这是相当长的时间，而且生命中不只有研究。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;导师&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicxmPYrSYxsFzwwTibibQqW0Ns3D58JicJvQvqXBicDNR68VK57g8CeuU19H0ZXsD3g7t8kOhub2n0ia7g/0?wx_fmt=gif"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;导师关系&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。导师是极其重要的人，会对你的博士生涯产生重要影响。理解这个关系的本质是很重要的：导师与学生之间是一种共生关系；你有自己的目标，想在博士阶段出些成果，但是导师也有他们的目标、约束，他们也要考虑自己的职业发展。因此，理解导师的激励机制是很有好处的，包括任职期间如何工作，这个职位的评估标准，他们如何获取经费，他们可能牵扯进了什么样的系内政治，他们如何拿奖，学术界通常是怎么运作的，还有尤其是他们如何获得认可和同事的尊重。这有助于避免或减轻与导师之间的摩擦并允许你进行适当的规划。我也不想让这种关系听上去更像是一种交易。导师与学生之间的关系不应该只是事业发展，而往往是一种持续的、可预测的关系。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;re-tenure 与 post-tenure&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。每位导师都不同，所以理解 tenure-track 的变化和他们对你博士生涯的影响也是很有帮助的。送上一条经验法则（记住也有很多例外），无论你的导师是处于 pre-tenure 还是 post-tenure，紧跟他的职业轨迹非常重要。通常情况下，年轻一些的教员常常比较多，级别也更低，但是他们也会对你的科研任务施加更强烈的建议，和你一起工作，抛出具体的想法，甚至会帮你检查代码（这是好事）。跟着这样的导师，更实际一些，课业也会更紧，因为他们需要发表很多质量不错的论文来获得 tenure，他们有动力推动你一样努力工作。相比之下，级别更高的教员或许有更大的实验室，除研究之外会有其他方面的优势（比如，委员会，讨论会，游学），这意味着，他们在学校里只能处在更高级别的职位，无论是在他们的研究领域，还是在监督学生上。讽刺的是，这就是「你在这个方程中漏掉了一个术语」和「你在这个领域还要多读些资料，和这个或那个人聊聊，这样或那样兜售你的成果」之间的区别。在后一种情况中，低水平的建议仍然来自于实验室里高年级博士研究生或者博士后。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;除了tenure 之外的其他变化&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。还有很多需要注意的变化。一些导师比较随意，另一些对待师生关系则比较专业谨慎。有些人会试图影响你的工作细节，有些则会放开手让你自己去做。一些会专注研究特定的几个模型及其在不同任务上的应用，而另一些则专注于任务不在意建模方法。从管理上看，有些导师能一周（或天！）见上几次，有些几个月都见不到人。一些导师会快速回复邮件，而另一些一周都不会回（甚至更长，哈哈）。一些导师会要求你给他一个时间表（比如，你最好能长时间工作或者周末工作）而另一些不会。一些导师慷慨地支持他们的学生，给学生配设备，还有一些认为有台笔记本或旧台式电脑就可以了。一些导师会资助你去参加会议，即使你没有投论文，有些则不会。一些导师是企业家类型的或者偏向应用，一些则更倾向于理论工作。一些会允许你暑期实习，另一些则认为实习会分心。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;选导师&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。所以导师该怎么选呢？首先要和他们单独面谈。师生关系有时可以比喻成婚姻，要确保你们合得来。当然，首先你得确定你能和他聊天和他相处，不过相对于前述的 Tenure，要明白导师仍旧是教授，尤其是否能与你在你感兴趣的问题上产生智力共鸣。这比他们采取哪种管理方法更加重要。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;收集资料&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。你也应该收集一下心仪导师的资料。和他们的学生聊聊。如果你想得到有用的消息，这件事在正式场合下一定不能做，只能在轻松的场合（比如聚会）下问问未来的学长学姐。很多情况下，学生一般不会直接说导师不好，但是如果你问他具体的问题，他通常会真实的回答你，比如，你可以问「你们多久见一次面？」，或者「他现在有什么职务」。另一个策略是看看他之前带出来的学生最后都怎么样了（你可以在网站上找到），这样你就大概知道自己以后的去处了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;给导师留下印象&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。导师学生互选过程有时可以比喻成婚姻，你选他们，他们也选你。他们认为理想的学生是有兴趣有激情的，自律能力强，不需要手把手教，主动性强，一周内不仅能完成导师布置的任务还能自己有所拓展；用意外的方法改进结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;要考虑整个实验室&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。另一个重点是要意识到你会一周见导师一次，但是同门每天都能在实验室里见到，他们会成为你最亲密的朋友。在大多数情况下，你最后会与一些高年级博士生或博士后合作，他们的角色会非常类似你的导师。尤其是博士后，他们可能是未来的教授，他们也渴望和你一起工作，这样能积累带学生的经验。因此，你要确定整个团队中能有合得来的人，你尊重的人，还有你能亲密地做研究项目的人。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;研究主题&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicxmPYrSYxsFzwwTibibQqW0NZpgQcyjRwK3NXVQ5PULkQDAPCSSSnYM23hv0OMPmziaXuXXdfKH7W5Q/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;人类一小部分知识的 t-SNE 可视化。每一个圈圈都是一篇 arxiv 论文，大小代表参考文献的数量。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以，如果你进入博士阶段，并找到一名导师。如何开展下去呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;外围的锻炼&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。首先注意博士阶段的性质，一个博士学位读下来有苦有乐，因为你会不断接触到元问题（meta problem）。你不只是在解决问题——这仅仅是你要做的分内事。你的大部分时间要花在外围上，找出什么问题是值得解决的，什么问题已经成熟到可以解决。你要持续想象自己在解决假设问题，问自己处在什么位置，这个问题能打开什么，或者是否有人关心你研究的问题。如果你像我一样，就会有点疯狂，因为你在花大量的时间在做你甚至无法确定是否正确，也不知道能不能解决的事情。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;研究品味&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。当你选择研究问题时，你会听到学术界讨一个神秘的概念「品味（taste）」。它一个实实在在的东西。当你向导师提出一个潜在的问题时，你可能会看到他们扭曲的脸，瞪大的眼睛，注意力飘忽的表情，或者当他们思考未知领域亟待探索时，你能感受到他眼神里的兴奋。在你抛出问题的瞬间发生很多事情：评价问题的重要性、难度、吸引力，它的历史语境（可能也会考虑是否能得到补助）。换句话说，你的导师是外围问题大师，在判断问题上品味很高。在博士阶段，你也会慢慢获得这方面的悟性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我想过去我这方面的品味不太好，从我早期的博士笔记中就能看出来。当时令我兴奋的很多问题现在回想起来在构思上都不够精巧，难以下手，相关性也不强。经过实践和学习后，我的品味才得到提升。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我来试着总结一下关于怎样培养品味的思考，以及怎么让问题有趣地研究下去。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;一个丰饶的领域&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。首先，要意识到在你的博士阶段你会深入某个领域，你的论文很有可能进入研究链的顶端，自成体系（成为你的 thesis）。因此，选择一个问题时，你应该多往前思考几步。预测事情怎样进展不太可能，但是你能感知到你还有多大的研究空间。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;配合导师的研究兴趣和研究长处。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;你会想要直接进入导师研究兴趣的领域。一些导师或许会只允许你进入边缘地带，但是这样你就不能全部利用他们的知识，他们就不太可能想帮助你的项目或促进你的工作。例如，（这是我以前的想法）每位导师在研究上都有一个通用的幻灯片模板，如果你的研究成果够前沿，能被添加到那个幻灯片模板中，你就会发现导师对你的研究投入更多了，给你的帮助也多了。此外，他们还能帮助推广和公开你的成果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;要有点雄心&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;：在努力这件事上要做到收放自如&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。人的心理都有个奇怪的 bug： 10 倍的重要或影响的问题在直观感觉解决起来就需要 10 倍的努力。这是个错觉——我的经验是 10 倍重要的问题，至多需要 2 到 3 倍的努力就行了。事实上，在一些情况下，一个 10 倍困难的问题解决起来可能更容易。为什么？因为你会有 10 倍的动力走出自己的黑箱，看到方法真正的局限性。从首要原理（first principles）开始思考，改变全部策略，继而创新。如果你渴望做出 10% 的改进并且很努力，你就会成功。但是如果你渴望做出 100% 的改进，你仍然很有可能成功，但会以一种非常不同的方式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;雄心但也要能解决&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。在这一点上，需要指出的重要一点是有很多重要的问题无法做成大项目。我推荐阅读 Richard Hamming 写的一条博客：你与你的研究（You and Your Research），这里面探讨了这个问题：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;如果你研究的问题不重要，你也就很有可能无法做出重要的成果。这是十分明显的。伟大的科学家会深思熟虑他们领域内的许多重要的问题，而且他们会密切关注、仔细琢磨如何攻克它们。让我警告你，「重要的问题」必须小心谨慎。当我在贝尔实验室的时候，物理学的三大突出问题在一定意义上都没有得到过研究。这里所说的「重要」是指肯定能得到诺贝尔奖和任何数量你想要的资金。我们不研究 1）时间旅行，2）物质传输，3）反重力。它们并不是不重要，而是因为我们无力解决。决定一个问题是否重要并不是因为结果，而是你可以合理地解决。这才是使一个问题重要的原因。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;做到 X 的人&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。最后，PhD 的目标不只是成为某个领域内的深度专家，而且还要在这个领域打上你的烙印。要引导它，塑造它。理想的情况是：当你的 PhD 阶段结束时，你已经在一个重要领域赢得了自己的一席之地，最好是一个可以容易和快速地描述的领域。你想听到人们说「她就是那个做到 X 的人」这样的话。如果你能填补一项空白，你就是成功的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;有价值的技能&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。认识在到读博期间你将成为所选择的领域内的一名专家（撇开兴趣不谈，5 年×每年 260 个工作日×每天 8 个小时是 10,400 小时。如果你相信 Gladwell，PhD 正是需要大量的时间才能成为专家。）所以，想一下 5 年后你成为了这个领域的世界级专家（不论你的研究的学术影响，1 万小时将保证这一点。）拥有这些技能是不是很振奋？或者对你未来的职业足够有价值？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;负面例子&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。也有一些难题或者论文类型你理想上想要避免。例如，有时你听到学习界讨论「增量工作（incremental work）」（这简直是学术界最糟糕的形容）。增量工作是指一篇论文通过使其更复杂并在一些基准上得到 2% 的额外增分，从而增强了一些已有的事情。这些论文的可笑之处在于有很高的机会会被接收（评审员没有拒绝这些论文的理由；有时它们也被称为 cockroach paper），所以你有这样的一系列论文被接受，你可以感觉自己非常高产，但事实上这些论文不会有很高的引用，你也不会在该领域有很高的影响力。类似的，寻找研究工程不能只理想的考虑「有这样一个下一步逻辑步骤还没有人做，让我来做」，或者「这应该是一个非常简单的 poster。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;案例学习&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;：我的主题&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。为了更详细的讨论这个话题，我打算使用自己如何展开 PhD 作为例子。首先，有趣的事实：我的整个主题都基于 PhD 期间一年半的研究。也就是，它花费了我相当长的时间在元问题空间（metaproblem space）不断摇摆，然后才找出了一个我感觉令我振奋的问题（其他两年我大部分是做 3D，比如 Kinect Fusion、3D 网、点云特征（point cloud features）、还有视频方面的工作）。然后在我读博第三年，在某个周六的下午两点，我来到了 Richard Socher 的办公室。我们闲聊时我意识到他在图像和语音上研究的一些问题事实上非常的有趣（当然，图像和语言交叉的这个领域在 Richard 之前就有了。）我难以看完所有需要查看的论文，但该领域看起来相当有前途：该领域相当的富饶（大量未解决的难题，在对图像进行基础描述尚有大量的可能性。）我认为这相当的酷，也很重要，也很简单去解释，看起来它处于成为可能的边缘（深度学习也只是刚开始有效），数据集也刚开始变得可用（Flickr8K 也刚出现）。这刚好满足李飞飞的兴趣，即使我没有成功，我至少得到了大量的时间，优化了我可能用于其他领域的有趣的深度网络。当所有事在我脑海中出现的时候，我强烈感觉到一股海啸。我把这个主题在第二天投给了导师李飞飞，感觉松了一口气。她热情澎湃地通过了，给予我鼓励。而且在接下来的工作中指导我，（例如，在我满足于排名的时候，飞飞坚持让我做图像语句生成。）后续的发展让我很高兴。简言之，我游荡了近两年才发现要深入的领域。给予数个启发方法，一旦我发现我要做什么，我就深入地去做。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;阻力&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。我还想提一下你的导师绝不可能是一贯正确的。我已经见过或听说过很多实例了，现在回想起来，导师应该为错误负责。如果你在读博士时觉得导师错了，有时候你应该鼓起勇气忽略导师的看法。学术界普遍赞赏独立思考，但你特定导师的回应可能会随着环境发生变化。我就知道一些赌一把最后得到了很好结果的例子，而我个人也经历过一些效果并不好的例子。比如说，在我第一年的时候，我坚决不同意吴恩达给我的一些建议。我最后开始研究一个他并不非常感兴趣的问题，但让人惊讶的是，事实证明他是非常正确的，而我则浪费了几个月时间。吃一堑长一智嘛 :)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;不要耍滑头&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。最后，我要让你认为 PhD 不只是一连串的论文。你不是一个论文写手。你是科研界的意愿，你的目标是推动该领域向前发展。论文是其中一种常见的做法，我建议你不要把目光放在已有的学术领域内。首先为自己想想，做一些其他人没有做但应该做的事，远离别人在你之前已经做出的成果。在我的整个 PhD 阶段我一直在尝试这么做。这个博客就是一个例子——这让我可以谈论一些通常不会发在论文里面的东西。ImageNet 人类推理实验就是一个例子——我强烈地认为，在 ILSVRC 上知道人类大致的准确度对该领域来说是非常重要的，所以我花了几周时间对其进行了评估。学术搜索工具（如 arxiv-sanity）也是一个例子——一直以来我都为论文文献搜索的低效性感到沮丧，所以我发布并维护了这个站点以便对他人有所帮助。两次参加 CS231n 教学也是一个例子——我在上面花了大量的精力，超过了一个应该做研究的博士生的合理程度，但我认为如果人们不能有效地学习这个主题和进入这一领域，这一领域的发展就会受到拖累。我的很多博士阶段的工作都很有可能会牺牲一些标准的学术指标（如 H 指数或在顶级会议上发表的数量），但我还是做了那些事情，我还会同样地再做那些事，在这里我也鼓励其他人也这么做。这可能言过其实了一点，除却思想观念上的一些东西，根据过去我与朋友和同事一些讨论，我知道这个观点是存在争议的，而且很多人也并不认同。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;写论文&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicxmPYrSYxsFzwwTibibQqW0N3IjbuEkbQPpxGzDcs0KUHfSHY8r69TV03HWSpf3wBiav3WRRQLDibemA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在学术界，能写好论文是一项关键的生存技能（就像是生火技能对穴居人一样）。特别地，很重要的一点是要意识到论文是一种特别的事物：它们看起来有一定的形式、以一定的方式流动、有一定的结构、语言以及其他学者所期望的统计数据。对我来说，查看我博士早期阶段的论文真是一种痛苦的历练，因为它们实在太糟糕了。在这方面有很多东西需要了解。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;查阅论文&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。如果你正在学习写更好的论文，阅读许多好论文并提取出其中的模式似乎是一个明智的选择。但事实证明这并不是最好的策略；这就好像是对于一个二元分类问题只接受正面的样本一样。你真正需要的是查阅大量糟糕的论文，其中一种方法是评阅论文。大部分好的会议的论文接收率大约为 25%，所以你查阅的大部分论文都很差，这让你可以构建一个强大的二元分类器。你可以阅读一篇糟糕的论文，看它的描述有多么不清楚，或者它如何没有定义自己的变量、摘要介绍有多模糊、或者它如何过快地深入到了细节之中——你可以学习让你的论文不落入同样的陷阱。另一个相关的有价值的经验是参加（或组织）读书俱乐部——你将看到经验丰富的研究者批评论文，并且了解自己的论文将会被其他人怎样分析。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;格式正确&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。我清楚地记得有一次和飞飞参加一次审阅会议。我在前面的几个小时里只评阅了 4 篇论文，而她拿起这些论文，每篇只翻了 10 秒钟就说其中一篇很好，其它都很糟糕。确实如此，我也接受了这一篇并拒绝了其它三篇，但这项花费我几个小时做成的事她只用几十秒就完成了。飞飞是将论文的格式作为强大的启发线索的。随着你变成越来越资深的研究者，你的论文将有一种特定风格的外观。一页引言/介绍。一页带有合适密度引用文献（不过于稀疏也不过于密集）的相关成果介绍。一张设计良好的 pull figure（在第一页或第二页）和系统图（在第三页）——不要用 MS Paint 制作。描写技术的章节在某个地方有些数学符号、带有大量数字的结果表（其中一些是粗体）、一个额外的聪明的分析实验、而且论文正好有 8 页（页数限制）且一行不少。你将不得不学习如何为你的论文赋予相同的格式，因为许多研究者在评价你的成果时都将其作为认知的捷径。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;确定核心贡献&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。在你开始写任何东西之前，首先很重要的是要确定你的论文对该领域的一个单一的核心贡献。我会特别强调其中的单个词。一篇论文不是你运行的一些实验的随机集合的报告。论文的目的是给出一个之前并不存在或并不明显的单个事物。你必须认为这个事物是重要的，它之前从未被完成过，然后你通过实验的方式在有对照组的环境中证明它的优点。整篇论文都应该围绕这一核心贡献精准地展开。尤其是不要有任何额外的无价值的扩展，也不要裹带任何其它东西。举一个具体的例子，在我早期的一篇关于视频分类的论文（Large-scale Video Classification with Convolutional Neural Networks）中我就犯了这个错误，我尝试一次打包两个贡献：1）一个用于视频卷积网络的架构布局集合，2）一个不相关的带有很小改进的多分辨率架构。我把它加上去是因为我觉得一是也许有人会对此感兴趣然后跟进后续研究，二是因为我觉得论文的贡献越多越好：两个贡献好于一个贡献。不幸的是，这是一个非常彻底的错误。第二个贡献是微不足道的/可疑的，它稀释了这篇论文，分散了注意力，而且也没人关心。在我 CVPR 2014 的一篇论文（Deep Visual-Semantic Alignments for Generating Image Descriptions）中我又犯了类似的错误，我在该论文给出了两个没有关联的模型：一个排序模型和一个生成模型。我可以举出一些好的论据来证明我应该分开发两篇论文；只些一个贡献的原因更多是历史上的，而非理智上的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;结构&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。一旦你确定了你的核心贡献，就有了一个写论文的默认配方。上层结构默认的是引言/介绍、相关工作、模型、实验、结论。当我写我的引言时，我发现可以以相关评论的形式写下一些条理分明的顶层叙述，然后再填写下面的文本，这会很有帮助。我喜欢围绕单个明确的点来组织我的段落，并且这个观点在第一段就会给出，并用该段的剩下部分来支撑这个观点。这样的结构可以让读者轻松地快速略览。然后我们需要一个好的思维流程，可以按以下线索进行：1）X（如果不明显，还要加上对 X 的定义）是一个重要的问题；2）核心的挑战是什么，2）X 上之前的成果已经用 Y 解决的问题，而这一次的问题是 Z；3）在这项工作中，我们做了 W(?)；4）这有以下有吸引力的特性，我们的实现表明了什么。你可以稍微调整这个结构，但这些核心的点需要得到明确。再重申一下：论文需要围绕你的确切贡献精准地进行组织。比如说，当你罗列挑战的时候，你需要确切列出那些你将在后面解决的问题，而不要牵扯到你做的与之无关的事情上（你可以在后面的结论中多做一点推测）。不只是在引言中，保持论文整体的合理结构也是很重要的。比如说，当你解释你的模型时，每一节应该：1）解释清楚在这一节做了什么，2）解释核心挑战，3）解释基本方法或之前其他人做了哪些工作，4）解释你的动机和你所做的工作，5）描述它。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;打破结构&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。你也应该灵活应对这些格式，扩展你的论文，为之增加一点香料。比如说 Razavian et al. 的这篇论文（CNN Features off-the-shelf: an Astounding Baseline for Recognition）惊人地将引言做成了一位学生和教授的对话形式。这做得很聪明，我很喜欢。另一个例子，Alyosha Efros 的很多论文都带着一种俏皮的语气，为有趣论文的书写给出了绝佳的案例。比如说他与 Antonio Torralba 合著的这篇论文《Unbiased look at dataset bias》。另一种我见过的效果不错论文是问答式的章节，可能用在附录中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;常见的错误&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：洗衣清单（laundry list）。洗衣清单是应该避免的一种非常常见的错误，它看起来像这样：「这里有一个问题。现在为了解决这个问题，我们首先做 X，然后我们做 Y，再做 Z，之后再是 Y，就得到了我们的结果。」你应该竭力避免这种结构。每一个点都应该得到证明、给出动机和解释。为什么你要做 X 或 Y？有没有替代选择？其他人做了什么？可以说这样的论文很常见（如果可能的话我倒愿意给出例子）。你的论文不是一份报告，不是你做过的事情的枚举，也不是你的按时间排列的笔记和实验的某种格式化的翻译。论文是对于一个问题、你的方法和其背景的高度处理过的和高度聚焦的讨论。它应该能教给你的同事一些东西，它必须要能证明你的步骤，而不只是描述你做了什么。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;语言&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。随着时间的推移，你会积累一个写论文时的好词词典和坏词词典。具体可以机器学习或计算机视觉论文为例：在你的论文中永远不要出现「study」和「investigate」（这是无聊的、被动的、糟糕的词）；而你应该使用「develop」或甚至「propose」这样的词。你不要提出一个「system」或甚至更糟的「pipeline」；相反，你开发了一个「model」。你不是在学习「features」，你是在学习「representations」。而且上帝保佑，你千万不要使用「combine」、「modify」或「expand」。这些多余的、粗陋的术语肯定会让你的论文被拒 :)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;提前两周的内部截至时间&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。并没有许多实验室这样做，但幸运的是飞飞对这个提前两周的内部截至时间限制很是坚定，在这个时间，你必须提交至少 5 页带有所有最终实验的草稿（即使不是最终的数字）；这份草稿会进入一个与外部完全一样的内部评审过程（具有相同的评审表等等）我发现这种做法非常有用，因为这会迫使你思考整篇论文的布局，从而总是能让你彰显出一些你必须为这篇论文的思路而运行的关键实验，并让论据思路条理清晰、连贯和有说服力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;关于这一主题的另一个好资源是 Jennifer Widom 写的《Tips for Writing Technical Papers》&lt;/span&gt;&lt;span&gt;（https://cs.stanford.edu/people/widom/paper-writing.html）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;写代码&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWicxmPYrSYxsFzwwTibibQqW0NuoKC35qos7b5Oz5vg2tUa2KDXbm3YLVeiciavjK9pukicV9iacvAqU4wqQ/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当然，你仍旧会花很多时间在实现你的想法上，也就是说，你还会编写很多代码。因为这并不是学术上独有的工作，所以我不会在此详谈，但还是有几点我想提一下。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;公开你的代码。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;虽然你可能会感到惊讶，但是你确实可以不发表论文也不公开代码。同时，你有很多动机将自己的代码藏起来：写代码会花费许多时间（研究项目的代码看起来像是意大利面，因为它的迭代非常快，所以你需要经常进行清理）；同时，光是想到别人可能会对你的代码评头论足，就已经足够吓人了，维护代码以及回答别人（永远会有）的问题是非常痛苦的，你甚至会担心别人可能会发现代码中的错误，从而减弱了研究的可信度。然而，这正是你应该发表代码的原因之一：为了避免尴尬的情况发生，你会不断采用更好的编码习惯（而这最终会帮你节省时间！）；你会被迫使学习更好的工程实践；你会被迫使对自己的代码更加严格要求（例如，编写单元测试以最小化错误出现的可能性），这一切都将让你的研究受到更多关注（并由此带来更多的引用次数），并且很自然地，你的研究也将对之后的研究更加有用。当你真的准备发表代码的时候，我建议你好好利用 docker containers（https://www.docker.com/）&lt;/span&gt;&lt;span&gt;；它会减少人们发邮件来问你要附件（和它们的各种版本），从而减轻你的烦恼。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;为将来的你着想&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。为了你自己的便捷，务必将自己的所有代码妥善记录，我保证几个月之后你会回来看你的代码（例如，为即将发表的论文再做几个实验），那时，你会一头雾水。我已经养成了为（自己的）每一个版本编写非常详尽的 readme.txt 文件的习惯，以便未来的自己能够明白代码的原理和使用方法等等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;做演讲&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWicxmPYrSYxsFzwwTibibQqW0NQSkUs043uxyRdNaTq0mpvbdbgFJQKqoLytBwxQqc4BDD4hz80Ez4cA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在，你的论文成功发表了！你需要就这篇论文向许多观众进行几分钟的演讲——它应该是什么样的？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;演讲的目的&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。首先，一个常有的误解是，演讲的目的是向听众介绍你在论文中做了什么。这是错误的，这一目的最多也只能排在第二或第三位。你的演讲应应该：1）使听众对你研究的问题产生浓厚兴趣（如果大家对问题本身没兴趣，他们也不会在乎你的解决方法的！）2）教些东西给听众（理想的情况是在让大家体验你的思考 / 解决方案的时候，不要害怕在别人的相关工作上花时间）以及 3）有趣（否则很多人会开始刷 Facebook）。理想情况下，在演讲结束之后。你的听众中应该有人在想这几件事情：「哇，我要换个研究方向」，「我一定要看看这篇论文」，以及「作者本人对整个领域的理解非常出众。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;一些可以做的事情&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：有些特征会让演讲更上一层楼，例如，要：有许多图片。人们喜欢图片。录像和动画应该更少一些，因为它们容易让人分心。要让演讲内容高度可执行——将一些人们在听到之后可以马上动手去做的东西。要：如果可能的话给一个 demo，它会让你的演讲更容易被记住。要发展一个你的研究涉及到更广泛的领域。要讲成一个故事（人们喜欢故事）。要引用，引用，引用——很多应用！加入引用不会占用你的幻灯片多大的空间，而你的同行们会因此感到高兴，并且认为你是一个十分谦虚的人，因为你意识到自己的贡献是建立在他人的许多成果之上的。你甚至可以引用在同一个会议发表的文章，并为之做简短的推荐。要进行练习！先自己练习，然后向同事 / 朋友展示。这常常会帮你发现许多叙述和流程中的重要问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;不要加很多文字&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。不要让文字挤满你的幻灯片。你应该少用甚至不用重点标识——演讲者们有时会使用重点标识来提醒自己要讲些什么，但是幻灯片不是给你自己看的，而是给观众看的。重点标识应该出现在你的演讲笔记中。于此类似地，尽可能地避免使用复杂的图表——你的听众是有固定带宽的，并且我保证那些在你看来十分熟悉且「简单」的图表，对于那些第一次看到的人来说，就不是这么好理解了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;注意，结果表&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：不要使用信息十分密集的表格来展示你的方法有多么优秀。既然你已经写了篇论文出来了，我相信你的结果至少是可靠的。我一致认为这一部分是非常无聊和无用的，除非数字能够表明一些（与证明你的论文无关的）十分有趣的东西，或者数字所表明的差距确实非常巨大。如果你真的要展示结果或图表，请循序渐进地将它们展示出来，而不是把所有东西扔到页面上，然后在一页幻灯片上花上三分钟。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;陷阱&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;：无聊与困惑之间的微小距离&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。如果你听众中的许多人都抱着一种学习的心态而来，要设计出一个好的演讲不是那么容易的。一个常见的失败案例是（作为一个听众），在演讲的前半段无聊至死，然后在后半段困惑不已，最后啥都没学到。经常出现这一情形的演讲的特点是，摘要非常概括性（过于概括了），然后紧接着技术（过于技术的）详解。尝试在你的演讲中规避这一倾向。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;陷阱：超时&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。许多演讲者会在开始的部分花费过多的时间（一般来讲这也会使得演讲变得无聊），然后火急火燎地了解最后的几张幻灯片，而那些往往是最有趣的结果、分析或 demo。不要做这样的演讲者。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;陷阱：形式化的演讲&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。我可能是个特例，但是我一直都喜欢挑战传统的、规避形式化的演讲。例如，我鄙视在幻灯片中加入演讲大纲的行为。因为这使得整个演讲变得无聊，就像在说：「这部电影讲述的是一个有魔力的戒指，在第一章我们会看到一个霍比特人得到这个戒指，第二章我们会看到他去了 Mordor，第三章里他将戒指扔到了 Mount Doom 并将之毁坏了。我将从第一章开始讲起」——拜托别这样！我只在非常长的演讲中才使用大纲页面，以便于听众在走神之后重新恢复记忆（30 分钟后他们往往会走几次神），但是这应该尽量少用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;观察并学习&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。最终，成为一个优秀演讲者的最好方法是（写论文也是这样），留意观察优秀的（和不怎么优秀的）演讲者的行为，然后在你的大脑里构建一个二元分类器。不要仅仅做演讲的听众；你要对它们进行分析、分解、然后从中学习。除此之外，留意现场反应。有时，当演讲者展示出一个复杂的数字表格时，你会注意到，许多观众立马低头看起了手机。为可能导致这一场景的行为构建一个内部分类器，并在你自己的演讲中避免这些行为。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参加会议&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWicxmPYrSYxsFzwwTibibQqW0NloYZbDa6XG5pGz9AhD6t98onrVtddQnP0Xz6Ow9DV1jn8KWntOvgFQ/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于会议：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;参加。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;参加会议是很重要的，特别是你所在的领域的最顶尖的 1-2 场会议。如果你的导师缺乏资金，不愿意为你的路费买单（例如，当你还没有论文的时候），那么你应当愿意自己买单。这是很重要的，因为你需要成为学术圈的一员，并能够见到更多同僚，以及了解研究话题的八卦。科学界可能有一些极少数的单打独斗的人，但是真相是，做研究很大程度上是一个高度社交性的事业——你是站在许多人的肩膀上的，且还有许多人和你一起努力，并且这些人也是你的论文的阅读者。此外，我很遗憾这么说，但是每一个领域都有一些没有出现在论文里、但是在整个圈子里广为流传的知识，包括接下来的重要话题有什么，哪些论文是最有趣的，论文的内线消息是什么，他们之前是如何发展的，哪些方法管用了（不是在论文里，而是在实际中），等等等等。成为圈子里的一员，并且了解这个集体中的共识，是很有价值的（并且很有趣！）——首先从中学习，然后最好能够影响这个圈子。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;讲座&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：根据演讲者进行选择，我使用的一个会议技巧是，在选择讲座的时候要看演讲嘉宾，而不是讲座主题（这是一项技能，慢慢地你会发现有价值的人），并且，根据我的经验，我发现亲耳听这些人演讲会大有裨益，尽管话题甚至和你的研究领域没有直接联系。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;真正有价值的信息可能在走廊上&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。现在，创新的速度（尤其在机器学习领域）已经比会议的间隔时间要短了，所以你在会议看到的大部分论文实际上都算是旧新闻了。因此，会议更多地是一项社交活动。与其参加一个讲座，我建议你把去走廊转转作为一项主要活动。你还可以去海报宣传去逛逛，说不定会发现一些错过的有趣论文和想法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;据说一个博士生有三个阶段。在第一个阶段，一篇相关论文的引用你大部分都没看过；在第二个阶段，你能认出这些论文；在第三个阶段，你已经与所有论文的第一作者喝过一圈了。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;最后的一些想法&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尽管我现在找不到出处了，但是我曾听到 YC 的 Sam Altman 说，建立一个创业公司没有捷径可走。你不能指望通过玩弄体制，或者通过伪装来获得长久的胜利。我想在学术领域也是一样的。最终，你的目的是用优秀的研究推动这一领域的进步，如果你试图针对某些指标动手脚，从长远来看你无法成功。在学术界尤其如此，因为学术界令人惊讶地小，并且高度关联，所以，任何你试图在学术履历上用点阴招（例如，常常自己引用自己、将同一想法稍作修改后重复发表、重复提交被退回的论文而没有丝毫修改、为了自己的便利而抛弃一些基本原则，等等）最终将让你尝尽苦果，而你也不会成功。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以，总而言之就一句话：好好工作、适当交流，人们会注意到你，好事也会发生。祝博士之旅愉快！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;论文：连接图像与自然语言（CONNECTING IMAGES AND NATURAL LANGUAGE）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWicxmPYrSYxsFzwwTibibQqW0NcD1jPRoNpwbrtxaVGmtNaMnx5vTIluH24mvvrib9lQ7ukRCbo8xP6Og/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;导师审核&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要&lt;/span&gt;&lt;strong&gt;&lt;span&gt;：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;人工智能领域的一个长期目标是开发能够感知和理解我们周围丰富的视觉世界，并能使用自然语言与我们进行关于其的交流的代理。由于近些年来计算基础设施、数据收集和算法的发展，人们在这一目标的实现上已经取得了显著的进步。这些进步在视觉识别上尤为迅速——现在计算机已能以可与人类媲美的表现对图像进行分类，甚至在一些情况下超越人类，比如识别狗的品种。但是，尽管有许多激动人心的进展，但大部分视觉识别方面的进步仍然是在给一张图像分配一个或多个离散的标签（如，人、船、键盘等等）方面。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这篇学位论文中，我们开发了让我们可以将视觉数据领域和自然语言话语领域连接起来的模型和技术，从而让我们可以实现两个领域中元素的互译。具体来说，首先我们引入了一个可以同时将图像和句子嵌入到一个共有的多模态嵌入空间（multi-modal embedding space）中的模型。然后这个空间让我们可以识别描绘了一个任意句子描述的图像，而且反过来我们还可以找出描述任意图像的句子。其次，我们还开发了一个图像描述模型（image captioning model），该模型可以根据输入其的图像直接生成一个句子描述——该描述并不局限于人工编写的有限选择集合。最后，我们描述了一个可以定位和描述图像中所有显著部分的模型。我们的研究表明这个模型还可以反向使用：以任意描述（如：白色网球鞋）作为输入，然后有效地在一个大型的图像集合中定位其所描述的概念。我们认为这些模型、它们内部所使用的技术以及它们可以带来的交互是实现人工智能之路上的一块垫脚石，而且图像和自然语言之间的连接也能带来许多实用的益处和马上就有价值的应用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从建模的角度来看，我们的贡献不在于设计和展现了能以复杂的处理流程处理图像和句子的明确算法，而在于卷积和循环神经网络架构的混合设计，这种设计可以在一个单个网络中将视觉数据和自然语言话语连接起来。因此，图像、句子和关联它们的多模态嵌入结构的计算处理会在优化损失函数的过程中自动涌现，该优化考虑网络在图像及其描述的训练数据集上的参数。这种方法享有许多神经网络的优点，其中包括简单的均质计算的使用，这让其易于在硬件上实现并行；以及强大的性能——由于端到端训练（end-to-end training）可以将这个问题表示成单个优化问题，其中该模型的所有组件都具有一个相同的最终目标。我们的研究表明我们的模型在需要图像和自然语言的联合处理的任务中推进了当前最佳的表现，而且我们可以一种能促进对该网络的预测的可解读视觉检查的方式来设计这一架构。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;点击「阅读原文」，下载论文↓↓↓&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 08 Sep 2016 18:51:22 +0800</pubDate>
    </item>
    <item>
      <title>学界 | KDD 2016 演讲和论坛视频出炉：深度学习是一切问题的终极答案吗？</title>
      <link>http://www.iwgc.cn/link/2612471</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自 Video Lectures&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：Terrence、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;当地时间 8 月 13 到 17 日，第 22 届 ACM SIGKDD 数据挖掘及知识发现会议在美国旧金山举行。KDD 2016 是世界顶级的跨学科会议，汇集了来自数据科学、数据挖掘、知识发现、大规模数据分析和大数据领域的研究者和实践者。近日，KDD 2016 期间的一些演讲和研讨会视频陆续公开，机器之心对其进行了简单梳理，视频内容请查阅 http://videolectures.net/kdd2016_sanfrancisco/ 或 KDD 2016 Video YouTube 频道 https://www.youtube.com/channel/UCPsUUDUlcTJuP-fRa7z85aQ?app=desktop。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;一、小组研讨会（Panel）&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;KDD 2016 的这个 Panel 有一个非常有意思的主题：「深度学习是新的终极答案吗？」研讨会主持人是谷歌杰出科学家、前雅虎 Computational Advertising 研究者兼副总裁 Andrei Broder。参与研讨的学者包括华盛顿大学计算机科学与工程副教授 Pedro Domingos、牛津大学计算机科学教授兼 Google DeepMind 研究科学家 Nando de Freitas、Clopinet 独立工程顾问 Isabelle Guyon、加州大学伯克利分校电气工程与计算机科学教授 Jitendra Malik、普渡大学计算机科学系副教授 Jennifer Neville。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;深度学习是新的终极答案吗？（Is Deep Learning the New 42?）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWicxmPYrSYxsFzwwTibibQqW0NdbTTSEC4Yn0u1lhCKptXcglaGGgaSIoSLZfMibrCjmY3lBEm1ibOqqtg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;主题介绍：&lt;/span&gt;&lt;span&gt;深度学习的历史最早可以追溯到五十年之前，但在思想市场中它被意识到的价值却经历了高峰和低谷。我们在历史最高记录时都对此毫无疑问：在过去的几年中，我们见证了视觉、语音识别、游戏、翻译等领域的非同寻常的发展。同时，亚马逊、苹果、Facebook、微软这些公司正在深度学习研究和设施方面进行巨额投入。机器学习的竞争被深度学习方法主导，开源的深度学习软件正在快速增长，流行的媒体也在支持这个过程，同时也喂养着意外后果的黑暗幽灵。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以深度学习会是所有问题的答案吗？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;根据 Douglas Adams 著名的《银河系漫游指南》，在「深思（Deep Thought）」计算机经过了 750 万年的工作后，计算机直截了当地发现了 42 这个数字是：生命、宇宙以及一切事情的终极答案。（尽管不幸的是没有人确切知道这个答案的问题是什么。）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;与其为了使「深思」可以回答我们的问题而再等上 750 万年，我们的这个小组谈论已经整合了一群杰出的专家，来为我们提供他们对于深度学习的观点和对现在和将来的影响。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;二、主题演讲（Keynote Talks）&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1.Graphons 和机器学习：稀疏大型网络的模型构建与估计（Graphons and Machine Learning: Modeling and Estimation of Sparse Massive Networks）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;演讲者：Jennifer Chayes，微软研究院杰出科学家兼常务董事&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWicxmPYrSYxsFzwwTibibQqW0Nv8ZHPDt3aKt6XRSHF0azXNXPm73QN8Wl501MFr2URNiccrER5RCqPYg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;主题介绍：&lt;/span&gt;&lt;span&gt;有很多大型稀疏网络的例子，尤其是互联网、万维网和在线社交平台。我们应该如何对这些网络进行建模和学习呢？和传统的学习过程中遇到的问题相比（我们有很多不同的例子），我们经常只能从这些网络中得到一个独立的例子。我们怎样利用目前的一个单独的快照来学习网络的模型，并在未来预测一个更大的类似网络呢？对于小型或中型网络来说，我们应该以参数的形式为网络建模，并设法学习这些参数。对于大型网络来说，非参数的表征更为合适。在这个演讲中，我们会首先回顾下 graphons 理论，这个为描述稠密图（dense graphs）所开发的理论已经经历了十年的发展，最近的理论描述了具有不受限制的平均度的稀疏图，包括幂律图。我会展示怎样利用这些 graphons 作为稀疏网络的非参数模型。最后，我们将会展示怎样得到这些非参数模型的连续估计量，还有怎样用不侵犯网络中个体隐私的方法做到这些。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2. 人类、计算机和一堆乱七八糟的真实数据（People, Computers, and The Hot Mess of Real Data）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;演讲者：Joseph M. Hellerstein，加州大学计算机科学 Jim Gray 教授&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWicxmPYrSYxsFzwwTibibQqW0NeCiaKgUc3hicdbF6RETFm4ibjjqefI3wAQDbox347PCJQiceL7yzPY0muQ/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;主题介绍：&lt;/span&gt;&lt;span&gt;在实践中，端对端的数据分析基本上不是一个纯设计过程。获取数据是非常需要技巧的。数据评估、wrangling 和特征提取都是消耗时间并且主观的。过去用来驱动数据产品的模型和算法是高度情景化的，涉及到数据源、编码和应用需求的时变特性。理想地说，所有的这些可能会从组织视图中受益，但通常是由个体用户驱动的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从历史角度来看，敏捷分析（agile analytics）和分析流程的建立都涉及到人与计算和基础设施之间的交互。在这份演讲中，我将会分享一些我们研究过程、用户研究、公司（Trifacta, Captricity）实践经验和一个新兴开源项目（Ground）当中的奇闻轶事。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3. 从 VC 视角来看机器学习领域的投资（A VC View of Investing in ML）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;演讲者：Greg Papadopoulos，NEA 投资合伙人&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWicxmPYrSYxsFzwwTibibQqW0NUCQr8pP8RVibDcFdgyYZiczflMluia1NibZVF4K7pd07rKibeiaXawgelMyA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;主题介绍：&lt;/span&gt;&lt;span&gt;我们正见证着一个跨市场和行业的数据科学应用的交汇处。算法进步、廉价的研发周期、在任何地方都可以获得网络数据，这个三大法宝无疑是一个催化剂。对许多人来说这个结果是对效率的持续提升，对一些人来说是关于每个行业的彻底重塑和颠覆。在这个演讲中，我们会给出在未来关注或投资的例子，然后重点介绍我们关于数据增值基础设施和应用端公司的生态系统观点。一个严重的问题是：这些在工具、技巧和教育方面数据整体优势是否真的会被转化成可以应用在任何地方的大众化功能。在未来我们会将机器学习当做一个商业领域，跟随它的价值并得出我们自己的预测。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;4. 信息安全的进化的意义（The Evolving Meaning of Information Security）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;演讲者：Whitfield Diffie，斯坦福大学安全与合作国际中心顾问学者、公钥加密概念的提出者之一&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWicxmPYrSYxsFzwwTibibQqW0NoAOibUOw27D4J3C2yibwtttFYs88iaXHDjCoHDS7EOlKjH5Ku5jxW7bOg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;主题介绍：&lt;/span&gt;&lt;span&gt;当你在研发安全系统的时候，作为对新的安全手段的回应，新的渗透技术似乎也会出现，但是总的来说，这股趋势将会反向：威胁的进化将成为安全的产生和进化的原因。从 20 世纪无线电的兴起开始，针对通信网络的攻击显现出了两种形式：一种是大屠杀（如对 Enigma 的破解），另一种是将一些看起来无伤大雅的信息泄漏聚集起来，形成一个对于目标行为的全面理解。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们将会分析这些趋势和其他人进行互动的方式，这会创造出一种情景，在这个情景中，通信网络中关于安全的可能性，甚至是安全的意义都需要得到重新检验。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;5. 使用深度循环神经网络学习去学习和组合性（Learning to learn and compositionality with deep recurrent neural networks）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;演讲者：Nando de Freitas，牛津大学计算机科学教授兼 Google DeepMind 研究科学家&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWicxmPYrSYxsFzwwTibibQqW0N25gu11Qx7XWhtcSRAmAbzXicySpAp9I2Lkm09INiakqIKSowuDJCvP6w/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;主题介绍：&lt;/span&gt;&lt;span&gt;深度神经网络表征在计算机视觉、语音、计算语言学、机器人、强化学习和其他很多数据丰富的领域中发挥着重要的作用。这个演讲中，我会展示 learning-to-learn 和组合性是解决知识迁移的关键成分，从而可以解决小规模数据规制和持续学习中的问题。我会用三个例子来解释：学习学习算法（learning learning algorithms）、神经编程器和解读器（neural programmers and interpreters）、学习通信（learning communication）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;三、应用数据集科学特邀报告（Applied Data Science Invited Talks）&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;应用数据科学特邀报告为世界一流的专家提供了展示数据挖据和知识发现应用的场所。这些特邀报告都来自于在各自领域里都直接做出了成功的数据挖掘应用的极具影响力的演讲者。这些报告和讨论的关注重点是创新的、前沿的大规模的或政府的数据挖掘应用，涉及领域涵盖：金融、医疗、生物信息学、公共政策、基础设施、电信、社交媒体和计算广告。下面机器之心简单列出了这 11 个特邀报告的主题的演讲者，感兴趣的读者可访问前文提供的网址查看。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWicxmPYrSYxsFzwwTibibQqW0N3oT5QtkwunaCbO8cfcEQE3wF5zhquicibHt7jgm8DL9Z7X4VoIcCmdsg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 你能教会大象跳舞吗？亦即：文化用数据科学当早餐（Can You Teach The Elephant To Dance? AKA: Culture Eats Data Science for Breakfast）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;演讲者：Jonathan Becher，SAP 首席数据官兼数字业务负责人&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2.Verizon 的大规模机器学习：理论和应用（Large Scale Machine Learning at Verizon: Theory and Applications）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;演讲者：Jeff Stribling，Verizon Labs 产品管理部副主任&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3. 计算社会科学：激动人心的进展和未来挑战（Computational Social Science: Exciting Progress and Future Challenges）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;演讲者：Duncan Watts，微软研究院首席科学家，微软研究院纽约实验室创始成员&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4. 贝叶斯优化和嵌入式学习系统（Bayesian Optimization and Embedded Learning Systems）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;演讲者：Jeff Schneider，卡内基梅隆大学计算机科学学院教授&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;5. 大众的智慧：源自数百万数据科学工作流程的数据准备 &amp;amp; 机器学习的最佳实践（The Wisdom of Crowds: Best Practices for Data Prep &amp;amp; Machine Learning derived from Millions of Data Science Workflows）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;演讲者：Ingo Mierswa，数据科学家，RapidMiner 创始人兼 CEO&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;6. 机器学习如何最终解决了 Wanamaker 悖论（How Machine Learning has Finally Solved Wanamaker』s Dilemma）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;演讲者：Oliver Downs，机器学习科学家和串行技术企业家，Amplero CEO 兼首席科学家&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;7. 加速实现自动汽车的竞赛（Accelerating the Race to Autonomous Cars）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;演讲者：Danny Shapiro，NVIDIA 汽车部门高级总监&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;8. 规模化学习稀疏模型（Learning Sparse Models at Scale）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;演讲者：Ralf Herbrich，亚马逊 Machine Learning Science 主任&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;9. 现在是时候了（It』s About Time）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;演讲者：Caitlin Smallwood，Netflix 科学与算法（Science and Algorithms）副总裁&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;10. 企业数据的肮脏小秘密（The Dirty Little Secret of Enterprise Data）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;演讲者：Andy Palmer，Tamr 联合创始人兼 CEO&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;11. 民主化消费者身份：数据科学给 Facebook 的答案（Democratizing Consumer Identity: Data Science』s Answer to Facebook）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;演讲者：Randell Cotta（Drawbridge 公司资深数据科学家），Devin Guan（Drawbridge 公司 CTO）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;四、应用数据集科学特邀研讨会（Applied Data Science Invited Panel）&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWicxmPYrSYxsFzwwTibibQqW0NWLoia4NDhq82ECU6bnyTjicfJZ4segbUpQnuH2ssceibstWMs6NCdyBkw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 大数据需要大梦想家：来自成功大数据投资者的经验教训（Big Data Needs Big Dreamers: Lessons from successful Big Data investors）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;参与者：Evangelos Simoudis（Synapse Partners 创始人兼常务董事）, Mark Gorenberg（Zetta Venture Partners 创始成员）, Tim Guleri（Sierra Ventures 常务董事）, Matt Ocko（DCVC Management 投资人）, Greg Sands（Costanoa Venture Capital 创始人兼常务董事）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 大数据工具和解决方案：神话与现实（Big Data Tools and Solutions: The Myths and the Reality）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;参与者：Usama Fayyad（Barclays 首席数据官、集团常务董事、首席信息官）, Udo Sglavo（SAS 研发部门高级主管）, Dan Steinberg（Salford Systems 总裁）, Ingo Mierswa（RapidMiner 创始人兼 CEO）, Richard Rovner（MathWorks 营销副总监）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 08 Sep 2016 18:51:22 +0800</pubDate>
    </item>
    <item>
      <title>专题 | 聚焦人工智能芯片：「机器之心」携「矽说」共同打造「脑芯编」（申请入群）</title>
      <link>http://www.iwgc.cn/link/2612472</link>
      <description>&lt;p&gt;&lt;span&gt;&amp;lt;序&amp;gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你信不信有一天，硅造的芯片会写诗？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果信，&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;那说好的&lt;/span&gt;&lt;span&gt;「&lt;/span&gt;&lt;span&gt;诗三百，一言以蔽之，思无邪&lt;/span&gt;&lt;span&gt;」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;还真的是&lt;/span&gt;&lt;span&gt;「&lt;/span&gt;&lt;span&gt;无邪&lt;/span&gt;&lt;span&gt;」&lt;/span&gt;&lt;span&gt;么？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果不信，请读下面这一首&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;昨夜神风送层云，几重卷积几重生&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;梦里不问形与令，烛台簇华照单影&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;真北路头初相见，一见泰坦误终身&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;半入豪门寻极乐，日起地平寒武竞&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果要给这诗一个赏析，大概可以是一个忧伤的故事。&lt;/span&gt;&lt;span&gt;天边云的变换复杂，而我却是半梦半醒，我在想一个人，想第一次和他相见，想他的风流倜傥，想他的英雄飒爽。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你是个文科生，或许你会嘲笑这首连平仄都不满足的劣质诗歌，韵脚也押的有些蹩脚，故事更是为赋新词强说愁。如果你是理科男，或许对这种思春的小情怀不以为然。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不过，那是因为你们并没有看懂这首诗。&lt;/span&gt;&lt;span&gt;因为这诗暗藏了一个密码，藏着人工智能遇到摩尔定律后蹭出的火花。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外，这诗不是人工智能的产物，只是矽说在这个人工智能横行的年代里特有的小情怀。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但可能在不远的将来，人工智能将会开车，会翻译，会调情，也会写下更美的篇章。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;想解开这个人工智能与集成电路的秘密？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「机器之心」和「矽说」共同推出了系列文章「脑芯编」，揭秘类脑芯片的过去、现在与未来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;「&lt;/span&gt;&lt;/span&gt;&lt;span&gt;矽说&lt;span&gt;」&lt;/span&gt;的撰稿人来自 UCLA、UW、台湾交大等半导体业顶尖高校以及业界顶尖公司，希望能把自己的所见所闻与大家分享。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;让&lt;/span&gt;&lt;span&gt;我们一起把这首诗一句一句地读下去。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;我们会：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1）定期分享系列文章。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2）组建微信群，方便大家一起讨论、学习和交流，我们也会邀请更多专业人士在群里进行分享。（申请方式见文末）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/Zj3LQ3NDWqjYpVwP7OgvvnbuHuVCn0XOia2O6KgAN9RVWUXRkuDO0Jhe1LNb6861JjVz4ibXGo2brTicSHdPL3vkQ/640?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;第一篇——&lt;span&gt;昨夜神风送层云&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在我读书的时候，人工智能（Artifical Intelligence, AI）从来就是 CS (Computer Science)的天下，哪有电路撺掇的份。那时候的码农们或许会挂着机器学习，数据挖掘，支持向量机，压缩感知……但从来没有一次，电路的突破是由人工智能推动的。可是在今天，如果你打开半导体行业的利好消息，有多少不是和人工智能，深度学习相关的？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;过去一个月，光在半导体巨头们发生的人工智能的故事就足以吊足大家的胃口。何况，这还是只是很多硅工心目中的人工智能元年。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/Zj3LQ3NDWqg3JZ77le1ueiafg0tRWOZrdagmdE8NRSvz1XfljupVZwq2hultDutoG94jRgiaGD4SpicicwlWNX7Hkg/0?"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/Zj3LQ3NDWqg3JZ77le1ueiafg0tRWOZrd9j36yn9sEdSlnh8eaWdicwAaxxaw6Oh5D71PXfsibobPKfVwn6O4A24g/0?"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/Zj3LQ3NDWqg3JZ77le1ueiafg0tRWOZrdicUeO4gSdfB55bDSgeS6xhQsptbnO7e4iabvSJBBruo0Q0iaYXEAEf28A/640?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/Zj3LQ3NDWqgP2ow4GibxKR3Se4WZkwEycUaz3ngIlWKVMTWL3STLh3yDVInMrp1WtEzLThPoN22u3bpB4k3PSpg/640?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;从人工智能到神经网络&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;在人工智能改变半导体行业之前，在人工智能领域发生过一场「华山论剑」，耗时数载，最终以「深度学习神经网络（Deep Learning Neural Network）」一统江湖落下帷幕。该过程腥风血雨，而主角「神经网络」的遭遇更堪比张无忌、杨过，历经少年时的悲惨遭遇，被无数号称时代「大侠」嗤之以鼻，但终究是主角光环加持，加之得外家指点，十年一剑终成大器，号令天下，谁敢不从。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本篇对这里其中的故事，按下不表，有好事者，可以去各处搜搜，剧情精彩不容错过。但是这里还是要感谢，在神经网络经历最寒冬的时候，一众大牛如 Yann LeCun 、 Geoffrey Hinton 等的默默坚守，才有神经网络的今天。不过他们也早已是 Facebook 和谷歌的科学家，如今功成名就，也是吾等小辈无法企及的高度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/Zj3LQ3NDWqg3JZ77le1ueiafg0tRWOZrdEpmBlAw5IQ89icQIUM32ejsNIROlBw4jwXvzOUAqW1VxnhZE8OdqOEg/640?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;Yann LeCun, &amp;nbsp; Geoffrey Hinton&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;神经网络在人工智能领域，属于机器学习一路的分支。所谓机器学习，就是让电脑经过学习后代替人脑做出判断、理解，甚至诀定（还记得赢了李世石的 AlphaGo 么？），而所谓深度学习和浅学习的区别在于设计者是否告诉电脑的学习策略。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最常见的例子是大家电子邮件系统里的垃圾邮件分类，一般一份邮件是否是垃圾邮件，在于它是否满足一些标准，比如是不是群发的，有没有叫你买东西的广告，是不是图片占有比例很高，然后发信人有没有被举报过等等……这些标准都是一个个特征，如果一种机器学习方法规定了学习的特征与策略，那就是浅学习，如果没有规定，需要算法本身去挖掘策略，那就是深度学习。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以，深度学习的一大隐忧就是——人类并不知道算法本身究竟在想什么？所以如果哪天他在他负责的算法下隐藏了一个暗算/统治人类的 bug，那我们就被彻底奴役了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不过，所谓「庄生晓梦迷蝴蝶」，人类自己究竟是不是被另外一个物种开发出来的一种新智慧呢？然后，那个物种是不是已经被我们灭绝了呢？我们并没有答案。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;码农老师教的生物课&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了弄清这横扫千军的神经网络，首先让我们来上一堂不污的生物课。既然叫神经网络，那起源就是生物脑科学。很久以前，人们发现一个单神经细胞（也叫神经元）包括输入（树突 dendrites），激活判断（细胞核 nucleus），输出（轴突 axon）和与下一个神经元的连接关系（突触 synapse）。如果用数学抽象出来过程，就是把一堆输入经过线性组合以后经过一个阈值判断，然后输出给下一级。这样一个简单的神经元就形成。把足够多个神经元连起来就能实现神经网络了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/Zj3LQ3NDWqg3JZ77le1ueiafg0tRWOZrdT7Kz5bxFFmHJpyWU866ovnOA4iaX87yb4P7H1mpiaYicjrboU2PNKEeAA/640?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;上面两个图就是真实的神经元和它的数学模型。（不过我还是要吐槽下：&lt;/span&gt;&lt;span&gt;谁起的中文？树突与突触傻傻分不清 ）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从上述神经元的提出，到许多仿生的算法结构的研究，如多层感知器(Multilayer Perceptron) ，脉冲神经元(Spiking Neural)之类的，经过了一个甲子的时间，特别但都没没什么巨大的成功，原因有两个：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1）当时的集成电路计算规模与资源远没有达到面向实际应用的需求，仔细去研究神经元的数学模型，会发现每个神经元有若干个权重和成累加计算 。他对应汇编可以大致是如下流程：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;累加器清零 &amp;nbsp; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; (mov)&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;-- 循环开始&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; (branch)&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; 从存储器中加载权重 &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;(load)&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; 从存储器/外设中加载输入&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;(load)&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; 权重 乘以 输入 &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;(multiply)&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; 累加 &amp;nbsp; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;(add)&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;-- 判断是否重新循环 &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;(goto)&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; 激活函数 &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; (??)&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;输出 存储 &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;(store)&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;对于一个 N 输入的神经元要走 N 个循环，这对于上个世纪的单核单线程的 CPU，实在是操作难度太复杂。这也就是为什么当流水线与并行处理 不断壮大的近十年，神经网络的发展得到了迅猛发展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2）连得不对。这短短四个字，虽说的轻巧，但要找到连连看的窍门，着实花费了多少人的青春？关于怎么连，各位看官先别着急，且听脑芯编下回分解。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;作为脑芯编的开篇，今天就到这里，所谓「神风送层云」指的就是集成电路的下一个增长点或许就在在人工智能领域取得巨大成功的神经网络硬件实现上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;「人工智能芯片硬件微信讨论群」，通过以下方式申请，我们在审核通过会邀请入群。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1）Google forms （点击查看原文）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2）http://www.diaochapai.com/survey/69e11a55-6f6d-44b9-baf0-31ccf8a946f7&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3）微信后台留言，请注明「职业」+「所在机构」+「在人工智能芯片硬件领域的相关研究和产业背景」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;欢迎关注矽说公众号：&lt;span&gt;silicon_talks&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 08 Sep 2016 18:51:22 +0800</pubDate>
    </item>
  </channel>
</rss>
