<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器之心</title>
    <link>http://www.iwgc.cn/list/670</link>
    <description>人与科技的美好关系</description>
    <item>
      <title>聚焦 | 这个周末，享受Yoshua Bengio、吴恩达、Andrej Karpathy等人的深度学习直播讲座</title>
      <link>http://www.iwgc.cn/link/2820644</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自 Standford&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀、李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;em style="color: rgb(136, 136, 136); line-height: 1.75em;"&gt;&lt;span&gt;这个周六、周日（当地时间），斯坦福（Standford CEMEX auditorium）将举办为期两天的讲座，探讨近期深度学习领域内取得的新进展。Yoshua Bengio、吴恩达、Open AI 的 &lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719010&amp;amp;idx=1&amp;amp;sn=aaa7cc47f27129bbced25e6d090e2c1d&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719010&amp;amp;idx=1&amp;amp;sn=aaa7cc47f27129bbced25e6d090e2c1d&amp;amp;scene=21#wechat_redirect"&gt;Andrej Karpathy &lt;/a&gt;等 12 人将进行专题讲演，届时斯坦福将在 YouTube 上对此次讲座进行直播。此次讲座无疑与 Bengio 8 月份组织深度学习暑期班（&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718578&amp;amp;idx=1&amp;amp;sn=ff7d748b149e7952c9fa3b53cefd5afc&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718578&amp;amp;idx=1&amp;amp;sn=ff7d748b149e7952c9fa3b53cefd5afc&amp;amp;scene=21#wechat_redirect"&gt;重磅 | Yoshua Bengio 深度学习暑期班学习总结，35 个授课视频全部开放（附观看地址）&lt;/a&gt;）一样是一个很好的学习机会。在此篇文章中，机器之心对 12 位大牛即将讲演的主题进行了介绍，读者可以针对自己感兴趣的深度学习研究领域在这个周末享受这些讲座。YouTube 直播地址如下。&lt;/span&gt;&lt;/em&gt;&lt;br/&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;周六 YouTube 直播地址：https://www.youtube.com/watch?v=eyovmAtoUx0&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;周日 YouTube 直播地址：https://www.youtube.com/watch?v=9dXiAecyJrY&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9WfdJmsQegTV58ZvX8druMVYjfHoS0vEdhswHA41AicibbhUwgPTPjWicic1KiadEGPpOkCKM9LMniahlg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;周六&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Hugo Larochelle：介绍前馈神经网络（Introduction to Feedforward Neural Networks）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;9:00-10:00&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;简介：我将讲解前馈神经网络的一些基础概念。开始时，我将简单回顾下前馈网络的基础多层架构，以及自动微分和随机梯度下降（SGD）的反向传播。然后，我将讨论下最近普遍被用于深度神经网络训练的一些思路，比如 SGD 的变体、batch normalization 和 无监督预训练。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Andrej Karpathy：计算机视觉中的深度学习（Deep Learning for Computer Vision）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;10:15-11:45&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;简介：我将讲解进行图像理解的卷积神经网络（ConvNet）的设计，ImageNet 大规模视觉识别挑战赛上顶级模型的历史，以及该领域最近的一些开发模式。我也将会谈及关于视觉识别任务环境中的卷积神经网络架构，比如物体检测、分割、视频处理。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Richard Socher：自然语言处理中的深度学习（Deep Learning for NLP）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;12:45-2:15&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;简介：我将讲解深度学习用于自然语言处理时的基础知识：词向量、循环神经网络、受语言学影响的任务和模型。最后，我将讲解一下将这些模型像乐高一样放到一起，产生被称为动态记忆网络的强大深度架构。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Sherry Moore：TensorFlow Tutorial&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2:45-3:45&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Ruslan Salakhutdinov：深度无监督学习的基础（Foundations of Deep Unsupervised Learning）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4:00-5:30&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;简介：建立能够从高维数据提取有用信息的智能系统一直是很多人工智能任务的核心，包括视觉物体识别、信息检索、语音感知和语言理解。在此教程中，我将讨论许多流行的无监督学习的数学基础，包括稀疏编码、自动编码器、受限玻尔兹曼机（RBM）、深度玻尔兹曼机和变分自编码器。我将进一步证明在视觉物体识别、信息检索和自然语言处理应用中，这些模型能够从高维数据中提取有用的层级表征。最后，如果时间允许，我将简要讨论下能对图像生成自然语言描述的模型，以及使用注意力机制从描述中生成图像的模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;吴恩达：Visionary Lecture&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;6:00-7:00&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;周日&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;John Schulman：策略梯度和 Q-学习：上升到力量、对抗和统一（Policy Gradients and Q-Learning: Rise to Power, Rivalry, and Reunification）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;9:00-10:30&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;简介：我将首先概述一下深度强化学习中目前最好的研究成果，其中包括最近的在视频游戏（如 Atari）、棋盘游戏（如 AlphaGo）和模拟机器人上的应用。然后我会给出这些成果背后的两种核心方法的教学介绍：策略梯度 和 Q-学习。最后，我将给出一个新的分析以说明这两种方法有多么类似。本演讲的主题将不仅是问「什么有效？」，而且还有「它在什么情况下有效？」以及「它为什么有效？」；另外还要找到这些问题的可用于调节具体的实现和设计更好的算法的答案。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Patrice Lamblin：Theano 教学（Theano Tutorial）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;10:45-11:45&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;简介：Theano 是一个 Python 库，允许在 CPU 或 GPU 上高效地定义、优化和评估涉及多维数组的数学表达式。自 Theano 诞生以来，它就一直在深度学习社区最受欢迎的框架之一，而且还有许多用于深度学习的框架也是基于它而构建的，其中包括 Lasagne、Keras、Blocks 等等。这个教程将首先关注 Theano 背后的概念以及如何构建和评估简单的表达，然后我会介绍如何定义和训练更为复杂的模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Adam Coates：用于语音的深度学习（Deep Learning for Speech）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;12:45-2:15&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;简介：传统的语音识别系统具有大量模块，其中每一个都需要单独的艰难的工程开发。现在深度学习已能创造能执行大多数传统引擎的「端到端」的任务的神经网络，这能极大地简化新型语音系统的开发，并开启了实现人类水平的表现的大门。在本教程中，我们将概览一遍类似百度的「Deep Speech」模型的端到端系统的开发步骤。我们将会将这些片段组合起来成为一个最先进的语音系统的「比例模型」——现在已经在驱动生产型的语音引擎的神经网络的小型版本。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Alex Wiltschko：Torch 教学（Torch Tutorial）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2:45-3:45&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;简介：Torch 是 Lua 语言环境中一个用于科学计算的开放平台，其关注的重点是机器学习，尤其是深度学习。Torch 为 GPU 计算提供了一流的支持，而且是以一种清晰的、交互式的和必需的风格，这是 Torch 和其它阵列库之间的显著不同点。尽管 Torch 从广泛的行业支持中获益匪浅，但却是社区所有的和社区开发的生态系统。包括 Torch NN、TensorFlow 和 Theano 在内的所有神经网络库都依靠自动微分（AD：automatic differentiation）来管理复杂函数组件的梯度计算。我将介绍一些自动微分的广义背景，这是基于梯度的优化的基础概念，还将展示 Twitter 通过 torch-autograd 对自动微分的灵活实现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Quoc Le：用于自然语言处理和语音的序列到序列学习（Sequence to Sequence Learning for NLP and Speech）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4:00-5:30&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;简介：我将首先提出序列到序列（seq2seq）学习和注意模型（attention model）的基础，以及它们在机器翻译和语音识别上的应用。然后我将讨论带有指针（pointer）和函数（function）的注意。最后我会描述强化学习可以在 seq2seq 和注意模型中发挥怎样的作用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Yoshua Bengio：深度学习的基础和挑战（Foundations and Challenges of Deep Learning）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;6:00-7:00&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;简介：为什么深度学习的效果这么好？未来还面临着什么挑战？这个演讲将首次探讨深度学习成功的关键因素。首先，根据 no-free lunch 定理，我们将讨论深度网络获取抽象的分布式表征的表达力。其次，我们将讨论我们的实际优化神经网络的参数的惊人能力——尽管存在非凸性（non-convexity）。然后我们将思考一些未来的难题，包括核心的表征问题——理解变化的基本解释因素，尤其是对于无监督学习，为什么这对于将强化学习带向下一阶段来说是非常重要的，以及仍然存在挑战性的优化问题，比如长期依赖的学习，理解深度网络的优化全局，以及为什么生物大脑的学习方式的秘密仍然值得从深度学习的角度来破解。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Sat, 24 Sep 2016 15:49:45 +0800</pubDate>
    </item>
    <item>
      <title>前沿 | MIT人工智能实验室开发机器学习系统，帮助医生诊断儿童交流障碍</title>
      <link>http://www.iwgc.cn/link/2820645</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自MIT CSAIL&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;作者：&lt;span&gt;&lt;a title="Posts by Jason Brownlee" rel="author" style="color: rgb(136, 136, 136); max-width: 100%; border: 0px; outline: 0px; vertical-align: baseline; box-sizing: border-box !important; word-wrap: break-word !important; background: transparent;"&gt;&lt;/a&gt;&lt;/span&gt;Larry Hardesty&amp;nbsp;&lt;span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对有语音和语言障碍的儿童来说，早期干预对儿童以后在学业和社交上的成功有巨大的影响。但很多有语言障碍的儿童（一项研究估计大约为 60%）在上幼儿园，甚至更大之前都不能确诊。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;MIT 计算机科学与人工智能实验室（CSAIL）和马萨诸塞州综合医院卫生职业研究所的研究人员改变了这一现象，他们开发了一个计算机系统能自动筛查语音和语言障碍的儿童，甚至有潜力提供更精准的诊断。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本周，在语言处理 Interspeech 大会上，研究人员报告了该系统的初始设置实验，实验产生了好的结果。电子工程教授、该论文的作者 John Guttag 说，「这是一个初步研究，但我认为它在可行性上相当令人信服。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该系统分析了儿童在一项标准 storytelling 测试上的录音，该测试是向儿童展示一系列的图像以及叙述，然后要求孩子重新讲述该故事。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Guttag 说，「真正令人激动的是它能够使用简化的工具以全自动的方式做筛查。你可以想象完全用平板或手机完成 storytelling 任务。我认为这开启了对大量儿童进行低成本筛选的可能性。而且我想如果我们能做到这一点，这对社会来说是一项巨大的福利。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;微妙的信号&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;研究人员使用一种被称为曲线下面积（ area under the curve）的标准测量方法评估系统的表现，描述了在有障碍人群与数量有限的假正例人权之间的权衡。（修正该系统限制假正例通常会导致对真正例的限制。）在医学文献中，诊断测试的曲线下面积大约是 0.7 就可以被认为足够准确；在 3 个独立的临床任务中，该系统的得分在 0.74 与 0.86 之间。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了建立新系统，Guttag 和电子工程硕士（也是该论文的第一作者） Jen Gong 使用到了机器学习。机器学习是计算机搜索大量数据中的模型，从而进行特定的分类。应用到此案例时，是用来诊断语言和语音障碍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;训练数据是由 MGH 卫生职业研究所的研究员 Jordan Green、Tiffany Hogan 积累，他们对开发更客观的评估 storytelling 测试结果的方法很感兴趣。身为语音-语言病理医生的 Green 说，「我们需要更好的诊断工具帮助医生做评估。评估儿童的语音非常具有挑战性，因为在发育中的儿童有很大的变化。你让 5 个医生做判断可能和得到 5 个答案。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不像由腭裂等解剖学特征引发的语音障碍，语言和语音障碍都有神经科学的基础。但 Green 解释说，它们影响不同的神经通道：语音障碍影响运动通道（motor pathway），而语言障碍影响认知和语言学通道。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;发音停顿指示器&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Green 和 Hogan 假设儿童发音的停顿是有帮助的诊断数据，因为他们难以找到 motor 控制发音所需要的词或语句。所以，这也是 Gong 和 Guttag 集中精力要做的事。他们确定了 儿童发音的 13 个声学特征，他们的机器学习系统能够搜索、寻找与特定诊断相关的模式。&lt;/span&gt;&lt;span&gt;发音长短停顿的数量、停顿的平均长度、停顿长度的变化性、在不间断话语上的相似统计都是他们确定的特征。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;经 storytelling 任务测试的儿童的录音数据被分类为正常发育、有语言障碍或有语音障碍。机器学习系统在 3 个不同的任务上进行训练：识别是否有障碍，是语言障碍还是语音障碍；识别语言障碍；识别语音障碍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;研究人员面临的一个障碍是数据集中正常发育的儿童的年龄范围要比有障碍儿童的年龄范围要窄：因为障碍儿童相对较少，研究人员不得不扩大目标年龄范围来收集数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Gong 使用被称为残差分析的统计技术解决这一问题。首先，她识别目标年龄与性别和他们发音的声学特征之间的关联。然后，她对每一个特征都纠正之间的关联，然后再将数据输入到机器学习算法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;德克萨斯州立大学行为与大脑科学系教授、该大学 Callier 交流障碍研究中心的执行主任 Thomas Campbell 说，「很早之前教育者就讨论过对筛查高风险语言和语音障碍儿童的可靠性测量工具的需要。该项研究的自动筛查方法给出了令人激动的技术发展，可以认为是在语言和语音筛查美国众多儿童是否有障碍上的一项重大突破。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Sat, 24 Sep 2016 15:49:45 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 谷歌互联网气球持续飞行三个月，人工智能让它不会迷失方向</title>
      <link>http://www.iwgc.cn/link/2820646</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自 Wired&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;作者：&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;Cade Metz&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个夏天，谷歌 X 实验室在秘鲁上空的平流层中投放了一个气球，它在那里呆了 98 天。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在谷歌 X 实验室已经和谷歌分家，成了新成立的谷歌母公司 Alphabet 下的一个成员，名字也变成了 X。在平流层中投放气球对 X 实验室来说是家常便饭，它的 Project Loon 就是专门做这种事的——这些气球可以在平流层中向还没有互联网接入的地区提供互联网。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;X 希望这些气球能够在平流层中待足够长的时间并持续提供稳定可靠的互联网接入。但大自然不会那么「稳定」：气球常常会飘走！所以说 X 实验室能让气球在秘鲁的上空呆上三个月已经是一件非常惊人的事了。而且更为惊人的是：这些气球的导航系统只能让气球上下移动，而不能控制水平方向上的位移——这是因为更复杂的方向控制系统会更重、成本也更高。它们就像热气球一样，需要在合适的天气状况中飞行。X 实验室没有给秘鲁上空的气球安装什么喷气式推进系统，而是给了它一个人工智能的大脑。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们使用了广义上的「人工智能（artificial intelligence）」这个词。但不管你叫它什么，这些在秘鲁上空给这些气球导航的新算法确实非常有效。这也代表着整个科技界近来的一场非常真实的也非常广泛的巨大变革。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在刚开始的时候，Loon 团队通过人工编写的算法来引导这些气球；这些算法可以响应一些预定义的变量集合（如：高度、位置、风速和每日时间等）。而新的算法则在很大程度上利用了机器学习技术：通过分析大量数据，这些算法可以随时间不断学习。它们可以基于过去发生过的状况调整气球未来的行为。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我们在越来越多合适的地方用上了越来越多的机器学习，」谷歌的前搜索工程师、现任 Loon 项目负责人 Sal Candido 说，「这些算法可以比任何人类都更高效地处理事情。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但这并不意味着这些算法总是能做出正确的决策。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Candido 拥有一个随机最优控制（stochastic optimal control）的博士学位。也就是说他专门研究的是系统面对不确定情况的控制问题，现在他就正在应用自己的专业知识来解决实际的问题。当你将一个气球投放到平流层时，会有很多可怕的不确定性，而你不能改变这一点。但在机器学习的帮助下，Candido 及其团队正在寻找更好的解决不确定难题的方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当 Loon 项目刚启动时，该团队认为为一个地球提供互联网覆盖的唯一方法是投放大量气球，然后让它们相隔很远地飘在空中。但现在，他们能更好地控制气球的飘动方向了，这就意味着他们可以只用更少的气球就能提供互联网覆盖了。「气球不会飘到海洋上去，」Candido 说，「我们可以在用户上空停留更久。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器学习不仅在 Project Loon 中的兴起，在整个谷歌乃至整个科技行业也是一样——Facebook、微软、Twitter 等许多公司都在这个方向上发力。最值得注意的是，这些公司都在向深度神经网络（deep neural networks）的方向发展——这是一种稍微类似于人脑中神经元网络的算法。这种技术在你的安卓手机上帮你识别语音指令、在 Facebook 上帮你识别照片中的人脸、在谷歌的搜索引擎中帮你选择合适的链接……过去，驱动谷歌搜索的算法是人工编程的。而现在，算法已经能够自己学习了，它根据人们的点击情况进行分析从而选择呈现最佳的搜索结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Project Loon 的导航系统并没有使用深度神经网络，而是使用了一种更简单的名叫高斯过程（Gaussian processes）的机器学习技术。但其中的基本思路是一样的。而且这也能让我们看到实际上深度学习只是人工智能革命的一部分。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Project Loon 已经收集到了 1700 万千米的气球飞行数据；通过高斯过程，该导航系统可以预测气球的运动轨迹，然后决定气球应该向上移动还是向下移动（这涉及到向气球充气和给气球放气）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些预测并不完美——很大程度上是因为平流层的天气是很难预测的。平流层位于我们所能感受的大多数气象现象之上，但 Candido 说这些气球所遭遇到的不确定性远远超过了该团队的预期。所以，他们还使用了一种被称为强化学习（reinforcement learning）的技术对系统进行了强化。该系统在做出预测后还会继续收集气球目前所处情况的额外信息——那些有效那些没有——然后使用这些数据来调制自己的行为。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从广义上讲，这和另一支谷歌研究团队打造 AlphaGo 的方法类似——这个下围棋的人工智能系统已经击败了一位世界最顶级的围棋棋手李世石。AlphaGo 通过分析数百万局人类棋局然后不断和自己对弈而学会了下围棋，它通过强化学习仔细地追踪成功或不成功的策略，从而提升了自己的棋力。AlphaGo 的设计者相信这些同样的技术也可以被用于机器人以及其它各种各样的在线任务或离线任务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这不是魔法，只是数据、数学和巨量计算处理能力的综合结果。正如 Candido 所说的那样，Loon 的导航系统之所以成为可能，是因为它能使用谷歌的巨型数据中心在成千上万台机器上处理信息。他也表示 Loon 的机器学习还不够完美。广义的机器学习也是一样——都还不够完美。人工智能并不总是那么智能，它并不总是能得到我们想要的结果。但是随着时间的推移，它会做得越来越好——不管是在地面、平流层、还是更进一步的星际空间中……&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Sat, 24 Sep 2016 15:49:45 +0800</pubDate>
    </item>
    <item>
      <title>业界 | D-Wave创始人的新公司要将人工智能、机器人和外骨骼结合到一起</title>
      <link>http://www.iwgc.cn/link/2820647</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自IEEE Spectrum&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀、李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;几位量子计算先驱近日创立了一家新公司 Kindred 来开发用于机器人的控制和训练的先进人工智能系统。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9WfdJmsQegTV58ZvX8druMbD8aDz3xvic2slDPAE64dXyjo7r1Etk0EcFErPsGCbl3CibQ0w6vk4xw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图片来自美国专利申请 US20160243701A1&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果量子计算还不够烧脑的话，D-Wave Systems 的一位创始人又看上了另一个未来十足的想法：使用人工智能和高科技外骨骼让人类（或者让猴子——根据对该技术的一份描述文件）能够控制和训练智能机器人大军。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Geordie Rose 是 D-Wave 的联合创始人兼首席技术官，该公司正在销售据称使用了量子力学效应的计算机器——据说其在一些特定问题上的计算速度已经达到了传统计算机的数亿倍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而 IEEE Spectrum 经过调查发现 Rose 同时还是另一家公司 Kindred Systems（也叫 Kindred AI）的 CEO，这家处于隐身模式的创业公司创立于 2014 年，致力于提供远程控制的和自主的机器人。他们的目标是让机器人编程更快更便宜，甚至可能彻底变革全世界的工作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Kindred 目前已经融资了 1000 万美元——据 Data Collective，这家风险投资公司领投了其中一轮。另一家硅谷风投公司 Eleven Two Capital 也参与了投资。Data Collective 在一片博客文章中描述 Kindred 是「使用人工智能驱动的机器人，使得一个人类工人就能完成四个人的工作。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Kindred 最近申请了美国的专利，其描述是：一种操作者可穿戴头戴式显示器和外骨骼套装来执行日常任务的系统。然后来自该套装和其它外部传感器的数据可在被分析后用来控制远程机器人。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Kindred 一直以来都很低调，没有发过媒体新闻稿，也只有一个非常简单的网站：www.kindred.ai。但是，去年 11 月时，一位 D-Wave 前研究者、Kindred 的联合创始人兼 CTO 曾告诉一些技术人士说该公司正在打造使用机器学习来识别模式和进行决策的个人机器人。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;她说：「量子力学很酷，但机器人中的类人智能更酷。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Kindred 位于加拿大不列颠哥伦比亚省温哥华，其最近提交的一份美国专利申请揭示了其勃勃雄心。该文件描述了一种头戴式显示器和带有传感器和执行器的外骨骼系统，操作者可穿戴它来执行日常任务。然后云端的计算机会分析来自该套装和其它外部传感器的数据，并依据分析结果控制远程机器人。这些数据也可被用训练机器学习算法，这让机器人可以自动模仿操作者的动作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;「操作者可能包含了非人类的动物，比如猴子。」该专利写道，「而且操作接口可能……需要重新调整尺寸以弥合人类操作者和猴子操作者之间的差异。」（事实上，这并非第一种让猴子直接控制机器人的设备，但之前的结果更关注脑机接口（参考阅读《&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719118&amp;amp;idx=1&amp;amp;sn=a9c6aa3cc961d93e228bbd3139e636b1&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719118&amp;amp;idx=1&amp;amp;sn=a9c6aa3cc961d93e228bbd3139e636b1&amp;amp;scene=21#wechat_redirect"&gt;斯坦福开发机器学习脑机接口，帮助猴子打出了莎士比亚名句&lt;/a&gt;》），而不是机器人控制和自动化。）&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9WfdJmsQegTV58ZvX8druMeODNXTHT6Eo0dWw95JKPC2iabZg063grjj6ApQ4NcEslOic4P4XXm7IA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;来自美国专利申请 US20160243701A1。&lt;span&gt;&lt;em&gt;&lt;span&gt;带有传感器和执行器的外骨骼套装渲染图，操作者可以穿戴它来远程控制机器人&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该专利申请描述一些有关操作者接口的细节、一套包含头部和颈部运动传感器的可穿戴机器人套装（上图）、用于捕捉手臂运动的设备和触感手套。其操作者可以使用脚踏板来控制机器人的移动，以及使用一个类似 Oculus Rift 的虚拟现实头设来体验机器人所看到的内容。该套装甚至还包含化学和生物传感器，还有用于捕捉脑波信号的 EEG 和 MRI 设备。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其所设想的机器人是 1.2 米高的人形机器人，外部还可能会覆盖一层合成皮肤，拥有两个（或更多）机器臂（用作手或夹持器）和用于移动的轮式底盘。它头上安装的相机可以为其猴子操作者传输高精度视频，同时它还带有用于红外和紫外成像、GPS、触控、临近度和应变度探测的传感器，甚至还带有一个辐射检测器。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该系统可被用于直接远程操控，操作者可以操作远程机器人来完成工业和家庭任务。充满传奇故事的机器人实验室 Willow Garage 曾在 2011 年实验了一款类似的系统 Heaphy，还取得了一定的成功。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在 Kindred 想要实现远程机器人的下一步。「尽管包含在人类大脑中的用于执行各种人类可执行的任务的大量信息是可用的，但过去用于执行这些任务的机器人相关设备却并没有或并没有充分地使用到它们。」Kindred 的专利文件表示。此外它还提到：「操作者也可能包含非人类的动物，比如猴子。而且操作接口可能……需要重新调整尺寸以弥合人类操作者和猴子操作者之间的差异。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;更重要的是，该公司想要该系统能够从其操作者身上学习，最终让机器人可以在没有人类——或猴子——的控制下执行任务。该专利表示：「设备控制指令和和在多轮运行中生成的环境传感器信息可以被用于衍生自动控制信息，这些信息可被用于促进自动化设备中的自动行为。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该文档还表示 Kindred 将使用「深度分层学习算法（deep hierarchical learning algorithms）」来实现这一目标，其中包括条件深度信念网络（CDBN: conditional deep belief network）和条件受限玻尔兹曼机（CRBM: conditional restricted Boltzmann machine）——这是一种强大的循环神经网络（recurrent neural network）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9WfdJmsQegTV58ZvX8druM420k48Ohx8fVlpFjiaqGib7G3wicyNuI6V83fOH1v3ic0bqRTLbYzNpLLg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;来自美国专利申请 US20160243701A1，上图展示了多个操作者和机器人通过 Kindred 的云端人工智能系统进行交流通信的方式&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;事实上，该专利的发明者之一 Graham Taylor 在 CDBN 和 CRBM 上都有一些研究贡献。Taylor 是安大略省圭尔夫大学机器学习研究组（Machine Learning Research Group）的负责人。他曾经在多伦多大学师从深度学习先驱 Geoff Hinton（Hinton 在 1985 年联合发明了玻尔兹曼机，他现在同时在谷歌和多伦多大学工作）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;量子计算公司 D-Wave 表示该系统的运算「类似于玻尔兹曼机」，而且其研究团队「正在研究并行使用这些架构来从根本上加速深度的和层次化的神经网络的学习」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2010 年时，Geordie Rose 与人合著了一篇论文《The Ising model: teaching an old problem new tricks》称量子计算机可以在一些类型的机器学习应用上比传统计算机更加高效。这会成为新领域——量子机器人（quantum robotics）——的开端吗？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Kindred 和 D-Wave 都没有回应 IEEE Spectrum 对此要求评论的请求，但据 LinkedIn 资料和加拿大的政府记录，Kindred 在温哥华有大约 25 名员工，包括几位原来 D-Wave 的员工。该公司似乎在旧金山湾区也有人，包括一位专门从事机械设计和机电一体化整合的机电一体化工程师。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;至于实际的应用，该专利提到了工业制造、家务甚至娱乐。它说：「其所执行的任务可能包括做一杯咖啡或表演编排的舞蹈。一位操作者……也许是一位表演者……可以提供可录制的动作集合（比如一组口头交流可通过机器人上的扬声器播放出来）。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尽管目前还不清楚 Kindred 的远程机器人系统已经做到哪种程度了，但该文件已经给出了该系统的外骨骼 3D 渲染模型、一些组件的详情、以及手套组件与机器人履带的照片。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;IEEE Spectrum 联系的机器人专家说这使得编程机器人更简单，如同 Kindred 想要做的那样，它将成为该领域的一大进步。但该公司是否有能力交付出描述的那样的系统有一些怀疑。在 Willow Garage 开发出 Heaphy 遥控机器人系统的 Tim Filed 说，「应用机器学习的部分远超如今的顶尖水平，它所需要的数据量是天文级的。」他提到了 Google Research 系统让机械臂学会从篮子中挑选物体进行了 80 万次尝试。他解释说，「想象一下使用人工操作进行 80 万次尝试所花费的时间，如今这是不可能的。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;俄勒冈州立大学的机器人专家 Bill Smart 说，「理论上这是一个不错的思路，但里面的技巧是要抓住任务的环境。此外，我敢打赌人类是没法让机器人实现最佳的运动方式的，因为人与机器有不同的动力学。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;使用灵长类动物教机器人如何唱歌、跳舞这个思路如何呢？Smart 开玩笑说，「如果你有无限量的猴子，你可能会得到一个最优的控制器吗？但保持它们做任务就是一个噩梦。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Sat, 24 Sep 2016 15:49:45 +0800</pubDate>
    </item>
    <item>
      <title>深度 | 提升深度学习模型的表现，你需要这20个技巧（附论文）</title>
      <link>http://www.iwgc.cn/link/2808920</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自machielearningmastery&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;作者：&lt;span&gt;&lt;a title="Posts by Jason Brownlee" rel="author" style="border: 0px; outline: 0px; vertical-align: baseline; color: rgb(136, 136, 136); font-weight: bold; background: transparent;"&gt;Jason Brownlee&lt;/a&gt;&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：杜夏德、陈晨、吴攀、Terrence、李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;本文原文的作者 Jason Brownlee 是一位职业软件开发者，没有博士学位的他通过「从应用中学习」的方法自学了机器学习，他表示对帮助职业开发者应用机器学习来解决复杂问题很有热情，也为机器学习社区贡献了很多实用的建议和指南，本文所讲解的是「能帮助你对抗过拟合以及实现更好的泛化」的 20 个技巧和技术。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你可以怎样让你的深度学习模型实现更好的表现？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是一个我常被问到的问题：「我该怎么提升准确度？」或者「如果我的神经网络表现很糟糕我该怎么办？」……&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我常常给出的回答是：「我也不完全知道，但我有很多想法。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然后我开始列出所有我可以想到的可能能够带来效果改进的想法。我将这些想法汇集到了这篇博客中，这些想法不仅能在机器学习上为你提供帮助，而且实际上也适用于任何机器学习算法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;提升算法的表现的想法&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这份列表并不是完整的，但是却是一个很好的开始。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我的目标是给你大量可以尝试的想法，希望其中会有一两个是你从来没有想到过的。毕竟，你总是需要好的想法来获得进步。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我将这份列表分成了 4 个子主题：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1. 通过数据提升性能表现&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2. 通过算法提升性能表现&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3. 通过算法微调提升性能表现&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;4. 通过整合提升性能表现&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;列表越往后，其所能带来的增益就越小。比如说，关于你的问题的新型框架或更多的数据所带来的效果总是会比微调你表现最好的算法所带来的效果更好。尽管并不总是如此，但一般而言确实是这样。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其中一些想法是特定于人工神经网络的，但还有许多是很通用的，你可以借鉴它们从而在使用其它技术来提升你的性能表现上获得灵感。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面就让我们正式开始吧！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1. 通过数据提升性能表现&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;修改你的训练数据和问题定义可以给你带来巨大的好处，也可能能带来最大的好处。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面是一些我们将会涵盖的内容的一个短列表：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 获取更多数据&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 创造更多数据&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3. 重新调整数据的规模&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4. 转换数据&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;5. 特征选择&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1）获取更多数据&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你能获取更多训练数据吗？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;基本上，你的训练数据的质量就限制了你的模型的质量。你需要为你的问题寻找最好的数据，而且是很多很多数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;深度学习和其它现代非线性机器学习技术都是数据越多越好，深度学习尤其是这样。这也是深度学习如此激动人心的主要原因之一。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;让我们看一下下面的图：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicF8wXlBVVVUGiahn69Rw7OWrnfOexOlSRqbv4eLgEeurnbmPA9GX4qnGibE6JbLviaGHibB0rr7BR2SQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;为什么选择深度学习？来自吴恩达的幻灯片&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;更多的数据并不总是有用，但它可以有用。如果要我选择，我肯定会希望获得更多的数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相关推荐：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;算法上的数据集&lt;/span&gt;&lt;span&gt;（https://www.edge.org/response-detail/26587）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2）创造更多数据&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;深度学习算法得到的数据越多，通常就表现得越好。如果你无法合理地得到更多数据，你可以创造更多数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如果你的数据是数字的向量，就在已有的向量上进行随机的修改来创造数据。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如果你的数据是图像，就在已有的图像上进行随机的修改。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如果你的数据是文本，就在已有的文本上进行随机的修改……&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个过程常被称为数据增强（data augmentation）或数据生成（data generation）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你可以使用生成模型，也可以使用某些简单的技巧。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;比如，对于照片图像数据，你可以通过随机移位和旋转已有的图像来获得新图像。这能够提升模型对于数据中这种变换的归纳能力——如果它们也预计会出现新数据中。这也和增加噪声有关，我们过去叫做添加抖动（adding jitter）。这可被用作是抑制过拟合训练数据集的正则化方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相关推荐：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;使用 Keras 进行深度学习的图像增强（http://machinelearningmastery.com/image-augmentation-deep-learning-keras/）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;什么是抖动？（使用噪声进行训练）（ftp://ftp.sas.com/pub/neural/FAQ3.html#A_jitter）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3）重新调整数据的规模&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是个快速的方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;将传统的拇指规则应用于神经网络：将你的数据的规模重新调整到你的激活函数的范围内。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你使用的是 S 型激活函数，那么就将你的数据调整到值位于 0 到 1 之间。如果你使用的是双曲正切（tanh），就将你的值调整到 -1 到 1 之间。这适用于输入（x）和输出（y）。比如说，如果你在输出层有一个 S 型函数来预测二元值，你可以将你的 y 值规范为二元的。如果你使用的是 softmax，你仍然可以从规范化 y 值中获益。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这仍然是一个好的拇指规则，但我会更进一步。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我建议你按以下形式创造你的训练数据集的不同版本：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;规范成 0 到 1；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;重新调整到 -1 到 1；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;标准化。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然后在每一个数据集上评估你的模型的表现。选择其中一个，然后再双倍下注。如果你修改了你的激活函数，再重复这个小实验。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;网络中大数值的积累并不是好事。此外，还有一些让你的网络中的数值变小的方法，例如规范化激活和权重，但我们会在后面谈论这些技术。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相关推荐：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;我应该标准化输入变量（列向量）吗？（ftp://ftp.sas.com/pub/neural/FAQ2.html#A_std）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如何在 Python 环境中利用 Scikit-Learn 包来为机器学习准备数据？（http://machinelearningmastery.com/prepare-data-machine-learning-python-scikit-learn/）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;4）转换你的数据&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这和上述建议的规模重调相关，但是需要更多的工作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你必须真正了解你的数据，并将其可视化，然后寻找出那些离群的数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;估计每个列的单变量分布。&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;列是否看起来像是一个倾斜的高斯分布，考虑用 Box-Cox 变换来调整倾斜的情况&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;列是否看起来像是一个指数分布，考虑用对数变换&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;列是否看起来像是拥有一些特征，但正在被一些明显的东西冲击，试着利用平方或者平方根&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;能否用某些方式让特征更具体或者离散来更好地强调这些特征&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;根据你的直觉，去尝试一些新的东西。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;能否利用主成分分析一类的投影方法预处理数据？&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;能否将多个属性聚合成为一个单一变量？&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;能否用一个新的布尔标志揭示问题的一些有趣的地方？&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;能否用其他方式探索时间结构或者其他结构？&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;神经网络可以进行特征学习。它们能做到这点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但如果你能更好地将问题的结构展示给神经网络用于学习，它们能更好地解决问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;抽查大量的不同转换形式的数据或者某些特定属性，看看什么可行什么不可行。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相关推荐：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如何定义你的机器学习问题（http://machinelearningmastery.com/how-to-define-your-machine-learning-problem/）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;挖掘特征工程。如何设计特征以及如何合理利用它们（http://machinelearningmastery.com/discover-feature-engineering-how-to-engineer-features-and-how-to-get-good-at-it/）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如何用 Python 和 Scikit-learn 结合的方式为机器学习准备数据（http://machinelearningmastery.com/prepare-data-machine-learning-python-scikit-learn/）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;5）特征选取&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;神经网络一般都对无关联的数据是稳健的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;它们将使用一个接近于零的权重并边缘化那些非预测属性的贡献。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不过，这是运用在那些无需做出好的预测的数据上的数据、权重和训练周期。能否从你的数据中删除某些属性？有很多特征选择方法和特征重要性的方法可以给你一些关于特征的想法，从而能更好的利用它们。尝试一部分。尝试全部。这样做是为了获得想法。。同样，如果你有时间，我会建议利用相同的网络来评估一些不同选择视角下的问题，看看它们的表现如何。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;也许你可以用更少的特征做得一样好，甚至有更好表现。是的，更快！&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;也许所有的特征选择方法可以引导出相同特定子集的特征。是的，对无用的功能达成共识！&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;也许选定的子集给你提供了一些想法或者更多的你可以执行的特征工程。是的，更多的想法！&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;相关推荐：&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;特征选择简介（http://machinelearningmastery.com/an-introduction-to-feature-selection/）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;Python 环境中机器学习的特征选择（http://machinelearningmastery.com/feature-selection-machine-learning-python/）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;6）重构你的问题&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;退一步再看你的问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你所收集的观察是唯一能构建你问题的方式吗？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;也许还有其他更好的地方。也许其他的问题框架可以更好地展示问题的某些结构从而能更好地进行学习？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我真的很喜欢这项练习，因为这迫使你打开你的内心。这很难，尤其是当你现阶段已经投资了你的自负、时间和金钱。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;即使你只是列出了 3 到 5 个备用的框架并让它们打了折扣，至少你正在你选择的方式中建立你的信心。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;也许你可以在某个允许时间步骤的窗口或方法中整合时间元素&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;也许你的分类问题可以变成一个回归问题，或者相反&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;也许你的二元输出可以变成一个 softmax 输出&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;也许你可以对一个子问题建模&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是一个想清问题的好方法，这也是一个在你想要利用工具之前的可行框架，因为你在解决方案上的投资会更少。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不管怎样，如果你卡住了，这个简单的方式还可以让你思若泉涌。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此外，你不必丢弃任何你之前的工作，看看之后的整合吧。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相关推荐：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如何定义你的机器学习问题（http://machinelearningmastery.com/how-to-define-your-machine-learning-problem/）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2. 通过算法提升表现表现&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器学习就是关于算法的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所有的理论和数字都描述了运用不同的方式从数据中学习一个决策过程（如果我们将自己限制在一个可预测模型中）。你已经选择利用深度学习来处理问题。这是你可以选择的最好方式吗？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在本节中，在继续深入研究你为何选择深度学习方法的某些细节之前，我们讨论一些关于算法选择的小的想法。&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Spot-Check Algorithms. 抽查算法&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Steal From Literature. 从文献中获取&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Resampling Methods. 重采样方法&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;让我们开始吧。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1）抽样算法&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;振作起来，你在事前可以不知道哪种算法能最好地执行你的问题。如果你知道，你可能不会需要机器学习。你收集的什么证据能证明你所选择的方法是一个好的选择？让我们来解决这个难题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当表现在所有的问题中处于平均值时，没有一种单独的算法可以比其他任何的都运行地更好。所有的算法都是平等的。这是从没有免费的午餐定理中总结归纳的。也许你的算法并不是解决你的问题的最好的方式。现在，我们不是要解决所有可能的问题，但是在所有算法中最新最热的那个不一定是你处理某个特定训练集最好的方法。我的建议是收集证据。想象可能会有更好的算法并给它们一个处理你问题的公平的机会。抽查一系列顶级的算法，看看哪些表现不错，哪些表现不好。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;评估某些线性方法，比如逻辑回归和线性判别分析&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;评估一些树的方法，比如分类回归树、随机森林和 Gradient Boosting&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;评估一些实例方法，比如支持向量机和 K 最近邻&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;评估其他的一些神经网络算法，比如 LVQ、MLP、CNN、LSTM、混合结构等等&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;重点关注表现最佳的，并通过进一步的调整或者数据准备提高表现。对你选择的深度学习方法进行结果排名，它们如何比较？也许你可以放下深度学习模型，并使用一些更快更简化的方式去训练，这甚至可以很容易理解。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相关推荐：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;一种用于机器学习的数据驱动方法（http://machinelearningmastery.com/a-data-driven-approach-to-machine-learning/）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;为什么你应该在你的机器学习问题上进行算法抽查（http://machinelearningmastery.com/why-you-should-be-spot-checking-algorithms-on-your-machine-learning-problems/）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;在 Python 环境中使用 Scikit-learn 抽查分类机器学习算法（http://machinelearningmastery.com/spot-check-classification-machine-learning-algorithms-python-scikit-learn/）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2）从文献中获取算法&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一种获取好算法的捷径是从文献中获取。还有谁跟你处理过一样的问题，他们用了什么方法？查看论文、书籍、博客、问答网站、教程和一切谷歌丢给你的东西。写下所有的想法，并按照你自己的方式处理它们。这不是研究的复制，这是关于一些你没有想到过的但可能能够提升你的思路的新想法。发表出来的研究是高度优化过的。有很多聪明的人写下了很多有趣的事情。在这些广袤的资源中挖掘你需要的金矿吧。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相关推荐：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如何研究一个机器学习算法（http://machinelearningmastery.com/how-to-research-a-machine-learning-algorithm/）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;谷歌学术搜索（http://scholar.google.com/）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3）重采样方法&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你必须知道你的模型有多好。你对你的模型的性能估计可靠吗？深度学习算法的训练很慢。这通常意味着我们不能使用黄金标准方法来估计模型的性能，比如 k-fold 交叉验证。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;也许你正在使用一个简单的训练集／测试集分割，这是很常见的。如果是这样，你需要确保这个分割能够代表这个问题。单变量统计和可视化将会是一个良好的开端。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;也许你可以利用硬件来提高评估结果。比如，如果你有一个集群或者 Amazon Web Services 的账户，我们可以并行训练 n 个模型然后再取领军和标准差去得到一个更稳健的估计。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;也许你可以使用一个验证 hold out 集来在它正在训练时获得一个验证模型性能的想法（对过早终止有用，见后文）。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;也许你能撤回一个你只在模型选择演算后使用的完全无效的验证集。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;走另一条路，也许可以使数据集更小，使用更强的重采样方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;也许你可以在一个只在某一样本中训练的模型和在整个样本中训练的模型之间看到很强的相关性。也许你可以进行模型选择并利用小数据集微调，然后将最终的技术扩展到完整的数据集上。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;也许你可以任意约束数据集，然后取样，并将其用于所有的模型开发&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你必须对你模型的性能估计有充足的信心。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相关推荐：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;评估 Keras 中深度学习模型的性能&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;评估利用重采样方法的 Python 中机器学习算法的性能&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3. 通过算法调优改进性能&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这才是肥肉所在。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你总能够从抽查中找出一两个不错的算法。得到表现最好的算法可能要花费一定的时间。下面是一些调优神经网络算法从而得到更好的表现的方法：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;诊断&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;权重初始化&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;学习率&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;激活函数&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;网络拓扑&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Batches 和 Epochs&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;正则化&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;优化与损失&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;早停&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你可能需要对给定网络的配置训练许多次（3-10 次或更多），从而对该配置的表现作出很好的评估。在这个小节中你学到的微调技可应用于所有方面。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;推荐一篇很好的讲解超参数优化的文章：http://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1) 诊断&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你知道架构的表现为什么没有改进，那你就能更好的改进其表现了。比如，是因为模型过拟合或者欠拟合？要切记这个问题。网络总是会在拟合上出问题，只是程度不同而已。一个快速了解你的模型的学习行为的方式是在每个 epoch 在训练和验证数据集上对模型进行评估，并标绘结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicF8wXlBVVVUGiahn69Rw7OWe4iaeP8XqgPFU4WpUohPSHnsNHoEUE7eHPOOKtkcoqMWQdkPlRz4k0A/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;模型在训练和验证数据集上的准确率&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如果训练比验证集的结果更好，你可能过拟合了，可以使用正则化技术进行调整&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如果两个结果都很低，你可能欠拟合了，可以通过增加网络的容量并进行更多、更长的训练进行调整&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如果有一个训练高于验证结果的拐点，你可以使用早停（Early Stopping）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;经常标绘这样的图，并研究使用不同的技术改进模型的表现。这些图可能是你所能创造的最有价值的诊断方法。另外一个有帮助的诊断方法是学习网络正确和错误的观察值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在一些问题上，下面这些建议可以尝试一下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;在难以训练的样本上，你可能需要更多的或增强的样本。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;在容易建模的训练数据集上，你可能需要移除大量样本。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;可能你需要使用专门的模型，专注于输入空间不同的明确区域。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相关推荐：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;在 Keras 中显示深度学习模型训练历史（http://machinelearningmastery.com/display-deep-learning-model-training-history-in-keras/）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;深度学习算法的过拟合和欠拟合（http://machinelearningmastery.com/overfitting-and-underfitting-with-machine-learning-algorithms/）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2）权重初始化&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;过去的经验法则是：使用小型随机数值进行初始化。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在实践中，这个法则仍然很好，但对你的网络而言它是最好的吗？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不同的激活函数也所启发，但我在实践中不记得看到过有什么不同。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;修定好你的网络并尝试不同的初始化方案。记住，权重是你一直想要找到的模型的实际参数。有许多套权重能给出好的表现，但你需要的是更好的表现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;尝试所有的初始化方法，看有没一个是最好的。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;尝试用自编码器（autoencoder）这样的无监督方法进行预学习。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;为了解决你的问题，尝试使用已有的方法重复训练新的输入和输出层（迁移学习）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;记住，改变权重初始化方法会影响到激活函数，甚至是优化函数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相关推荐：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;深度网络的初始化：http://deepdish.io/2015/02/24/network-initialization/&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3）学习率&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;调整学习率总会有所收获。下面是一些可以探索的方法：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;用超大或超小的学习率进行试验&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;从文献中找到常用的学习率值，看你能将网络改进到什么地步&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;尝试随着 epoch 降低学习率。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;尝试经过一定量的 epoch 训练后，就按一定概率降低学习率&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;尝试增加一个动量项，然后同时对学习率和动量进行网格搜索&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;越大的网络需要越多的训练，反之亦然。如果你增加更多的神经元或更多的层，请增加你的学习率。学习率与训练 epoch 的数量、batch 的大小、优化方法是紧密相关的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相关推荐：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;在 Python 中对深度学习模式使用学习率方案：http://machinelearningmastery.com/using-learning-rate-schedules-deep-learning-models-python-keras/&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;反向传播应该使用什么样的学习率？：ftp://ftp.sas.com/pub/neural/FAQ2.html#A_learn_rate&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;4）激活函数&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你或许应该使用 rectifier 激活函数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;它们用起来更好。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在那之前，在输出层上，一开始是 sigmoid 和 tanh 函数，然后是一个 softmax 函数、线性函数或者 sigmoid 函数。我不推荐做更多的尝试，除非你知道你在做什么。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尝试这三个函数并且调整你的数据以满足这些函数的边界。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;很明显，你想选择适合输出的形式的传递函数（transfer function），但是要考虑利用不同的表征。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;例如，从二元分类（binary classification）的 sigmoid 函数切换到解决回归问题的线性函数，然后后处理（post-process）你的输出。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这或许也需要将损失函数换成某些更加适合的东西。下面是关于数据转换的更多的想法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相关推荐：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;为什么要使用激活函数：ftp://ftp.sas.com/pub/neural/FAQ2.html#A_act&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;5）网络拓扑&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;改变你的网络结构会有回报。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你需要多少层和多少个神经元？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;没人只知道，所以别问。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你必须为你的问题开发出好配置。试验。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;尝试一个隐藏层包含很多个神经元（宽）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;尝试每层只有少量神经元的深度网络（深）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;尝试将以上结合起来&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;从最新的论文中找出与你类似的架构并尝试它们&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;尝试拓扑模式（扇出然后扇入）和书与论文中的好的经验规则（见下面链接）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;后面的网络需要更多的训练，在 epochs 和学习率上都需要。做相应的调整。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相关推荐：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面的链接可以给你很多尝试的想法，对我很有用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;我应该用多少个隐藏层？：ftp://ftp.sas.com/pub/neural/FAQ3.html#A_hl&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;我应该用多少个隐藏单元？：ftp://ftp.sas.com/pub/neural/FAQ3.html#A_hu&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;6）Batches 和 Epochs&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Batch 的大小限定了梯度以及多久更新权重。一个 epoch 是分批（batch-by-batch）暴露给网络的整个训练数据。你试验过不同的 batch 大小和 epochs 量吗？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;上面我已经谈过学习率、网络大小和 epochs 之间的关系了。带有大 epoch 的小 batch 和大量的训练 epoch 在现在的深度学习部署中很常见。以下这些方法可能不符合你的问题：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;尝试将 batch 大小与训练数据的大小对等，这依赖于内存（batch learning）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;尝试大小为 1 的 batch（在线学习）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;尝试不同 mini-batch 大小（8、16、32...）的网格搜索&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;尝试分别训练一些 epoch 以及大量的 epoch&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;考虑下接近无限量的 epoch，并设立抽查点捕捉最好的表现模型。一些网络架构要比其他架构对 batch 的大小更敏感。我认为多层感知机对 batch 大小比较稳健，LSTM 和 CNN 比较敏感，但这只是传闻。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相关推荐：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;What are batch, incremental, on-line, off-line, deterministic, stochastic, adaptive, instantaneous, pattern, constructive, and sequential learning?：ftp://ftp.sas.com/pub/neural/FAQ2.html#A_styles&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;直观上，mini-batch 的大小如何影响（随机）梯度下降的性能？：https://www.quora.com/Intuitively-how-does-mini-batch-size-affect-the-performance-of-stochastic-gradient-descent&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;7）正则化&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;正则化是遏制过拟合训练数据的很好的方法。最新的热门正则化技术是 dropout，你试过吗？Dropout 在训练期间随机跳过神经元，并强迫层内其他算法重拾这些神经元。简单而有效，开始 dropout 吧！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;网格搜索不同的 dropout 百分比。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在输入层、隐藏层和输出中试验 dropout&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;关于 dropout 的想法还有一些扩展，可以像 drop connect（http://cs.nyu.edu/~wanli/dropc/）那样尝试它们。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你也可以考虑其他更传统的神经网络正则化技术，比如：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;权重衰减以惩罚最大的权重&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;激活约束，以惩罚最大激活&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在可被惩罚的不同方面和可以应用的不同类型的惩罚（L1，L2，L1 和 L2 同时使用）上进行试验。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相关推荐：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Keras 的深度学习模型中的 dropout 正则化：http://machinelearningmastery.com/dropout-regularization-deep-learning-models-keras/&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;什么是权重衰减：ftp://ftp.sas.com/pub/neural/FAQ3.html#A_decay&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;8）优化和损失&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;曾经的方法是随机梯度下降，但现在有很多可以优化的方式。你有试过不同的优化程序吗？随机梯度下降是默认的。首先用不同的学习率、动量和学习率计划充分利用它。许多更高级的优化方法会提供更多的参数，更多的复杂性以及更快的收敛性。这是好是坏，取决于你的问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了最大化给定的方法，你真的需要深入到每一个参数，然后根据你的问题网格搜索不同的值。这困难，且耗费时间。但也可能有回报。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我发现新的/流行的方法可以收敛得更快并且能对于一个给定的网络拓扑结构的能力给出一个很快的想法，例如：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;ADAM（论文请点击「阅读原文」下载）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;RMSprop&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你还可以探索其他的优化算法，比如更传统的（Levenberg-Marquardt）和不太传统的（遗传算法）。其他的方法可以为随机梯度下降法提供很好的起点和优化的方式。要优化的损失函数和你将要解决的问题是密切相关的。不过，你会有一些回旋的余地（用于回归的 MSE 和 MAE 度量，等等），你也可能会通过换算你问题的损失函数得到一个小的凸点。这也可能与输入数据的规模和正在使用的激活函数的规模紧密相关。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相关推荐：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;梯度下降优化算法概述：http://sebastianruder.com/optimizing-gradient-descent/&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;什么是共轭梯度，Levenberg-Marquardt 等？ftp://ftp.sas.com/pub/neural/FAQ2.html#A_numanal&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;深度学习的优化算法，点击「阅读原文」下载&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;9）早停&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一旦性能开始下降，你可以终止学习。这可以节省大量的时间，甚至可能让你使用更复杂的重采样方法来评估模型的性能。早停是一种遏制训练数据过拟合的正则化手段，要求你在每一个 epoch 中监控训练模型的表现并验证数据集。一旦验证数据集的表现开始下降，训练就可以停止。如果这一条件得到满足（测量精度损失），你还可以设置检查点来保存模型，并允许模型继续学习。检查点可以让你在没有停止的情况下早停，给你几个模型在运行结束时进行选择。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相关推荐：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如何在 Keras 的深度学习模型中设置检查点：http://machinelearningmastery.com/check-point-deep-learning-models-keras/&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;什么是早停？：ftp://ftp.sas.com/pub/neural/FAQ3.html#A_stop&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;4. 用模型组合（Ensemble）来提升表现&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你可以将多个模型的预测相结合。算法调试后，这是需要改进的下一个大区域。事实上，你可以从多个足够好的模型的预测结合中获取好的表现，而不是多个高度调整（脆弱）的模型。我们会看看你可能要考虑的模型组合的三大领域：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Combine Models. 模型结合&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Combine Views. 视角结合&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Stacking. 堆&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1）模型结合&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不要选择一个模型，把它们结合起来。如果你有多个不同的深度学习模型，每个模型都在这个问题上的表现良好，那么通过取均值来结合它们的预测。模型越不相同，效果越佳。例如，你可以使用完全不同的网络拓扑结构或者不同的技术。如果每个模型都很灵巧，但方式不同，那么集成预测将更为强劲。或者，你可以用相反的位置进行试验。每次训练网络的时候，你要用不同的权重对这个网络进行初始化，该网络会收敛成一组不同的最终权重。将此过程重复多次，生成许多的网络，然后结合这些网络的预测。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;它们的预测将是高度相关的，但它可能会在这些模式上给你一个更难预测的小凸点（bump）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相关推荐：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;在 Python 中用 scikit-learn 组合机器学习算法：http://machinelearningmastery.com/ensemble-machine-learning-algorithms-python-scikit-learn/&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如何提高机器学习算法的结果：http://machinelearningmastery.com/how-to-improve-machine-learning-results/&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2）视角结合&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;正如上文所述，但是以你的问题的一个不同视角或框架来训练每个网络。再一遍，目标是得到熟练的的模型，但是用不同的方式（比如不相关的预测）。你可以依靠非常不同的缩放（scaling）和上文中提到的转换技巧。用于训练不同模型的问题的转换和框架越多，就越有可能改善你的结果。运用预测的简单平均将是一个良好的开端。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3）层叠&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你还可以了解如何最好地结合多种模型的预测。这就是所谓的层叠泛化，简称层叠（是 stacking）。通常情况下，你可以利用像正则回归这样学习如何为不同模型的预测加权的简单线性方法来取得更好均值结果。基准结果使用多个子模型的预测的平均，但是会用学到的模型权重提升表现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相关推荐：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;层叠泛化（层叠）：http://machine-learning.martinsewell.com/ensembles/stacking/&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;附加资源&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有很多很好的资源，但很少能将所有的想法都联系在一起。我将列出一些资源和相关的发布信息，如果你想深入了解，你会发现这很有趣&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相关推荐：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;神经网络常见问题解答：ftp://ftp.sas.com/pub/neural/FAQ.html&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如何在 Python 中使用 Keras 网格搜索深度学习模型的超参数：http://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;必须知道的深度神经网络提示/技巧：http://lamda.nju.edu.cn/weixs/project/CNNTricks/CNNTricks.html&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如何增加深度神经网络验证的准确性：http://stackoverflow.com/questions/37020754/how-to-increase-validation-accuracy-with-deep-neural-net&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Fri, 23 Sep 2016 17:15:03 +0800</pubDate>
    </item>
    <item>
      <title>业界 | Show and Tell：谷歌在TensorFlow上开源图像描述系统</title>
      <link>http://www.iwgc.cn/link/2808921</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Google Research blog&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;作者：Chris Shallue, Software Engineer, Google Brain Team&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;em style="color: rgb(136, 136, 136);"&gt;&lt;span&gt;2014 年，Google Brain 团队的研究科学家训练了一个自动准确描述图像内容的机器学习系统。后来对该系统的进一步开发使其赢得了微软 COCO 2015 图像描述挑战赛的并列冠军，这项比赛是为了对比出准确描述图像的最佳算法。&lt;/span&gt;&lt;/em&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;今天，该团队在 TensorFlow 上开源最新版本的图像描述系统。此次公开的版本相比于原始版本包含了对图像描述系统计算机视觉组件的极大改进，可更快速的进行训练，并产出更精细、准确的描述。这些改进在论文 Show and Tell: Lessons learned from the 2015 MSCOCO Image Captioning Challenge 中有详尽的概述与分析。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicF8wXlBVVVUGiahn69Rw7OWP82TzictcbiclPIwSHpC8m0AnmcwVibcEpBAc4SPibsQI5E4kCft0ZNvdg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;我们系统生成的对图片的自动描述&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;新旧版本有什么不同？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 2014 年的系统中，我们使用 Inception V1 图像分类模型初始设定图像编码器，它可产生对识别图像中不同物体有帮助的编码。当时，它是可用的最好的图像模型，在 ImageNet 2012 图像分类任务基准上获得了 89.6% 的准确率。在 2015 年，我们使用最新的 Inception V2 取代了 V1，V2 模型当时在同样的分类任务上取得了 91.8 % 的成绩。在此视觉组件上的进步使得我们的描述系统在 BLEU-4 标准（该标准普遍使用于机器翻译中，用来评估机器生成的句子的质量）上的准确率上升了 2 个点，这也是它能在微软图像描述挑战赛中取得成功的关键因素。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今天开放的版本使用 Inception V3 初始设定图像编码器，V3 在 ImageNet 分类任务上取得了 93.9% 的准确率。使用更好的视觉模型初始设定图像编码器使得该图像描述系统有更好的能力识别图像中的不同物体，生成更细节、更准确的描述。相比于图像挑战赛中使用的那代系统，最新的系统在 BLEU-4 标准上的准确率又有了 2 个点的改进。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对视觉组件的另一个关键改进是对图像模型的精调。在该系统中，图像编码器是由对图像中物体分类的模型进行初始化的，此次精调就解决了这个问题，因为图像描述系统的目标是使用由图像模型生成的编码描述图像中的物体。例如，一个图像分类模型可以告诉你图像中有狗、草地和飞盘，但自然描述也可以告诉你草的颜色、狗与飞盘的关联。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在精调阶段，通过在人类生成的图像描述数据上联合训练视觉和语言组件对图像描述系统进行了改进。这使得该系统能从图像中迁移出对生成描述有帮助但对物体分类没必要的信息。特别的，在精调之后，该系统能更准确的描述物体的颜色了。更重要的是，精调阶段必须发生在语言组件学会生成描述之后，否则随机初始化语言组件的噪声会不可逆的破坏视觉组件。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicF8wXlBVVVUGiahn69Rw7OWlF3P4ic9Cocroh4Ee0ZcibicvO3jBQklCKf9nIK6Urfkz0d3g1dlwkDFw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;左图：更好的图像模型使其能生成更详细、更准确的描述；右图：在精调图像模型之后，图像生成系统更能准确的描述物体颜色。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;直到最近，我们的图像描述系统才被部署到 DistBelief 软件框架中。今天公开的在 TensorFlow 中的实现取得了同样等级的准确率和极大的速度进步：在英伟达 K 20 GPU 上，相比于在 DistBelief 中每训练一步的 3 秒时间，在 TensorFlow 框架中每训练一步的时间降到了 0.7 秒，意味着总体训练时间只是之前的 25%。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;关于该系统的一个天然问题是它是否能够生成之前从未看到过的环境与互动的新型描述。该系统是通过千百张人类描述过的图像进行训练的，在看到类似于之前的场景时它总会重复使用人类的描述。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicF8wXlBVVVUGiahn69Rw7OWnQgsFfs8Ym03sZnefMPMgOzWjlhSicksT47qJIlruXFNLpbrib3IYBQg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;在看到类似于之前的场景时，该系统总是重复使用人类的描述&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以，它真的理解每张图像中的物体和物体之间的关联吗？或者说它总是在从训练数据中反刍图像的描述？无比令人激动的是，我们的模型真的开发出了在全新场景上生成准确的图像描述的能力，表明对图像中物体与环境的更深的理解。此外，它也学习如何用自然口音的英语表达知识，尽管除了阅读人类描述之外它没受过额外的语言训练。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicF8wXlBVVVUGiahn69Rw7OWKYv58Kl9eeveic4PIVeVSZhiaKswEv17I9EzMibACS2lIh00icVNf64wDg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;我们的模型使用从训练集类似场景中学到的概念，生成全新的图像描述。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们希望在 TensorFlow 中开源的这一模型能推进图像描述研究与应用，也使得更多刚兴趣的人能进行学习。想要训练自己的图像描述系统以及获取更多关于该神经网络架构的细节，浏览该模型的代码主页：https://github.com/tensorflow/models/tree/master/im2txt。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然我们的系统使用的是 Inception V3 图像分类模型，你也可以尝试使用最新发布的 Inception-ResNet-v2 模型训练该系统，看看结果是否会更好。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;点击阅读原文，下载论文↓↓↓&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Fri, 23 Sep 2016 17:15:03 +0800</pubDate>
    </item>
    <item>
      <title>学界 | Yoshua Bengio新论文提出量子化神经网络：训练带有低精度权重和激活的神经网络</title>
      <link>http://www.iwgc.cn/link/2808922</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自 arxiv.org &lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicF8wXlBVVVUGiahn69Rw7OW29rANRz9RFqWWMk0a4avNA9uWaiaZoedA7VjARzMUFgcVTZZL9qq6lA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：我们在这里介绍一种用来在运行时间（run-time）训练量子化神经网络（QNN：Quantized Neural Networks）——一种带有极低精度（如：1 bit）的权重（weights）和激活（activation）的神经网络——的方法。在训练时间（train-time），量子化的权重和激活被用于计算参数梯度。在前向通过的过程中，QNN 会极大地减少内存大小和接入，并使用位形式的运算（bit-wise operations）代替大部分算术运算。这样有望极大地降低功率消耗。我们在 MNIST、CIFAR-10、SVHN 和 ImageNet 数据集上训练了 QNN。训练出的 QNN 实现了可与 32 bit 的同类媲美的预测精度。比如说，我们的带有 1 bit 权重和 2 bit 激活的 AlexNet 的量子化版本实现了 51% 的 top-1 精度。此外，我们还将参数梯度量子化到了 6 bit，这使得梯度计算仅能使用位形式的计算。量子化循环神经网络（quantized recurrent neural networks）在 Penn Treebank 数据集上进行了测试，仅使用 4 bit 就实现了其同类的 32 bit 网络所达到的精度。最后但并非不重要的是，我们编程了一个二元矩阵乘法 GPU 核（kernel）；比起未经优化过的 GPU 核，在我们的 GPU 核上运行 MNIST QNN 的速度可以快上 7 倍，而且在分类精度上不会出现任何损失。该 QNN 代码已经在网上发布。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;代码发布地址：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Theano 框架：https://github.com/MatthieuCourbariaux/BinaryNet&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Torch 框架：https://github.com/itayhubara/BinaryNet&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;点击阅读原文，下载论文↓↓↓&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;</description>
      <pubDate>Fri, 23 Sep 2016 17:15:03 +0800</pubDate>
    </item>
    <item>
      <title>SyncDaily | 苹果收购机器学习公司Tuplejump、谷歌放出测试版VR SDK</title>
      <link>http://www.iwgc.cn/link/2808923</link>
      <description>&lt;blockquote&gt;&lt;em style="color: rgb(136, 136, 136); line-height: 1.75em; text-align: justify; white-space: pre-wrap;"&gt;&lt;span&gt;苹果收购机器学习公司Tuplejump、Facebook Messenger 新功能：投票+自动转账......机器之心日报，精选一天前沿科技优质内容。&lt;/span&gt;&lt;/em&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h2 style="margin-top: 8px; font-weight: bold; max-width: 100%; white-space: normal; border-color: rgb(216, 40, 33); text-align: justify; color: rgb(216, 40, 33); line-height: 28px; font-family: 微软雅黑; border-bottom-width: 2px; border-bottom-style: solid; min-height: 32px; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;span&gt;&lt;/span&gt;确认收购Tuplejump，苹果又买了一家机器学习公司&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicF8wXlBVVVUGiahn69Rw7OWQIOAMu0xicBf3Rn6Bq7ewOeoyGSYxzURaIP9UicKJGTmjiacnzjeB7JhA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;苹果今日确认收购 Tuplejump，一家来自印度的初创企业，该公司目前主要做的是对数据进行储存、处理、查询数据以及可视化的工作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是继去年底收购 Perceptio 和不久前收购 Turi 后，苹果又一次收购的机器学习公司。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;苹果的发言人未证实也未否认此消息，这是该公司事实上收购了的标准做法，收购协议的条款并未披露。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Tuplejump 公司 2013 年成立于印度海得拉巴，与多数机器学习公司一样，其并非家喻户晓。目前该公司网站无法进行访问。该公司自称是大数据技术早期使用者，主要帮助财富 500 强公司来使用这些技术。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Tuplejump 还建立了一个开源目录搜索系统，简化数据管理技术，使数据使用起来变得非常简单。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;据悉苹果对 Tuplejump 开发的开源项目 FiloDB 特别感兴趣，FiloDB 主要由 Evan Chan 负责，据他的 LinkedIn 资料页面显示，他是在 2015 年 8 月加入 Tuplejump，该技术可将应用机器学习概念和分析有效应用到大量复杂数据中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;h2 style="margin-top: 8px; font-weight: bold; max-width: 100%; white-space: normal; border-color: rgb(216, 40, 33); text-align: justify; color: rgb(216, 40, 33); line-height: 28px; font-family: 微软雅黑; border-bottom-width: 2px; border-bottom-style: solid; min-height: 32px; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;span&gt;&lt;/span&gt;Facebook Messenger 新功能：投票+自动转账&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Facebook 打算在自家聊天应用 Messenger 中增加两项新功能：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;一个是群聊投票&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;另一个是通过机器学习技术来检测转账交易&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些新功能最快本周就能上线，不过目前仅限美国用户使用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicF8wXlBVVVUGiahn69Rw7OWIqxfgpRBIXoYLKz8a0agXwFiavO1sZznVeI5X9Kj1dy4AncY2RWExfQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;聊天应用一大好处就是群组聊天十分便利，但也正因为人数众多，每当大家要做决定时众口难调。所以 Facebook 计划只在群组聊天中推出「投票」这项新功能，只要输入问题和一些选项，群组中任何人都能直接发起投票，且投票没有时间限制。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicF8wXlBVVVUGiahn69Rw7OWRkXqiaHtbKJ9k2Hyxy09sCJdflLprtFUyWKFChALCVNeaicX56yddlIQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;另一个新功能是利用机器学习技术来检测用户的转账交易，通过这项技术对用户对话中的内容进行分析。当出现相关词汇时，在 Facebook Messenger 应用中将会出现转账链接，用户可以通过这个链接直接进行转账操作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h2 style="margin-top: 8px; font-weight: bold; max-width: 100%; white-space: normal; border-color: rgb(216, 40, 33); text-align: justify; color: rgb(216, 40, 33); line-height: 28px; font-family: 微软雅黑; border-bottom-width: 2px; border-bottom-style: solid; min-height: 32px; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;span&gt;&lt;/span&gt;Uber的新加坡对手Grab也能叫到无人车了&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicF8wXlBVVVUGiahn69Rw7OWt2bbGicjJd5NUTwZAePBp77wX4bMr1zahxu09I9ylibFrXdY01kpUr5w/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;据外媒报道，新加坡打车应用 Grab 与创业公司 nuTonomy 达成合作，在新加坡测试自动驾驶技术。从周五开始，Grab 用户将能够预约到 nuTonomy 的无人车。就在几天前，Uber 开始在匹兹堡面向公众测试自动驾驶汽车。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前，科技公司和汽车制造商都在争相开发自动驾驶汽车，制定新的商业计划。从长期来看，自动驾驶汽车预计将改变个人出行方式。Grab 表示，其应用将允许选定通勤者在新加坡西部地区和毗邻区预约并乘坐 nuTonomy 无人车。nuTonomy 无人车目前正在新加坡西部地区进行测试。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Grab 和 nuTonomy 在一份声明中称，每一辆无人车中都将配备一位负责安全的司机和一位技术支持工程师。nuTonomy 从今年 8 月份开始在新加坡对其首辆无人驾驶出租车进行公开测试，该公司希望于 2018 年在新加坡推出 100 辆可商业化运营的无人驾驶出租车。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h2 style="margin-top: 8px; font-weight: bold; max-width: 100%; white-space: normal; border-color: rgb(216, 40, 33); text-align: justify; color: rgb(216, 40, 33); line-height: 28px; font-family: 微软雅黑; border-bottom-width: 2px; border-bottom-style: solid; min-height: 32px; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;span&gt;&lt;/span&gt;微软编程语言 TypeScript 2.0 发布&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicF8wXlBVVVUGiahn69Rw7OWjSaIfiaCEpZbmCMxECgNmB8jia2UWibXCEicdx238BmLQJEkUibseUiaQzLw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;微软在 JavaScript 基础上开发的编程语言 TypeScript 发布了 2.0 版。开发 JavaScript 大型程序是一大挑战，原因是它在程序运行时才执行错误检查，而其它静态编译语言开发的程序是在编译时就会执行错误检查。通过 TypeScript，微软在保证兼容性的同时为 JavaScript 引入了类似其它语言的错误和验证。在 TypeScript 2.0 中，微软引入的最大变化是对 null 值的控制。null 被用于表示没有任何值的变量。但 null 引用会导致很多问题，它的发明被作者称为是「十亿美元错误」，然而所有主流编程语言都支持 null 概念。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;微软为 TypeScript 2.0 加入了控制 null 值的选项，启用选项后变量默认被要求设定一个值，避免无意中将变量值设为 null。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;h2 style="margin-top: 8px; font-weight: bold; max-width: 100%; white-space: normal; border-color: rgb(216, 40, 33); text-align: justify; color: rgb(216, 40, 33); line-height: 28px; font-family: 微软雅黑; border-bottom-width: 2px; border-bottom-style: solid; min-height: 32px; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;span&gt;&lt;/span&gt;谷歌放出测试版VR SDK，开发者可开发Daydream应用了&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicF8wXlBVVVUGiahn69Rw7OWjcxR8ictagyjbAW9AicibDGbcZoO9LkLStuVtlDW2qian9QTp8Jyt8rwWA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;据外媒报道，在今年 5 月的 Google I/O 大会上，谷歌推出了高质量的移动 VR 平台 Daydream。在收集了数月的反馈后，它们终于放出了测试版的谷歌 VR SDK，开发者可以开始打造 Daydream 应用了。此外，由于谷歌已经与 Unity 和 Unreal 达成合作，开发者们还能直接用上两家公司的游戏引擎和开发工具。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一版 SDK 简化了 VR 开发任务，允许开发者集中精力打造「沉浸感十足的移动交互 VR 应用。」同时，它还支持异步投影技术（asynchronous reprojection，可提高刷新率）和高保真立体音效。此外，Daydream 的手柄可玩性也很强。谷歌 VR SDK 原生就支持 Unity 的引擎和开发工具，因此游戏可以得到更好的优化。此外，SDK 中还加入了对头部追踪和深度链接的支持。同时，Unreal Engine 4 的加入也让开发者如虎添翼。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编辑整理，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/640?wx_fmt=png"/&gt;&lt;/p&gt;</description>
      <pubDate>Fri, 23 Sep 2016 17:15:03 +0800</pubDate>
    </item>
    <item>
      <title>深度 | 从硬件配置到软件安装，一台深度学习机器的配备指南</title>
      <link>http://www.iwgc.cn/link/2792414</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自graphific.github.io &lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;作者：Roelof Pieters&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李亚洲、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;本文作者 Roelof Pieters 是瑞典皇家理工学院 Institute of Technology &amp;amp; Consultant for Graph-Technologies 研究深度学习的一位在读博士，他同时也运营着自己的面向客户的深度学习产品。对于写作这个系列文章的动机，他写道：「我已经习惯了在云上工作，并且还将继续在云上开发面向产品的系统/算法。但是在更面向研究的任务上，基于云的系统还存在一些缺陷，因为在研究时你要做的基本上就是尝试各种各样的算法和架构，并且需要快速改进和迭代。为了做到这一点，我决定自己使用 GPU 设计和打造自己的量身定制的深度学习系统。在这一些方面这比我想象的简单，但另一些方面却更困难。在接下来的文章中，我会和你分享我的『冒险之旅』，不关你是深度学习实践的新手还是老手，希望这都对你有用。」目前该系列文章已经更新了两篇，机器之心将其统一编译到了这篇文章中。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;第一部分：硬件平台搭建&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOwIooT5Fz9r9ps6LXYb0t2PmyWquGMTbbX6edQEjaPueF9TeznG0Lgrg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你像我一样，每天（和每夜）都在和实际的机器学习应用打交道，你就知道在完成一项任务时如果没有合适的硬件会有多么痛苦。不管你是业界人士还是在学术界工作，为了一项实验或计算的结果等待不必要长的时间总是会让人感到烦恼。对于用于生产的研究和开发，高速硬件是必需的，而 GPU 通常是我们所面临的主要瓶颈，尤其对于深度神经网络（DNN）更是如此。是的，确实是这样：亚马逊这样的云提供商以低于每小时 1 美元的价格出售可以执行 GPU 计算的实例和可以导出、共享和重复使用的可以直接进行生产的虚拟机。如果你常常从头开始安装库，你可能知道软件和硬件库都可以使用定期更新的安装脚本或 dockerized 容器轻松地完成安装。这些都还不错。但是如果一个应用的需求超过了亚马逊所能提供的 4GB GPU 呢（即使他们最新的 g2.8xlarge 仍然也只提供同样的 4GB GPU）？其它云提供商也很少提供更大的 GPU（通常是 6GB），而且似乎都是专门为特定的应用（视频版或生物科学）定制的。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;那么如果你有这种需求，你该怎么做呢？很简单，搭建你自己的 GPU 平台！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;目录&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;了解你的研究&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;起步：选择正确的组件&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;将它们组装到一起&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;DIY 或寻求帮助&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;选项 A：DIY&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;选项 B：外界帮助&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;了解你的研究&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一旦我决定了搭建我自己的 GPU 系统时，我首先想到的是：为什么要这么麻烦自己去搭建一个呢，英伟达不是刚发布了其强大的 DevBox 吗，而且还可能有其它供应商也在为深度学习应用做同样的事？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;确实如此，也有一些其它公司在生产面向研究的机器，但它们都不面向欧洲发售。英伟达的 DevBox 也仅在美国出售，而且价格还高得离谱（大约 9000 美元的硬件组件售价 1.5 万美元），而且还要排队等待。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以该怎么办呢？简单：搭建你自己的 GPU 平台！&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;起步：选择正确的组件&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;浏览网络时我发现 Tim Dettmers 的博客（http://timdettmers.com/）很好地讲解了如何为深度学习应用选择合适的 GPU 和硬件。在这里我不打算将他说过的内容再完全重复一遍。你可以自己去他的博客看！文章和下面的评论都值得一读。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;简而言之：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;双精度（比如英伟达的 Tesla K20/40/80）完全是浪费钱，因为 DNN 不需要这样的精度；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;想想你现在和未来需要多少个 GPU。4 个 GPU 是最多了，因为再多也不能再带来太多性能增益了。这主要是因为最好的主板最多只支持最多 40 个通道（以 16x8x8x8 的配置）。另外，每个 GPU 都会增加一定的管理工作——你的系统需要决定使用哪个 GPU 来执行哪项任务。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;获取一个支持 PCIe 3.0 的主板，它还要支持一根线缆上带有 8pin + 6pin 的 PCIe 电源连接器，这样你才能添加到 4 个 GPU。主板还应该支持你的 GPU 配置，即支持 x8/x8/x8/x8 的 4 GPU 设置的物理线路；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;找一个能把所有东西都装进去的机箱。越大的机箱空气流动就越好。确保有足够的 PCIe 槽以支持所有 GPU 以及其它你可能需要安装的 PCIe 卡（比如高速千兆网卡等）。一个 GPU 通常会占据 2 个 PCIe 插槽的空间。一个典型的机箱需要有 7 个 PCIe 槽，因为最后一个安装在底部的 GPU 可以仅使用一个槽。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;CPU 不需要非常快，也不需要有很多核。只需要确保 CPU 的核数至少是你的 GPU 的数量的两倍就可以了（再次强调：要考虑未来的使用情况；英特尔的 CPU 通常一个核有两个线程）。还要确保该 CPU 支持 40 个 PCIe 通道，一些新的 Haswell CPU 只支持 32 个；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;RAM 大小是你的全部 GPU 内存之和的两倍；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;SSD 很不错，但除非决定有必要才用——如果你加载的数据无法配入到 GPU 内存和 RAM 的组合中。如果你确实要使用一个 SSD，它的容量至少应该大于你最大的数据集；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;至于普通的机械硬盘，你可能需要大量的磁盘空间来存储你的数据集和其它类型的数据。如果你需要至少 3 个同样大小的磁盘，RAID5 就很不错。基本上一旦发生单个错误时，你不会丢失你的数据。用于提升性能的 RAID0 等其它 RAID 配置通常没多大用处：你可用 SSD 提速，而且它已经超过了你的 GPU 通过 PCIe 带宽加载数据的速度；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;至于供电单元（PSU），只要你负担得起，就尽可能选一个最高效的，并且要把你所需要的总功率考虑在内（要考虑未来的使用）：钛或铂金品质的 PSU 值得你花钱购买：你能省钱和保护环境，因为其所节省的电力开销用不了多久就能把你的额外购买成本节省回来。对于 4 GPU 系统，你大概需要 1500 到 1600 W；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;冷却是非常非常重要的，因为它会同时影响到性能和噪音。你需要一直将 GPU 的温度保持在 80 度（约 26.7 摄氏度）以下。更高的温度会拉低该单元的电压并影响到性能。另外，太高的温度也对你的 GPU 有害；这是你需要避免的。冷却有两种主要选项：风冷（风扇）和水冷（管道）：&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: circle;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;风冷更便宜、安装和维护更简单、但会制造大量噪音；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;水冷价格更高、难以正确安装，但没有任何噪音，而且对组件的冷却效果也好得多。但你总归需要机箱风扇来冷却其它组件，所以你总会听到一些噪音，但会比全风冷的系统的噪音小。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;将它们组装到一起&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;根据我读到的内容、Tim Dettmers 的回复和英伟达的 DevBox and Gamer 论坛的建议，我开始将这些组件组装到一起。很明显这台机器受到了英伟达 DevBox 的部分启发（至少机箱是这样），但价格差不多只有 DevBox 的一半。&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;机箱：Carbide Air 540 High Airflow ATX Cube&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;主板：华硕 X99-E WS 工作站级主板，带有 4 路 PCI-E Gen3 x16 支持&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;RAM：64GB DDR4 Kingston 2133Mhz (8x8GB)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;CPU：Intel(Haswell-e) Core i7 5930K (http://ark.intel.com/products/82931/Intel-Core-i7-5930K-Processor-15M-Cache-up-to-3_70-GHz) (6 Core 3.5GHz)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;GPU：3 块 NVIDIA GTX TITAN-X 12GB&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;HDD：3 块 RAID5 配置的 3TB WD Red&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;SSD：2 块 500GB SSD Samsung EVO 850&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;PSU： Corsair AX1500i (1500 W) 80 Plus Titanium (94% 的能效)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;冷却：用于 CPU 和 GPU 的自制水冷系统（软管）：在机箱顶部钻了一个注水孔，前面有一个透明的储水器（见下图）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOwXTqYO0hetKia6KrHt1ZlrrrHsXKibrldc6zqhFHbWP6xSyk1C5gKMLzA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;左图：正在构建中的系统。你可以看到用于水冷的塑料管穿过 Carbide Air 540 机箱上原本就有的孔洞。主板是竖直安装的。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;中图和右图：建造好的系统。注意可以从外面看到的储水器。还可以看到从上至下的红色塑料管：上连注水口，下接水泵，穿过安装在 GPU 上的散热器模块。还可以看到 CPU 上有一个类似的结构。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;DIY 或寻求帮助&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;选项 A：DIY&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当然，如果你有时间和意愿自己动手打造所有的一切，这将成为你完全理解各个组件的工作方式以及哪些硬件可以很好适配的绝佳方法。另外，你也可能能更好地理解当组件出现故障时应该做什么并更轻松地修复它。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;选项 B：外界帮助&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一种选择是寻找专业的公司预定零件并让他们帮助组装好整个系统。你要寻找的这类公司应该是定制游戏机电脑的公司，他们常常为游戏玩家打造定制化的系统。他们甚至有水冷系统的经验，尽管游戏机电脑通常只需要水冷 CPU，但他们会有很好用的工具套件。当然，为了安装全水冷系统，你需要将 GPU 外壳打开，将芯片暴露出来安装散热片，再装上水管、压缩机帽等等各种所需的组件。不过水冷也有麻烦的地方：一旦出现漏水，你的 GPU 和其它组件就会被毁坏。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因为我觉得我不能将这些东西装在一起以及正确地安装水冷气系统，而且我还没有多少时间阅读操作手册，所以我选择了第二种方案：找了一个非常熟练的硬件打造商帮我组装了我的深度学习机器的第一个版本。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;第二部分：安装软件和库&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;目录&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;软件和库&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="list-style-type: decimal;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;安装 CUDA&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;测试 CUDA&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;深度学习库&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;软件和库&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在，我们有了一台裸机，是时候安装软件了！网上已有有了一些好的博文指导安装深度学习工具和库。为了简单化，我临时把一些要旨放在一起。这篇个文章将帮助你安装英伟达 CUDA 驱动，以及我青睐的一些深度学习工具与库。此外，我也假设你已经在电脑上安装了 Ubuntu 14.04.3 作为操作系统。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1.安装 CUDA&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;让图像驱动程序能正常工作是一件很痛苦的事。我当时的问题是 Titan X GPU 只能得到 Nvidia 346 的支持，这些驱动不能在我特定的监控器下工作。经过一些 xconfig 改装，我终于让它能在高于 800×600 的分辨率下工作了，我使用了 LINUX X64 (AMD64/EM64T) DISPLAY DRIVER 352.30 版本作为图像驱动。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;设置演示安装的是 CUDA 7.0，我选择安装最新的 CUDA 7.5。虽然该版本的确有所改进，但在一些库上也难以正常工作。如果你想快速启动并运行，可以尝试 7.0 版本。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;!/usr/bin/env bash&lt;br/&gt;# Installation script for Cuda and drivers on Ubuntu 14.04, by Roelof Pieters (@graphific)&lt;br/&gt;# BSD License&lt;br/&gt;if [ "$(whoami)" == "root" ]; then&lt;br/&gt; &amp;nbsp;echo "running as root, please run as user you want to have stuff installed as"&lt;br/&gt; &amp;nbsp;exit 1&lt;br/&gt;fi&lt;br/&gt;###################################&lt;br/&gt;# &amp;nbsp; Ubuntu 14.04 Install script for:&lt;br/&gt;# - Nvidia graphic drivers for Titan X: 352&lt;br/&gt;# - Cuda 7.0 (7.5 gives "out of memory" issues)&lt;br/&gt;# - CuDNN3&lt;br/&gt;# - Theano (bleeding edge)&lt;br/&gt;# - Torch7&lt;br/&gt;# - ipython notebook (running as service with circus auto(re)boot on port 8888)&lt;br/&gt;# - itorch notebook (running as service with circus auto(re)boot on port 8889)&lt;br/&gt;# - Caffe &lt;br/&gt;# - OpenCV 3.0 gold release (vs. 2015-06-04)&lt;br/&gt;# - Digits&lt;br/&gt;# - Lasagne&lt;br/&gt;# - Nolearn&lt;br/&gt;# - Keras&lt;br/&gt;###################################&lt;br/&gt;&lt;br/&gt;# started with a bare ubuntu 14.04.3 LTS install, with only ubuntu-desktop installed&lt;br/&gt;# script will install the bare minimum, with all "extras" in a seperate venv&lt;br/&gt;&lt;br/&gt;export DEBIAN_FRONTEND=noninteractive&lt;br/&gt;&lt;br/&gt;sudo apt-get update -y&lt;br/&gt;sudo apt-get install -y git wget linux-image-generic build-essential unzip&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;# manual driver install with:&lt;br/&gt;# sudo service lightdm stop&lt;br/&gt;# (login on non graphical terminal)&lt;br/&gt;# wget http://uk.download.nvidia.com/XFree86/Linux-x86_64/352.30/NVIDIA-Linux-x86_64-352.30.run&lt;br/&gt;# chmod +x ./NVIDIA-Linux-x86_64-352.30.run&lt;br/&gt;# sudo ./NVIDIA-Linux-x86_64-352.30.run&lt;br/&gt;&lt;br/&gt;# Cuda 7.0&lt;br/&gt;# instead we install the nvidia driver 352 from the cuda repo&lt;br/&gt;# which makes it easier than stopping lightdm and installing in terminal&lt;br/&gt;cd /tmp&lt;br/&gt;wget http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1404/x86_64/cuda-repo-ubuntu1404_7.0-28_amd64.deb&lt;br/&gt;sudo dpkg -i cuda-repo-ubuntu1404_7.0-28_amd64.deb&lt;br/&gt;&lt;br/&gt;echo -e "\nexport CUDA_HOME=/usr/local/cuda\nexport CUDA_ROOT=/usr/local/cuda" &amp;gt;&amp;gt; ~/.bashrc&lt;br/&gt;echo -e "\nexport PATH=/usr/local/cuda/bin:\$PATH\nexport LD_LIBRARY_PATH=/usr/local/cuda/lib64:\$LD_LIBRARY_PATH" &amp;gt;&amp;gt; ~/.bashrc&lt;br/&gt;&lt;br/&gt;echo "CUDA installation complete: please reboot your machine and continue with script #2"&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2. 测试 CUDA&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;完成安装了？很好，接下来让我们看一下 CUDA 驱动是否能够正常工作。直接进入 CUDA 样本目录，运行 ./deviceQuery。你的 GPU 应该会被显示如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOwE3NZHSXicdLje6gyeoCPEMnFH9Miby043ZzufY4ctqO3ic0BIAmfWfrbQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;#!/usr/bin/env bash&lt;br/&gt;# Test script for checking if Cuda and Drivers correctly installed on Ubuntu 14.04, by Roelof Pieters (@graphific)&lt;br/&gt;# BSD License&lt;br/&gt;&lt;br/&gt;if [ "$(whoami)" == "root" ]; then&lt;br/&gt; &amp;nbsp;echo "running as root, please run as user you want to have stuff installed as"&lt;br/&gt; &amp;nbsp;exit 1&lt;br/&gt;fi&lt;br/&gt;###################################&lt;br/&gt;# &amp;nbsp; Ubuntu 14.04 Install script for:&lt;br/&gt;# - Nvidia graphic drivers for Titan X: 352&lt;br/&gt;# - Cuda 7.0 (7.5 gives "out of memory" issues)&lt;br/&gt;# - CuDNN3&lt;br/&gt;# - Theano (bleeding edge)&lt;br/&gt;# - Torch7&lt;br/&gt;# - ipython notebook (running as service with circus auto(re)boot on port 8888)&lt;br/&gt;# - itorch notebook (running as service with circus auto(re)boot on port 8889)&lt;br/&gt;# - Caffe &lt;br/&gt;# - OpenCV 3.0 gold release (vs. 2015-06-04)&lt;br/&gt;# - Digits&lt;br/&gt;# - Lasagne&lt;br/&gt;# - Nolearn&lt;br/&gt;# - Keras&lt;br/&gt;###################################&lt;br/&gt;&lt;br/&gt;# started with a bare ubuntu 14.04.3 LTS install, with only ubuntu-desktop installed&lt;br/&gt;# script will install the bare minimum, with all "extras" in a seperate venv&lt;br/&gt;&lt;br/&gt;export DEBIAN_FRONTEND=noninteractive&lt;br/&gt;&lt;br/&gt;# Checking cuda installation&lt;br/&gt;# installing the samples and checking the GPU&lt;br/&gt;cuda-install-samples-7.0.sh ~/&lt;br/&gt;cd NVIDIA\_CUDA-7.0\_Samples/1\_Utilities/deviceQuery &amp;nbsp;&lt;br/&gt;make &amp;nbsp;&lt;br/&gt;&lt;br/&gt;#Samples installed and GPU(s) Found ?&lt;br/&gt;./deviceQuery &amp;nbsp;| grep "Result = PASS"&lt;br/&gt;greprc=$?&lt;br/&gt;if [[ $greprc -eq 0 ]] ; then&lt;br/&gt; &amp;nbsp; &amp;nbsp;echo "Cuda Samples installed and GPU found"&lt;br/&gt; &amp;nbsp; &amp;nbsp;echo "you can also check usage and temperature of gpus with nvidia-smi"&lt;br/&gt;else&lt;br/&gt; &amp;nbsp; &amp;nbsp;if [[ $greprc -eq 1 ]] ; then&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;echo "Cuda Samples not installed, exiting..."&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;exit 1&lt;br/&gt; &amp;nbsp; &amp;nbsp;else&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;echo "Some sort of error, exiting..."&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;exit 1&lt;br/&gt; &amp;nbsp; &amp;nbsp;fi&lt;br/&gt;fi&lt;br/&gt;&lt;br/&gt;echo "now would be time to install cudnn for a speedup"&lt;br/&gt;echo "unfortunately only available by registering on nvidias website:"&lt;br/&gt;echo "https://developer.nvidia.com/cudnn"&lt;br/&gt;echo "deep learning libraries can be installed with final script #3"&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3. 深度学习库&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;好了，来到最后一步，它也是很有趣的一部分：选择个人偏好的深度学习库，这也是由所在领域所决定的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;作为研究人员，Theano 能给你最大的自由度，做自己想做的事。你可以自己部署许多事，也因此更能深度理解 DNN 如何工作。但对想首先尝试下的初学者来说可能不合适。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;我个人是 Keras（主要贡献者：François Chollet，已经加入了谷歌）和 Lasagne（8 个人的团队，但主要贡献者是 Sander Dielemans，近期读完了博士，如今加入了谷歌 DeepMind）的粉丝。这两个库有很好的抽象水平，也被积极的开发，也提供插入自己模块或代码工程的简单方式。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如果你习惯 Python，那使用 Torch 会具有挑战性，因为你需要学习 Lua。在使用 Torch 一段时间之后，我可以说它是一个很好使用的语言。唯一一个问题是从其他语言接入到 Lua 很难。对研究目的，Torch 表现也很好。但对生产水平管道而言，Torch 难以进行测试，而且看起来完全缺乏任何类型的错误处理。Torch 积极的一面有：支持 CUDA，有很多可以使用的 程序包。Torch 看起来也是产业内使用最普遍的库。Facebook（Ronan Collobert &amp;amp; Soumith Chintala）、DeepMind（Koray Kavukçuoğlu）、Twitter（Clement Farabet）的这些人都是主要贡献者。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Caffe 是之前占据主导地位的深度学习框架（主要用于 Convnets），如今仍在被普遍使用，也是一个可以作为开始的很好的框架。训练制度（solver.prototxt）与架构（train val.prototxt）文档之间的分离使得实验更容易进行。我发现 Caffe 也是唯一一个支持使用电脑外多 GPU 的框架，你可以穿过 GPU 或 GPU id 参数使用所有可用的 GPU。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;Blocks 是最近的一款基于 Python 的框架，很好的分离了自己编写的模块与被称为 Brick 的模块。特别是其 partner「Fuel」，是一个处理数据的很好方式。Fuel 是一个对许多已有的或你自己的数据集的 wrapper。它利用「iteration schemes」将数据导流到模型中，并可以「transformers」所有类型的数据转换和预处理步骤。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Neon 是 Nervana System 公司基于 Python 的深度学习框架，建立在 Nervana 的 GPU Kernel（对英伟达 CuDNN 的替代）之上。Neon 是运行该特殊 Kernel 的唯一框架，最新的基准测试显示在一些特定任务上它是最快的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOwHWOlLv9578czee8dNRibGZhoiaEAia8Aibr7wemR7urChwUm0kICZpX4Zg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;展示深度学习库（面向 Python）的另一种方式：从更低层次的 DIY 到更高层次的、更功能性的框架。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;准备好了吗？下面的脚本将安装 Theano、Torch、Caffe、Digits、Lasange、Keras。我们之前用过 Digits，但它是一个建立在 Caffe 之上的图形网页接口。这相当的基础，但如果你刚开始的话，训练一些 ConvNets 以及建立一些图形分类器会是很简单的方法。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;#!/usr/bin/env bash&lt;br/&gt;# Installation script for Deep Learning Libraries on Ubuntu 14.04, by Roelof Pieters (@graphific)&lt;br/&gt;# BSD License&lt;br/&gt;&lt;br/&gt;orig_executor="$(whoami)"&lt;br/&gt;if [ "$(whoami)" == "root" ]; then&lt;br/&gt; &amp;nbsp;echo "running as root, please run as user you want to have stuff installed as"&lt;br/&gt; &amp;nbsp;exit 1&lt;br/&gt;fi&lt;br/&gt;###################################&lt;br/&gt;# &amp;nbsp; Ubuntu 14.04 Install script for:&lt;br/&gt;# - Nvidia graphic drivers for Titan X: 352&lt;br/&gt;# - Cuda 7.0 (7.5 gives "out of memory" issues)&lt;br/&gt;# - CuDNN3&lt;br/&gt;# - Theano (bleeding edge)&lt;br/&gt;# - Torch7&lt;br/&gt;# - ipython notebook (running as service with circus auto(re)boot on port 8888)&lt;br/&gt;# - itorch notebook (running as service with circus auto(re)boot on port 8889)&lt;br/&gt;# - Caffe &lt;br/&gt;# - OpenCV 3.0 gold release (vs. 2015-06-04)&lt;br/&gt;# - Digits&lt;br/&gt;# - Lasagne&lt;br/&gt;# - Nolearn&lt;br/&gt;# - Keras&lt;br/&gt;###################################&lt;br/&gt;&lt;br/&gt;export DEBIAN_FRONTEND=noninteractive&lt;br/&gt;sudo apt-get install -y libncurses-dev&lt;br/&gt;&lt;br/&gt;# next part copied from (check there for newest version): &lt;br/&gt;# https://github.com/deeplearningparis/dl-machine/blob/master/scripts/install-deeplearning-libraries.sh&lt;br/&gt;&lt;br/&gt;####################################&lt;br/&gt;# Dependencies&lt;br/&gt;####################################&lt;br/&gt;&lt;br/&gt;# Build latest stable release of OpenBLAS without OPENMP to make it possible&lt;br/&gt;# to use Python multiprocessing and forks without crash&lt;br/&gt;# The torch install script will install OpenBLAS with OPENMP enabled in&lt;br/&gt;# /opt/OpenBLAS so we need to install the OpenBLAS used by Python in a&lt;br/&gt;# distinct folder.&lt;br/&gt;# Note: the master branch only has the release tags in it&lt;br/&gt;sudo apt-get install -y gfortran&lt;br/&gt;export OPENBLAS_ROOT=/opt/OpenBLAS-no-openmp&lt;br/&gt;export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$OPENBLAS_ROOT/lib&lt;br/&gt;if [ ! -d "OpenBLAS" ]; then&lt;br/&gt; &amp;nbsp; &amp;nbsp;git clone -q --branch=master git://github.com/xianyi/OpenBLAS.git&lt;br/&gt; &amp;nbsp; &amp;nbsp;(cd OpenBLAS \&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;amp;&amp;amp; make FC=gfortran USE_OPENMP=0 NO_AFFINITY=1 NUM_THREADS=$(nproc) \&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;amp;&amp;amp; sudo make install PREFIX=$OPENBLAS_ROOT)&lt;br/&gt; &amp;nbsp; &amp;nbsp;echo "export LD_LIBRARY_PATH=$LD_LIBRARY_PATH" &amp;gt;&amp;gt; ~/.bashrc&lt;br/&gt;fi&lt;br/&gt;sudo ldconfig&lt;br/&gt;&lt;br/&gt;# Python basics: update pip and setup a virtualenv to avoid mixing packages&lt;br/&gt;# installed from source with system packages&lt;br/&gt;sudo apt-get update -y &lt;br/&gt;sudo apt-get install -y python-dev python-pip htop&lt;br/&gt;sudo pip install -U pip virtualenv&lt;br/&gt;if [ ! -d "venv" ]; then&lt;br/&gt; &amp;nbsp; &amp;nbsp;virtualenv venv&lt;br/&gt; &amp;nbsp; &amp;nbsp;echo "source ~/venv/bin/activate" &amp;gt;&amp;gt; ~/.bashrc&lt;br/&gt;fi&lt;br/&gt;source venv/bin/activate&lt;br/&gt;pip install -U pip&lt;br/&gt;pip install -U circus circus-web Cython Pillow&lt;br/&gt;&lt;br/&gt;# Checkout this project to access installation script and additional resources&lt;br/&gt;if [ ! -d "dl-machine" ]; then&lt;br/&gt; &amp;nbsp; &amp;nbsp;git clone git@github.com:deeplearningparis/dl-machine.git&lt;br/&gt; &amp;nbsp; &amp;nbsp;(cd dl-machine &amp;amp;&amp;amp; git remote add http https://github.com/deeplearningparis/dl-machine.git)&lt;br/&gt;else&lt;br/&gt; &amp;nbsp; &amp;nbsp;if &amp;nbsp;[ "$1" == "reset" ]; then&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;(cd dl-machine &amp;amp;&amp;amp; git reset --hard &amp;amp;&amp;amp; git checkout master &amp;amp;&amp;amp; git pull --rebase $REMOTE master)&lt;br/&gt; &amp;nbsp; &amp;nbsp;fi&lt;br/&gt;fi&lt;br/&gt;&lt;br/&gt;# Build numpy from source against OpenBLAS&lt;br/&gt;# You might need to install liblapack-dev package as well&lt;br/&gt;# sudo apt-get install -y liblapack-dev&lt;br/&gt;rm -f ~/.numpy-site.cfg&lt;br/&gt;ln -s dl-machine/numpy-site.cfg ~/.numpy-site.cfg&lt;br/&gt;pip install -U numpy&lt;br/&gt;&lt;br/&gt;# Build scipy from source against OpenBLAS&lt;br/&gt;rm -f ~/.scipy-site.cfg&lt;br/&gt;ln -s dl-machine/scipy-site.cfg ~/.scipy-site.cfg&lt;br/&gt;pip install -U scipy&lt;br/&gt;&lt;br/&gt;# Install common tools from the scipy stack&lt;br/&gt;sudo apt-get install -y libfreetype6-dev libpng12-dev&lt;br/&gt;pip install -U matplotlib ipython[all] pandas scikit-image&lt;br/&gt;&lt;br/&gt;# Scikit-learn (generic machine learning utilities)&lt;br/&gt;pip install -e git+git://github.com/scikit-learn/scikit-learn.git#egg=scikit-learn&lt;br/&gt;&lt;br/&gt;####################################&lt;br/&gt;# OPENCV 3&lt;br/&gt;####################################&lt;br/&gt;# from http://rodrigoberriel.com/2014/10/installing-opencv-3-0-0-on-ubuntu-14-04/&lt;br/&gt;# for 2.9 see http://www.samontab.com/web/2014/06/installing-opencv-2-4-9-in-ubuntu-14-04-lts/ &lt;br/&gt;cd ~/&lt;br/&gt;sudo apt-get -y install libopencv-dev build-essential cmake git libgtk2.0-dev \&lt;br/&gt; &amp;nbsp; pkg-config python-dev python-numpy libdc1394-22 libdc1394-22-dev libjpeg-dev \&lt;br/&gt; &amp;nbsp; libpng12-dev libtiff4-dev libjasper-dev libavcodec-dev libavformat-dev \&lt;br/&gt; &amp;nbsp; libswscale-dev libxine-dev libgstreamer0.10-dev libgstreamer-plugins-base0.10-dev \&lt;br/&gt; &amp;nbsp; libv4l-dev libtbb-dev libqt4-dev libfaac-dev libmp3lame-dev libopencore-amrnb-dev \&lt;br/&gt; &amp;nbsp; libopencore-amrwb-dev libtheora-dev libvorbis-dev libxvidcore-dev x264 v4l-utils unzip&lt;br/&gt;&lt;br/&gt;wget https://github.com/Itseez/opencv/archive/3.0.0.tar.gz -O opencv-3.0.0.tar.gz&lt;br/&gt;tar -zxvf &amp;nbsp;opencv-3.0.0.tar.gz&lt;br/&gt;&lt;br/&gt;cd opencv-3.0.0&lt;br/&gt;mkdir build&lt;br/&gt;cd build&lt;br/&gt;&lt;br/&gt;cmake -D CMAKE_BUILD_TYPE=RELEASE -D CMAKE_INSTALL_PREFIX=/usr/local -D WITH_TBB=ON -D BUILD_NEW_PYTHON_SUPPORT=ON -D WITH_V4L=ON -D WITH_QT=ON -D WITH_OPENGL=ON ..&lt;br/&gt;make -j $(nproc)&lt;br/&gt;sudo make install&lt;br/&gt;&lt;br/&gt;sudo /bin/bash -c 'echo "/usr/local/lib" &amp;gt; /etc/ld.so.conf.d/opencv.conf'&lt;br/&gt;sudo ldconfig&lt;br/&gt;ln -s /usr/lib/python2.7/dist-packages/cv2.so /home/$orig_executor/venv/lib/python2.7/site-packages/cv2.so&lt;br/&gt;&lt;br/&gt;echo "opencv 3.0 installed"&lt;br/&gt;&lt;br/&gt;####################################&lt;br/&gt;# Theano&lt;br/&gt;####################################&lt;br/&gt;# installing theano&lt;br/&gt;# By default, Theano will detect if it can use cuDNN. If so, it will use it. &lt;br/&gt;# To get an error if Theano can not use cuDNN, use this Theano flag: optimizer_including=cudnn.&lt;br/&gt;&lt;br/&gt;pip install -e git+git://github.com/Theano/Theano.git#egg=Theano&lt;br/&gt;if [ ! -f ".theanorc" ]; then&lt;br/&gt; &amp;nbsp; &amp;nbsp;ln -s ~/dl-machine/theanorc ~/.theanorc&lt;br/&gt;fi&lt;br/&gt;&lt;br/&gt;echo "Installed Theano"&lt;br/&gt;&lt;br/&gt;# Tutorial files&lt;br/&gt;if [ ! -d "DL4H" ]; then&lt;br/&gt; &amp;nbsp; &amp;nbsp;git clone git@github.com:SnippyHolloW/DL4H.git&lt;br/&gt; &amp;nbsp; &amp;nbsp;(cd DL4H &amp;amp;&amp;amp; git remote add http https://github.com/SnippyHolloW/DL4H.git)&lt;br/&gt;else&lt;br/&gt; &amp;nbsp; &amp;nbsp;if &amp;nbsp;[ "$1" == "reset" ]; then&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;(cd DL4H &amp;amp;&amp;amp; git reset --hard &amp;amp;&amp;amp; git checkout master &amp;amp;&amp;amp; git pull --rebase $REMOTE master)&lt;br/&gt; &amp;nbsp; &amp;nbsp;fi&lt;br/&gt;fi&lt;br/&gt;&lt;br/&gt;####################################&lt;br/&gt;# Torch&lt;br/&gt;####################################&lt;br/&gt;&lt;br/&gt;if [ ! -d "torch" ]; then&lt;br/&gt; &amp;nbsp; &amp;nbsp;curl -sk https://raw.githubusercontent.com/torch/ezinstall/master/install-deps | bash&lt;br/&gt; &amp;nbsp; &amp;nbsp;git clone https://github.com/torch/distro.git ~/torch --recursive&lt;br/&gt; &amp;nbsp; &amp;nbsp;(cd ~/torch &amp;amp;&amp;amp; yes | ./install.sh)&lt;br/&gt;fi&lt;br/&gt;. ~/torch/install/bin/torch-activate&lt;br/&gt;&lt;br/&gt;if [ ! -d "iTorch" ]; then&lt;br/&gt; &amp;nbsp; &amp;nbsp;git clone git@github.com:facebook/iTorch.git&lt;br/&gt; &amp;nbsp; &amp;nbsp;(cd iTorch &amp;amp;&amp;amp; git remote add http https://github.com/facebook/iTorch.git)&lt;br/&gt;else&lt;br/&gt; &amp;nbsp; &amp;nbsp;if &amp;nbsp;[ "$1" == "reset" ]; then&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;(cd iTorch &amp;amp;&amp;amp; git reset --hard &amp;amp;&amp;amp; git checkout master &amp;amp;&amp;amp; git pull --rebase $REMOTE master)&lt;br/&gt; &amp;nbsp; &amp;nbsp;fi&lt;br/&gt;fi&lt;br/&gt;(cd iTorch &amp;amp;&amp;amp; luarocks make)&lt;br/&gt;&lt;br/&gt;cd ~/&lt;br/&gt;git clone https://github.com/torch/demos.git torch-demos&lt;br/&gt;&lt;br/&gt;#qt dependency&lt;br/&gt;sudo apt-get install -y qt4-dev-tools libqt4-dev libqt4-core libqt4-gui&lt;br/&gt;&lt;br/&gt;#main luarocks libs:&lt;br/&gt;luarocks install image &amp;nbsp; &amp;nbsp;# an image library for Torch7&lt;br/&gt;luarocks install nnx &amp;nbsp; &amp;nbsp; &amp;nbsp;# lots of extra neural-net modules&lt;br/&gt;luarocks install unup&lt;br/&gt;&lt;br/&gt;echo "Installed Torch (demos in $HOME/torch-demos)"&lt;br/&gt;&lt;br/&gt;# Register the circus daemon with Upstart&lt;br/&gt;if [ ! -f "/etc/init/circus.conf" ]; then&lt;br/&gt; &amp;nbsp; &amp;nbsp;sudo ln -s $HOME/dl-machine/circus.conf /etc/init/circus.conf&lt;br/&gt; &amp;nbsp; &amp;nbsp;sudo initctl reload-configuration&lt;br/&gt;fi&lt;br/&gt;sudo service circus restart&lt;br/&gt;&lt;br/&gt;cd ~/&lt;br/&gt;&lt;br/&gt;## Next part ...&lt;br/&gt;####################################&lt;br/&gt;# Caffe&lt;br/&gt;####################################&lt;br/&gt;&lt;br/&gt;sudo apt-get install -y libprotobuf-dev libleveldb-dev \&lt;br/&gt; &amp;nbsp;libsnappy-dev libopencv-dev libboost-all-dev libhdf5-serial-dev \&lt;br/&gt; &amp;nbsp;libgflags-dev libgoogle-glog-dev liblmdb-dev protobuf-compiler \&lt;br/&gt; &amp;nbsp;libatlas-base-dev libyaml-dev &lt;br/&gt; &amp;nbsp;&lt;br/&gt;git clone https://github.com/BVLC/caffe.git&lt;br/&gt;cd caffe&lt;br/&gt;for req in $(cat python/requirements.txt); do pip install $req -U; done&lt;br/&gt;&lt;br/&gt;make all&lt;br/&gt;make pycaffe&lt;br/&gt;&lt;br/&gt;cd python&lt;br/&gt;pip install networkx -U&lt;br/&gt;pip install pillow -U&lt;br/&gt;pip install -r requirements.txt&lt;br/&gt;&lt;br/&gt;ln -s ~/caffe/python/caffe ~/venv/lib/python2.7/site-packages/caffe&lt;br/&gt;echo -e "\nexport CAFFE_HOME=/home/$orig_executor/caffe" &amp;gt;&amp;gt; ~/.bashrc&lt;br/&gt;&lt;br/&gt;echo "Installed Caffe"&lt;br/&gt;&lt;br/&gt;####################################&lt;br/&gt;# Digits&lt;br/&gt;####################################&lt;br/&gt;&lt;br/&gt;# Nvidia Digits needs a specific version of caffe&lt;br/&gt;# so you can install the venv version by Nvidia uif you register&lt;br/&gt;# with cudnn, cuda, and caffe already packaged&lt;br/&gt;# instead we will install from scratch&lt;br/&gt;cd ~/&lt;br/&gt;&lt;br/&gt;git clone https://github.com/NVIDIA/DIGITS.git digits&lt;br/&gt;&lt;br/&gt;cd digits&lt;br/&gt;pip install -r requirements.txt&lt;br/&gt;&lt;br/&gt;sudo apt-get install graphviz&lt;br/&gt;&lt;br/&gt;echo "digits installed, run with ./digits-devserver or &amp;nbsp; &amp;nbsp; ./digits-server"&lt;br/&gt;&lt;br/&gt;####################################&lt;br/&gt;# Lasagne&lt;br/&gt;# https://github.com/Lasagne/Lasagne&lt;br/&gt;####################################&lt;br/&gt;git clone https://github.com/Lasagne/Lasagne.git&lt;br/&gt;cd Lasagne&lt;br/&gt;python setup.py install&lt;br/&gt;&lt;br/&gt;echo "Lasagne installed"&lt;br/&gt;&lt;br/&gt;####################################&lt;br/&gt;# Nolearn&lt;br/&gt;# asbtractions, mainly around Lasagne&lt;br/&gt;# https://github.com/dnouri/nolearn&lt;br/&gt;####################################&lt;br/&gt;git clone https://github.com/dnouri/nolearn&lt;br/&gt;cd nolearn&lt;br/&gt;pip install -r requirements.txt&lt;br/&gt;python setup.py install&lt;br/&gt;&lt;br/&gt;echo "nolearn wrapper installed"&lt;br/&gt;&lt;br/&gt;####################################&lt;br/&gt;# Keras&lt;br/&gt;# https://github.com/fchollet/keras&lt;br/&gt;# http://keras.io/&lt;br/&gt;####################################&lt;br/&gt;git clone https://github.com/fchollet/keras.git&lt;br/&gt;cd keras&lt;br/&gt;python setup.py install&lt;br/&gt;&lt;br/&gt;echo "Keras installed"&lt;br/&gt;&lt;br/&gt;echo "all done, please restart your machine..."&lt;br/&gt;&lt;br/&gt;# &amp;nbsp; possible issues &amp;amp; fixes:&lt;br/&gt;# - skimage: issue with "not finding jpeg decoder?" &lt;br/&gt;# "PIL: IOError: decoder zip not available"&lt;br/&gt;# (https://github.com/python-pillow/Pillow/issues/174)&lt;br/&gt;# sudo apt-get install libtiff5-dev libjpeg8-dev zlib1g-dev \&lt;br/&gt;# &amp;nbsp; &amp;nbsp; libfreetype6-dev liblcms2-dev libwebp-dev tcl8.6-dev tk8.6-dev python-tk&lt;br/&gt;# next try:&lt;br/&gt;# pip uninstall pillow&lt;br/&gt;# git clone https://github.com/python-pillow/Pillow.git&lt;br/&gt;# cd Pillow &lt;br/&gt;# python setup.py install&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;原文链接：http://graphific.github.io/posts/building-a-deep-learning-dream-machine/&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;br/&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;br/&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 22 Sep 2016 15:54:20 +0800</pubDate>
    </item>
    <item>
      <title>业界 | Nature：对抗偏见，大数据算法需要更多责任</title>
      <link>http://www.iwgc.cn/link/2792415</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Nature&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：杜夏德&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;从搜索结果到个性化广告，算法在不知不觉中渗透进生活的方方面面。它既带来的信息和方便也造成了很多隐性的不平等，甚至是偏见。然而算法造成的偏见该如何消除，它虽不像人类偏见那样固执，但消除起来也没那么容易，涉及到公开算法使用的数据，以及算法本身的设计，然而这些又牵涉到设计算法的公司的隐私。幸运的是学界和业界已经意识到这一问题，并开始「问责算法」。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;关于科学平等的呼吁一次次出现在媒体中，不是声称要追求最完美的平等就是呼吁找出不平等的根源。无害的废话？之所以说这些是废话，依据的并不是批评家在社交媒体和博客上抱怨的那些伪科学和其中牵扯的商业利益。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一些审查应该有一个更重要的目标。在很短的时间内，大数据算法的平等已经渗透到我们生活的每一个方面。一个巨大的产业已经成长起来，它们梳理并融合多个海量的数据集——文档，例如，上网习惯——来生成个人的档案。它们常常以广告为目的，但也传递了关于信用保险等的决策，它们帮助控制我们看到的新闻或广告，而且不论我们是否启用了它们。他们能决定是否让监控和法律执法机构像社会活动家和持不同政见者鞭策我们——或潜在的安全或刑事威胁。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不仅仅是缺少受欢迎的审查。而是在很大程度上缺少能够广泛使用的算法，比如管理民主生活方方面面的规则和保障的算法：充分监督、制衡、上诉、法定诉讼程序，以及过了法定时间后，将过去的罪行从记录中删除的权利。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;算法，从最简单的到最复杂的，都是遵从几组指令或者学习完成一个目标。原则上说，它们可以通过减少人类的偏见和成见来做出公正的分析和决策。但是另一个风险是，它们也有可能增加偏见或成见，并且会复制或者加剧人类犯错。在一个强大的计算机、机器学习和大数据时代，这些平等问题自然就出现了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;产生偏见，消除偏见&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在美国的部分地区，司法部门使用的服务一般由商业公司提供，这些服务通常使用算法来预测某人再次犯罪的可能性。但事实上这些算法用来进行量刑决策，比如某人是否得到缓刑或假释。然而结果是有争议的，批评家们强调了该算法有造成对黑人偏见的风险。国家监督和执法机构正在采用类似的技术。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;算法中存在很多偏见产生的根源。一个是规则的硬编码和数据集的使用，这已经反映在共同的社会自旋中，产生偏见，去除偏见。虚假或可疑的相关性是另一个陷阱。一个广泛引用的例子是使用算法会给那些需要较长通勤时间的人打负分，因为数据显示，长距离通勤与员工流失有关。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这有歧视贫困人口的风险，这些人往往是那些倾向于住的离中央商务区更远的少数群体。这反过来又加剧了这些地区的失业，并形成一个恶性循环。很多算法在使用犯罪或者其他数据时也容易陷入自我实现预言（self-fulfilling prophecies），造成对贫困人口和少数群体地区的偏见。还一个大问题是人们通常无从知晓他们的档案是基于什么来源建立起来的——或者它们根本就不存在。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;「对算法简单过度的依赖存在严重缺陷」&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;立法者应该纠正算法的权力和责任中的不对称。最起码，应该对个人数据属于个人这个原则进行更广泛的讨论。人们有权知晓自己的数据，以及他们的数据档案是怎么建立起来的，同时也有权质疑这些数据。一些研究者强调尽管网络和社交媒体已经表现出有益于民主，但推荐算法还是会破坏社会结构——例如，给于极端观点生存空间，以及赋予那些煽情肤浅的虚假新闻或产生误导的谣言以特权。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今年 7 月，卫报总编辑 Katharine Viner 曾说，需要加入一些个性化算法以实现让算法可以按个人所想计算。但是这会可能会导致增强预先存在的观点，同时催生出一个让谎言和非理性繁荣的共鸣空间。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;幸运的是，目前学术界正在推进更好的「算法责任（algorithmic accountability）」，，值得赞扬的是，像谷歌和微软这样的技术产业公司也参与进来。不断加快的速度和机器学习以及其他人工智能（AI）技术的采纳大大刺激了「算法责任」的推进。一个明智的做法是增加透明度，让算法设计者公开他们训练和使用的数据集源头。披露算法的设计本身就会向审查开放，但几乎可以肯定的是这将会与公司的保密措施产生碰撞。研究者希望找到一种在不透露算法的情况下纠正偏见的方式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;提出的补救措施中有一些是技术性的，比如开发出新的计算技术，能更好的处理和纠正训练数据集和算法中的偏见——一种对算法持肯定态度的措施。深入研究的目标是如何监控高度自主化的人工智能系统，对于这种系统，即便连设计者也不知道这个机器是如何做决定，或者达成结论的。这种深入研究有望开发出监控算法的算法。关于这项研究还需要很多讨论和工作。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;由于在研究评估中使用了科学指标，所以过分依赖算法能存在严重缺陷。很明显，（更为复杂的）算法会导致世界上的一部分人落后于其他人。确实如此，无处不在甚至更复杂的人工智能算法已经存在。社会需要认真讨论如何摆脱会犯人类错误的软件和机器。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;em style="color: rgb(136, 136, 136); text-align: justify;"&gt;&lt;span&gt;原文链接：http://www.nature.com/news/more-accountability-for-big-data-algorithms-1.20653&lt;/span&gt;&lt;/em&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em style="color: rgb(136, 136, 136); text-align: justify;"&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibWyk1o4CFoo380DegN6BOw7z4cMruG9ibPwWpE5avEExG18UOLQO0BNE7oQDvBAdnUllldEstaIHw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 22 Sep 2016 15:54:20 +0800</pubDate>
    </item>
  </channel>
</rss>
