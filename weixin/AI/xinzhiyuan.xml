<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>新智元</title>
    <link>http://www.iwgc.cn/list/2322</link>
    <description>智能+中国的资讯社交平台,致力于推动中国从互联网+迈向智能+新纪元.重点关注人工智能、机器人、大数据、虚拟现实、量子计算、智能医疗等前沿领域发展,关注人机融合、人工智能和机器人革命对人类社会与文明进化...</description>
    <item>
      <title>【一图看懂百度世界大会】李彦宏、黄仁勋、吴恩达三体合一</title>
      <link>http://www.iwgc.cn/link/2522575</link>
      <description>&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;1 &lt;/span&gt;新智元原创&lt;/span&gt;&lt;span&gt;1&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;记者&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;：闻菲、胡祥杰&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;【新智元导读】&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;李彦宏、黄仁勋、吴恩达放在一起，你会想到什么？ 在人工智能领域，这三个人分别代表了数据、硬件和算法，这正好是近年来人工智能得到迅速发展的核心推动力量。在今天举行的百度世界2016大会上，&lt;span&gt;围绕百度正式提出的人工智能核心——“百度大脑”&lt;/span&gt;发表主旨演讲，从&lt;span&gt;数据、硬件和算法三方面&lt;/span&gt;全方位介绍百度人工智能技术和产业布局。本年度的百度世界大会有两个关键词“开放”和“应用”: 百度首先是开源了深度学习平台Paddlepaddle，随后发布人工智能开放平台ai.baidu.com；在应用上，百度在想智能硬件和智能商务发展。开发和应用一直是行业比较关心的两个主题，至于百度能做得多好，还有待观察。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;李彦宏用一个小时的主题演讲，介绍了百度大脑在语言、图像、自然语言处理和用户画像这四方面的应用。从会长展位、论坛设计到讲者邀请，大会凸显了百度拥抱以深度学习为代表的人工智能技术的诚意和决心。新智元记者第一时间带你回顾本届大会看点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;inherit&gt;&lt;br/&gt;&lt;/inherit&gt;&lt;/p&gt;&lt;p&gt;&lt;inherit&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz/UicQ7HgWiaUb1GNdLuPNMK8Mz5ukxeTwWExDbnS6Hr1JicPgZ9AlGJiagK9n98c23sHos09uyGV9zPDRROhA5hHbLg/0?wx_fmt=gif"/&gt;&lt;/inherit&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;9月1日，2016百度世界大会在北京举行，百度创始人、董事长兼CEO李彦宏出席并向在坐近千名嘉宾展示了百度大脑的核心AI能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;李彦宏在会上表示，移动互联网利用人口红利带来的增长已经逐渐见顶，互联网正在进下一幕人工智能时代，人工智能将使全社会迎来变革性的发展。&lt;/span&gt;&lt;span&gt;而百度的人工智能可以归纳为四个字——“百度大脑”。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;李彦宏从语音、图像、自然语言理解和用户画像能力四个方面展示了百度大脑的进化程度，以及人工智能背景下人们的“智能生活”。如今，百度大脑能力已进入百度数十个业务和产品线当中。李彦宏表示，如何更好地利用这些能力，还需要各行业从自己的领域出发进行思考和想象。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;strong&gt;上午主论坛：数据+硬件+算法&lt;/strong&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;李彦宏：数据&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;李彦宏介绍，百度大脑由三大部分组成：人工智能的算法、计算能力和大数据。其中，计本和算方法包括超大规模的神经网络、万亿级的参数、千亿样本和千亿特征训练。在计算能力方面，百度几年前便开始自建中国最大的GPU集群，数十万台服务器构成了百度大脑的实体，保证了百度大脑超强的计算能力。在数据方面，百度已经收集了全网上万亿的互联网网页内容，还有每天数十亿次网民的搜索请求和每天数百亿次的网民定位请求，这些都构成了百度大数据的基础。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;李彦宏在会上介绍了百度大脑在语音、图像、自然语言处理和用户画像这四大领域在百度产品中的应用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前，百度大脑语音合成日请求量2.5亿，语音识别率达97%。用户请求这些语音合成都是用来做什么呢？李彦宏举了一个例子，手机听小说的需求量从原来每天不到一小时，增长为现在超过两小时。用户发现，让计算机念小说可能是不错的体验，甚至是享受。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;李彦宏现场演示了百度的语音能力。例子一是帮助电话促销员，利用语音识别功能，识别出电话另一端客户说了什么，然后根据客户的反馈，实时给出销售建议。第二个例子是合成张国荣的声音。李彦宏表示，有了合成声音的能力，你可以合成自己的声音给父母，陪伴老人，也可以在加班不能回家时，合成自己的声音给孩子念睡前故事。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在图像能力方面，百度大脑人脸识别准确率达到99.7%；百度无人车刷新了KITTI测试的多个世界记录，并在KITTI最激烈的车辆检测评比中排名第一。自然语言处理，李彦宏用度秘与体育评论员杨毅合作解说奥运会篮球比赛为例子。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;用户画像的外部例子播放了一则视频。传奇影业6月份上映电影《魔兽》，他们与百度合作，利用用户画像功能，使用用户标签体系，将用户分为一定会看、一定不看和可看可不看三类人群。对最后一类人群进行营销，成功提升票房20%。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;黄仁勋：百度是英伟达在中国最大的客户&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/UicQ7HgWiaUb39ziamfOZfA6o5epAiavAQa9qFZuIcfLCiaZwicPKsVUun6kZA6ah0aCLeB0HRsOyrUlMlLP5X64L3nA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;主论坛的邀请嘉宾是英伟达创始人兼 CEO 黄仁勋。演讲中，黄仁勋宣布继续在无人驾驶汽车领域深化合作，双方将汇聚百度云平台、地图技术和英伟达汽车人工智能计算平台，创建从云服务到汽车自动驾驶的平台。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;黄仁勋表示，百度是英伟达在中国最大的客户，也是最重要的客户。百度很早就开始与英伟达合作，研发适合人工智能的硬件平台。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;“人工智能、深度学习和自动驾驶的蓬勃发展，带来了GPU计算发展新的黄金时代。NVIDIA将利用创新的硬件和算法，帮助合作伙伴用全新的方式来处理数据，更高效的训练人工智能系统。”黄仁勋在演讲中提到，“未来，NVIDIA也将持续加强与包括百度在内的中国创新企业的合作，助力这些企业成为相关技术和产业的领跑者。”&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;大会上，李彦宏与黄仁勋表示，双方将达成合作，共同创建从云端到汽车的自动驾驶平台，该平台将向中国乃至全球的汽车制造商开放。依托双方在人工智能领域的丰富的经验与专业知识，此次合作结合了百度云平台、地图技术和英伟达汽车人工智能计算平台。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;黄仁勋表示：“百度与英伟达的合作将带来世界上首个端对端、由地图到汽车的开放平台。此次合作也将有助于我们在未来数年实现自动驾驶汽车的美好愿景。”&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;吴恩达：三个礼物&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/UicQ7HgWiaUb39ziamfOZfA6o5epAiavAQa9m0HjcyTL6JKkgSZS1osoux4nD6J39QtrTkyeSgamyutDZ4Ssmib7eDA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，百度首席科学家吴恩达上台。吴恩达用“三个礼物”命名他的演讲，首先，介绍了即将于两个月后在安卓手机平台登录的百度语音输入法，增加了很多新功能。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外两份礼物，吴恩达公布了百度人工智能的两大开放平台：百度深度学习平台（PaddlePaddle）与百度大脑开放平台（ai.baidu.com）。与其他第三方平台相比，百度深度学习平台更加易学易用，百度大脑开放平台则向合作伙伴开放技术与培训资料，促进行业发展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此外，吴恩达还介绍了百度内部使用深度学习平台的例子。“我给大家看四个例子，第一，我们有一个小团队用计算语言处理和机器学习能力做了一个巡警机器人，他可以自动打电话给客户，来自动挖掘线下风险，包括办证、色情、助考等等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;“第二个例子，我们也有一个小团队使用我们的机器学习技术做了智能写作助手，你写几句话，他就可以自动做词语替换，词语推荐，帮你修改文章。第三个例子，在我们贴吧产品，我们拿到一些图片，我们也需要做自动图片剪裁，本来拿到上面的结果，不过如果我们用我们的智能剪裁能力可以拿到图片下面的结果，提高用户体验。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;“第四个例子，我们有一个小团队做了新的产品，如果你拍一张照片，看一看你穿什么衣服，就可以自动识别出你穿什么衣服，也提供你一个时尚搭配。这些创新的产品，这些创新的项目，我们的工程师可以月做成功，原因就是他们可以拿到我们百度大脑的技术，非常快的非常容易拿到最有用的技术拿来融合做工作。”&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;吴恩达还介绍，百度开放云团队跟太原铁路局合作，做物流优化的工作。“我们已经训练了几个模型来预测精准的火车和货车的到达时间，预测未来仓储需求、未来运力需求，我们预测这些模型可以把中专时间降低50%，这会对物流有巨大的影响。”&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;strong&gt;无人车分论坛：跨越无人驾驶的鸿沟&lt;/strong&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下午的分论坛包括服务生态论坛、金融科技论坛、无人车论坛、内容生态论坛和国际化论坛。新智元重点报道无人车论坛。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/UicQ7HgWiaUb39ziamfOZfA6o5epAiavAQa9uibj8JCXFzdwQtnr5qhZISraSruBJeCXKDQW60EaOFnkFNse9F8Ogjg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;span&gt;无人车生态，百度称自己占据的是红色部分&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;百度高级副总裁、百度技术战略委员会主席、百度自动驾驶事业部总经理王劲第一个上台，王劲表示，百度大脑现在离真正的无人驾驶还有一段距离，不过，根据今天凌晨刚刚收到的消息，&lt;strong&gt;百度已经获得加州无人驾驶测试的牌照，是全球第15张&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;王劲说，今年买64线激光雷达的价格还是50万人民币。百度不久前投资的雷达公司表示，如果订单达到100万，500美元的激光雷达可以做到。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;百度无人车和携程的合作已经有一段时间，从4月开始，主要是在景区内接驳的应用。目前，国内有100个景区表示，如果百度无人车准备就绪，他们都愿意尝试。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/UicQ7HgWiaUb39ziamfOZfA6o5epAiavAQa9P4ErL32icHem1Y2R2bSEUdkiccPjLIDhia1gSvvsDRtTVEpgPxS0PIT7g/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;去年百度无人车后备箱的三台服务器，现在已经缩到一台了&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第二位嘉宾是奇瑞常务执行副总经理陈安宁，他在现场呼吁政府颁发无人驾驶测试执照。陈安宁说，老牌传统车厂认为自己可以做无人驾驶，但车企与互联网企业合作才是好的办法，因为车厂最擅长的就是集成，做跨行业的集成，奇瑞也自己在做一、二、三级的无人驾驶。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第三位演讲者是北京新能源汽车股份有限公司总经理郑刚。他介绍，北京新能源汽车股份有限公司已经在硅谷设置电池研发中心，开始使用最新一代的纯电动汽车，跟百度无人车合作，年底前会在一个世界级会议上试运行。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;百度首席架构师James Peng 带来“跨越无人驾驶的鸿沟”主题演讲。他认为，目前无人驾驶最大的难点就在于城区道路，而这也是百度无人车下一年的攻克目标。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/UicQ7HgWiaUb39ziamfOZfA6o5epAiavAQa9mmGUwhQLkewicVBcaeibV7ZcUnP7LNd2lE0kl6e6OFRzlWibn7paHmDSg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/UicQ7HgWiaUb39ziamfOZfA6o5epAiavAQa9ultianibovLb1aoEhP9ib6IYfj5WbiaRwSmX7KQaTib2Q58GuI1QM71nBbA/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/UicQ7HgWiaUb39ziamfOZfA6o5epAiavAQa91j4GlJ6mYjzLsWxYAhgm18QTmj8hPVF5RBxIuVQBfSwS4rfLxMjmnw/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/UicQ7HgWiaUb39ziamfOZfA6o5epAiavAQa9Zk9I8DM8k0xnb8f4E6PD1p8bonib6IYlx2AJIUiamUvcv1xxkntbwGZQ/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/UicQ7HgWiaUb39ziamfOZfA6o5epAiavAQa9d5fXqHMRh1QickWJdib1w08dqNxe55AyQ9h4tdfXz8lNaAM6QVHSwuicg/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/UicQ7HgWiaUb39ziamfOZfA6o5epAiavAQa93qtTpbKy1f3THXdw9cgeX6wNLd3iboCEwq5tlvR03zjTOST9ZJ82WSg/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;strong&gt;百度智能驾驶另一动作：成立L3事业部&lt;/strong&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在下午进行的“服务生态论坛”上，百度对外宣布成立L3事业部，并将推出L3自动驾驶解决方案，借助百度在人工智能、大数据、高精地图等方面的技术，推动汽车工业升级。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/UicQ7HgWiaUb39ziamfOZfA6o5epAiavAQa9O4ICn0bLLWSvawozmUicSkV1R9cqIjyAbk5phLjKVhPhIYel6tQw4Sg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;百度L3事业部总经理顾维灏在演讲中表示，百度L3事业部将把人工智能、大数据、高精地图等技术，与包含车企、Tier1厂商、芯片厂商以及服务提供商在内的合作伙伴共享。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/UicQ7HgWiaUb39ziamfOZfA6o5epAiavAQa9Yv7HfJJYayBwbVm66g92q2ujeJRbyYprCoEiah1vsG9geicb2oM09xow/0?wx_fmt=jpeg"/&gt; &lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;顾维灏表示，百度L3事业部将基于SD地图、ADAS地图、高精地图，向国内外的汽车企业提供L3自动驾驶系统解决方案，以及包括联网产品、标准化接口在内的L3级HMI人机交互平台。未来，百度L3事业部希望能够与国内外车厂在L3自动驾驶领域有更加深入的合作。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;顾维灏介绍道，“百度推动L3自动驾驶发展，最为核心的技术就是Learning Map以及高精地图。”对于L3自动驾驶来说，实时更新的精准的高精地图数据是必要的基础。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;据介绍，百度高精地图目前已经具备了规模化量产能力，其自动化生产程度达到90%以上，能自动识别包括交通标志、地面标志、车道线、信号灯路沿、桥梁、灯柱、护栏等多种目标，准确率超过90%。而依托由多源感知数据处理、云服务中心和数据中心等构成的Learning map平台，百度高精地图的数据可以实现分钟级更新。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/UicQ7HgWiaUb39ziamfOZfA6o5epAiavAQa9aztfGLJYqekOiaKs51IDS9maDAant9fatbbssHaKv9dvYLVd40hT8EA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;顾维灏透露，百度L3事业部与NVIDIA合作，为生态伙伴提供芯片级的解决方案。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;strong&gt;一图看懂百度大脑&lt;/strong&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/UicQ7HgWiaUb39ziamfOZfA6o5epAiavAQa9C5P9M723V6ZWa3qgibJs8l3JRl1RnPUjftyxsyY385WLrlsNuxQaqjg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/UicQ7HgWiaUb39ziamfOZfA6o5epAiavAQa9qgpZibYYD05T1nxsb8fOoRibSR0TjYia70wZN1WPCgfnPmhRYvUw6XcCg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/UicQ7HgWiaUb39ziamfOZfA6o5epAiavAQa9NwlnnVfGIyhXNabQhSQdC8HQiask14s34JRRhz7kEukw90lK8uH1R4w/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;strong&gt;附：李彦宏2016百度世界大会发言&lt;/strong&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Robin：各位来宾大家早上好！欢迎来到2016百度世界。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;大家知道，百度世界是我们每年举办一次的百度技术创新大会。今年的主题我们聚焦在人工智能，大家在之前收到的请柬上已经看到这个主题了。刚才开场视频是以人工智能为主题的，今天我的主题演讲也将围绕着人工智能来展开。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今年6月份，我在百度联盟峰会上讲了一个概念，叫做互联网的下一幕。下一幕是什么意思呢？就是说，互联网的发展在此之前已经经过了两个非常重要的阶段，第一个阶段大概持续了十几年的时间，就是我们讲的PC互联网阶段。第二个阶段是在最近四五年，我们把它叫做移动互联网的阶段。对于中国市场来说，随着上网人数越来越多，上网人口的渗透率越来越高，现在已经达到了七亿多，就是说已经超过了50%的渗透率，同时，每一个上网的人现在也基本都用上了智能手机。这意味着什么呢？这意味着，未来互联网的增长不能再靠人口红利来驱动了，也就是说，移动互联网的时代其实正在离开我们。这可能是很多人觉得难以接受的。我们国家现在进入了所谓的新常态，经济的增长需要靠“互联网+”行动计划来推动，所谓“互联网+”就是希望用互联网的思维方式、互联网的效率来推动各个行业、产业的继续发展。但是，我们互联网的从业者其实又深深地感受到了这其中的危机，这个危机就是因为过去的粗放增长阶段已经结束了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;移动互联网之后的下一幕是什么？其实现在已经很清楚了，就是我们所说的人工智能。人工智能对于百度来说是核心当中的核心，我们也很幸运，在过去的五六年当中，百度花了很大很大的精力投入到人工智能的研发当中。人工智能对于百度来说意味着什么呢？我可以用简单的四个字来描述，就是百度大脑。百度大脑的概念我们其实在大约三年前就对外讲过。那个时候我们讲，百度大脑已经具备了大概两三岁孩子的智力水平了。自此以后，不断的有人来问我，尤其是今年人工智能突然火起来了之后，很多人来问我说，你们这个百度大脑现在相当于多少岁人的智力水平了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;要回答这个问题其实还蛮难的，我也不知道它现在是多少岁了，因为毕竟人脑和电脑它还是有很大的区别，百度大脑虽然是一个人工智能的大脑，但是它和人正常的发育的过程还是很不一样的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;百度大脑到底由什么构成的呢？它基本上是由三个大的部分组成的。第一个组成部分，就是人工智能的算法。我们有超大规模的神经网络，这是模拟人的神经元组成的网络，但其实我们也不知道真正人脑工作的原理是什么，只是想象当中应该是这个样子。我们还使用了万亿级的参数，人脑的神经源大概是千亿级的，我们也有千亿的样本和千亿的特征进行训练。整个这些东西组成了百度大脑当中算法的部分。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;百度大脑的第二个组成部分是我们计算能力。现在我们已经使用了数十万台的服务器来进行计算，而这当中很多的服务器不是传统基于CPU的服务器，而是基于GPU。早年的时候，GPU主要在游戏等领域使用得比较广泛，在人工智能、尤其是深度学习起来以后，我们发现，其实GPU特别适合人工智能的计算，尤其是深度学习的计算，一块GPU可以顶100个CPU的计算能力。有关GPU的事情，我之后会请一位外部的嘉宾，就是NVIDIA的创始人和CEO黄仁勋先生，让他给大家介绍更多有关GPU的，尤其是在人工智能领域应用的情况。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;百度大脑的第三部分是数据。数据也非常非常重要，而且这个数据量也是非常大的。比如说，我们已经收集了全网上万亿的互联网网页内容，这其中包括了很多视频、音频、图像，这些数据也是数以百亿级的。我们还有每天数十亿次网民的搜索请求，而且还有每天数百亿次的网民定位请求，就是说这个人在什么地方，这样的请求也比大家想象得多，每天都有好几百亿次这样的定位请求。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有了算法，有了计算能力，有了数据，百度大脑就可以开始工作了。百度大脑又到底有什么样的功能？让我们来看一看。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们今天想重点介绍的四个功能：一个是语音的能力，一个是图像的能力，一个是自然语言理解的能力，还有一个就是用户画像的能力。这几个能力虽然都是属于人工智能中比较典型的应用，但是它的发展阶段也是很不一样的。比如说语音，现在就已经进入了相对比较成熟的阶段，在很多很多领域中都开始进入实用阶段，识别的准确率也已经很高了。图像最近几年也有了长足的进展。这两者都属于人工智能当中认知的部分，所以深度学习的算法非常适合处理这些形式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相对来说，自然语言的理解、或处理能力就更加难一些，并处在一个更加早期的阶段，因为它除了认知方面的能力之外，还要求有推理、规划等等能力，才能够真正地理解自然语言。用户画像的能力，其实从传统意义上来讲并不是人工智能的领域，但是由于近年来大数据的发展，尤其是大型互联网公司有能力搜集很多用户的数据之后，再用人工智能的方法、用机器学习的方法，就可以把一个人的特征描绘得非常非常清楚。所以今天，用户画像也变成了人工智能、或者说变成了百度大脑的一个重要功能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面我就分别来讲一下这几个功能，这几个百度大脑的功能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们先看一下语音，刚才也讲了应该说今天人工智能发展的最成熟的一部分能力，而语音又分成两个方向，一个是语音的合成，一个是语音的识别。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们先看看语音识别。今年MIT Technology Review杂志，把百度的Deep Speech 2评为“2016改变世界十大突破技术”，这就是百度的语音识别引擎，它已经到了第二代，主要就是使用了深度学习的能力。这样的一个技术已经可以把语音识别的准确度做到多少呢？大概可以做到97%的准确率，这样的准确率已经达到、甚至有时已经超过了人对语音的识别能力。当然，我们讲这些能力不是为了简单地去炫耀这个数字有多好，我更感兴趣的是，当你有了这些能力时，它可以在什么领域应用，又可以在哪些方面帮助到我们，这其实才是最最让我们觉得兴奋的地方。我个人的想象力很有限，整个百度几万人的想象力也是有限的，但是这些能力如果赋予到很多很多人，赋予给几亿人、几十亿人，这个可能性几乎是无限的。先用我们比较有限的想象力来给大家举一个例子。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是一个销售、电话销售的例子，是一个 2B(To B)的应用。这个应用是什么意思呢？很多的公司其实都有电话销售这样的一个部门，都需要这样做。但是销售，尤其是电话销售这个行业，大家知道流动性是比较大的，很多销售都是新人，新人的话就会经过一定的时间培训才能够上岗，但即使是经过培训的话，也不一定有那些有经验的销售那么出活儿、出单。其实有经验、最优秀的销售和一般、较差的销售相比，在效率上有非常大的差别。我们怎么才能够让新手、让没有经验的销售，能够具备最优秀销售的销售能力？过去的做法是，把优秀的销售经验总结成册子让大家去学习，让这些销售去背，但是怎么活学活用还是需要一个过程的。而有了这么高精度的语音识别能力之后，我们就可以彻底改变这样一个状况了，甚至可以让一个刚刚上岗一个月的销售就具备最优秀销售的能力，也就是说，我们可以通过实时的语音识别甄别出用户或客户在问什么问题，然后我们再实时地在屏幕上告诉新的销售，最优秀的销售是怎么回答这个问题的。过去没有实时的语音识别的时候，你需要线下学，学完了之后上去用、很容易就忘了，但是有了这个系统之后，我们就可以解决这样的问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们来看一下这个案例。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;【播放语音识别技术演示视频】&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;大家看到，在刚才的过程中，百度大脑一直在实时地识别双方的对话，尤其是从电话里面传出来的声音，有的时候并不是那么清晰，对于人来说要完全听清楚每一个字其实都是有一定难度的，但百度大脑的语音识别能力已经可以做到非常精准，并且可以根据用户的问题、实时推荐下一步的工作要怎样应对，这是一个语音识别应用在企业日常运作中的一个例子，就像我刚才讲的，应该还有很多很多应用场景，大家可以根据自己的背景去想象。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;语音识别是一方面，语音合成又是另外一个方面。语音合成是什么意思呢？就是机器可以把文字转换成语音，把它念出来、读出来。今天的语音合成也有了和过去非常不一样的体验，最主要的就是，它可以用比较自然的人的声音读出来，而不是像过去机器一样，每一个字之间的停顿都是一样长，是匀速的、没有表情的。这样的自然体验，当然对于用户的黏性来说也是有很大的作用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在，百度每天要响应2.5亿次的语音合成请求，这些请求用来干什么呢？比如说，过去人们看小说，今天可以在手机百度里面听小说。慢慢的人们听小说的时间也更长了，过去每个人平均在小说频道会花大概四十分钟左右的时间，现在要花将近两个半小时，就是因为把计算机合成出来的语音读出来给我们听，确实是一个很不错的体验，甚至是一种享受。那么这种读出来的小说，和我们平时听到的广播有什么本质上的不一样？其实非常不一样。广播是每一个人听到的东西是一模一样的，而今天的语音合成，它可以做到每一个人听到的东西都是不一样的，完全根据你个人的需求进行定制，这就是为什么它的（用户）黏性会很高，它能够具备自然发声的能力。不仅如此，其实我们可以想象一下，它如果能够模拟一个自然人的表达方式或发声能力，它就可以模拟任何一个你喜欢的人的说话方式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不知道有没有人注意到，百度地图里导航功能就是用语音来进行的，其中有一个选项可以用我的声音进行导航。其实导航的那些话我并没有说过，机器只是根据我平时说话的情况合成了一个李彦宏的声音。这样的声音不仅在我身上可以做到，在很多其他人身上也可以做到。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们现在来给大家展示一个合成的声音。我们合成了一下13年前已经去世的张国荣的声音，我们来放一段video。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;【播放情感语音合成视频】&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为什么给大家展示这个呢？一方面我知道，很多人是张国荣的粉丝，另一方面，其实合成张国荣的声音比合成一般人的声音要更难。为什么呢？因为他的国语语料相对来说比较少，所以，我们能够合成他的声音，就一定能合成很多很多人的声音。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于百度来说，百度大脑的语音合成能力可以让每个人都有自己的声音模型，你只要按照我们的要求说50句话，我就学会了你说话的方式。当你拥有自己的合成声音之后，比如说家里的老人想经常听你说一说，你把这个声音合成出来让他听就好了。或者说你平时要加班，小孩睡觉之前想听个故事，你合成自己的声音给孩子讲一遍这个故事，听起来也会很亲切。所以大家可以看到，这些语音的能力会带来各种各样新的可能性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面我给大家讲一下图像。用一个比较专业的术语来讲，我们叫做计算机视觉。这也是现在广义的人工智能中非常重要的领域。说到图像的识别，我想大家自然而然会反应出来一个什么应用呢？应该就是我们通常讲的人脸识别的应用。人脸识别的准确率今天已经达到了99.7%，已经非常非常准确了。现场的屏幕能够识别出来我们一些嘉宾，根据他们的人脸，我们知道这个人是谁，这个准确率已经比较高了。刚才进来的时候，大家也可以看到一些人脸识别的展台，我们是可以识别很多很多人的面孔的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;那么，人脸识别这个技术是怎么实现的？我们要对人脸的特征提取它的关键点，把这些点打出来之后要做一些处理，把它连成一个面部表情，据此来识别这样一个人。这就使得当一个人的表情发生变化的时候，我们仍然能够识别出来这个特点是没有发生变化的，比如他在哭，他在笑，他在愤怒，他在迷茫，他的表情是不一样的，但是他的表情特征是不变的，所以我们仍然可以很准确地识别出这样一个人。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除了面部识别之外，图像识别还在很多领域也有应用。我们再看一个，这是上海的一个全景图，大家使用百度地图有时候需要看这样一个景，到一个陌生的地方之前，想看看到那看到的样子是什么。当然，这个图不是一个简单的图像的采集，我们采集了图像之后要对图像中各种各样的目标进行识别，这个大楼是什么样的大楼，那个路牌上面写的什么字，对写的这个字识别的话，跟人脸识别还不太一样，这里面有一个特殊的图像识别的技术就是OCR，这个是二十多年前我们的一个专利，到今天它的准确率已经非常高了，下面我们也是用一段视频给大家看一下百度地图是如何利用图像识别的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;【播放百度地图视频】&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是百度地图利用图像识别的情况，其实还有一个很重要的领域也是非常需要图像识别的技术，这个领域是什么呢？这就是我们过去一年来讲得比较多的无人驾驶汽车。无人驾驶汽车涉及到很多很多的技术，比如说我们需要计算机视觉的技术，需要高精度地图，需要对环境的感知，需要定位，甚至需要语音的通话。但应该说，计算机视觉或者是图像识别的技术是“最后一公里”，无人驾驶汽车真的要变成没有人，真的要能够解决99.999%、甚至100%的情况，最终还是要依靠计算机视觉的能力，要识别各种各样的极端的情况。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;去年年底开始，我们给大家展示过百度的无人车在五环上跑，在高速上跑的情况，过去一年左右的时间我们也花了不少精力去提升我们在城市道路上运营的水平，下面我们也放一段视频给大家看一下。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;【播放无人车视频】&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;大家看到左下角这是人能够看到的视野，这个视野其实是比较窄的，主屏幕是无人车能够看到的路面情况，大家可以感受到，它感知的范围其实比人要宽了很多，很多比较远的目标都可以感知到，每个目标都给出它唯一的编号进行识别。对面有什么车过来了，遇到红绿灯，遇到障碍怎么办，行人怎么能识别出来，或者是树木，周边的汽车等等，每一个目标我们都进行了识别和编号，这就是实际的、一个百度无人驾驶汽车在城市道路中行驶的情况，上面的45是限速。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是大致的一个车看到的世界是什么样的。这里面涉及了很多计算机视觉或者是图像识别的技术，尤其是这两个技术：一个是我们叫做车辆的检测，你行驶过程中怎么能够知道旁边有车辆，这个车辆在哪？这个车辆的检测我们现在按照国际权威的评测来看，车辆检测的能力，百度无人车已经排名第一了。还有一个很重要的能力是车辆跟踪的能力。这个不仅是全自动的无人车，即使是对半自动的、高度自动驾驶来说，也是一个很基本的能力。你怎样能够准确地跟着前面的车走，这个技术在包括准确性、全面性、连续性等六项指标中，我们已经有四项拿到了第一。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是无人车对于图像识别依赖的情况。我们再给大家展示一个领域，就是增强现实AR，AR其实也是非常依赖（图像识别）。拿着手机拍一下现实的情况，我们要能够识别出来这是哪，这里面有什么，然后才能跟用户进行互动，才能产生真实世界和一些虚拟世界的完美的结合。那么这个东西有什么应用呢？我们也觉得很高兴我们的周总、我们的广告主非常敏锐地把握到了这么一个机会，他说OK，我可以把现实世界中我的产品和虚拟世界中我希望用户感知的东西结合在一起，这样的一个做法也可以说是一种新型的广告形式，下面我们就来看一个具体的例子。这是我们跟欧莱雅中国合作的一个例子。我们放视频。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;【播放欧莱雅视频】&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以大家看到无论你拿手机拍一张明信片，还是拍一个实物的洗发水，它都可以准确地识别出来这个东西，和用户进行互动，这里面不仅有图像识别的技术，也很大程度上取决于广告主的创意，如果创意和这个技术结合，对消费者的吸引力也非常大，所以我们也期待将来的时间和客户很好地合作，把这个创意，把最优秀的想法和最优秀的技术结合起来，给消费者带来实惠。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是有关图像识别方面的几个例子。下面我们再看自然语言处理。自然语言处理其实我刚才也讲了，它的成熟程度应该不如语音，甚至不如图像识别，但是即使在目前的状态下，它也能够给大家带来很多很多不一样的体验。最直接的例子应该是我们去年在百度世界大会上讲的一个例子，就是度秘。度秘是一个个人智能的助理。这个个人智能助理今天我们可以在手机百度里面找到，度秘跟用户进行交互，现在已经有超过一半的交互是通过语音和图像来完成的，去年我们也讲了，语音和图像将来会变成一个主流。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;度秘除了它能够识别语音和图像之外，其实它更关键、更核心的技术，是能够用人的语言来与人进行交流，并且能够理解人的很多意思和意图，尽管不是每一次都能理解。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;过去这段时间我们也利用度秘的自然语言的能力做了一个比较有意思的应用，用度秘来解说奥运篮球，下面我们看一下视频。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;【播放度秘与杨毅合作解说视频】&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个不是度秘单独完成的一次解说，是他和著名篮球评论员杨毅先生一起合作做的一次奥运篮球比赛的解说。今天我们也很高兴把杨毅先生请到了现场，现在请他上台。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;【嘉宾杨毅登台】&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;杨毅：大家上午好，我是杨毅。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Robin：刚才我们看到很有意思。你跟度秘一起解说了一场篮球的比赛，而且我也注意到你的风格和度秘的风格还是很不一样的，我想问你一下，作为一个篮球评论员，你觉得一个好的解说员应该具备什么样的能力？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;杨毅：首先我觉得很难说我有资格来讲一个好的评论员要具备什么样的能力，我相信很多行业都在不断地前进和发展。而且对一个解说员，即使他解说了一万场比赛，但他下面面临的一场比赛也是新的。但我想，总的来说，一个解说要想很好地工作，首先你要对这个项目有非常深刻的了解，无论对它的项目特点还是历史背景，第二个要有非常快速的现场反应能力，第三个我觉得要有出众的语言表达能力，把你看到的、听到的，能够尽快地呈现给观众或者是听众。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Robin：对，这些能力度秘都在不断地学习过程中，还有很多不完美的地方，我也希望度秘能够从你的身上学到很多很多东西。刚才我们看到你和度秘合作的这样一次解说，它跟你学习了一次之后，我们想让它单独做一次篮球比赛的解说，现在我们看一下度秘解说篮球奥运决赛的情况。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;【播放度秘解说奥运篮球决赛视频】&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Robin：ok，这是度秘单独的解说，也想请杨毅先生评论一下你的学生表现怎么样？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;杨毅：显然度秘比之前和它一起说的时候完成得更好了。其实我跟它说的时候，它的表现就是出乎我的预料的，我也听说它学习过上百场甚至上千场的比赛，它对比赛的基本知识储备是没问题的，在这个行业里面，它可能比我知道得还多，因为几年前的比赛我可能已经忘了，但是仍然装在它的电脑里。上知天文，下知地理，什么都明白，它的表达也是比较清楚的，在我跟它说的时候，我觉得只有一个小小的问题，我觉得它说话的速度确实是好慢。但是大家刚才看到，它说决赛的时候能明显感到语速加快了，更符合体育竞技的特点，更快速地将现场的情绪传达给观众。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Robin：对，我其实非常同意。刚才听的时候我也有点着急，它说的语速是比较慢的。但是像你刚才讲的，度秘也有它的优势，比如它的记忆能力是比人强的，它学习了几百场的奥运篮球比赛，每个运动员的个人资料它都记得非常清楚，遇到这些知识型的问题，它可以非常迅速地、方便地回答。另外我们看解说本身，用户是可以跟度秘进行互动的，你点一下“双方三分球的对比”，马上就出来各种各样的数据了，这是度秘的优势。但是度秘的劣势就是它对人的语言的理解和人的语言的创造能力还有很多需要学习的地方，我们也非常希望杨毅先生能够多给我们度秘提一些建议和提升的地方，也希望我们下次再有机会合作时，它说话至少快一点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;杨毅：我觉得它下面的这些功能是非常好的。你可以想象一下，如果它成为一个成熟的产品，在每个球迷收看比赛的时候在家里身边沙发上都能摆一个小机器人，一边看着电视里的比赛，听着电视里的解说，当然它可能在电视里解说；同时他身边也有个度秘，可以不断地就他所关心的问题问身边这个小机器人，能够随时给他进行解答，就真正成为了球迷在收看比赛时候的好朋友。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Robin：我相信这一天一定会到来的！而且对于度秘来说，篮球和其他的比赛没有任何区别，都是学习知识，它主要的能力还是不断地学习人的思维方式和表达方式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;杨毅：我相信它肯定会越来越好。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Robin：谢谢杨毅。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;【嘉宾杨毅下场】&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Robin：这是有关自然语言理解的一些介绍，下面再给大家展示一个自然语言理解的应用。这个应用的领域其实也不是特别新，就是自动翻译。你要想把一种语言转换成另外一种语言，你必须得理解这种语言在说什么。它不是简单的把语音转成文字，更多的是需要你知道它是什么意思。今天的百度翻译已经可以支持27种语言、数百种不同方向的对译了。现在我们来看一下百度翻译有多大程度上能够理解人的自然语言。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;【播放百度翻译演示视频】&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Robin：这其实不是一个演示，这是一个实际的例子。今天当大家打开百度翻译，它已经具备了这样的能力。所以我们看到对于自然语言的理解一旦能够达到一定程度，它就又打开了很多新的可能性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面我们讲百度大脑的第四个能力，就是用户画像的能力。用户画像也是基于百度的大数据以及机器学习的方式所获得的一个能力。现在我们已经有接近10亿的用户画像，其中对于他们的识别我们已经用到了千万级的细分标签。这些标签主要在两个维度上体现，一个是通用的维度，它的人口学特征、短期的意图、位置属性；也有一些垂直行业的特征，他在金融领域是什么样的情况，它在保险、医疗、旅游、健康等领域都有什么样的爱好、习惯，这些东西都共同构成了我们的用户画像。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;用户画像有什么用途？首先给大家举一个百度的例子。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最近几个月大家可能注意到了手机百度，除了上面的搜索框之外，下面增加了各种各样的文章。这些文章有时候是新闻，有时候不见得是新闻，但是确实是你感兴趣的东西。之所以它能够把你感兴趣的东西推荐出来，就是因为我们利用了百度的用户画像。我知道你是一个什么人，你喜欢看什么样的东西。有了这样的个性化推荐，过去两个月手机百度推荐的文章的阅读量增长了10倍，这种能力就是靠百度给用户打了60多万个标签，而每个用户都是这其中某些标签组合后描画出来的，所以它可以做到千人千面，准确地讲，不是千人千面，而是万人万面，亿人亿面，每个人对于百度来说都是不一样的个体。所以，每个人看到的信息和文章都是不一样的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是一个百度内部使用的例子，我们也认为用户画像可以在很多其他领域使用。我们再给大家展示一个外部的例子。这是6月份上映的电影《魔兽》，它的出品人是传奇影业，他们就是利用了百度大脑的用户画像功能来提升它的票房。那么它是怎么做到的呢？我们也来看一个视频。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;【播放传奇影业视频】&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个做法很聪明，它把人群分成三类，一类人是不管怎么样都要看的，另外一类是不管怎么样都不会看的，这两种人他们都不太关心。它关心的是它可以影响的人群，再通过用户画像把这些人从摇摆的转换成真正去电影院看的。（原来）他认为如果有5%的票房提升就很满意了，最后实际上提升超过了200%。当然这不是简单的说百度你给我用户画像，它一用就实现了提升，他们也下了很大的功夫去设计整体的推广过程。原版的video是比这个长很多的，大家有兴趣可以联系我们的工作人员，看它完整的做法是什么样的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;讲到这里，我基本上把百度大脑几个主要的大功能都已经呈现出来了。下面我想请一位大家都很熟悉的明星，和我一起回顾一下百度大脑的这几个功能。这个明星就在我们这张照片中。我们首先用百度大脑的图像识别功能把这位明星找出来。大家知道他是谁吗？对，他就是著名演员胡歌。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;【嘉宾胡歌登台】&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;胡歌：你好，Robin，各位尊敬的来宾大家好。我是胡歌。今天非常荣幸可以参加百度世界大会。刚才我在侧台也听了非常精彩的演讲，感受到了很多新的科技。之前我有听说过人脸支付，以后如果可以像刚才那样在一大群人中先进行人脸识别，再完成支付，这个真是太便捷、太智能了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Robin：你是想抢着买单吗？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;胡歌：如果以后有机会我和Robin要一块吃饭，到买单的时候，我肯定把脸转过去，不跟你抢买单。（笑）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Robin：没问题，我买单。刚才我们已经看到了百度大脑对你的面部的识别。我还可以给你展示一些其他的能力，比如语音合成的能力。这个能力是这样的，当你念一首词，你念它的上半部分，百度大脑念它的下半部分，但是它念出来应该跟你是一样的，它学的是你的声音。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;胡歌：这么厉害。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Robin：这首词，是百度名字的来历。你可以来念一下上阙。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;胡歌：东风夜放花千树，更吹落、星如雨。宝马雕车香满路。凤箫声动，玉壶光转，一夜鱼龙舞。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;【情感语音合成技术现场演示】&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;胡歌：太神奇了，首先让我震撼的是，它能把我的声音模仿得这么像。第二，它连百度钱包的代言词都给我改了，真的挺智能的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Robin：这是语音识别的能力，其实用户画像的能力对你其实也有用，为什么有用呢？你的粉丝都是什么样的人。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;【大屏幕展示粉丝用户画像结果】&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Robin：这是根据你的粉丝的兴趣偏好“画”出来的东西。我还是有一点惊讶的，本来以为关心影视、音乐应该是最大的群体，但是我们看到旅游出行、网络购物是你这些粉丝群体特别特别喜欢的东西。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;胡歌：我看到旅游出行和餐饮美食可能是他们最感兴趣的，那么能不能在这儿根据这个兴趣数据也为我的粉丝谋取一些专属的福利呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Robin：好啊。那我们下来通过糯米或是其他的平台给胡歌粉丝提供专享的优惠。百度大脑的这些能力都是今天已经实现的。刚才我也讲到这个大脑一天一天都在学习和成长，它的能力也在不断的进步。所以我完全可以想象有一天当你决定要接一部戏的时候，你只要在这个合同上签一下字，剩下的事情就都交给百度大脑来干，它可以合成你的声音、可以合成你的图像、可以做你的动作，以后演戏你只要说Yes，剩下的事我们就都给你办了（笑）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;胡歌：科技在不断发展，但是演戏对我来说还是我毕生艺术上的追求，我觉得百度大脑可以为我的生活带来很多便利，但演戏这个事我还是自己来干吧！（笑）我相信它可以做好，但是我更愿意自己来做！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Robin：好的好的，以后百度大脑具有新的能力的时候，我及时通知你。这有可能是好消息，也有可能是坏消息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;胡歌：谢谢！感谢今天让我感受到了这么先进的科技，我也希望百度大脑能够越来越强大，越来越智能。谢谢Robin！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;【嘉宾胡歌下场】&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Robin：谢谢胡歌！今天我们全面展示了百度大脑各种各样的能力，我觉得，而在我自己和百度同学的想象范围内，这些能力能做的事情已经很多了，但是更让我兴奋的是如果这些能力赋予到全社会的每个人，它能够变换出来无穷无尽的可能性。所以，百度大脑会把语音、图像、自然语言理解和用户画像等能力完全开放出来，并且在大多数情况下这些能力会是免费提供的。有了这样的能力，有了开放共享，将给各行各业的人群带来过去大家做不到的、不敢想的能力。我在这里也邀请每个人重新想象你所在的行业，重新想象中国经济，重新想象世界的未来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谢谢大家！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;【号外】&lt;/strong&gt;&lt;span&gt;&lt;span&gt;由中国自动化学会和新智元联合主办&lt;/span&gt;的AI全球年度盛典『AI WORLD 2016世界人工智能大会』即将盛大开幕。&lt;strong&gt;&lt;span&gt;大会官网：&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;http://aiworld2016.com/&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/UicQ7HgWiaUb39ziamfOZfA6o5epAiavAQa9QLMXpuxRPEU0B0okUyyW2kLfxmxRQNzibxQl9gyOSe7sORFYKMRX3JQ/0?wx_fmt=jpeg"/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/UicQ7HgWiaUb39ziamfOZfA6o5epAiavAQa9ggA8S7l8ZxV46J4YiaeOsuSULficdm22lb8J9ASn8icpZUb6SNsr3w4EA/0?wx_fmt=jpeg"/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/UicQ7HgWiaUb39ziamfOZfA6o5epAiavAQa9M4EJG3lOiaHrWNcu0wsbPqFPrA7YmV8PJI9bdkHado90fOq9pyyxXJA/0?wx_fmt=jpeg"/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/UicQ7HgWiaUb39ziamfOZfA6o5epAiavAQa9HETPF65LFUCX5zyzzy1HACrSMFPZRR5R6KAJiabaUanSNx10ricLxf3Q/0?wx_fmt=jpeg"/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;更多详情，点击“阅读原文”，查看大会官网&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 01 Sep 2016 21:49:41 +0800</pubDate>
    </item>
    <item>
      <title>【新智元专访】吴恩达：百度要做智能时代的“超级电力公司”</title>
      <link>http://www.iwgc.cn/link/2522576</link>
      <description>&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;1 &lt;/span&gt;新智元原创&lt;/span&gt;&lt;span&gt;1&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;【新智元导读】&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;今天2016百度世界大会，吴恩达接受新智元等几家核心媒体专访。这也是吴恩达最近半年面对媒体最长时间的露出。在回答新智元记者提问时，吴恩达表示&lt;span&gt;：百度开源深度学习平台核心是帮助开发者学会使用深度学习模型；在业务方面，无论2B2C，只要抓住关键都可以做。此外，吴恩达还表示，现在人工智能机会非常多，但百度要做的就是开放技术，为第三方提供支持。可以看出，百度在积极推进将人工智能作为新的电能，稳固自己“超级电力公司”的地位。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;inherit&gt;&lt;br/&gt;&lt;/inherit&gt;&lt;/p&gt;&lt;p&gt;&lt;inherit&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz/UicQ7HgWiaUb1GNdLuPNMK8Mz5ukxeTwWExDbnS6Hr1JicPgZ9AlGJiagK9n98c23sHos09uyGV9zPDRROhA5hHbLg/0?wx_fmt=gif"/&gt;&lt;/inherit&gt;&lt;/p&gt;&lt;p&gt;&lt;inherit&gt;&lt;br/&gt;&lt;/inherit&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;【新智元】最近 Hinton 说机器在10年之内可以拥有常识，您同意他这个说法吗？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;吴恩达：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;他有这样说？我去问问他。可我觉得很难讲。你们都听到Robin讲移动互联网时代，其实移动互联网，好像是2007年，乔布斯就在苹果中介绍的第一个iPhone中提到了。10年之前谁可以想到今年我们已经进入了移动互联网时代？所以，未来10年后人工智能发展的怎么样的情况谁都不知道，因为技术发展的这么快，我真的是觉得预测10年后世界会怎么样还是有一些还是很难的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;【新智元】谷歌的 Jeff Dean说，最快15年或许可以实现通用人工智能。您认为通用人工智能是百度的目标吗？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;吴恩达：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;其实每一个人每天都已经在用人工智能，比如说你用手机拍照，手机可以识别出第三方人脸，把垃圾邮件去掉也是人工智能，用搜索也是用人工智能，所以人每天已经有很多次使用人工智能了。&lt;/span&gt;&lt;span&gt;人工智能成功的时候，就是未来使用人工智能你感觉不到你在使用人工智能。未来你进到一辆汽车里，这辆汽车自动带你去想去的地方，你不用再想这是人工智能汽车。现在用的语音识别也是人工智能，到时候就不用再不断的想这是人工智能了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;【新智元】你们刚刚宣布开源深度学习平台PaddlePaddle，下一步想在生态建设方面有什么样的打算？Deep Speech今后会开源吗？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;吴恩达：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;现在世界有好几个不同的这类学习平台，有一些学习平台是支持新的算法研究的，我们的重点是帮助开发者使用最领先的深度学习模型。如果想用我们的平台来发明新的模型也可以，不过我们的重点是帮你学习使用这些模型。而且我们也会非常努力支持中国的开发者社区。&lt;/span&gt;&lt;span&gt;百度已经开放了语音识别的CPC平台，如果今天想用我们的语音识别API或者SDK，已经可以免费使用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;【新智元】您认为无监督学习下一步将有什么突破？百度在无监督学习方面有什么布局吗？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;吴恩达：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;无监督学习有很大的潜力。人的学习很多都是无监督的学习。&lt;/span&gt;&lt;span&gt;不过，这些工作还是在研究阶段，有可能过几年会有突破，这条路也是不太清楚。我们也有一些研究人员正在做这类工作，不过是不是会在一两年内有所突破还是很难讲。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;【新智元】以前百度产品和技术往往是2C的，就是面对大众的，现在开源术底层技术以后，会朝2B的模式发展吗？在美国谷歌或者是其他的人工智能公司也有这样的状况吗？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;吴恩达：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我们现在也有一些2B的业务，我觉得广告就是2B的业务。我们的开放云也是一个2B的业务。有很多机会关键就是怎么样抓住这些机会，无论是2B还是2C都可以做。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/UicQ7HgWiaUb39ziamfOZfA6o5epAiavAQa9GmAv0nKSYBwQNia5HkfutAAltdRUgI8H71jRQtZ1LNon0qia8NOrj1Ow/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;人工智能机会太多，百度要做的是为第三方提供支持&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;今天上午你讲了开放百度深度学习和百度大脑的平台，为什么想要开放这样的平台给开发者用，从您自身研究的角度来说，这样的开放能带来怎样的变化？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;吴恩达：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;在这个时代，我们有机会可以使用人工智能大量改变很多行业。我也说过人工智能是一个新电能，意思就是你想100年前电能不仅改变了一个行业，第一个发明是电灯，不过电能改变了很多不同行业，包括农业，甚至冰箱的发明，也改变了通讯，这个世界上用电来做的各种行业。所以现在人工智能可以改变更多的行业。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;百度是一家互联网公司，我们最重要的产品还是搜索，糯米、广告等等，人工智能对我们的产品已经有巨大的影响。不过我们下一步是希望跟各类的科技行业、科技公司和传统公司合作，帮助他们找到更好的项目机会，改变他们的行业。&lt;/span&gt;&lt;span&gt;我觉得这个工作价值非常大，我也不担心现在做这个会没有成果，只要找到最好的办法支持第三方公司就行。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;能不能找一个例子，说一下百度这两个平台开放出去对不同的项目和行业带来哪些作用？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;吴恩达：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我们的深度学习平台是开放给开发者的，现在深度学习的应用场景很多，所以很难讲。因为在百度有好几百个项目都是使用深度学习。第三方的包括生物纬度的预测、DNA序列分析。我不是说这些项目是我们做的，如果你问我电脑有什么用？现在是很难回答的，所以你问我机器学习有什么用，现在也一样很难回答。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第二个，我们也输出已经训练好的模型。比如说刚才说了斯坦佛大学和华盛顿大学发现，在手机语音输出比文本输出快三倍，如果有一个产品想用语音识别，直接用我们的语音识别或者用我们的语音合成系统。要做新的APP或者新的硬件，比如说自己想做一个智能电灯，让用户使用起来可以控制电灯，&lt;span&gt;可以&lt;/span&gt;用我们的语音识别做，图像也是，我们做了很多人脸识别的工作，已经跟第三方智能门锁公司正在合作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果在你外国看到一个外国字，看不懂，你拍一张照片，就可以自动识别这些字是什么，我们的地图团队就拍了很多照片，那些路标也用这些东西自动识别出来的，所以这些应用场景真的非常非常多。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我觉得在人工智能时代，有一个很大的问题就是机会太多了。在百度，我们的团队有很多不同的想法，不过，我们有很多非常有潜力的项目，真的没有去做，&lt;/span&gt;&lt;span&gt;比如启动人工智能做新的药品，我觉得那是一个非常好的项目，还没有人去做。农业上的精确杀虫也有很大的潜力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;关于把精力放在哪个项目上面，百度的决策机制是怎么样的？&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;吴恩达：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;一个大公司，没有办法只是我一个人选择全部的项目。因为我们公司有很不多同的部门，都需要自己决定应该做什么创新的项目。我们有很多工程师或者研究人员，他们有一个想法就自己找时间去做。有时候他们的工作做得比较成熟，做到了比较高端的层面，我们看到这个项目很有潜力，就会去投入更多个资源给这个项目。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有时候我也会看到一些比较大的机会，我们就跟团队一起探索一下，做一些商业分析去决定看做哪些工作。我个人是非常量化的，非常注重数字。如果有一个项目可以影响100万个用户，另一个项目可以影响500万个用户——数量这么大，人的大脑是很难理解100万用户和500万个用户有什么不一样的，人脑没有太好的办法理解这些数据的意思，所以我们评估这些项目的时候非常依赖数据的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;商业分析还会从其他哪些维度进行评估？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;吴恩达：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;现在很多项目重点都是找到最好的方法帮助最多的人，为他们带来最大的影响。如果你问我怎么赚钱，百度是公司，当然长期角度来讲追求盈利也是重要的。不过现在机会这么多，&lt;span&gt;我觉得我们过几年有机会对整个社会有非常非常大的影响。比如说农业，如果我们可以跟第三方公司合作改变农业，找到足够好的商业模式，我真的不是太担心。&lt;/span&gt;真的是帮助到了很多人，商业机会就自然而来了。&lt;span&gt;百度公司真的是有很多很多想法的公司，&lt;/span&gt;&lt;/span&gt;&lt;span&gt;我比较遗憾的是，我们没有足够的人去做这些项目。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;人工智能大事小事都要做&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;今天百度说开放自己的平台，可能未来有医疗大脑、交通大脑、银行大脑？您最看好人工智能改变的是哪个行业？&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;吴恩达：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;这是一个非常好的问题，也是一个非常难回答的问题，因为如果100年前我问你电能对哪个行业有最大的影响？这个很难回答。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们正在做不少有关医疗的工作，医疗大脑的项目从去年初开始做的，今天是第一次为大家展示它可以做得到的事情。我们有一些行业是发布过的，包括自动驾驶，我们的金融也是进展非常快的。这些是大量依赖人工智能的行业，百度可以自己做，也有机会跟第三方公司合作。自动驾驶百度就是在跟第三方车厂在合作。因为百度真的不知道怎么样生产一辆汽车，或者真的不知道怎么样生产一个方向盘，所以我们是跟车厂合作，我们做智能部分，他们做汽车。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;这次大会上百度展示特别多的应用场景，去年更多的停留在理论进展的阶段，今年尝试了很多应用的场景。这些应用场景是不是会马上应用于现实生活中，对这些行业产生改变？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;吴恩达：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;这些应用场景有些会比较快，可能就几个月，或者不需要太多的时间就可以实现。有些还需要一、两年，我今天讲的应用场景都是最长希望是一年就可以实现。&lt;/span&gt;&lt;span&gt;有些事比较难的，比如音乐作曲，除了百度以外还有好几个公司也在做这样的研究，很快这类技术很快会被使用。陪伴机器人这个还是比较难的，不过那些都是未来的产品，智能门锁、智能音箱等这些希望很快就能实现，希望一年之内就可以实现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;最快的就是智能门锁和智能音箱这些吗？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;吴恩达：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;百度至少有好几百个人工智能的项目，我们有很大的人工智能项目，比如搜索、广告、自动驾驶等等。我们也有很多小项目，人工智能不只是为一大件事情工作，我们的数据中心测硬件可能导致的失败，我们也可以用人工智能测试硬件失败的比例。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;上个月，8月4、5号左右，百度宣布了增强现实平台，这也是依赖于人工智能，在百度，好像我们每次一、两个月都有新的创新产品产生。&lt;/span&gt;&lt;span&gt;刚才讲了我们新的语音输入法，希望两个月后可以下载，打算最晚10月底、11月初可以上市，我们有很多想法利用人工智能技术很快的把这些想法实现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;您认为基于人工智能最有可能出现大众型的应用会在哪个领域，您认为百度在这个方面会有哪些投入，有可能在这个方面有一些产品？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;吴恩达：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;有一些巨大的方向已经在做了，自动驾驶和金融，医疗也有很大的潜力。还有很多方法，只是百度我们没有足够的知识去做，比如说让你用语音控制的音箱或者家电。比如说我们有一个团队正在跟Harman合作，跟他们做智能音箱，未来也会有这种机会我们创造一个新的解决方案团队，跟一些硬件公司进行比较深度的合作。不过，我不想去努力设计音箱，这不是我会做的事情。所以这类工作，智能音箱、智能门锁、智能家电我们重点还是支持第三方硬件公司跟他们一些协同合作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;百度对自动驾驶有信心&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;前段时间特斯拉辅助驾驶和自动驾驶出了几起事故引发了比较广泛的讨论，您对这个技术的前景，它现在发展的现状，包括特斯拉遇到的问题百度怎么解决这些问题，以及无人驾驶在伦理方面您有什么样的思考和意见？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;吴恩达：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我们觉得只有一条路可以走，所以我们对我们自己有信心，另外公司选择另外的办法做也是好的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;您的意思是说特斯拉这个问题不一定是无人驾驶里的普遍问题吗？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;吴恩达：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;现在技术方面还需要做一些工作，不过我们对安全的问题是非常重视的，但是要做到非常安全的，没有事故的自动驾驶车，我们现在有比较清楚的路线图，但是还有几年时间的路要走。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;团队管理与公司内部合作&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;您是在美国管理着一个实验室，这个实验室现在大概有多少人？&lt;/span&gt;现在在进行哪些项目？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;吴恩达：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我们美国团队有200人左右，分好几个团队，最大的团队是做有关语音的研究的产品工作，也有一大部分是做自动驾驶项目的。不过，我们也有另外一些团队是做深度学习的基本研究工作的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;按人工智能不同的功能和方向分的吗？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;吴恩达：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;对，有一部分是这样的，不过也有的团队在探索怎么样做新的语音产品。比如说刚才讲了一个新的语音输入法，是中文语音为主的键盘。我们也在看，如果我们做一个英文语音为主的键盘应该怎么样做，包括怎么设计。我们的智能音箱工作有一部分在中国，有一部分在美国也正在做，其实200个人可以做很多不同的项目。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;您提到的语音输入法的应用，全部是美国团队在做吗？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;吴恩达：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我刚才讲的那个是上海团队做的。有一些想法是我们美国团队先行的，有些想法是上海团队想到的。其实语音输入法是我们上海团队负责。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;您在美国那个团队跟百度在国内的团队怎么合作，想像中美国团队更偏向于理论研究，国内团队可能更便重实际业务。理论研究和实际业务之间这两个团队怎么结合？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;吴恩达：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;你讲的这种情况可能几年前是这样的，不过现在中国有很好的研究人员，所以人工智能最基本的发展都是中国团队做的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我觉得很多东西都是在中国发明的，有时候也好奇，在中国发明了一些新的技术，不过没有足够的信心，我们发明了这个技术还要看有没有人已经做了一模一样的东西。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;百度是第一个做GPU集群深度学习的公司，美国领先的人工智能公司都是跟着我们走这条路，所以可以看到，在深度学习算法上，人工智能算法上很多都是。当然有一部分是中国发明，有一部分是美国发明的，现在我觉得我们中国和美国的研究人员都是非常强的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;作为人工智能技术的领头人，各个业务是怎么样合作的？比如糯米、金融这种人工智能是怎么合作的？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;吴恩达：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;百度内部我们有一个团队，在百度有各类的人工智能技术，我们现在有一个团队是负责理解各种各样的技术，所以我们如果我们内部有一个部门想我们有什么人工智能技术，这个团队直接负责跟他们沟通和理解。有时候如果他们确定有些产品应该用语音识别，他们也会跟这个团队连接到我们的语音识别团队，让他们有更深度的合作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因为人工智能发展的快，在百度我们也做了很多培训的工作，来让我们自己的人员看到很多例子，看到很多应用场景。也有很多内部的课程，教我们的工程师怎么样用人工智能，也教我们的产品经理怎么样设计新的人工智能的产品。其实在我们百度内部已经有很多有关人工智能培训的资料，所以我们打算慢慢的把这类的培训资料开放在我们的平台上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;双方会协商这个产品应该用到哪个方面，然后双方配合？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;吴恩达：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;对。因为有很多问题需要理解人工智能，也需要理解一个行业。比如智能音箱，需要理解人工智能也需要理解音箱，我们内部也是这样的。不过怎么样做外卖，我是理解一点点，我不是外卖的专家，就需要我们的团队和他们的团队一起协同创新。&lt;/span&gt;&lt;span&gt;跟内部各个业务线合作的这个团队，&lt;/span&gt;&lt;span&gt;现在还没有向外具体公布具体的人数，还会想扩建这个团队。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;逐利的技术没有用，要用技术改变社会&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;论坛上您和Robin都提到了百度要成为一家人工智能的公司，这是不是意味着百度相比于以前的发展阶段来说，当下更注重以人工智能为代表的科技创新，而不是商业模式的创新——是在做这样的转型吗？&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;吴恩达：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我觉得逐利的技术是没有什么用的。举一个例子，比如我们有能力可以让你输入一张图片，或者自动输出一句话，告诉你这张图片的内容是什么这个技术到底有什么。技术逐利我觉得没有什么用，不过这些技术给我们机会，让我们或者若第三方的团队找新的应用场景，或者新的商业机会。所以，人工智能不只是做人工智能就可以成功，是需要找到有效、有意思的应用场景进行商业运作才行。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;好的产品需要结合各种各样不同的技术。而在百度，最强的就是人工智能技术。所以我们想使用我们的人工智能帮助第三方，我个人的目的是想找到办法想支持第三方，跟第三方公司和开发者一起去做，让这些技术改变很多行业，从而改变社会。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;现在人人都在说人工智能，有些人感觉人工智能吹的有点过了，您怎么看这种现象？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;吴恩达：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我觉得人工智能真的是会改变很多行业，这是一个非常高的目标，这个非常高的目标可以改变很多行业，这是我们可以实现的。有一个更高的目标就是人想去做什么，人工智能就可以做，第二个目标那条路还是不太清楚。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;【号外】&lt;/strong&gt;&lt;span&gt;&lt;span&gt;由中国自动化学会和新智元联合主办&lt;/span&gt;的AI全球年度盛典『AI WORLD 2016世界人工智能大会』即将盛大开幕。&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;大会官网：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;http://aiworld2016.com/&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/UicQ7HgWiaUb39ziamfOZfA6o5epAiavAQa9QLMXpuxRPEU0B0okUyyW2kLfxmxRQNzibxQl9gyOSe7sORFYKMRX3JQ/0?wx_fmt=jpeg"/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/UicQ7HgWiaUb39ziamfOZfA6o5epAiavAQa9ggA8S7l8ZxV46J4YiaeOsuSULficdm22lb8J9ASn8icpZUb6SNsr3w4EA/0?wx_fmt=jpeg"/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/UicQ7HgWiaUb39ziamfOZfA6o5epAiavAQa9M4EJG3lOiaHrWNcu0wsbPqFPrA7YmV8PJI9bdkHado90fOq9pyyxXJA/0?wx_fmt=jpeg"/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/UicQ7HgWiaUb39ziamfOZfA6o5epAiavAQa9HETPF65LFUCX5zyzzy1HACrSMFPZRR5R6KAJiabaUanSNx10ricLxf3Q/0?wx_fmt=jpeg"/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;更多详情，点击“阅读原文”，查看大会官网&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 01 Sep 2016 21:49:41 +0800</pubDate>
    </item>
    <item>
      <title>图灵学习：首个只需要“看”就能学习的系统</title>
      <link>http://www.iwgc.cn/link/2522577</link>
      <description>&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;1 &lt;/span&gt;新智元编译&lt;/span&gt;&lt;span&gt;1&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&amp;nbsp;来源：extremetech.com&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;译者&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;：闻菲&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;【新智元导读】&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;谢菲尔德大学研究人员日前在学术期刊《群智能》（Swarm Intelligence）刊文，介绍了一个叫“图灵学习”的系统。研究人员表示，这是首个让计算机只通过“看”就学会技能的系统。这种自行理解复杂模型的能力，为研发通用人工智能打下了基础。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;inherit&gt;&lt;br/&gt;&lt;/inherit&gt;&lt;/p&gt;&lt;p&gt;&lt;inherit&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz/UicQ7HgWiaUb1GNdLuPNMK8Mz5ukxeTwWExDbnS6Hr1JicPgZ9AlGJiagK9n98c23sHos09uyGV9zPDRROhA5hHbLg/0?wx_fmt=gif"/&gt;&lt;/inherit&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;上述论文已经公开发表，地址：http://link.springer.com/article/10.1007%2Fs11721-016-0126-1#Sec33&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;【题目】图灵学习：无需度量推断机器人群行为的方法及其应用（Turing learning: a metric-free approach to inferring behavior and its application to swarms）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;【作者】Wei Li, Melvin Gauci, Roderich Groß&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;摘要&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们提出图灵学习系统，一种推测自然或人工系统行为的新的系统识别方式。图灵学习过程同时优化两个计算机项目群，一组代表受调查的系统的行为模式，另一个代表分类器。通过观察系统的行为和模型生成的结果，计算机能够得到两组数据。分类器的目标是找出这两组数据集的不同，然后将自然的和后期生成的分别归到不同类型里。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/UicQ7HgWiaUb0gUkf57uOplb0gTvc0sxLpqs4fZAEibLFXpDwv3h31ZOZgxcjmNL2lgu40V3LibITgjQIO1fZkSVjA/0?wx_fmt=jpeg"/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在，计算机能自己从理解数据并找出规律。图为谷歌训练自动识别人脸的算法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;研究人员介绍，使用所谓的“图灵学习”系统，让人工智能观看一个机器人群的简单行动后，找出这群机器人行动遵守的准则，其方法并非找出表明机器人群某个行为特征的指示器，而是通过简单的模仿：计算机不断模仿机器人群的行为，一次比一次精准，最终在模仿的过程中，学会了机器人群的行为模式。研究人员认为，图灵学习系统十分简单，有望模仿人和其他动物的行为，被用于从生化分析到个人安保等各种场景。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;与其他系统识别方法不同之处在于，图灵学习系统不需要预先设置度量（metric），定量表示系统和模型之间的区别。作者在论文中描述了两个案例，表明模拟机器人群的行为规律不能通过基于度量的系统推断得出。相比之下，图灵学习以极高的准确率对机器人群的行为作出了预测。不仅如此，图灵学习还产生了一个有用的副产物——分类器——可以用于检测机器人群的异常行动。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;结果表明，针对个体进行运动跟踪，能够直接推理机器人群的集体行动。当使用度量很难对机器人群行动进行特征分类时，图灵学习就尤其有用，因此该系统可以被用于一系列广泛的任务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;研究中，一个机器人群被称为“代理”，根据简单的规则运动，这一规则我们并不知道。同时，另一个机器人群，也叫做“模型”，一开始进行随机、无意义的行为。然后，“分类器”算法比较这两个机器人群。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;算法并不知道哪个是代理，哪个是模型。因此，最开始完全靠猜测。不过，一旦算法猜对了，就会获得某种奖励（每当模型成功骗过分类器时，模型也会得到奖励）。从原理上说，即使从随机状态开始，分类器也能够很快区分出不相关的部分，然后聚焦对结果准确率真正有影响的因素。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图灵学习系统的功能基本上与神经网络相同。不过，由于需要的人类干预少，因此被带入人类偏见的可能性也偏低。这一点是图灵学习系统的优势所在。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;编译来源：http://www.extremetech.com/extreme/234669-turing-learning-breakthrough-computers-can-now-learn-from-pure-observation&lt;/span&gt;&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;【号外】&lt;/strong&gt;&lt;span&gt;&lt;span&gt;由中国自动化学会和新智元联合主办&lt;/span&gt;的AI全球年度盛典『AI WORLD 2016世界人工智能大会』即将盛大开幕。&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;大会官网：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;http://aiworld2016.com/&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/UicQ7HgWiaUb39ziamfOZfA6o5epAiavAQa9QLMXpuxRPEU0B0okUyyW2kLfxmxRQNzibxQl9gyOSe7sORFYKMRX3JQ/0?wx_fmt=jpeg"/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/UicQ7HgWiaUb39ziamfOZfA6o5epAiavAQa9ggA8S7l8ZxV46J4YiaeOsuSULficdm22lb8J9ASn8icpZUb6SNsr3w4EA/0?wx_fmt=jpeg"/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/UicQ7HgWiaUb39ziamfOZfA6o5epAiavAQa9M4EJG3lOiaHrWNcu0wsbPqFPrA7YmV8PJI9bdkHado90fOq9pyyxXJA/0?wx_fmt=jpeg"/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/UicQ7HgWiaUb39ziamfOZfA6o5epAiavAQa9HETPF65LFUCX5zyzzy1HACrSMFPZRR5R6KAJiabaUanSNx10ricLxf3Q/0?wx_fmt=jpeg"/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;更多详情，点击“阅读原文”，查看大会官网&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 01 Sep 2016 21:49:41 +0800</pubDate>
    </item>
    <item>
      <title>全球首个人工智能“出家人”，他的未来不可想象 | 晚课预告</title>
      <link>http://www.iwgc.cn/link/2522578</link>
      <description>&lt;table width="895" style="width: 736px;"&gt;&lt;tbody style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;tr style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;td valign="top" rowspan="5" colspan="1" style="word-break: break-all; max-width: 100%; word-wrap: break-word !important; box-sizing: border-box !important;"&gt;&lt;span&gt;你知道全球首个人工智能“出家人”是谁吗？&lt;/span&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他叫贤二，被大家称作佛法界的“siri”。但他比siri更厉害，他还懂佛法。贤二是一个拥有佛教世界观的机器僧，它有着呆萌的外貌，充满了幽默细胞，他用诙谐的话语传播着佛法，开解众生的困惑与“骚扰”，一经诞生就颇受大众的喜爱和追捧。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;贤二打破了大众对机器人的一贯认知，也让人心生好奇，如此可爱的机器僧是怎样诞生的？人工智能和佛法的结合对人工智能的应用发展、对佛法的传播又会有什么样的影响？人工智能的发展前景究竟会走向何方呢？&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/tr&gt;&lt;tr style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/tr&gt;&lt;tr style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/tr&gt;&lt;tr style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;9月4日，来听新智元创始人、人工智能专家杨静为大家分享：“贤二机器僧：漫画小和尚到机器智能的高僧大德”！&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;分享嘉宾&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/donYUrCu9C4ibkCTneGcWB4DUnBrSaCRS0jsJvdic68hRibvia0ia4ticiaMXc1r2ukqQBboR9BGcOjndZUrKxz8PmiaQA/640?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;杨静&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;新智元创始人&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;人工智能专家&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;分享书籍&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/donYUrCu9C4ccFJlX4nTXuySa92SB3F0icwx8ugDkgQj5Ugib6icGsqWEdggl2NVicV0DOxWyJKtgTG8y1iahYpkwzw/640?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;“妈妈老是唠叨怎么办？”“老人嘛，让着她吧。” 呆萌的人工智能“出家人”贤二机器僧总能给出有趣的答案。《贤二机器僧漫游人工智能》全面讲述贤二机器僧创制过程，带你了解佛学和科技如何擦出“爱的火花”。贤二机器僧的出现对佛教和科技有着怎样的积极意义和重要影响？让贤二机器僧带你解读人工智能发展史，深入探寻人工智能当下与未来的发展与意义。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;分享大纲&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;缘起龙泉极客栈&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;漫画小和尚想修成机器“僧”&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;贤二机器僧“萌生”&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;龙泉寺十周年普茶晚会&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;龙泉寺中秋贤二2代亮相&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;贤二终将修成“机器佛”&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;如何参与在线晚课&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;庐客汇在线晚课目前仅提供给购买“12+50”的会员，如果您想听课，请关注庐客汇公众号（lukehui1230），点击菜单 &lt;/span&gt;&lt;strong&gt;&lt;strong&gt;微商城 → 庐客汇12+50全年服务&lt;/strong&gt;&lt;/strong&gt;&lt;span&gt;，完成付费。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;详情可添加小庐微信&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz/MJFnicXpzpvGCxrSyw59ANPZhwSkQ7oxhqff0Srf8Piav7ZJ6Q8ZRQVicQkd2nCEub3o24S1lG99dWMAtHGia0jFDQ/640?wx_fmt=jpeg"/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;—转载授权、商务合作—&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;联系邮箱：zhouyi@cheerspublishing.com&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;—END—&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;点击【阅读原文】，即刻报名12+50阅读服务。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 01 Sep 2016 21:49:41 +0800</pubDate>
    </item>
    <item>
      <title>【重磅】百度开源分布式深度学习平台，挑战TensorFlow (教程)</title>
      <link>http://www.iwgc.cn/link/2498767</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;1 &lt;/span&gt;新智元编译&lt;/span&gt;&lt;span&gt;1&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&amp;nbsp;来源：Github，Hacker News，paddlepaddle.org&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;译者&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;：胡祥杰&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;【新智元导读】&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;今天百度开源深度学习平台Paddle。业内人士纷纷点赞：&lt;span&gt;Paddle&lt;/span&gt;代码简洁、设计干净，没有太多的abstraction，速度比Tensorflow、The&lt;/span&gt;&lt;span&gt;ano快，显存占用小，可多机多卡并行，支持CPU和GPU、文档比较全……Hacker News有评论，在不支持TensorFlow的中国，百度的Paddle或有机会获胜。百度一直说自己深耕深度学习，其技术水平如何，本次开源或可提供一些线索。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;inherit&gt;&lt;br/&gt;&lt;/inherit&gt;&lt;/p&gt;&lt;p&gt;&lt;inherit&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz/UicQ7HgWiaUb1GNdLuPNMK8Mz5ukxeTwWExDbnS6Hr1JicPgZ9AlGJiagK9n98c23sHos09uyGV9zPDRROhA5hHbLg/0?wx_fmt=gif"/&gt;&lt;/inherit&gt;&lt;/p&gt;&lt;p&gt;&lt;inherit&gt;&lt;br/&gt;&lt;/inherit&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;百度深度学习 PaddlePaddle&amp;nbsp;（Parallel Distributed Deep Learning）是一个云端托管的分布式深度学习平台，对于序列输入、稀疏输入和大规模数据的模型训练有着良好的支持，支持GPU运算，支持数据并行和模型并行，仅需少量代码就能训练深度学习模型，大大降低了用户使用深度学习技术的成本。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;根据百度官方网站的介绍，Paddle 有以下优势：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;inherit&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/UicQ7HgWiaUb0gUkf57uOplb0gTvc0sxLpic7Lo3WKyIj6D2MXuYhgNk3h9dMszpJmXYGePK3bWHybZsvnYX4bzbQ/0?wx_fmt=png"/&gt;&lt;/inherit&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Github 上介绍，PaddlePaddle有以下特点：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class="list-bullet1 list-paddingleft-2" style="margin-left: 1.5em; -webkit-padding-start: 0px; outline: none;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;灵活&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;PaddlePaddle支持大量的神经网络架构和优化算法。很容易安装复杂的模型，比如拥有注意力（attention）机制或者复杂记忆连接的神经机器翻译模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class="list-bullet1 list-paddingleft-2" style="margin-left: 1.5em; -webkit-padding-start: 0px; outline: none;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;高效&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了利用异构计算资源的能力，PaddlePaddle中的每一级都会进行优化，其中包括计算、内存、架构和通信。以下 是几个例子：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ol start="1" class="list-number2 list-paddingleft-2" style="list-style-type: lower-latin;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;通过SSE/AVX 内联函数、BLAS数据库（例如MKL,ATLAS，cuBLAS）或者定制化的CPU/GPU 核优化数字。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;高度优化的递归网络，在没有padding 的情况下，也能处理不同长度的序列。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;对拥有高维稀疏数据的模型进行局部优化和分布式训练。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;inherit&gt;&lt;br/&gt;&lt;/inherit&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;可扩展&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有了PaddlePaddle，使用多个CPU和GPU以及机器来加速训练可以变得很轻松。 PaddlePaddle 能通过优化通信，获得高吞吐量和性能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;inherit&gt;&lt;br/&gt;&lt;/inherit&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;与产品的连接&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;PaddlePaddle的部署也很简单。在百度，PaddlePaddle 已经被用于产品和服务中，拥有大量用户。应用场景包括广告点击率（CTR）预测、大规模图像分类、光学字符识别、搜索排名、计算机病毒检测、推荐等等。PaddlePaddle 在百度有着巨大的影响。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;inherit&gt;&lt;br/&gt;&lt;/inherit&gt;&lt;/p&gt;&lt;p&gt;&lt;inherit&gt;&lt;br/&gt;&lt;/inherit&gt;&lt;/p&gt;&lt;p&gt;&lt;inherit&gt;&lt;span&gt;PaddlePaddle地址：&lt;/span&gt;&lt;/inherit&gt;&lt;span&gt;Github：&lt;/span&gt;&lt;a style="font-size: 14px; text-decoration: underline;"&gt;https://github.com/baidu/paddle&lt;/a&gt; &lt;span&gt;官方：&lt;/span&gt;&lt;a style="font-size: 14px; text-decoration: underline;"&gt;http://www.paddlepaddle.org/doc_cn/&lt;/a&gt;&lt;span&gt;（中文）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;评价 ：贾扬清在知乎上的技术点评&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Facebook 深度学习研究员贾扬清在知乎上评价说&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：今天刚看到的，简单说一些第一印象（以目前的github repo为准）。整体的设计感觉和Caffe心有灵犀，同时解决了Caffe早期设计当中的一些问题（比如说default stream）。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;inherit&gt;&lt;br/&gt;&lt;/inherit&gt;&lt;/p&gt;&lt;p&gt;&lt;inherit&gt;&lt;span&gt;1. 很高质量的GPU代码&lt;/span&gt;&lt;/inherit&gt;&lt;/p&gt;&lt;p&gt;&lt;inherit&gt;&lt;br/&gt;&lt;/inherit&gt;&lt;/p&gt;&lt;p&gt;&lt;inherit&gt;&lt;span&gt;2. 非常好的RNN设计&lt;/span&gt;&lt;/inherit&gt;&lt;/p&gt;&lt;p&gt;&lt;inherit&gt;&lt;br/&gt;&lt;/inherit&gt;&lt;/p&gt;&lt;p&gt;&lt;inherit&gt;&lt;span&gt;3. 设计很干净，没有太多的abstraction，这一点比TensorFlow好很多。&lt;/span&gt;&lt;/inherit&gt;&lt;/p&gt;&lt;p&gt;&lt;inherit&gt;&lt;br/&gt;&lt;/inherit&gt;&lt;/p&gt;&lt;p&gt;&lt;inherit&gt;&lt;span&gt;4. 高速RDMA的部分貌似没有开源（可能是因为RDMA对于cluster design有一定要求）：&lt;/span&gt;&lt;a style="font-size: 14px; text-decoration: underline;"&gt;&lt;span&gt;Paddle/RDMANetwork.h at master · baidu/Paddle · GitHub&lt;/span&gt;&lt;/a&gt;&lt;/inherit&gt;&lt;/p&gt;&lt;p&gt;&lt;inherit&gt;&lt;br/&gt;&lt;/inherit&gt;&lt;/p&gt;&lt;p&gt;&lt;inherit&gt;&lt;span&gt;5. 设计思路比较像第一代的DL框架，不过考虑到paddle已经有年头了，这样设计还是有历史原因的。&lt;/span&gt;&lt;/inherit&gt;&lt;/p&gt;&lt;p&gt;&lt;inherit&gt;&lt;br/&gt;&lt;/inherit&gt;&lt;/p&gt;&lt;p&gt;&lt;inherit&gt;&lt;span&gt; &amp;nbsp; &amp;nbsp;5.1 config是hard-code的protobuf message，这对扩展性可能会有影响。&lt;/span&gt;&lt;/inherit&gt;&lt;/p&gt;&lt;p&gt;&lt;inherit&gt;&lt;br/&gt;&lt;/inherit&gt;&lt;/p&gt;&lt;p&gt;&lt;inherit&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; 5.2 可以看到很多有意思的类似历史遗留的设计：采用了STREAM_DEFAULT macro，然后通过TLS的方式定向到非default stream：&lt;/span&gt;&lt;span&gt;Paddle/hl_base.h at 4fe7d833cf0dd952bfa8af8d5d7772bbcd552c58 · baidu/Paddle · GitHub&lt;/span&gt;&lt;span&gt;&amp;nbsp;（所以Paddle off-the-shelf不支持mac？）&lt;/span&gt;&lt;/inherit&gt;&lt;/p&gt;&lt;p&gt;&lt;inherit&gt;&lt;br/&gt;&lt;/inherit&gt;&lt;/p&gt;&lt;p&gt;&lt;inherit&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; 5.3 在梯度计算上采用了传统的粗粒度forward/backward设计（类似Caffe）。可能有人会说“所以paddle没有auto gradient generation”，这是不对的，autograd的存在与否和op的粒度粗细无关。事实上，TensorFlow在意识到细粒度operator超级慢的速度以后，也在逐渐转回粗粒度的operator上。&lt;/span&gt;&lt;/inherit&gt;&lt;/p&gt;&lt;p&gt;&lt;inherit&gt;&lt;br/&gt;&lt;/inherit&gt;&lt;/p&gt;&lt;p&gt;&lt;inherit&gt;&lt;span&gt;目前只看到这里。总之是一个非常solid的框架，百度的开发功底还是不错的。&lt;/span&gt;&lt;/inherit&gt;&lt;/p&gt;&lt;p&gt;&lt;inherit&gt;&lt;br/&gt;&lt;/inherit&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;影响力评价 ：&amp;nbsp; Hack News的评论&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;inherit&gt;&lt;br/&gt;&lt;/inherit&gt;&lt;/p&gt;&lt;p&gt;&lt;inherit&gt;&lt;span&gt;cs702: 又一个深度学习框架，这次来自百度。&lt;/span&gt;&lt;/inherit&gt;&lt;/p&gt;&lt;p&gt;&lt;inherit&gt;&lt;br/&gt;&lt;/inherit&gt;&lt;/p&gt;&lt;p&gt;&lt;inherit&gt;&lt;span&gt;鉴于TensorFlow在AI研究者和实践者中的统治力逐渐增强，加上拥有大量使用基础的既有框架，比如Theano，Torch和Caffe，我并不认为这一新的框架在美国或者其他西方的市场会获得大范围的采用。在我看来，TensorFlow的势力在当下很难战胜。&lt;/span&gt;&lt;/inherit&gt;&lt;/p&gt;&lt;p&gt;&lt;inherit&gt;&lt;br/&gt;&lt;/inherit&gt;&lt;/p&gt;&lt;p&gt;&lt;inherit&gt;&lt;span&gt;但是，Paddle在中国可能会获得大范围的采用，因为那是百度的母国市场。&lt;/span&gt;&lt;/inherit&gt;&lt;/p&gt;&lt;p&gt;&lt;inherit&gt;&lt;br/&gt;&lt;/inherit&gt;&lt;/p&gt;&lt;p&gt;&lt;inherit&gt;&lt;span&gt;Vonnik：使用TensorFlow的大部分都是来自Udacity 课程的学生。所以，“Tensor Flow崛起” 这这种说法并不正确，这些人中95%都是没用什么经验的，更不用说在实际产品中应用了。从技术层面上来说，TensorFlow并没有比其他的框架好很多。它有一个很漂亮的网站，有几个教学视频，但是它性能并不是很好，比如，在大型产品的环境中。深度学习平台实际上变化得非常快：TensorFlow、CNTK、DSSTNE等等，都是过去10个月间出现的。所以说，Paddle 还是有机会的，尤其是在中国，因为那里的人不能使用谷歌云——那是TensorFlow最佳的训练平台。&lt;/span&gt;&lt;/inherit&gt;&lt;/p&gt;&lt;p&gt;&lt;inherit&gt;&lt;br/&gt;&lt;/inherit&gt;&lt;/p&gt;&lt;p&gt;&lt;inherit&gt;&lt;span&gt;HackerNews上，曾有一个关于最受欢迎的深度学习工具的投票，时间范围是7月15日到8月15日，当时，TensorFlow获得了第一。&lt;/span&gt;&lt;/inherit&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;inherit&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/UicQ7HgWiaUb0gUkf57uOplb0gTvc0sxLp3iaHuia8O9VVmIbR3eX9ibibLRm1kFvVd9xP3coR5hXXl9DOvnNkcCvADw/0?wx_fmt=jpeg"/&gt;&lt;/inherit&gt;&lt;/p&gt;&lt;p&gt;&lt;inherit&gt;&lt;br/&gt;&lt;/inherit&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;总的来说， Paadle是百度使用了多年的深度学习平台，并且已经做出了一些实际的产品，较为成熟。在性能和各项指标上，比如：代码简洁、设计很干净，没有太多的abstraction、&amp;nbsp;速度比tensorflow，theano快，显存占用小、可多机多卡并行，支持cpu和gpu、文档比较全等等，Paddle也获得了较高的肯定，是一个不错的深度学习工具，在国内有较大的应用潜力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;inherit&gt;&lt;br/&gt;&lt;/inherit&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;附：PaddlePaddle快速入门教程 http://www.paddlepaddle.org/doc_cn/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们以文本分类问题作为背景，介绍PaddlePaddle使用流程和常用的网络基础单元的配置方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;h2 style="font-family: &amp;#39;Trebuchet MS&amp;#39;, sans-serif; color: rgb(32, 67, 92); border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(204, 204, 204); margin: 20px -20px 10px; padding-top: 3px; padding-bottom: 3px; padding-left: 10px; font-size: 25.6px; background-color: rgb(242, 242, 242);"&gt;&lt;span&gt;安装(Install)&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;首先请参考&lt;/span&gt;&lt;span&gt;安装教程&lt;/span&gt;&lt;span&gt;安装PaddlePaddle。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;h2 style="font-family: &amp;#39;Trebuchet MS&amp;#39;, sans-serif; color: rgb(32, 67, 92); border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(204, 204, 204); margin: 20px -20px 10px; padding-top: 3px; padding-bottom: 3px; padding-left: 10px; font-size: 25.6px; background-color: rgb(242, 242, 242);"&gt;&lt;span&gt;使用概述(Overview)&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;文本分类问题&lt;/strong&gt;：对于给定的一条文本， 我们从提前给定的类别集合中选择其所属类 别。比如通过用户对电子商务网站评论，评估产品的质量：&lt;/span&gt;&lt;/p&gt;&lt;ul class="simple list-paddingleft-2"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;这个显示器很棒！ （好评）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;用了两个月之后这个显示器屏幕碎了。（差评）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;每一个任务流程都可以分为如下5个基础部分。&lt;/span&gt;&lt;/p&gt;&lt;center&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/UicQ7HgWiaUb0gUkf57uOplb0gTvc0sxLp5LwiaadiaPbqYdosz1eSnt8dR24FPjtOob5KVKtvLyyibFzmB6UuHvicSg/0?wx_fmt=jpeg"/&gt;&lt;/center&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ol class="simple list-paddingleft-2"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;数据格式准备&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;ul class=" list-paddingleft-2"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;每行保存一条样本，类别Id 和文本信息用Tab间隔， 文本中的单词用空格分隔（如果不切词，则字与字之间用空格分隔），例如：&lt;/span&gt;&lt;code class="docutils literal" style="padding-right: 1px; padding-left: 1px; font-size: 0.95em; background-color: rgb(236, 240, 243);"&gt;&lt;span&gt;类别Id‘\t’&amp;nbsp;这&amp;nbsp;个&amp;nbsp;显&amp;nbsp;示&amp;nbsp;器&amp;nbsp;很&amp;nbsp;棒&amp;nbsp;！&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;数据向模型传送&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;ul class=" list-paddingleft-2"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;PaddlePaddle可以读取Python写的传输数据脚本，所有字符都将转换为连续整数表示的Id传给模型&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;网络结构（由易到难展示4种不同的网络配置）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;ul class=" list-paddingleft-2"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;逻辑回归模型&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;词向量模型&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;卷积模型&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;时序模型&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;优化算法&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;训练模型&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;预测&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;h2 style="font-family: &amp;#39;Trebuchet MS&amp;#39;, sans-serif; color: rgb(32, 67, 92); border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(204, 204, 204); margin: 20px -20px 10px; padding-top: 3px; padding-bottom: 3px; padding-left: 10px; font-size: 25.6px; background-color: rgb(242, 242, 242);"&gt;&lt;span&gt;数据格式准备(Data Preparation)&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;在本问题中，我们使用&lt;/span&gt;&lt;span&gt;Amazon电子产品评论数据&lt;/span&gt;&lt;span&gt;， 将评论分为好评(正样本)和差评(负样本)两类。&lt;/span&gt;&lt;code class="docutils literal" style="padding-right: 1px; padding-left: 1px; font-size: 0.95em; background-color: rgb(236, 240, 243);"&gt;&lt;span&gt;demo/quick_start&lt;/span&gt;&lt;/code&gt;&lt;span&gt;里提供了数据下载脚本 和预处理脚本。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;cd&lt;/span&gt; demo/quick_start
./data/get_data.sh
pip install -r requirements.txt
./preprocess.sh&lt;/span&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;h2 style="font-family: &amp;#39;Trebuchet MS&amp;#39;, sans-serif; color: rgb(32, 67, 92); border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(204, 204, 204); margin: 20px -20px 10px; padding-top: 3px; padding-bottom: 3px; padding-left: 10px; font-size: 25.6px; background-color: rgb(242, 242, 242);"&gt;&lt;span&gt;数据向模型传送(Transfer Data to Model)&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;h3 style="font-family: &amp;#39;Trebuchet MS&amp;#39;, sans-serif; color: rgb(32, 67, 92); border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(204, 204, 204); margin: 20px -20px 10px; padding-top: 3px; padding-bottom: 3px; padding-left: 10px; font-size: 22.4px; background-color: rgb(242, 242, 242);"&gt;&lt;span&gt;Python数据加载脚本(Data Provider Script)&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;下面dataprovider_bow.py文件给出了完整例子，主要包括两部分：&lt;/span&gt;&lt;/p&gt;&lt;ul class="simple list-paddingleft-2"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;initalizer： 定义文本信息、类别Id的数据类型。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;process： yield文本信息和类别Id，和initalizer里定义顺序一致。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;from&lt;/span&gt; &lt;span&gt;paddle.trainer.PyDataProvider2&lt;/span&gt; &lt;span&gt;import&lt;/span&gt; &lt;span&gt;*&lt;/span&gt;&lt;span&gt;# id of the word not in dictionary&lt;/span&gt;UNK_IDX &lt;span&gt;=&lt;/span&gt; &lt;span&gt;0&lt;/span&gt;&lt;span&gt;# initializer is called by the framework during initialization.# It allows the user to describe the data types and setup the# necessary data structure for later use.# `settings` is an object. initializer need to properly fill settings.input_types.# initializer can also store other data structures needed to be used at process().# In this example, dictionary is stored in settings.# `dictionay` and `kwargs` are arguments passed from trainer_config.lr.py&lt;/span&gt;&lt;span&gt;def&lt;/span&gt; &lt;span&gt;initializer&lt;/span&gt;(settings, dictionary, &lt;span&gt;**&lt;/span&gt;kwargs): &amp;nbsp; &amp;nbsp;&lt;span&gt;# Put the word dictionary into settings&lt;/span&gt;
 &amp;nbsp; &amp;nbsp;settings&lt;span&gt;.&lt;/span&gt;word_dict &lt;span&gt;=&lt;/span&gt; dictionary &amp;nbsp; &amp;nbsp;&lt;span&gt;# setting.input_types specifies what the data types the data provider&lt;/span&gt;
 &amp;nbsp; &amp;nbsp;&lt;span&gt;# generates.&lt;/span&gt;
 &amp;nbsp; &amp;nbsp;settings&lt;span&gt;.&lt;/span&gt;input_types &lt;span&gt;=&lt;/span&gt; [ &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;span&gt;# The first input is a sparse_binary_vector,&lt;/span&gt;
 &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;span&gt;# which means each dimension of the vector is either 0 or 1. It is the&lt;/span&gt;
 &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;span&gt;# bag-of-words (BOW) representation of the texts.&lt;/span&gt;
 &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;sparse_binary_vector(&lt;span&gt;len&lt;/span&gt;(dictionary)), &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;span&gt;# The second input is an integer. It represents the category id of the&lt;/span&gt;
 &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;span&gt;# sample. 2 means there are two labels in the dataset.&lt;/span&gt;
 &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;span&gt;# (1 for positive and 0 for negative)&lt;/span&gt;
 &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;integer_value(&lt;span&gt;2&lt;/span&gt;)]&lt;span&gt;# Delaring a data provider. It has an initializer 'data_initialzer'.# It will cache the generated data of the first pass in memory, so that# during later pass, no on-the-fly data generation will be needed.# `setting` is the same object used by initializer()# `file_name` is the name of a file listed train_list or test_list file given# to define_py_data_sources2(). See trainer_config.lr.py.&lt;/span&gt;&lt;span&gt;@provider&lt;/span&gt;(init_hook&lt;span&gt;=&lt;/span&gt;initializer, cache&lt;span&gt;=&lt;/span&gt;CacheType&lt;span&gt;.&lt;/span&gt;CACHE_PASS_IN_MEM)&lt;span&gt;def&lt;/span&gt; &lt;span&gt;process&lt;/span&gt;(settings, file_name): &amp;nbsp; &amp;nbsp;&lt;span&gt;# Open the input data file.&lt;/span&gt;
 &amp;nbsp; &amp;nbsp;&lt;span&gt;with&lt;/span&gt; &lt;span&gt;open&lt;/span&gt;(file_name, &lt;span&gt;'r'&lt;/span&gt;) &lt;span&gt;as&lt;/span&gt; f: &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;span&gt;# Read each line.&lt;/span&gt;
 &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;span&gt;for&lt;/span&gt; line &lt;span&gt;in&lt;/span&gt; f: &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;span&gt;# Each line contains the label and text of the comment, separated by \t.&lt;/span&gt;
 &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;label, comment &lt;span&gt;=&lt;/span&gt; line&lt;span&gt;.&lt;/span&gt;strip()&lt;span&gt;.&lt;/span&gt;split(&lt;span&gt;'&lt;/span&gt;&lt;span&gt;\t&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;) &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;span&gt;# Split the words into a list.&lt;/span&gt;
 &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;words &lt;span&gt;=&lt;/span&gt; comment&lt;span&gt;.&lt;/span&gt;split() &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;span&gt;# convert the words into a list of ids by looking them up in word_dict.&lt;/span&gt;
 &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;word_vector &lt;span&gt;=&lt;/span&gt; [settings&lt;span&gt;.&lt;/span&gt;word_dict&lt;span&gt;.&lt;/span&gt;get(w, UNK_IDX) &lt;span&gt;for&lt;/span&gt; w &lt;span&gt;in&lt;/span&gt; words] &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;span&gt;# Return the features for the current comment. The first is a list&lt;/span&gt;
 &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;span&gt;# of ids representing a 0-1 binary sparse vector of the text,&lt;/span&gt;
 &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;span&gt;# the second is the integer id of the label.&lt;/span&gt;
 &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;span&gt;yield&lt;/span&gt; word_vector, &lt;span&gt;int&lt;/span&gt;(label)&lt;/span&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;h3 style="font-family: &amp;#39;Trebuchet MS&amp;#39;, sans-serif; color: rgb(32, 67, 92); border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(204, 204, 204); margin: 20px -20px 10px; padding-top: 3px; padding-bottom: 3px; padding-left: 10px; font-size: 22.4px; background-color: rgb(242, 242, 242);"&gt;&lt;span&gt;配置中的数据加载定义(Data Provider in Configure)&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;在模型配置中利用&lt;/span&gt;&lt;code class="docutils literal" style="padding-right: 1px; padding-left: 1px; font-size: 0.95em; background-color: rgb(236, 240, 243);"&gt;&lt;span&gt;define_py_data_sources2&lt;/span&gt;&lt;/code&gt;&lt;span&gt;加载数据：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;from&lt;/span&gt; &lt;span&gt;paddle.trainer_config_helpers&lt;/span&gt; &lt;span&gt;import&lt;/span&gt; &lt;span&gt;*&lt;/span&gt;&lt;span&gt;file&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;"data/dict.txt"&lt;/span&gt;word_dict &lt;span&gt;=&lt;/span&gt; &lt;span&gt;dict&lt;/span&gt;()&lt;span&gt;with&lt;/span&gt; &lt;span&gt;open&lt;/span&gt;(dict_file, &lt;span&gt;'r'&lt;/span&gt;) &lt;span&gt;as&lt;/span&gt; f: &amp;nbsp; &amp;nbsp;&lt;span&gt;for&lt;/span&gt; i, line &lt;span&gt;in&lt;/span&gt; &lt;span&gt;enumerate&lt;/span&gt;(f):
 &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;w &lt;span&gt;=&lt;/span&gt; line&lt;span&gt;.&lt;/span&gt;strip()&lt;span&gt;.&lt;/span&gt;split()[&lt;span&gt;0&lt;/span&gt;]
 &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;word_dict[w] &lt;span&gt;=&lt;/span&gt; i&lt;span&gt;# define the data sources for the model.# We need to use different process for training and prediction.# For training, the input data includes both word IDs and labels.# For prediction, the input data only includs word Ids.&lt;/span&gt;define_py_data_sources2(train_list&lt;span&gt;=&lt;/span&gt;&lt;span&gt;'data/train.list'&lt;/span&gt;,
 &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;test_list&lt;span&gt;=&lt;/span&gt;&lt;span&gt;'data/test.list'&lt;/span&gt;,
 &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;module&lt;span&gt;=&lt;/span&gt;&lt;span&gt;"dataprovider_bow"&lt;/span&gt;,
 &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;obj&lt;span&gt;=&lt;/span&gt;&lt;span&gt;"process"&lt;/span&gt;,
 &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;args&lt;span&gt;=&lt;/span&gt;{&lt;span&gt;"dictionary"&lt;/span&gt;: word_dict})&lt;/span&gt;&lt;/pre&gt;&lt;ul class="simple list-paddingleft-2"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;data/train.list,data/test.list: 指定训练、测试数据&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;module=”dataprovider”: 数据处理Python文件名&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;obj=”process”: 指定生成数据的函数&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;args={“dictionary”: word_dict}: 额外的参数，这里指定词典&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;更详细用例请参考文档&lt;/span&gt;&lt;span&gt;Python Use Case&lt;/span&gt;&lt;span&gt;， 数据格式和详细文档请参考&lt;/span&gt;&lt;span&gt;&amp;nbsp;PyDataProviderWrapper&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;h2 style="font-family: &amp;#39;Trebuchet MS&amp;#39;, sans-serif; color: rgb(32, 67, 92); border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(204, 204, 204); margin: 20px -20px 10px; padding-top: 3px; padding-bottom: 3px; padding-left: 10px; font-size: 25.6px; background-color: rgb(242, 242, 242);"&gt;&lt;span&gt;网络结构(Network Architecture)&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;本节我们将专注于网络结构的介绍。&lt;/span&gt;&lt;/p&gt;&lt;center&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/UicQ7HgWiaUb0gUkf57uOplb0gTvc0sxLpNlzqlZ9L6xQqvwZVyMawxK9xXL5qjqxeOiaRvZThk6CbmJkf7ib9hknQ/0?wx_fmt=jpeg"/&gt;&lt;/center&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们将以基本的逻辑回归网络作为起点，并逐渐展示更加深入的功能。更详细的网络配置 连接请参考&lt;/span&gt;&lt;span&gt;Layer文档&lt;/span&gt;&lt;span&gt;。 所有配置在&lt;/span&gt;&lt;code class="docutils literal" style="padding-right: 1px; padding-left: 1px; font-size: 0.95em; background-color: rgb(236, 240, 243);"&gt;&lt;span&gt;demo/quick_start&lt;/span&gt;&lt;/code&gt;&lt;span&gt;目录，首先列举逻辑回归网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;h3 style="font-family: &amp;#39;Trebuchet MS&amp;#39;, sans-serif; color: rgb(32, 67, 92); border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(204, 204, 204); margin: 20px -20px 10px; padding-top: 3px; padding-bottom: 3px; padding-left: 10px; font-size: 22.4px; background-color: rgb(242, 242, 242);"&gt;&lt;span&gt;逻辑回归模型(Logistic Regression)&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;流程如下：&lt;/span&gt;&lt;/p&gt;&lt;center&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/UicQ7HgWiaUb0gUkf57uOplb0gTvc0sxLpVBMlc20RQiafY9AVGK5pPTN6kgia345ic8lAO3gwToe5GAgAydWYuffDg/0?wx_fmt=jpeg"/&gt;&lt;/center&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class="simple list-paddingleft-2"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;获取利用one-hot vector表示的每个单词，维度是词典大小&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;word &lt;span&gt;=&lt;/span&gt; data_layer(name&lt;span&gt;=&lt;/span&gt;&lt;span&gt;"word"&lt;/span&gt;, &amp;nbsp;size&lt;span&gt;=&lt;/span&gt;word_dim)&lt;/span&gt;&lt;/pre&gt;&lt;ul class="simple list-paddingleft-2"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;获取该条样本类别Id，维度是类别个数。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;label &lt;span&gt;=&lt;/span&gt; data_layer(name&lt;span&gt;=&lt;/span&gt;&lt;span&gt;"label"&lt;/span&gt;, size&lt;span&gt;=&lt;/span&gt;label_dim)&lt;/span&gt;&lt;/pre&gt;&lt;ul class="simple list-paddingleft-2"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;利用逻辑回归模型对该向量进行分类，同时会计算分类准确率&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;# Define a fully connected layer with logistic activation (also called softmax activation).&lt;/span&gt;output &lt;span&gt;=&lt;/span&gt; fc_layer(&lt;span&gt;input&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;word,
 &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;size&lt;span&gt;=&lt;/span&gt;label_dim,
 &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;act_type&lt;span&gt;=&lt;/span&gt;SoftmaxActivation())&lt;span&gt;# Define cross-entropy classification loss and error.&lt;/span&gt;classification_cost(&lt;span&gt;input&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;output, label&lt;span&gt;=&lt;/span&gt;label)&lt;/span&gt;&lt;/pre&gt;&lt;ul class="simple list-paddingleft-2"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;input: 除过data层，每个层都有一个或多个input,多个input以list方式输入&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;size: 该层神经元个数&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;act_type: 激活函数类型&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;效果总结：我们将在后面介绍训练和预测的流程的脚本。在此为方便对比不同网络结构， 我们随时总结了各个网络的复杂度和效果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;center&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;table cellspacing="0" cellpadding="6" rules="all" frame="border"&gt;&lt;thead&gt;&lt;tr&gt;&lt;th scope="col" class="left" style="padding-right: 5px; background-color: rgb(238, 221, 238);"&gt;&lt;span&gt;网络名称&lt;/span&gt;&lt;/th&gt;&lt;th scope="col" class="left" style="padding-right: 5px; background-color: rgb(238, 221, 238);"&gt;&lt;span&gt;参数数量&lt;/span&gt;&lt;/th&gt;&lt;th scope="col" class="left" style="padding-right: 5px; background-color: rgb(238, 221, 238);"&gt;&lt;span&gt;错误率&lt;/span&gt;&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="left"&gt;&lt;span&gt;逻辑回归&lt;/span&gt;&lt;/td&gt;&lt;td class="left"&gt;&lt;span&gt;252 KB&lt;/span&gt;&lt;/td&gt;&lt;td class="left"&gt;&lt;span&gt;8.652%&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/center&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;h3 style="font-family: &amp;#39;Trebuchet MS&amp;#39;, sans-serif; color: rgb(32, 67, 92); border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(204, 204, 204); margin: 20px -20px 10px; padding-top: 3px; padding-bottom: 3px; padding-left: 10px; font-size: 22.4px; background-color: rgb(242, 242, 242);"&gt;&lt;span&gt;词向量模型(Word Vector)&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;embeding模型需要稍微改变数据提供的脚本，即&lt;/span&gt;&lt;code class="docutils literal" style="padding-right: 1px; padding-left: 1px; font-size: 0.95em; background-color: rgb(236, 240, 243);"&gt;&lt;span&gt;dataprovider_emb.py&lt;/span&gt;&lt;/code&gt;&lt;span&gt;，词向量模型、 卷积模型、时序模型均使用该脚&lt;/span&gt;&lt;/p&gt;&lt;ul class="simple list-paddingleft-2"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;文本输入类型定义为整数类型integer_value&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;设置文本输入类型seq_type为SequenceType.SEQUENCE&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;def&lt;/span&gt; &lt;span&gt;initializer&lt;/span&gt;(settings, dictionary, &lt;span&gt;**&lt;/span&gt;kwargs):
 &amp;nbsp; &amp;nbsp;settings&lt;span&gt;.&lt;/span&gt;word_dict &lt;span&gt;=&lt;/span&gt; dictionary
 &amp;nbsp; &amp;nbsp;settings&lt;span&gt;.&lt;/span&gt;input_types &lt;span&gt;=&lt;/span&gt; [ &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;span&gt;# Define the type of the first input as sequence of integer.&lt;/span&gt;
 &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;integer_value(&lt;span&gt;len&lt;/span&gt;(dictionary), seq_type&lt;span&gt;=&lt;/span&gt;SequenceType&lt;span&gt;.&lt;/span&gt;SEQUENCE), &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;span&gt;# Define the second input for label id&lt;/span&gt;
 &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;integer_value(&lt;span&gt;2&lt;/span&gt;)]&lt;span&gt;@provider&lt;/span&gt;(init_hook&lt;span&gt;=&lt;/span&gt;initializer)&lt;span&gt;def&lt;/span&gt; &lt;span&gt;process&lt;/span&gt;(settings, file_name): &amp;nbsp; &amp;nbsp;&lt;span&gt;...&lt;/span&gt;
 &amp;nbsp; &amp;nbsp;&lt;span&gt;# omitted, it is same as the data provider for LR model&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;该模型依然是使用逻辑回归分类网络的框架， 只是将句子利用连续向量表示替换稀疏 向量表示， 即对第3步进行替换。句子表示的计算更新为2步：&lt;/span&gt;&lt;/p&gt;&lt;center&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/UicQ7HgWiaUb0gUkf57uOplb0gTvc0sxLpOsAiadyAuFzGcBs7Ps1kOTGpSFDsOa1cRLYCe2michUVRrfhPibsNdaXA/0?wx_fmt=jpeg"/&gt;&lt;/center&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class="simple list-paddingleft-2"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;利用单词Id查找对应的该单词的连续表示向量(维度为word_dim)， 输入N个单词，输出为N个word_dim维度向量&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;emb &lt;span&gt;=&lt;/span&gt; embedding_layer(&lt;span&gt;input&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;word, size&lt;span&gt;=&lt;/span&gt;word_dim)&lt;/span&gt;&lt;/pre&gt;&lt;ul class="simple list-paddingleft-2"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;将该句话包含的所有单词向量求平均得到句子的表示&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;avg &lt;span&gt;=&lt;/span&gt; pooling_layer(&lt;span&gt;input&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;emb, pooling_type&lt;span&gt;=&lt;/span&gt;AvgPooling())&lt;/span&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;其它部分和逻辑回归网络结构一致。 效果总结：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;center&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;table cellspacing="0" cellpadding="6" rules="all" frame="border"&gt;&lt;thead&gt;&lt;tr&gt;&lt;th scope="col" class="left" style="padding-right: 5px; background-color: rgb(238, 221, 238);"&gt;&lt;span&gt;网络名称&lt;/span&gt;&lt;/th&gt;&lt;th scope="col" class="left" style="padding-right: 5px; background-color: rgb(238, 221, 238);"&gt;&lt;span&gt;参数数量&lt;/span&gt;&lt;/th&gt;&lt;th scope="col" class="left" style="padding-right: 5px; background-color: rgb(238, 221, 238);"&gt;&lt;span&gt;错误率&lt;/span&gt;&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="left"&gt;&lt;span&gt;词向量模型&lt;/span&gt;&lt;/td&gt;&lt;td class="left"&gt;&lt;span&gt;15 MB&lt;/span&gt;&lt;/td&gt;&lt;td class="left"&gt;&lt;span&gt;8.484%&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/center&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;h3 style="font-family: &amp;#39;Trebuchet MS&amp;#39;, sans-serif; color: rgb(32, 67, 92); border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(204, 204, 204); margin: 20px -20px 10px; padding-top: 3px; padding-bottom: 3px; padding-left: 10px; font-size: 22.4px; background-color: rgb(242, 242, 242);"&gt;&lt;span&gt;卷积模型(Convolution)&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;卷积网络是一种特殊的从词向量表示到句子表示的方法， 也就是将词向量模型额步 骤3-2进行进一步演化， 变为3个新的子步骤。&lt;/span&gt;&lt;/p&gt;&lt;center&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/UicQ7HgWiaUb0gUkf57uOplb0gTvc0sxLpX88TZiabq8rAoJHD5SqBD6jHavqEmiaKzI00BvibzuvERsic1DJhicr163g/0?wx_fmt=jpeg"/&gt;&lt;/center&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;文本卷积分为三个步骤：&lt;/span&gt;&lt;/p&gt;&lt;ol class="simple list-paddingleft-2"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;获取每个单词左右各k个近邻， 拼接成一个新的向量表示；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;对该表示进行非线性变换 （例如Sigmoid变换）, 成为维度为hidden_dim的新的向量；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;在每个维度上取出在该句话新的向量集合上该维度的最大值作为最后的句子表示向量。 这3个子步骤可配置为:&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;span&gt;text_conv &lt;span&gt;=&lt;/span&gt; sequence_conv_pool(&lt;span&gt;input&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;emb,
 &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; context_start&lt;span&gt;=&lt;/span&gt;k,
 &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; context_len&lt;span&gt;=&lt;/span&gt;&lt;span&gt;2&lt;/span&gt; &lt;span&gt;*&lt;/span&gt; k &lt;span&gt;+&lt;/span&gt; &lt;span&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;效果总结：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;center&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;table cellspacing="0" cellpadding="6" rules="all" frame="border"&gt;&lt;thead&gt;&lt;tr&gt;&lt;th scope="col" class="left" style="padding-right: 5px; background-color: rgb(238, 221, 238);"&gt;&lt;span&gt;网络名称&lt;/span&gt;&lt;/th&gt;&lt;th scope="col" class="left" style="padding-right: 5px; background-color: rgb(238, 221, 238);"&gt;&lt;span&gt;参数数量&lt;/span&gt;&lt;/th&gt;&lt;th scope="col" class="left" style="padding-right: 5px; background-color: rgb(238, 221, 238);"&gt;&lt;span&gt;错误率&lt;/span&gt;&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="left"&gt;&lt;span&gt;卷积模型&lt;/span&gt;&lt;/td&gt;&lt;td class="left"&gt;&lt;span&gt;16 MB&lt;/span&gt;&lt;/td&gt;&lt;td class="left"&gt;&lt;span&gt;5.628%&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/center&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;h3 style="font-family: &amp;#39;Trebuchet MS&amp;#39;, sans-serif; color: rgb(32, 67, 92); border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(204, 204, 204); margin: 20px -20px 10px; padding-top: 3px; padding-bottom: 3px; padding-left: 10px; font-size: 22.4px; background-color: rgb(242, 242, 242);"&gt;&lt;span&gt;时序模型(Time Sequence)&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;center&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/UicQ7HgWiaUb0gUkf57uOplb0gTvc0sxLpJbHnK98libMHDdFTSOBDeO5jcia5ESrEwZIHkNHjAHQj65F8Tr4PNphA/0?wx_fmt=jpeg"/&gt;&lt;/center&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;时序模型即为RNN模型, 包括简单的RNN模型、GRU模型、LSTM模型等。&lt;/span&gt;&lt;/p&gt;&lt;ul class="simple list-paddingleft-2"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;GRU模型配置：&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;gru &lt;span&gt;=&lt;/span&gt; simple_gru(&lt;span&gt;input&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;emb, size&lt;span&gt;=&lt;/span&gt;gru_size)&lt;/span&gt;&lt;/pre&gt;&lt;ul class="simple list-paddingleft-2"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;LSTM模型配置：&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;lstm &lt;span&gt;=&lt;/span&gt; simple_lstm(&lt;span&gt;input&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;emb, size&lt;span&gt;=&lt;/span&gt;lstm_size)&lt;/span&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;针对本问题，我们采用单层LSTM模型，并使用了Dropout，效果总结：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;center&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;table cellspacing="0" cellpadding="6" rules="all" frame="border"&gt;&lt;thead&gt;&lt;tr&gt;&lt;th scope="col" class="left" style="padding-right: 5px; background-color: rgb(238, 221, 238);"&gt;&lt;span&gt;网络名称&lt;/span&gt;&lt;/th&gt;&lt;th scope="col" class="left" style="padding-right: 5px; background-color: rgb(238, 221, 238);"&gt;&lt;span&gt;参数数量&lt;/span&gt;&lt;/th&gt;&lt;th scope="col" class="left" style="padding-right: 5px; background-color: rgb(238, 221, 238);"&gt;&lt;span&gt;错误率&lt;/span&gt;&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="left"&gt;&lt;span&gt;时序模型&lt;/span&gt;&lt;/td&gt;&lt;td class="left"&gt;&lt;span&gt;16 MB&lt;/span&gt;&lt;/td&gt;&lt;td class="left"&gt;&lt;span&gt;4.812%&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/center&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;h2 style="font-family: &amp;#39;Trebuchet MS&amp;#39;, sans-serif; color: rgb(32, 67, 92); border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(204, 204, 204); margin: 20px -20px 10px; padding-top: 3px; padding-bottom: 3px; padding-left: 10px; font-size: 25.6px; background-color: rgb(242, 242, 242);"&gt;&lt;span&gt;优化算法(Optimization Algorithm)&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;优化算法&lt;/span&gt;&lt;span&gt;包括 Momentum, RMSProp，AdaDelta，AdaGrad，ADAM，Adamax等，这里采用Adam优化方法，加了L2正则和梯度截断。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;settings(batch_size&lt;span&gt;=&lt;/span&gt;&lt;span&gt;128&lt;/span&gt;,
 &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; learning_rate&lt;span&gt;=&lt;/span&gt;&lt;span&gt;2e-3&lt;/span&gt;,
 &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; learning_method&lt;span&gt;=&lt;/span&gt;AdamOptimizer(),
 &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; regularization&lt;span&gt;=&lt;/span&gt;L2Regularization(&lt;span&gt;8e-4&lt;/span&gt;),
 &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; gradient_clipping_threshold&lt;span&gt;=&lt;/span&gt;&lt;span&gt;25&lt;/span&gt;)&lt;/span&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;h2 style="font-family: &amp;#39;Trebuchet MS&amp;#39;, sans-serif; color: rgb(32, 67, 92); border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(204, 204, 204); margin: 20px -20px 10px; padding-top: 3px; padding-bottom: 3px; padding-left: 10px; font-size: 25.6px; background-color: rgb(242, 242, 242);"&gt;&lt;span&gt;训练模型(Training Model)&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;在完成了数据和网络结构搭建之后， 我们进入到训练部分。&lt;/span&gt;&lt;/p&gt;&lt;center&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/UicQ7HgWiaUb0gUkf57uOplb0gTvc0sxLpUStKohHKSGiaUuVqEFtWyCrVpUYDicGNZRhsLKHFhO2NGXurWZZ79iaYQ/0?wx_fmt=jpeg"/&gt;&lt;/center&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;训练脚本：我们将训练的命令行保存在了&amp;nbsp;&lt;/span&gt;&lt;code class="docutils literal" style="padding-right: 1px; padding-left: 1px; font-size: 0.95em; background-color: rgb(236, 240, 243);"&gt;&lt;span&gt;train.sh&lt;/span&gt;&lt;/code&gt;&lt;span&gt;文件中。训练时所需设置的主要参数如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;paddle train &lt;span&gt;\&lt;/span&gt;--config&lt;span&gt;=&lt;/span&gt;trainer_config.py &lt;span&gt;\&lt;/span&gt;--log_period&lt;span&gt;=&lt;/span&gt;&lt;span&gt;20&lt;/span&gt; &lt;span&gt;\&lt;/span&gt;--save_dir&lt;span&gt;=&lt;/span&gt;./output &lt;span&gt;\&lt;/span&gt;--num_passes&lt;span&gt;=&lt;/span&gt;&lt;span&gt;15&lt;/span&gt; &lt;span&gt;\&lt;/span&gt;--use_gpu&lt;span&gt;=&lt;/span&gt;&lt;span&gt;false&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;这里没有介绍多机分布式训练，可以参考&lt;/span&gt;&lt;span&gt;分布式训练&lt;/span&gt;&lt;span&gt;的demo学习如何进行多机训练。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;h2 style="font-family: &amp;#39;Trebuchet MS&amp;#39;, sans-serif; color: rgb(32, 67, 92); border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(204, 204, 204); margin: 20px -20px 10px; padding-top: 3px; padding-bottom: 3px; padding-left: 10px; font-size: 25.6px; background-color: rgb(242, 242, 242);"&gt;&lt;span&gt;预测(Prediction)&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;可以使用训练好的模型评估带有label的验证集，也可以预测没有label的测试集。&lt;/span&gt;&lt;/p&gt;&lt;center&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/UicQ7HgWiaUb0gUkf57uOplb0gTvc0sxLpxFzAxdC2o3ibEIckoq6r9vBUMUHiaWpouzWw31zGBICe235Io0Y5VGcg/0?wx_fmt=jpeg"/&gt;&lt;/center&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;测试脚本如下，将会测试配置文件中test.list指定的数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;paddle train &lt;span&gt;\&lt;/span&gt;--use_gpu&lt;span&gt;=&lt;/span&gt;&lt;span&gt;false&lt;/span&gt; &lt;span&gt;\&lt;/span&gt;--job&lt;span&gt;=&lt;/span&gt;&lt;span&gt;test&lt;/span&gt; &lt;span&gt;\&lt;/span&gt;--init_model_path&lt;span&gt;=&lt;/span&gt;./output/pass-0000x&lt;/span&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;可以参考&lt;/span&gt;&lt;span&gt;Python API预测&lt;/span&gt;&lt;span&gt;&amp;nbsp;教程，或其他&lt;/span&gt;&lt;span&gt;demo&lt;/span&gt;&lt;span&gt;的Python预测过程。也可以通过如下方式预测。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;预测脚本(&lt;/span&gt;&lt;code class="docutils literal" style="padding-right: 1px; padding-left: 1px; font-size: 0.95em; background-color: rgb(236, 240, 243);"&gt;&lt;span&gt;predict.sh&lt;/span&gt;&lt;/code&gt;&lt;span&gt;)：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;model&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;"output/pass-00003"&lt;/span&gt;paddle train &lt;span&gt;\&lt;/span&gt;
 &amp;nbsp; &amp;nbsp;--config&lt;span&gt;=&lt;/span&gt;trainer_config.lstm.py &lt;span&gt;\&lt;/span&gt;
 &amp;nbsp; &amp;nbsp;--use_gpu&lt;span&gt;=&lt;/span&gt;&lt;span&gt;false&lt;/span&gt; &lt;span&gt;\&lt;/span&gt;
 &amp;nbsp; &amp;nbsp;--job&lt;span&gt;=&lt;/span&gt;&lt;span&gt;test&lt;/span&gt; &lt;span&gt;\&lt;/span&gt;
 &amp;nbsp; &amp;nbsp;--init_model_path&lt;span&gt;=&lt;/span&gt;&lt;span&gt;$model&lt;/span&gt; &lt;span&gt;\&lt;/span&gt;
 &amp;nbsp; &amp;nbsp;--config_args&lt;span&gt;=&lt;/span&gt;&lt;span&gt;is_predict&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;1&lt;/span&gt; &lt;span&gt;\&lt;/span&gt;
 &amp;nbsp; &amp;nbsp;--predict_output_dir&lt;span&gt;=&lt;/span&gt;. &lt;span&gt;\&lt;/span&gt;mv rank-00000 result.txt&lt;/span&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;与训练网络配置不同的是：无需label相关的层，指定outputs输出概率层(softmax输出)， 指定batch_size=1，数据传输无需label数据，预测数据指定test_list的位置。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;is_predict &lt;span&gt;=&lt;/span&gt; get_config_arg(&lt;span&gt;'is_predict'&lt;/span&gt;, &lt;span&gt;bool&lt;/span&gt;, &lt;span&gt;False&lt;/span&gt;)trn &lt;span&gt;=&lt;/span&gt; &lt;span&gt;'data/train.list'&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; &lt;span&gt;not&lt;/span&gt; is_predict &lt;span&gt;else&lt;/span&gt; &lt;span&gt;None&lt;/span&gt;tst &lt;span&gt;=&lt;/span&gt; &lt;span&gt;'data/test.list'&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; &lt;span&gt;not&lt;/span&gt; is_predict &lt;span&gt;else&lt;/span&gt; &lt;span&gt;'data/pred.list'&lt;/span&gt;obj &lt;span&gt;=&lt;/span&gt; &lt;span&gt;'process'&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; &lt;span&gt;not&lt;/span&gt; is_predict &lt;span&gt;else&lt;/span&gt; &lt;span&gt;'process_pre'&lt;/span&gt;batch_size &lt;span&gt;=&lt;/span&gt; &lt;span&gt;128&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; &lt;span&gt;not&lt;/span&gt; is_predict &lt;span&gt;else&lt;/span&gt; &lt;span&gt;1&lt;/span&gt;&lt;span&gt;if&lt;/span&gt; is_predict:
 &amp;nbsp; &amp;nbsp;maxid &lt;span&gt;=&lt;/span&gt; maxid_layer(output)
 &amp;nbsp; &amp;nbsp;outputs([maxid,output])&lt;span&gt;else&lt;/span&gt;:
 &amp;nbsp; &amp;nbsp;label &lt;span&gt;=&lt;/span&gt; data_layer(name&lt;span&gt;=&lt;/span&gt;&lt;span&gt;"label"&lt;/span&gt;, size&lt;span&gt;=&lt;/span&gt;&lt;span&gt;2&lt;/span&gt;)
 &amp;nbsp; &amp;nbsp;cls &lt;span&gt;=&lt;/span&gt; classification_cost(&lt;span&gt;input&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;output, label&lt;span&gt;=&lt;/span&gt;label)
 &amp;nbsp; &amp;nbsp;outputs(cls)&lt;/span&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;h2 style="font-family: &amp;#39;Trebuchet MS&amp;#39;, sans-serif; color: rgb(32, 67, 92); border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(204, 204, 204); margin: 20px -20px 10px; padding-top: 3px; padding-bottom: 3px; padding-left: 10px; font-size: 25.6px; background-color: rgb(242, 242, 242);"&gt;&lt;span&gt;总体效果总结(Summary)&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;这些流程中的数据下载、网络配置、训练脚本在&lt;/span&gt;&lt;code class="docutils literal" style="padding-right: 1px; padding-left: 1px; font-size: 0.95em; background-color: rgb(236, 240, 243);"&gt;&lt;span&gt;/demo/quick_start&lt;/span&gt;&lt;/code&gt;&lt;span&gt;目录，我们在此总 结上述网络结构在Amazon-Elec测试集(25k)上的效果:&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;center&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;table cellspacing="0" cellpadding="6" rules="all" frame="border"&gt;&lt;thead&gt;&lt;tr&gt;&lt;th scope="col" class="left" style="padding-right: 5px; background-color: rgb(238, 221, 238);"&gt;&lt;span&gt;网络名称&lt;/span&gt;&lt;/th&gt;&lt;th scope="col" class="left" style="padding-right: 5px; background-color: rgb(238, 221, 238);"&gt;&lt;span&gt;参数数量&lt;/span&gt;&lt;/th&gt;&lt;th scope="col" class="left" style="padding-right: 5px; background-color: rgb(238, 221, 238);"&gt;&lt;span&gt;错误率&lt;/span&gt;&lt;/th&gt;&lt;th scope="col" class="left" style="padding-right: 5px; background-color: rgb(238, 221, 238);"&gt;&lt;span&gt;配置文件&lt;/span&gt;&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="left"&gt;&lt;span&gt;逻辑回归模型&lt;/span&gt;&lt;/td&gt;&lt;td class="left"&gt;&lt;span&gt;252KB&lt;/span&gt;&lt;/td&gt;&lt;td class="left"&gt;&lt;span&gt;8.652%&lt;/span&gt;&lt;/td&gt;&lt;td class="left"&gt;&lt;span&gt;trainer_config.lr.py&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td class="left"&gt;&lt;span&gt;词向量模型&lt;/span&gt;&lt;/td&gt;&lt;td class="left"&gt;&lt;span&gt;15MB&lt;/span&gt;&lt;/td&gt;&lt;td class="left"&gt;&lt;span&gt;8.484%&lt;/span&gt;&lt;/td&gt;&lt;td class="left"&gt;&lt;span&gt;trainer_config.emb.py&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td class="left"&gt;&lt;span&gt;卷积模型&lt;/span&gt;&lt;/td&gt;&lt;td class="left"&gt;&lt;span&gt;16MB&lt;/span&gt;&lt;/td&gt;&lt;td class="left"&gt;&lt;span&gt;5.628%&lt;/span&gt;&lt;/td&gt;&lt;td class="left"&gt;&lt;span&gt;trainer_config.cnn.py&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td class="left"&gt;&lt;span&gt;时序模型&lt;/span&gt;&lt;/td&gt;&lt;td class="left"&gt;&lt;span&gt;16MB&lt;/span&gt;&lt;/td&gt;&lt;td class="left"&gt;&lt;span&gt;4.812%&lt;/span&gt;&lt;/td&gt;&lt;td class="left"&gt;&lt;span&gt;trainer_config.lstm.py&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/center&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;h2 style="font-family: &amp;#39;Trebuchet MS&amp;#39;, sans-serif; color: rgb(32, 67, 92); border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(204, 204, 204); margin: 20px -20px 10px; padding-top: 3px; padding-bottom: 3px; padding-left: 10px; font-size: 25.6px; background-color: rgb(242, 242, 242);"&gt;&lt;span&gt;附录(Appendix)&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;h3 style="font-family: &amp;#39;Trebuchet MS&amp;#39;, sans-serif; color: rgb(32, 67, 92); border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(204, 204, 204); margin: 20px -20px 10px; padding-top: 3px; padding-bottom: 3px; padding-left: 10px; font-size: 22.4px; background-color: rgb(242, 242, 242);"&gt;&lt;span&gt;命令行参数(Command Line Argument)&lt;/span&gt;&lt;/h3&gt;&lt;ul class="simple list-paddingleft-2"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;–config：网络配置&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;–save_dir：模型存储路径&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;–log_period：每隔多少batch打印一次日志&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;–num_passes：训练轮次，一个pass表示过一遍所有训练样本&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;–config_args：命令指定的参数会传入网络配置中。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;–init_model_path：指定初始化模型路径，可用在测试或训练时指定初始化模型。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;默认一个pass保存一次模型，也可以通过saving_period_by_batches设置每隔多少batch保存一次模型。 可以通过show_parameter_stats_period设置打印参数信息等。 其他参数请参考&lt;/span&gt;&lt;span&gt;令行参数文档&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;h3 style="font-family: &amp;#39;Trebuchet MS&amp;#39;, sans-serif; color: rgb(32, 67, 92); border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(204, 204, 204); margin: 20px -20px 10px; padding-top: 3px; padding-bottom: 3px; padding-left: 10px; font-size: 22.4px; background-color: rgb(242, 242, 242);"&gt;&lt;span&gt;输出日志(Log)&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;TrainerInternal.cpp:160] &amp;nbsp;Batch=20 samples=2560 AvgCost=0.628761 CurrentCost=0.628761 Eval: classification_error_evaluator=0.304297 &amp;nbsp;CurrentEval: classification_error_evaluator=0.304297&lt;/span&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;模型训练会看到这样的日志，详细的参数解释如下面表格：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;center&gt;&lt;table cellspacing="0" cellpadding="6" rules="all" frame="border"&gt;&lt;thead&gt;&lt;tr&gt;&lt;th scope="col" class="left" style="padding-right: 5px; background-color: rgb(238, 221, 238);"&gt;&lt;span&gt;名称&lt;/span&gt;&lt;/th&gt;&lt;th scope="col" class="left" style="padding-right: 5px; background-color: rgb(238, 221, 238);"&gt;&lt;span&gt;解释&lt;/span&gt;&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="left"&gt;&lt;span&gt;Batch=20&lt;/span&gt;&lt;/td&gt;&lt;td class="left"&gt;&lt;span&gt;表示过了20个batch&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td class="left"&gt;&lt;span&gt;samples=2560&lt;/span&gt;&lt;/td&gt;&lt;td class="left"&gt;&lt;span&gt;表示过了2560个样本&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td class="left"&gt;&lt;span&gt;AvgCost&lt;/span&gt;&lt;/td&gt;&lt;td class="left"&gt;&lt;span&gt;每个pass的第0个batch到当前batch所有样本的平均cost&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td class="left"&gt;&lt;span&gt;CurrentCost&lt;/span&gt;&lt;/td&gt;&lt;td class="left"&gt;&lt;span&gt;当前log_period个batch所有样本的平均cost&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td class="left"&gt;&lt;span&gt;Eval: classification_error_evaluator&lt;/span&gt;&lt;/td&gt;&lt;td class="left"&gt;&lt;span&gt;每个pass的第0个batch到当前batch所有样本的平均分类错误率&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td class="left"&gt;&lt;span&gt;CurrentEval: classification_error_evaluator&lt;/span&gt;&lt;/td&gt;&lt;td class="left"&gt;&lt;span&gt;当前log_period个batch所有样本的平均分类错误率&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/center&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;【号外】&lt;/strong&gt;&lt;span&gt;&lt;span&gt;由中国自动化学会和新智元联合主办&lt;/span&gt;的AI全球年度盛典『AI WORLD 2016世界人工智能大会』即将盛大开幕。&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;大会官网：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;http://aiworld2016.com/&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/UicQ7HgWiaUb0gUkf57uOplb0gTvc0sxLpcTSEsSKkmOJkAhuLVscXwxurjkbWPfrkf4BJ9ZD78tuZ4JOtzicLhwg/0?wx_fmt=jpeg"/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/UicQ7HgWiaUb0gUkf57uOplb0gTvc0sxLpeVWZZWngGK2g5bSsxYT0sugwHrgKlcPcyFSo325Q9P49Ncdw1mLexA/0?wx_fmt=jpeg"/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/UicQ7HgWiaUb0gUkf57uOplb0gTvc0sxLpYzJJNVzhnU2nx2YrSQvuzD1v880lrUQG2RQlDdDmmkCRrpAkjFqveQ/0?wx_fmt=jpeg"/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/UicQ7HgWiaUb0gUkf57uOplb0gTvc0sxLp3J7ZnZU1Y9cYUd7QTqeqS6qibibJYQJReut6PYtg7mXGGIfTlvG2MRXg/0?wx_fmt=jpeg"/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/UicQ7HgWiaUb0gUkf57uOplb0gTvc0sxLpziaDJBZiaaAOBefvBxucWgXqR9R595kurNwlnayCEjKmZVVmeJDClRag/0?wx_fmt=jpeg"/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/UicQ7HgWiaUb0gUkf57uOplb0gTvc0sxLpjCM7f8Nv2mibDCUtRkZicXEa4lHMvXSY7QkibI4yAicAa8iabsDf0yzKbWg/0?wx_fmt=jpeg"/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;更多详情，点击“阅读原文”，查看大会官网&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 31 Aug 2016 13:14:08 +0800</pubDate>
    </item>
    <item>
      <title>谷歌开源图像分类工具TF-Slim，定义TensorFlow复杂模型</title>
      <link>http://www.iwgc.cn/link/2498768</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;1 &lt;/span&gt;新智元编译&lt;/span&gt;&lt;span&gt;1&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&amp;nbsp;来源：Google Research&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：&lt;strong&gt;Nathan Silberman &amp;amp; Sergio Guadarrama，谷歌研究员&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;译者&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;：闻菲&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;【新智元导读】&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;谷歌今天宣布开源 TensorFlow 高级软件包 TF-Slim，&lt;span&gt;能使用户快速准确地定义复杂模型，尤其是图像分类任务。这不由让人想起&lt;/span&gt; Facebook 上周开源“从像素级别理解图像”的计算机视觉系统。不管怎么说，在计算机视觉方面，强大的工具又多了。下文是官方博文翻译&lt;/span&gt;。&lt;span&gt;&lt;strong&gt;在新智元后台回复“0831”下载论文。&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz/UicQ7HgWiaUb1GNdLuPNMK8Mz5ukxeTwWExDbnS6Hr1JicPgZ9AlGJiagK9n98c23sHos09uyGV9zPDRROhA5hHbLg/0?wx_fmt=gif"/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今年早些时候，我们发布了图像分类模型 Inception V3 在 TensorFlow 上的运行案例。代码能够让用户使用同步梯度下降用 ImageNet 分类数据库训练模型。Inception V3 模型的基础是一个叫做 TF-Slim 的 TensorFlow 库，用户可以使用这个软件包定义、训练、评估 TensorFlow 模型。TF-Slim 库提供的常用抽象能使用户快速准确地定义模型，同时确保模型架构透明，超参数明确。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;自发布以来，TF-Slim 已经得到长足发展，无论是网络层、代价函数，还是评估标准，都增加了很多类型，训练和评估模型也有了很多便利的常规操作手段。这些手段使你在并行读取数据或者在多台机器上部署模型等大规模运行时，不必为细节操心。此外，我们还制作了 TF-Slim 图像模型库，为很多广泛使用的图像分类模型提供了定义以及训练脚本，这些都是使用标准的数据库写就的。TF-Slim 及其组成部分都已经在谷歌内部得到广泛的使用，很多升级也都整合进了 tf.contrib.slim.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今天，我们将 TF-Slim 的最新版本与 TF 社区共享，&lt;/span&gt;&lt;strong&gt;亮点包括：&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: square;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;很多新的层（比如 Atrous 卷积层和 Deconvolution），使神经网络架构更丰富；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;支持更多的代价函数和评估指标（如 mAP，IoU）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;部署运行库，让在一台或多台机器上进行同步或异步训练更容易&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;代码，用于定义和训练广泛使用的图像分类模型，比如 Inception、VGG、AlexNet、ResNet&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;训练好的模型，这些模型使用 ImageNet 分类数据库训练，但也能用于其他计算机视觉任务&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;ImageNet、CIFAR10 和 MNIST 这些容易使用的标准图像数据库&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;使用 TF-Slim 的 GitHbu 代码：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;README：https://github.com/tensorflow/models/blob/master/slim/README.md&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;使用说明：https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/slim&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;贡献突出的研究员：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: circle;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;TF-Slim：Sergio Guadarrama, Nathan Silberman.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;模型定义和检查：Christian Szegedy, Sergey Ioffe, Vincent Vanhoucke, Jon Shlens, Zbigniew Wojna, Vivek Rathod, George Papandreou, Alex Alemi&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;系统基础设施：Jon Shlens, Matthieu Devin, Martin Wicke&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Jupyter 说明：Nathan Silberman, Kevin Murphy&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;参考文献：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="list-style-type: decimal;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Going deeper with convolutions&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;, Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, Andrew Rabinovich, CVPR 2015&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift &lt;/span&gt;&lt;/strong&gt;&lt;span&gt;Sergey Ioffe, Christian Szegedy, ICML 2015&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Rethinking the Inception Architecture for Computer Vision&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;, Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens, Zbigniew Wojna, arXiv technical report 2015&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Very Deep Convolutional Networks for Large-Scale Image Recognition&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;, Karen Simonyan, Andrew Zisserman, ICLR 2015&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;ImageNet Classification with Deep Convolutional Neural Networks&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;, Alex Krizhevsky, Ilya Sutskever, Geoffrey E. Hinton, NIPS 2012&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Deep Residual Learning for Image Recognition&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;, Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun, CVPR 2016&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;在新智元后台回复“0831”下载论文&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;【号外】&lt;/strong&gt;&lt;span&gt;&lt;span&gt;由中国自动化学会和新智元联合主办&lt;/span&gt;的AI全球年度盛典『AI WORLD 2016世界人工智能大会』即将盛大开幕。&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;大会官网：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;http://aiworld2016.com/&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/UicQ7HgWiaUb0gUkf57uOplb0gTvc0sxLpcTSEsSKkmOJkAhuLVscXwxurjkbWPfrkf4BJ9ZD78tuZ4JOtzicLhwg/0?wx_fmt=jpeg"/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/UicQ7HgWiaUb0gUkf57uOplb0gTvc0sxLpeVWZZWngGK2g5bSsxYT0sugwHrgKlcPcyFSo325Q9P49Ncdw1mLexA/0?wx_fmt=jpeg"/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/UicQ7HgWiaUb0gUkf57uOplb0gTvc0sxLpYzJJNVzhnU2nx2YrSQvuzD1v880lrUQG2RQlDdDmmkCRrpAkjFqveQ/0?wx_fmt=jpeg"/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/UicQ7HgWiaUb0gUkf57uOplb0gTvc0sxLp3J7ZnZU1Y9cYUd7QTqeqS6qibibJYQJReut6PYtg7mXGGIfTlvG2MRXg/0?wx_fmt=jpeg"/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/UicQ7HgWiaUb0gUkf57uOplb0gTvc0sxLpziaDJBZiaaAOBefvBxucWgXqR9R595kurNwlnayCEjKmZVVmeJDClRag/0?wx_fmt=jpeg"/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/UicQ7HgWiaUb0gUkf57uOplb0gTvc0sxLpjCM7f8Nv2mibDCUtRkZicXEa4lHMvXSY7QkibI4yAicAa8iabsDf0yzKbWg/0?wx_fmt=jpeg"/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;更多详情，点击“阅读原文”，查看大会官网&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 31 Aug 2016 13:14:08 +0800</pubDate>
    </item>
    <item>
      <title>另一种开源：OpenAI 介绍深度学习基础设施</title>
      <link>http://www.iwgc.cn/link/2498769</link>
      <description>&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;1&lt;/span&gt;新智元编译&lt;/span&gt;&lt;span&gt;1&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&amp;nbsp;来源：OpenAI&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;Vicki Cheung、Jonas Schneider、Ilya Sutskever 和 Greg Brockman&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;译者&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;：闻菲、胡祥杰&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;【新智元导读】&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;OpenAI 昨天在博客发文，&lt;span&gt;结合实例，&lt;/span&gt;介绍了 OpenAI 进行深度学习研究时采用的基础设施配置，并且提供了相关开源代码。&lt;span&gt;&lt;span&gt;文章激起了很多反响&lt;/span&gt;，其中&lt;/span&gt;也有负面评论，比如有用户在 Hacker News 指出，OpenAI 博文只提供了“训练”部分的细节，称不“深度学习基础设施”。&lt;span&gt;不过，相对于软硬件开源，OpenAI 从另一个侧面，对深度学习模型的实际部署提供了帮助。下文是对 OpenAI 官方博文的编译。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz/UicQ7HgWiaUb1GNdLuPNMK8Mz5ukxeTwWExDbnS6Hr1JicPgZ9AlGJiagK9n98c23sHos09uyGV9zPDRROhA5hHbLg/0?wx_fmt=gif"/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;深度学习是一门实践科学，而拥有好的基础设施对项目进展有着事半功倍的效果。所幸，如今的开源生态系统，让每个人都能够搭建很好的深度学习基础设施。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这篇文章里，我们将分享深度学习研究进展，描述我们选择使用的基础设施，并且开源一个 Kubernetes 批处理优化缩放管理器（Scaling Manager），希望对你进行深度学习有用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;实例：Improved Techniques for Training GANs&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;使用情况&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;深度学习项目一般从想法开始，先在小问题上测试。这个阶段，你希望快速运行实验，理想情况下，最好在屏幕上跑代码，不出一个小时就能得到结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;要让模型真的跑起来，必须要在可以预想的每一步都想好，并且针对局限制定预防措施。（这就跟搭建软件系统一样，必须跑很多次代码才能了解软件如何运作。）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你必须从每个角度审视你的模型，从而了解模型实际上学到了什么。例如 Dario Amodei 这个游戏里的强化学习代理（负责控制右边的平板），它取得了高分，但仔细观察发现，它其实只是停在一处而已（详见 https://openai.com/blog/infrastructure-for-deep-learning/?ref=mybridge.co）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因此，深度学习基础设施必须使用户灵活反思模型，只是得到摘要统计数据是不够的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一旦模型显示出足够的潜力，你就应该把它放大到更大型的数据库和更多GPU上运行。这个有时候需要花上好几天的时间。你需要仔细进行试验管理，对选择的超参数范围尤其经心才行。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;研究早期阶段是没有规律的，时间过得很快；而后期则是一丝不苟，某种程度上说有些艰苦，但这些都是取得理想结果必须付出的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;基础设施&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;软件&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/UicQ7HgWiaUb0gUkf57uOplb0gTvc0sxLpfmCy6uD4C8ArxGl5VOxu4NuUicbLhCqmZC4JzKb52IicSibCMibbLQibuDA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们研究中的绝大部分代码都是用Python写成，这在我们的开源项目中已经有所体现。我们的GPU计算大部分使用的是TensorFlow，在特定的例子中，会使用Theano。CPU的计算，除了使用以上提到的，我们还使用Numpy。研究者有时候也会使用高水平的框架，比如Keras。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;和大多数深度学习社区一样，我们使用Python2.7。我们通常会使用Anaconda，它在打包上较为方便，特别是针对一些难以打包的工具，比如针对科学数据库的OpenCV和Performance Optimizations。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;硬件&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于一个理想的批量作业，集群中的节点数量增加1倍，可以把工作时间减半。不巧的是，在深度学习中，人们经常看到，虽然GPU增多，但是增速却没有多大提升。所以，顶尖的性能要求有最顶级的GPU。我们还使用一个大量的CPU，用于模拟器和增强学习环境，或者小型的模型中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/UicQ7HgWiaUb0gUkf57uOplb0gTvc0sxLpBTaxVv0gYFSdvXZVAS7oV6rQmlb1Z931SAxsbeSklYk7sWLxANYTHw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;AWS 非常慷慨，同意送给我们大量的计算。我们正在CPU的例子和水平扩展的GPU中使用它们。我们也在运营自己的实体服务器，主要跑TitanX GPU，我们希望能有一个混合的云，可以长期使用：用不同的GPU、互联和其他技术进行试验，这对深度学习的未来是很重要的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/UicQ7HgWiaUb0gUkf57uOplb0gTvc0sxLpTKk8Cn5AXjicVReLr66v7gdIBtfoa08Wl681L10tsj2mQibxquEyRLgg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;条款&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们对待基础设施就像许多公司对待产品一样：它必须代表一个简单的交互，并且，可用性是一个重要的 功能。我们使用一系列连续的工具来管理我们所有的服务器，尽可能同等地安装它们。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/UicQ7HgWiaUb0gUkf57uOplb0gTvc0sxLpKx6yeqgKaOiaDiaAhPf6ME0DeibclglFliaAIh9sdXP7HNnptnYOrbiccOw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们使用Terraform来设置自己的AWS云资源（比如，网络路线，DNS记录等等）。我们的云和实体节点运行Ubuntu，和Chef一起安装。为了获得更快的注册速度，我们使用Packer来预先bake集群AMI。我们所有的集群使用的都是非重叠的IP，这些集群在公共互联网上，使用我们研究员笔记本的OpenVPN实现互联，在实体节点上使用的则是StrongSwan。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们会存贮人们的主目录、数据集以及NFS、EFS/S3上的结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;编配（Orchestration）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;可扩展的基础设施通常最后都会让简单的事情变得更困难。我们在小型和大型任务中的基础设施上都付出了相同的努力，我们也在积极地巩固自己的工具包，让分布式的使用案例与局部性的一样可获取。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们提供了一系列SSH节点（有的包括GPU,有的没有），可用于专用的实验和运行Kubernetes，这是我们针对实体和AWS节点的集群计划。我们的集群跨越了3个AWS区域——我们的工作充满了突发性，所以有时候，我们会在扩展个人区域的能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Kubernetes 要求每一个任务狗咬变成一个 Docker容器，使得我们可以获得独立的位置和代码快照。但是，建立一个新的Docker 容器，会在研究者的循环周期中增加额外的时间，所以我们提供了一个工具，来透明地把代码从研究者的笔记本电脑转移到标准图像中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/UicQ7HgWiaUb0gUkf57uOplb0gTvc0sxLpcGIotK0BIn3xPuU7VGp0LFmZXicqUdrCYRWzG5vXWgB6tlt9VNFGLqQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们直接向研究者的笔记本公开了Kubernetes的flannel网络，让用户可以通过网络无缝地进入自己正在运行的工作。这对进入监测服务器，比如TensorBoard特别有用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;kubernetes-ec2-autoscaler&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/UicQ7HgWiaUb0gUkf57uOplb0gTvc0sxLpUKJbAJ9yt69oIxvmXvcwSTdjLszNDibCAkL7nRqpzIljWoMhpOOATSQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;代码：&lt;span&gt;https://github.com/openai/kubernetes-ec2-autoscaler&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;编译来源：Infrastructure for Deep Learning&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;【号外】&lt;/strong&gt;&lt;span&gt;&lt;span&gt;由中国自动化学会和新智元联合主办&lt;/span&gt;的AI全球年度盛典『AI WORLD 2016世界人工智能大会』即将盛大开幕。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/UicQ7HgWiaUb0gUkf57uOplb0gTvc0sxLpcTSEsSKkmOJkAhuLVscXwxurjkbWPfrkf4BJ9ZD78tuZ4JOtzicLhwg/0?wx_fmt=jpeg"/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/UicQ7HgWiaUb0gUkf57uOplb0gTvc0sxLpeVWZZWngGK2g5bSsxYT0sugwHrgKlcPcyFSo325Q9P49Ncdw1mLexA/0?wx_fmt=jpeg"/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/UicQ7HgWiaUb0gUkf57uOplb0gTvc0sxLpYzJJNVzhnU2nx2YrSQvuzD1v880lrUQG2RQlDdDmmkCRrpAkjFqveQ/0?wx_fmt=jpeg"/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/UicQ7HgWiaUb0gUkf57uOplb0gTvc0sxLp3J7ZnZU1Y9cYUd7QTqeqS6qibibJYQJReut6PYtg7mXGGIfTlvG2MRXg/0?wx_fmt=jpeg"/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/UicQ7HgWiaUb0gUkf57uOplb0gTvc0sxLpziaDJBZiaaAOBefvBxucWgXqR9R595kurNwlnayCEjKmZVVmeJDClRag/0?wx_fmt=jpeg"/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/UicQ7HgWiaUb0gUkf57uOplb0gTvc0sxLpjCM7f8Nv2mibDCUtRkZicXEa4lHMvXSY7QkibI4yAicAa8iabsDf0yzKbWg/0?wx_fmt=jpeg"/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;更多详情，点击“阅读原文”，查看大会官网&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 31 Aug 2016 13:14:08 +0800</pubDate>
    </item>
    <item>
      <title>【重磅】计算机视觉和CNN 发展十一座里程碑（附论文下载）</title>
      <link>http://www.iwgc.cn/link/2493919</link>
      <description>&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;1&lt;/span&gt;新智元编译&lt;/span&gt;&lt;span&gt;1&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&amp;nbsp;来源：adeshpande3.github.io&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Adit Deshpande，UCLA CS研究生&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;译者&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;：闻菲、胡祥杰&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;【新智元导读】&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;从AlexNet到ResNet，计算机视觉领域和&lt;span&gt;卷积神经网络（&lt;/span&gt;CNN）每一次发展，都伴随着代表性架构&lt;span&gt;取得历史性的成绩&lt;/span&gt;&lt;/span&gt;。作者回顾&lt;span&gt;计算机视觉和CNN&lt;span&gt;过去5年&lt;/span&gt;&lt;/span&gt;，总结了他认为不可错过的标志模型。&lt;span&gt;&lt;strong&gt;在新智元后台回复“0830”下载论文。&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz/UicQ7HgWiaUb1GNdLuPNMK8Mz5ukxeTwWExDbnS6Hr1JicPgZ9AlGJiagK9n98c23sHos09uyGV9zPDRROhA5hHbLg/0?wx_fmt=gif"/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这篇文章中，我们将总结计算机视觉和卷积神经网络领域的重要进展，重点介绍过去5年发表的重要论文并讨论它们为什么重要。从 AlexNet 到 ResNet 主要讲基本网络架构的发展，余下则是各领域的重要文章，包括对抗生成网络、生成图像描述模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本文结构如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: circle;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;AlexNet（2012年）&lt;/span&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;ZF Net（2013年）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;VGG Net（2014年）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;GoogLeNet &lt;span&gt;（2015年）&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;微软 ResNet &lt;span&gt;（2015年）&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;区域 CNN（R-CNN - 2013年，Fast R-CNN - 2015年，Faster R-CNN - 2015年）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;生成对抗网络&lt;span&gt;（2014年）&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;生成图像描述&lt;span&gt;（2014年）&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;空间转化器网络（2015年）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;AlexNet（2012年）&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一切都从这里开始（尽管有些人会说是Yann LeCun 1998年发表的那篇论文才真正开启了一个时代）。这篇论文，题目叫做“ImageNet Classification with Deep Convolutional Networks”，迄今被引用6184次，被业内普遍视为行业最重要的论文之一。Alex Krizhevsky、Ilya Sutskever和 Geoffrey Hinton创造了一个“大型的深度卷积神经网络”，赢得了2012 ILSVRC（2012年ImageNet 大规模视觉识别挑战赛）。稍微介绍一下，这个比赛被誉为计算机视觉的年度奥林匹克竞赛，全世界的团队相聚一堂，看看是哪家的视觉模型表现最为出色。2012年是CNN首次实现Top 5误差率15.4%的一年（Top 5误差率是指给定一张图像，其标签不在模型认为最有可能的5个结果中的几率），当时的次优项误差率为26.2%。这个表现不用说震惊了整个计算机视觉界。可以说，是自那时起，CNN才成了家喻户晓的名字。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;论文中，作者讨论了网络的架构（名为AlexNet）。相比现代架构，他们使用了一种相对简单的布局，整个网络由5层卷积层组成，最大池化层、退出层（dropout layer）和3层全卷积层。网络能够对1000种潜在类别进行分类。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/UicQ7HgWiaUb2LVY4tic7mahGfvNVUT3kqwQ3fLdvXqibYKn2G4JiaTWeX8yRrCL1vOSQibkaHQNQnZV6nQymHRuucTg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;AlexNet 架构：看上去有些奇怪，因为使用了两台GPU训练，因而有两股“流”。使用两台GPU训练的原因是计算量太大，只能拆开来。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;要点&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: square;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;使用ImageNet数据训练网络，ImageNet数据库含有1500多万个带标记的图像，超过2.2万个类别。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;使用ReLU代替传统正切函数引入非线性（ReLU比传统正切函数快几倍，缩短训练时间）。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;使用了图像转化（image translation）、水平反射（horizontal reflection）和补丁提取（patch extraction）这些数据增强技术。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;用dropout层应对训练数据过拟合的问题。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;使用批处理随机梯度下降训练模型，注明动量衰减值和权重衰减值。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;使用两台GTX 580 GPU，训练了5到6天&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;为什么重要？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Krizhevsky、Sutskever 和 Hinton 2012年开发的这个神经网络，是CNN在计算机视觉领域的一大亮相。这是史上第一次有模型在ImageNet 数据库表现这么好，ImageNet 数据库难度是出了名的。论文中提出的方法，比如数据增强和dropout，现在也在使用，这篇论文真正展示了CNN的优点，并且以破纪录的比赛成绩实打实地做支撑。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;ZF Net（2013年）&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2012年AlexNet出尽了风头，ILSVRC 2013就有一大批CNN模型冒了出来。2013年的冠军是纽约大学Matthew Zeiler 和 Rob Fergus设计的网络 ZF Net，错误率 11.2%。ZF Net模型更像是AlexNet架构的微调优化版，但还是提出了有关优化性能的一些关键想法。还有一个原因，这篇论文写得非常好，论文作者花了大量时间阐释有关卷积神经网络的直观概念，展示了将滤波器和权重可视化的正确方法。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这篇题为“Visualizing and Understanding Convolutional Neural Networks”的论文中，Zeiler和Fergus从大数据和GPU计算力让人们重拾对CNN的兴趣讲起，讨论了研究人员对模型内在机制知之甚少，一针见血地指出“发展更好的模型实际上是不断试错的过程”。虽然我们现在要比3年前知道得多一些了，但论文所提出的问题至今仍然存在！这篇论文的主要贡献在于提出了一个比AlexNet稍微好一些的模型并给出了细节，还提供了一些制作可视化特征图值得借鉴的方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/UicQ7HgWiaUb2LVY4tic7mahGfvNVUT3kqwVbF89LNGzcJVeC9bvMjD6fbeFYAXwq3uCR2PnWuib28BXX4MXByAQmw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;要点&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: square;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;除了一些小的修改，整体架构非常类似AlexNet。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;AlexNet训练用了1500万张图片，而ZFNet只用了130万张。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;AlexNet在第一层中使用了大小为11×11的滤波器，而ZF使用的&lt;span&gt;滤波器&lt;/span&gt;大小为7x7，整体处理速度也有所减慢。做此修改的原因是，对于输入数据来说，第一层卷积层有助于保留大量的原始象素信息。11×11的&lt;span&gt;滤波器&lt;/span&gt;漏掉了大量相关信息，特别是因为这是第一层卷积层。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;随着网络增大，使用的&lt;span&gt;滤波器&lt;/span&gt;数量增多。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;利用ReLU的激活函数，将交叉熵代价函数作为误差函数，使用批处理随机梯度下降进行训练。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;使用一台GTX 580 GPU训练了12天。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;开发可视化技术“解卷积网络”（Deconvolutional Network），有助于检查不同的特征激活和其对输入空间关系。名字之所以称为“deconvnet”，是因为它将特征映射到像素（与卷积层恰好相反）。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;DeConvNet&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;DeConvNet工作的基本原理是，每层训练过的CNN后面都连一层“deconvet”，它会提供一条返回图像像素的路径。输入图像进入CNN之后，每一层都计算激活。然而向前传递。现在，假设我们想知道第4层卷积层某个特征的激活值，我们将保存这个特征图的激活值，并将这一层的其他激活值设为0，再将这张特征图作为输入送入deconvnet。Deconvnet与原来的CNN拥有同样的&lt;span&gt;滤波器&lt;/span&gt;。输入经过一系列unpool（maxpooling倒过来），修正，对前一层进行过滤操作，直到输入空间满。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这一过程背后的逻辑在于，我们想要知道是激活某个特征图的是&lt;span&gt;什么结构&lt;/span&gt;。下面来看第一层和第二层的可视化。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/UicQ7HgWiaUb2LVY4tic7mahGfvNVUT3kqwRjaS20h8WPe3o3lpX7rffBibyVtrKk9AG2XylHhwQLGVxSPHxNBcXkw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;ConvNet的第一层永远是低层特征检测器，在这里就是对简单的边缘、颜色进行检测。第二层就有比较圆滑的特征了。再来看第三、第四和第五层。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/UicQ7HgWiaUb2LVY4tic7mahGfvNVUT3kqw3XGsS3YvPO7LoNHbqW1LagUbfeDpe1mQkmgKoV1twN0qcsfPHKeqyA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些层展示出了更多的高级特征，比如狗的脸和鲜花。值得一提的是，在第一层卷积层后面，我们通常会跟一个池化层将图像缩小（比如将 32x32x32 变为16x16x3）。这样做的效果是加宽了第二层看原始图像的视野。更详细的内容可以阅读论文。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;为什么重要？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;ZF Net不仅是2013年比赛的冠军，还对CNN的运作机制提供了极好的直观信息，展示了更多提升性能的方法。论文所描述的可视化方法不仅有助于弄清CNN的内在机理，也为优化网络架构提供了有用的信息。Deconv可视化方法和 occlusion 实验也让这篇论文成了我个人的最爱。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;VGG Net（2015年）&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;简单、有深度，这就是2014年错误率7.3%的模型VGG Net（不是ILSVRC 2014冠军）。牛津大学的Karen Simonyan 和 Andrew Zisserman Main Points创造了一个19层的CNN，严格使用3x3的过滤器（stride =1，pad= 1）和2x2 maxpooling层（stride =2）。简单吧？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/UicQ7HgWiaUb2LVY4tic7mahGfvNVUT3kqwYFcaG3b7vkFtnLuL8licBZx3bKCChQCSCgceLcwVdamicukyJibWW12ug/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;要点&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: square;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;这里使用3x3的滤波器和AlexNet在第一层使用11x11的滤波器和ZF Net 7x7的滤波器作用完全不同。作者认为两个3x3的卷积层组合可以实现5x5的有效感受野。这就在保持滤波器尺寸较小的同时模拟了大型滤波器，减少了参数。此外，有两个卷积层就能够使用两层ReLU。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;3卷积层具有7x7的有效感受野。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;每个maxpool层后滤波器的数量增加一倍。进一步加强了缩小空间尺寸，但保持深度增长的想法。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;图像分类和定位任务都运作良好。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;使用Caffe工具包建模。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;训练中使用scale jittering的数据增强技术。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;每层卷积层后使用ReLU层和批处理梯度下降训练。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;使用4台英伟达Titan Black GPU训练了两到三周。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;为什么重要？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在我看来，VGG Net是最重要的模型之一，因为它再次强调CNN必须够深，视觉数据的层次化表示才有用。深的同时结构简单。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;GoogLeNet（2015年）&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;理解了我们刚才所说的神经网络架构中的简化的概念了吗？通过推出 Inception 模型，谷歌从某种程度上把这一概念抛了出来。GoogLeNet是一个22层的卷积神经网络，在2014年的ILSVRC2014上凭借6.7%的错误率进入Top 5。据我所知，这是第一个真正不使用通用方法的卷积神经网络架构，传统的卷积神经网络的方法是简单堆叠卷积层，然后把各层以序列结构堆积起来。论文的作者也强调，这种新的模型重点考虑了内存和能量消耗。这一点很重要，我自己也会经常忽略：&lt;/span&gt;&lt;span&gt;把所有的层都堆叠、增加大量的&lt;span&gt;滤波器&lt;/span&gt;，在计算和内存上消耗很大，过拟合的风险也会增加。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/UicQ7HgWiaUb2LVY4tic7mahGfvNVUT3kqwZpicrjOy7vFp48oI3RKK28W0cISDnFGVRUM0ZRtO7mDNicA1BW16LaNQ/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;换一种方式看 GoogLeNet：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/UicQ7HgWiaUb2LVY4tic7mahGfvNVUT3kqwBibBIPnUWrjnG6XJb9PzOsvJ9Skemgy8QyP9so7qXwPZJwMLrNtIzNg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Inception 模型&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一次看到GoogLeNet的构造时，我们立刻注意到，并不是所有的事情都是按照顺序进行的，这与此前看到的架构不一样。我们有一些网络，能同时并行发生反应。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/UicQ7HgWiaUb2LVY4tic7mahGfvNVUT3kqwGKoDNal0O6EuibdUtibuc5fpWISmMLGXOdBwo6sDb3QpIpLvNbITZChg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个盒子被称为 Inception 模型。可以近距离地看看它的构成。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/UicQ7HgWiaUb2LVY4tic7mahGfvNVUT3kqwaybdoyCOsQUl4UZChbnLsdvtpa9wpnEfGqDT32mWqJTPg1PVcib08IQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;底部的绿色盒子是我们的输入层，顶部的是输出层（把这张图片向右旋转90度，你会看到跟展示了整个网络的那张图片相对应的模型）。基本上，在一个传统的卷积网络中的每一层中，你必须选择操作池还是卷积操作（还要选择&lt;span&gt;滤波器&lt;/span&gt;的大小）。Inception 模型能让你做到的就是并行地执行所有的操作。事实上，这就是作者构想出来的最“初始”的想法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/UicQ7HgWiaUb2LVY4tic7mahGfvNVUT3kqw8WdIFNOpf02ySo1Ribld4bvlIjItex2KFatvRnziciaRPrn1cFPAQaXxA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在，来看看它为什么起作用。它会导向许多不同的结果，我们会最后会在输出层体积上获得极端大的深度通道。作者处理这个问题的方法是，在3X3和5X5层前，各自增加一个1X1的卷积操作。1X1的卷积（或者网络层中的网络），提供了一个减少维度的方法。比如，我们假设你拥有一个输入层，体积是100x100x60（这并不定是图像的三个维度，只是网络中每一层的输入）。增加20个1X1的卷积&lt;span&gt;滤波器&lt;/span&gt;，会让你把输入的体积减小到100X100X20。这意味着，3X3层和5X5层不需要处理输入层那么大的体积。这可以被认为是“池特征”（pooling of feature），因为我们正在减少体积的高度，这和使用常用的最大池化层（maxpooling layers）减少宽度和长度类似。另一个需要注意的是，这些1X1的卷积层后面跟着的是ReLU 单元，这肯定不会有害。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你也许会问，“这个架构有什么用？”这么说吧，这个模型由一个网络层中的网络、一个中等大小的过滤卷积、一个大型的过滤卷积、一个操作池（pooling operation）组成。网络卷积层中的网络能够提取输入体积中的每一个细节中的信息，同时 5x5 的&lt;span&gt;滤波器&lt;/span&gt;也能够覆盖大部分接受层的的输入，进而能提起其中的信息。你也可以进行一个池操作，以减少空间大小，降低过度拟合。在这些层之上，你在每一个卷积层后都有一个ReLU，这能改进网络的非线性特征。基本上，网络在执行这些基本的功能时，还能同时考虑计算的能力。这篇论文还提供了更高级别的推理，包括的主题有稀疏和紧密联结（见论文第三和第四节）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;要点&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;整个架构中使用了9个Inception 模型，总共超过100层。这已经很深了……没有使用完全连接的层。他们使用一个平均池代替，从 7x7x1024 的体积降到了 1x1x1024，这节省了大量的参数。比AlexNet的参数少了12X在测试中，相同图像的多个剪裁建立，然后填到网络中，计算softmax probabilities的均值，然后我们可以获得最后的解决方案。在感知模型中，使用了R-CNN中的概念。Inception有一些升级的版本（版本6和7），“少数高端的GPU”一周内就能完成训练。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;为什么重要？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;GoogLeNet 是第一个引入了“CNN 各层不需要一直都按顺序堆叠”这一概念的模型。用Inception模型，作者展示了一个具有创造性的层次机构，能带来性能和计算效率的提升。这篇论文确实为接下来几年可能会见到的令人惊叹的架构打下了基础。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;微软 ResNet（2015年）&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;想象一个深度CNN架构，再深、再深、再深，估计都还没有 &lt;span&gt;ILSVRC 2015 冠军，&lt;span&gt;微软的152层ResNet架构深。除了在层数上面创纪录，ResNet 的&lt;/span&gt;错误率也低得惊人，达到了3.6%，人类都大约在5%~10%的水平。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_gif/UicQ7HgWiaUb2LVY4tic7mahGfvNVUT3kqwCx6uxlecFuPdKpfGodrlQicU9Dh1GH87brH3bj1lWloqwQq64048qhQ/0?wx_fmt=gif"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;为什么重要？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;只有3.6％的误差率，这应该足以说服你。ResNet模型是目前最好的CNN架构，而且是残差学习理念的一大创新。从2012年起，错误率逐年下降，我怀疑到ILSVRC2016，是否还会一直下降。我相信，我们现在堆放更多层将不会实现性能的大幅提升。我们必须要创造新的架构。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;区域 CNN：R-CNN（2013年）、Fast R-CNN（2015年）、Faster R-CNN（2015年）&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一些人可能会认为，R-CNN的出现比此前任何关于新的网络架构的论文都有影响力。第一篇关于R-CNN的论文被引用了超过1600次。Ross Girshick 和他在UC Berkeley 的团队在机器视觉上取得了最有影响力的进步。正如他们的文章所写， Fast R-CNN 和 Faster R-CNN能够让模型变得更快，更好地适应现代的物体识别任务。&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;R-CNN的目标是解决物体识别的难题。在获得特定的一张图像后， 我们希望能够绘制图像中所有物体的边缘。这一过程可以分为两个组成部分，一个是区域建议，另一个是分类。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;论文的作者强调，任何分类不可知区域的建议方法都应该适用。Selective Search专用于RCNN。Selective Search 的作用是聚合2000个不同的区域，这些区域有最高的可能性会包含一个物体。在我们设计出一系列的区域建议之后，这些建议被汇合到一个图像大小的区域，能被填入到经过训练的CNN（论文中的例子是AlexNet），能为每一个区域提取出一个对应的特征。这个向量随后被用于作为一个线性SVM的输入，SVM经过了每一种类型和输出分类训练。向量还可以被填入到一个有边界的回归区域，获得最精准的一致性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/UicQ7HgWiaUb2LVY4tic7mahGfvNVUT3kqwAibodnKMicd3zHVS0iaCGYwQcw2BT4jQ8ukgbF7NcHYzQmfvfJQmeTcwA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;非极值压抑后被用于压制边界区域，这些区域相互之间有很大的重复。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Fast R-CNN&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;原始模型得到了改进，主要有三个原因：训练需要多个步骤，这在计算上成本过高，而且速度很慢。Fast R-CNN通过从根本上在不同的建议中分析卷积层的计算，同时打乱生成区域建议的顺利以及运行CNN，能够快速地解决问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/UicQ7HgWiaUb2LVY4tic7mahGfvNVUT3kqw9EnRfAYB68XP8bicvn1kWeyZia0bibnGRBbwNnFibTBPxBUnV4Mr4riaibpQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Faster R-CNN&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Faster R-CNN的工作是克服R-CNN和 Fast R-CNN所展示出来的，在训练管道上的复杂性。作者 在最后一个卷积层上引入了一个区域建议网络（RPN）。这一网络能够只看最后一层的特征就产出区域建议。从这一层面上来说，相同的R-CNN管道可用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/UicQ7HgWiaUb2LVY4tic7mahGfvNVUT3kqwsUkAl5HQkvywFbYILPPs6ZsVibW0yFu58H0dtpFOYQ2GYkCmCdKQ3Ug/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;为什么重要？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;能够识别出一张图像中的某一个物体是一方面，但是，能够识别物体的精确位置对于计算机知识来说是一个巨大的飞跃。更快的R-CNN已经成为今天标准的物体识别程序。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;生成对抗网络（2015年）&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;按照Yann LeCun的说法，生成对抗网络可能就是深度学习下一个大突破。假设有两个模型，一个生成模型，一个判别模型。判别模型的任务是决定某幅图像是真实的（来自数据库），还是机器生成的，而生成模型的任务则是生成能够骗过判别模型的图像。这两个模型彼此就形成了“对抗”，发展下去最终会达到一个平衡，生成器生成的图像与真实的图像没有区别，判别器无法区分两者。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/UicQ7HgWiaUb2LVY4tic7mahGfvNVUT3kqwEB3ibU97Nw572ZG5sotkme1dsEGch5FjeOZrGQz3X1kc3oouh8lJcTQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;左边一栏是数据库里的图像，也即真实的图像，右边一栏是机器生成的图像，虽然肉眼看上去基本一样，但在CNN看起来却十分不同。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;为什么重要？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;听上去很简单，然而这是只有在理解了“数据内在表征”之后才能建立的模型，你能够训练网络理解真实图像和机器生成的图像之间的区别。因此，这个模型也可以被用于CNN中做特征提取。此外，你还能用生成对抗模型制作以假乱真的图片。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;生成图像描述（2014年）&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;把CNN和RNN结合在一起会发生什么？Andrej Karpathy 和李飞飞写的这篇论文探讨了结合CNN和双向RNN生成不同图像区域的自然语言描述问题。简单说，这个模型能够接收一张图片，然后输出&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/UicQ7HgWiaUb2LVY4tic7mahGfvNVUT3kqw7MV9NQUNAa3IHaOOhYJzpGGxennRibF4ia1vPmibK4JFNlNT5AP787wDA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;很神奇吧。传统CNN，训练数据中每幅图像都有单一的一个标记。这篇论文描述的模型则是每幅图像都带有一句话（或图说）。这种标记被称为弱标记，使用这种训练数据，一个深度神经网络“推断句子中的部分与其描述的区域之间的潜在对齐（latent alignment）”，另一个神经网络将图像作为输入，生成文本的描述。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;为什么重要？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;使用看似不相关的RNN和CNN模型创造了一个十分有用的应用，将计算机视觉和自然语言处理结合在一起。这篇论文为如何建模处理跨领域任务提供了全新的思路。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;空间转换器网络（2015年）&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，让我们来看该领域最近的一篇论文。本文是谷歌DeepMind的一个团队在一年前写的。这篇论文的主要贡献是介绍了空间变换器（Spatial Transformer）模块。基本思路是，这个模块会转变输入图像，使随后的层可以更轻松地进行分类。作者试图在图像到达特定层前改变图像，而不是更改主CNN架构本身。该模块希望纠正两件事：姿势标准化（场景中物体倾斜或缩放）和空间注意力（在密集的图像中将注意力集中到正确的物体）。对于传统的CNN，如果你想使你的模型对于不同规格和旋转的图像都保持不变，那你需要大量的训练样本来使模型学习。让我们来看看这个模块是如何帮助解决这一问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;传统CNN模型中，处理空间不变性的是maxpooling层。其原因是，一旦我们知道某个特定特性还是起始输入量（有高激活值），它的确切位置就没有它对其他特性的相对位置重要，其他功能一样重要。这个新的空间变换器是动态的，它会对每个输入图像产生不同的行为（不同的扭曲/变形）。这不仅仅是像传统 maxpool 那样简单和预定义。让我们来看看这个模块是如何工作的。该模块包括：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: square;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;一个本地化网络，会吸收输入量，并输出应施加的空间变换的参数。参数可以是6维仿射变换。&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;采样网格，这是由卷曲规则网格和定位网络中创建的仿射变换（theta）共同产生的。&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;一个采样器，其目的是执行输入功能图的翘曲。&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/UicQ7HgWiaUb2LVY4tic7mahGfvNVUT3kqwC1rEY7WOZXjjPMgDCc5wb28svZwrBKJGIEc1Tzh5CFLpHNec5Xs3oA/0?wx_fmt=png"/&gt;&lt;/strong&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该模块可以放入CNN的任何地方中，可以帮助网络学习如何以在训练过程中最大限度地减少成本函数的方式来变换特征图。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/UicQ7HgWiaUb2LVY4tic7mahGfvNVUT3kqwOUIic1Eorj9ADWVaHmGanzaG56kJWtogx3K96bFKL3B4JX3uZIKibUfg/0?wx_fmt=png"/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;为什么重要？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;CNN的改进不一定要到通过网络架构的大改变来实现。我们不需要创建下一个ResNet或者 Inception 模型。本文实现了对输入图像进行仿射变换的简单的想法，以使模型对平移，缩放和旋转保持不变。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;***&lt;span&gt;&lt;strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;在新智元后台回复“0830”，下载论文（共11篇）。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;编译来源：&lt;/span&gt;&lt;span&gt;The 9 Deep Learning Papers You Need To Know About&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;【号外】&lt;/strong&gt;&lt;span&gt;&lt;span&gt;由中国自动化学会和新智元联合主办&lt;/span&gt;的AI全球年度盛典『AI WORLD 2016世界人工智能大会』即将盛大开幕。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/UicQ7HgWiaUb2LVY4tic7mahGfvNVUT3kqw7DvCKEOobnvNDRnoxX0Pk9IMJSoJOLH6OV9YYRiclM5d5eohn6pbjzQ/0?wx_fmt=jpeg"/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/UicQ7HgWiaUb2LVY4tic7mahGfvNVUT3kqwDIiaJ4H7TsURm6y1JUzoFfM071ia9xicygLdStRJeer8kEAbZ9ng9Eiaibw/0?wx_fmt=jpeg"/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/UicQ7HgWiaUb2LVY4tic7mahGfvNVUT3kqwTZGem3T1eHnfBxte4rnUicGYashWDNF7VicjAqXxJKfn22g05OQVicCRA/0?wx_fmt=jpeg"/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/UicQ7HgWiaUb2LVY4tic7mahGfvNVUT3kqwNTiaBTicBeBtt5Iw4EJSI4cz3GScicaPKyErZmOJrNpbF8Xpagsc2Ybsg/0?wx_fmt=jpeg"/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/UicQ7HgWiaUb2LVY4tic7mahGfvNVUT3kqwiaVfP2pcbJsaX8ibo64o66zH7sNAjkNoFoBrlO5Ygl5td8dYXZLvEI5Q/0?wx_fmt=jpeg"/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;更多详情，点击“阅读原文”，查看大会官网&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;</description>
      <pubDate>Tue, 30 Aug 2016 20:12:05 +0800</pubDate>
    </item>
    <item>
      <title>纽约客：人工智能的炒作和希望</title>
      <link>http://www.iwgc.cn/link/2493920</link>
      <description>&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;1&lt;/span&gt;新智元编译&lt;/span&gt;&lt;span&gt;1&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&amp;nbsp;来源：New Yorker&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;译者&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;：张冬君&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;【新智元导读】&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;《纽约客》8月26日发表文章《人工智能的炒作和希望》&lt;/span&gt;&lt;span&gt;，将AI分为三个阶段。第一个阶段是识别智能，在更加强大的计算机里运行的算法能从大量文本中识别模式和获取主题，甚至能从几个句子获取整个文章的意义。第二个阶段是认知智能，机器已经超越模式识别，而且开始从数据中做出推论。第三个阶段的实现要等到我们能创建像人类一样思考、行动的虚拟人类才行。作者认为，我们现在只处于第一阶段，“识别智能”。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz/UicQ7HgWiaUb1GNdLuPNMK8Mz5ukxeTwWExDbnS6Hr1JicPgZ9AlGJiagK9n98c23sHos09uyGV9zPDRROhA5hHbLg/0?wx_fmt=gif"/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Om Malik是一名科技作家，还是科技新闻网站GigaOm的创始人和创业基金TrueVentures的合伙人。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本月早些时候，约翰·奥利弗在HBO的脱口秀节目“Last Week Tonight”上，讽刺媒体公司疯狂追求点击率。这条视频在网上疯狂传播，在YouTube上已经有近六百万次观看。在节目进行到十分钟左右，奥利弗炮轰Tronc（更名后的Tribune Publishing Company）和其宣传视频。视频中，一个女性机器人发言人在介绍人工智能给新闻界带来的好处。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/UicQ7HgWiaUb2LVY4tic7mahGfvNVUT3kqwcrD2vYXuepBEraLNKDRUaWIQf1XFvdHTRB7ZWlR7M6eDF7UdbxB17w/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;span&gt;Tronc 董事长 Michael Ferro说，每天要用人工智能制作2000个视频&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;Tronc不是唯一热情拥抱人工智能的公司。AI十分火热，每一家公司都在谈论它将如何改变一切。即便是梅西百货公司最近也宣布，它已经在旗下十家百货商店测试一个IBM的AI工具，目的是换回那些放弃传统零售店转而支持网上购物的客户。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;就像之前的“云计算”、“大数据”和“机器学习”，“人工智能”这个词已经被市场营销人员和广告文案人员大肆使用。&lt;span&gt;&lt;strong&gt;人们说的“人工智能”里面有很大一部分其实是数据分析，还是原来的套路。&lt;/strong&gt;&lt;/span&gt;如果这些过度炒作让你忍不住问“人工智能到底是什么？”别担心，你并不是一个人。我曾向许多专家询问这个词的定义，得到了不同的答案。他们一致同意的只有一件事，&lt;strong&gt;那就是人工智能是一组试图模拟或增强人类智能的技术。&lt;/strong&gt;对我来说，“增强”才是重点，智能软件可以帮助我们与这个日益数字化的世界进行交互。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;三十年前，我读报纸，用电动打字机打字，可以看的电视频道屈指可数。而在今天，我有来自Netflix、亚马逊、HBO等的流媒体视频，有时候我都不知道怎么选择。我们越来越难以承受电子邮件、消息、约会和提醒的轰炸。增强智能使人类面对着越来越多的信息输入和选择，数量多到一个人无法应付。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;与其他技术相比，计算机和软件对于大多数人来说更难理解，充斥着神秘感。曾经有一段时间，你要用录音机把一封信或者一篇文档记录下来，然后再由别人转写成文字给你。一个人在机器的帮助下将语音转换成文本。而在今天，你可以对着你的iPhone说话，它会自己转录你的消息。&lt;strong&gt;如果五十年前的人们看到我们目前的语音转换成文本的功能，他们会觉得技术已经具有知觉。&lt;/strong&gt;现在也是同样的情况，我们夸大了与世界交互的方式。著名的作家和未来学家凯文·凯利说，“我们现在能做到的，在50年前是AI，在50年后就不会被称作AI。”&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在以前没有互联网的时候，我们要么打电话要么写信给朋友，一次联系一个人，来了解他们最近的生活。这是一个缓慢的过程，要花很多的精力和时间来了解每一个人。其结果是，我们的互动很少，因为打长途电话费钱，写信也要时间成本。随着因特网的出现，电子邮件成为一种促进和加快这些互动的方式。而Facebook在这方面做的更好，它把你的电话簿变成了一个中枢，让你能同时与数百、甚至数千名朋友同时联系。该算法使我们能轻松维持更多的关系而几乎无需成本。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Michelle Zhou花了15年的时间在IBM研究院和IBM Watson团队工作，之后离开IBM成为情绪分析初创企业Juji的联合创始人。情绪分析是人工智能和人机交互的一个交叉领域，Zhou作为该领域的专家，&lt;span&gt;&lt;strong&gt;将AI分为三个阶段。第一个阶段是识别智能，在更加强大的计算机里运行的算法能从大量文本中识别模式和获取主题，甚至能从几个句子获取整个文章的意义。第二个阶段是认知智能，机器已经超越模式识别，而且开始从数据中做出推论。第三个阶段的实现要等到我们能创建像人类一样思考、行动的虚拟人类才行。&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们离创建虚拟人类还有很长的路要走。尽管媒体吹得天花乱坠，但是没有任何一个技术是完美的，AI最有价值的功能在于增强人类智能。要达到这一点，我们需要训练计算机来模仿人类。 2016年4月，彭博商业周刊的一篇报道就提供了一个很好的例子。它描述了提供自动化AI个人助理的公司聘请人类“教员”来检查和评估AI助理的表现。“我们用复制人类智能的能力来定义人工智能，这很讽刺，”Sean Gourley说，他是数据分析公司Primer的创始人，善于在算法的帮助下从大型数据集挖掘智能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;无论是Spotify、Netflix或者是新一代AI聊天机器人，所有这些工具都依赖于人类自身提供数据。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;当我们在听歌时，把歌曲加入播放列表并分享给别人，我们就在向Spotify释放重要的信号。这些信息能训练其算法，使它不仅能发现我们喜欢什么，还能预测我们的喜好。&lt;br/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;甚至是我们经常谈论的“计算机视觉”，它之所以有效，是因为人类上传了数十亿的照片，并且用元数据标记这些照片，给予这些照片情境。日益强大的计算机可以通过扫描这些照片从中找出模式和意义。同样地，谷歌利用它多年收集的数十亿语音样本建立了一个智能系统，能理解各种口音和细微差别，这使得谷歌的语音搜索功能成为可能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;将Zhou的三个阶段作为衡量标准，我们目前还在“识别智能”阶段——今天的计算机使用深度学习来更快更好地发现模式。然而，一些公司正在研究能用于推断意义的技术，这将是我们要走的下一步。“我们是否会到达第三阶段，这不重要，”Zhou在给我的电子邮件中这样说。“我仍然热衷于人机共生，那时，计算机可以做它们能做到的最好的事（即要求一致性、客观性和精确度的事），人类做人类能做到最好的事（有创意，不精确但适应性强）。”&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;未来几十年里，人类将继续训练计算机来模仿我们。而在此期间，我们将不得不面对AI的各种泡沫。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;编译来源： &lt;/span&gt;&lt;span&gt;THE HYPE—AND HOPE—OF ARTIFICIAL INTELLIGENCE&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;http://www.newyorker.com/business/currency/the-hype-and-hope-of-artificial-intelligence?t=1472427441113&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;hr style="line-height: 25.6px; white-space: normal;"&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;【号外】&lt;/strong&gt;&lt;span&gt;&lt;span&gt;由中国自动化学会和新智元联合主办&lt;/span&gt;的AI全球年度盛典『AI WORLD 2016世界人工智能大会』即将盛大开幕。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/UicQ7HgWiaUb2LVY4tic7mahGfvNVUT3kqw7DvCKEOobnvNDRnoxX0Pk9IMJSoJOLH6OV9YYRiclM5d5eohn6pbjzQ/0?wx_fmt=jpeg"/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/UicQ7HgWiaUb2LVY4tic7mahGfvNVUT3kqwDIiaJ4H7TsURm6y1JUzoFfM071ia9xicygLdStRJeer8kEAbZ9ng9Eiaibw/0?wx_fmt=jpeg"/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/UicQ7HgWiaUb2LVY4tic7mahGfvNVUT3kqwTZGem3T1eHnfBxte4rnUicGYashWDNF7VicjAqXxJKfn22g05OQVicCRA/0?wx_fmt=jpeg"/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/UicQ7HgWiaUb2LVY4tic7mahGfvNVUT3kqwNTiaBTicBeBtt5Iw4EJSI4cz3GScicaPKyErZmOJrNpbF8Xpagsc2Ybsg/0?wx_fmt=jpeg"/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/UicQ7HgWiaUb2LVY4tic7mahGfvNVUT3kqwiaVfP2pcbJsaX8ibo64o66zH7sNAjkNoFoBrlO5Ygl5td8dYXZLvEI5Q/0?wx_fmt=jpeg"/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;更多详情，点击“阅读原文”，查看大会官网&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 30 Aug 2016 20:12:05 +0800</pubDate>
    </item>
    <item>
      <title>【新智元100】7 张图看懂美国人工智能产业</title>
      <link>http://www.iwgc.cn/link/2493921</link>
      <description>&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;1&lt;/span&gt;新智元编译&lt;/span&gt;&lt;span&gt;1&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&amp;nbsp;来源：O'Reilly&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;译者&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;：胡祥杰 &amp;nbsp;张冬君&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;【新智元导读】&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;本文是O‘reilly的报告《 美国人工智能新市场》的作者&lt;span&gt;Aman Naimat针对报告所写的解读文章。通过数据分析的方法，&lt;span&gt;Aman 对美国人工智能市场进行了粗略分析，分为行业对AI 的投资、企业对AI投资、企业对AI技术的采纳情况（应用案例）以及美国AI企业地理分布几个部分。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;Aman 说&lt;/span&gt;&lt;span&gt;本&lt;/span&gt;&lt;span&gt;报告的目的不是要争论AI是什么和不是什么，采取实用的方法来定义AI，并且基于正在使用或是开发AI的企业进行分析。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;报告要点：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="width: 528.537px; line-height: 25.6px; white-space: normal;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;除软件和&lt;/span&gt;&lt;span&gt;IT&lt;/span&gt;&lt;span&gt;行业以外，每个行业只有少数几十家公司实际涉及&lt;/span&gt;&lt;span&gt;AI&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;北美地区目前只有1500家公司正在做与AI相关的东西。在各个行业里所有中型到大型企业中，只有不到1%的企业使用AI，&lt;/span&gt;&lt;span&gt;但使用AI的企业似乎都是其行业的领导者，它们都非常有名，而且是所在领域里最成功的企业。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;除了任务自动化外，还有一些新奇的应用。例如，远程信息处理、物联网和机器人技术在全行业都有影响，其代表的不仅仅是人类任务自动化。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;AI企业的地理位置是双峰分布，比整个高科技行业的分布形式还要明显。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz/UicQ7HgWiaUb1GNdLuPNMK8Mz5ukxeTwWExDbnS6Hr1JicPgZ9AlGJiagK9n98c23sHos09uyGV9zPDRROhA5hHbLg/0?wx_fmt=gif"/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2004年，在斯坦福大学计算机科学系迷宫式的过道里，我跟一个长得很像圣诞老人对话。这个大胡子男人是约翰·麦卡锡，他在50年代&lt;span&gt;与马文·明斯基一起&lt;/span&gt;创造了人工智能这个词，是人工智能的创始人之一。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;麦卡锡在一段时间内一直都是行业的先锋，包括为AI创建Lisp语言。他的其他创新包括，分时计算机，垃圾回收和Lambda演算。我本科学习的就是自然语言处理，当时AI还没有今天那么酷，当然，自然语言处理也没有，它们离现在这些激动人心的概念都还很远。但是，所谓的AI冬天的解冻已开始。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我记得，那天我的眼睛一直盯着房间里的旧温控计，我和麦卡锡一直从关系数据库的缺点谈到了拥有自省能力的AI。温控计是每个大学和医院都能找到的最乏味的那类东西。但是，麦卡锡却认为，温控计也能拥有思考，拥有情感和信仰。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他此前曾发表文章，描述了对当时AI发展状态的失望，更确定的说，是对数据库的失望。我不知道Nest（智能家居公司）的创始人在开发出那些漂亮的产品时，有没有从麦卡锡对温控计的思考上获得激励或者灵感。但是，每一次我看到Nest时，我都会想起麦卡锡，想到我们在那间办公室里关于温控计的谈话，虽然我还不确定的我“Nest”对事物有多少信仰，但是，在管理其有限的任务上，它确实做得很好。它已经有一个模型，根据我的设定，可以预测未来和目标，从而驱动它自己的行为。它也许不是我们想到的关于AI 的一切，但是只在短短几年间，温控计已经离麦卡锡的愿景很近了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;约翰·麦卡锡教授在2011年去世。很快地，AI从人工智能计算机科学系的实验室和失败的研究尝试走到了现实世界。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;和领域内的很多人一样，我常常思考，AI是否会保持这样的发展，还是我们会进入到另一个AI的冬天。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;大多数参与AI的人都相当务实，希望能解决实际问题，这给了我信心。我很欣赏在电视上看到的每一个沃森（Watson）的广告，因为IBM为实现AI的普及，在商业化上花了重金。同时，对于这些非常新的技术，我也担心被过度吹捧的和不能实现的可能性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;每个人都加入了战斗。谷歌的CEO最近宣布，人工智能和机器学习会成为他们所有的产品的核心部件。他们实际上已经有些落后了，像亚马逊这类的公司，已经推出真正基于AI和自然语言理解的智能家居产品，比如Echo和Alexa。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;本报告旨在覆盖AI目前市场及其商业采纳情况，关注走出学术实验室进入产业的AI。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我们正处在大规模采用人工智能的风口浪尖。大市场的预测被抛来抛去，我们必须用自己拥有的数据站稳脚跟。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们的目标是建立一个基准，可用于研究行业未来的发展。虽然我确实试着用数据对AI 目前的商业环境进行描绘。支撑的数据会单独提供，而我的分析只是其中的一个阐释。这份报告的一个目标是为行业提供关于同行是如何采用AI的、其基本方向和用户案例提供指导。本报告不会对AI的未来进行预测，检测的项目也限定在美国公司中。&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;人工智能的起始&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能真正进入主流产业是在2011年到2012年。AI 在这段时间的兴起，有几个物质上的原因，还有几个基础性的技术，共同创造了这场完美的风暴。下文就是一些让AI在全世界得以进入主流发展和公司的技术创新和市场条件：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;大数据基础设施&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Google发表的论文Map Reduce的兴起，促成了一些项目，比如Hadoop，从而提供了AI所需要的廉价、大规模数据处理基础设施。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;云计算&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这一技术的进展使得计算成本急剧下降。比如，在校生只用1000美元，就能租用一台拥有100个节点机器，用于数据处理工作，此前，相同性能的计算机可能会需要投入1亿美元才能做到。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;海量的数据&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;开放资源爬虫（Crawlers）使得网络上的资源变得可获取。另外，开源存储器，比如Commoncrawl也使得互联网上的大多数网页也可以轻易地被每个人获得。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Watson 和 Siri&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然还不是那么完美，但是Watson和Siri 在推动AI 的普及上功不可没。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投资&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从2009年开始，有超过100以美元的投资流向了大数据基础设施，为今天的AI应用开发打下了基础。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;专业人才&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;能够执行AI开发中的多重任务的人才，从数据处理到数据科学，这些年来至少增减了10倍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;一个小心翼翼的世界&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在我分析AI在商业世界的形势之前，我想指出，当下的大多数技术离通用AI还差很远。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我将通用AI定义为是一个达到人类水平或超人类水平智能的系统，能理解世界，理解并解决一般性问题。对现代AI宣扬者的一个主要反对观点是，大部分AI都是bag-of-word模型，它们不能思考或者做任何有关认知的事情。有人称，谷歌DeepMind在理论上是一个通用AI，但是对我来说，它仍然只是在到处试验，我们还没有看到它其他任何的应用。Aving说过，有许多技术在给定的某个人类任务中能达到或者超过人类智能水平（即“狭义智能”）。而且，这样的任务以前是由擅长于此的人来完成的。DeepMind在围棋比赛中获胜，围棋不像象棋，它需要人的直觉，绝非粗暴地计算每一步就能获胜。图像识别也做到了这一点，有时比人类的表现还要好。例如，Spiderbook公司的AI在列出目标客户名单上，能达到最优秀的销售人员的水平。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然而，此次报告的目的不是要争论AI是什么和不是什么。我采取实用的方法来定义AI，并且基于正在使用或是开发AI的企业进行分析。我不是要验证人们说的AI是什么，或是区分“好”AI和“坏”AI。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;报告研究方法&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为对本报告进行研究，我的团队使用了Spiderbook开发的基于图像的机器学习模型，研究了整个企业网络，然后根据成熟度和投资额将企业分为不同层次。我们征询了世界近50万家企业，用数据来深度理解AI景观图和各种相关技术，如认知计算、深度学习、机器视觉、自然语言理解，以及聊天机器人。该引擎阅读并理解了数十亿公共文件，包括所有的新闻报道、业务关系、论坛、招聘广告、博客、推特、专利，以及我们已经得到授权的专有数据库。这些数据在很大程度上代表了企业网络，我们利用这些数据创建一个知识图谱，显示各个企业是如何相互关联的，哪一家企业在用什么产品或是拥有具备特定技能的员工。除知识图谱外，我们还利用基于网络的机器学习创建了一个关于公司的发展重、项目以及投资的实时快照。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;行业对AI的投资&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/UicQ7HgWiaUb2LVY4tic7mahGfvNVUT3kqwKppicpiaXWEKX2lyzSHIFeB0s9AvGdbnicuRb53NZLq8PUkLauCTkdRcQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;正如预期的那样，AI最大的一部分被用于软件和IT相关企业。虽然后面的数字细分了投资AI的行业，但是实际数量仍然很低。除软件和IT行业以外，每个行业只有少数几十家公司实际涉及AI。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;企业对AI的投资&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;即使是用狭隘的AI定义，北美地区目前也只有1500家公司正在做与AI相关的东西。这意味，在各个行业里所有中型到大型企业中，只有不到1%的企业使用AI。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面的表格显示了积极投资AI的部分公司，按行业排序。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;尽管每一个行业只有不到1%的企业使用AI，但使用AI的企业似乎都是其行业的领导者。它们都非常有名，而且是所在领域里最成功的企业。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;这个发现的原因很难辨别：是因为它们本身就是行业的领军者？或者是因为它们有额外的资源来尝试包括AI在内的所有新想法？还是因为它们早早采用了新技术，为其他企业在各自行业的随后发展奠定了基础？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;AI投资企业排名&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面显示的是在AI投资最多并且声称要将其作为核心战略的企业。其中不仅有人们熟知的谷歌和Facebook，还有MITRE这种依靠联邦研究资助的非盈利公司。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谷歌&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Facebook&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Rocket Fuel&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;IBM&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;亚马逊&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;雅虎&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;英特尔&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;微软&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;德勤&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;MITRE&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;百度&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;领英&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;百度&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Cylance&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Lockheed Martin&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;NASA&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Sentient Corporation&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Electronic Arts&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/UicQ7HgWiaUb2LVY4tic7mahGfvNVUT3kqwy16vaPBy0avRVXxBUXRQEkQxlTtfpMVbQOsDCgZmmAibAgWJicTLaSVg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;AI使用案例&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我最近观摩了由梅肯研究院主办的AI杰出人员座谈会，谈论他们对AI领域未来的展望以及现在使用这些技术可能实现的事情。该小组提出的各种想法比现在AI的实际应用要令人兴奋得多，虽然有一些很极端，但是大部分很人性化。这些想法涉及的范围很广，从疾病诊断到农业和照顾老人。但是，基于我们的研究，AI的主要应用领域更加平庸——使人类要完成的任务自动化。下面的数字量化了企业的预算是如何花费在特定的AI用例上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/UicQ7HgWiaUb2LVY4tic7mahGfvNVUT3kqwlUsQUvkDxhjjDelhaO3KRtjkxj6c3frfCCUg8icict2svuvCl17NsLHQ/0?wx_fmt=png"/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;在这张图中，&lt;strong&gt;除了任务自动化外，还有一些新奇的应用。例如，远程信息处理、物联网和机器人技术在全行业都有影响，其代表的不仅仅是人类任务自动化。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;网络情报与安全：AI的一个主要推动力&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;看到AI在网络智能中有这么广泛的应用让人很惊讶，毕竟网络智能在AI界并不是一个大的讨论话题，然而有大量的预算投入这一领域。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;有越来越多的企业在网络智能方面建设、咨询、或者使用AI，比其他用例还要多。也许社会上的威胁要比报道出来的要多吧，毕竟公司没必要宣传这些威胁。或者，这也可能是美国政府连续资助这一垂直领域的附带现象吧。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;AI成熟企业的技术采用情况&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在过去的十年里，已经出现大量的AI相关算法来解决经典问题，如分类或自然语言处理。有一些算法，因其有效性和适应性，现在还存在并能用于更大的范围，但是大多数算法却已经退场。算法最新的创新一直是在深度学习领域，而之前是潜在狄利克雷分配（LDA）、半监督学习、潜在语义索引（LSI）、支持向量机等等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其中一些技术已经自成一类，即使它们解决的问题有很多重叠。&lt;strong&gt;例如，深度学习可用于自然语言理解，甚至是认知计算，即使它最主要用于图象处理。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;AI使用情况的分类不能清楚显示AI成熟市场的现有水平。下面两张图显示有多少家企业在实验室之外使用这些AI技术。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/UicQ7HgWiaUb2LVY4tic7mahGfvNVUT3kqwHm2d3dfxWc0vf5JantfK4fq6lCauUWEntMibcnI4YibvKAaRBM6AcicRA/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/UicQ7HgWiaUb2LVY4tic7mahGfvNVUT3kqwTc07FTTXBL8fn5suxPARTeag0WvicbdgfEfRAib8vkUkMNpgrlZVHD2g/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第二张图显示了AI技术的子类，以及投资这些子类的企业数量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;AI企业的地理位置&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;AI企业的地理位置是双峰分布，比整个高科技行业的分布形式还要明显。比如，我以前的大数据市场报告显示，大数据公司在地理上比AI公司要更加分散。或许我们都可以猜出奇点会出现在哪里。以下的数字显示各个州的AI企业分布情况。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/UicQ7HgWiaUb2LVY4tic7mahGfvNVUT3kqww1evkkvFc6nyWVX7QOF1R6PRoImiamWfZmdhQWdZOFYwXm5MgOdy4Qg/0?wx_fmt=png"/&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/UicQ7HgWiaUb2LVY4tic7mahGfvNVUT3kqwluBtHXkibJEGeDnRuLBL9pN9UAfp8w7pG8EPiapmA7lpIcQA8wEtWtWg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;总结&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;AI 的冬天已经解冻，并且正在走向春天。虽然AI仍处于非常早期的阶段，其巨大的潜力和最近围绕基于任务的AI所取得的进展，已经引起了一些反响。有一些聚焦领域的应用案例，比如网络情报、市场营销和制造业的自动化等市场已经有了一些基于AI的产品。通用问题解决和健康医疗应用是谈话中被提及得最多的话题，但是，并没有太多公司把预算花在这上面。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;近5年前，政府和私人企业在大数据技术、云计算基础设施和最重要的——人才培养上的付出，共同驱动了AI的兴起。在过去的几个月里，大多数的科技公司，比如亚马逊、特斯拉、谷歌都把AI看成下一个十年里，公司的创新驱动力。在这些公司的董事会里，一小部分核心成员也接受了AI，在美国，涉及AI领域投入的公司少于1500家。虽然这在整个工业界中只是很少的部分，但是引领这股浪潮的公司都是最大而且最有前途的，当AI成为现实，这些公司当然也就能有最大的收益。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本文作者：Aman Naimat&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;原文链接：https://www.oreilly.com/ideas/the-new-artificial-intelligence-market&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;【号外】&lt;/strong&gt;&lt;span&gt;&lt;span&gt;由中国自动化学会和新智元联合主办&lt;/span&gt;的AI全球年度盛典『AI WORLD 2016世界人工智能大会』即将盛大开幕。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/UicQ7HgWiaUb2LVY4tic7mahGfvNVUT3kqw7DvCKEOobnvNDRnoxX0Pk9IMJSoJOLH6OV9YYRiclM5d5eohn6pbjzQ/0?wx_fmt=jpeg"/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/UicQ7HgWiaUb2LVY4tic7mahGfvNVUT3kqwDIiaJ4H7TsURm6y1JUzoFfM071ia9xicygLdStRJeer8kEAbZ9ng9Eiaibw/0?wx_fmt=jpeg"/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/UicQ7HgWiaUb2LVY4tic7mahGfvNVUT3kqwTZGem3T1eHnfBxte4rnUicGYashWDNF7VicjAqXxJKfn22g05OQVicCRA/0?wx_fmt=jpeg"/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/UicQ7HgWiaUb2LVY4tic7mahGfvNVUT3kqwNTiaBTicBeBtt5Iw4EJSI4cz3GScicaPKyErZmOJrNpbF8Xpagsc2Ybsg/0?wx_fmt=jpeg"/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/UicQ7HgWiaUb2LVY4tic7mahGfvNVUT3kqwiaVfP2pcbJsaX8ibo64o66zH7sNAjkNoFoBrlO5Ygl5td8dYXZLvEI5Q/0?wx_fmt=jpeg"/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;点击“阅读原文”，查看大会官网。&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 30 Aug 2016 20:12:05 +0800</pubDate>
    </item>
  </channel>
</rss>
