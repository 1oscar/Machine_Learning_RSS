<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>36大数据</title>
    <link>http://www.iwgc.cn/list/1149</link>
    <description>关注大数据和互联网趋势,最大,最权威,最干货的大数据微信号(dashuju36).大数据第一科技媒体.不发软文,只做知识分享.</description>
    <item>
      <title>实战 | 数据建模那点事儿</title>
      <link>http://www.iwgc.cn/link/2774493</link>
      <description>&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/jAqr3XzCYibyuickHrXHziaJNegTkAyxKIBwqOQQBicFRFeeb57wJz3iaKCq8c5L7cZ9YAYdiaNHVp7CWF4yglw8lfow/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;作者：陈丹奕&lt;/p&gt;&lt;p&gt;&lt;span&gt;本文由 知乎 陈丹奕授权发布。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;今天要说内容是建模。为啥我作为一个数学能力并不强的人要在这献丑讲建模的事呢？其实我的目的很简单，就是为了告诉大家一个事实：数据分析中的建模，并没有想象中那么高深莫测，人人都有机会做出自己的模型。&lt;/p&gt;&lt;h1 data-mce-style="text-align: center;" style="color: rgb(51, 51, 51); font-family: &amp;#39;microsoft yahei&amp;#39;; line-height: 25px; white-space: normal; text-align: center;"&gt;&lt;span&gt;第一部分：数据建模理论和逻辑&lt;/span&gt;&lt;/h1&gt;&lt;h2 style="font-size: 18px; margin-top: 16px; margin-bottom: 16px; padding-top: 10px; padding-bottom: 10px; line-height: 18px; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(238, 238, 238); color: rgb(68, 68, 68); font-family: &amp;#39;microsoft yahei&amp;#39;; white-space: normal;"&gt;&lt;span&gt;&lt;strong&gt;一、从数据分析的定义开始&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;维基百科对数据分析的定义如下：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Analysis of data&lt;/strong&gt;&amp;nbsp;is a process of inspecting, cleaning, transforming, and modeling data with the goal of discovering useful information, suggesting conclusions, and supporting decision making. Data analysis has multiple facets and approaches, encompassing diverse techniques under a variety of names, in different business, science, and social science domains.&lt;br/&gt;（来源：Data analysis&lt;em class="icon-external"&gt;&lt;/em&gt;）&lt;/p&gt;&lt;p&gt;简单翻译：数据分析是一个包含数据检验、数据清洗、数据重构，以及数据建模的过程，目的在于发现有用的信息，有建设性的结论，辅助决策的制定。数据分析有多种形式和方法，涵盖了多种技术，应用于商业、科学、社会学等多个不同的领域。&lt;/p&gt;&lt;p&gt;和上篇文章中我画的图对比一下：&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/jAqr3XzCYibyuickHrXHziaJNegTkAyxKIBa60NAZzrMsCOLB5MbLDqEbLFRMydUAnWJTibmzSdO0WUKTb72icLgO7Q/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;我在上篇文章中为了让初学者更容易走通全流程，简化了数据清洗的过程，实际上数据清洗绝非一次完成，“检验-清洗-检验”的过程可能会重复数次乃至数十次。&lt;/p&gt;&lt;p&gt;而建模呢？再次引用维基上对数据建模的定义：&lt;/p&gt;&lt;p&gt;Data modeling is a process used to define and analyze data requirements needed to support the business processes within the scope of corresponding information systems in organizations. Therefore, the process of data modeling involves professional data modelers working closely with business stakeholders, as well as potential users of the information system.（来源：Data modeling&lt;em class="icon-external"&gt;&lt;/em&gt;）&lt;br/&gt;简单翻译：数据建模是一个用于定义和分析在组织的信息系统的范围内&lt;strong&gt;支持商业流程&lt;/strong&gt;所需的数据要求的过程。因此，数据建模的过程需要专业建模师与商业人员和信息系统潜在用户的紧密合作。这段话的定义更偏向信息系统和商业数据建模，我之所以在此引用这段话，是为了明确接下来的讨论内容主要方向是商业数据分析和建模，至于科学研究方向的数据建模，不在这篇文章的讨论范围以内。&lt;/p&gt;&lt;p&gt;请注意上边这段话中的一个核心：&lt;strong&gt;支持商业流程。&lt;/strong&gt;商业数据建模，乃至商业数据分析，其最终目的都是要支持某种商业流程，要么优化原有流程，提高各部分效率；要么重构原有流程，减少步骤；要么告诉决策者，哪些流程改造方向是错误的，以避免走错路。&lt;strong&gt;最终的目标，一定是提升效率。但在不同的情况下，提升效率的方式也是不同的，因此在每个模型建立时，都需要确定其解决的具体目标问题。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;再往前走一步，数学—主要是统计学，在建模的过程中又扮演什么样的角色呢？继续引用维基：&lt;/p&gt;&lt;p&gt;Mathematical formulas or models called algorithms may be applied to the data to identify relationships among the variables, such as correlation or causation. In general terms, models may be developed to evaluate a particular variable in the data based on other variable(s) in the data, with some residual error depending on model accuracy (i.e., Data = Model + Error)（来源：Data modeling&lt;em class="icon-external"&gt;&lt;/em&gt;）&lt;/p&gt;&lt;p&gt;简单翻译：数学公式或模型称为算法，可应用于数据以确定变量之间的关系，如相关性或因果关系。在一般情况下，模型开发出来后用于评估一个特定的变量与数据中其他其他变量的关系，根据模型的准确性不同，这些关系中会包含残差（即，数据=模型+错误）&lt;/p&gt;&lt;p&gt;这段描述很明确，&lt;strong&gt;统计学在数据建模的过程中，主要用于帮助我们找出变量之间的关系，并对这种关系进行定量的描述，输出可用于数据集的算法。&lt;/strong&gt;一个好的数据模型，需要通过多次的测试和优化迭代来完成。&lt;/p&gt;&lt;p&gt;综上，给出一个我认为的“数据建模”定义：&lt;strong&gt;数据集+商业目标+算法+优化迭代= 数据建模。定义中的每一部分都必不可少。&lt;/strong&gt;&lt;/p&gt;&lt;h2 style="font-size: 18px; margin-top: 16px; margin-bottom: 16px; padding-top: 10px; padding-bottom: 10px; line-height: 18px; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(238, 238, 238); color: rgb(68, 68, 68); font-family: &amp;#39;microsoft yahei&amp;#39;; white-space: normal;"&gt;&lt;span&gt;&lt;strong&gt;二、数据模型的建立过程&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;照例，先上流程图：&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/jAqr3XzCYibyuickHrXHziaJNegTkAyxKIBvjrdAMYHXGTpibKlibcPxtzc0PMHDNIHg3VymLjFfI8Jrvn0MQlOjQ6A/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;上图的流程颜色对应数据分析全流程，为了方便大家阅读，我把全流程图再贴一次：&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/jAqr3XzCYibyuickHrXHziaJNegTkAyxKIBa60NAZzrMsCOLB5MbLDqEbLFRMydUAnWJTibmzSdO0WUKTb72icLgO7Q/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;接下来，我重点解读明黄色（浅黄？）部分的内容：&lt;/p&gt;&lt;ul style="margin-bottom: 16px; color: rgb(51, 51, 51); font-family: &amp;#39;microsoft yahei&amp;#39;; font-size: 15px; line-height: 25px; white-space: normal;" class=" list-paddingleft-2"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;选择变量与重构变量&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在进行建模之前，首先要考虑的是使用哪些变量来建立模型，需要从业务逻辑和数据逻辑两个方面来考虑：&lt;/p&gt;&lt;p&gt;业务逻辑：变量基于收集到的数据，而数据在收集时，会产生与业务层面相关的逻辑，比如在汽车参数中，一旦我们定义了“家用轿车”这个类别，那么无论什么品牌什么车型，“轮胎数量（不计备胎）”这个变量就有99%以上几率为4……当然在接下来的建模中，我们不会选择这个变量。这一类情况是业务知识来告诉我们哪些变量可以选择，哪些不能选择。&lt;/p&gt;&lt;p&gt;数据逻辑：通常从数据的完整性、集中度、是否与其他变量强相关（甚至有因果关系）等角度来考虑，比如某个变量在业务上很有价值，但缺失率达到90%，或者一个非布尔值变量却集中于两个值，那么这个时候我们就要考虑，加入这个变量是否对后续分析有价值。&lt;/p&gt;&lt;p&gt;我个人认为，在选择变量时，业务逻辑应该优先于数据逻辑，盖因业务逻辑是从实际情况中自然产生，而建模的结果也要反馈到实际中去，因此选择变量时，业务逻辑重要程度相对更高。&lt;/p&gt;&lt;p&gt;而在变量本身不适合直接拿来建模时，例如调查问卷中的满意度，是汉字的“不满意”“一般”“满意”，那么需要将其重构成“1”（对应不满意）“2”（对应一般）“3”（对应满意）的数字形式，便于后续建模使用。&lt;/p&gt;&lt;p&gt;除这种重构方式之外，将变量进行单独计算（如取均值）和组合计算（如A*B）也是常用的重构方法。其他的重构方法还有很多种，在此不一一阐述。&lt;/p&gt;&lt;ul style="margin-bottom: 16px; color: rgb(51, 51, 51); font-family: &amp;#39;microsoft yahei&amp;#39;; font-size: 15px; line-height: 25px; white-space: normal;" class=" list-paddingleft-2"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;选择算法&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;我们在建模时，目标是解决商业问题，而不是为了建模而建模，故此我们需要选择适合的算法。常用建模算法包括相关、聚类、分类（决策树）、时间序列、回归、神经网络等。&lt;/p&gt;&lt;p&gt;以对消费者的建模为例，举一些场景下的常用算法对应：&lt;/p&gt;&lt;p&gt;划分消费者群体：聚类，分类；&lt;/p&gt;&lt;p&gt;购物篮分析：相关，聚类；&lt;/p&gt;&lt;p&gt;购买额预测：回归，时间序列；&lt;/p&gt;&lt;p&gt;满意度调查：回归，聚类，分类；&lt;/p&gt;&lt;p&gt;等等。&lt;/p&gt;&lt;p&gt;确定算法后，要再看一下变量是否满足算法要求，如果不满足，回到选择/重构变量，再来一遍吧。如果满足，进入下一步。&lt;/p&gt;&lt;ul style="margin-bottom: 16px; color: rgb(51, 51, 51); font-family: &amp;#39;microsoft yahei&amp;#39;; font-size: 15px; line-height: 25px; white-space: normal;" class=" list-paddingleft-2"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;设定参数&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;算法选定后，需要用数据分析工具进行建模。针对不同的模型，需要调整参数，例如聚类模型中的K-means算法，需要给出希望聚成的类别数量，更进一步需要给出的起始的聚类中心和迭代次数上限。&lt;/p&gt;&lt;p&gt;这些参数在后续测试中会经过多次调整，很少有一次测试成功的情况，因此请做好心理准备。&lt;/p&gt;&lt;ul style="margin-bottom: 16px; color: rgb(51, 51, 51); font-family: &amp;#39;microsoft yahei&amp;#39;; font-size: 15px; line-height: 25px; white-space: normal;" class=" list-paddingleft-2"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;加载算法与测试结果&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;算法跑完之后，要根据算法的输出结果来确定该算法是否能够解决问题，比如K-means的结果不好，那么考虑换成系统聚类算法来解决。或者回归模型输出的结果不满足需求，考虑用时间序列来做。&lt;/p&gt;&lt;p&gt;如果不需要换算法，那么就测试一下算法输出的结果是否有提升空间，比如聚类算法中指定聚类结果包含4类人群，但发现其中的两类特征很接近，或者某一类人群没有明显特征，那么可以调整参数后再试。&lt;/p&gt;&lt;p&gt;在不断的调整参数，优化模型过程中，模型的解释能力和实用性会不断的提升。当你认为模型已经能够满足目标需求了，那就可以输出结果了。&lt;strong&gt;一个报告，一些规则，一段代码，都可能成为模型的输出。&lt;/strong&gt;在输出之后，还有最后一步：接收业务人员的反馈，看看模型是否解决了他们的问题，如果没有，回到第一步，再来一次吧少年……&lt;/p&gt;&lt;p&gt;以上，就是建模的一般过程。如果你有些地方觉得比较生涩，难以理解，也没有关系。下一篇专栏中，我将向你们介绍一个具体的数据模型，我会对建模的过程一步步进行拆解，力求简明易懂。&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/jAqr3XzCYibyuickHrXHziaJNegTkAyxKIBnwEibic8CxuemickkvI4hcm1IN30rODvFQgNT2x1jERzypWia1QW5Riaqnw/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;h1 data-mce-style="text-align: center;" style="color: rgb(51, 51, 51); font-family: &amp;#39;microsoft yahei&amp;#39;; line-height: 25px; white-space: normal; text-align: center;"&gt;&lt;span&gt;第二部分：数据建模的应用&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;我写了个建模的流程，有过建模经验的人自然懂，没有经验的各位也不要着急，这次我以一个真实模型为例，给大家详细讲述建模的各个步骤。照例，先上流程图：&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/jAqr3XzCYibyuickHrXHziaJNegTkAyxKIBxpepZNM5T7t4WTRhCLruLknHU9gzicKzic6ic5e5oCDKIK7n3BKuGpLaA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;大家可以看到，这个图是由我之前文章中的两张图拼合而来，而我今天讲的这个真实模型，将把图中所有的流程都走一遍，保证一个步骤都不漏。&lt;/p&gt;&lt;h2 style="font-size: 18px; margin-top: 16px; margin-bottom: 16px; padding-top: 10px; padding-bottom: 10px; line-height: 18px; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(238, 238, 238); color: rgb(68, 68, 68);"&gt;&lt;strong&gt;Step 0：项目背景&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;话说这个项目跟我加入百度有直接关系……&lt;/p&gt;&lt;p&gt;2013年的最后一天，我结束了在三亚的假期，准备坐飞机回家，这时候接到一个知乎私信，问我对百度的一个数据科学家（其实就是数据分析师啦）职位是否感兴趣，我立刻回信，定了元旦假期以后去面试。两轮面试过后，面试官——也是我加入百度后的直属Leader——打电话给我，说他们对我的经历很满意，但是需要我给他们一份能体现建模能力的报告。&lt;/p&gt;&lt;p&gt;按说这也不是一件难事，但我翻了翻电脑后发现一个问题：我从上家公司离职时，为了装13，一份跟建模相关的报告文件都没带……最后双方商定，我有一个星期时间来做一份报告，这份报告决定了我是否能加入百度。&lt;/p&gt;&lt;p&gt;那么，是时候展示我的技术了！我的回合，抽卡！&lt;/p&gt;&lt;h2 style="font-size: 18px; margin-top: 16px; margin-bottom: 16px; padding-top: 10px; padding-bottom: 10px; line-height: 18px; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(238, 238, 238); color: rgb(68, 68, 68);"&gt;&lt;strong&gt;Step 1：目标确定&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;看看报告的要求：&lt;/p&gt;&lt;p&gt;&lt;em&gt;数据最好是通过抓取得来，需要用到至少一种（除描述统计以外）的建模技术，最好有数据可视化的展示&lt;/em&gt;&lt;/p&gt;&lt;p&gt;看来是道开放题，那么自然要选择一个我比较熟悉的领域，因此我选择了……《二手主机游戏交易论坛用户行为分析》&lt;/p&gt;&lt;p&gt;为啥选这个呢？你们看了我那么多的Mario图，自然知道我会选主机游戏领域，但为什么是二手？这要说到我待在国企的最后半年，那时候我一个月忙三天，剩下基本没事干，因此泡在论坛上倒卖了一段时间的二手游戏……&lt;/p&gt;&lt;p&gt;咳咳……总之，目标就确定了：&lt;strong&gt;分析某二手主机游戏交易论坛上的帖子，从中得出其用户行为的描述，为用户进行分类，输出洞察报告。&lt;/strong&gt;&lt;/p&gt;&lt;h2 style="font-size: 18px; margin-top: 16px; margin-bottom: 16px; padding-top: 10px; padding-bottom: 10px; line-height: 18px; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(238, 238, 238); color: rgb(68, 68, 68);"&gt;&lt;strong&gt;Step 2：数据获取&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;简单来说，就是用python写了个定向爬虫，抓了某个著名游戏论坛的二手区所有的发帖信息，包括帖子内容、发帖人信息等，基本上就是长这个样子：&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/jAqr3XzCYibyuickHrXHziaJNegTkAyxKIBuzicFObGmLuV9AD9HypRvYV0HAHeZPyQCeTicKTVsxaQjibHkV1vuiaRnw/0?wx_fmt=png"/&gt;（打码方式比较简单粗暴，请凑合看吧……）&lt;/p&gt;&lt;h2 style="font-size: 18px; margin-top: 16px; margin-bottom: 16px; padding-top: 10px; padding-bottom: 10px; line-height: 18px; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(238, 238, 238); color: rgb(68, 68, 68);"&gt;&lt;strong&gt;Step 3：数据清洗&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;这个模型中的数据清洗，主要是洗掉帖子中的无效信息，包括以下两类：&lt;/p&gt;&lt;p&gt;1、论坛由于其特殊性，很多人成交后会把帖子改成《已出》等标题，这一类数据需要删除：&lt;/p&gt;&lt;p&gt;2、有一部分人用直接贴图的方式放求购信息，这部分体现为只抓到图片链接，需要删除。&lt;/p&gt;&lt;p&gt;数据清洗结束了么？其实并没有，后边会再进行一轮清洗……不过到时再说。&lt;/p&gt;&lt;h2 style="font-size: 18px; margin-top: 16px; margin-bottom: 16px; padding-top: 10px; padding-bottom: 10px; line-height: 18px; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(238, 238, 238); color: rgb(68, 68, 68);"&gt;&lt;strong&gt;Step 4：数据整理&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;用上面的那些帖子数据其实是跑不出啥结果的，我们需要把数据整理成可以进一步分析的格式。&lt;/p&gt;&lt;p&gt;首先，我们给每条帖子打标签，标签分为三类：行为类型（买 OR 卖 OR 换），目标厂商（微软 OR 索尼 OR 任天堂），目标对象（主机 OR 游戏软件）。打标签模式是”符合关键词—打相应标签“的方法，关键词表样例如下：&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/jAqr3XzCYibyuickHrXHziaJNegTkAyxKIB9iaDUtg2I9c7vyG1VbcVzaGhODWfmNicWiaY3SgMqWBOYv3OVB6WhiaM0Q/0?wx_fmt=png"/&gt;（主机掌机那个标签后来我在实际操作时没有使用）&lt;/p&gt;&lt;p&gt;打完标签之后，会发现有很多帖子没有打上标签，原因有两种：一是关键词没有涵盖所有的产品表述（比如三公主这种昵称），二是有一部分人发的帖子跟买卖游戏无关……&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/jAqr3XzCYibyuickHrXHziaJNegTkAyxKIB8HRtwrJGf8RunsRMYb7zpIQlTLj2CLj34CCHsaEGdGcAt0g0PBHtdQ/0?wx_fmt=png"/&gt;这让人怎么玩……&lt;strong&gt;第二次数据清洗开始&lt;/strong&gt;，把这部分帖子也洗掉吧。&lt;/p&gt;&lt;p&gt;其次，我们用发帖用户作为视角，输出一份用户的统计表格，里边包含每个用户的发帖数、求购次数、出售次数、交换次数、每一类主机/游戏的行为次数等等，作为后续搭建用户分析模型之用。表格大概长这个样子：&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/jAqr3XzCYibyuickHrXHziaJNegTkAyxKIBbMGOReoI8hw3wGcedatQfpvQv6Qtt8v96HqueC0PUaq2licFzYlhAWQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;之后这个表的列数会越来越多，因为数据重构的工作都在此表中进行。&lt;/p&gt;&lt;p&gt;整理之后，我们准备进行描述统计。&lt;/p&gt;&lt;h2 style="font-size: 18px; margin-top: 16px; margin-bottom: 16px; padding-top: 10px; padding-bottom: 10px; line-height: 18px; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(238, 238, 238); color: rgb(68, 68, 68);"&gt;&lt;strong&gt;Step 5 &amp;amp; 6：描述统计 &amp;amp; 洞察结论&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;描述统计在这个项目中的意义在于，描述这一社区的二手游戏及主机市场的基本情况，为后续用户模型的建立提供基础信息。&lt;/p&gt;&lt;p&gt;具体如何进行统计就不说了，直接放成品图，分别是从各主机市场份额、用户相互转化情况、地域分布情况进行的洞察。&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/jAqr3XzCYibyuickHrXHziaJNegTkAyxKIB4ribM6PjrdSEV7XXsonznPWkEh3ZO9iawp2IOpwPINey78KorK6MUeCg/0?wx_fmt=png"/&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/jAqr3XzCYibyuickHrXHziaJNegTkAyxKIBe1MLMvaicA8va0sjFZ0F4rAQkAC0Z1JqTPwiaiagRrhntbibBQSNzzJC4g/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;h2 style="font-size: 18px; margin-top: 16px; margin-bottom: 16px; padding-top: 10px; padding-bottom: 10px; line-height: 18px; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(238, 238, 238); color: rgb(68, 68, 68);"&gt;&lt;strong&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/jAqr3XzCYibyuickHrXHziaJNegTkAyxKIBwSuIiaFRPMf45OfTvXpDAyp593yZKuO8dWV3qDLrFUZ2YC8tY1ib1XDg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;h2 style="font-size: 18px; margin-top: 16px; margin-bottom: 16px; padding-top: 10px; padding-bottom: 10px; line-height: 18px; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(238, 238, 238); color: rgb(68, 68, 68);"&gt;&lt;strong&gt;Step 7 &amp;amp; 8：选择变量 &amp;amp; 选择算法&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;因为我要研究的是这些用户与二手交易相关的行为，因此初步选择变量为发帖数量、微软主机拥有台数、索尼主机拥有台数、任天堂主机拥有台数。&lt;/p&gt;&lt;p&gt;算法上面，我们的目标是将用户分群，因此选择聚类，方法选择最简单的K-means算法。&lt;/p&gt;&lt;h2 style="font-size: 18px; margin-top: 16px; margin-bottom: 16px; padding-top: 10px; padding-bottom: 10px; line-height: 18px; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(238, 238, 238); color: rgb(68, 68, 68);"&gt;&lt;strong&gt;Step 9 &amp;amp; 10：设定参数 &amp;amp; 加载算法&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;K-means算法除了输入变量以外，还需要设定聚类数，我们先拍脑袋聚个五类吧！&lt;/p&gt;&lt;p&gt;（别笑，实际操作中很多初始参数都是靠拍脑袋得来的，要通过结果来逐步优化）&lt;/p&gt;&lt;p&gt;看看结果：&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/jAqr3XzCYibyuickHrXHziaJNegTkAyxKIBtHKHN1XcoiaaVdcqySHKOyFH99co0BUbRctC5cueMSlSC18Iric5qZVQ/0?wx_fmt=png"/&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/jAqr3XzCYibyuickHrXHziaJNegTkAyxKIBFh251HQTYUQUibd3c9BRZ9Qwhbee0BrvEKicTVkTro58jjAelnKPzrag/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;第一类别的用户数跟总体已经很接近了，完全没有区分度啊！&lt;/p&gt;&lt;h2 style="font-size: 18px; margin-top: 16px; margin-bottom: 16px; padding-top: 10px; padding-bottom: 10px; line-height: 18px; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(238, 238, 238); color: rgb(68, 68, 68);"&gt;&lt;strong&gt;Step 7‘ &amp;amp; 8’ &amp;amp; 9‘ &amp;amp; 10’ &amp;amp; 11：选择变量 &amp;amp; 选择算法 &amp;amp;设定参数 &amp;amp; 加载算法 &amp;amp;重构变量&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;这一节你看标题都这么长……&lt;/p&gt;&lt;p&gt;既然我们用原始值来聚类的结果不太好，那么我把原始值重构成若干档次，比如发帖1-10的转换为1,10-50的转换为2，依次类推，再聚一次看看结果。&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/jAqr3XzCYibyuickHrXHziaJNegTkAyxKIBibZaARNRvicRNicLMO4P4GA5BGeAP9kjVbuc7rCL7pYy9gHFXov8ukoqg/0?wx_fmt=png"/&gt;哦哦！看上去有那么点意思了！不过有一类的数量还是有一点少，我们聚成四类试试：&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/jAqr3XzCYibyuickHrXHziaJNegTkAyxKIB1GuKmiahhxhFz7LKpmuqIlacGLpNCD035KHwDBMQzzicAn8TZl446A1Q/0?wx_fmt=png"/&gt;哦哦，完美！ 我们运气不错，一次变量重构就输出了一个看上去还可以的模型结果，接下来去测试一下吧。&lt;/p&gt;&lt;h2 style="font-size: 18px; margin-top: 16px; margin-bottom: 16px; padding-top: 10px; padding-bottom: 10px; line-height: 18px; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(238, 238, 238); color: rgb(68, 68, 68);"&gt;&lt;strong&gt;Step 12：结果测试&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;测试过程中，很重要的一步是要看模型的可解释性，如果可解释性较差，那么打回重做……&lt;/p&gt;&lt;p&gt;接下来，我们看看每一类的统计数据：&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/jAqr3XzCYibyuickHrXHziaJNegTkAyxKIBMhFh7xSXawgHExWU9wUAp1Z61S9QPAUdkMK7dIEXicibYQ11SNn8kFZw/0?wx_fmt=png"/&gt;这个表出来以后，基本上可以对我们聚类结果中的每一类人群进行解读了。结果测试通过！&lt;/p&gt;&lt;h2 style="font-size: 18px; margin-top: 16px; margin-bottom: 16px; padding-top: 10px; padding-bottom: 10px; line-height: 18px; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(238, 238, 238); color: rgb(68, 68, 68);"&gt;&lt;strong&gt;Step 13 &amp;amp; 14 &amp;amp; 15：输出规则 &amp;amp; 模型加载 &amp;amp; 报告撰写&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;这个模型不用回朔到系统中，因为仅仅是一个我们用来研究的模型而已。因此，输出规则和模型加载两步可以跳过，直接进入报告撰写。&lt;/p&gt;&lt;p&gt;聚类模型的结果可归结为下图：&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/jAqr3XzCYibyuickHrXHziaJNegTkAyxKIBla6Ria4b6TsmRI9K1M3PZaiaPEo7tQLG20q0o0ylTUu0ibSia7ibCFxGGgg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;眼熟不？在我的第二篇专栏文章第一份数据报告的诞生 - 一个数据分析师的自我修养&amp;nbsp;&amp;nbsp;中，我用这张图来说明了洞察结论的重要性，现在你们应该知道这张图是如何得来的了。&lt;/p&gt;&lt;p&gt;撰写报告的另外一部分，在描述统计-洞察结论的过程中已经提到了，把两部分放在一次，加上背景、研究方法等内容，就是完整的报告啦！&lt;/p&gt;&lt;p&gt;最后附送几张各类用户发帖内容中的关键词词云图：&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/jAqr3XzCYibyuickHrXHziaJNegTkAyxKIBVErBSugSqW8u9BKpgSerzXKkic9mTWqaALbm1f7VdY0EwCfgoYgJWbA/0?wx_fmt=png"/&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/jAqr3XzCYibyuickHrXHziaJNegTkAyxKIB9PZ92LrQ2crX3icibZo30Wls7pw19gt3sIRY9ya1I90v9YhflfC1vt7w/0?wx_fmt=png"/&gt;&lt;br/&gt;那么，这篇文章就到此结束了，最后的最后，公布一下我做这份报告用到的工具：&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/jAqr3XzCYibyuickHrXHziaJNegTkAyxKIBx9MJ4EnHZjzO2zjYIVcP0qUPqUeRWDgzTfbbLXckxOgvFBEme6J8qQ/0?wx_fmt=png"/&gt;大家可以看到，要当一个数据分析师，要用到很多类别的工具，多学一点总是没有坏处的，在此与大家共勉。&lt;/p&gt;&lt;p&gt;End.&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 21 Sep 2016 09:44:21 +0800</pubDate>
    </item>
    <item>
      <title>读后感| 《浪潮之巅》：没有任何时候可以高枕无忧</title>
      <link>http://www.iwgc.cn/link/2774494</link>
      <description>&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/jAqr3XzCYibyuickHrXHziaJNegTkAyxKIBeTHnqXS7mtgdFUFouJTmGUGN8BexxDJzhg4bdyS6WxtJKUysF673yg/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;作者：Heidi格物志&lt;/p&gt;&lt;p&gt;终于花了断断续续一周时间，把书架上积满灰尘的《浪潮之巅》读完了……&lt;/p&gt;&lt;h3 style="border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(238, 238, 238); margin-bottom: 16px; color: rgb(68, 68, 68); font-family: &amp;#39;microsoft yahei&amp;#39;; line-height: 25px; white-space: normal;"&gt;&lt;strong&gt;【引言】&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;吴军博士在书中提到的女性CEO，基本上是悲催的：提到惠普的卡琳·菲奥莉娜——“系列错误的决定和平庸的管理才能”;提到雅虎的CEO卡罗尔·巴茨——“对于互联网这个行业是外行”，1000多页讲互联网，却连被尊称为互联网女皇的玛丽·米克尔提都没有提到。虽然为女性有点鸣不平，但有一点却得承认：如果让我选一本书陪我度过睡前半小时，我宁可选择《禅与摩托车修理技术》或者《论宗教的产生》，也不会选择《浪潮之巅》。&lt;/p&gt;&lt;p&gt;因为这里面充斥了很多我听过但总是不求甚解的词儿。而且关键是读完后，没有办法去显示自己的逼格(和男生聊，还是聊不过人家，和女生聊，大部分又听不懂)。&lt;/p&gt;&lt;p&gt;所以非常感谢本次强制性的读书任务，让我终于从书架上取下了这本刚买回来就束之高阁的积满灰尘的书，并非常认真地读完。&lt;/p&gt;&lt;p&gt;我对自己的要求比较低，读懂这本书是第一步，至于那些超越了读懂之外的“心得体会”，顶多作为beta版本吧，必须多看几遍，经常刷新、升级，才能够不断沉淀成自己的东西。&lt;/p&gt;&lt;p&gt;所以我的读书笔记里，会包含很多对于其他人都很明白的东西，请原谅我非要以自己的方式去阐释一遍。&lt;/p&gt;&lt;h3 style="border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(238, 238, 238); margin-bottom: 16px; color: rgb(68, 68, 68); font-family: &amp;#39;microsoft yahei&amp;#39;; line-height: 25px; white-space: normal;"&gt;&lt;strong&gt;一. 本书讲了什么&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;提及了除机械革命外的一波又一波非串行关系的浪潮(行业变革)，通信革命，以及方兴未艾的个人电脑革命、互联网革命、信息革命、云计算革命……&lt;/p&gt;&lt;p&gt;讲了在这些浪潮中IT企业的兴衰史，每一波浪潮中，都有趁势而起的公司，经过激烈的角逐，有一些站在了该浪潮之巅，成为实质意义上的垄断者以及市场规则的制定者，也有一些虽然没有在生态链中称霸江湖，但是在某个领域却屹立不倒的领导者，这些读起来让人热血澎湃。即便是江湖霸主，然而在书中也能够读到它“不甘心”的另一面，比如微软。在个人电脑浪潮中，它虽然做到了操作系统的老大，然而在操作系统上，时刻提防着苹果，在互联网上，败给了雅虎，在搜索上，败给了GOOGLE，浏览器市场也在GOOGLE紧逼下节节败退……更可怕的是，当他在收拾眼前战场的时候，在错过了互联网机遇之后，又错过了移动互联网……然后云计算……&lt;/p&gt;&lt;p&gt;&lt;span&gt;而本书真正的重心是放到Why的剖析上，提到了很多因素，分不同的公司、时代而异，有内因(如董事会的短见)，也有外因(如华尔街、强大的竞争对手等)，也有在表面原因下的根因的进一步钻取，如不因人的意志为转移的诺威格定律、摩尔定律以及反摩尔定律，以及所谓的“基因决定论”。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;书中还用了很多的篇幅讲干货，就其中在外因上占据主导地位的华尔街、风投也进行了详尽的说明。&lt;/p&gt;&lt;p&gt;企业兴衰的结果令人震撼，书中的干货令人大开眼界，而兴衰之因的总结令人掩卷沉思。&lt;/p&gt;&lt;p&gt;吴军博士的字太多，但是图是缺乏的，所以我想用几张图去演绎我的收获。&lt;/p&gt;&lt;h3 style="border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(238, 238, 238); margin-bottom: 16px; color: rgb(68, 68, 68); font-family: &amp;#39;microsoft yahei&amp;#39;; line-height: 25px; white-space: normal;"&gt;&lt;strong&gt;二. IT产业行业生态图&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;书中提到了那么多的公司，令人眼花缭乱，他们之间的关系更是错综复杂，本来是同盟的，瞬间又称为竞争对手，本来相安无事的，却瞬间狭路相逢。&lt;/p&gt;&lt;p&gt;我想，要真正读通此书，不得不去试图进一步了解IT产业，于是必须图示化帮助我自己更好理解这个大环境，还有很多不成熟的地方，姑且叫成版本0.4吧。&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/jAqr3XzCYibyuickHrXHziaJNegTkAyxKIBynyibT32O6N05R7zP3wYvLY01tnwUOCVibpGe1bSRpOqiaVcezWyXniaMg/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1. 没有永恒的对手和盟友&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;看上图，一个公司可能同时在多个阵营里和不同的公司构成竞争关系，又和自己的上下游形成盟友关系。&lt;/p&gt;&lt;p&gt;而企业间的竞争关系是不断演变的，比如微软和谷歌，本来微软在个人电脑领域成为了一方霸主，时刻提放着苹果，而Google彼时也只是做做搜索，和雅虎抢占着互联网流量。而当Google开始做浏览器后，微软发现自己的互联网入口浏览器陷入了背水之战，当时剿灭网景浏览器的绝招完全不凑效。&lt;/p&gt;&lt;p&gt;企业间或许没有“独木桥”和“阳关道”之说，不禁想起了本来做电商的阿里和做社交的腾讯，大势所趋必然意味着他们之间要打上一仗。&lt;/p&gt;&lt;p&gt;盟友也有朝一日会成为对手，当初的微软还是帮苹果写软件的开发商呢?&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;思考：我们必须很清楚自己做的业务的竞争格局，谁是我当下的竞争对手?谁是我们的盟友?谁可能是我长远的竞争对手?识别清楚竞争对手，不是为了跟着他们亦步亦趋，而是为了超越竞争，立于不败之地。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2. 所谓的浪潮，真的是不可预测的吗?&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;吴军博士讲，与其预测，不如说是更好适应，然而适应其实也意味着：&lt;/p&gt;&lt;ul style="margin-bottom: 16px; color: rgb(51, 51, 51); font-family: &amp;#39;microsoft yahei&amp;#39;; font-size: 15px; line-height: 25px; white-space: normal;" class=" list-paddingleft-2"&gt;&lt;li&gt;&lt;p&gt;是否能够比别人更早看到(不管是CEO自己的天赋、牛逼的情报调查、还是能够广纳言路、还是能够赋权给创新小团队)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;是否能够比别人更快取舍(当断不断，定受其乱)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;公司、董事会是否能够允许尽快做出调整(警惕大公司病、所谓的基因、华尔街和董事会的压力)&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;所以，为了更好适应，第一条件却可能仍指向是否有更好的嗅觉、更好的感知。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;所谓的浪潮到底是什么?它真的是自然发生的吗?我宁可认为它是人为的，它之所以不可逆，是因为多种人为因素在一起发挥着合力，不是单凭一个公司的力量、一个人的力量可以抗拒，因为你对抗其实不是对抗大自然，而是对抗着你的企业赖以生存的生态环境。浪潮在短期来看是偶然的，比如如果乔布斯没有发明第一台个人电脑，是否个人电脑革命要延期呢?，又如乔布斯没有被董事会请回开创了i时代，Google是否也会放慢安卓联盟，移动互联网的浪潮也要更慢到来呢?&lt;/p&gt;&lt;p&gt;但在长期来看，又可能会发现，该来的，一定会来，只是时间早晚问题，或者只是谁来主导的问题。&lt;/p&gt;&lt;p&gt;为什么呢?&lt;/p&gt;&lt;p&gt;书中提到了几个值得我们反思思考的定律：&lt;/p&gt;&lt;p&gt;&lt;span&gt;摩尔定律：&lt;/span&gt;既有成本一定会不断下降，而且下降的速度会加快(所以我们一定会面临网速更快、计算和存储的成本不断下降的)&lt;/p&gt;&lt;p&gt;&lt;span&gt;反摩尔定律&lt;/span&gt;：企业营收的下降，促使公司要不断推陈出新、加快创新。&lt;/p&gt;&lt;p&gt;&lt;span&gt;诺威格定律&lt;/span&gt;：会促使企业不断寻求新的突破点——守，也即意味着退。&lt;/p&gt;&lt;p&gt;然而仅仅有这几个定律，只可以说明企业一定要不断变，但是说明不了为何在某段时间内可能会有什么浪潮。&lt;/p&gt;&lt;p&gt;不禁想，是否除了这几个显而易见定律，还有一个恒古至今的隐形规律，是否和人类的“贪婪”需求升级有关，本来没有网可以上的时候，大家都没有想过上网，一旦有网上了，有人就希望网更快，信息更多，可以随时享受网络……可以随时购物……可以更轻量地使用各种服务……&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以，企业求变，可能归根结底，仍然是要回归到市场需求的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;另外的求变，是在交叉的领域，比如当互联网遇到图书、当互联网遇到手机、当互联网遇到传统线下产业……&lt;/p&gt;&lt;p&gt;反正，站在马后炮的角度，看上面的图上的变革，觉得那么顺其自然。&lt;/p&gt;&lt;h3 style="border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(238, 238, 238); margin-bottom: 16px; color: rgb(68, 68, 68); font-family: &amp;#39;microsoft yahei&amp;#39;; line-height: 25px; white-space: normal;"&gt;&lt;strong&gt;三. 在时间轴上去看兴衰&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;读的时候，想如果把这些公司都放到一个图表上去看看，会不会很好玩，于是就这么做了……然后我试图把我GET到的转折点标注了出来。&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/jAqr3XzCYibyuickHrXHziaJNegTkAyxKIBib78lqvvwXnHicopQdRmL6TdRPbIEMyUIMic2I7F1RkjibqxHZlwpAtJRg/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;查看大图看这里：http://photo.weibo.com/1668540465/wbphotos/large/photo_id/4020758143699381/album_id/3559802702237352&lt;/p&gt;&lt;p&gt;呈现成图的时候，觉得很幸运的是，基本上波澜壮阔的兴衰史，发生在陪伴我们成长的年代：80年代初至今。&lt;/p&gt;&lt;p&gt;令人久久无法释怀的，恐怕不是本来就没有机会，是“本来可以……”“然而却……”&lt;/p&gt;&lt;ul style="margin-bottom: 16px; color: rgb(51, 51, 51); font-family: &amp;#39;microsoft yahei&amp;#39;; font-size: 15px; line-height: 25px; white-space: normal;" class=" list-paddingleft-2"&gt;&lt;li&gt;&lt;p&gt;AT&amp;amp;T，本来可以借助2000年前后的网络革命和20世纪90年代延续至今的无线通信飞跃得到绝佳的发展机会，然而却在变革中断送了性命。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;IBM，本来可以凭借雄厚的财力和技术，成为个人电脑时代的领导者，但是却彻底退出了个人电脑的舞台。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;微软，本来可以凭借操作系统江湖一霸的地位，可轻易拿下任何江山，然而却一再错过新的突破点，固守不断缩小的江山。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;雅虎，本来可以避开GOOGLE，专注于品牌广告市场，但是却陷入搜索之争，等到大梦初醒，已经为时已晚。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;惠普，本来可以凭借已有优势，成为科技领域弄潮儿，与IBM一决雌雄，然而却在一系列并购收购出卖后沦为电器公司。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;摩托罗拉，本来最有资格领导移动通信大潮，很遗憾，它只踏上一个浪尖就被诺基亚超越了。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;诺基亚，曾经的全球手机销量第一的江湖霸主，错过了新操作系统的智能手机发展，前途异常黯然。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;……&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;思考：永远不可高枕无忧，过去的百年企业很多，而如今10年之内，一个企业可能就会从创业、成长、成熟、衰落全部历经。对于互联网企业来讲，原地踏步也即是等着淘汰的结果自然而然发生。&lt;/span&gt;&lt;/p&gt;&lt;h3 style="border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(238, 238, 238); margin-bottom: 16px; color: rgb(68, 68, 68); font-family: &amp;#39;microsoft yahei&amp;#39;; line-height: 25px; white-space: normal;"&gt;&lt;strong&gt;四. 影响企业兴衰的内外因总结&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;通过本书不断提到的总结分析，影响一个公司兴衰的内外因，大概如下：&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/jAqr3XzCYibyuickHrXHziaJNegTkAyxKIBU3ODo7TFQSIkqvF8WseQGLEzncpbYKo8xQhHDTBetw0pvicPpU1IfZw/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;可以说，幸运的公司是类似的，不幸的公司则各又各的不幸，幸运的公司得天时地利人和，而不幸的公司只要一个原因处崩盘则全线崩盘，所以把公司搞垮比把公司搞好太容易了。&lt;/p&gt;&lt;p&gt;但是既然是浪潮之巅，书中不会聚焦于谈各种公司败因，比如因为公关危机、董事长老婆外遇等各种因素，而是重点探讨的是一个双刃剑的原因：也即“浪潮”，比其他外因更不可抗拒。&lt;span&gt;而不同的公司因为客观规律和“内因”的双重制约，对于“浪潮”的反应、适应情况不同，而导致了不同的结局，所以最终还是从内因出发。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1. CEO的作用(是被夸大的吗?)&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;前段时间不知道在哪里听到一句话，说企业高层决策者的决策对公司的成败是最最重要的。&lt;/p&gt;&lt;p&gt;不知道吴军博士自己快读《浪潮之巅》后有没有同样的感觉：CEO的作用，真的有那么神奇?一个人，可以完全决定了企业不同的命运。&lt;/p&gt;&lt;p&gt;&lt;span&gt;救世主型：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;郭士纳：&lt;/strong&gt;大刀阔斧的变革让IBM明确定位而利于不败之地。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;乔布斯：&lt;/strong&gt;一旦回归，苹果就飞扬而起，开创了i时代，且辉煌至今。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;比尔·盖茨：&lt;/strong&gt;当代拿破仑，靠自己的天才谋略和商机洞察、聪明的四两拨千斤，开创了个人电脑霸主地位。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;埃里森：&lt;/strong&gt;若没有埃里森，甲骨文就是一个二流企业。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;钱伯斯：&lt;/strong&gt;让思科稳坐网络设备供应商头把交椅。&lt;/p&gt;&lt;p&gt;&lt;span&gt;扶不起的阿斗型：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;菲奥莉娜：&lt;/strong&gt;靠拆分和不合适的并购，把惠普从科技公司变成电器公司。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;高尔文：&lt;/strong&gt;不成气候的家族企业继承者，让摩托罗拉全线崩溃。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;塞寥尔：&lt;/strong&gt;无谓的扩张和莫名其妙的忽悠投资者让雅虎千疮百孔。&lt;/p&gt;&lt;p&gt;也别忽视了书中还有很多有才干但是没有挽回败局的英雄们，吴军博士认可了他们的才干，但说因为企业基因无法改变努力的结果。&lt;/p&gt;&lt;p&gt;&lt;span&gt;思考：CEO太重要。&lt;/span&gt;从浪潮之巅看过来，我们虽然可能不一定有机会成为某个浪潮之巅的企业的CEO(应该说有0.1%不到的几率吧)，但是明白这一点，还是对自己的工作影响挺大的。因为，一个小小的产品、项目，其实都可以类比为一个创业公司，而且，很多变革，宏观来看，影响的是这些大企业，从微观来看，其实已经可以影响我们日常的判断。我们作为OWNER，何尝不是CEO?我们也会关心竞争、行业趋势、市场占有率和用户使用数据，以免自己的产品被投资者砍掉(撤回资源)，也会吸纳不同的人才来共同创业。CEO就是很重要，CEO就是要做重要的决策，为此你可以广纳言听、你也可以因为天赋独断专行，你也可以根据数据让自己判断更加准确，你可以大刀阔斧进行改革也可以固守已有稳定市场谋求小小渐变…………但是有一点是非常确信的，也就是：&lt;span&gt;作为CEO，如果不想拱手让人、主动让贤，不断提升自己来带动业务成长，是至关重要的事情。&lt;/span&gt;你永远别想高枕无忧。&lt;/p&gt;&lt;p&gt;还有，虽然你可能会因为自己的性格、习惯被建议要多倾听，但是你不能因为这个而不敢做决策，把决策也放给别人或迟迟不下决定。&lt;/p&gt;&lt;p&gt;因为一个企业必须得有人控制，否则想一下AT&amp;amp;T，CEO的能力必须提升，否则想一下摩托罗拉。&lt;/p&gt;&lt;p&gt;我不太能明白的是：既然CEO这么重要，为何没有像古代打仗一样，每个CEO背后多一些军师?&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2. 商业模式(绝大多数下，比技术优势更重要)&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;因为技术信仰而壮大的公司往往会把技术捧到天上，然后误导很多其他公司争相效仿。&lt;/p&gt;&lt;p&gt;过去我只知道GOOGLE和FACEBOOK的工程师文化，还一度和开发同学们探讨，是否能够在项目组内部也推行这样的文化。&lt;/p&gt;&lt;p&gt;但是，如今我更加深刻感知到，这里说的工程师早已不是我之前理解的工程师，而是&lt;span&gt;具备了商业头脑、创意的工程师，或者是具备了工程思维、商业头脑、创意的产品经理或者其他。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;另外，从《重新定义公司》中提到的巴斯德象限来讲(咦，今天不是要写这本书的读书笔记吧)，创意往往出在“基于应用的创新”矩阵中，如果要应用，而且追求更大的应用和市场占用，只凭借技术是不行的，所以摩托罗拉过度迷信技术而忽视了其他，而郭士纳在改革时删减了纯研究的经费。技术甚至可以因为收购而获得，而商业模式往往等到要效仿的时候，已经大势所趋不可逆转了。&lt;/p&gt;&lt;p&gt;通过商业模式而在竞争中取胜的例子，在书中有太多，比如：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Oracle:&lt;/strong&gt;&amp;nbsp;不同于IBM的卖服务，而是卖软件，仅收取必要的咨询费用，获得了IBM更多的市场份额。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;雅虎：&lt;/strong&gt;美国网景沉迷于收上网费，微软还想要收软件费用的时候，它让大家可以免费上网，但是看看广告收广告商的钱，很快成为第一互联网公司。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;惠普：&lt;/strong&gt;在呈现败局的时候，新的CEO通过改变商业模式为代销，在短短几个季度PC市场占用率超过了戴尔，排名全球第一。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Google：&lt;/strong&gt;开创的印钞机商业模式，至今前途无量。&lt;/p&gt;&lt;p&gt;&lt;span&gt;技术需要养，技术需要储备，技术需要巨大的投资，而商业模式则是可能会四两拨千斤&lt;/span&gt;，而好的商业模式是无法坐等的，这里就体现了CEO和公司高层决策者的洞察和决断力。(再回归到CEO的重要性)。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3. 企业的基因(有时，不是靠牛逼的CEO和牛逼的商业模式所能改变的)&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;按吴军博士引用红杉资本的话，一家公司的基因在创办的3个月内就定型了。&lt;/p&gt;&lt;p&gt;按吴军博士自己的说法，一家成型的公司改变基因的可能性确实很小。&lt;/p&gt;&lt;p&gt;他举了太多的例子，去论证了基因决定论：&lt;/p&gt;&lt;p&gt;牛逼的CEO可能各有牛逼之处，犯了特别典型错误的CEO则是个人才干和魄力不足，而被作者认为有才干但是依然以失败而告终的CEO，作者则很多总结为基因问题。比如：&lt;/p&gt;&lt;ul style="margin-bottom: 16px; color: rgb(51, 51, 51); font-family: &amp;#39;microsoft yahei&amp;#39;; font-size: 15px; line-height: 25px; white-space: normal;" class=" list-paddingleft-2"&gt;&lt;li&gt;&lt;p&gt;微软即使有牛逼的盖茨，依然因为基因决定了无法用MSN盈利;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;摩托罗拉和Intel之争，即使双方统帅换一个个，摩托罗拉依然无法战胜Intel;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;IBM的基因决定了他无法称霸个人电脑……&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;所以按他的结论，企业一旦成熟(也就2年之内吧，3个月太短)，就只能随波逐流，寻求渐变，而无法突破了吗?&lt;/p&gt;&lt;p&gt;那作者提到的那么多不断寻找到新的突破点的公司又是怎么产生的呢?比如Google从搜索到安卓，FaceBook从社交到云计算，亚马逊从买书的电商到云计算……&lt;/p&gt;&lt;p&gt;&lt;span&gt;我觉得作者可以讲客观规律，也可以声明企业基因的重要性，从而不断警示位高权重的人不断去审视环境，不断寻求突破&lt;/span&gt;，并形成一些机制，比如学习GOOGLE用授权给小团队的方式不断刺激创新，但是如果要发展成宿命论，似乎还是有些过于武断了。&lt;/p&gt;&lt;p&gt;摆脱宿命论，对于以下几个问题的探讨，才真的具有意义：&lt;/p&gt;&lt;ul style="margin-bottom: 16px; color: rgb(51, 51, 51); font-family: &amp;#39;microsoft yahei&amp;#39;; font-size: 15px; line-height: 25px; white-space: normal;" class=" list-paddingleft-2"&gt;&lt;li&gt;&lt;p&gt;企业的基因到底是怎么形成的?&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;企业的基因是一定会到了某个阶段跟不上时代吗?&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;在以上情况发生时，牛逼的CEO或者高层如何带领公司突破基因，突出重围?&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;或者对于这三个问题，也可以期待牛逼的人专门出个书了。&lt;/p&gt;&lt;h3 style="border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(238, 238, 238); margin-bottom: 16px; color: rgb(68, 68, 68); font-family: &amp;#39;microsoft yahei&amp;#39;; line-height: 25px; white-space: normal;"&gt;&lt;strong&gt;五. 什么觉得可能不对?&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;看完了将近1000多页的书，对于很多总结不断点头，但是如果非要给自己提一个挑战，试图去想一些不对的地方，会不会有呢?&lt;/p&gt;&lt;p&gt;有个著名的书评作家说，书评原则之一是不要指责作者没有说本来就没打算说的事情，所以可能不算不对，而是自己心存困惑，比如：&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 浪潮是否真的不可预测，对于企业是否只有适应?&lt;/span&gt;&lt;/p&gt;&lt;p&gt;如果从几个已知定律，以及结合人类需求的层次，是否有一定的预知。&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 如果不可预测，那么如何能够更快感知?如果只寄托于CEO的“嗅觉”、“灵机一动”，似乎很多成功都只是偶然。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;我倒是期待，吴军博士有新的著作可以更深剖析背后的HOW。&lt;/p&gt;&lt;p&gt;&lt;span&gt;3. 公司的决策机制&lt;/span&gt;&lt;/p&gt;&lt;p&gt;即使承认CEO的无敌重要性，我也不太相信那么多的扭转(或败或兴)，来自一个个体，如果是中国古代朝廷，我或许相信一些，因为君主拥有至高无上的权利。&lt;/p&gt;&lt;p&gt;然而在现在的企业里，CEO的决策有多少真正代表他的个人有多少是因为有效的企业管理?为何在同时强调硅谷的开放、扁平、创意文化的时候，又有那么多的因为一人意志决定的成败。这里或许有些夸大的成分。不过，我也很有兴趣能够进一步了解这些公司背后的决策团队和机制。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;写在最后：&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;没有任何时候可以高枕无忧，没有任何借口可以拒绝成长。&lt;/p&gt;&lt;p&gt;大到一个公司，顷刻之间，可以从顶峰坠落，一旦错过某个机遇或者出现重大失误，就再也难以回头。&lt;/p&gt;&lt;p&gt;小到我们个人，永远无法躺在过去的成果、影响力上睡懒觉，因为所谓的浪潮，它来，或者不来，不是我们的个人意志所能改变的。&lt;/p&gt;&lt;p&gt;最后，我是计划要读第二遍的，等我读完后，再去修订以上心得。&lt;/p&gt;&lt;p&gt;End.&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 21 Sep 2016 09:44:21 +0800</pubDate>
    </item>
    <item>
      <title>教程 | 如何组建一支优秀的数据分析团队？</title>
      <link>http://www.iwgc.cn/link/2774495</link>
      <description>&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/jAqr3XzCYibyuickHrXHziaJNegTkAyxKIBv9Qjj9FHAMl72vSibL18CeIcz1WOcvXUDdyqickCg98Vy19Fj0cEvr2A/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;作者：陈丹奕&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Q：数据分析人员能做什么？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;A：从纷繁的数据里提炼出有价值的信息并给公司提供支持啊。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Q：你怎么提炼啊？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;A：写程序采集啊，清洗啊，用一定的算法计算数据内部联系，根据业务做出判断啊……&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Q：如果都是用已有的算法，这些事情为什么不能用现成的流程来做呢？或者为什么不能写成程序，让机器自己实现呢？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;A：呃…………&lt;/p&gt;&lt;p&gt;作为一名数据分析师，刚入行的时候跟人聊天聊成这样，非常常见也非常令人不爽。但我们数据分析师是不是仅能手工操作一些算法，等着机器和算法逐步取代我们么？并不是！&lt;/p&gt;&lt;p&gt;&lt;strong&gt;照例观点先行：数据分析不等于数据分析算法/程序，数据分析算法/程序只是分析师手中的工具，数据分析要取得成功必须依赖人的力量，数据分析师的作用在于根据对业务的理解，合理使用分析工具，完成分析目标。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;结合业务的数据分析才是科学的，一切只看计算机输出结果不考虑业务实际情况的数据分析都是无（shua）用（liu）功（mang）。计算机能实现的算法也好，程序也好，只是数据分析中的一部分；如何选择分析切入点，如何选择数据来源，如何确定算法，如何解读结论，这些机器统统做不了，需要我们数据分析师来解决。&lt;/p&gt;&lt;p&gt;观点在上边两段里已经充分展示了，接下来我要愉快的展（che）开（dan）观点内容了：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;数据分析通常包括几个阶段：提出/发现问题——获取并清洗数据——建模——调整优化——输出结论。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这是一个闭环流程，每一步都需要人工参与，程序会参与中间三步，算法在建模中会用到，而数据分析的最重要两步，问题和结论，目前是不可能完全交给计算机去处理的（其实我个人认为这两步在真正的人工智能出现前，绝不可能由计算机自动处理），因此数据分析人员最大的优势，就是“经验”，也就是业务理解能力和数据分析经验。&lt;/p&gt;&lt;p&gt;详细解释一下数据分析的几个阶段：&lt;/p&gt;&lt;h2 style="font-size: 18px; margin-top: 16px; margin-bottom: 16px; padding-top: 10px; padding-bottom: 10px; line-height: 18px; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(238, 238, 238); color: rgb(68, 68, 68); font-family: &amp;#39;microsoft yahei&amp;#39;; white-space: normal;"&gt;&lt;span&gt;&lt;strong&gt;提出/发现问题阶段：&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;大多数时候，数据分析都是为了解决一个问题（锁定某个产品的目标客户，对同样的人群做营销活动用A方案好还是B方案好，等等），或者验证一个猜想（不让旅游者上班高峰坐地铁是不是会大幅度缓解拥挤现象，啤酒和尿布放一起是不是真的会提升啤酒的销售额，等等），总之需要达到一个目标。即使是探索性分析（拿着一大堆数据看看能不能找出点什么结论），那也需要先预设一个或多个目标作为切入点，然后在探索过程中逐步修正。&lt;/p&gt;&lt;p&gt;提出和发现问题的过程，交给计算机干不太靠谱，首先计算机不会提出问题（因为笨），其次计算机能发现的问题也一定是人已经发现了的问题（还是因为笨），需要先有人来设定规则，然后计算机才能根据规则发现问题。而数据分析师，就是设定规则的人。&lt;/p&gt;&lt;p&gt;目标和规则的设定，一定要基于业务，这样分析结果才有用，否则会得出正确但无用的结论。举个栗子，订阅报纸的数据扔给计算机去分析关联关系，看有哪些报纸可以进行组合促销，最后得出个光明日报和人民日报关联系数90%多，所以这俩报纸可以组合起来卖，问题是这俩报纸本来就是要求党政机关订阅的党报，组合起来毫无意义，该订的还是要订，不订的还是不订，这就是典型的正确但无用的分析结果。懂业务能让分析师少做这种无用功，但是计算机要想懂业务就得由人来教，教还不一定能教会，教完了又不能触类旁通（报纸的关联算法拿到电商去完全不能用啊），这样的计算机永远都不如分析师懂业务。&lt;/p&gt;&lt;h2 style="font-size: 18px; margin-top: 16px; margin-bottom: 16px; padding-top: 10px; padding-bottom: 10px; line-height: 18px; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(238, 238, 238); color: rgb(68, 68, 68); font-family: &amp;#39;microsoft yahei&amp;#39;; white-space: normal;"&gt;&lt;strong&gt;&lt;span&gt;获取并清洗数据：&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;这个阶段计算机参与的较多，分析师的工作是指出拿什么数据，拿哪些字段，数据获取到以后用哪些规则进行清洗整理。如果数据源不变，需要重复或定期进行分析时，这个阶段的规则可以固化，由计算机来自动执行，但规则仍然是由分析师来制定的。&lt;/p&gt;&lt;h2 style="font-size: 18px; margin-top: 16px; margin-bottom: 16px; padding-top: 10px; padding-bottom: 10px; line-height: 18px; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(238, 238, 238); color: rgb(68, 68, 68); font-family: &amp;#39;microsoft yahei&amp;#39;; white-space: normal;"&gt;&lt;strong&gt;&lt;span&gt;建模、调整优化：&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;这两个阶段中，分析算法出场了，描述分析、关联分析、回归、分类、聚类、时间序列，每个类别里都有一大堆的固定算法，分析师不能通过手算得出结论，需要借助封装好算法的分析工具（图形化的SPSS，命令行方式的R，等等），看来这一阶段计算机要超越分析师了！&lt;/p&gt;&lt;p&gt;等等，建模哪有这么简单，计算机解决不了的问题一大堆呢：什么时候用哪个类别的算法（该做分类还是聚类），同一类别不同算法哪个更适合当前情况（K-means还是两步聚类，这是个问题），同一个算法怎么调整参数能使效果更好（到底该把用户聚成几类呢），算法输出的结果是否正常（有一部分数据出了问题导致分析结果出现偏差）等等。这些问题计算机统统不知道耶，需要分析师来告诉它该做什么事。&lt;/p&gt;&lt;p&gt;打个比方，数据分析就是打仗，算法是机枪、大炮、坦克等等技术兵器，分析师是士兵、炮手、驾驶员（操纵者），不能因为士兵自己不能一分钟吐出几百发子弹或者炮手自己不能一下子拆掉一个碉堡，就让机枪大炮坦克把操纵者扔下，自己上阵去打仗……就算是无人机，那也得有个拿遥控器的驾驶员蹲在办公室里操作啊……&lt;/p&gt;&lt;p&gt;算法始终只是工具，数据分析效果如何还是要看用工具的分析师功力如何。一个做过几十个分析项目的分析师，功力通常来说比刚入行的分析师或者纯开发人员要深厚一些（极少数天赋异禀的不算……），选算法调参数建模型的能力更强一些，分析出来的结果也会相对靠谱一些——没错，经验在这两个阶段就是优势。&lt;/p&gt;&lt;h2 style="font-size: 18px; margin-top: 16px; margin-bottom: 16px; padding-top: 10px; padding-bottom: 10px; line-height: 18px; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(238, 238, 238); color: rgb(68, 68, 68); font-family: &amp;#39;microsoft yahei&amp;#39;; white-space: normal;"&gt;&lt;strong&gt;&lt;span&gt;输出结论：&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;这一阶段计算机的工作已经基本完成了，对模型输出的数据进行解读，那完全是分析师的天下——同一份数据给不同的分析师，可能会得出不同的结论，很多时候分析师并不单单根据数据本身得出结论，还要结合很多外界因素来修正结论。分析师的经验越丰富，拥有的有效信息量越多，得出的结论就越接近事实（之所以用接近，是因为对数据解读的准确度永远达不到100%，影响结果的因素太多了，比如一个企业销售额连续增长10年，分析师根据公司数据和市场情况判断下一年还会继续增长，结果老板出事跑路了，企业直接倒闭），而这个过程是计算机目前没办法自主进行的，商业智能系统做的再好，也需要由分析师来设定规则，告诉计算机在什么时间需要做什么。&lt;/p&gt;&lt;p&gt;也许随着大数据和人工智能的发展，有一天计算机可以完全不依赖人工设定的规则（不需要确定数据来源，不需要选择算法和模型，不需要人工干预来修正模型，等等），自己对数据进行全方位的分析，加入所有因素的影响，并输出准确度非常高的报告，只有到那时候，分析师才会失业啊。&lt;/p&gt;&lt;p&gt;不过，真到了那一天，恐怕不光是分析师失业的问题吧……&lt;/p&gt;&lt;p&gt;&lt;strong&gt;一个成功的数据分析团队：角色与职责&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;多年以来我和数百家企业打过交道，在这个过程中，我领悟了让数据分析项目成功的一些因素，也亲眼看着很多项目失败。&lt;/p&gt;&lt;p&gt;最常见的失败原因说出来可能会让你惊讶。并非是缺乏数据专业知识或者整合失误，而仅仅是因为企业没有让“利用数据”成为任何人员的职责。太多公司花费好几个月收集有趣的数据，然后让它们静静地躺在角落里积攒灰尘。这个现象驱使我来撰写本文，希望它能给你灵感，让你为下一个分析项目增加一些结构性。 对分析的应用，本应该成为你不断汲取的商业泉源。&lt;/p&gt;&lt;p&gt;如果能为下列每个角色，找到至少一个乐于担当的人选，我保证你项目成功率会增加一千倍!对每个角色的具体描述和建议见下文。&lt;/p&gt;&lt;p&gt;*并未经过科学证实&lt;/p&gt;&lt;h2 style="font-size: 18px; margin-top: 16px; margin-bottom: 16px; padding-top: 10px; padding-bottom: 10px; line-height: 18px; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(238, 238, 238); color: rgb(68, 68, 68); font-family: &amp;#39;microsoft yahei&amp;#39;; white-space: normal;"&gt;&lt;strong&gt;&lt;span&gt;角色及其输出&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/jAqr3XzCYibyuickHrXHziaJNegTkAyxKIB8Qd3ib6tT5hKcg3icj7rwxqLRLNOyCN4k7SYByTx6AZqrViak0k1YjHjQ/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;h2 style="font-size: 18px; margin-top: 16px; margin-bottom: 16px; padding-top: 10px; padding-bottom: 10px; line-height: 18px; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(238, 238, 238); color: rgb(68, 68, 68); font-family: &amp;#39;microsoft yahei&amp;#39;; white-space: normal;"&gt;&lt;strong&gt;&lt;span&gt;项目领导者&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;有一个团队成员要负责分析工作的实施交付。你可能已经知道，一个高效的项目管理者要：&lt;/p&gt;&lt;ul style="margin-bottom: 16px; color: rgb(51, 51, 51); font-family: &amp;#39;microsoft yahei&amp;#39;; font-size: 15px; line-height: 25px; white-space: normal;" class=" list-paddingleft-2"&gt;&lt;li&gt;&lt;p&gt;识别项目的利益相关者，并搞清他们需要什么。这些人会问“我们要回答的商业问题是什么?”&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;设定并传达工作目标、范围和时间，落实到每个相关人员。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;管理项目所依赖的资源，发现交付过程中的障碍。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;确保项目如实交付、达成目标(例如，数据确实回答了对业务至关重要的问题)。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;确保每个相关人员，从工程师到产品经理，同步工作并理解要交付什么。这个部分比较重要，因为人们通常低估或高度数据的作用。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;对项目领导者的建议：&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;如果你专注于那些可以直接为产品或业务带来改变的问题，你的分析项目会得到最及时的反馈。例如：新的宣传活动带来的顾客是否转化为付费用户了(是否该继续在这个宣传渠道上继续投资)?或者，我们准备取消这个功能，你能否查看一下是否有付费用户在使用这个服务?&lt;/p&gt;&lt;p&gt;保证项目的规模尽可能小。一开始，只跟踪对于业务重要的少数几个关键行为，这样就能够快速回答最紧迫的商业问题(如，使用这个此功能的用户留存度如何?)及时的，有用的分析结果会让你所在的机构着迷，他们很快会提出更多你在下一轮要回答的问题。换句话说，分析工作应该是敏捷的，随着每次迭代更加深入。如果分析项目的规模太大(如，需要花费工程师两周时间)，那你可能冒着拖延其他紧急项目的风险。&lt;/p&gt;&lt;h2 style="font-size: 18px; margin-top: 16px; margin-bottom: 16px; padding-top: 10px; padding-bottom: 10px; line-height: 18px; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(238, 238, 238); color: rgb(68, 68, 68); font-family: &amp;#39;microsoft yahei&amp;#39;; white-space: normal;"&gt;&lt;strong&gt;&lt;span&gt;数据建构者&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;这个头衔听起来很炫，但它只是意味着你的团队需要有个懂技术的人创建数据模型，并理解查询语句如何工作。数据模型可以很简单，甚至像一封电子邮件，列出你要跟踪的行为和优先级。&lt;/p&gt;&lt;p&gt;这个模型有助于确定和传达你的项目范围。数据建构者帮助整个团队评估哪些业务问题可以被回答，哪些不能。通常这个人不必是数据科学博士，一般由一个app开发人员，或者懂得用电子表格建立模型的人担任。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;对数据分析者的建议：&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;花点时间让曾经使用过相同工具的人看看你的数据模型。例如，如果你在使用Keen，就跟使用过Keen的开发者聊聊。也可以让分析服务提供者和你一起审阅你的数据模型。不管你在使用什么工具，都会有些事情需要取舍，解决方案总有些部分不会按照预期工作。节省些时间，跟有过相同经历的人谈谈你的计划吧。&lt;/p&gt;&lt;p&gt;建立数据模型时，使用客户和业务领域的习惯用语，而不是应用开发者的习惯用语。例如，不要去追踪“阶段变化”，客户和你公司里的其他人无法理解它。如果能保证使用的语言是业务导向的，它会帮助你的机构/企业理解如何去查询和使用数据。&lt;/p&gt;&lt;p&gt;保证让至少一个人审阅你的数据模型，保证模型可被他人理解。你可能会发现有些对自己来说很直白的标签，对其他人来说并不清晰。比如，对于机构里的不同人员，“uuid”意味着不同的东西。&lt;/p&gt;&lt;p&gt;不要重复发明轮子(不要做无用功)。&lt;/p&gt;&lt;h2 style="font-size: 18px; margin-top: 16px; margin-bottom: 16px; padding-top: 10px; padding-bottom: 10px; line-height: 18px; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(238, 238, 238); color: rgb(68, 68, 68); font-family: &amp;#39;microsoft yahei&amp;#39;; white-space: normal;"&gt;&lt;strong&gt;&lt;span&gt;产品开发者&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;项目一开始，就要有至少一个开发人员承担埋点的工作。他们在各处加一些代码，这样每次登录、购买、上传和其他行为的数据都能被保存。如果事件的来源有很多，比如移动应用+网页，这个工作可能由多个开发者完成(如，一个网站开发者和一个移动开发者)。在小一些的机构，埋点的开发者通常也扮演数据建构者。在大一些的团体中，开发者和数据建构者紧密合作，确保模型数据足够理想，以及事物被跟踪并以一致的格式标记(如“user.id” = “23cv42343jk88” 不是 “user.id” = “fran@cooldomain.com”)。埋点是个相对直接的过程，许多分析服务有直接可用的客户库使得此过程简化，不过，你的团队依然需要决定要跟踪什么行为，如何命名。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;对产品开发者的建议：&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;确保根据对你的机构有意义的数据模型进行埋点。如果你的团队没有数据建构者，那么就扮演这个角色，在开始埋点之前规划一个模型。这会帮你理清思路，也更利于与他人沟通。&lt;/p&gt;&lt;p&gt;使用分开的repository，带有各自的key，针对dev, test和prod，这样就不会让生成数据和测试数据混淆。&lt;/p&gt;&lt;p&gt;埋点成功后，在正式使用前找个人审阅一下存进来的数据。和产品的其他功能一样，分析的实施也需要有个QA过程。埋点过程中错误很常见，如，把数字发送为字符串、命名不清、不正确地使用JSON的格式，或者标签里有错别字。&lt;/p&gt;&lt;h2 style="font-size: 18px; margin-top: 16px; margin-bottom: 16px; padding-top: 10px; padding-bottom: 10px; line-height: 18px; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(238, 238, 238); color: rgb(68, 68, 68); font-family: &amp;#39;microsoft yahei&amp;#39;; white-space: normal;"&gt;&lt;strong&gt;&lt;span&gt;分析者&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;你会收集很多有意思的数据，但如果没人利用，这些数据就不会有价值。团队里需要至少有一个人对数据背后隐藏的东西非常好奇。我把这些人称为分析者。分析者通常是个开发者、产品经理或产品团队/营销团队的某个人。这些人不仅疯狂地想了解业务问题的答案，还能时时提出新问题。分析者喜欢钻研项目第一阶段收集的数据，而且有很多点子，引出下一阶段应该收集的新东西。换句话说，团队中需要有个人享受实践分析的过程。不要着急，这样的人有很多:)。技术背景对这个角色有很大帮助，这使得他们能快速理解什么样的查询语句可以得到想要的答案。&lt;br/&gt;这个角色对于项目成功至关重要，如果没人从数据中理解、学习，就无法从中得到任何价值。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;对分析者的建议：&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;分析的结果可能对你自己而言显而易见或很有意义，但别人看来可能不是这样。这是因为你从一开始就知道要回答什么问题。你知道数据包含哪些不包含哪些。此外你写的查询语句最终生成了可视化结果或报告。要让他人理解最终得到的数字都意味者什么，那么你要分享很多上下文内容给他们。&lt;/p&gt;&lt;p&gt;分享分析的结果时，需要写明你从数据中得到的结论，以及根据分析结果应该采取什么业务行动(如，上个版本发布后我们的转化率下降了，所以应该改回去)。其他人可能不仅没有正确解读数据所需的上下文，他们也很可能不像你那样感觉数据很迷人，且没时间去试图理解其意义。&lt;/p&gt;&lt;p&gt;不要用力过猛，不过，对于这个岗位来说沟通技巧很重要。分析者大约半数的时间都用在了沟通上。解释与总结从数据中获得的结论、结果需要花点时间。如果你的分析结果不能只是静静躺在别人的收件箱里。有些你是机构里唯一意识到某个机会或问题的人，应该确保机构对机会或问题有所反应。有时你得做那个难搞的人。不要低估自己工作的价值。&lt;/p&gt;&lt;p&gt;如果分析工作是你常常要做又来不及做的，试着把它加入你官方的职位描述中，每周或每月贡献固定时间在上面。不要让它干预你的其他时间。&lt;/p&gt;&lt;h2 style="font-size: 18px; margin-top: 16px; margin-bottom: 16px; padding-top: 10px; padding-bottom: 10px; line-height: 18px; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(238, 238, 238); color: rgb(68, 68, 68); font-family: &amp;#39;microsoft yahei&amp;#39;; white-space: normal;"&gt;&lt;strong&gt;&lt;span&gt;报告制作者&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;这个角色不是必需的，但你可能会想要制作一些报告，便于整个团队和其他利益相关者获取。要想让数据的实用性会大大提升，数据应该更紧密地与业务流程相连，而不是被遗弃在数据库里等着有人翻阅。一个前端开发者要能够把query变成产品经理和其他业务人员阅读的报告。下面是一些可能有用的例子：&lt;/p&gt;&lt;ol style="margin-bottom: 16px; color: rgb(51, 51, 51); font-family: &amp;#39;microsoft yahei&amp;#39;; font-size: 15px; line-height: 25px; white-space: normal;" class=" list-paddingleft-2"&gt;&lt;li&gt;&lt;p&gt;Email寄送周报&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;内部网站的一个页面&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;在面向用户的app中&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;用Google表格公开发布&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;推送到slack频道&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;在某个面板上展示&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;推送到salesforce&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;strong&gt;对报告制作者的建议：&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;确保报告的使用者能理解数据才能让你的工作产生最大价值。一个办法是，不断问他们“当你看到转化率5.2%时，这对你来说意味着什么?你会认为它是怎么计算出来的?”&lt;/p&gt;&lt;p&gt;另一种提高报告可读性的方式是写一份指南(如注释)，以解释数据从何而来、如何被计算。例如，数据是否包含从网站和app获取的用户，或只是来自其中一种的用户?它是否包括测试用户和公司的内部用户，或者他们已经被过滤掉了?&lt;/p&gt;&lt;p&gt;玩得开心点!整个分析项目中最棒的部分，就是看着有人因为从结果学到了新东西而双眼放光，而你，通常就是让这一切发生的人。&lt;/p&gt;&lt;p&gt;本文由 知乎 陈丹奕授权发布。&lt;/p&gt;&lt;p&gt;End.&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 21 Sep 2016 09:44:21 +0800</pubDate>
    </item>
    <item>
      <title>传统业务如何互联网+</title>
      <link>http://www.iwgc.cn/link/2774496</link>
      <description>&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/jAqr3XzCYibyuickHrXHziaJNegTkAyxKIBM4xhicybYOzQGrEYBLNnhjZSHJtCSiaAyrTsdvEVoPgtSFDLIKvMUevA/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;作者：Jiaxing&lt;/p&gt;&lt;p&gt;本周，我想兑换一张国航机票。&lt;/p&gt;&lt;p&gt;通过国航APP搜索，订票时它说我名字不是中文，这个错误是之前国航会员和凤凰知音会员帐户合并时产生的，它错误地把我的护照拼音名字合并到了会员帐户，并且还不允许我修改。此前在柜台办理值机时工作人员就给我说有问题，后来我添加了一个乘机人，每次买票都要重新选一次，总算让登机牌打印上了中文名字。&lt;/p&gt;&lt;p&gt;这次影响到了我的兑票，就必须联系凤凰知音修改了。经过5~6次提示语“现在路线正忙，请您耐心等待”之后，接线员给我说必须通过邮件形式发送修改信息和身份证照片到凤凰知音VIP邮箱，三个工作日内可以修改。根据接收的短信，我发了一封邮件。&lt;/p&gt;&lt;p&gt;等到第三天，我的名字还是拼音。经过再次尝试APP兑换，我发现界面虽然不能改名字，但可以改证件，选择通过护照购买，输入护照号码，然后收到“系统繁忙，请您稍后再试”的提示语。每一次“再试”我都得重新输入一次密码，每次重新兑换我都得重新选择城市、选择日期、搜索机票、修改为护照、输入护照号码、输入密码，为了一张￥1500元的机票，我也是蛮拼的。最后还是“系统繁忙”。&lt;/p&gt;&lt;p&gt;今天，我决定通过国航网站再试一试。哇，这次顺利地进入了兑换界面，并且网页上是可以自行输入姓名身份证号码!激动地进入最后的支付界面，它告诉我找不到兑换承让人……&lt;/p&gt;&lt;p&gt;最后一招是拨打客服电话。先试图进入贵宾会员菜单，不幸不被识别为贵宾。转里程兑换菜单，耐心等待了一次提示音，不到十分钟声音甜美的客服MM就帮助我办理完了机票兑换，密码输入、税费支付全部通过电话按键完成。办完后我问了一句：“为什么通过APP和网站办理不了兑换呢?”客服MM耐心地回答说：“那是因为系统太过繁忙。”又追问了一下我的信息修改进度，客户MM首先表示没有看到有邮件往来记录，然后询问了我的邮箱地址，表示未收到邮件，让我再发一次。只得作罢，挂了电话才记得是用另一个邮箱发的……&lt;/p&gt;&lt;p&gt;与此相似的经历，是办理移动业务，我也偏爱拨打10086——因为“移动营业厅”界面的复杂程度直接把我吓退了。好在没浪费我什么时间。&lt;/p&gt;&lt;p&gt;这些业务的共同特点是，流程较为固定，用户的目的性很强，而不像一般的互联网消费品那样，需要大量浏览、对比和决定。我们喜欢在电商网站中面对着各种图片、评论长时间地浏览，但经常在传统业务的办事大厅头就开始眩晕。&lt;/p&gt;&lt;p&gt;于是我开始分析：对比网站甚至APP，简单地拨打数字 + 对话操作的方式无疑是最优的;即使反复等待接线员，最后处理的效率还是高于当下的互联网端。这是因为，输入数字比查找信息快捷，传统企业又很擅长和客户通过短信互动，就算没有记录，号码也可以轻易地从近期短信中找到;客服具备专业性，同样的操作，远远比用户高效，后台系统“繁忙”程度也远远低于外网……&lt;/p&gt;&lt;h3 style="border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(238, 238, 238); margin-bottom: 16px; color: rgb(68, 68, 68); font-family: &amp;#39;microsoft yahei&amp;#39;; line-height: 25px; white-space: normal;"&gt;&lt;strong&gt;我们需要一个什么样的传统业务互联网产品?&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;有比输入电话号码更好的方式吗?&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;简单设计：比如用“里程换票”、“购票”这样气泡代替一个接一个子菜单，携程和去哪儿网的界面在这方面做得不错，虽然美观上还有待提升。做得最好的之一，我认为是Apple Music的初始界面。&lt;/p&gt;&lt;center style="color: rgb(51, 51, 51); font-family: &amp;#39;microsoft yahei&amp;#39;; font-size: 15px; line-height: 25px; white-space: normal;"&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/jAqr3XzCYibyuickHrXHziaJNegTkAyxKIBeHsgibGco4mMvEb2bguGzQ5v2ZJ932lCLahqWTBmbHFkh9yyVzNqCaA/0?wx_fmt=jpeg"/&gt;&lt;/center&gt;&lt;p&gt;&lt;strong&gt;能不能更多采用语音交流?&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;既然客服交流体验这样好，为什么不采用语音技术来做呢?在这个领域，还是Apple的Siri领先了。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;记住用户的选择?&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;看看我之前噩梦一样的反复输入吧，为什么APP就不能聪明一点，有一点记忆能力呢?谁也不愿意被“白痴”服务吧。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;成为服务专家?&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;对于传统企业，买完产品看服务，我们需要的是专业的服务人员，而不是仅仅给用户开一个自助服务的新渠道完事。&lt;/p&gt;&lt;h3 style="border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(238, 238, 238); margin-bottom: 16px; color: rgb(68, 68, 68); font-family: &amp;#39;microsoft yahei&amp;#39;; line-height: 25px; white-space: normal;"&gt;&lt;strong&gt;那么，做这些事需要什么样的技术?&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;一流的体验设计师&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;记住，这是企业全新的产品线，请按照产品建设来进行投资，而不是随便搞一个网页。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;语音技术&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;语音识别有一些技术壁垒，对企业来说，当前可以考虑一些商业产品，重心放在业务设计上。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;数据分析&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;通过数据来认知用户的特点，进行细分，从而优化自己的产品。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;云平台化&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;无论是解决“系统繁忙”的问题，还是支撑更多样的用户体验，更快速的数据分析，都离不开平台的支撑，否则，一切都只有从零开始。云计算将硬件资源虚拟化变为可按需使用，而云平台解决了不少系统架构的难点：扩容、高可用以及运行状态监控，通过云服务商的产品线完善，更是将软件的复用程度从包、组件提升到了应用程序级别。&lt;/p&gt;&lt;p&gt;基于云平台进行产品开发，将会大大提速传统企业进入互联网+时代，先行者甚至可以构建出自己的行业云，一举反超过去的巨头，这也是当今传统IT领域最至关重要的转型点。&lt;/p&gt;&lt;p&gt;End.&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 21 Sep 2016 09:44:21 +0800</pubDate>
    </item>
    <item>
      <title>创业 | 人人都在说大数据，那么大数据行业创业的方向是什么?</title>
      <link>http://www.iwgc.cn/link/2759204</link>
      <description>&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/jAqr3XzCYibx7yzFvYWf2FnSq0ckztibKcg82SZ0c9MVTbvpQz8HEArATPSDE9M44icMXSCxLjhroF2TA4rc7nFVg/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;作者：王峰&lt;/p&gt;&lt;p&gt;本人目前在A从事2B的大数据解决方案与产品设计工作，以大数据商业化为目标，各行业客户都有，简单跟大家分享下我们目前的大数据落地实操经验。&lt;/p&gt;&lt;h3 style="border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(238, 238, 238); margin-bottom: 16px; color: rgb(68, 68, 68); font-family: &amp;#39;microsoft yahei&amp;#39;; line-height: 25px; white-space: normal;"&gt;&lt;strong&gt;一、厚积薄发：谈谈BAT平台优势&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;大数据这块做的好的平台， 就个人来看，A算做的不错了，从云计算的布局到大数据，步步为营，也是筚路蓝缕。大公司的优势在于三个字，熬的起。业务几乎都是以平台、生态的构建为目标，最终是enable别人成功，并从别人成功中获益的模式。&lt;/p&gt;&lt;p&gt;在这个过程中，有4点优势会体现出来：&lt;/p&gt;&lt;p&gt;&lt;span&gt;电商行业能力通过云计算炮台对外部输出。&lt;/span&gt;这块之前我还存在一定的误区，认为电商行业的经验固然重要，但是真正实操应用其他行业的时候，可能失效。这块关键的是视野、思路、方法论。&lt;/p&gt;&lt;p&gt;比如电商沉淀下的大数据管理、用户标签体系设计、流计算/实时计算的场景与应用、个性化推荐的策略等等，当遇到类似场景的时候，你会心领神会的借鉴当初的思路，去帮助其他行业解决，去探索。填充了你的弹药库，而不是两眼一抹黑的干。&lt;/p&gt;&lt;p&gt;另一方那面，电商行业的成功经验，能够让我们快速从中抽取与提炼核心组件与模块，快速产品化，在大数据的平台首页 - 数加平台上架官方的大数据产品，冷启动数据市场，比如我们的推荐引擎、DataV可视化引擎、数据开发工具、机器学习平台，这些原来都是内部用户的，或者电商用的，现在拿出来，让其他行业用，能够快速抢占市场，占位。&lt;/p&gt;&lt;p&gt;&lt;span&gt;云计算的长期积累，夯实了IAAS与客户基础。&lt;/span&gt;通常意义上，我们内部对大数据路线有个约定俗成的三字经“存-通-用”，做大数据、大数据首先要有数据，阿里云多年积累已经夯实了IAAS层，为后续的大数据业务一方面提供成型的基建如ECS、OSS、OTS、ADS等等，可以说很好的解决了“存”的问题。&lt;/p&gt;&lt;p&gt;另一方面，多年积累的客户，在IAAS温饱满足的同时，有客户特别是头部的大B客户越来越多涌现比如如何用好数据、加工数据、用数据助力业务的诉求，这就给大数据业务的开展带来了机会。&lt;/p&gt;&lt;p&gt;&lt;span&gt;“丁”字型的人才储备深度，在业务快速发展阶段能够相互补位。&lt;/span&gt;一般业务刚兴起时缺人比较严重的首先是前端、其次是产品，然后是数据、算法，待到技术可行的阶段，就是销售。大公司的人才储备，特别是复合型的人才，能够为新兴业务发展快速注入新鲜血液，并通过转岗机制确保良性兼容，老人做新业务，非常高效。&lt;/p&gt;&lt;p&gt;&lt;span&gt;品牌影响力在业务拓展上的助力。&lt;/span&gt;这块并非绝对，当然很多场合下，阿里巴巴这个品牌本身就是实力、信誉的保障。今天我们对外输出大数据能力的时候，很多时候确实也利用到了这块的影响力，毕竟数据业务本身是一个公司的核心资产，对乙方都需要在技术与商业道德上进行双重考量，所以很多号称“第三方独立”数据服务公司也就浮出水面，一方面中立的身份，另一方面依赖或者嫁接多平台，不绑死。&lt;/p&gt;&lt;h3 style="border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(238, 238, 238); margin-bottom: 16px; color: rgb(68, 68, 68); font-family: &amp;#39;microsoft yahei&amp;#39;; line-height: 25px; white-space: normal;"&gt;&lt;strong&gt;二、他山之石：看看A现在是怎么做大数据的&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;我们从商业层面去做大数据业务，通过商业来拓展技术的边界，同时也让客户认可价值，并买单，从而变现。更准确的讲，我们现在不是做大数据变现，而是做的大数据能力变现，将我们在人工智能、数据管理、数据应用的框架、引擎去帮助客户解决具体的业务问题，帮客户用好自己的数据是第一要务，然后才是用别人的数据补充自己，最后才是用自己的数据服务别人。我们看几个典型的场景：&lt;/p&gt;&lt;p&gt;&lt;span&gt;case 1：服务某互联网创业公司&lt;/span&gt;&lt;/p&gt;&lt;p&gt;互联网公司一般跑的比较快，特别是业务，很多时候初期是堆人、砸钱来堆用户数、订单等，技术外包比较常见，特别是当前环境。理所当然，这块也带来了大数据业务的机会，比如在020外卖场景下，如何分配好订单，使得运力的利用率最大化，同时在指定时间内能满足叫单需求。&lt;/p&gt;&lt;p&gt;这类业务可以说之前就没出现过，也几乎没多少人工运营的经验，很多时候运营就是凭直觉也好，或者所谓的经验也好，来派发订单。&lt;/p&gt;&lt;p&gt;我们的机会点在于：虽然这是对方的核心业务，但是总这块内容需要人，一时半会招不到人，同时不做这块业务，每天会有大量的补贴在补贴运力与处理投诉，是很大一笔开支，从这两点考虑，是不是该做?&lt;/p&gt;&lt;p&gt;&lt;span&gt;case 2：服务某传统技术型公司&lt;/span&gt;&lt;/p&gt;&lt;p&gt;该公司技术县先进，能够进行快速实景的3D建模，但是有个“最后一公里” 的问题非常致命，现有的重绘技术比较落后，需要2-3天才能重新根据大量测绘数据绘制出3D模型，不及时，使得应用的场景受限。能否将原来绘制时间由天级别缩短到小时级别甚至分钟级别?从而拓展应用场景，更好的进行商业化?&lt;/p&gt;&lt;p&gt;&lt;span&gt;case 3：服务某传统制造业企业&lt;/span&gt;&lt;/p&gt;&lt;p&gt;客户是世界最大的某材料生产企业之一，日产千万件，每件根据质量划分不同的等级，不同的等级价格不同，而良品率的提升直接与收益挂钩，客户已经具备初步的数据采集能力，但存储的数据未开发，也带来不小的存储成本，生产流程靠经验或理论，没有快速优化与验证的闭环，如何利用现有数据，提升良品率优化生产线?去低效产能的同时，赋能“智”造! ?&lt;/p&gt;&lt;p&gt;可以看到，目前的玩法并不是通常意义上大家理解的精准营销、广告、人群画像，或者输出一份分析图表的大数据，而是从客户的问题出发，并且直接影响到生产或者业务效果的落地，让客户认可我们的价值，从而来商业化。&lt;/p&gt;&lt;h3 style="border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(238, 238, 238); margin-bottom: 16px; color: rgb(68, 68, 68); font-family: &amp;#39;microsoft yahei&amp;#39;; line-height: 25px; white-space: normal;"&gt;&lt;strong&gt;三、围三缺一：现阶段大数据业务下的BAT目前缺什么&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;一般而言，作为平台方位保障公平，我们不会既做裁判员、又做运动员，大部分情况下，平台做提供的是通用型的产品、基础性的服务，留出二次开发、增值开发的空间，enable别人成功。&lt;/p&gt;&lt;p&gt;当然现阶段为了更好的启发市场，平台方需要自己做出标杆，告诉大家怎么做，从而揭竿而起，期望应者云集，基于我们的云平台来创新、创业。在这个框架下，有几点痛点：&lt;/p&gt;&lt;p&gt;&lt;span&gt;缺技术型人才，&lt;/span&gt;我们挖掘的场景很多，技术需求量比较大，比如算法、比如前端、可视化设计等，我们缺合格靠谱的技术型ISV来与平台共建、分成。&lt;/p&gt;&lt;p&gt;&lt;span&gt;大数据的商机很多，我们缺少那些熟知某领域关键问题的合作伙伴&lt;/span&gt;，给平台带来商机与挑战，给平台提需求，让平台帮你成功。&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于平台现在提供的产品与服务，我们缺强力的合作伙伴，&lt;/span&gt;能够挖掘现有产品的业务价值，在其他行业上能够给用起来，能够进行二次开发，能够增值，一起赚钱。&lt;/p&gt;&lt;p&gt;&lt;span&gt;缺数据，&lt;/span&gt;对于有任何数据沉淀的合作伙伴，我们都欢迎一起坐下来聊聊，共同开发数据价值，服务云上客户。&lt;/p&gt;&lt;p&gt;对于平台暂时无法满足一些行业垂直类需求，我们期望能够联合这方面有突出能力的合作伙伴一起打单，在阿里云2B的大数据解决方案中，也会有这些ISV的一席之地。&lt;/p&gt;&lt;h3 style="border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(238, 238, 238); margin-bottom: 16px; color: rgb(68, 68, 68); font-family: &amp;#39;microsoft yahei&amp;#39;; line-height: 25px; white-space: normal;"&gt;&lt;strong&gt;四、创业机会&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;分析到这，差不多也比较明确，创业者的机会抓住以下几点关键词：独立第三方、基于云、补生态，再明确下：&lt;/p&gt;&lt;p&gt;&lt;span&gt;(1) 从生态视角来看&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;技术合作伙伴&lt;/strong&gt;：可以基于云，帮忙卖平台的成品(渠道)、可以基于平台的服务或者产品二次加工再卖(增值服务)，可以做自己独立的产品(合作共建)，配合平台一起打单。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;人力合作伙伴&lt;/strong&gt;：可以是三五个人，无论是算法还是数据能力，基于我们的阿里云大数据众智平台，接活。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;数据合作伙伴&lt;/strong&gt;：将自身无论通过哪类渠道沉淀的数据，通过平台提供的产品，对外输出，进行变现。借助平台的力量帮助变现。&lt;/p&gt;&lt;p&gt;&lt;span&gt;(2)从大数据本身来看&lt;/span&gt;&lt;/p&gt;&lt;p&gt;如果我们不看生态，或者不依赖平台，当然也可以，我个人对大数据业务或者说大数据产品的判断：&lt;/p&gt;&lt;p&gt;&lt;span&gt;大数据产品 = 数据 + AI + 传达&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;数据&lt;/strong&gt;：产品/系统需要的数据，可以是客户的，也可以是产品自带&lt;/p&gt;&lt;p&gt;&lt;strong&gt;AI&lt;/strong&gt;：人工智能、算法、模型、统计、处理逻辑等&lt;/p&gt;&lt;p&gt;&lt;strong&gt;传达&lt;/strong&gt;：呈现、界面、服务方式、可视化等&lt;/p&gt;&lt;p&gt;对于不同的创业者，就看你主打的是哪一块，不同的创业方向在这三块有不同的打法与侧重，对于我个人而言，我会主攻AI，另外的两部分视情形而定。也就是用AI/大数据能力，形成服务壁垒，从而进行变现。&lt;/p&gt;&lt;h3 style="border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(238, 238, 238); margin-bottom: 16px; color: rgb(68, 68, 68); font-family: &amp;#39;microsoft yahei&amp;#39;; line-height: 25px; white-space: normal;"&gt;&lt;strong&gt;五、几点建议&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;建议先2B，2C的数据用起来很麻烦，很多时候甚至都缺失，更不用谈加工、变现。&lt;/p&gt;&lt;p&gt;选择一个出油的行业，先在一个行业下做出1、2个客户，然后沉淀框架与产品，然后打爆一个行业/子行业，然后再考虑延展性。没有深度的服务能力很多时候是做不出效果与爆点。&lt;/p&gt;&lt;p&gt;&lt;span&gt;基础数据服务化，行业应用智能化&lt;/span&gt;。公司在对外提供服务的时候，如果是基础类的服务，请将数据做成在线，可计量计费，跑量，以量取胜，当然如果这类服务还自带吸数据的属性，那就完美了比如风控接口。如果提供的是行业智能化/算法类项目，走价，做出溢价，比如panlantir。&lt;/p&gt;&lt;p&gt;无论做什么，一定要在初期就要立足产品化的目标，用产品去打。产品的抽象与沉淀过程，意味着你的目标与方向，这点没想明白就不要做了。&lt;/p&gt;&lt;p&gt;&lt;span&gt;请讲清楚定价，定价是反应你对市场了解的唯一标准，甚至是检验产品的重要属性，定价过程反映了业务模式与打法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;做好商务工作，大数据业务本来就是技术类的产品，好的商务可以帮你快速弥补产品与客户之间的GAP，不仅仅是演示，更需要舌灿莲花，更需要从客户的视角来验证我们产品对他们的重要性。&lt;/p&gt;&lt;p&gt;End.&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 20 Sep 2016 10:05:05 +0800</pubDate>
    </item>
    <item>
      <title>运营 | 剖析用户生命周期和价值</title>
      <link>http://www.iwgc.cn/link/2759205</link>
      <description>&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/jAqr3XzCYibx7yzFvYWf2FnSq0ckztibKcBZT3FBh9Ne057dZ2I3W4mV606LccSibicQYlCGoiaKu627YQZhAN9amYw/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;作者：秦路&lt;/p&gt;&lt;p&gt;做运营，我们常会听到用户生命周期的概念。&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;传统营销学上讲得是客户生命周期(CL：Customer Lifetime)管理。对互联网运营，我更倾向用户生命周期的说法。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;传统公司怎么管理客户生命周期呢，我们生活中遇到的很多营销手段，都可以归纳到这个范畴。不定期收到的各类促销信息、商场消费后拿到的满减券、航空公司的里程数、售后维护等等。&lt;/p&gt;&lt;p&gt;一切的手段都是为了延长客户的消费周期。你去菜场买一把菜，末了老板王二麻再送你一把葱，说：下次记得再来，都可以算。&lt;/p&gt;&lt;p&gt;互联网公司，客户在广义上变为用户，用户生命周期就是今天的话题。&lt;/p&gt;&lt;p&gt;用户生命周期管理是一个很大的话题，用户从第一次使用APP，到最后一次打开的时间，我把它定义为用户生命周期。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;运营角色一直贯穿整个生命周期，在新用户还没有注册前，就寻求媒体曝光、渠道推广和活动营销、哪怕在卸载APP后，同样会用尽手段希望唤回用户，例如老用户回馈，邮件推送社交好友动态等。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;很多文章都会通俗的解释说，运营就是让用户留下来，没错，但是它漏了后半句话。&lt;/p&gt;&lt;h3 style="border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(238, 238, 238); margin-bottom: 16px; color: rgb(68, 68, 68); font-family: &amp;#39;microsoft yahei&amp;#39;; line-height: 25px; white-space: normal;"&gt;&lt;strong&gt;让用户留下来，并且赚钱&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;用户生命周期价值CLV(Customer Lifetime Value，也有称LTV：Life Time Value)比生命周期更重要。让用户能在生命周期中产生商业价值，才是运营的使命。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;这里的商业价值，不单纯是电商广告游戏等赚钱模式。信息和数据这些无形且很难量化的也是商业资产。&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;运营的目标就是尽一切可能延长用户的生命周期，并且在生命周期中尽一切可能产生商业价值。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;用户商业价值CLV会不断累加，生命周期CL会不断减少。期间又能划分成新增期、成长期、成熟期、衰退期、流失期等。这里就不深讲，主要讲与运营结合。&lt;/p&gt;&lt;p&gt;为什么要谈用户生命周期和价值?因为做运营不得不接受的事实是，无论你是多么出色的运营，都无法真正制止用户的流失(流失的概念，可以看这篇文章拓展阅读)。你可以延长它，但就是不能阻止它。&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;当产品获得足够多的用户时，最大的问题不是继续获取，而是从用户身上赚回钱。成熟的产品都应该考虑CL，以及更重要的CLV。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;菜场首席运营官王二麻同志，他每次在你买菜后送一把葱，不是看你可爱帅气(虽然关注我文章的确实都很可爱帅气!)，而是希望下一次顾客仍旧去他那里买菜。这是打感情牌。&lt;/p&gt;&lt;p&gt;送一把葱才多少钱，可只要送的葱足够多，哪怕让10%的顾客有好感下次仍去他那里买菜，王二麻就能把钱赚回来。王二麻都有这个运营意识，人人都是运营的口号应该喊出来了。&lt;/p&gt;&lt;p&gt;只要用户能用产品更长时间，就有更大的可能赚钱。CL和CLV是基的不能再基的关系。&lt;/p&gt;&lt;p&gt;有些特殊的商业形态，获利周期极短或者只有一次，比如婚庆，比如微商，反正我是没见过傻的再买第二次的人了。这时没有CL。&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;这里引出运营的终极公式之一：赚钱=CLV(用户生命周期价值)-CAC(获客成本)-COC(运营成本)&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;(整个公式是运营体系的框架之一，另外两个指标以后会写)&lt;/p&gt;&lt;p&gt;运营是互联网商业变现的落地和执行者。不同产品不同商业模式，用户的CLV也会差异很大。比如电商的CLV由一系列购买的指标决定，新媒体和门户的CLV由广告和曝光量指标决定，游戏的CLV则是土豪玩家这个群体。&lt;/p&gt;&lt;p&gt;一个合理的CLV模型应该是综合考量各种指标和数据建立起来的。&lt;/p&gt;&lt;p&gt;一款产品若没有探索出合适的商业模式，CLV模型很难搭建起来。需求低频，或者变现周期漫长，则计算一样不准确。&lt;/p&gt;&lt;p&gt;用户生命周期则比CLV更容易理解和计算。&lt;/p&gt;&lt;p&gt;我们通常说的留存率，就是用户生命周期的杀手锏应用。通过留存率，我们分析出用户的黏性、活跃度等指标。但留存率很难和商业挂钩，不具备商业的可解释性。我们就会换算成生命周期。&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/jAqr3XzCYibx7yzFvYWf2FnSq0ckztibKcGMjmPPZ2UtbSpJsPYJB8eymjQjYxDZU2hGFEcsWB59ycbKLrwib6ZUQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;h3 style="border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(238, 238, 238); margin-bottom: 16px; color: rgb(68, 68, 68); font-family: &amp;#39;microsoft yahei&amp;#39;; line-height: 25px; white-space: normal;"&gt;&lt;strong&gt;用户生命周期=周期/(1-周期内新增留存率)&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;如果一款产品新增用户的月留存率是70%，那么估算出：平均用户生命周期=1个月/(1-70%)=3.3个月。&lt;/p&gt;&lt;p&gt;运营的目标就是延长用户生命周期从3.3个月到4个月、5个月乃至更长。并且在此期间产生商业价值。对于大部分产品，这个公式都是适用的。&lt;/p&gt;&lt;p&gt;如果这个产品低频，例如旅游类产品，普通人不可能频繁旅游，那么数据上留存率就不会特别好看。这时的估算会有偏差，可以拓大时间维度。&lt;/p&gt;&lt;p&gt;如果需要更精准的指标，则可以将数据制作成频数分布图。&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/jAqr3XzCYibx7yzFvYWf2FnSq0ckztibKchUe6UkTkWq3M2Z6UWTUE9mTYCv5u3tJFSNVoKumkiaThbibN7w8xMYlw/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;来看看怎么精准的分析和运营：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1.用户生命周期最少的那部分用户，例如10天，有什么具体特征，为什么不用?&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2.用户生命周期最多的那部分用户，有什么特点?&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3.分布人数最多的用户，怎么样能想办法抓住他们的痛点?延长他们生命周期&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;4.究竟是用的久的用户(二八理论)，还是分布人数最多的用户(长尾理论)，产生的商业价值大?&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;每个用户的生命周期都能产生商业价值，但有些用户注定更有价值。&lt;/p&gt;&lt;p&gt;用户生命周期和流失是息息相关的，用户流失，便是用户生命周期的终止。&lt;/p&gt;&lt;p&gt;用户不用APP，可能是比较忙，可能是出去旅游了，可能是大姨妈来了心情不好。那么运营应该怎么判定他是上述情况，还是卸载不用呢?也许我们需要几个月后才会发现用户最后登录停留在某一天。高级运营和初级运营的分水岭在于：&lt;span&gt;&lt;strong&gt;初级运营经常事后补救，高级运营能够防范于未然。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;将用户的流失可能扼杀在萌芽阶段，是延长用户生命周期的有效手段之一。这听起来很玄乎，但举个例子就会明白的。&lt;/p&gt;&lt;p&gt;一款社交应用，通过流失用户的特征分析。发现了如下的几个特点。&lt;/p&gt;&lt;ul style="margin-bottom: 16px; color: rgb(51, 51, 51); font-family: &amp;#39;microsoft yahei&amp;#39;; font-size: 15px; line-height: 25px; white-space: normal;" class=" list-paddingleft-2"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;流失用户中，40%的用户没有完善资料&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;新增用户没有导入通讯录好友，流失概率比导入的高20%&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;新增用户在第一周使用中，如果添加的好友低于3，则一个月后的流失概率超过一半&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;用户流失前一个月，互动率远低于APP平均值。&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这些特征很容易读懂了解，运营也很容易针对性的采取策略。例如良好的新手引导、引入好友推荐(想想微博和各兴趣向APP)、增加曝光量、乃至使用机器人(这里有几个好玩案例，以后分享^ ^)等等。&lt;/p&gt;&lt;p&gt;如果数据化运营更彻底，可以运营和数据分析结合，将上述的特征建模，得出一个比较准确的流失概率预测。用模型计算出某一类人群流失概率在80%以上，和知道什么样的人可能流失，在运营上是两个层次。&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;我们可以构建决策树模型，因为决策树模型的可解释性强，它是if-then的集合，运营非常容易理解。比如用户完善资料低于50%，且没有导入通讯录好友，且好友数量低于3，则其一个月后的流失概率为80%。模型训练出叶节点，运营用SQL就能跑出来可能流失的用户群。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;另外，发掘出变化性变量在运营中有奇效。比如完善资料，是否导入通讯录好友，都是静态、状态型的特征，更多是产品上的优化。&lt;/p&gt;&lt;p&gt;但是某一类用户流失，能通过其他数据特征体现，比如上周打开了APP20次，本周打开了5次，下周打开了1次，趋势是下降的，这绝逼是累感不爱了啊!(趋势上升是另外一种运营策略了)这时我们运营就可以采取温暖的爱的抱抱，运营这类用户。&lt;/p&gt;&lt;p&gt;写到这里，突然觉得自己很温暖。虽然运营们营销，推送，喜欢从用户身上赚钱，但是我知道我们是好运营。&lt;/p&gt;&lt;p&gt;Tips：&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="list-style-type: decimal;"&gt;&lt;li&gt;&lt;p&gt;用户生命周期运营实际会更复杂，比如真正产生商业价值的群体应该去计算运营和分析，需不需要引入CRM，RFM等等，比如常见的积分体系能不能提高CL。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;本文由&amp;nbsp;&lt;span&gt;微信公众号：秦路 授权发布。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;End.&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 20 Sep 2016 10:05:05 +0800</pubDate>
    </item>
    <item>
      <title>分享 | 中小企业如何搭建数据分析平台?</title>
      <link>http://www.iwgc.cn/link/2759206</link>
      <description>&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/jAqr3XzCYibx7yzFvYWf2FnSq0ckztibKc0W60DJH3GqRC1QCaoTRr5yHUxceU4AjiamiaLdfmh9IGUhI8Dej5YwDg/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;作者：纳元罗斯&lt;/p&gt;&lt;p&gt;&lt;strong&gt;在信息化建设方面，中小企业不同于大型企业规范的项目管理，由于人员、财力、管理的局限性，很多地方需要做不同的预算和管理，有着自己适用的方案和体系。&lt;/strong&gt;关于中小企业该如何搭建企业数据平台，这里分享永银文化的建设经验，原文永银文化CIO周苏东在帆软百城巡展上的演讲。&lt;/p&gt;&lt;p&gt;&lt;span&gt;关于永银文化&lt;/span&gt;&lt;/p&gt;&lt;p&gt;永银文化主要从事钱币、邮票、贵金属的业务，在文创的基础上做一些产品的开发和整合。依附强有力的银行渠道，礼品渠道，以及京东、天猫、苏宁易购等电商渠道，对全国市场做深入的销售。&lt;/p&gt;&lt;p&gt;虽然在渠道上形成了一个三驾马车的相对均衡的态势，但实质上依附于一个独立市场。当市场形势变化，无法预测时就会处于一个被动的局面，这样的被动体现在以下四方面。&lt;/p&gt;&lt;p&gt;&lt;span&gt;1、体系缺失&lt;/span&gt;&lt;/p&gt;&lt;p&gt;曾经由于市场的突然消失，一时间暴露出库存积压的问题。这背后很大的原因是整个销售体系和管控体系的缺失，没能够达到实时监控的目的，缺乏对产品渠道的把控力度。&lt;/p&gt;&lt;p&gt;&lt;span&gt;2、传统渠道失效&lt;/span&gt;&lt;/p&gt;&lt;p&gt;早些年，由于对公市场十分繁荣，产品的研发不需要科学的考量。但后来，市场的大潮退去，原来依附的渠道失效， 整个销售陷入一个被动局面。&lt;/p&gt;&lt;p&gt;&lt;span&gt;3、销售管理缺失&lt;/span&gt;&lt;/p&gt;&lt;p&gt;由于缺少销售体系管控，直接造成了对每个销售人员掌握的客户信息缺乏管控。每个销售人员手里掌握的客户，有没有重复，有没有遗漏，有没有重复上报，都没有管控，这些都无从考证。&lt;/p&gt;&lt;p&gt;&lt;span&gt;4、财务控制的失效&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于每个客户的应收账期是多少?客户是不是已经产生了信用危险?要求是否合规?这些信息领导层都无从知晓。&lt;/span&gt;由于缺乏管控，导致公司整体销售业绩很好，但应收帐款却有很大缺失。&lt;/p&gt;&lt;p&gt;以上种种问题，在过去销售业绩低沉的时候暴露无疑。后来，公司上下都形成一致意见，认为目前的形势，内部管理比外部拓展经营更为重要。基于这个契机，永银在信息数据管理方面开始逐渐推进系统的改进、研发、和外购。&lt;/p&gt;&lt;p&gt;但由于中小企业的规模限制，其管理思路和管理体系都智能在限制的资源中发挥，这就需要一个通用性、开发性很强的产品，帆软FineReport就成了不二选择。从数据展示平台到移动化，将输入端、逻辑处理端到输出端都有效集中在了一起。&lt;/p&gt;&lt;h3 style="border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(238, 238, 238); margin-bottom: 16px; color: rgb(68, 68, 68); font-family: &amp;#39;microsoft yahei&amp;#39;; line-height: 25px; white-space: normal;"&gt;&lt;strong&gt;项目实施过程&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;1、定位&lt;/span&gt;&lt;/p&gt;&lt;p&gt;项目的框架是首要前提。前期需要确定好项目平台的定位，包括平台的应用范围和应用场景。&lt;/p&gt;&lt;p&gt;&lt;span&gt;2、沟通&lt;/span&gt;&lt;/p&gt;&lt;p&gt;定位之后是确定平台关系，包括业务系统和信息系统的关系、新的信息系统和原有的信息系统的关系，关系确定之后需要跟老板沟通，了解需求，然后逐步对内外管理层调研，形成一个流程化的体系。&lt;/p&gt;&lt;p&gt;&lt;span&gt;3、规划&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;规划无外乎人、财、物、事。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;人力方面需要很多不同的角色，在项目规划中需要他们去配合实现某些场景，验证可行性。财力方面需要一个精确的投资成本和实施范围估算，与财务和内控达成共识。关于物料，实施过程的服务器调用都需要提前做一些规划，提前准备。而后在流程过程中，每个环节都要有相应的负责人去维系，所以也要事先确定这些角色。&lt;/p&gt;&lt;p&gt;&lt;span&gt;4、实施&lt;/span&gt;&lt;/p&gt;&lt;p&gt;实施过程较为简单，但技术的实施过程需要注意对整个项目的管控。为了保证成功的开发、交互，过程中需要严格遵守方法论。&lt;/p&gt;&lt;h3 style="border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(238, 238, 238); margin-bottom: 16px; color: rgb(68, 68, 68); font-family: &amp;#39;microsoft yahei&amp;#39;; line-height: 25px; white-space: normal;"&gt;&lt;strong&gt;建设的关键节点&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;在搭建数据分析平台的过程中，有三个关键节点。&lt;/p&gt;&lt;p&gt;&lt;span&gt;关键节点1：数据精准&lt;/span&gt;&lt;/p&gt;&lt;p&gt;报表工作对数据要求很高，如果整个基础数据有任何一点缺失、不到位，前端报表的制作就会变得很困难，更谈不上准确的数据体系。久而久之，容易造成人员对整个报表体系信任度的下降。例如此前，与某银行的订单来往都是通过接口的方式来流通，但有一次银行传输的数据中，营业部字段后面加了空格，导致系统自动新建一个客户，造成了后续统计的问题。所以，对于数据不光是内部还有外部，都需要一个强烈的校验机制。&lt;/p&gt;&lt;p&gt;&lt;span&gt;关键节点2：逻辑一致&lt;/span&gt;&lt;/p&gt;&lt;p&gt;业务部门对数据逻辑的理解和IT部门有所不同，所以在数据处理过程中需要双方对数据的抽取、提炼、整理、显示都保持一套完整的、对内统一逻辑。在永银的报表工作中，会在每一张数据报表中写上清楚的逻辑，以便提供后续校验。&lt;/p&gt;&lt;p&gt;&lt;span&gt;关键节点3：交互简单、快&lt;/span&gt;&lt;/p&gt;&lt;p&gt;终端用户并不能理解数据处理的技术过程，对于数据展示的要求是简单而快。所以我们会提前将数据清洗、抽取、切片、聚类;在固定时间，按时间、地点、体系、产品等等做综合的数据维度，放在数据仓库。&lt;/p&gt;&lt;h3 style="border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(238, 238, 238); margin-bottom: 16px; color: rgb(68, 68, 68); font-family: &amp;#39;microsoft yahei&amp;#39;; line-height: 25px; white-space: normal;"&gt;&lt;strong&gt;建设过程经验分享&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;源头控制&lt;/strong&gt;：对于每个进入系统的数据都要做好严格的检查校验。这样的工作需要持续、不断，效益会岁时间慢慢浮现。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;顶层设计&lt;/strong&gt;：数据分析平台在信息系统架构的定位需要做明确的把控，比如以财务为核心，就要遵循SAP的法则。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;以终为始&lt;/strong&gt;：数据平台的上线会导致对整个数据来源过程的重新审视，会重新去看待整个信息架构的合理性，流程的合理性，强壮性，整个业绩体系，组织架构的合理性。随着数据平台的上线，很多数据都需要重新考虑，体系需要梳理，然后做相应调整。&lt;/p&gt;&lt;p&gt;&lt;span&gt;规范流程&lt;/span&gt;&lt;/p&gt;&lt;p&gt;规范流程涉及公司内部管理的梳理和整合，流程体系的梳理建设和整个文档编码的设计都需要配合整个管理体系的建设。&lt;/p&gt;&lt;p&gt;&lt;span&gt;应用案例&lt;/span&gt;&lt;/p&gt;&lt;p&gt;一期的数据平台分为三类：填报应用、报表展示、数据分类。&lt;/p&gt;&lt;p&gt;填报应用&lt;/p&gt;&lt;p&gt;填报功能包括订单上报，退货上报，流程审批，采购、物流、仓储体系的一个出入柜的扫码和储位管理。&lt;/p&gt;&lt;center style="color: rgb(51, 51, 51); font-family: &amp;#39;microsoft yahei&amp;#39;; font-size: 15px; line-height: 25px; white-space: normal;"&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/jAqr3XzCYibx7yzFvYWf2FnSq0ckztibKccfn3gTJjC04jVD6F5zQBM2Cu3kYIsTbA1ibR4U9AXyRKuMjOMBJqPuA/0?wx_fmt=jpeg"/&gt;&lt;/center&gt;&lt;p&gt;报表展示&lt;/p&gt;&lt;center style="color: rgb(51, 51, 51); font-family: &amp;#39;microsoft yahei&amp;#39;; font-size: 15px; line-height: 25px; white-space: normal;"&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/jAqr3XzCYibx7yzFvYWf2FnSq0ckztibKcTVxkpJM7UicEauO96G3Wl6MNDo7RYn03riaFuT8mIEx8Ric9kGLQeBLgg/0?wx_fmt=jpeg"/&gt;&lt;/center&gt;&lt;p&gt;移动端应用&lt;/p&gt;&lt;center style="color: rgb(51, 51, 51); font-family: &amp;#39;microsoft yahei&amp;#39;; font-size: 15px; line-height: 25px; white-space: normal;"&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/jAqr3XzCYibx7yzFvYWf2FnSq0ckztibKcy3NxP0N7YsK2wgaKSnjp0ZOrAS8bSshficiarIl8RJI4judOCxufiaMRw/0?wx_fmt=jpeg"/&gt;&lt;/center&gt;&lt;p&gt;数据分类&lt;/p&gt;&lt;p&gt;关于BI的数据清洗、分类、切片、整合，都是通过定时调动的方式，一天会有30个定时调动。这里可以将调动分成几节，有的是一级调动做完，有的一级调动做完之后可能会有二级调动再继续，再替换，这样的效果非常好。&lt;/p&gt;&lt;p&gt;End.&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 20 Sep 2016 10:05:05 +0800</pubDate>
    </item>
    <item>
      <title>最全的Spark基础知识解答</title>
      <link>http://www.iwgc.cn/link/2730055</link>
      <description>&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/jAqr3XzCYibyOibUHmfe12ibKNCewzVJZMib5DQNiaxdJ2cxJUkwaqyxsssdRJ4p45qhnTFdWL2nJhIhBVkeqWjHDjA/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;br/&gt;&lt;/p&gt;&lt;h3 style="border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(238, 238, 238); margin-bottom: 16px; color: rgb(68, 68, 68); font-family: &amp;#39;microsoft yahei&amp;#39;; line-height: 25px; white-space: normal;"&gt;&lt;span&gt;&lt;strong&gt;一. Spark基础知识&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&amp;nbsp;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;1.Spark是什么?&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;UCBerkeley AMPlab所开源的类HadoopMapReduce的通用的并行计算框架。&lt;/p&gt;&lt;p&gt;dfsSpark基于mapreduce算法实现的分布式计算，拥有HadoopMapReduce所具有的优点;但不同于MapReduce的是Job中间输出和结果可以保存在内存中，从而不再需要读写HDFS，因此Spark能更好地适用于数据挖掘与机器学习等需要迭代的map reduce的算法。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;2.Spark与Hadoop的对比(Spark的优势)&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;1、Spark的中间数据放到内存中，对于迭代运算效率更高&lt;/p&gt;&lt;p&gt;2、Spark比Hadoop更通用&lt;/p&gt;&lt;p&gt;3、Spark提供了统一的编程接口&lt;/p&gt;&lt;p&gt;4、容错性– 在分布式数据集计算时通过checkpoint来实现容错&lt;/p&gt;&lt;p&gt;5、可用性– Spark通过提供丰富的Scala, Java，Python API及交互式Shell来提高可用性&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;3.Spark有那些组件&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;1、Spark Streaming：支持高吞吐量、支持容错的实时流数据处理&lt;/p&gt;&lt;p&gt;2、Spark SQL， Data frames: 结构化数据查询&lt;/p&gt;&lt;p&gt;3、MLLib：Spark 生态系统里用来解决大数据机器学习问题的模块&lt;/p&gt;&lt;p&gt;4、GraphX是构建于Spark上的图计算模型&lt;/p&gt;&lt;p&gt;5、SparkR是一个R语言包，它提供了轻量级的方式使得可以在R语言中使用 Spark&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;br/&gt;&lt;/p&gt;&lt;h3 style="border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(238, 238, 238); margin-bottom: 16px; color: rgb(68, 68, 68); font-family: &amp;#39;microsoft yahei&amp;#39;; line-height: 25px; white-space: normal;"&gt;&lt;strong&gt;二. DataFrame相关知识点&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;&amp;nbsp;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;1.DataFrame是什么?&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;DataFrame是一种以RDD为基础的分布式数据集，类似于传统数据库中的二维表格。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;2.DataFrame与RDD的主要区别在于?&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;DataFrame带有schema元信息，即DataFrame所表示的二维表数据集的每一列都带有名称和类型。这使得SparkSQL得以洞察更多的结构信息，从而对藏于DataFrame背后的数据源以及作用于DataFrame之上的变换进行了针对性的优化，最终达到大幅提升运行时效率的目标。&lt;/p&gt;&lt;p&gt;反观RDD，由于无从得知所存数据元素的具体内部结构，Spark Core只能在stage层面进行简单、通用的流水线优化。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;3.DataFrame 特性&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;1、支持从KB到PB级的数据量&lt;/p&gt;&lt;p&gt;2、支持多种数据格式和多种存储系统&lt;/p&gt;&lt;p&gt;3、通过Catalyst优化器进行先进的优化生成代码&lt;/p&gt;&lt;p&gt;4、通过Spark无缝集成主流大数据工具与基础设施&lt;/p&gt;&lt;p&gt;5、API支持Python、Java、Scala和R语言&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;br/&gt;&lt;/p&gt;&lt;h3 style="border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(238, 238, 238); margin-bottom: 16px; color: rgb(68, 68, 68); font-family: &amp;#39;microsoft yahei&amp;#39;; line-height: 25px; white-space: normal;"&gt;&lt;strong&gt;三 .RDD相关知识点&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;&amp;nbsp;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;1.RDD，全称为?&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;Resilient Distributed Datasets，意为容错的、并行的数据结构，可以让用户显式地将数据存储到磁盘和内存中，并能控制数据的分区。同时，RDD还提供了一组丰富的操作来操作这些数据。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;2.RDD的特点?&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul style="margin-bottom: 16px; color: rgb(51, 51, 51); font-family: &amp;#39;microsoft yahei&amp;#39;; font-size: 15px; line-height: 25px; white-space: normal;" class=" list-paddingleft-2"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;它是在集群节点上的不可变的、已分区的集合对象。&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;通过并行转换的方式来创建如(map, filter, join, etc)。&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;失败自动重建。&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;可以控制存储级别(内存、磁盘等)来进行重用。&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;必须是可序列化的。&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;是静态类型的。&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&amp;nbsp;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;3.RDD核心概念&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;Client：客户端进程，负责提交作业到Master。&lt;/p&gt;&lt;p&gt;Master:Standalone模式中主控节点，负责接收Client提交的作业，管理Worker，并命令Worker启动分配Driver的资源和启动Executor的资源。&lt;/p&gt;&lt;p&gt;Worker：Standalone模式中slave节点上的守护进程，负责管理本节点的资源，定期向Master汇报心跳，接收Master的命令，启动Driver和Executor。&lt;/p&gt;&lt;p&gt;Driver： 一个Spark作业运行时包括一个Driver进程，也是作业的主进程，负责作业的解析、生成Stage并调度Task到Executor上。包括DAGScheduler，TaskScheduler。&lt;/p&gt;&lt;p&gt;Executor：即真正执行作业的地方，一个集群一般包含多个Executor，每个Executor接收Driver的命令Launch Task，一个Executor可以执行一到多个Task。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;4.RDD常见术语&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;DAGScheduler： 实现将Spark作业分解成一到多个Stage，每个Stage根据RDD的Partition个数决定Task的个数，然后生成相应的Task set放到TaskScheduler中。&lt;/p&gt;&lt;p&gt;TaskScheduler：实现Task分配到Executor上执行。&lt;/p&gt;&lt;p&gt;Task：运行在Executor上的工作单元&lt;/p&gt;&lt;p&gt;Job：SparkContext提交的具体Action操作，常和Action对应&lt;/p&gt;&lt;p&gt;Stage：每个Job会被拆分很多组任务(task)，每组任务被称为Stage，也称TaskSet&lt;/p&gt;&lt;p&gt;RDD：Resilient Distributed Datasets的简称，弹性分布式数据集，是Spark最核心的模块和类&lt;/p&gt;&lt;p&gt;Transformation/Action：SparkAPI的两种类型;Transformation返回值还是一个RDD，Action返回值不少一个RDD，而是一个Scala的集合;所有的Transformation都是采用的懒策略，如果只是将Transformation提交是不会执行计算的，计算只有在Action被提交时才会被触发。&lt;/p&gt;&lt;p&gt;DataFrame： 带有Schema信息的RDD，主要是对结构化数据的高度抽象。&lt;/p&gt;&lt;p&gt;DataSet：结合了DataFrame和RDD两者的优势，既允许用户很方便的操作领域对象，又具有SQL执行引擎的高效表现。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;5.RDD提供了两种类型的操作：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;transformation和action&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;1，transformation是得到一个新的RDD，方式很多，比如从数据源生成一个新的RDD，从RDD生成一个新的RDD&lt;/p&gt;&lt;p&gt;2，action是得到一个值，或者一个结果(直接将RDD cache到内存中)&lt;/p&gt;&lt;p&gt;3，所有的transformation都是采用的懒策略，就是如果只是将transformation提交是不会执行计算的，计算只有在action被提交的时候才被触发&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;6.RDD中关于转换(transformation)与动作(action)的区别&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;transformation会生成新的RDD，而后者只是将RDD上某项操作的结果返回给程序，而不会生成新的RDD;无论执行了多少次transformation操作，RDD都不会真正执行运算(记录lineage)，只有当action操作被执行时，运算才会触发。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;7.RDD 与 DSM的最大不同是?&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;DSM(distributed shared memory)&lt;/p&gt;&lt;p&gt;RDD只能通过粗粒度转换来创建，而DSM则允许对每个内存位置上数据的读和写。在这种定义下，DSM不仅包括了传统的共享内存系统，也包括了像提供了共享 DHT(distributed hash table) 的 Piccolo 以及分布式数据库等。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;8.RDD的优势?&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;1、高效的容错机制&lt;/p&gt;&lt;p&gt;2、结点落后问题的缓和 (mitigate straggler)&amp;nbsp;&lt;/p&gt;&lt;p&gt;3、批量操作&lt;/p&gt;&lt;p&gt;4、优雅降级 (degrade gracefully)&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;9.如何获取RDD?&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;1、从共享的文件系统获取，(如：HDFS)&lt;/p&gt;&lt;p&gt;2、通过已存在的RDD转换&lt;/p&gt;&lt;p&gt;3、将已存在scala集合(只要是Seq对象)并行化 ，通过调用SparkContext的parallelize方法实现&lt;/p&gt;&lt;p&gt;4、改变现有RDD的之久性;RDD是懒散，短暂的。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;10.RDD都需要包含以下四个部分&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;a.源数据分割后的数据块，源代码中的splits变量&lt;/p&gt;&lt;p&gt;b.关于“血统”的信息，源码中的dependencies变量&lt;/p&gt;&lt;p&gt;c.一个计算函数(该RDD如何通过父RDD计算得到)，源码中的iterator(split)和compute函数&lt;/p&gt;&lt;p&gt;d.一些关于如何分块和数据存放位置的元信息，如源码中的partitioner和preferredLocations0&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;11.RDD中将依赖的两种类型&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;窄依赖(narrowdependencies)和宽依赖(widedependencies)。&lt;/p&gt;&lt;p&gt;窄依赖是指父RDD的每个分区都只被子RDD的一个分区所使用。相应的，那么宽依赖就是指父RDD的分区被多个子RDD的分区所依赖。例如，map就是一种窄依赖，而join则会导致宽依赖&lt;/p&gt;&lt;p&gt;依赖关系分类的特性：&lt;/p&gt;&lt;p&gt;第一，窄依赖可以在某个计算节点上直接通过计算父RDD的某块数据计算得到子RDD对应的某块数据;&lt;/p&gt;&lt;p&gt;第二，数据丢失时，对于窄依赖只需要重新计算丢失的那一块数据来恢复;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;br/&gt;&lt;/p&gt;&lt;h3 style="border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(238, 238, 238); margin-bottom: 16px; color: rgb(68, 68, 68); font-family: &amp;#39;microsoft yahei&amp;#39;; line-height: 25px; white-space: normal;"&gt;&lt;strong&gt;Spark Streaming相关知识点&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;&amp;nbsp;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;1.Spark Streaming的基本原理&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;Spark Streaming的基本原理是将输入数据流以时间片(秒级)为单位进行拆分，然后以类似批处理的方式处理每个时间片数据&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;RDD 基本操作&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;常见的聚合操作：&lt;/p&gt;&lt;ol style="margin-bottom: 16px; color: rgb(51, 51, 51); font-family: &amp;#39;microsoft yahei&amp;#39;; font-size: 15px; line-height: 25px; white-space: normal;" class=" list-paddingleft-2"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;count(*) 所有值不全为NULL时，加1操作&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;count(1) 不管有没有值，只要有这条记录，值就加1&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;count(col) col列里面的值为null，值不会加1，这个列里面的值不为NULL，才加1&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&amp;nbsp;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;sum求和&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;ol style="margin-bottom: 16px; color: rgb(51, 51, 51); font-family: &amp;#39;microsoft yahei&amp;#39;; font-size: 15px; line-height: 25px; white-space: normal;" class=" list-paddingleft-2"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;sum(可转成数字的值) 返回bigint&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;avg求平均值&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;avg(可转成数字的值)返回double&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;distinct不同值个数&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;count(distinct col)&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&amp;nbsp;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;按照某些字段排序&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;select col1,other... from table where conditio order by col1,col2 [asc|desc]&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;Join表连接&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;join等值连接(内连接)，只有某个值在m和n中同时存在时。&lt;/p&gt;&lt;p&gt;left outer join 左外连接，左边表中的值无论是否在b中存在时，都输出;右边表中的值，只有在左边表中存在时才输出。&lt;/p&gt;&lt;p&gt;right outer join 和 left outer join 相反。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;Transformation具体内容：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;reduceByKey(func, [numTasks]) : 在一个(K，V)对的数据集上使用，返回一个(K，V)对的数据集，key相同的值，都被使用指定的reduce函数聚合到一起。和groupbykey类似，任务的个数是可以通过第二个可选参数来配置的。&lt;/p&gt;&lt;p&gt;join(otherDataset, [numTasks]) :在类型为(K,V)和(K,W)类型的数据集上调用，返回一个(K,(V,W))对，每个key中的所有元素都在一起的数据集&lt;/p&gt;&lt;p&gt;groupWith(otherDataset, [numTasks]) : 在类型为(K,V)和(K,W)类型的数据集上调用，返回一个数据集，组成元素为(K, Seq[V], Seq[W]) Tuples。这个操作在其它框架，称为CoGroup&lt;/p&gt;&lt;p&gt;cartesian(otherDataset) : 笛卡尔积。但在数据集T和U上调用时，返回一个(T，U)对的数据集，所有元素交互进行笛卡尔积。&lt;/p&gt;&lt;p&gt;flatMap(func) :类似于map，但是每一个输入元素，会被映射为0到多个输出元素(因此，func函数的返回值是一个Seq，而不是单一元素)&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Case 1将一个list乘方后输出&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;val input = sc.parallelize(List(1,2,3,4))&lt;/p&gt;&lt;p&gt;val result = input.map(x =&amp;gt; x*x)&lt;/p&gt;&lt;p&gt;println(result.collect().mkString(","))&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Case 2 wordcount&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;val textFile = sc.textFile(args(1))&lt;/p&gt;&lt;p&gt;val result = textFile.flatMap(line =&amp;gt; line.split("\\s+")).map(word =&amp;gt; (word, 1)).reduceByKey(_ + _)&lt;/p&gt;&lt;p&gt;println(result.collect().mkString(","))&lt;/p&gt;&lt;p&gt;result.saveAsTextFile(args(2))&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Case 3 打印rdd的元素&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;rdd.foreach(println) 或者 rdd.map(println).&lt;/p&gt;&lt;p&gt;rdd.collect().foreach(println)&lt;/p&gt;&lt;p&gt;rdd.take(100).foreach(println)&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;spark SQL&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/jAqr3XzCYibyOibUHmfe12ibKNCewzVJZMib31QxHDtsOmdGJ1xq4ia9b6BX3VKDPDibV4thGHnkVdwUYYTmyY5GicUpA/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;Spark Streaming优劣&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;优势：&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;1、统一的开发接口&lt;/p&gt;&lt;p&gt;2、吞吐和容错&lt;/p&gt;&lt;p&gt;3、多种开发范式混用，Streaming + SQL, Streaming +MLlib&lt;/p&gt;&lt;p&gt;4、利用Spark内存pipeline计算&lt;/p&gt;&lt;p&gt;&lt;strong&gt;劣势：&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;微批处理模式，准实时&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/jAqr3XzCYibyOibUHmfe12ibKNCewzVJZMibXpf884xs9BCQ7mNibD37c220kptRX984OllINJ34hJNPYR0xmt0NGyw/0?wx_fmt=jpeg"/&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/jAqr3XzCYibyOibUHmfe12ibKNCewzVJZMib2Z8Poe202twE7zsCw4xiaK4q4IqeBsV2DqdazwiaibE4PrA0JIicaqWQAw/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;Storm结构：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/jAqr3XzCYibyOibUHmfe12ibKNCewzVJZMib73AdDvicdTYToib20l8y4mzibGlpfLQI8qYvp2ZRcg0pSNumDypvcEOlA/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;DStream&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;1.将流式计算分解成一系列确定并且较小的批处理作业&lt;/p&gt;&lt;p&gt;2.将失败或者执行较慢的任务在其它节点上并行执行，执行的最小单元为RDD的partition&lt;/p&gt;&lt;p&gt;3.较强的容错能力&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;spark stream example code&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/jAqr3XzCYibyOibUHmfe12ibKNCewzVJZMibicVibawHvhOrTwzfNTOQHt9EFdXFGMAsicUoK3icdLfI9w1Hggia4YdgtBw/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;br/&gt;&lt;/p&gt;&lt;h3 style="border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(238, 238, 238); margin-bottom: 16px; color: rgb(68, 68, 68); font-family: &amp;#39;microsoft yahei&amp;#39;; line-height: 25px; white-space: normal;"&gt;&lt;strong&gt;四. 日志系统&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;&amp;nbsp;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;1.Flume&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;Flume是一个分布式的日志收集系统，具有高可靠、高可用、事务管理、失败重启等功能。数据处理速度快，完全可以用于生产环境。&lt;/p&gt;&lt;p&gt;Flume的核心是agent。&lt;/p&gt;&lt;p&gt;Agent是一个java进程，运行在日志收集端，通过agent接收日志，然后暂存起来，再发送到目的地。&lt;/p&gt;&lt;p&gt;Agent里面包含3个核心组件：source、channel、sink。&lt;/p&gt;&lt;p&gt;Source组件是专用于收集日志的，可以处理各种类型各种格式的日志数据,包括avro、thrift、exec、jms、spoolingdirectory、netcat、sequencegenerator、syslog、http、legacy、自定义。source组件把数据收集来以后，临时存放在channel中。&lt;/p&gt;&lt;p&gt;Channel组件是在agent中专用于临时存储数据的，可以存放在memory、jdbc、file、自定义。channel中的数据只有在sink发送成功之后才会被删除。&lt;/p&gt;&lt;p&gt;Sink组件是用于把数据发送到目的地的组件，目的地包括hdfs、logger、avro、thrift、ipc、file、null、hbase、solr、自定义。&lt;/p&gt;&lt;p&gt;Apache Kafka是分布式发布-订阅消息系统。&lt;/p&gt;&lt;p&gt;它最初由LinkedIn公司开发，之后成为Apache项目的一部分。Kafka是一种快速、可扩展的、设计内在就是分布式的，分区的和可复制的提交日志服务。&lt;/p&gt;&lt;p&gt;Apache Kafka与传统消息系统相比，有以下不同：&lt;/p&gt;&lt;p&gt;1、它被设计为一个分布式系统，易于向外扩展;&lt;/p&gt;&lt;p&gt;2、它同时为发布和订阅提供高吞吐量;&lt;/p&gt;&lt;p&gt;3、它支持多订阅者，当失败时能自动平衡消费者;&lt;/p&gt;&lt;p&gt;4、它将消息持久化到磁盘，因此可用于批量消费&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;br/&gt;&lt;/p&gt;&lt;h3 style="border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(238, 238, 238); margin-bottom: 16px; color: rgb(68, 68, 68); font-family: &amp;#39;microsoft yahei&amp;#39;; line-height: 25px; white-space: normal;"&gt;&lt;strong&gt;五. 分布式搜索&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;&amp;nbsp;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;搜索引擎是什么?&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;搜索引擎是指根据一定的策略、运用特定的计算机程序从互联网上搜集信息，在对信息进行组织和处理后，为用户提供检索服务，将用户检索相关的信息展示给用户的系统。搜索引擎包括全文索引、目录索引、元搜索引擎、垂直搜索引擎、集合式搜索引擎、门户搜索引擎与免费链接列表等。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;Lucene是什么?&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;Lucene一个高性能、可伸缩的信息搜索库，即它不是一个完整的全文检索引擎，而是一个全检索引擎的架构，提供了完整的查询引擎和索引引擎，部分文本分析引擎。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;Elasticsearch是什么?&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;Elasticsearch一个高可扩展的开源的全文本搜索和分析工具。&lt;/p&gt;&lt;p&gt;它允许你以近实时的方式快速存储、搜索、分析大容量的数据。Elasticsearch是一个基于ApacheLucene(TM)的开源搜索引擎。无论在开源还是专有领域，Lucene可以被认为是迄今为止最先进、性能最好的、功能最全的搜索引擎库。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;ElasticSearch 有4中方式来构建数据库&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;最简单的方法是使用indexAPI，将一个Document发送到特定的index，一般通过curltools实现。&lt;/p&gt;&lt;p&gt;第二第三种方法是通过bulkAPI和UDPbulkAPI。两者的区别仅在于连接方式。&lt;/p&gt;&lt;p&gt;第四种方式是通过一个插件-river。river运行在ElasticSearch上，并且可以从外部数据库导入数据到ES中。需要注意的是，数据构建仅在分片上进行，而不能在副本上进行。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;ELK是一套常用的开源日志监控和分析系统&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;包括一个分布式索引与搜索服务Elasticsearch，一个管理日志和事件的工具logstash，和一个数据可视化服务Kibana，logstash 负责日志的收集，处理和储存，elasticsearch 负责日志检索和分析，Kibana 负责日志的可视化。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;br/&gt;&lt;/p&gt;&lt;h3 style="border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(238, 238, 238); margin-bottom: 16px; color: rgb(68, 68, 68); font-family: &amp;#39;microsoft yahei&amp;#39;; line-height: 25px; white-space: normal;"&gt;&lt;strong&gt;六. 分布式数据库&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;&amp;nbsp;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;1.Hive是什么?&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;Hive是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供类SQL查询功能。本质是将HQL转换为MapReduce程序&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;2.Hive的设计目标?&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;1、Hive的设计目标是使Hadoop上的数据操作与传统SQL相结合，让熟悉SQL编程开发人员能够轻松向Hadoop平台迁移&lt;/p&gt;&lt;p&gt;2、Hive提供类似SQL的查询语言HQL，HQL在底层被转换为相应的MapReduce操作&lt;/p&gt;&lt;p&gt;3、Hive在HDFS上构建数据仓库来存储结构化的数据，这些数据一般来源与HDFS上的原始数据，使用Hive可以对这些数据执行查询、分析等操作。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;3.Hive的数据模型&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul style="margin-bottom: 16px; color: rgb(51, 51, 51); font-family: &amp;#39;microsoft yahei&amp;#39;; font-size: 15px; line-height: 25px; white-space: normal;" class=" list-paddingleft-2"&gt;&lt;li&gt;&lt;p&gt;Hive数据库&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;内部表&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;外部表&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;分区&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;桶&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Hive的视图&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Hive在创建内部表时，会将数据移动到数据仓库指向的路径，若创建外部表，仅记录数据所在的路径，不对数据位置做任何改变，在删除表的时候，内部表的元数据和数据会被一起删除，外部表只会删除元数据，不删除数据。这样来说，外部表要比内部表安全，数据组织液更加灵活，方便共享源数据。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;4.Hive的调用方式&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;1、Hive Shell&lt;/p&gt;&lt;p&gt;2、Thrift&lt;/p&gt;&lt;p&gt;3、JDBC&lt;/p&gt;&lt;p&gt;4、ODBC&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;5.Hive的运行机制&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;1、将sql转换成抽象语法树&lt;/p&gt;&lt;p&gt;2、将抽象语法树转化成查询块&lt;/p&gt;&lt;p&gt;3、将查询块转换成逻辑查询计划(操作符树)&lt;/p&gt;&lt;p&gt;4、将逻辑计划转换成物理计划(M\Rjobs)&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;6.Hive的优势&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;1、并行计算&lt;/p&gt;&lt;p&gt;2、充分利用集群的CPU计算资源、存储资源&lt;/p&gt;&lt;p&gt;3、处理大规模数据集&lt;/p&gt;&lt;p&gt;4、使用SQL，学习成本低&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;7.Hive应用场景&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;1、海量数据处理&lt;/p&gt;&lt;p&gt;2、数据挖掘&lt;/p&gt;&lt;p&gt;3、数据分析&lt;/p&gt;&lt;p&gt;4、SQL是商务智能工具的通用语言，Hive有条件和这些BI产品进行集成&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;8.Hive不适用场景&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;1、复杂的科学计算&lt;/p&gt;&lt;p&gt;2、不能做到交互式的实时查询&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;9.Hive和数据库(RDBMS)的区别&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;1、数据存储位置。Hive是建立在Hadoop之上的，所有的Hive的数据都是存储在HDFS中的。而数据库则可以将数据保存在块设备或本地文件系统中。&lt;/p&gt;&lt;p&gt;2、数据格式。Hive中没有定义专门的数据格式，由用户指定，需要指定三个属性：列分隔符，行分隔符，以及读取文件数据的方法。数据库中，存储引擎定义了自己的数据格式。所有数据都会按照一定的组织存储。&lt;/p&gt;&lt;p&gt;3、数据更新。Hive的内容是读多写少的，因此，不支持对数据的改写和删除，数据都在加载的时候中确定好的。数据库中的数据通常是需要经常进行修改。&lt;/p&gt;&lt;p&gt;4、执行延迟。Hive在查询数据的时候，需要扫描整个表(或分区)，因此延迟较高，只有在处理大数据是才有优势。数据库在处理小数据是执行延迟较低。&lt;/p&gt;&lt;p&gt;5、索引。Hive没有，数据库有&lt;/p&gt;&lt;p&gt;6、执行。Hive是MapReduce，数据库是Executor&lt;/p&gt;&lt;p&gt;7、可扩展性。Hive高，数据库低&lt;/p&gt;&lt;p&gt;8、数据规模。Hive大，数据库小&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;hive代码简单例子：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;创建一个名为”test“的table&lt;/p&gt;&lt;p&gt;create table students (name string,age int,city string,class string) row format delimited fields terminated by ',';&lt;/p&gt;&lt;p&gt;load data local inpath "/opt/students.txt" into table students;&lt;/p&gt;&lt;p&gt;create EXTERNAL table IF NOT EXISTS studentX (name string,age int,city string,class string) partitioned by (grade string) ROW FORMAT DELIMITED FIELDS TERMINATED BY ',';&lt;/p&gt;&lt;p&gt;alter table studentX add partition (grade='excellent') location '/testM/excellent/';&lt;/p&gt;&lt;p&gt;alter table studentX add partition (grade='good') location '/testM/good/';&lt;/p&gt;&lt;p&gt;alter table studentX add partition (grade='moderate') location '/testM/moderate/';&lt;/p&gt;&lt;p&gt;#加载数据&lt;/p&gt;&lt;p&gt;load data inpath "/testtry/studentsm.txt" into table studentX partition (grade='excellent');&lt;/p&gt;&lt;p&gt;load data inpath "/testtry/students.txt" into table studentX partition (grade='good');&lt;/p&gt;&lt;p&gt;show partitions studentX;&lt;/p&gt;&lt;p&gt;select * from studentX where grade='excellent';&lt;/p&gt;&lt;p&gt;表删除操作：drop table students;&lt;/p&gt;&lt;p&gt;创建一个名为”test“的table&lt;/p&gt;&lt;p&gt;create table students (name string,age int,city string,class string) row format delimited fields terminated by ',';&lt;/p&gt;&lt;p&gt;load data local inpath "/bin/students.txt" into table students;&lt;/p&gt;&lt;p&gt;###&lt;/p&gt;&lt;p&gt;练习:创建外部表，指定数据存放位置&lt;/p&gt;&lt;p&gt;create EXTERNAL table IF NOT EXISTS studentX (name string,age int,city string,class string) partitioned by (class string) ROW FORMAT DELIMITED FIELDS TERMINATED BY ',';&lt;/p&gt;&lt;p&gt;alter table test add partition (class='one') location '/testmore/one';&lt;/p&gt;&lt;p&gt;对表进行查询&lt;/p&gt;&lt;p&gt;Select * from students;&lt;/p&gt;&lt;p&gt;分区表操作&lt;/p&gt;&lt;p&gt;hive&amp;gt;create table students (name string,age int,city string,class string) partitioned by (class string) row format delimited fields terminated by ',';&lt;/p&gt;&lt;p&gt;hive&amp;gt;load data local inpath "students.txt" into table students partition (class='one');&lt;/p&gt;&lt;p&gt;hive&amp;gt;show partitions students;&lt;/p&gt;&lt;p&gt;hive&amp;gt;select * from students where grade='two';&lt;/p&gt;&lt;p&gt;查询操作&lt;/p&gt;&lt;p&gt;group by、 order by、 join 、 distribute by、 sort by、 clusrer by、 union all&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;hive常见操作&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/jAqr3XzCYibyOibUHmfe12ibKNCewzVJZMibEYvTtqWnNXwaw0Ru0pzyYPn328S9EYhloesOPyWkXSBrYtOr0uIvMQ/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;Hbase 的模块：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;原子性(是指不会被线程调度机制打断的操作，这种操作一旦开始，就一直运行到结束，中间不会有任何contextswitch(切换到领一个线程))，一致性，隔离性，持久性&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/jAqr3XzCYibyOibUHmfe12ibKNCewzVJZMibWpcDTIxzDO7T5hGKEdYHA8HiaTKocyVkaXZVMO6LsGaYpaL5rT2OxIg/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;h3 style="border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(238, 238, 238); margin-bottom: 16px; color: rgb(68, 68, 68); font-family: &amp;#39;microsoft yahei&amp;#39;; line-height: 25px; white-space: normal;"&gt;&lt;strong&gt;Region- Region用于存放表中的行数据&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;&amp;nbsp;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;Region Server&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/jAqr3XzCYibyOibUHmfe12ibKNCewzVJZMibgnSNCHw7IoXhSoPUdFIYNrKUiaib1pUaMETXOktKD9HHpGsxtOylsTKA/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;Master&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/jAqr3XzCYibyOibUHmfe12ibKNCewzVJZMibVEiaGI9oz5LeweiaB7vTsmZPCibZPephbnHGmQGgGgiburVo9pbkjIib4iaA/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;Zookeeper&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/jAqr3XzCYibyOibUHmfe12ibKNCewzVJZMibT2XVLNzMFdyzXSDBpyZGfJcvnicgn2zvFI3Nlbl5ZUhliajqJqWI19rw/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;HDFS&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/jAqr3XzCYibyOibUHmfe12ibKNCewzVJZMib1Wc80tlGcpibT643Pl8tY1hEGib98wTZto8OSIvSVnTDvTuLubyAd2Tg/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;API&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/jAqr3XzCYibyOibUHmfe12ibKNCewzVJZMib1fXpYTxFBSHM5AASFnu5eiakyKjlYQuicEUCZUIHBHtkJf6mvj764psw/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;br/&gt;&lt;/p&gt;&lt;h3 style="border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(238, 238, 238); margin-bottom: 16px; color: rgb(68, 68, 68); font-family: &amp;#39;microsoft yahei&amp;#39;; line-height: 25px; white-space: normal;"&gt;列式存储格式 Parquet&lt;/h3&gt;&lt;p&gt;&amp;nbsp;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;Parquet 是面向分析型业务的列式存储格式，由 Twitter 和 Cloudera 合作开发， 2015 年 5 月从 Apache 的孵化器里毕业成为 Apache 顶级项目，最新的版本是 1.8.0 。&lt;/p&gt;&lt;p&gt;列式存储和行式存储相比的优势 :&lt;/p&gt;&lt;ul style="margin-bottom: 16px; color: rgb(51, 51, 51); font-family: &amp;#39;microsoft yahei&amp;#39;; font-size: 15px; line-height: 25px; white-space: normal;" class=" list-paddingleft-2"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;可以跳过不符合条件的数据，只读取需要的数据，降低 IO 数据量。&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;压缩编码可以降低磁盘存储空间。由于同一列的数据类型是一样的，可以使用更高效的压缩编码(例如 Run Length Encoding 和 DeltaEncoding )进一步节约存储空间。&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;只读取需要的列，支持向量运算，能够获取更好的扫描性能。&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&amp;nbsp;&lt;br/&gt;&lt;/p&gt;&lt;h3 style="border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(238, 238, 238); margin-bottom: 16px; color: rgb(68, 68, 68); font-family: &amp;#39;microsoft yahei&amp;#39;; line-height: 25px; white-space: normal;"&gt;&lt;strong&gt;Hive操作&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;&amp;nbsp;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;Hive&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/jAqr3XzCYibyOibUHmfe12ibKNCewzVJZMibtibWEwIUbNWImTgGbaRAFeicMS1vUARI3librOiafd7dtHrtA1VQ9UlneA/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;br/&gt;&lt;/p&gt;&lt;h3 style="border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(238, 238, 238); margin-bottom: 16px; color: rgb(68, 68, 68); font-family: &amp;#39;microsoft yahei&amp;#39;; line-height: 25px; white-space: normal;"&gt;&lt;strong&gt;其他知识点&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;MLlib是spark的可以扩展的机器学习库，由以下部分组成：通用的学习算法和工具类，包括分类，回归，聚类，协同过滤，降维。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;数据分析常见模式：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;1、Iterative Algorithms，&lt;/p&gt;&lt;p&gt;2、Relational Queries，&lt;/p&gt;&lt;p&gt;3、MapReduce，&lt;/p&gt;&lt;p&gt;4、Stream Processing&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;Scala的好处：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;1、面向对象和函数式编程理念加入到静态类型语言中的混合体&lt;/p&gt;&lt;p&gt;2、Scala的兼容性—-能够与Java库无缝的交互&lt;/p&gt;&lt;p&gt;3、Scala的简洁性—-高效，更不容易犯错&lt;/p&gt;&lt;p&gt;4、Scala的高级抽象&lt;/p&gt;&lt;p&gt;5、Scala是静态类型—-类型推断&lt;/p&gt;&lt;p&gt;6、Scala是可扩展的语言&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;ElasticSearch 基础代码：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/jAqr3XzCYibyOibUHmfe12ibKNCewzVJZMib60yBPu7EibKLAichXDqXCwHgYmf40crictCDWeaTumdltcds3HMxr59wA/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;br/&gt;&lt;/p&gt;&lt;h3 style="border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(238, 238, 238); margin-bottom: 16px; color: rgb(68, 68, 68); font-family: &amp;#39;microsoft yahei&amp;#39;; line-height: 25px; white-space: normal;"&gt;&lt;strong&gt;基础问答题&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;Q:你理解的Hive和传统数据库有什么不同?各有什么试用场景。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;A:1、数据存储位置。Hive是建立在Hadoop之上的，所有的Hive的数据都是存储在HDFS中的。而数据库则可以将数据保存在块设备或本地文件系统中。&lt;/p&gt;&lt;p&gt;2、数据格式。Hive中没有定义专门的数据格式，由用户指定，需要指定三个属性：列分隔符，行分隔符，以及读取文件数据的方法。数据库中，存储引擎定义了自己的数据格式。所有数据都会按照一定的组织存储。&lt;/p&gt;&lt;p&gt;3、数据更新。Hive的内容是读多写少的，因此，不支持对数据的改写和删除，数据都在加载的时候中确定好的。数据库中的数据通常是需要经常进行修改。&lt;/p&gt;&lt;p&gt;4、执行延迟。Hive在查询数据的时候，需要扫描整个表(或分区)，因此延迟较高，只有在处理大数据是才有优势。数据库在处理小数据是执行延迟较低。&lt;/p&gt;&lt;p&gt;5、索引。Hive没有，数据库有&lt;/p&gt;&lt;p&gt;6、执行。Hive是MapReduce，数据库是Executor&lt;/p&gt;&lt;p&gt;7、可扩展性。Hive高，数据库低&lt;/p&gt;&lt;p&gt;8、数据规模。Hive大，数据库小&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;Q:Hive的实用场景&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;A:1、Data Ingestion (数据摄取)&lt;/p&gt;&lt;p&gt;2、Data Discovery(数据发现)&lt;/p&gt;&lt;p&gt;3、Data analytics(数据分析)&lt;/p&gt;&lt;p&gt;4、Data Visualization &amp;amp; Collaboration(数据可视化和协同开发)&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;Q:大数据分析与挖掘方法论被称为CRISP-DM方法是以数据为中心迭代循环进行的六步活动&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;A:它们分别是：商业理解、数据理解、数据准备、建立模型_、模型评估、结果部署_。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;Q:数据分析挖掘方法大致包含 ( )：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;A:1.分类 Classification&lt;/p&gt;&lt;p&gt;2.估计Estimation&lt;/p&gt;&lt;p&gt;3.预测Prediction&lt;/p&gt;&lt;p&gt;4. 关联规则Association Rules&lt;/p&gt;&lt;p&gt;5. 聚类Cluster&lt;/p&gt;&lt;p&gt;6. 描述与可视化Description and Visualization&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;Q:在数据分析与挖掘中对数据的访问性要求包括&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;交互性访问、批处理访问_、迭代计算、数据查询，HADOOP仅仅支持了其中批处理访问，而Spark则支持所有4种方式。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;Q:Spark作为计算框架的优势是什么?&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;A:1、Spark的中间数据放到内存中，对于迭代运算效率更高&lt;/p&gt;&lt;p&gt;2、Spark比Hadoop更通用&lt;/p&gt;&lt;p&gt;3、Spark提供了统一的编程接口&lt;/p&gt;&lt;p&gt;4、容错性– 在分布式数据集计算时通过checkpoint来实现容错&lt;/p&gt;&lt;p&gt;5、可用性– Spark通过提供丰富的Scala, Java，Python API及交互式Shell来提高可用性&lt;/p&gt;&lt;p&gt;End.&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Sun, 18 Sep 2016 10:32:09 +0800</pubDate>
    </item>
    <item>
      <title>用R语言实现对不平衡数据的四种处理方法</title>
      <link>http://www.iwgc.cn/link/2730056</link>
      <description>&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/jAqr3XzCYibyOibUHmfe12ibKNCewzVJZMib3zWibpBJkVwiaFictl6cuIkbrkBHlyqFib30YcWRtcsicIzibeib3yiaZIKxOQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;在对不平衡的分类数据集进行建模时，机器学习算法可能并不稳定，其预测结果甚至可能是有偏的，而预测精度此时也变得带有误导性。那么，这种结果是为何发生的呢?到底是什么因素影响了这些算法的表现?&lt;/p&gt;&lt;p&gt;在不平衡的数据中，任一算法都没法从样本量少的类中获取足够的信息来进行精确预测。因此，机器学习算法常常被要求应用在平衡数据集上。那我们该如何处理不平衡数据集?本文会介绍一些相关方法，它们并不复杂只是技巧性比较强。&lt;/p&gt;&lt;p&gt;本文会介绍处理非平衡分类数据集的一些要点，并主要集中于非平衡二分类问题的处理。一如既往，我会尽量精简地叙述，在文末我会演示如何用R中的ROSE包来解决实际问题。&lt;/p&gt;&lt;h3 style="border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(238, 238, 238); margin-bottom: 16px; color: rgb(68, 68, 68); font-family: &amp;#39;microsoft yahei&amp;#39;; line-height: 25px; white-space: normal;"&gt;&lt;strong&gt;什么是不平衡分类&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;不平衡分类是一种有监督学习，但它处理的对象中有一个类所占的比例远远大于其余类。比起多分类，这一问题在二分类中更为常见。(注：下文中占比较大的类称为大类，占比较小的类称为小类)&lt;/p&gt;&lt;p&gt;不平衡一词指代数据中响应变量(被解释变量)的分布不均衡，如果一个数据集的响应变量在不同类上的分布差别较大我们就认为它不平衡。&lt;/p&gt;&lt;p&gt;举个例子，假设我们有一个观测数为100000的数据集，它包含了哈佛大学申请人的信息。众所周知，哈佛大学以极低的录取比例而闻名，那么这个数据集的响应变量(即：该申请人是否被录取，是为1，否为0)就很不平衡，大致98%的观测响应变量为0，只有2%的幸运儿被录取。&lt;/p&gt;&lt;p&gt;在现实生活中，这类例子更是不胜枚举，我在下面列举了一些实例，请注意他们的不平衡度是不一样的。&lt;/p&gt;&lt;ol style="margin-bottom: 16px; color: rgb(51, 51, 51); font-family: &amp;#39;microsoft yahei&amp;#39;; font-size: 15px; line-height: 25px; white-space: normal;" class=" list-paddingleft-2"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;一个自动产品质量检测机每天会检测工厂生产的产品，你会发现次品率是远远低于合格率的。&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;某地区进行了居民癌症普查，结果患有癌症的居民人数也是远远少于健康人群。&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;在信用卡欺诈数据中，违规交易数比合规交易少不少。&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;一个遵循6δ原则的生产车间每生产100万个产品才会产出10个次品。&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;生活中的例子还有太多，现在你可以发现获取这些非平衡数据的可能性有多大，所以掌握这些数据集的处理方法也是每个数据分析师的必修课。&lt;/p&gt;&lt;h3 style="border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(238, 238, 238); margin-bottom: 16px; color: rgb(68, 68, 68); font-family: &amp;#39;microsoft yahei&amp;#39;; line-height: 25px; white-space: normal;"&gt;&lt;strong&gt;为什么大部分机器学习算法在不平衡数据集上表现不佳?&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;我觉得这是一个很有意思的问题，你不妨自己先动手试试，然后你就会了解把不平衡数据再结构化的重要性，至于如何再结构化，我会在操作部分中讲解。&lt;/p&gt;&lt;p&gt;下面是机器学习算法在不平衡数据上精度下降的原因：&lt;/p&gt;&lt;ol style="margin-bottom: 16px; color: rgb(51, 51, 51); font-family: &amp;#39;microsoft yahei&amp;#39;; font-size: 15px; line-height: 25px; white-space: normal;" class=" list-paddingleft-2"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;响应变量的分布不均匀使得算法精度下降，对于小类的预测精度会很低。&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;算法本身是精度驱动的，即该模型的目标是最小化总体误差，而小类对于总体误差的贡献很低。&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;算法本身假设数据集的类分布均衡，同时它们也可能假定不同类别的误差带来相同的损失(下文会详细叙述)。&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h3 style="border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(238, 238, 238); margin-bottom: 16px; color: rgb(68, 68, 68); font-family: &amp;#39;microsoft yahei&amp;#39;; line-height: 25px; white-space: normal;"&gt;&lt;strong&gt;针对不平衡数据的处理方法&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;这类处理方法其实就是大名鼎鼎的“采样法”，总的说来，应用这些方法都是为了把不平衡数据修正为平衡数据。修正方法就是调整原始数据集的样本量，使得不同类的数据比例一致。&lt;/p&gt;&lt;p&gt;而在诸多学者研究得出基于平衡数据的模型整体更优的结论后，这一类方法越来越受到分析师们的青睐。&lt;/p&gt;&lt;p&gt;下列是一些具体的处理方法名称：&lt;/p&gt;&lt;ol style="margin-bottom: 16px; color: rgb(51, 51, 51); font-family: &amp;#39;microsoft yahei&amp;#39;; font-size: 15px; line-height: 25px; white-space: normal;" class=" list-paddingleft-2"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;欠采样法(Undersampling)&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;过采样法(Oversampling)&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;人工数据合成法(Synthetic Data Generation)&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;代价敏感学习法(Cose Sensitive Learning)&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;让我们逐一了解它们。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1.欠采样法&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;该方法主要是对大类进行处理。它会减少大类的观测数来使得数据集平衡。这一办法在数据集整体很大时较为适宜，它还可以通过降低训练样本量来减少计算时间和存储开销。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;欠采样法共有两类：随机(Random)的和有信息的(Informative)。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;随机欠采样法会随机删除大类的观测直至数据集平衡。有信息的欠采样法则会依照一个事先制定的准则来删去观测。&lt;/p&gt;&lt;p&gt;有信息的欠采样中，利用简易集成算法(EasyEnsemble)和平衡级联算法(BalanceCascade)往往能得到比较好的结果。这两种算法也都很直白易懂。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;简易集成法：&lt;/strong&gt;首先，它将从大类中有放回地抽取一些独立样本生成多个子集。然后，将这些子集和小类的观测合并，再基于合并后的数据集训练多个分类器，以其中多数分类器的分类结果为预测结果。如你所见，整个流程和无监督学习非常相似。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;平衡级联法&lt;/strong&gt;：它是一种有监督的学习法，首先将生成多个分类器，再基于一定规则系统地筛选哪些大类样本应当被保留。&lt;/p&gt;&lt;p&gt;但欠采样法有一个显而易见的缺陷，由于要删去不少观测，使用该方法会使得大类损失不少重要信息。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2.过采样法&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这一方法针对小类进行处理。它会以重复小类的观测的方式来平衡数据。该方法也被称作升采样(Upsampling)。和欠采样类似，它也能分为随机过采样和有信息的过采样两类。&lt;/p&gt;&lt;p&gt;随机过采样会将小类观测随机重复。有信息过采样也是遵循一定的准则来人工合成小类观测。&lt;/p&gt;&lt;p&gt;使用该方法的一大优势是没有任何信息损失。缺点则是由于增加了小类的重复样本，很有可能导致过拟合(译者注：计算时间和存储开销也增大不少)。我们通过该方法可以在训练集上得到非常高的拟合精度，但在测试集上预测的表现则可能变得愈发糟糕。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3.人工数据合成法&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;简单说来，人工数据合成法是利用生成人工数据而不是重复原始观测来解决不平衡性。它也是一种过采样技术。&lt;/p&gt;&lt;p&gt;在这一领域，SMOTE法(Synthetic Minority Oversampling Technique)是有效而常用的方法。该算法基于特征空间(而不是数据空间)生成与小类观测相似的新数据(译者注：总体是基于欧氏距离来度量相似性，在特征空间生成一些人工样本，更通俗地说是在样本点和它近邻点的连线上随机投点作为生成的人工样本，下文叙述了这一过程但有些晦涩)。我们也可以说，它生成了小类观测的随机集合来降低分类器的误差。&lt;/p&gt;&lt;p&gt;为了生成人工数据，我们需要利用自助法(Bootstrapping)和K近邻法(K-neraest neighbors)。详细步骤如下：&lt;/p&gt;&lt;ol style="margin-bottom: 16px; color: rgb(51, 51, 51); font-family: &amp;#39;microsoft yahei&amp;#39;; font-size: 15px; line-height: 25px; white-space: normal;" class=" list-paddingleft-2"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;计算样本点间的距离并确定其近邻。&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;生成一个0到1上的均匀随机数，并将其乘以距离。&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;把第二步生成的值加到样本点的特征向量上。&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;这一过程等价于在在两个样本的连线上随机选择了一个点&lt;/strong&gt;。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;R中有一个包专门用来实现SMOTE过程，我们将在实践部分做演示。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;4.代价敏感学习(CSL)&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这是另一种常用且有意思的方法。简而言之，该方法会衡量误分类观测的代价来解决不平衡问题。&lt;/p&gt;&lt;p&gt;这方法不会生成平衡的数据集，而是通过生成代价矩阵来解决不平衡问题。代价矩阵是描述特定场景下误分类观测带来的损失的工具。近来已有研究表明，代价敏感学习法很多时候比采样法更优，因此这种方法也值得一学。&lt;/p&gt;&lt;p&gt;让我们通过一个例子来了解该方法：给定一个有关行人的数据集，我们想要了解行人是否会携带炸弹。数据集包含了所有的必要信息，且携带炸弹的人会被标记为正类，不带炸弹的就是负类。现在问题来了，我们需要把行人都分好类。让我们先来设定下这一问题的代价矩阵。&lt;/p&gt;&lt;p&gt;如果我们将行人正确分类了，我们不会蒙受任何损失。但如果我们把一个恐怖分子归为负类(False Negative)，我们要付出的代价会比把和平分子归为正类(False Positive)的代价大的多。&lt;/p&gt;&lt;p&gt;代价矩阵和混淆矩阵类似，如下所示，我们更关心的是伪正类(FP)和伪负类(FN)。只要观测被正确分类，我们不会有任何代价损失。&lt;/p&gt;&lt;center style="color: rgb(51, 51, 51); font-family: &amp;#39;microsoft yahei&amp;#39;; font-size: 15px; line-height: 25px; white-space: normal;"&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/jAqr3XzCYibyOibUHmfe12ibKNCewzVJZMib206SvAarCt9YBaDX3cnGEbPDia2MMHOcOkNnrTC4Xic1ABJVwsEycf1Q/0?wx_fmt=png"/&gt;&lt;/center&gt;&lt;p&gt;该方法的目标就是找到一个使得总代价最小的分类器：&lt;/p&gt;&lt;p&gt;Total Cost = C(FN)xFN + C(FP)xFP&lt;/p&gt;&lt;p&gt;其中,&lt;/p&gt;&lt;p&gt;FN是被误分类的正类样本数&lt;/p&gt;&lt;p&gt;FP是被误分类的负类样本数&lt;/p&gt;&lt;p&gt;C(FN)和C(FP)分别代表FN和FP带来的损失。本例中C(FN) &amp;gt; C(FP)&lt;/p&gt;&lt;p&gt;除此之外，我们还有其他的比较前沿的方法来处理不平衡样本。比如基于聚类的采样法(Cluster based sampling)，自适应人工采样法(adaptive synthetic sampling)，边界线SMOTE(border line SMOTE)，SMOTEboost，DataBoost-IM，核方法等。这些方法的基本思想和前文介绍的四类方法大同小异。还有一些更直观的方法可以帮助你提升预测效果：如利用聚类技术，把大类分为K个次类，每个此类的样本不重叠。再基于每个次类和小类的合并样本来训练分类器。最后把各个分类结果平均作为预测值。除此之外，也可以聚焦于获取更多数据来提高小类的占比。&lt;/p&gt;&lt;h3 style="border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(238, 238, 238); margin-bottom: 16px; color: rgb(68, 68, 68); font-family: &amp;#39;microsoft yahei&amp;#39;; line-height: 25px; white-space: normal;"&gt;&lt;strong&gt;应当使用哪类评价测度来评判精度?&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;选择合适的评价测度是不平衡数据分析的关键步骤。大部分分类算法仅仅通过正确分类率来衡量精度。但在不平衡数据中，使用这种方法有很大的欺骗性，因为小类对于整体精度的影响太小。&lt;/p&gt;&lt;center style="color: rgb(51, 51, 51); font-family: &amp;#39;microsoft yahei&amp;#39;; font-size: 15px; line-height: 25px; white-space: normal;"&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/jAqr3XzCYibyOibUHmfe12ibKNCewzVJZMibyrJ0NrsaBTBia8a4eX4P8FVuiaEbiatKYTBatZEsAcvZaVlVJVI9XZ7zw/0?wx_fmt=png"/&gt;&lt;/center&gt;&lt;p&gt;混淆矩阵和代价矩阵的差异就在于代价矩阵提供了跟多的误分类损失信息，其对角元素皆为0。而混淆举证只提供了TP，TN，FP，FN四类样本的比例，它常用的统计量则为正确率和错误率：&lt;/p&gt;&lt;p&gt;Accuracy: (TP + TN)/(TP+TN+FP+FN)&lt;/p&gt;&lt;p&gt;Error Rate = 1 – Accuracy = (FP+FN)/(TP+TN+FP+FN)&lt;/p&gt;&lt;p&gt;如前文所提，混淆矩阵可能会提供误导性结果，并且它对数据变动非常敏感。更进一步，我们可以从混淆矩阵衍生出很多统计量，其中如下测度就提供了关于不平衡数据精度的更好度量：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;准确率(Preciosion)：&lt;/strong&gt;正类样本分类准确性的度量，即被标记为正类的观测中被正确分类的比例。&lt;/p&gt;&lt;p&gt;Precision = TP / (TP + FP)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;召回率(Recall)：&lt;/strong&gt;所有实际正类样本被正确分类的比率。也被称作敏感度(Sensitivity)&lt;/p&gt;&lt;p&gt;Recall = TP / (TP + FN)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;F测度(F measure)：&lt;/strong&gt;结合准确率和召回率作为分类有效性的测度。具体公式如下(ß常取1)：&lt;/p&gt;&lt;p&gt;F measure = ((1 + β)² × Recall × Precision) / ( β² × Recall + Precision )&lt;/p&gt;&lt;p&gt;尽管这些测度比正确率和错误率更好，但总的说来对于衡量分类器而言还不够有效。比如，准确率无法刻画负类样本的正确率。召回率只针对实际正类样本的分类结果。这也就是说，我们需要寻找更好的测度来评价分类器。&lt;/p&gt;&lt;p&gt;谢天谢地!我们可以通过ROC(Receiver Operationg Characterstics)曲线来衡量分类预测精度。这也是目前广泛使用的评估方法。ROC曲线是通过绘制TP率(Sensitivity)和FP率(Specificity)的关系得到的。&lt;/p&gt;&lt;p&gt;Specificity = TN / (TN + FP)&lt;/p&gt;&lt;p&gt;ROC图上的任意一点都代表了单个分类器在一个给定分布上的表现。ROC曲线之所以有用是因为它提供了分类数据收益(TP)和损失(FP)的可视化信息。ROC曲线下方区域的面积(AUC)越大，整体分类精度就越高。&lt;/p&gt;&lt;p&gt;但有时ROC曲线也会失效，它的不足包括：&lt;/p&gt;&lt;ol style="margin-bottom: 16px; color: rgb(51, 51, 51); font-family: &amp;#39;microsoft yahei&amp;#39;; font-size: 15px; line-height: 25px; white-space: normal;" class=" list-paddingleft-2"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;对于偏态分布的数据，可能会高估精度&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;没有提供分类表现的置信区间&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;无法提供不同分类器表现差异的显著性水平&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;作为一种替代方法，我们也可以选择别的可视化方式比如PR曲线和代价曲线。特别地，代价曲线被认为有以图形方式描述分类器误分类代价的能力。但在90%的场合中，ROC曲线已经足够好。&lt;/p&gt;&lt;h3 style="border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(238, 238, 238); margin-bottom: 16px; color: rgb(68, 68, 68); font-family: &amp;#39;microsoft yahei&amp;#39;; line-height: 25px; white-space: normal;"&gt;&lt;strong&gt;在R中进行不平衡数据分类&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;我们已经学习了不平衡分类的一些重要理论技术。是时候来应用它们了!在R中，诸如ROSE包和EMwR包都可以帮助我们快速实现采样过程。我们将以一个二分类案例做演示。&lt;/p&gt;&lt;p&gt;ROSE(Random Over Sampling Examples)包可以帮助我们基于采样和平滑自助法(smoothed bootstrap)来生成人工样本。这个包也提供了一些定义良好的函数来快速完成分类任务。&lt;/p&gt;&lt;p&gt;让我们开始吧&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/jAqr3XzCYibyOibUHmfe12ibKNCewzVJZMibPicX3YGk9r3UTAOW4FdhEBoZMQOiblknkgIoEqsTW2MMhGHAKftVsfxQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;ROSE包中内置了一个叫做hacide的不平衡数据集，它包括hacide.train和hacide.test两个部分，让我们把它读入R环境：&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/jAqr3XzCYibyOibUHmfe12ibKNCewzVJZMibDicJ6UfTaKrW3icKWia6ibW7EvJKdo0XcjTukIo2HlLicHELM6PRUOV7pCw/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;如你所见，数据集有3个变量的1000个观测。cls是响应变量，x1和x2是解释变量。让我们检查下cls的不平衡程度：&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/jAqr3XzCYibyOibUHmfe12ibKNCewzVJZMibPYwXZJMBk6va1jnBcsQniatGicqGMAX2kdzibrvLeRas7obfsX8dl9fTw/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;可以看到，数据集中只有2%的正样本，其余98%都属于负类。数据的不平衡性极其严重。那么，这对我们的分类精度会带来多大影响?我们先建立一个简单的决策树模型：&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/jAqr3XzCYibyOibUHmfe12ibKNCewzVJZMibU4ibXCqCvOEHwQS4Umbo2xYNg09glBkxfY6ggjtqkr7hUxYLZovwfOQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;然我们看看这个模型的预测精度，ROSE包提供了名为accuracy.meas()的函数，它能用来计算准确率，召回率和F测度等统计量。&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/jAqr3XzCYibyOibUHmfe12ibKNCewzVJZMibOx59BQqMWYTjMrpJN1HiatGI9B4xpUJ5o1ZypyibHDUKdfFic603r4tLA/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;这些测度值看上去很有意思。如果我们设定阈值为0.5，准确率等于1说明没有被误分为正类的样本。召回率等于0.2意味着有很多样本被误分为负类。0.167的F值也说明模型整体精度很低。&lt;/p&gt;&lt;p&gt;我们再来看看模型的ROC曲线，它会给我们提供这个模型分类能力的直观评价。使用roc.curve()函数可以绘制该曲线：&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/jAqr3XzCYibyOibUHmfe12ibKNCewzVJZMibVGCLdb10dpWjMiaK5wWQ2iawBuoKBsGUxyILZAiaC1F9SnF6Hjp3SXmSA/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;AUC值等于0.6是个很槽糕的结果。因此我们很有必要在建模前将数据集修正平衡。在本案例中，决策树算法对于小类样本无能为力。&lt;/p&gt;&lt;p&gt;我们将使用采样技术来提升预测精度。这个包提供了ovun.sample()的函数来实现过采样和欠采样。&lt;/p&gt;&lt;p&gt;我们先试试过采样&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/jAqr3XzCYibyOibUHmfe12ibKNCewzVJZMibpzibnSjgbFXWKGvDia8C63LPic0JqI5azSUcfILJdHfKQRMzdzjH7OeVQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;上述代码实现了过采样方法。N代表最终平衡数据集包含的样本点，本例中我们有980个原始负类样本，所以我们要通过过采样法把正类样本也补充到980个，数据集共有1960个观测。&lt;/p&gt;&lt;p&gt;与之类似，我们也能用欠采样方法，请牢记欠采样是无放回的。&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/jAqr3XzCYibyOibUHmfe12ibKNCewzVJZMibhjI6MWYc1wlG5BTIKiaVc2QDp3wPWiashDABdia2Onqz1DoQRlxLlibb5Q/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;欠采样后数据是平衡了，但由于只剩下了40个样本，我们损失了太多信息。我们还可以同时采取这两类方法，只需要把参数改为method = “both”。这时，对小类样本会进行有放回的过采样而对大类样本则进行无放回的欠采样。&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/jAqr3XzCYibyOibUHmfe12ibKNCewzVJZMibmtVpicO0wYcxWSyibScnIve9Y5T3hm1537AbovrxL53IqCkaz7icpuJeA/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;函数的参数p代表新生成数据集中正类的比例。&lt;/p&gt;&lt;p&gt;但前文已经提过两类采样法都有自身的缺陷，欠采样会损失信息，过采样容易导致过拟合，因而ROSE包也提供了ROSE()函数来合成人工数据，它能提供关于原始数据的更好估计。&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/jAqr3XzCYibyOibUHmfe12ibKNCewzVJZMib83v1KYpaz8J3ibyeVz1PpJV0T7DdJULATffOqicPf8W2Nbu4AI5uDOTw/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;这里生成的数据量和原始数据集相等(1000个观测)。现在，我们已经用4种方法平衡了数据，我们分别建模评评估精度。&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/jAqr3XzCYibyOibUHmfe12ibKNCewzVJZMibebo0yGSM3bavDJPsSWLNt3AyOrO9QRGFRNUBb2FNgs2RHh0rJ2T90g/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/jAqr3XzCYibyOibUHmfe12ibKNCewzVJZMibrtd5Qq0t1SWTUtV9qibIhPty0g2kZzetziaicib2JicA0EIPxLMibUd4kwkw/0?wx_fmt=png"/&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/jAqr3XzCYibyOibUHmfe12ibKNCewzVJZMib1PVAqgIhtc50FXglI6e1ic6yvP6zUOts6OiaEdmtZHS7yIHuzApPJI6Q/0?wx_fmt=png"/&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/jAqr3XzCYibyOibUHmfe12ibKNCewzVJZMibSrB0DfxNd7obEtCfd34c407dGQ9bRBPSE7MeDJatW5XajsBzxx7aOw/0?wx_fmt=png"/&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/jAqr3XzCYibyOibUHmfe12ibKNCewzVJZMibAF6GLznVtfEn8H9EXGaIv0t0BXpRO1MWtKU0UyJ4C2t6UkP9icMGRjQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;因此，我们发现利用人工数据合成法可以带来最高的预测精度，它的表现比采样法要好。这一技术和更稳健的模型结合(随机森林，提升法)可以得到更高的精度。&lt;/p&gt;&lt;p&gt;这个包为我们提供了一些基于holdout和bagging的模型评估方法，这有助于我们判断预测结果是否有太大的方差。&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/jAqr3XzCYibyOibUHmfe12ibKNCewzVJZMib9vXBzShic7VVblog2kc9LITN1icP0rbsNLgcAfDSmcwBFYhEwoQdxEdg/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;可以发现预测精度维持在0.98附近，这意味着预测结果波动不大。类似的，你可以用自助法来评估，只要把method.asses改为”BOOT”。extr.pred参数是一个输出预测结果为正类的列的函数。&lt;/p&gt;&lt;h3 style="border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(238, 238, 238); margin-bottom: 16px; color: rgb(68, 68, 68); font-family: &amp;#39;microsoft yahei&amp;#39;; line-height: 25px; white-space: normal;"&gt;&lt;strong&gt;结语&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;当我们面对不平衡数据集时，我们常常发现利用采样法修正的效果不错。但在本例中，人工数据合成比传统的采样法更好。为了得到更好的结果，你可以使用一些更前沿的方法，诸如基于boosting 的人工数据合成。&lt;/p&gt;&lt;p&gt;End.&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Sun, 18 Sep 2016 10:32:09 +0800</pubDate>
    </item>
    <item>
      <title>Machine Learning：一部气势恢宏的人工智能发展史</title>
      <link>http://www.iwgc.cn/link/2730057</link>
      <description>&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/jAqr3XzCYibyOibUHmfe12ibKNCewzVJZMibomBbkhtUiat4zHWnnlZDlAUvuicYkU1rk9uTJianm2og5hfLbGDYZKMlA/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;作者：DataCastle&lt;/p&gt;&lt;p&gt;主要介绍了机器学习的从产生，发展，低潮和全盛的历史。&lt;/p&gt;&lt;p&gt;AlphaGo的胜利，无人驾驶的成功，模式识别的突破性进展，人工智能的的飞速发展一次又一次地挑动着我们的神经。作为人工智能的核心，机器学习也在人工智能的大步发展中备受瞩目，光辉无限。&lt;/p&gt;&lt;p&gt;如今，机器学习的应用已遍及人工智能的各个分支，如专家系统、自动推理、自然语言理解、模式识别、计算机视觉、智能机器人等领域。&lt;/p&gt;&lt;p&gt;但也许我们不曾想到的事机器学习乃至人工智能的起源，是对人本身的意识、自我、心灵等哲学问题的探索。而在发展的过程中，更是融合了统计学、神经科学、信息论、控制论、计算复杂性理论等学科的知识。&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/jAqr3XzCYibyOibUHmfe12ibKNCewzVJZMibmFvHEmMYYBSGtgibibfuAKdRgzzUSC5rHZE4nRWpH8GhgiaUzZJPxffWg/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;总的来说，机器学习的发展是整个人工智能发展史上颇为重要的一个分支。其中故事一波三折，令人惊讶叹服，颇为荡气回肠。&lt;/p&gt;&lt;p&gt;其中穿插了无数牛人的故事，在下面的介绍中，你将会看到以下神级人物的均有出场，我们顺着ML的进展时间轴娓娓道来：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/jAqr3XzCYibyOibUHmfe12ibKNCewzVJZMibTpymNIweDZ76TV5MgP1q6ibFNnr9PpxCIcsZKOmBVM2n88w8zwWXSGg/0?wx_fmt=jpeg"/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;h3 style="border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(238, 238, 238); margin-bottom: 16px; color: rgb(68, 68, 68); font-family: &amp;#39;microsoft yahei&amp;#39;; line-height: 25px; white-space: normal;"&gt;&lt;strong&gt;基础奠定的热烈时期&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;20世纪50年代初到60年代中叶&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Hebb于1949年基于神经心理学的学习机制开启机器学习的第一步。&lt;/strong&gt;此后被称为Hebb学习规则。Hebb学习规则是一个无监督学习规则，这种学习的结果是使网络能够提取训练集的统计特性，从而把输入信息按照它们的相似性程度划分为若干类。这一点与人类观察和认识世界的过程非常吻合，人类观察和认识世界在相当程度上就是在根据事物的统计特征进行分类。&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/jAqr3XzCYibyOibUHmfe12ibKNCewzVJZMib2N3ic3lgt2BgadGgDGmOOtrNj4s2Zpx96zibkjEdfgibedPWXMuQzhCXw/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;从上面的公式可以看出，权值调整量与输入输出的乘积成正比，显然经常出现的模式将对权向量有较大的影响。在这种情况下，Hebb学习规则需预先定置权饱和值，以防止输入和输出正负始终一致时出现权值无约束增长。&lt;/p&gt;&lt;p&gt;Hebb学习规则与“条件反射”机理一致，并且已经得到了神经细胞学说的证实。比如巴甫洛夫的条件反射实验：每次给狗喂食前都先响铃，时间一长，狗就会将铃声和食物联系起来。以后如果响铃但是不给食物，狗也会流口水。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1950年，阿兰·图灵创造了图灵测试来判定计算机是否智能。&lt;/strong&gt;图灵测试认为，如果一台机器能够与人类展开对话(通过电传设备)而不能被辨别出其机器身份，那么称这台机器具有智能。这一简化使得图灵能够令人信服地说明“思考的机器”是可能的。&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/jAqr3XzCYibyOibUHmfe12ibKNCewzVJZMibib4xSRJlGTApYWyD6VYS4AueBkaBJC4uAdJoGZLsNsAEEBVXFDaicF6g/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2014年6月8日，一台计算机(计算机尤金·古斯特曼是一个聊天机器人，一个电脑程序)成功让人类相信它是一个13岁的男孩，成为有史以来首台通过图灵测试的计算机。&lt;/strong&gt;这被认为是人工智能发展的一个里程碑事件。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1952，IBM科学家亚瑟·塞缪尔开发了一个跳棋程序。&lt;/strong&gt;该程序能够通过观察当前位置，并学习一个隐含的模型，从而为后续动作提供更好的指导。塞缪尔发现，伴随着该游戏程序运行时间的增加，其可以实现越来越好的后续指导。&lt;/p&gt;&lt;p&gt;通过这个程序，塞缪尔驳倒了普罗维登斯提出的机器无法超越人类，像人类一样写代码和学习的模式。他创造了“机器学习”，并将它定义为“可以提供计算机能力而无需显式编程的研究领域”。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1957年，罗森·布拉特基于神经感知科学背景提出了第二模型，非常的类似于今天的机器学习模型。&lt;/strong&gt;这在当时是一个非常令人兴奋的发现，它比Hebb的想法更适用。基于这个模型罗森·布拉特设计出了第一个计算机神经网络——感知机(the perceptron)，它模拟了人脑的运作方式。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3年后，维德罗首次使用Delta学习规则用于感知器的训练步骤。&lt;/strong&gt;这种方法后来被称为最小二乘方法。这两者的结合创造了一个良好的线性分类器。&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/jAqr3XzCYibyOibUHmfe12ibKNCewzVJZMibovAf0lFrEXbZUSlvHpCC1eHEaicGib9MesgUk2qJibwSLViaV8MScoVicrQ/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1967年，最近邻算法(The nearest neighbor algorithm)出现，由此计算机可以进行简单的模式识别。&lt;/strong&gt;kNN算法的核心思想是如果一个样本在特征空间中的k个最相邻的样本中的大多数属于某一个类别，则该样本也属于这个类别，并具有这个类别上样本的特性。该方法在确定分类决策上只依据最邻近的一个或者几个样本的类别来决定待分样本所属的类别。&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/jAqr3XzCYibyOibUHmfe12ibKNCewzVJZMibJ0Hf3sQlgtPsfERJPdyab5pOHunBGvYem24FK4gqJuCjejicTCDWekQ/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;kNN的优点在于易于理解和实现，无需估计参数，无需训练，适合对稀有事件进行分类，特别适合于多分类问题(multi-modal,对象具有多个类别标签)， 甚至比SVM的表现要好。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Han等人于2002年尝试利用贪心法，针对文件分类实做可调整权重的k最近邻居法WAkNN (weighted adjusted k nearest neighbor)，以促进分类效果;&lt;/strong&gt;而Li等人于2004年提出由于不同分类的文件本身有数量上有差异，因此也应该依照训练集合中各种分类的文件数量，选取不同数目的最近邻居，来参与分类。&lt;/p&gt;&lt;p&gt;1969年马文·明斯基将感知器兴奋推到最高顶峰。他提出了著名的XOR问题和感知器数据线性不可分的情形。&lt;/p&gt;&lt;p&gt;明斯基还把人工智能技术和机器人技术结合起来，开发出了世界上最早的能够模拟人活动的机器人Robot C，使机器人技术跃上了一个新台阶。明斯基的另一个大举措是创建了著名的“思维机公司”(Thinking Machines，Inc.)，开发具有智能的计算机。&lt;/p&gt;&lt;p&gt;此后，神经网络的研究将处于休眠状态，直到上世纪80年代。尽管BP神经的想法由林纳因马在1970年提出，并将其称为“自动分化反向模式”，但是并未引起足够的关注。&lt;/p&gt;&lt;h3 style="border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(238, 238, 238); margin-bottom: 16px; color: rgb(68, 68, 68); font-family: &amp;#39;microsoft yahei&amp;#39;; line-height: 25px; white-space: normal;"&gt;&lt;strong&gt;停滞不前的冷静时期&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;20世纪60年代中叶到70年代末&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;从60年代中到70年代末，机器学习的发展步伐几乎处于停滞状态。虽然这个时期温斯顿(Winston)的结构学习系统和海斯·罗思(Hayes Roth)等的基于逻辑的归纳学习系统取得较大的进展，但只能学习单一概念，而且未能投入实际应用。此外，神经网络学习机因理论缺陷未能达到预期效果而转入低潮。&lt;/p&gt;&lt;p&gt;这个时期的研究目标是模拟人类的概念学习过程，并采用逻辑结构或图结构 作为机器内部描述。机器能够采用符号来描述概念(符号概念获取)，并提出关于学习概念的各种假设。&lt;/p&gt;&lt;p&gt;事实上，这个时期整个AI领域都遭遇了瓶颈。当时的计算机有限的内存和处理速度不足以解决任何实际的AI问题。要求程序对这个世界具有儿童水平的认识，研究者们很快发现这个要求太高了：1970年没人能够做出如此巨大的数据库，也没人知道一个程序怎样才能学到如此丰富的信息。&lt;/p&gt;&lt;h3 style="border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(238, 238, 238); margin-bottom: 16px; color: rgb(68, 68, 68); font-family: &amp;#39;microsoft yahei&amp;#39;; line-height: 25px; white-space: normal;"&gt;&lt;strong&gt;重拾希望的复兴时期&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;20世纪70年代末到80年代中叶&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;从70年代末开始，人们从学习单个概念扩展到学习多个概念，探索不同的学习 策略和各种学习方法。这个时期，机器学习在大量的时间应用中回到人们的视线，又慢慢复苏。&lt;/p&gt;&lt;p&gt;1980年，在美国的卡内基梅隆大学(CMU)召开了第一届机器学习国际研讨会，标志着机器学习研究已在全世界兴起。此后，机器归纳学习进入应用。&lt;/p&gt;&lt;p&gt;经过一些挫折后，多层感知器(MLP)由伟博斯在1981年的神经网络反向传播(BP)算法中具体提出。当然BP仍然是今天神经网络架构的关键因素。有了这些新思想，神经网络的研究又加快了。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1985 -1986神经网络研究人员(鲁梅尔哈特，辛顿，威廉姆斯-赫，尼尔森)先后提出了MLP与BP训练相结合的理念。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;一个非常著名的ML算法由昆兰在1986年提出，我们称之为决策树算法，更准确的说是ID3算法。这是另一个主流机器学习的火花点。此外，与黑盒神经网络模型截然不同的是，决策树ID3算法也被作为一个软件，通过使用简单的规则和清晰的参考可以找到更多的现实生活中的使用情况。&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/jAqr3XzCYibyOibUHmfe12ibKNCewzVJZMibPV2kSIZicQxMX4UCM1iaZTmR8BEDNxe5wVJFfVPMpfIKvmmvQBMAmB6A/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;决策树是一个预测模型，他代表的是对象属性与对象值之间的一种映射关系。树中每个节点表示某个对象，而每个分叉路径则代表的某个可能的属性值，而每个叶结点则对应从根节点到该叶节点所经历的路径所表示的对象的值。决策树仅有单一输出，若欲有复数输出，可以建立独立的决策树以处理不同输出。数据挖掘中决策树是一种经常要用到的技术，可以用于分析数据，同样也可以用来作预测。&lt;/p&gt;&lt;h3 style="border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(238, 238, 238); margin-bottom: 16px; color: rgb(68, 68, 68); font-family: &amp;#39;microsoft yahei&amp;#39;; line-height: 25px; white-space: normal;"&gt;&lt;strong&gt;现代机器学习的成型时期&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;20世纪90年初到21世纪初&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;1990年,Schapire最先构造出一种多项式级的算法 ,对该问题做了肯定的证明 ,这就是最初的Boosting算法。一年后 ,Freund提出了一种效率更高的Boosting算法。但是,这两种算法存在共同的实践上的缺陷 ,那就是都要求事先知道弱学习算法学习正确的下限。&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/jAqr3XzCYibyOibUHmfe12ibKNCewzVJZMibFlI6IELsmcJXib5F69Ej0S0JXbiaBbCIBoic8LhLzSl6yfAnw52g6hWBQ/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;1995年 ,Freund和schapire改进了Boosting算法 ,提出了 AdaBoost (Adap tive Boosting)算法,该算法效率和 Freund于 1991年提出的 Boosting算法几乎相同 ,但不需要任何关于弱学习器的先验知识 ,因而更容易应用到实际问题当中。&lt;/p&gt;&lt;p&gt;Boosting方法是一种用来提高弱分类算法准确度的方法,这种方法通过构造一个预测函数系列,然后以一定的方式将他们组合成一个预测函数。他是一种框架算法,主要是通过对样本集的操作获得样本子集,然后用弱分类算法在样本子集上训练生成一系列的基分类器。&lt;/p&gt;&lt;p&gt;同年，机器学习领域中一个最重要的突破，支持向量(support vector machines, SVM )，由瓦普尼克和科尔特斯在大量理论和实证的条件下年提出。从此将机器学习社区分为神经网络社区和支持向量机社区。&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/jAqr3XzCYibyOibUHmfe12ibKNCewzVJZMibsNEia1VTUCbOxEH0AnIxlibX49WVbCWZ0PP48JRcSYbPRFtmddrN9SDQ/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;然而两个社区之间的竞争并不那么容易，神经网络要落后SVM核化后的版本将近2000s 。支持向量机在以前许多神经网络模型不能解决的任务中取得了良好的效果。此外，支持向量机能够利用所有的先验知识做凸优化选择，产生准确的理论和核模型。因此，它可以对不同的学科产生大的推动，产生非常高效的理论和实践改善。&lt;/p&gt;&lt;p&gt;支撑向量机 , Boosting，最大熵方法(比如logistic regression, LR)等。这些模型的结构基本上可以看成带有一层隐层节点(如SVM, Boosting)，或没有隐层节点(如LR)。这些模型在无论是理论分析还是应用都获得了巨大的成功。&lt;/p&gt;&lt;p&gt;另一个集成决策树模型由布雷曼博士在2001年提出，它是由一个随机子集的实例组成，并且每个节点都是从一系列随机子集中选择。由于它的这个性质，被称为随机森林(RF)，随机森林也在理论和经验上证明了对过拟合的抵抗性。&lt;/p&gt;&lt;p&gt;甚至连AdaBoost算法在数据过拟合和离群实例中都表现出了弱点，而随机森林是针对这些警告更稳健的模型。随机森林在许多不同的任务，像DataCastle、Kaggle等比赛等都表现出了成功的一面。&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/jAqr3XzCYibyOibUHmfe12ibKNCewzVJZMibcicmTD4Aia4iaibookg4rYWDicwBoBGFDQsgk3bZiaINT7qnic51LEia42469w/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;h3 style="border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(238, 238, 238); margin-bottom: 16px; color: rgb(68, 68, 68); font-family: &amp;#39;microsoft yahei&amp;#39;; line-height: 25px; white-space: normal;"&gt;&lt;strong&gt;大放光芒的蓬勃发展时期&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;21世纪初至今&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在机器学习发展分为两个部分，浅层学习(Shallow Learning)和深度学习(Deep Learning)。浅层学习起源上世纪20年代人工神经网络的反向传播算法(Back-propagation)的发明，使得基于统计的机器学习算法大行其道，虽然这时候的人工神经网络算法也被称为多层感知机(Multiple layer Perception)，但由于多层网络训练困难，通常都是只有一层隐含层的浅层模型。&lt;/p&gt;&lt;p&gt;神经网络研究领域领军者Hinton在2006年提出了神经网络Deep Learning算法，使神经网络的能力大大提高，向支持向量机发出挑战。 2006年，机器学习领域的泰斗Hinton和他的学生Salakhutdinov在顶尖学术刊物《Scince》上发表了一篇文章，开启了深度学习在学术界和工业界的浪潮。&lt;/p&gt;&lt;p&gt;这篇文章有两个主要的讯息：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1)很多隐层的人工神经网络具有优异的特征学习能力，学习得到的特征对数据有更本质的刻划，从而有利于可视化或分类;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2)深度神经网络在训练上的难度，可以通过“逐层初始化”( layer-wise pre-training)来有效克服，在这篇文章中，逐层初始化是通过无监督学习实现的。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Hinton的学生Yann LeCun的LeNets深度学习网络可以被广泛应用在全球的ATM机和银行之中。同时，Yann LeCun和吴恩达等认为卷积神经网络允许人工神经网络能够快速训练，因为其所占用的内存非常小，无须在图像上的每一个位置上都单独存储滤镜，因此非常适合构建可扩展的深度网络，卷积神经网络因此非常适合识别模型。&lt;/p&gt;&lt;p&gt;2015年，为纪念人工智能概念提出60周年，LeCun、Bengio和Hinton推出了深度学习的联合综述。&lt;/p&gt;&lt;p&gt;深度学习可以让那些拥有多个处理层的计算模型来学习具有多层次抽象的数据的表示。这些方法在许多方面都带来了显著的改善，包括最先进的语音识别、视觉对象识别、对象检测和许多其它领域，例如药物发现和基因组学等。深度学习能够发现大数据中的复杂结构。它是利用BP算法来完成这个发现过程的。BP算法能够指导机器如何从前一层获取误差而改变本层的内部参数，这些内部参数可以用于计算表示。深度卷积网络在处理图像、视频、语音和音频方面带来了突破，而递归网络在处理序列数据，比如文本和语音方面表现出了闪亮的一面。&lt;/p&gt;&lt;p&gt;当前统计学习领域最热门方法主要有deep learning和SVM(supportvector machine)，它们是统计学习的代表方法。可以认为神经网络与支持向量机都源自于感知机。&lt;/p&gt;&lt;p&gt;神经网络与支持向量机一直处于“竞争”关系。SVM应用核函数的展开定理，无需知道非线性映射的显式表达式;由于是在高维特征空间中建立线性学习机，所以与线性模型相比，不但几乎不增加计算的复杂性，而且在某种程度上避免了“维数灾难”。而早先的神经网络算法比较容易过训练，大量的经验参数需要设置;训练速度比较慢，在层次比较少(小于等于3)的情况下效果并不比其它方法更优。&lt;/p&gt;&lt;p&gt;神经网络模型貌似能够实现更加艰难的任务，如目标识别、语音识别、自然语言处理等。但是，应该注意的是，这绝对不意味着其他机器学习方法的终结。尽管深度学习的成功案例迅速增长，但是对这些模型的训练成本是相当高的，调整外部参数也是很麻烦。同时，SVM的简单性促使其仍然最为广泛使用的机器学习方式。&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/jAqr3XzCYibyOibUHmfe12ibKNCewzVJZMibA1y08J9nM2NbtOXsKVuvSckiawMErklPAwbRrHQXL01xhomx8TJWlbw/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;人工智能机器学习是诞生于20世纪中叶的一门年轻的学科，它对人类的生产、生活方式产生了重大的影响，也引发了激烈的哲学争论。但总的来说，机器学习的发展与其他一般事物的发展并无太大区别，同样可以用哲学的发展的眼光来看待。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;机器学习的发展并不是一帆风顺的，也经历了螺旋式上升的过程，成就与坎坷并存。其中大量的研究学者的成果才有了今天人工智能的空前繁荣，是量变到质变的过程，也是内因和外因的共同结果。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;回望过去，我们都会被这一段波澜壮阔的历史所折服吧。&lt;/p&gt;&lt;p&gt;End.&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Sun, 18 Sep 2016 10:32:09 +0800</pubDate>
    </item>
  </channel>
</rss>
